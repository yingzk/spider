投资者眼中的大佬，创客眼中的“大”——腾讯云，近日豪掷万代金券，助力“中国天津北辰直通硅谷创新创业大赛”！

腾讯云将作为本次直通硅谷创业大赛的钻石赞助商，为优秀项目提供万代金券的云服务支持！

首先，对于进入复赛的项目，腾讯云将提供“孵化计划”扶持服务：价值万元的腾讯云产品代金券！只要进入本次大赛复赛，完成腾讯云账号企业认证，且无任何腾讯云消费，即可获得此项扶持服务！

其次，对于进入决赛的项目，腾讯云将提供“起飞计划”扶持服务，除了包含价值万元的腾讯云代金券外，还可获得折腾讯云产品购买优惠，可再减免万元！
此外，腾讯云还为进入决赛的项目提供了价值万元的上云迁移服务以及技术支持，包括新品体验、技术咨询、解决方案等。只要进入大赛决赛，且完成腾讯云账号企业认证、无任何腾讯云消费，即可获得此项扶持服务！
而本次大赛决赛胜出的项目团队或企业，将获得由腾讯云提供的“腾飞计划”扶持服务资源，其中包含：
价值万元的腾讯云产品代金券、最高减免达万元的折云产品购买优惠、还有价值万元的上云迁移服务、价值万元的护航服务、价值万元的技术培训，还有对架构师支持新产品优先体验、产品使用技术咨询、行业解决方案咨询等！优胜的项目只要完成腾讯云账号企业认证，且无任何腾讯云消费，即可获得此项扶持服务！顺带一提，以上优惠券有效期是个月哦！

此次大赛将有家以上的优质项目参赛，分为企业组和团队组。初赛将筛去其中的九成，将有个项目进入复赛！复赛将再筛去其中的九成，共有个优质项目进行最终角逐，最终选出企业优胜项目和团队优胜项目各名！
个进入复赛项目万元=万元个进入决赛项目万元=万元个优胜项目万元=万元共计万元！外加腾讯云提供的其他各种优惠和扶持，总服务价值超过千万元！怎一个“豪”字了得！

自腾讯云联合投资机构、孵化器和产业园区等推出创业扶持计划“云创业”以来，已经为很多创业者及创业项目提供了服务支持。此次腾讯云作为钻石赞助商助力“中国天津北辰直通硅谷创新创业大赛”，将使参赛创业项目获能以更低的门槛获得云资源、技术支持、营销扶持、护航服务等全套创业资源。

中国天津北辰直通硅谷创新创业大赛是由天津市北辰区人民政府主办的大型国际创新创业大赛。

大赛以重新定义时代为主题，为大赛优胜项目团队和企业提供了万现金奖励和免费的天硅谷游学机会。等这些项目回国后，还将获得巨额的项目投资。此外，天津本地还有百亿配套扶持基金鼎力支持！今天无意间发现腾讯云镜像有 ，追求新系统的我，马上就重装了云服务器。重装完后发现，配置太低，远程桌面都变得不是很顺畅，于是装完 后便不打算另外装管理工具了。网上查了资料，可以用操作 ，这样就可以直接在本地机子管理服务器了，也可以为服务器节省空间。废话不多说，接下来介绍操作方法。       管理 使用的是， 实用工具是一个命令行实用工具，用于  语句和脚本的临时、交互执行以及自动执行  脚本撰写任务。
微软官方介绍地址 
打开命令提示符，输入  可以查看帮助
    __
    首先，我们需要用身份验证登录 
  登录成功后，开启
   修改密码为
    =当然这时候会提示，密码复杂度不够，将替换成复杂的密码就可以了
以上就开启了，并且修改了的密码
修改成功后可以用登录测试一下，因为现在已经用身份验证登录了，所以需要先退出。只需要输入回车即可
退出后重新用去登录
    输入这个命令回车后，会出现要求密码的提示，这时候输入刚刚设置的密码即可登录成功
如果提示登录失败，有可能是因为之前安装数据库的时候没有开启混合登陆模式，这个需要到注册表中去修改。
打开注册表，唤出查找框，查找，将值修改为即可
修改后就开启了 和  身份混合登录了博客地址作者介绍：周家溢，美团点评工程师， 年  前端开发经验，主要负责过好友去哪、霸王餐、点评  框架等项目的开发。在  前端开发和工程化、 开发和调试上有些经验积累和研究。

作为特邀用户，大众点评早在小程序内测阶段就开始了产品的设计和研发，「大众点评」也理所当然成为  月  号小程序上线后的首批应用之一，并在上线当天就获得了超过两百万的访问。我想大家一定迫切想知道如何在小程序的开发中少走弯路，为此我们专门总结了开发过程中的各种「坑」和经验，希望为后续的开发者们提供一些思路和建议。
大众点评 介绍
首先让我们简单了解大众点评的功能：
大众点评 主要页面一览

大众点评 产品特性
根据小程序的开发规范，我们总结出几个影响小程序产品形态的关键特性：

 实现，类  开发
代码体积不超过 
用户最多打开  层页面
不支持与 、 和其他小程序间的跳转

以上特征要求我们只为用户提供核心服务，且从产品到技术，都必须围绕「简约」二字做文章。因此，结合大众点评业务场景，最终在「大众点评」中，我们主要提供以下两种基础服务：

快速找店：通过搜索、分类列表和推荐三种形式，让用户快速找到商户，并提供包括定位、电话、点评、菜品等商户信息，帮助用户做出决策

购买团购：为用户推荐团购商品并实现交易闭环，帮助用户获得实惠


大众点评 开发经验谈
产品层面足够精简，我们再来看看技术层面如何做到简约。
前期技术选型
我们先看下项目之初开发同学的困惑：

小程序是个新鲜事物，参与开发的同事普遍对开发流程和运行原理知之甚少
在不知道小程序有多少坑的前提下，我们还是要保证在小程序开放前完成全部基础功能的开发，存在着不少风险
小程序的接口稳定性和丰富程度、安全性、连接速度等究竟如何

稍微了解小程序开发流程并测试接口后，我们发现在腾讯运维体系的支撑下，相关服务的稳定性和性能不用担心，但新的问题随之而来：

小程序暂不支持  包管理方式、不支持类  组件化开发方式、不支持类  打包方式，与现阶段前端开发有较大差别，一定程度会影响开发效率
小程序实现方面，现阶段还是基于 可参考小程序细节点说明，所以必须要考虑  和  的兼容性问题

对于任何新生的应用场景，开发环境、工具和框架不够完善都可以理解，但如何才能既保证开发过程的简单又提供一定的规范和工程化能力？为此，在遵从小程序基本框架的前提下，我们做了如下技术选型和简单封装：

项目区分开发目录和构建目录，在开发目录中进行开发，再通过  对开发目录进行构建主要处理压缩等基本功能，构建目录才是小程序真正的运行代码
引入  的 ，解决开发依赖的管理、请求接口的版本化管理，但不使用任何  包只复制一份  实现
只使用  语法，配合 ，快速检查基本  错误，现阶段小程序报错提示不够友好，部分错误由  语法错误引起
对小程序提供的  进行  封装，代码以  风格书写，以便  各种运行时的错误

与此同时，我们持续关注小程序社区和论坛的动态，比如利用社区的方案处理富文本渲染的问题，但对于部分技术和框架，我们持观望态度：

各类模拟解决组件化的方案和框架我们希望详细了解小程序的运行和构建机制，在代码逻辑相对简单的情况下，框架的封装对于我们来说弊大于利
使用  或者  等需要引入大量  代码的  语法，主要是因为  代码的限制，后续会详细介绍我们在体积优化方面所做的工作如果你只是为了学习体验小程序的开发，那就尽情使用吧

开发过程中的「坑」
接下来进入大家更关注的环节，在开发过程中，小程序开发究竟有哪些「坑」，以及我们如何应对？其实作为内测用户，在小程序开发的初期，确实遇到了不少坑，但这里不得不赞一下微信的同事，我们每次反馈问题都可以得到迅速响应，问题总是非常快的被解决。所以在这里我们并不打算谈论小程序有哪些  ，以及怎么解决等问题，想了解的朋友可以参考推荐资料中的「微信小程序常见 」。但一些技术架构，或者产品交互上的限制，还是需要第一次开发小程序的开发者引起注意。以下仅列出我们觉得比较重要的一些问题：
平台差异

小程序会在开发者工具、 设备和  设备运行，不同平台可能存在实现上的差异，从而导致少许的展现不一致。不过总体来说，兼容问题比起之前的开发方式减少很多，期望小程序团队进一步做好底层兼容，为前端程序员造福。

基础架构设计

 接口必须是 ，且需支持  版本  以上
小程序开发采用完全的前后分离方式， 层只负责提供  接口，虽然文档提到是实时更新，但发布过程中仍然存在两个版本同时被使用的问题

开发思维和技术限制

没有 \ 操作，只能通过数据改变视图
再次强调小程序最多支持级页面
开发代码  小程序编译封装的代码 = 最终的编译包  

对应的解决方案
针对上面提到的问题，我们通过自己的实践总结了一套解决方案，这里也与开发者一起分享讨论：
平台差异性
在开发过程中，我们肯定以开发者工具为主完成开发及调试，但这不代表在真机能获得与预期完全一致的展现。在过往开发  框架的经历中，我们也总会遇到 、、 表现不一致的问题，这里既涉及到底层实现的差异，也涉及到不同开发团队的沟通问题，这个问题很难一劳永逸地被完美解决。
所以针对这个问题，我们的办法是通过  的方式，类似  端日志的方式，记录关键功能的信息，再辅以常用的真机调试、抓包等调试技巧。
 服务支持
随着苹果对  的推动，大众点评也完成了全站  化，所以在我们项目后期，这个问题自然消失了。但对于一些中小型公司或者个人开发者来说，这仍然是一个问题，这里推荐直接使用腾讯云的小程序云服务来解决。
 接口版本化
应对思路并不复杂，可以通过  向前兼容，或者  版本化管理在  请求中统一携带当前小程序的版本信息方式解决，我们采用了后者。
开发思维的转变
在传统的  开发模式下，前端习惯于直接更改  内容，这种方案在大量  需要更新时就会变得非常低效，之后随着 的推广和   技术，大家慢慢习惯于通过变动数据来实现视图的更新，不过在  始终保留着对  进行操作的 。但是在小程序里面，由于  代码是运行在  中，所以不存在  和  的概念，任何相关的操作都是无效的你可能发现在开发者工具里面可以使用，但是在真机一定是不行的
因此，有些常见方案的实现思路就要发生转变，包括但不局限于以下的操作：

类似微信通讯录的锚点切换可以使用微信的  实现
计算内容的高度决定截行  显示「展开收起」开关

 级页面限制
解决这个问题，其实大致有三种思路：

优化产品交互流程，尽量简化产品流程直到少于级
 思路，在页面达到第五级之后，后续所有页面打开都通过方式。带来的问题也显而易见，如果用户在第个页面点击返回，他只能看到第四个页面，中间的  个页面都不见了，适用于特定场景
 的思路，采用技术手段保证主流程只有级在我们的实现中，既有把搜索功能作为页面的一个状态而非页面的方式，也有把订单提交后以  的方式销毁当前页面的办法，之后通过统一封装页面路由的方式，采用  接口判断当前页面是否在历史堆栈中，没有则通过  接口打开，有则通过  的方式返回，在页面侧  事件中去读取最新的参数信息，完成页面的更新动作

优化代码体积
最后，我们单独来聊一聊代码体积优化的问题。
为什么要优化体积？
虽然现阶段大众点评仅提供了找店和团购两个主要功能，但  的代码量毕竟太小，为了在  的体积下把更多的功能和更好的体验带给用户，并未为以后的扩展预留足够的空间，这就要求我们在代码的体积控制上必须「斤斤计较」。
小程序体积是如何计算的？
小程序会把我们项目的 、、、 全部转化为 ，合并成一个文件上传到微信云服务器。当用户第一次打开小程序时再从服务中下载并解析。以我们的项目为例，通过工具的压缩和统计，在我们计算出项目体积达到了，经过微信编译上传，在手机端预览下载时，下载的文件达到了，这正是开发者工具显示告诉我们的编译包大小。    
如何优化？

编译层面：在编译包和开发包直接存在了 的差距，开发者是否有办法通过代码写法进行优化，还需要我们去深入的了解。

构建层面：自己对 、、 进行压缩，通过我们的项目测试，在使用微信默认的代码压缩上传的情况下，我们的项目体积增大了

接口层面：  返回的数据尽量是最小的，且最好是可以直接展示的，也就是说需要在我们的  接入层要完成对数据的处理工作，比如时间、距离的展示等等
开发层面：

 尽可能的使用  复用，且减少样式的命名长度，背景图片统一以  的方式使用，因为样式的压缩只能是去掉空格，在页面展示复杂的情况下， 可能会占用比  更多的体积在微信开发者工具  版上已经修复了因为  的使用导致引入冗余编译文件，增大编译包的问题；
 功能尽可能以模块化的方式，如果你的小程序需要多个开发团队参与，主要负责团队需要设计提供统一的前端公共服务；
精简 ，我们发现当  被编译成  后会占用非常大的体积减少一个压缩后  的 ，可以减少编译包 



推荐资料

微信开发者文档    ，建议在开发前完整地阅读文档和  使用说明 
微信小程序常见 微信官方社区的  和场景问题描述，前人经验的总结，防止再次掉坑 
一起脱去小程序的外套和内衣  微信小程序架构解析

大众点评 开发小结
点评前端团队有幸鉴证了微信小程序从早期内测到功能和基础设施逐步完善的整个过程，再次感谢小程序团队始终聆听我们开发者的声音和意见，即时响应，不断丰富  功能，持续完善开发体验。这让我们有理由相信，围绕微信小程序的生态会越来越完善，并且随着腾讯云在  服务层对小程序的支持越发有力，对于中小型企业和个人创业者来说，微信小程序的开发门槛变得更低。在这里也欢迎更多的微信小程序开发者和创业者的加入。

相关推荐
一起脱去小程序的外套和内衣  微信小程序架构解析
【腾讯云的种玩法】元体验腾讯云小程序后端解决方案
从前端界面开发谈微信小程序体验作者：范健
导语： 共享内存无锁队列是老调重弹了，相关的实现网上都能找到很多。但看了公司内外的很多实现，都有不少的问题，于是自己做了重新实现。主要是考虑了一些异常情况加强健壮性，并且考虑了的内存模型。

为什么需要共享内存无锁队列？
为了便于查找定位问题，需要做一个日志收集跟踪系统，每个业务模块都需要调用输出格式化的本地日志并将日志发送到远端。
为了避免发送日志阻塞业务，典型的做法是业务线程将日志写入队列，另一个线程异步地从队列中读取数据并发送。考虑到性能，且日志数据能容忍小概率的丢失，所以队列不应该是在磁盘上。又因为业务模块可能是多线程模式也可能是多进程模式，所以队列应该是在共享内存中。
简单的做法是，对队列的读写都加锁，但这样无疑会导致高并发下性能瓶颈就在这把锁上。所以我们需要无锁队列。看了公司内外很多版本的无锁队列实现，多多少少都有些问题，所以自己重新实现了一个版本。
环形数组
大部分无锁队列都是用环形数组实现的，简单高效，这里也不例外。假设队列长度为_，用_表示可读的位置，用_表示可写的位置。
每次修改_或_的时候都需要将其归一化：
_ = _
队列已使用空间_的计算为：
_ = _ 
  _  _  _  _  _
判断队列的条件为：
_ == _
如果不做特殊处理，判断队列的条件和的条件一样，从而难以区分。所以我们将队列可写入长度设为_。这样判断长度为_的数据是否可以写入的条件为：
 注意是  而不是 = 
_  _  _
一写一读
先来考虑一写一读的场景，实现起来最简单。
写操作：先判断是否可以写入，如果可以，则先写数据，写完数据后再修改_。
读操作：先判断是否可以读取_  ，如果可以，则先读数据，读完再修改_。
因为_和_都只会有一个地方去写，所以其实不需要加锁也不需要原子操作，直接修改即可。需要注意读写数据的时候都需要考虑遇到数组尾部的情况。
多写一读
再来考虑复杂些的多写一读的场景。因为多个生产者都会修改_，所以在不加锁的情况下必须使用原子操作，笔者使用的是内置原子操作函数：
 __系列的内置函数在之后已经过时，不建议使用
 的函数就是用__系列内置函数实现的，所以也考虑了提出的内存模型
 该函数在 == 的时候，将 = ，并返回，否则返回，并将 = 
 最后两个参数分别表示修改成功和失败时使用的内存模型，后面会讲
 _____          _  _
一种错误实现：
有的实现在写入过程中对_使用了多次原子操作，比如先原子增加_，再写入数据，如果写入失败，再原子减小_，看起来每次操作都是原子的，但多个原子操作连在一起就不是原子操作了，整个写入过程中对_应当只有一次原子操作。
常见的错误实现：
 先读取_，判断新的数据是否有足够的空间可以写入。 如果没有足够空间则返回队列满。
 如果有足够的空间，则准备写入。 一写的时候，是先写数据再改_。多写的时候为了避免同时写到同一片内存，需要先申请空间再写入数据。即先原子增加_，如果成功，再写入数据。 为了避免在生产者还未写完数据的时候，消费者就尝试读取，所以需要个同步机制告诉消费者数据正在写入中。比如头部预留一个字节，初始为表示正在写入，写完数据后再改为表示写入完成。头部中一般还有字节表示数据长度。
 消费者发现_  即可尝试读取。 如果首字节为，表示数据正在写入，等待。 如果首字节不为，表示数据已写完，可以读取。
 消费者读取数据后，需要将_前移到合适的位置，且因为只有一个消费者，这里无需使用原子操作。
这种实现看似，其实也有问题。如果生产者在修改_之后，在修改头部首字节为之前，这段时间内的话，就会导致消费者永远停留在等待生产者写完的状态上，且这个状态无法自动恢复。
我的优化一：

消费者发现头部首字节为，则等待，但最多等待一段时间比如。
在写入数据限制了最大长度的前提下，以现代计算机的速度，从修改_然后数据最后修改头部首字节为，这段时间是非常快的，远小于。
如果等待后，发现首字节还是，则认为该生产者了，根据头部中的长度信息，向前跳过这个非法数据块。

但如果生产者还没来得及写入数据长度就了呢？就想跳过非法数据块也不知道该跳多少了。
我的优化二：
 将队列分成个定长，定义如下：
  {
  {
      {
          _
         _ __
         _ __
         _ __
     }
      __
 }
  _

  _ __  {
      _  __ == __
          __ = 
          __  __
          __ = 
 }
}
 生产者写数据时先计算需要的_，再原子地将_前移_。写数据的时候第一个最后写，每个内部依然是最后写头部首字节_ = 。
 当等待后发现_还是，认为写入者之后，就可以以为单位向前跳跃，直到跳到一个合法或者没有可以读取的数据为止。合法判断条件为。
这样就算生产者在任意时刻，消费者都有能力自动恢复，找到下一个合法。但如果消费者并没有真正只是因为某种神秘的原因写入太慢超过了，怎么办？

首先，因为消费者已经跳过，所以它这次写入的数据肯定是不会被消费了，即极小概率会遗漏数据。
其次，我们考虑更极小概率的情况，只有当生产者慢到队列循环了完整一轮，其它生产者重新申请到这片准备写入，才会产生数据脏写。
再次，就算真的出现数据脏写，一般头部的_和_等信息不会对不上，消费者每次消费数据都会通过函数检测，检测不通过的都会跳过。
最后，如果说非要考虑极端情况，可以通过在头部中再加入_和_来校验数据。笔者考虑到日志数据容忍这种极小概率的错乱，所以省略了。

内存模型
看似完美了，真的吗？其实不然。以上还没有考虑内存模型。因为编译器的优化，实际代码执行顺序不一定是你写的顺序。也就是说虽然我们是先写数据最后设置_ = ，但实际执行顺序并不一定真的如此，有可能先执行了_ = ，再执行数据，这就乱套了。因此我们需要指定内存模型。关于内存模型推荐参阅文章
生产者对于_的修改，内存模型应该使用。保证在这个操作之前的 不会重排到这个操作之后去，这样就不会向消费者提前释放可用信号。
_____  ___
 消费者对于_的读取，内存模型应该使用。保证在这个操作之后的 不会重排到这个操作之前去，这样就不会提前读到生产者还未写完的数据。
_____ ___
 对_的修改，即调用___函数，最后两个参数应该都是_，即内存模式使用，即没有约束。因为_只是多生产者之间用来做类似互斥的竞争，本来就是靠_真正约束生产者和消费者之间的行为顺序。
共享内存
另外一个值得一提的点是，共享内存我使用，而非。因为担心一台机器上部署的程序太多，可能出现共享内存冲突的情况。万一出现共享内存冲突，被别的程序写坏了，就会出现莫名其妙的情况。所以使用指定模块相关的文件路径，就不用太担心了。
需要多读吗？
如果再进一步实现多写多读，需要对_也考虑原子操作，加上稍显复杂的检查跳跃逻辑，实现难度较高。但我们首先该问一个问题，真的需要多读吗？
我认为是不需要的：

首先，消费者可以批量读取，一次读取足够或者全部的可读数据。通过对后续业务逻辑的优化，一般单读都能满足性能要求。
其次，可以一读批量读取后再做进一步进程内多线程分发，会更加简单。
再次，如果单读真的不能满足性能要求，说明读后的业务逻辑非常重，那么这个时候，性能瓶颈就肯定不会是队列读取这里了，那么给读加锁无疑是更合适的选择。

有感而发

要写出高健壮性的代码，一定要时刻记得，程序可能会在你的任何一行代码处因为或者意外，不要想当然以为执行了上一行代码就一定会执行下一行代码。后重启是否能正常恢复？
写多线程多进程相关的逻辑，涉及到并发操作的时候，要考虑仔细，需不需要加锁？不加锁会有什么问题？
使用共享内存等共享资源时，更要想到，这资源不是我独占的，万一被有意或无意的篡改了数据该怎么办？能否尽量避免被别人篡改？如果被篡改，是否有发现和恢复机制？
不要以为你写的代码顺序就是真正的执行顺序，需要考虑内存模型。一、 背景：直播类行业发展与压力
    直播类行业爆发式发展

直播类业务是基于影音形态 以信息传递为目标的服务方式 其发展空间依赖于两种基础能力技术与资源，进而基于产品能力进行放大。
基于终端解码能力、移动普及和产品维度的进步，从端“体育赛事综艺”的直播点播形态，扩张到移动时代的游戏直播、个人直播以及细分垂直直播。直播类业务迅速成长成为一个独立行业，规模庞大，分工精细。
   视频云平台已承载业务

当前直播类业务已经进入万花筒式的发展阶段，从当前视频云平台的承载业务来看，内部业务有“全民歌”、“企鹅电竞”等为代表的个人直播与游戏直播，外部业务更有“斗鱼”“龙球”“”“全民”等众多需求。
视频云平台当前承载的业务体量大，业务数量多，已经是一个成长迅速的服务平台，那如此繁复的服务需求，带来的规划增长是什么情况呢？
   视频云平台面临的压力

第一个挑战点  资源：业务快速增长对视频云系统提出了持续扩大的资源运营压力。
以近一年的业务增长情况来看：
     设备量增长：超过越过万台规模量级；
     客户量增长：超过越过接入业务规模；
     带宽增长：更是超过，达到级线后持续海量攀升。
如此海量的服务压力，对视频平台提出了更高的要求，仅就服务能力目标来说，大容量、低成本、高质量的直播平台就是当前主要述求。
而基于腾讯云所规划的的基础服务能力能力，云所具有的更大弹性，更集中的资源管理能力，全球化的部署策略，在资源供给方面具备强大优势，可以提升交付速度、容量空间与全球服务的基础需求。视频云上云是一个使直播类业务，更具发展空间的战略方向。而视频云平台在进行云化建设之前，已经成长为一个成熟的复杂巨系统。接下来可以看一下这个巨系统上云，我们将会面临的挑战。
二、         挑战：视频云上云难点
    难点分类

核心原因：涉及多平台多部门，且机房基础环境差异大。
     平台间依赖
由于平台功能定位的不同，三大平台的主诉求与服务目标也各不相同：
互动直播：以双向传输、实时交互为需求，实时视频通信。互动直播在需要大量扩散时，多数用户仅观看，为单向传输，复用直播下行扩散能力，依赖直播平台。
直播平台：以单向传输、高扩散比为需求，有延时直播。直播内容存在点播需求，此部分业务由点播平台承载，故依赖点播平台。
点播平台：以预存储视频、按需回放为需求，非实时播放。
按上述三个平台的规划目标， 其依赖情况如下：
互动直播依赖直播：互动直播内容在需要大量扩散时，多数用户仅观看不互动，为单向传输，复用直播下行扩散能力，依赖直播平台。
互动直播、直播依赖点播：两种直播的内容，均有点播回放需求，需要依赖点播平台。
所以三大平台上云顺序由依赖顺序决定，点播直播互动直播，其中互动直播在扩散需求不大时，可与直播平台同步进行。
    自研机房与云机房环境差异大

从上述三个方面看，基础环境上的差异，对于系统架构，特别是灰度上云方案的过渡期自研云机房第三方机房并存、且流量需互通，提出了巨大的挑战。
   支撑系统上云能力
支撑系统原有设计运行环境为自研机房，且均以内网服务形态支撑各类业务，相关部分模块不具备外网服务能力。当面临云上建设时，具体矛盾凸显出来：
外网通信需求：第三方机房等环境下，需要打通统一运营平台，即面临需由外网通信条件下，进行支撑系统汇总管理独立部署无法实现汇总。原支撑系统部分业务，仅支持内网通信，需解决。
外网通信加密、加速需求：灰度上云过程中，信令需经外网穿越各机房间，需要进行加密处理，同时要保证通信效率，确保不会影响业务能力，需保障。
内网模块跨网管理需求：部分业务模块如转码，其上下游模块均由内网通信，在第三方环境下，需经外网与国内支撑系统打通。此类模块无外网，且不应有外网，需应对。
三、 应对：视频云上云详细方案
    直播平台上云方案

视频云平台的服务目标是全球用户，所以直播平台必须具备全球同步能力，以此保证全球用户均可享受同样服务内容。
而且直播平台云上建设中，突出的风险是灰度过程，所以直播平台需先规划并建设全球跨云运营方案。然后依此方案，解决在灰度过程中的质量控制与调度需求。
跨云交互方案核心点说明：
     调度中心交互
主播上行流，只会推送上图三大区中的一个区域，但其观众可能横跨三个区域，所以调度中心需要完成流数据互换，以保证各区均拥有同样流数据，服务拉流模块，进而提供全球服务。
在这个环节，流数据的同步速度与稳定性，就是保证服务质量的前提。此处通过多种方式提升外网通信条件下的通信质量：
双腾讯自有：打通云支撑自研通路，通过此配置方案，腾讯云机房与自研机房间，可由腾讯专线进行流量交互，避免形成外网穿越。实现原理：网平交换平面识别到目标为自有，则绕行内网专线
权限放通：打通云支撑公有云通咱，通过安全审核后，由网平进行放通策略配置，使两方可由内网进行直接通信，避免形成外网穿越。实现原理：物理网互通，但需要对软隔离网络，进行打通配置操作
    源回源交互
当主播与观众同同区接入时，需要跨区拉流，在调度中心的管理下，各区均可通过访问本区调度中心，寻找指定流所在流处理模块的位置域名，并进行拉流服务，提供下行服务。
以此解决灰度过程中，三区共存情况下，流在全球环境下的播放需求。
   互动直播平台上云方案

互动直播同时依赖点播与直播，所以需要分阶段上云，以适配整体上云节奏。如不按此流程进行，则可能出现业务流在云机房与自研机房间的多次穿越。
     依赖前置：直播点播上云
直播接流模块上云：直播平台需要为互动直播提供下行扩散服务，此处需直播平台先上云，使互动直播流上云后，即可在云上完成扩散服务。
点播存储模块上云：点播平台需要为互动直播提供录制文件存储能力，以提供对应点播服务。此处需点播平台先上云，使互动直播录制文件上云后，直接落存储，提供点播服务。
在这个阶段，由代理上云，完成下一阶段上云的准备工作。
   阶段上云：互动直播部分上云转码推流、录制截图、鉴黄
转码推汉与录制模块上云后，可以依托云机房的资源能力，迅速放大服务能力。同时由于等模块由于接入点需求超过个扩展接入点，云机房暂无此能力，所以此环节以中间模块为上云目标。
方案关键点：
增加媒体适配层 – 收敛：未使用普通代理或直出，原因是录制模块拥有自治能力，模块内有调度与执行两部分组成。如果使录制模块直出，与等尚处自研模块通信，需配置录制模块外网，投放三网，安全与资源两方面均无法满足。媒体适配层可区分信令流与业务流，使用少量即可完成接流，同时适配录制模块调度策略，按路由要求，按将业务流投放到指定录制设备上。
 增加_ – 质量保证：通过配置，结合媒体适配层同样配置，解决收敛问题后，使流量由腾讯专线上云，保证了通信质量。
    完成上云：互动直播完成上云其它模块上云
最终环节为解决的众多用户就近接入点等问题后，完成涉及模块上云。最终完成上云工作。
   点播平台上云方案

点播平台由自研的存储形态，改为云机房的存储形态，通过分区域集中部署，改善服务能力，实现点播的服务目标。
方案关键点：
      增加上传代理 – 灰度过渡
点播流上云，需解决原有内网模块跨云通信问题，此处通过解决灰度过渡问题，避免相关模块改造后，上云完成又废弃外网功能，造成开发资源浪费。
      改造接入 – 适配
是云机房提供的统一存储服务，性能优于，但接口更丰富，点播专门开发此模块进行适配。
       分区集中存储 – 各区独立
以广州云机房为国内首批上云承载点，以新加坡为海外首批上云承载点。后续将投放天津、上海点，并扩建海外点。
   跨云方案与效果
     架构分类

视频云为了减少业务模块的过渡性改造工作，使用了大量解决跨云通信问题，同时应对灰度与全球通信需求。
方案关键点：

层代理 – 互动直播流上云

互动直播为了优化双人互动视频，使用了私有协议进行服务，此类流无法使用层代理，需定制开发，以配置方式决策路由出口落点，实现代理功能。

层复合代理 – 流媒体适配层

互动直播录制模块，按上文所说，为进行收敛，进行了定制开发，不但适配私有协议，同时扩展支持信令交互，具体基础代理以外的录制策略路由及流调度能力。

层代理 – 点播文件上云

点播为支持第三方上传服务，使用了协议上传，所以此处以代理方式实现业务流出自研机房上云动作，云机房侧由点播接流后，存入。

层复合代理 – 织云桥头堡

织云做为运营平台，与设备稳定通信并传输业务包是质量评估点之一，由于海外业务网络远，但统一管理平台需集中部署国内，这里基于“指定路由协议”进行加密通信，同时提供信令传输与文件分发能力，提高运营效率。
     优化效果

多种均是为了减少短期开发，提高跨云质量，从对比图来看，直接走外网进行跨云通信图上，云机房跨云服务卡顿率不稳定，且高于自研机房质量。而经过优化后，云机房跨云服务卡顿率与自研机房基本一致。
此处涉及的典型代理有四种：

同运营商 – 跨云拉流

原有自研机房拉流方式为内网通信，而出外网跨云拉流时不区分运营商拉流，导致质量下降，经改造主动向调度模块上报，请求分配同运营商流处理，实现同运营商拉流，提升拉流质量。

调度数据缓冲层 – 全球同步

流数据在全球有同步需求，当前核心部署在广州云，全球直接访问效率低容易发生抢占锁，及网络不稳引起的通信失败，增加本地缓冲层，实时同步核心数据，提升响应服务效率。

录制文件上传 – 通道收敛

录制模块为内网模块台，如独立配置外网通信，不但需要改造，且由于外网使运营复杂。这里增加流媒体适配层，通过绕行内网专线，提升稳定性，改善服务能力。

基于调的加速通道

跨国拉流时，由于路线长，其间外网路由不可控，质量无法何证。这里基于调系统，寻找实时最优线路，由代理加速器进行代理通信，提高流传输稳定性，进行提升服务质量。
   上云灰度放量方案与质量对比

上云分为两个环节：灰度与质量验证，这里分别说明一下：
     灰度
调接入 – 依赖客户端：使用腾讯的客户，可以通过调系统，引导使用最优上行接入点。这里的灰度需对调返回引导地址，进行更换，按服务端配置文件指定百分比，按比例将客户端引向云机房接入点。这里不直接将云机房接入点引入调系统的原因，是由于调按质量引导，一旦混用，则无法控制灰度量级，所以必须使用配置文件引导。
域名接入 – 依赖：未使用腾讯的客户，导由域名访问视频云接入点，这里按平台、省份、运营商多个维度，进行域名管理，通过轮询机制，增加云机房接入点，进行引导灰度。
两相比较，调灰度灵活、生效快，但依赖；域名灰度比例难以调度，回滚时间略长，但无依赖，具有广泛适用性。整体评估，视频云的灰度，由使用调的自有业务入手，验证能力后，进而实施域名调度。
   质量验证
质量验证方式需要统一，当前效果最好的验证方式，就是使用调进行对比评估。将同一路流，同时推送云机房与自研机房，并从两区域分别拉流，以调数据验证质量。

以上节所述评估方式，结合实际客户端播放情况进行评估，云机房由于基础环境更新，云机房质量与自研质量持平或更优。
四、 步履：直播类业务云化之路

原有直播平台的服务目标为内部业务，改造空间和适配性有限，所以进行了前置的重构工作，重构并切换完成后，上云工作正式展开。
：新系统上线切换完成，正式启动上云工作。
：云上完成全模块部署，并进行业务流测试，测试正常，具体上云基础环境。
：结合业务情况与灰度方向，确定灰度方案，直播由自研业务企鹅电竞启动，互动直播由大智慧启动，点播业务由录制类小业务进行。
：自研云机房互联测试拉流优化、点播测试等完成，灰度工作准备启动。
：点播平台首先启动灰度上云。
后续节点：
：当前点播业务流流量已经上云，预计完成点播上云。但自研已有存量点播文件，需待过期后删除下线
：预计直播平台完成上云。
：预计互动直播平台完成上云。
五、 出海：视频云海外建设
    海外分布能力

当前视频云在全球已有多个服务点，具体分布如上图所示，其颜色分类说明如下：
      独立部署点
红色节点：视频云独立部署点，单具备完整直播服务能力。
      独立待部署点
橙色节点：视频云规划中的独立部署点。
       接入点
紫色节点：视频云接入点，但无独立服务能力。
   流数据全球同步与统一调度

流数据全球同步能力，是统一调度的基础。若所有访问均直接请求核心大量跨国访问，服务质量无法保证，这里增加数据中转服务模块。
方案说明：
     数据中转广州模块
具备读写核心能力，同时拥有本地缓存，是所有数据中转模块的同步数据源。
    数据中转香港模块
定制加密通信隧道，提升与广州通信质量，向广州模块提交香港数据流信息；同时做为海外其它中转模块的代理，提供数据同步服务。
     数据中转其它模块
向香港模块提交流数据信息，同时由香港模块，获取广州模块提供的所有流数据信息。
    模块
调度模块，需要高速处理调度信息，所有流数据原始信息，均由发往本地数据中转模块，并由中转模块查询全球流数据信息。
   海外统一存储方案

视频云当前的海外节点正在持续建设，服务规模还在发展中，考虑到为腾讯云基础能力，设备投放量大，基础成本起点高，当前按存储量进行规划后，以新加坡为统一存储落地点，提供点播存储服务。
方案关键点：
     海外统一存储
当前海外主要服务目标为东南亚，当前复用新加坡为统一存储结点，后续按业务增长潜力进行多点容灾规划。
    录制解耦外网通信
为保证录制模块功能统一，解耦外网路由能力，由统一进行录制文件代理上传功能，实现海外录制文件的存储落地能力。使得录制在纯内网环境下可以简化逻辑，不因涉及海外路由优化，而被动改造。
   运营环境全球解决方案

织云统一管理的基础是自研机房已建设的平台集群。为了统一管理，不再单独建设各点织云系统，这里面临的问题，就是如何在全球分布的视频云平台上，进行透明化管理。
方案关键点：
     织云核心集群 – 保留在自研
织云不只支持视频云，还有大量自研业务，需要具备全环境服务能力，留在自研改造灰度风险低。
    香港代理 – 海外加速
海外到国内的网络质量不稳定，而香港是海外接入质量最好的点拥有专线，由香港作为海外代理接入点，进行提速。
     桥头堡代理 – 加密分发
桥头堡代理提供加密通信与跨机房路由功能，同时提供本地文件分发能力，减少文件重复传输，提供透明访问代理。
   海外上行加速

海外上行接入点网络复杂，直接就近接入，未必是最佳选择，这里分别使用调的全球质量分析能力，优化接入。
方案关键点：
     调 – 采集分析
采集所有接入点在各地的接入质量数据。
    客户端 – 寻路请求
客户端由调获取网络质量最优的上行接入点。
     客户端 – 接入上行
客户端按路由接入，获取最优服务能力。
   海外下行加速

视频云除了上行接入部分进行了优化，下行部分也规划了优化方案。
方案关键点：
     专线 – 跨洲优化
通过网平专线的能力，提供跨洲情况下的下行加速，北美的流需要在东南亚播放时，该视频流将由专线到达东南亚后，再进行扩散下行。
    并行加速 – 跨扩大通路
间建立多信道，解决单一信道容量有限的问题，扩大通路能力。
     多连接 – 单路视频流加速
使用类方式，在多信道同时传输数据，提高单路视频传输能力。
    转 – 协议优化
依赖可靠联接，长途通信时，转为包进行跨传输，更有灵活性及更大吞吐能力。
六、         平台：视频云平台运营规划

视频云需要海量资源搭建服务基础，同时提供丰富的服务能力，所以使用了三层结构，提供平台服务能力：
      腾讯云 – 基础资源
基于腾讯云提供的基础资源能力，视频云可以选择不同能力的组件完成架构工作。实体机支撑环境、自研过渡、云机房虚拟化能力、关系型数据库、数据库、云统一存储、消息队列、管理网关、出口加密网关等等。后续将依此基础资源能力，在优化性能设备等，扩大覆盖海外新节点等，优化资源交付快速供给与上线等数个方面，进行扩展，发挥腾讯云的资源优势，扩大服务范围。
     视频云 – 业务能力
视频云业务基础，组成部分由客户端开始，接业务流流向，覆盖所有业务模块。当前模块分布于多个部门与机房，后续基于资源与业务需求，提升模块性能架构技术，适配业务需求等定制需求，提升服务能力。
     运维 – 运营管理
运营优化的核心层，通过顶层封装，提供多方面的全球服务能力，如自动化运维基础监控与视频云运维，快速交付容量管理与场景化工具，容灾调度与柔性，成本优化资源负载，数据挖掘日志与业务数据、质量响应多维监控、舆情与告警
七、 小结
直播类业务云化建设，本质上是一个将自研已有的“复杂巨系统”向全球化扩展的上云之路，各方面团队共同面对，并解决了诸多环境差异与业务适配需求的难点，在保证业务能力与服务质量的大前提下，做了很多辛劳工作，保障了上云之路持续扩展。但路漫漫其修远兮，视频业务方兴未艾，未来更有成为基础服务的潜力，其上有更大的服务空间可以探索。
相关推荐
视频云解决方案作者：宋增宽

下半年利用空余时间研究和分析了部分源码，本文从网络模型、数据结构和内存管理、持久化和多机协作四个角度对的设计思路进行了分析，若有不正确之处，希望各路大神指出。
是业界普遍应用的缓存组件，研究一个组件框架，最直观的办法就是从应用方的角度出发，将每个步骤的考虑一番，从这些步骤入手去研究往往能够最快的体会到一个组件框架的设计哲学。以为例，每当发起一条请求时，是如何管理管理网络请求，收到请求后又是通过什么样的数据结构进行组织并操作内存，这些数据又是如何到磁盘实现持久化，再到多机环境下如何同步和保证一致性……本文就是从网络模型、数据结构设计与内存管理、持久化方法和多机四个角度简要描述了的设计和自己的一点体会。
一网络模型
是典型的基于的事件驱动模型，单进程单线程，高效的框架总是类似的。网络模型与的异步模型几乎一致。
流程上整体分为接受请求处理器、响应处理器和应答处理器三个同步模块，每一个请求都是要经历这三个部分。
集成了等多种事件管理机制，可以根据操作系统版本自由选择合适的管理机制，其中是最优选择的机制。
的网络模型有着所有事件驱动模型的优点，高效低耗。但是面对耗时较长的操作的时候，同样无法处理请求，只能等到事件处理完毕才能响应，之前在业务中也遇到过这样的场景，删除中全量的，整个操作时间较长，操作期间所有的请求都无法响应。所以了解清楚网络模型有助于在业务中扬长避短，减少长耗时的请求，尽可能多一些简单的短耗时请求发挥异步模型的最大的威力，事实上在的设计中也多次体现这一点。
二数据结构和内存管理
字符串
 结构
的字符串是对语言原始字符串的二次封装，结构如下：
  {
     
     
     
}
可以看出，每当定义一个字符串时，除了保存字符的空间，还分配了额外的空间用于管理属性字段。
 内存管理方式
动态内存管理方式，动态方式最大的好处就是能够较为充分的利用内存空间，减少内存碎片化，与此同时带来的劣势就是容易引起频繁的内存抖动，通常采用“空间预分配”和“惰性空间释放”两种优化策略来减少内存抖动，也不例外。
每次修改字符串内容时，首先检查内存空间是否符合要求，否则就扩大倍或者按增长；减少字符串内容时，内存并不会立刻回收，而是按需回收。
关于内存管理的优化，最基本的出发点就是浪费一点空间还是牺牲一些时间的权衡，像、、的机制等采用的核心思路都是“预分配迟回收”，也是一样的。
 二进制安全
判断字符串结束与否的标识是字段，而不是语言的\，因此是二进制安全的。
放心的将序列化后的二进制字符串存入。
简而言之，通过的简单封装，的字符串的操作更加方便，性能更友好，并且屏蔽了语言字符串的一些需要用户关心的问题。
字典哈希
字典的底层一定是，涉及到一定会涉及到算法、冲突的解决方法和表扩容和缩容。
 算法
使用的就是常用的，算法能够给出在任意输入序列下的散列分布性，并且计算速度很快。之前做共享内存的的需求时也正是利用了的优势，解决了原有结构的函数散列分布性差的问题。
 冲突解决方法
链地址法解决冲突，通用解决方案没什么特殊的。多说一句，如果选用链地址解决冲突，那么势必要有一个散列性非常好的函数，否则的性能将会大大折扣。选用了，所以可以放心大胆的采用链地址方案。
 扩容和缩容
维持表在一个合理的负载范围之内，简称为过程。
的过程也是一个权衡的过程，在做评估之前首先明确一点，不管中间采用什么样的策略，在宏观上看一定是：分配一个新的内存块，老数据搬到新的内存块上，释放旧内存块。
老数据何时搬？怎么搬？就变成了一个需要权衡的问题。
第一部分的网络模型上明确的指出的事件驱动模型特点，不适合玩长耗时操作。如果一个非常大，需要进行扩容就一次性把老数据过去，那就会非常耗时，违背事件驱动的特点。所以依旧采用了一种惰性的方案：新空间分配完毕后，启动标识符表明过程的开始；之后所有增删改查涉及的操作时都会将数据迁移到新空间，直到老空间数据大小为表明数据已经全部在新空间，将禁用，表明结束。
将一次性的集中问题分而治之，在的设计哲学中体现的淋漓尽致，主要是为了避免大耗时操作，影响响应客户请求。
整数集合
变长整数存储，整数分为三个变长尺度，根据存入的数据所属的类型，进行规划。
每次插入新元素都有可能导致尺度升级例如由位涨到位，因此插入整数的时间复杂度为。这里也是一个权衡，内存空间和时间的一个折中，尽可能节省内存。
跳跃表
的和普通的没什么不同，都是冗余数据实现的从粗到细的多层次链表，中应用跳表的地方不多，常见的就是有序集合。
的跳表和普通没有什么特殊之处。
链表
的链表是双向非循环链表，拥有表头和表尾指针，对于首尾的操作时间复杂度是，查找时间复杂度，插入时间复杂度。
的链表和普通链表没有什么特殊之处。
三和持久化
持久化日志，持久化实体数据，优先级大于。
持久化
机制：通过定时事件将缓冲区内的数据定时写到磁盘上。
重写
为了减少大小，提供了重写功能，这个重写功能做的工作就是创建一个新文件代替老的，并且这个新的文件没有一条冗余指令。例如对先插入，后删除，再插入共条指令，最终状态为，只需条指令就可以
实现原理就是读现有数据库的状态，根据状态反推指令，跟之前的无关。同样，为了避免长时间耗时，重写工作放在子进程进行。
持久化
和两个命令都是用于生成文件，区别在于会出一个子进程单独进行，不影响处理正常请求。
定时和定次数后进行持久化操作。
简而言之，的过程其实是比较简单的，满足条件后直接去写文件就结束了。
四多机和集群
主从服务器
避免单点是所有服务的通用问题，也不例外。解决单点就要有备机，有备机就要解决固有的数据同步问题。
 ——原始版主从同步
最初的同步做法是指令，通过每次都会全量数据，显然每次都全量复制的设计比较消耗资源。改进思路也是常规逻辑，第一次全量，剩下的增量，这就是现在的指令的活。
 
部分重同步实现的技术手段是“偏移序号积压缓冲区”，具体做法如下：
主从分别维护一个，主每次完成一个请求便，从每同步完后更新自己；
从每次打算同步时都是携带着自己的到主，主将自身的与从做差结果与积压缓冲区大小比较，如果小于积压缓冲区大小，直接从积压缓冲区取相应的操作进行部分重同步；
否则说明积压缓冲区不能够掉主从不一致的数据，进行全量同步。
本质做法用空间换时间，显然在这里牺牲部分空间换回高效的部分重同步，收益比很大。

本质：多主从服务器的系统，多台主从上加了管理监控，以保证系统高可用性。
客户请求时如果相应数据后不属于请求节点所管理的，会给客户返回错误，并给出正确的。从这个层面看，的集群还不够友好，集群内部的状态必须由客户感知。
 容灾
主从服务器，从用于备份主，一旦主故障，从代替主。
通过的研究，深刻体会到的一点就是：所有设计的过程都是权衡和割舍的过程。同样放到日常的工作和开发中也是如此，一句代码写的好不好，一个模块设计的是否科学，就从速度和内存的角度去衡量看是否需要优化，并去评估每一种优化会收益到什么，同时会损失什么，收益远大于损失的就是好的优化，这样往往对于开发和提升更有针对性，更能提高效率。

相关推荐单机主从高可用性优化操作  云爬虫初探云存储导语
框架的微线程模式在网络密集型开发中优势明显，用同步的方式写异步的代码真的很爽。消息系统这边目前也有若干模块都在使用框架，新增模块也首选。在使用过程中，也遇到过一些性能问题，下面跟大家分享下解决思路。
的性能瓶颈
是单  多架构，随着的核心数越来越多，是核心，是核心，为了充分利用机器的计算资源，就必须扩展越来越多的，而只能有一个，所以会成为业务瓶颈。下面来聊聊怎么解决瓶颈。
 代替回包

 图：创建的时候，设置来源地址 

图：回包时，由直接回包，并调用断开连接 
 优化路由函数__
一般来讲，的路由函数只需随机选一个保持负载均衡即可。对于某些业务，需要对分处理，则需要解析出请求的来计算。以协议为例，对于只关心和，就可以把其他字段删除，用简化版的 ，其他字段在解析时，则直接放到字段的解析可以参考解析原理。如果使用的版本支持字段就更简单了，把不需要的字段设置选项，和就可以使用同样的协议，同时保持的高效了。

图：和协议对比 
下图是我们群系统消息存储模块的占用情况，单 占用率，而每个则最多只占了。这是在经过，方法优化之后，优化前 占用以上，差不多是每个的倍。

图：单  个的占用情况 
 绕过，直接监听收包
如果以上方法仍然不能解决的瓶颈，那么可以绕过，由直接监听收包。这样，既解决瓶颈问题，也减少了大量内存拷贝和共享队列锁的抢占，一举多得。可参考同学的文章《一种性能改良方法》

图：__启动监听微线程

图：监听函数处理收包，并创建微线程和处理请求 
不过这种方式，有一个不爽的地方就是不能批量监听端口，没有提供_方法，因为微线程底层的就是用来实现的。
这种去化，有两个弊端：
 的具有防雪崩的设计，去就意味着没有防雪崩； 和之间的共享队列，可以缓存请求，在模块发布时，使用热重启，可以减少甚至避免丢包。去化，重启进程必然会丢失请求； 同下的在  模式下，具有容灾功能，即一个挂了，同一下其他可以顶上；在去化的情况下，注意同一端口多共同监听。总之，去化慎用。
性能优化
 缓存等对象
使用框架时，处理每个，难以避免会很多对象出来，最明显的就是的创建，甚至有时候，一个请求，就会有数个的创建，内存和消耗了大量的性能。由于同类有大量的相同信息，我们能不能把缓存起来，每次需要变化的东西，重新传入？

图：对象池类
需要缓存的对象，只需继承即可。使用智能指针操作对象，在智能指针释放时，则自动调用，把对象放回对象池。每个对象都有自己的对象池，使用者不必关心对象池的存在，也不用自己释放对象，简单易用，居家旅行必备。其他类似的对象，都可以用这种方式进行优化。

图：对象池使用方法 
 缓存，由用户自己管理，而不是托管给框架
既然可以缓存，那么可不可以呢？答案是肯定的，相对复杂，每个占用的内存可能达到几或几十以上，不用重复创建和释放，肯定能得到更大的收益。但有以下几个问题： 比较复杂，里面脏数据比较难以控制； 是由用户创建，框架释放，我们怎么回收到对象池中？
第一个问题，定义方法，由对象池调用，清空脏数据；第二个问题，看过源码的同学可能知道，框架处理其实只是调用 然后 那我们自己启动微线程，处理即可。
那么带来另一个问题，智能指针对象无法通过微线程函数传递；我们搞一个裸的对象池类，不使用智能指针：

图：的对象池类， 类直接继承即可
图：启动微线程处理

图：创建智能指针时，设置删除器，删除器的作用是把放归对象池 
 避免的重复创建
看源码的时候发现，_的实现是，不断创建和释放，根据缓存的思想，那么我们可不可以把缓存起来呢？把收归到里面，缓存的同时，也会被缓存起来。
图：的实现 
接下来自己实现一个函数。

图：自己实现一个 
别急还没完：测试发现，缓存的方式是有问题的。假设 使用一个发出去一个请求，恰好下游超时，处理完毕后， 又通过这个发出去请求，从该的读到的就是的脏数据。这样形成错位效应，后面所有请求读到的都是脏数据。怎么解决呢？
串包校验，请求和回复不符的，继续处理里面的后续数据：

图：解决脏数据问题

图：优化前

图：优化后
利用以上优化方法， ，对我们消息上行模块进行优化，优化前单压测值为，优化后压测值，大约提升。从年开始，我们就吧腾讯公司内各个业务的页面导流给宝贝回家，从年开始，我们更开放了寻亲接入给第三方网站。这些导流给宝贝回家论坛带来了巨大的访问压力，于是我们又把宝贝回家的论坛服务器迁移到腾讯云上面来提供更稳定的服务。一晃块年了。
国庆上班，宝贝回家的志愿者开始说网站好像有点慢了，再后来说网站打不开了。登录服务器一看，访问量增长的有点厉害啊，疑似攻击，打开了各种防护，流量还是居高不下。只好赶快把弹性伸缩打开，在机器扛不住的时候迅速扩容扛过去。

弹性伸缩是程序员和运维最好的朋友之一
接着又找运维和安全的兄弟帮忙分析，分析不出所以然，但是看到头像的请求量明显暴涨了数百倍，占据了的大头，于是对头像的请求进行了分流，把头像都转向到透传来缓解压力。但是无法缓存用户没有设置头像的情况，于是又修改了服务器配置，支持“软”，也就是说在找不到头像的时候用默认头像通过的方式返回，避免。

这样折腾了一通以后，访问量终于降下来了，重新分析，发现新增了数十倍的访问量，几乎全部来自于安卓手机。这时突然想起一件事。国庆前内部有个小群，在讨论把“浏览器”的失败页面指向寻亲项目的事。当时也没上心，因为按照百度统计，浏览器在国内的也就不到的市场份额，估计应该不会给项目带来太大的流量冲击。莫非，当时大家讨论的其实不是“浏览器”而是“内核”

是腾讯的移动端浏览器内核，被广泛应用在微信、手机等腾讯的安卓客户端上。回到国庆前的群里面一问，果然不小心招来了这个大客户。这个客户有多大呢，也就比微信和手机加起来大一些，没有意外的话就是全国最大了

有流量是好事，但是寻亲项目是个公益项目，没有提前准备好这么多预算啊……还是先从技术上想办法吧，谁让我们是专业志愿者呢？
 先检查头像流量异常暴涨的问题：为什么页面访问量增长数十倍，头像的访问量增长了数百倍呢？对比分析了的移动端和段页面后很快找到了原因：论坛打开一个帖子的时候会显示所有评论者的头像，因此头像的访问量本来应该是帖子访问量的十几倍到几十倍。但是对于端的头像加载采用了链接静态化、懒加载等优化手段，配合协议缓存大大减少了头像的访问量，而移动端没有做这些优化。

知道原因就好办了，在中把
 = ={  || }{  }{}{  }{} = 
改为
 = =
           {  || }{    }{}{    }{}
沿用了端的头像链接生成方式。但是端的头像尺寸比移动端大一些，所以做了个。
但是这样做完，服务器流量并没有降下来……因为头像被全面分流以后，帖子的访问能力被释放出来了，现在访问论坛的帖子成了主要压力来源。
的论坛帖子是可以做伪静态化的，但是不能支持真静态化。有几个原因：如果访客是带着登录态来的，那么应该给他显示个性化的动态数；统一个链接如果由、手机、和终端访问，应该返回各自对应的版本。因此主要靠服务器缓存机制而不是静态化来扛压力。
但是分析一下用户场景就能发现在现状下其实是有很大的优化余地的：超过的用户都是由引流的其他的用户，基本上不会论坛的注册用户，显示设备就是安卓手机，不用过多考虑多种设备的兼容问题。
因此我们把寻亲页面导流导一个独立的域名 上，这个域名通过来带透传论坛帖子，并利用的伪静态化链接来实现真静态化。而对于终端兼容的问题要做两件事：：修改后台，识别到通过域名访问的情况下，总是返回移动手机版本的帖子：在静态化的帖子的页面脚本上监测用户客户端。当发现当前用户其实不是移动终端的时候，用脚本调回到原来的域名上提供动态服务。
做了这些事情以后，吧绝大多数的新增压力分流走了：，静态

优化后虽然服务器负载还是比以前重了很多，但是已经可以用一台服务器扛起来了

那么最终这个抗住了引流的论坛使用了一个什么牛逼的服务器呢？

为啥配置这么低呢？谁叫这腾讯云的服务器这么能扛啊导语
作为一枚初入鹅厂的鲜鹅，对这里的一切都充满着求知欲。看到我们的平台如此生机勃勃，各种技术分享交流如火如荼，在努力的汲取着养分的同时也期待自己能为这个生态圈做出贡献。正好新人导师让我看看能否把产品目前使用的从老的组件库分离出来的，自己也查阅了相关的各种资料，对文件上传的这些事有了更进一步的了解。把这些知识点总结一下，供自己日后回顾，也供有需要的同学参考，同时也欢迎各位大牛拍砖指点共同学习。
 对象
在网页上传文件，最核心元素就是这个 的对象了。什么鬼？好像不太熟啊别急，看到真人就熟了：
 =
就是他啊！其实在  文档中该标签每出现一次，一个  对象就会被创建。该标签包含一个按钮，用来打开文件选择对话框，以及一段文字显示选中的文件名或提示没有文件被选中。
把这个标签放在标签内，设置的为服务器目标上传地址，并点击按钮或通过调用的方法就可以实现最简单的文件上传了。
 = = = =
       = = =
       = =提交
 
这样就完成功能啦？没错。但是你要是敢提交这样的代码，估计脸要被打肿
都什么年代了，我们要的是页面无刷新上传！
更优雅的上传
现代网页通过什么来实现用户与服务器的无刷新交互？
——
对，就是这个你很熟悉的家伙。如果你开发的产品支持的浏览器是现代浏览器，那么恭喜你，文件上传就是这么！特别强调强调现代浏览器是因为我们接下来讨论的指的是  。
那什么是 ？为什么不行？因为它有如下限制：

仅支持文本数据传输 无法传输二进制数据

传输数据时 没有进度信息提示 只能提示是否完成

受浏览器 同源策略 限制 只能请求同域资源

没有超时机制 不方便掌控请求节奏


而  针对这些缺陷做出了改进：

支持二进制数据 可以上传文件 可以使用对象管理表单

提供进度提示 可通过  事件回调方法获取传输进度

依然受 同源策略 限制 这个安全机制不会变 新提供  等 设置为  时表示允许任何域名请求 从而实现跨域访问有关详细介绍请耐心往下读

可以设置 及  方便设置超时时长和超时后续处理


关于的细节就不在这里赘述了，有兴趣可以移步这篇博客。目前 主流浏览器基本上都支持 除了系列需要及更高版本 因此以下是不支持的
上面提到的就是我们最常用的一种方式。通过在脚本里新建对象，把对象设置到表单项中，然后利用异步上传到服务器：
  =  
  =  
  = 
  = 
 

 

 = {
     === {
        对请求成功的处理
    }
}


 = 
完成最基本的需求无法满足我们对用户体验的追求，所以我们还想要支持上传进度显示和上传图片预览。
上传进度
因为是   所以很容易就可以支持对上传进度的监听。细心地小伙伴会发现在的 的里一个对象，调用点运算符就可以看到智能提示出来一个事件监听器，那是不是我们只要绑定对象的事件就可以了呢？
很接近了，但是对象的直属事件并不是用来监听上传资源的进度的。对象还有一个属性 它返回一个 对象，这个对象拥有下列下列方法：
















这些方法在对象中都存在同名版本，区别是后者是用于加载资源时，而前者用于资源上传时。其中 事件回调方法可用于跟踪资源上传的进度，它的参数对象包含两个重要的属性和。分别代表当前已上传的字节数  和文件的总字节数。比如我们可以这样计算进度百分比：
 =  {
      {
          =     
         对进度进行处理
    }
}
其中事件的属性代表文件总大小是否可知。如果  属性的值是 ，那么意味着总字节数是未知并且  的值为零。
如果是现代浏览器，可以直接配合提供的元素使用，方便快捷的显示进度条。
 = = =

 其属性绑定上面代码中的的值即可。再进一步我们还可以对的样式统一调整，实现优雅降级方案，具体参见这篇文章。
再说说我在测试这个事件时遇到的一个问题。一开始我设在事件回调里的断点总是只能走到一次，并且值始终等于。觉得有点诡异，改用打印值不见效，于是直接加大上传文件的大小到，终于看到了个不同的百分比值。
因为在上传阶段即之后，=之前触发，每触发一次。所以文件太小网络环境好的时候是直接到的。
图片预览
普通青年的图片预览方式是待文件上传成功后，后台返回上传文件的，然后把预览图片的元素的指向该。这其实达不到预览的效果和目的。
属于文艺青年的现代浏览器又登场了：“使用的 吧！” 让我们直接上代码，直奔主题：
  {
         = 
         = 
         = 
         = 
        = 
       

         =  
        =  {
              {
                  = 
            }
       }
       
}
这里我们使用来处理图片的异步加载。在创建新的对象之后，我们建立了函数，然后调用开始在后台进行读取操作。当图像文件加载后，转换成一个  ，并传递到回调函数中设置给的。
另外我们还可以通过使用对象来实现预览
  = 
 = 
 =  {
     明确地通过调用释放
    
}

多文件支持
什么？一个一个添加文件太烦？别急，打开一个开关就好了。别忘了我们文章一开头就登场的对象，它有一个属性。只要这样
 = = 
我们就能在打开的文件选择对话框中选中多个文件了。然后你在代码里拿到的对象的属性就是一个选中的多文件的数组了。
  = 
  = 
  =  

  =      {
      = 
      
}
的方法提供第三个可选参数用于指定文件名，这样就可以使用同一个表单项名，然后用文件名区分上传的多个文件。这样也方便前后台的循环操作。
二进制上传
有了，其实我们还有一种上传的途径，读取文件内容后直接以二进制格式上传。
  =  
 = {
    
}
 把从里读取的文件内容，放到的字段里

不过已经把的方法移除了。所以可能得自行实现一个
 = {
      =  
      =   
       =     { 
         =   
    }
    
}
这段代码将字符串转成位无符号整型，然后存放到一个位无符号整型数组里面，再把整个数组发送出去。
到这里，我们应该可以结合业务需求实现一个比较优雅的文件上传组件了。等等，哪里优雅了？都不支持拖拽！
拖拽的支持
利用的  事件，我们可以很快实现对拖拽的支持。首先我们可能需要确定一个允许拖放的区域，然后绑定相应的事件进行处理。看代码
 

 = 
  
  
  

 阻止和的默认行为，这样才能使事件被触发
  {
    
    
}

  {
    
    
}

  {
    
    

      = 
      = 

       
}
这里可以把通过事件对象的拿到的数组和之前相同处理，以实现预览上传等功能。有了这些事件回调，我们也可以在不同的事件给我们元素添加不同的来实现更好交互效果。
好了，一个比较优雅的上传组件可以进入生产模式了。什么？还要支持？好吧，让我们来看看以下的浏览器如何实现无刷新上传。
借用
之前说了要实现文件上传使用对象即可。这在低版本的里也是适用的。那我们为什么还要用呢？
因为在现代浏览器中我们可以用  来支持二进制数据，异步文件上传，并且动态创建。而低版本的里的是 。所以我们通过异步向服务器发上传请求的路走不通了。只能老老实实的用的。
而的会导致页面的刷新。原因分析好了，那么答案就近在咫尺了。我们能不能让的不刷新整个页面呢？答案就是利用。把的指定到一个看不见的，那么返回的数据就会被这个接受，于是乎就只有这个会刷新。而它又是看不见的，用户自然就感知不到了。
__ = 
  = 
  =   __
 = 
 = 
 


  = 
 = 
然后响应的事件，获取
 = {
     获取的内容，即服务返回的数据
      =  || 
     处理数据 。。。

    删除
    {
         _ = 
        __
    } 
}
的实现大致如此，但是如果文件上传的地址与当前页面不在同一个域下就会出现跨域问题。导致的回调里的访问服务返回的数据失败。
这时我们再祭出这把利剑，来解决跨域问题。首先在上传之前注册一个全局的函数，把函数名发给服务器。服务器需要配合在里让浏览器直接调用这个函数。
 生成全局函数名，避免冲突
 _ = _
  =   {
      = 
       {
         _  
    }
}

  = 
 =  {
     处理 。。。

     删除
     _ = 
    __
     删除全局函数本身
     = 
}

 如果已有其他参数，这里需要判断一下，改为拼接 =
 =   =  
好了，实现一个文件上传组件的基本知识点大致总结了一下。在这些基础知识之上我们开始可以为我们的业务开发各种酷炫的 了。在之后的开发中会把相关的更细的知识点也总结进来，不足之处也欢迎大家指正。本文是腾讯 微信号第三篇文章，深度解析本届热门研究。文章第一部分是三大前沿领域重点文章解析，包括信息抽取、问答系统和机器翻译等。第二部分是简介及我们团队首次亮相。
腾讯 去年四月成立，今年是首次参展，共计三篇文章被录取，位居国内企业前列。此次团队由实验室主任张潼博士与副主任俞栋博士共同带领到现场交流学习。

图：腾讯 主任张潼博士现场演讲座无虚席

图：参与的团队

图：现场论文展示
从研究领域和前沿思考出发，我们重点关注了三大领域的前沿研究，以下为重点论文评述。
以下论文均可在官网下载：
问答系统
  
随着人工智能的发展，图灵测试受到越来越多的挑战，问答系统就是其中一个尝试：试图让机器用准确、简洁的语言回答用户提出的自然语言问题。近年来，基于神经网络的问答系统已成主流。在本届，知识问答系统及检索式问答系统也继续在神经网络模型基础之上有新突破：一方面在知识问答系统中，在解决问题表示以及答案生成任务时，基于端到端神经网络模型被进一步优化；另一方面，检索式问答系统中，针对小规模文档精确检索以及针对大规模文档快速检索，有了新尝试和突破。
一、知识问答系统
、           
如何让知识问答系统生成自然语言形式的答案目前仍是一大挑战，中科院发表的这篇文章给出了一种可融入外部知识库的端到端神经网络模型。为给出一个自然的答案，此模型使用了端到端的语言模型。同时为引入外部知识库，而引入了检索机制。针对需要结合多个事实回答的复杂问句，模型用三种不同模式获取词汇并进行选取：用拷贝方式取得问句中的实体、用预测方式产生让答案更自然的连接词、用检索方式获取相关事实并结合多个相关事实产生复杂问句的自然形式的答案。论文分别在模拟数据集和真实数据集上进行了模型检验，在自动评估和人工评估上都证实了其模型超出其他传统端到端模型。

、             
基于神经网络的知识问答系统已取得瞩目成绩，然而传统神经网络方法在进行问句表示的同时，并没有考虑答案对其影响。这篇中科院与企业合作完成的文章中，作者提出了一种基于端到端的神经网络模型，特别地利用交叉注意力机制对问句和答案进行互相关注。一方面利用答案信息动态地进行问句表示，使得问句表示更加灵活充分；另外一方面也根据问题对答案不同方面的不同关注，对问句答案得分进行不同权重表示。此外，知识库全局知识被进一步引入用来训练并扩展词表，从而充分捕捉到知识库的全局结构信息，并缓解了传统模型中的词表溢出问题。在公开的数据集上，实验证明该方法能有效提升端到端模型实验性能。

二、检索式问答系统
、        
检索式问答系统试图从文档中获取问题的答案。一般步骤是先从一众文档中检索相关文档，然后再进一步检索出相关篇章。由北大和微软合作发表的这篇文章重点解决后面一步，即阅读理解式的问答系统。文章基于端到端的多层神经网络模型从篇章中获取答案。
模型分为四部分：一是使用多层双向神经网络编码问题和篇章的语义向量表示；二是使用门注意力机制得到问题感知的篇章的语义向量表示；三是通过注意力机制提炼篇章的语义向量表示，从全部篇章中编码最终语义向量表示；四是利用来预测答案边界，从而得到最终答案。在发布的机器阅读理解比赛数据集上，本文提出的模型的单模型和集成模型结果都分别排名第一。

、     
大规模文档中检索答案在时间有效性上目前仍是一大挑战，由华盛顿大学和谷歌等多家机构联合发表的这篇文章中，针对大规模文档检索提出了一种高效检索并保持甚至提高目前最先进模型性能的架构  模型分层对文档检索。首先使用快速模型从大规模文档中选择问题相关的少量句子：使用三种不同句子简单表示方式处理大规模文档，然后利用或注意力机制得到文档的一个摘要表示，并使用三种不同方式选择少量候选句子，然后才用相对慢速的端到端神经网络模型从候选句子中产生最终结果。在部分数据集上，实验结果显示此框架可以比基础模型检索速度高出到倍。

机器翻译
 
粗略统计，本届有篇机器翻译相关的论文篇长文篇短文。我们重点关注其中三个较有代表性方向的相关研究工作，并总结了相关趋势。
一、基于句法的翻译模型
本次会议中，有关如何在神经网络翻译模型中引入句法信息的工作共有篇，是本届会议中机器翻译领域的一个重要方向。受过去统计机器翻译发展脉落从基于字符串的翻译模型到基于句法树的翻译模型的启发，来自不同单位的研究者探讨了各种引入句法信息的方式，包括引入源端句法树或目标端句法树，使用成分句法树或依存句法树及至浅层组块结构。
腾讯 研究员参与的两个研究分别探索了从源端和目标端引入句法信息的可能性。第一个工作通过使用一种简单有效的方式将句法树转化为句法标签序列，在不更改序列到序列模型框架的条件下将源端句法信息引入神经网络翻译系统中。第二个工作则是在解码器端引入一个额外的组块层，通过限定每个组块短语中的所有词共用一个组块层状态及源端上下文向量，不仅引入了目标端的句法信息，同时以一种比较巧妙的方式引入“短语”翻译。
               

二、神经网络的理解和可视化
神经网络机器翻译模型自年被提出以来，一个主要问题是神经网络结构及运行过程的不可解释性，让研究者无法根据翻译出现的问题对网络结构进行针对性改进设计，从而引发一个重要问题  当前神经网络模型无法保证将源端语义内容无损传递至目标端，让生成的译文流畅度较好但忠实度不足，比如遗漏翻译或过度翻译错误。
本次会议有两篇论文尝试理解及可视化神经网络模型，其中一篇  来自清华大学组，他们提出了一种新的可视化方法，通过计算神经网络中任意两个神经元之间的相关性，为分析、理解和调试神经网络机器翻译提供了可能性。
       

另一篇论文则通过外在词性和形态标注任务来评判通过不同粒度方法训练得到的词语表示，分析神经网络翻译模型对词语的理解能力。
        
三、神经网络结构的改进
本次会议同样有多篇工作尝试对当前神经网络结构进行改进，其中三篇工作比较有代表性：
、       
在编码器端使用卷积神经网络代替主流的递归神经网络，在效果相当的前提下速度提升近倍。

、       
为当前主流的非线性 比如或提供了一种线性的可能替代  ，在深层神经网络中取得了较好效果。

、      
通过将时间消耗最大的词汇表归一化过程替换为高效的二进制预测  问题，可极大提高翻译模型的训练和解码速度以及内存消耗。

四、三大趋势总结
趋势一：神经网络机器翻译的进一步可视化，建立起神经网络内部向量数字和自然语言结构的关联，为神经网络翻译模型提供更有效的理解和调试工具。
趋势二、神经网络机器翻译模型框架的优化。最近的工作表明递归神经网络并不是神经网络机器翻译模型的惟一选择，最近的工作使用全面替代，更进一步只用前向神经网络注意力机制，均取得了速度和翻译效果上的进步。如果找到一种在效果和可解释性上更优的模型框架，是未来的一个重要研究方向。
趋势三、解决更通用的翻译问题。虽然当前神经网络机器翻译方法和过去的统计机器翻译方法差异很大，但很多翻译问题是相通的，所以解决通用的翻译问题也是未来的一个研究趋势。比如如何在资源匮乏领域构建好的翻译模型，如何进行篇章级翻译，以及如何在当前词级别的神经网络翻译模型中进行短语的翻译？腾讯 最近接收的两篇 论文对后两个问题进行了初步探索。
信息抽取
 
信息抽取主要是指从文本中自动抽取特定目标信息的技术。本次大会有关信息抽取论文共计多篇，涵盖实体识别、事件抽取、关系抽取、三元组抽取等多个具体任务，其中模型大部分还是以神经网络为主，但方法各有特点。我们从几个领域里分别选取了一篇代表性文章进行解读：
、       
该篇论文由腾讯 和  合作完成，主要介绍了一种轻量级的词级别深度卷积网络。该模型能有效捕捉文本的全局语义信息，并能在神经网络层数增加的前提下保证计算量不变。该模型在六个分本分类主题分类和情感分类的公开数据集中取得目前最优的结果。

、           
该论文是腾讯 研究员在中科院自动化所读博期间发表的三元组抽取工作，入选了  。该论文提出了一种新型的标记策略，通过设计特殊标签可有效关联词语与三元组之间的关系。因此，基于此标记策略，成功地把三元组抽取问题转换为序列标注问题，提出了一种端对端的序列标注模型用于三元组抽取。

、          
该论文是腾讯 研究员在中科院自动化所读博期间研究的事件抽取工作，提出了一种直接应用角色信息做事件识别的方法，基本思想是在事件识别过程中重点关注事件的角色词。作者为此提出了一个基于神经网络的事件识别模型，并通过有监督的关注机制实现上述目标。

、          
该论文针对命名实体识别任务提出了一种新颖的解决方式，并入选   。传统的命名实体识别方法是将该任务转换为一个序列标注的问题，本文不再从序列标注的角度出发，而是采用一种对输入文本中的文本片段分类的方式识别实体。该论文通过固定窗口的方式获得输入文本中的各片段，然后利用片段的上下文背景信息及片段本身信息对片段进行实体分类。该方法在几个公开的实体识别数据中获得了最优结果。此外，相比于序列标注的方式，该方法可以有效解决重叠实体的问题。
关于腾讯  团队
自然语言处理  ，简称赋予计算机通过自然语言文本与外界交互的能力。中心使命是追踪和研究最前沿的自然语言文本理解和生成技术，并孵化下一代自然语言处理技术与商业应用场景。目前团队有位基础研究科学家，其中大多拥有国内外知名院校的博士学位，在学界或工业界科研经历丰富。同时在应用探索上，中心与腾讯多个应用工程师团队及国内外高校及实验室紧密合作。
在前沿研究上，中心正致力于打造一个文本理解引擎，实现基于语义分析、知识推理和统计机器学习相结合的深度文本理解。开放域人机对话是领域目前最艰巨的任务之一，中心正在打造一个开放域人机对话引擎  ，通过深度理解自然语言提升回复质量，并允许用户定制不同性别和语言风格的聊天机器人。研究人员结合深度学习技术和研究热点，取得了诸多创造性的成果，研究成果被近期多个相关顶级会议和刊物录用，包括会议论文篇，会议论文篇，及期刊论文篇。
在应用探索上，中心特别注重研究与具体产品间的交互。其文本理解、文本生成、对话和翻译等技术应用到了公司诸多产品中，提升产品智能化以更好服务用户。研究人员还积极从产品实际需求中发现新的问题，为学术界提供更丰富的研究课题和场景。
本届腾讯 被收录的三篇论文包括：
论文一：      
论文二：      
论文三：       
一分钟了解 
国际计算机语言协会年会，      是计算语言学里最重要的国际会议，今年是第届，于月日到月日在加拿大温哥华举办。会议涵盖生物医学、认知建模与心理语言学、交互式对话系统、机器翻译等各个领域。
在评估会议的学术影响力指标上，本次会议均创新高 —— 论文有效提交数 篇，包括 篇长文和  篇短文。录取数为  篇长文、 篇短文％与 篇杰出论文 。而在新发布的谷歌学术指标中，是计算机语言学和自然语言处理领域排名最高的国际学术年会。
整个会议期共  个报告，长文将展示  分钟，短文  分钟，密度为历届最高。并首次举办了关注女性研究群体的「 」，及可代为照顾儿童的「」，方便已为人父母的研究者参会。
录取论文涉及领域占比最高的五类是：信息提取检索与问答、文档分析和自然语言处理应用、语义、机器翻译、机器学习、生成与总结。而投稿热度增长最快的领域为对话和交互系统、机器人视觉基础 与机器学习 。
腾讯 主任张潼介绍到，「早期利用语法和规则分析自然语言，年代后，随着以  为代表的自然语言数据集建立扩充，统计自然语言方法在计算语言学里作用越来越大并成为主流。年后随着互联网高速发展及以自然语言为核心的人机交互方式兴起，自然语言研究被赋予极高应用价值。」
腾讯 副主任俞栋认为，「自然语言的理解、表达、生成和转换一直是自然语言处理的核心问题。近年来有很多新的解决思路和方法。今年的涉及自然语言处理的各方面，尤其在语义解析、语义角色标注、基于语义和语法的自然语言生成、机器翻译和问答系统方向上都有一些有趣的工作。」首先说下分区分服和全区全服的概念，查了一下资料，没有找到合适的定义。说下自己的理解：所有游戏服务器都有玩家数据库，如果以数据库为单位划分  ，单  如果能承载超过万的同时在线，可以认为是全区全服的游戏，以下可以认为是分区分服的只是个人的标准。早些年设计的  游戏游戏交互频率高，要求网络延迟低，需要就近接入，所以大多采用分区分服的方式。而  游戏，以好友关系链作为主要玩法，单服需要大量的注册用户，且对网络延迟要求不高，所以大多采用全区全服的方式。
全区全服并不是说一个游戏只有一个大区。比如逆战，分了电信区和网通区两个独立的大区，就近部署服务器，减少网络延迟给玩家的影响，类似的还有  飞车等。
全区全服的游戏代表有  农场、摩登城市、夜店之王，分区分服的游戏代表有幻想、御龙在天等。
接下来以摩登城市  为例，谈谈在全区全服的  游戏开发中遇到的问题。 是一款模拟经营性质的  休闲游戏，以城市建设为主线，融合偷菜的玩法，最高在线人数上十万，日活跃上百万。后台架构如下图所示，玩家进入游戏，首先通过  服务器获取  的  ，建立长连接，所有的游戏逻辑都在  上实现，玩家在游戏过程中数据发生变化时通过  写入全内存数据库  。玩家拉取关系链、付费、防沉迷及日志服务器等辅助模块则通过  组件与  通信。

全服全服游戏在设计和部署中一些不同于分区分服的地方，从以下个方面大概说一下：
一可扩展性
对于类型的游戏，到达甚至都是有可能的，所以在服务器设计之初就要考虑所有的功能模块都要具有可平滑扩展的能力。通过上面的架构图我们可以看到，摩登城市的、、以及辅助模块都是以服务器组的形式出现的，对于某个功能都有几台服务器一起分担外部的请求。由于游戏的特性，在做扩容的时候最好能做到不停机。
逻辑服务器扩容
由于  之间关系相对独立，在不停机增加  的时候我们只需要将新增加的服务器与各个内部的功能模块之间建立通信关系就可以了，摩登城市游戏服务器之间通信使用了  组件， 支持动态的刷新通道，我们所需要做的工作只是让辅助模块以及  能够动态的发现新增加的 ，可以通过  或者定时检查的的方式实现。
前面已经说到，登陆游戏首先向  服务器请求  的 ，所有  向  定时上报当前负载、提供服务的  和端口，所以新加服务器的就会暴露给外面玩家。
功能模块的扩容
 与各个辅助模块想要不停机动态扩容的话，相对来说复杂一些。难点在于，新增服务器要分担其他服务器上的负载，要保证服务的无状态性，举例来说：玩家上次请求是通过  拉取好友关系，这次的请求能否通过新增的  来执行，取决于  上是否有保存影响到拉取好友关系的临时信息如  等，如果没有，说明  可以相应的请求，实现动态扩容。
数据库模块
已经实现了动态扩容的功能，并且在运营摩登城市的过程中，经过了实战检验。
二负载均衡
谈到平滑扩容就必须聊聊负载均衡了，对于同一个功能模块的一组服务器如何实现压力分担，就是个人理解的负载均衡。
逻辑服务器的负载均衡
逻辑服务器是直接与玩家进行网络通信的服务器，实现负载均衡有一些现成的解决方案，如、 等，都可以达到网络层的平均负载。摩登城市没有选用这些方案，而是增加了服务器，可以应用到一些特殊的场景，更加灵活控制每台逻辑服务器是否开启和在线人数。从运营后的数据来看，电信玩家与联通玩家数量比大概为，所以现在外网电信的数量是网通的倍。
功能模块的负载均衡
 采用按  取模的方式实现，这样做好处有两点：

实现简单，逻辑服务器向后端发送请求时只需要取模的方式确定发送到哪个 。

定位问题方便，可以确切的知道处理单个玩家逻辑是哪台服务器。


数据库  本身具有负载均衡的机制。
三容灾策略
摩登城市的容灾方法基本是依靠心跳包，检测服务器状态实现的。
逻辑服务器
上面已经提到，逻辑服务器会定时发送心跳到  ，如果某台  出现宕机
或者硬件问题，上报心跳包超时， 就会把它设置为不可用状态，不会再把这台服务器推送给新进玩家。已经连接到这台服务器的玩家通过刷新页面的方式会重新连接到可用服务器。
当这台服务器恢复后，上报心跳包给 ， 将其设置为可用状态。
功能模块
所有为其他  提供服务的模块都会有心跳包发到其他  ，以便于其他  知道当前模块是否可用。如架构图中所示  会发送心跳包给所有的  ，如果  出现故障，心跳包超时，所有  发往  的请求就会平均的发送到其他的  上，直到  恢复工作。
四服务器部署
玩网游的人都知道一句话，世上最远的距离不是从美国到中国，而是从网通到电信。作为网络游戏的开发者，如果不考虑国内的网络环境，将会死的很惨。一些从国外引入的游戏，都或多或少的面临着网络的考验。
前面已经讲过， 类的游戏对网络延迟的并不是很敏感。所以摩登城市的服务器没有就近部署，而是集中部署在上海市北  和上海江场联通机房。
考虑到电信用户数量要远远大于联通用户，所以所有功能模块、数据库、电信  都部署在上海市北 ，部分联通的  部署在上海江场机房，联通的  拉取玩家数据以及其他请求通过同城专线。
以上几点是在开发摩登城市过程中的自己的一些心得体会，难免会有偏颇，希望各位大神斧正，有说的不明白的地方欢迎骚扰。最后为现在所做的项目将魂做个广告，将魂是一款三国背景的战棋类回合制网页策略游戏，有风格各异的武将、刺激多样副本和精美的动漫画面风格。既可以游戏中体验经典的三国历史故事，又可以收集各种武将并带领他们去参加各种激烈的战斗哦！

相关推荐缓存系统在游戏业务中的特异性如何使用私有网络部署全球同服游戏服务作者简介：


 李智桦老师，北京站金牌讲师，台湾著名精益布道师，敏捷专家，著有《精益开发与看板方法 》。
敏捷开发的目的不是为了快速交付 
它是一种用来应付需求快速变化的软体开发方法。
– 

许多主管或是工程师，都把敏捷开发误以为是一种快速交付的方法，就因为它比传统开发方法快一些，当然；还有它叫做「敏捷」的缘故。因此我们常常听到主管们在会议上抱怨「不是已经在敏捷开发了吗，为什么开发速度还是那么慢呢」
「敏捷」二字的误导
这一篇文章的目的不在回答上面那个说来话长，必须用听诊器仔细推敲才能回答的问题，而只是想修正一下大家对「敏捷」这二个字的误解。
敏捷二字其实是针对需求变化的快速反应而来，而不是过去所谓的  快速应用开发法附注。
下面的说明则是在解释敏捷开发为何会比传统开发方法快的原因。
透过游戏来做说明
敏捷开发不是一种快速的开发方法，为了解释这个道理，敏捷课程的讲师们经常会在课程里依靠游戏的方式来作说明这是效果最好的一种方式，大家玩上一回便知道前置时间所造成的浪费之处了，但时间不够的时候，则会改成视频的形式。
请欣赏上课时我们经常会放的一段翻铜板游戏   =。
放这段视频的目的在于修正大家对敏捷的误解。尤其是让高级主管知道 – 敏捷开发不是一种为了快速交付而出现的方法，它之所以比较快则是因为避开了许多浪费。
下面这一张图是为了更容易作说明而画的，希望能解决困扰。
透过图示的方式进行说明 

上面这一张传统敏捷的开发流程图示，强调四个实施敏捷开发时为何会快于传统开发流程的地方
前置时间
传统开发法依循计划、分析、设计、开发、测试再进行修改整合后发布的步骤进行，是一种顺序性的开发模式，也就是说当前一个步骤还没完成之前，后面的步骤就会处于等待的状态，当前一个步骤用掉越多时间时则后面步骤的前置时间就会越长，而形成时间上越多的浪费。
也就是说传统开发浪费了太多的时间。前置时间造成了一种没有充分运用资源的现象，当进行到分析或设计的步骤时，程式设计人员仍然处于等待的状态，因此形成了时间的浪费。
反观敏捷开发，实行的是一种务实的做法，例如在进行需求搜集的步骤时，当收集到足够一次迭代开发的需求时即开始下一个步骤，尽量缩短前置时间的浪费，然后将分析、设计、开发与测试“形成一个开发步骤，减少了步骤与步骤之间的衔接时间，这种开发方式形成了一种所谓的「衍生式的设计」，也就是遇到实质上的问题时才采用设计方法来克服它，而不是预先作好设计的方式。因此让起步显得轻量化了，再加上只有小小的规范，所以敏捷才有了轻量化的开发方法的称谓。
在铜板游戏中，我们通常会用一张的纸张作为前置时间的限制，要求学员把或个铜板放上去，游戏进行时只有在所有在纸张上的铜板都完全翻转过之后才能传递给下一位，形成后面的学员空等待的时间，也就是前置时间的浪费。
在铜板游戏中，我们通常会分成三次来进行游戏，第一次采用的纸张，代表最大的前置时间，接着将纸张撕成四等分，也就是采用四分之一的前置时间大小的纸张，最后一回则完全拿掉纸张，也就是极小化前置时间的限制，目的在让学员更容易意识到速度上的差异
首次发布时间
敏捷开发采用迭代的开发方式，每个循环都会有一个潜在可以进行发布的小增量用来展示开发的成果，通过这种展示，我们要求客户在看完之后给予回馈以便进行改善的机会，这种让客户体会开发成果同时也给予客户决定开发方向的绝对主权客户可以在看到需求如何被达成，然后评估产品的可用程度，是否已经达到提前上线的水准，也就是产品足以提前交付了吗。
通常这个展示时间会设定在 到 个星期之内，因此客户几乎可以预期在这段时间之后可以看到预期的开发成果。这与传统开发只在产品完成后才做一次发布的方式截然不同，客户只有在这个时候才看得到成果，在开发过程中完全没有改善的机会。
这种迭代展示的形式，给予了客户提前验收的机会，也给予了开发团队自然提前完工的机会。
资料需求
敏捷开发不作完整的需求分析因为计划总是赶不上变化的，当需求的搜集量及品质，已经足够一个开发周期的工作量时就可以开工了。
这便是敏捷开发著名的「需求够二个星期的工作量了，可以开干了」，一种尽快开工不浪费时间去等待需求全部收集完整的开发模式。 需求的品质，就是所谓的    ，它才是决定开发速度的决定性因素
测试方法
敏捷开发对软件带来的最大影响便是测试了。传统的α内部测试，注、β交付客户测试、γ测试优化处理方式在采用敏捷开发后几乎不存在了，因为敏捷开发在开发周期内即不断的在进行测试的动作，因此也就没有了在做α、β、γ测试时必须停下开发过程，冻结程序开发的时间浪费了。
做了近二十年的敏捷开发，有二个明显的趋势成为了敏捷团队的持续研究重点，一个就是测试，也就是从头到尾都要测试内建质量。另一个则是组织层面的彻底改变，这个较难，因为观念要变。有空再来聊一聊
小结
这是观念的问题，当你知道敏捷开发是针对需求变化的快速反应而来以后，便容易意会到为什么它会花费那么多的功夫在处理需求的变化了。
例如 目前很流行的会议，为什么它每周都要召开一次呢，有必要吗是不是太浪费时间了呢其实，它的目的正是在应付随着时间而善于改变的需求变化罢了。
如果想要加速开发的时间，则前提是把需求弄好，拥有好的需求品质，当需求越能抽象的解题注意不是明确的解题，一旦太明确化就失去变化的能力了，抽象解题提供了宏观上的  让我们能够看见全貌，然后据此拟定正确的开发方向，方向对了返工的次数自然变少，减少了在返工时所浪费的时间，也就自然地变快起来了。
为何要抽象化呢 因为抽象时比较能包容那些属于不确定的因素，也就是未来还没发生的事情，他可以减少我们提前做决策时的方向偏差。
而敏捷开发对抽象化最大的贡献大概就是采用用户故事  来描述需求了，它实现了我们用抽象化来做快速解题的能力。
如果你尚未或是正准备进入敏捷开发的领域，记得从需求开始，而需求的撰写请不要忘了采用用户故事。
如果一定要把敏捷开发说成是一种快速的开发方法的话，则应该要正名成〝一种快速处理需求变化的方法〞。
是的；用来处理改变需求它就变得快得不得了了。原因是它在迭代中采用了使用者故事作为需求描述的方法，所以比起传统的文件规格更能应付需求的变化，更加拥有弹性，所以特别能够变通。
而你运用用户故事来描述需求的好坏，也决定了你应付需求变化的速度及能力。

附注
快速应用开发法 
快速应用开发   是指一种以最小幅度的… 技术设计的报告。 快速应用开发的方法正是需要在功能与效能间取得一个平衡点，借此来加速应用程式的开发时间，并减少之后所需的维护成本。他是对应到至年代间的非敏捷流程开发，例如说结构化系统分析与设计方法以及其他像是瀑布模型等所诞生的一种开发法。
附注
α、β、γ 常用来表示软体测试过程中的三个阶段： α  是第一阶段，一般只供内部测试使用； β  是第二阶段，已经消除了软件中大部分的不完善之处； γ  是第三个阶段，此时产品已经相当成熟，只需在个别地方再做进一步的优化处理。

问答
实践者：
  老师，目前我们团队  人数 从  变成  发现光在每日站立会议，就会花费许多时间。我记得您的书上有写，敏捷团队是  加减  人，是比较合适的。所以想请教您，这种情况要怎么调整 希望您给点建议。

老师：
站立会议的目的是让项目透明化，不是风险管理或是项目会议，简短的只报告三件事应该是很快的过程，但一旦开始有问题式的应答之后，便会开始变得冗长了。
请把握原则，有需要深入讨论的另外开会议室开会。人数太多是严重的问题，按照相关性分批来开是一个解决的方法，实在必须一起听的时候，在聚集在一起，也就是说：例如个、个人个别进行站立会议，之后在将二组人结合起来一起开，以组的方式交换必要资讯进行，速度就会快很多了。
或是由一组先开站立会议，之后再让另一组加入。请以相关必要知道的资讯流通与交换为原则即可。 
过去，我开过个人的站立会议，但只要把握原则，很少超时的。也看过个人的站立会议开了半个小时以上还没开完，完全没有把握原则，实在是一种浪费。请以产能为考量就不会去开太长的会议了。

实践者：
目前在使用 有遇到问题，再请教一下需求变的太快。当已经排入 的，常常因为需求端的改变，必须重新定义、取消，或是插件。目前一个已经是一周安排一次，应该已经很短了。那这部分应该怎么调整，会使这样类似的情形降低

老师：
需求的品质需要设法提升。 
当有需求产生时处理的过程太早了就会产生因为后续的变化必须更改需求而重作  尽量延迟决策      的精实原则或许可以帮上忙。另外，在看板的 之后加上ㄧ个审查需求是否备妥的栏位   用来 需求是否真的了。
这个栏位可以配合每周运用个小时来召开需求的   对需求品质的提升帮助会很大。试试看

  年度现状调查报告完整中文版下载
扫二维码，下载报告

链接：=

文章来源：时代社区前序：
经过将近一周深夜调试到、点终于把环境配置好了无数次的重新安装囧。配置过程中也明白了很多关联的知识点，本文记录我成功搭建的过程。
主角介绍：
  ™是一个开源的分布式分析引擎，提供之上的查询接口及多维分析能力以支持超大规模数据，最初由  开发并贡献至开源社区。它能在亚秒内查询巨大的表。

 介绍：
  可扩展超快引擎 
 是为减少在上百亿规模数据查询延迟而设计
     接口 
 为提供标准支持大部分查询功能
  交互式查询能力 
 通过，用户可以与数据进行亚秒级交互，在同样的数据集上提供比更好的性能
  多维立方体 
 用户能够在里为百亿以上数据集定义数据模型并构建立方体
  与工具无缝整合
 提供与工具，如，的整合能力，即将提供对其他工具的整合
  其他特性 
  管理与监控 
  压缩与编码 
  增量更新 
  利用 
  基于的 近似算法 
  友好的界面以管理，监控和使用立方体 
  项目及立方体级别的访问控制安全
  支持

环境：
 系统：
   位  

 软件：
 
 
 
 
 
 

 ：
当然也有虚拟机可以配置好的这一系列，如果遇到问题也可以下方留言我们共同探讨
注意：环境搭配是必须的，你前期不要试图再重新尝试其他版本，这样会给你带来困扰的，而且会出现一系列奇怪的问题。

安装过程：
三个大步骤就可以完成环境的部署了，酒足饭饱，泡好茶客官准备开始咯：
更改服务器名称：
         这一行就是我们添加 就是本地，这里不要写成，否则你会遇到大坑。  改完要重启服务器。
 更改
设定：。
命令：
    
 更改对应
命令：    
      
      
            
上传这些文件到服务器上。
为了整洁方便使用，我统一解压放在根目录 ，放在目录下。
  
       
 配置环境变量：
命令： 
添加如下环境配置
_=
_=
_=
_=
_=
_= 



_=

 _=
 =___

=______
 _ _ 
 配置
目录位置： \\ 

 
        
        
    


        
        
    


 
    
        
        
    
  
        
        
    

 
        
        
    


 
这里主要是指定位置：
 _=
 主要是这个节点记住改名成

    
        
        
    

        
        _
    
     
              
    
  

  
              
    
  

  
              
    
    

  
              
    
  

由于是单机部署，那么这里设置成
 和  _=


    
        
        
    

    

        配置实际的主机名和端口
    




    

        配置实际的主机名和端口
    


 配置 
目录：\


        　　持久保存的目录
           
    
    
          是否是分布式
        
    
          
                  指定要连接的端口
                  
        
        
                  指定要连接的节点
                  
      
            
                 
                   
    


 _=
 _=
 __=
 __=
里面内容改成
 配置
目录：\此文件内容较多，我把需要更改的写出来
 修改目录名：
 
    
    
                           {}    {}
  
  
    
    {}
         
  
  
    
    {}_
              
  
修改成 连接，以及帐号和密码我的环境， 
    
    
    =
    
            
                    
        =   
    
  
     
    
    
         
  
    
    
    
         
  

  _        
_=

       
 __=

            
 ___=
在目录下创建，给权限。
顺便说下这里因为要连接所以需要把包复制到目录下。
配置
目录\
=
 配置
提示找不到类需要简单修改一下 
增加指定目录：
 __={_}{_}{_}{__}
 _={_}{_}{_}{_}
 初始化各项数据：
 初始化，并启动
   执行完毕就会有字样说明成功了。注意这个操作只执行一次
启动：创建如下目录：
执行命令
      
      
       
    
 初始化库。
目录下
   
 启动
  
 启动和

 初始化样例数据且启动主角 
导入实例数据：
启动 ： 
，到此为止如果都没问题的话，我们就可以访问：帐号： 密码：
小体验：
用已经成功导入的样例，进行。选择一个时间范围 观察进度选择_项目进行查询
 _   _ _    _   _
表格形式：其他形式：   
好了，到此为止分享完毕。你可以自己自由折腾了。哈哈本文主要总结下端相机相关开发的经验。
众所周知，平台不仅系统碎片化严重，而且不同手机的硬件配置差异导致开发某些模块的时候坑比较多，相机模块就是其中之一。为什么呢？首先，系统目前已经提供了两套 ，其中  是从   开始提供的。你可能会想了，那岂不是现在市面上很多机型都可以使用  啦？然而并不是，原因就是下面要说的第二点，很多手机对  的支持都不到位，即使是很多现在刚发的新机，它们有些依然只支持老的 ！这就导致做相机开发的时候不得不根据手机的实际情况切换不同的 。
很显然，自己从零开始构建这么一个模块是比较困难的，这里推荐提供的一个非官方库，如果你的需求是相机预览、切换前后摄像头、切换闪光灯、切换预览图片的比例以及拍照等功能的话，那么这款小巧的库是一个不错的选择。这个项目可以帮助开发者快速创建一个可以适配不同系统和不同设备，并且包含各种基本功能的相机界面，它的使用正如它的说明文档中那样，引入一个自定义的，其他一切和有关的事情都由它来处理。
既然已经有这个轮子了，那这篇文章是不是就完结了？图森破！前面提到过，这个库是非官方库，所以它已经有很长时间没有更新了，中堆了很多已知竟然没人去解！但是，又能怎样呢？还不是只能原谅它，难不成要自己撸一个？看完的代码你就知道撸一个这个库多么不容易，需要很熟悉 和  ，而且要适配那么多机型也确实是困难啊，一个版本迭代的时间根本做不完呐
言归正传，这次自己做相机模块的需求开发之前调研了几个轮子，最终还是决定使用这个库，因为它比较小巧简洁，没有多余的废代码或者废功能，也方便我自己定制相机界面。上还有几个特别高的模块封装，但是个人感觉有点复杂了，可能不便于定制。
本文主要说的是自己在做相机模块需求或者说使用的过程中遇到了哪些问题以及相应的解决方案，最终我对进行了一番，感兴趣可以看下这个库，主要改进的点已经在文档中说明了，可能最有用的是补齐重要路径的以及修复几个上线后的 吧。
 简述组件的设计
通过阅读组件的源码可知，内部设计如下图表所示：

其中的核心类是自定义的组件，它支持通过来设置摄像头、宽高比、闪光灯等属性，相机相关的各项工作实际上是通过和这两个抽象类来完成的。
是用来实现相机预览的，内部可能是用或者来实现，所以它的实现子类有两个，和。因为是从   开始才有的算是的一个增强版，所以在 之后使用的是，在 之前只能使用。
是用来实现相机开启、设置相机参数以及实现各种相机功能的核心类，根据 的不同分为三个实现子类，、和，其中是为   及以上系统提供的，继承自，是为   及以上系统提供的。
和的创建代码如下：

搞清楚了前面的图表再去阅读的源码就清晰很多了，其他的类都是围绕着而展开的。
就是描述宽和高，例如、或者等；就是描述的宽高比，例如和这两个都是，但是是；就是维护到的映射列表，例如{ { }  {}} 这种形式；就是用来监测相机界面屏幕旋转，然后通知相关组件应对屏幕旋转的变化，例如对预览画面进行调整。  
 关于和的选择
下面详细说下和的选择问题，它实际上并不是那么简单地根据 然后选择创建对应的的实现子类就可以了。这里还有一个小细节，那就是如果是选择了，但是在启动相机的时候发现这个手机对的支持很弱怎么办？从源码来看，这个时候会自动将它降级为，然后使用之前设置的相机参数尝试重新启动相机。这种情况在很多手机上都存在，从我手头上测试的机型来看，小米 、 、 、 、 等机型都是这样子的后面有表格记录了该数据。

看到这段代码的时候我先是一愣，哟嚯，还有这种操作，，转瞬一想，微微一笑，因为我发现这段代码很明显是可以优化的。首先，之前是创建好了的，这里切换是不需要改变的，所以这里没有必要重新调用方法；其次，对于某个手机来说，如果它是 以上的系统，但是对  的支持就是很差怎么办？如果按照这段代码的逻辑，将导致这个手机每次启动相机的时候都会先用试一次，发现不行再用试一次，很明显这样会减慢相机的启动速度。其实，我们只要记录下这个手机上是否之前使用启动失败转而使用启动成功的事件，如果有这个记录的话，那么选择的时候就直接使用，不要再用了！哈哈，真是机智如我 😎
相应的修改已经体现在我改进之后的库中，大致代码如下：

 的选择
下面看下的选择问题，前面提到实际上就是图像的宽高比，可能是，也可能是，也可能是其他的比例。另外，我们还需要知道相机模块这里有好几个地方需要设置宽高比，这里建议阅读相机开发那些坑这篇文章，其中详细解析了下面的三个尺寸之间的关系：
尺寸：即自定义相机应用中用于显示相机预览图像的的尺寸，当它铺满全屏时就是屏幕的大小。这里显示的预览图像暂且称作手机预览图像。在组件的源码中有个属性，如果设置为的话，那么它就会铺满组件所占的空间，如果设置为的话，那么会根据的设置按照这个宽高比显示预览图像。
：相机硬件提供的预览帧数据尺寸。预览帧数据传递给，实现预览图像的显示。这里预览帧数据对应的预览图像暂且称作相机预览图像。
：相机硬件提供的拍摄帧数据尺寸。拍摄帧数据可以生成位图文件，最终保存成或者等格式的图片。这里拍摄帧数据对应的图像称作相机拍摄图像。
为了保证相机模块的显示和工作正常，通常建议上三个尺寸的宽高比是一样的，如果比例不一致的话就可能导致图像变形，而且这个比例最好是或者这样比较普遍支持的比例，否则输出结果千奇百怪，例如华为这款手机，它就不支持输出这个比例的图片，但是好在这个比例还是支持的。
在细读了原始的、和的尺寸选择的代码之后，我觉得这块的代码不够严谨，例如输出图像的大小默认就是这个比例下能够输出的最大大小。
不过老实说，这块代码的确是不好写，因为不同应用的需求不同，例如我这边产品要求输出图片最好是这个大小，那么我就会优先选择这个比例，而不是中默认的这个比例。所以这里我修改了原始的的选择以及和的选择的代码，让优先使用这个比例，不支持的话那就使用这个比例，在支持这个比例的时候优先使用这个输出图像大小，如果不支持的话那就尝试其他的大小，在这个比例下的逻辑类似，大致代码如下：不同应用要根据自己的需求修改哦


下表是我利用一些测试手机收集得到的数据，从表格数据中不难看出，除了的最新亲儿子之外，其他手机对  的支持都比较弱，导致要切换到。另外，大部分手机都支持的图像比例，而且大部分手机也都支持输出这个大小的图像，但是有些手机不支持从而选择了这个输出大小，甚至选择了这个比例下的这个输出大小。

注：当时收集数据的时候没有去注意  ，所以这一栏基本为空。其中  为什么是从一个大小变到另一个大小呢？因为当时自己的比例和尺寸选择策略导致预览图像大小是，这个大小导致预览画面非常模糊，后来发现了这个问题，于是想办法调整策略使其变成，调整后显示就不再模糊啦
注：不过即使是保证了三个尺寸的比例是一致的，在某些手机上还是会出现一些奇怪的现象，比如的列表中的这个和这个，也就是保存的图片和预览时看到的图片不一样！这个现象我在一台华为荣耀手机上必现，暂时还没有很好的解决方案，好在问题机型并不多，可以延期解决
 相机拍照
相机拍照也存在着不少潜在的坑，下面我们来说道说道。下面的代码片段是这个类中相机拍照的实现，它的大致流程是，在相机开启的情况下，如果相机能自动对焦的话，那么就先调用方法自动对焦，对焦完成之后就调用方法进行拍照，如果不能自动对焦的话，那么就直接调用方法进行拍照。方法的实现就是先看是否是，如果是的话那么就将其置为，然后立即调用进行拍照，成功之后再将置为。

这段代码有什么问题呢？从我这边的测试来看，其中主要存在着下面三个问题：
部分手机上方法调用可能很耗时：我在一台魅族手机上测试发现对焦特别慢，界面表现就是点击了拍照按钮，大概有秒的时间在自动对焦，这是一个非常不好的体验。针对这个问题，我设定了一个最短对焦时间，如果这台手机没能在最短对焦时间之内完成对焦的话，那么就直接调用去进行拍照，也就是可能牺牲拍出来的图片效果以获得更好的拍照体验。
这个变量的问题：因为另一个问题让我发现一个由变量带来的新问题，场景是如果用户点击拍照，在拍照结果还没来得及出现之前立即按下键退出到桌面，这个时机很难控制，但是还是有办法复现的，一旦复现了，那么这句是没有被调用的，这将导致之后都没法再调用进行拍照了。这个的解决方案是在的方法中将重置为。
某些手机上调用方法会掉：这个问题是应用灰度之后发现的，也许是自动对焦过程出现了什么问题吧，我这里的处理是暂时将其住了，出现异常的话就直接调用方法。在相机开发那些坑中也有提到过这个问题，“在拍照按钮事件响应中执行或前，一定要检验有没有设置预览并开启了相机预览。这里有个方法可以判断预览状态：是预览帧数据的回调函数，它会在收到相机的预览帧数据时被调用，因此在里面可以设置是否允许对焦和拍照的标志位。”
改进之后的过程代码如下

 相机权限
众所周知，从 开始，系统引入了动态权限的机制，所以如果你的应用的设置在及以上的话，你需要在运行的时候检查相机权限是否授予了，如果没有授予的话就要申请。对于 以下的系统，只要在文件中声明相机权限就可以了。
这次是真的可以了？你心里肯定知道答案一定是否。国产手机现在定制之后的系统基本上都有了自己的权限管理机制，往往还有个系统应用“安全中心”来帮忙管理权限，所以还要兼容这些不同的权限管理机制。
下面的方法是用来检查相机权限，并且在权限授予的情况下开启相机的过程，这个方法会在包含的的方法中被调用。

如果设置在以下的话，那么就只会走第一个这个分支，我们重点说下这个分支的情况，下面的分支的分析可以参考其他文档，例如  新的运行时权限开发者需要知道的一切。
在 以下系统中，这个方法返回的结果一定是，如果是原生系统的话，那么就是真的已经具有这个权限了。但是在众多的国产系统中，其实并没有，在上面代码执行到的时候系统会拦截这个操作，然后弹出系统自定义的权限申请对话框，各家还不样，例如小米手机、手机和华为手机上有个秒钟的倒计时，魅族手机上没有显示倒计时。

如果倒计时结束了还没有点击允许的话那就表示拒绝了，那么打开相机就会失败或者异常。一旦是因为权限没有授予然后启动相机失败了的话，可以考虑弹出一个对话框告知用户，然后让用户跳转到应用对应的权限授予界面去开启权限。具体跳转到哪里可以参考这份代码，它处理了不同的定制系统跳转到对应权限授予界面的逻辑。
这里需要注意的是，原生系统的设置中都有个“应用“选项，进入之后可以找到对应应用的详情界面，但是只有部分系统支持在这里直接管理这个应用的权限，所以说让用户跳转到这里是不可以的。更值得注意的是，小米系统在这里有个，小米系统在这个应用详情中看似支持直接修改权限，但是权限修改之后根本就没有用，只有到系统中的安全中心改权限才有效！
 输出图像
你以为不同手机的坑就上面这些？！三星手机告诉你，你还是太年轻了！某一天，测试同学拿着一台三星手机过来问你，“为什么我是竖着拍照，怎么上传到服务器之后再点开查看的时候图片是横着的呢？”，这个时候你接过手机，打开文件管理找到这张图片的保存路径，然后一看这张图，发现它明明是竖着的，此时你肯定会想这锅一定要甩出去，回道，“这一定是后台开发同学的！一定是他旋转了图片！”。结果一问后台同学，他说，“我不会旋转图片的，不是我的锅”，然后没有再回复你了。此时此刻，你才焕然大悟，想到了三星手机那个一直存在的，拍照得到的图片会自动旋转！哎，看来并没有兼容这种情况啊！
但是，细读下的代码你会发现，这不算是的锅，拍照的时候最终会回调方法，其参数是 ，一般情况下我们都只是将这个字节数组保存到某个文件中即可得到拍照的图片。但是，我们并没有去检查这个图片的信息，因为大多数时候其中的这个元数据都是，可是在三星手机上无论你是竖着拍照还是横着拍照，这个值都是！
这时候你可能会想了，那为什么在文件管理中看到的这张图是竖着的呢？很显然，三星内置的相册或者文件管理在显示图片的时候会考虑图片的信息，实际上这图是横着的，结果显示给你看的时候这图旋转回来了，变成了竖着的。那怎么办呢？难道要针对三星手机在竖屏下拍照做个特殊处理？
我这里的做法是将数据保存到图片之后，再去读取下它的信息，如果它的不是，那么就根据信息将图片旋转下，然后重新保存下来。注：这里并没有去修改为

注：关于三星手机的这个问题可以看下这个
 手动对焦
一开始还不知道，等交互出来的时候才发现，这个组件缺了手动对焦的功能，但是好在有热心的开发者对进行了，使其支持了手动对焦，还给官方的提了，可惜官方没有理人家，所以代码并没有合入到组件中，但是这个手动对焦的代码基本可用，对应的代码提交记录可以参见的这次提交，可能你和我一样，只需要稍微修改下对焦的样式就可以看到效果了。
前面提到过，部分手机上在某些情况下调用这个自动对焦方法会导致，所以为了安全起见，我将引入的手动对焦代码中的方法的调用都做了保护，其中有一处值得说道下，下面是在中新加的代码，这里出现的有好几例。

上面代码在部分手机上调用的时候出现了，我猜测原因是这个手机可能并不支持___这种对焦模式吧，之前的代码中设置都会先判断这个是否支持，而这次并没有判断，也许正是这个原因导致的时候出现了吧。
改进之后的方法，增加是否支持的判断逻辑和保护
 
，以上就是我这次做端自定义相机模块需求开发的总结，撒花完结啦，希望能有点作用
 ，从前面的内容可以看出官方推出的非正式组件存在着不少的问题，中堆积了不少手机兼容性问题和异常问题，     。这个库并不适合所有的自定义相机场景的开发，但是如果它能够达到你的基本诉求的话，也是一个不错的库。最后，如果你决定使用的话，推荐使用我改进过后的 😎
补充资料
关于和的区别： 简易教程关于端相机开发的坑：相机开发那些坑关于 的使用的官方文档： 关于 的使用：  相机开发详解关于运行时权限：  新的运行时权限开发者需要知道的一切庄进发，信息安全部后台开发工程师，主要负责内部系统的后台搭建  

导语
项目需要做一个文件上传下载服务，利用 ＋ 做一个代理服务，上传入口统一，分发到不同的机器存储，下载链接和物理存储隔离，支持添加  的方式扩容，这里主要讲一下思路和搭建配置过程，大神勿喷。
主要逻辑

上传
前端请求  服务，  调用  脚本，脚本通过查找配置，找到对应的逻辑存储路径和物理存储机器的  的  和端口，通过  发包到对应  ，部署在对应机器的  接受数据，并写到本地文件。
下载
下载请求  ，  调用  脚本，脚本解析链接参数，根据参数找到对应的  地址，请求返回文件二进制内容，脚本接受到  返回的数据，返回给请求端。
配置＋
接下来主要讲一下  安装配置这里包括的二进制流处理 ， 计算，  操作，  操作
、安装   
下载解压  
、安装 轻量级 
修改  里面的安装路径 = 然后安装  
、安装__下载解压
、 安装__ 提供函数和宏处理一些基本任务，减轻第三方模块开发的代码量
下载__
、 安装编译，导入
 _=  

 _= 

 =  ___ __ =__ =

  
 
启动 重启命令`     
如果报错找不到库   
测试直接打开浏览器就可以了就可以看到欢迎界面了
 、配置运行  脚本
增加库的查找路径__，__
 
、增加下载   拷贝到__ 目录下就可以了
、增加    
修改  里面的 ＝就是 的安装路径，后将生成的 拷贝到 __目录下
 、安装 可以用现成的  _ 拷贝到 __ 或者用  编译生成  拷贝到 __ 位需要增加编译命令 
、下载 
、下载  
主要代码
、前端上传页面代码
 

    
           
    
    
            =___ = =
            = =
            = = = 
           
    

 、上传代码，该模块在解析文件上传请求的过程中，主要采用了简单的类似有限状态机的算法来实现的，在不同的状态由相应的  进行处理。
文件下载服务写到     下面 
 

     _ = 
     =_
       
               
         ___
     

    _

      
         =
           
            =   
             
        

          == 
             =
             =
              == 
                 =
                  _    
                      = 
                      
                          =  =
                         =   
                          
                            获取文件后缀名字
                            =
                             =
                            =  
                             =  
                            存储的文件路径                    
                                 
                               
                                       
                                =打开文件失败  
                                 
                            
                        
                            =请求参数找不到文件名字
                             
                        
                        跳出循环
                         
                    
                 
            
          == 
              
               
               
            
          ==_ 
              
                _=
                 __
               =__
               
                = 
                        
          == 
            
        
               
        
    
     

、接收二进制数据
 读取
 
       =  
     

 读取
 
       =  
     

 读取
 
       =  
     

 读取字符串
 
     

、写二进制数据，这里和  的通信协议是：开始标志位＋包长度＋ 字符串＋结束标志位，所以对应  用的参数就是  ， 就是转化为大端

=    
=
=
=
 =
 =
=

、下载错误的时候，使用了  直接跳转到错误页面，方便输出错误信息，其实这里还可以做用户  校验
 =
= 参数解析有问题 
 =``` __

相关推荐
双向认证配置指南微信小程序文件上传下载应用场景作者：俞尚 

聚类的规则是模糊的，无法精确描述的
空间当前聚类的规则是  或  小时内的照片会聚在同一个类中。目前来看规则太简单，也不够准确，容易产生一些错误的聚类。从用户角度来说，照片聚类规则其实也不复杂，只要把时间地点相对接近照片聚在一起。但是具体规则又很难精确描述的，什么情况下算接近，无法用一个具体的数值来衡量。如果  米算近，那  米为什么又不算呢？聚类规则是一个非常主观，非常模糊概念。
怎么人工判断照片聚类效果的好坏
直接查看一个个聚类的照片来判断聚类是否合理、评估效果，是非常低效的也不直观。人类对图象的理解有天然的优势。是否可以用图表来表示照片之间距离和时间的关系，可以比较直观的看出聚类效果的好坏？这的确是好主意，但有个困难，照片地理位置本身是二维，加上时间是第三维。对三维图象理解还是不够直观吧。有个巧妙的办法是计算照片之间距离，把位置信息  坐标变成一个一维的数字。如下图：
 轴横坐标是时间， 轴纵坐标是照片之间的距离。 

人对照片拍摄地点远比拍摄时间敏感
我们对用户需求的理解，很容易产生偏差，而不自知。在这里很容易把时间和地点作为同样重要的因素来考虑。事实上人对照片地点记忆深刻得多。你很容易想起，今年或去年到哪些城市，但很难说清楚是哪个月份哪一天。另外近期记忆也是如此，我在办公室上班一整天，然后下班后  分钟内在  公里远处吃饭。也不会愿意把办公室  个小时跨度的照片与  分钟间隔的吃饭照片聚在一个类当中，尽管时间跨度很小。  
简单算法的尝试
刚刚开始聚类规则，仅仅是控制时间和距离来进行聚类。从  小时， 聚类这个规则开始。 

这个方案，总体还算准确。有以下几个问题：
如果有张照片刚是距离  或者时间间隔是  小时  分钟，就会强行分类。
某些聚类太离散，包含了多个地点，不符合预期。 

某些类有些点距离虽然也小于 ，但是本身是个不在同一个地点，聚类不对 。
左上角那个点明显不对
在飞机上，拍摄时间很短，但是距离肯定超过 ，聚类出错 高速状态下。
如果某地沙滩上呆上太半天，时间肯定超  小时，也会聚类出错。静止状态。
所以简单的聚类算法总会有这新或者那样的问题。为了修正上面的一些问题，针对算法做改进。
优化后的规则如下
当时间小于  分钟，距离在  以内，聚类；
当时间小于  分钟，距离在  以内，聚类；
当距离小于 ，时间在  分钟内，聚类；
当距离小于 ，时间在  分钟内，聚类；
其它情况， 小时， 聚类。
如上图所示，低于这条线的点会被聚在同一个类中。
聚类效果有改善，但仍然有问题。算法指定了太多的魔术数字。对于一些边界处理仍然有问题。如果距离好是 ，时间时  分钟，就不会被聚类。如果  分钟又会聚在一起。这些奇怪的规则，很难说服自己。
聚类规则的进一步讨论
显然指定时间和距离的规则，不可能有完美的解决方案。回到这张图上来，用人类的语言来描述，应该是时间地点相对较近，而且分布较为均匀的照片，应该聚在一起。但无法说清楚，具体数值是多少。取决照片分布情况。但计算机无法理解人类的思维模式，其实还没有解决方案。

通用聚类算法的局限性
很容易想到，有关于聚类的算法的研究已经非常深入了，有多种通用聚类算法可以选择。比如：
划分聚类，需要知道要划分的聚类的数目，然后计算各个点距离来聚类。
层次聚类，按照某种条件，进行层次分解，直到满足条件。
基于密度的聚类，比较容易发现球形的聚类。旅游照片往往是线形。
基于网格的聚类。
这里 、 都不适合用来做照片聚类，我们无法事先知道一批照片应该聚成多少类。照片地点分布，往往是线性的，而不是球形。
另外，网上的资料很多，但基本上都过于理论化，我们可以用指定的算法，指定一个规则来得到聚类结果。但是往往不知道这些规则的对应的现实意义是什么，也就无法优化聚类效果。最终也比较难得到一个非常好聚类模型。
层次聚类法
最终我们考虑了采用了层次聚类算法。具体方法如下：
把所有照片聚成一个类考虑到算法效率，先按天聚类；
判断一个聚类照片分布情况是是否均匀方差大于  且 照片张数大于 ；
不够均匀则找到聚类中间隔最大的位置，分成两个聚类。然后重复第  个步骤。
经验证，这种方案聚类效果非常的好。准确率 以上，各个聚类都比较准确，没有离散点等错误案例。效果如下图：

照片聚类的其它问题
照片时间和位置信息丢失
如果时间丢失，应该废弃。如果仅丢失时间，考虑根据时间对位置信息进行差值处理。
飞机上快速运动时，怎么处理？
飞机上照片一般张数比较少，同时处于匀速运动状态，方差较小，一般也能聚在一起。
照片时间与位置两个因素怎么平衡，目前只考虑了位置信息，后面可以讨论具体算法。
聚类也要考虑不同的时间段和场景。比如，对较近时间内，推荐发说说时，聚类应该更加严格。较远时间，一般可以推荐上传到相册，对聚类的要求可以适当宽松。导语： 本系列文章以《深度学习原理与实践》一书的内容为基础，结合网络上其他材料，提取并梳理了一些感觉比较有意义的点，也记录了一个菜鸟的心路历程。好东西要大家分享，感觉这本书超赞的，拿来入门很合适。或许会有不对的地方，希望发现的人能指出来，谢谢。

 写在前面
至于什么是人工智能，这里就不赘述了。人工智能中有一个分支叫做机器学习，机器学习中有一个分支叫做深度学习。机器学习是指从现实世界中获取大量数据并挑选有代表意义的样本交给算法处理，算法在这个基础上寻找特定的规律。我们提供的数据是多个维度的，即一个事物具有多个属性，例如房子的面积，地理位置，楼层等，这些属性影响了我们想要知道的结果，例如房价。那么我们说这些属性都是我们想要的特征，挑选出对我们求职结果有用的特征就叫做特征工程。那么可以看出机器学习对特征工程有着很高的依赖性，并且这种特征工程往往需要花费很多的时间和人力。于是，可以通过多层非线性变换的组合方式，得到更抽象也更有效的特征表示的深度学习诞生了。
 步骤及概念
 数据的清洗及预处理
数据的清洗是指对异常样本的处理，例如就我们的样本中某一字段发生了局部的缺失。处理这个异常我们可以：丢弃该样本行 丢弃缺失的字段列 填充默认值 填充平均值 。数据的预处理的目的是使凌乱的数据容易被算法处理，对此可以使用离散化，归一化，标准化以及数值变换等方法。
 前向传播图
所谓前向传播，是指网络的正向计算，由输入计算出结果的过程。利用描绘好的模型例如= 和是模型的参数，有训练获得，以及算法模型例如逻辑回归，等。
 代价函数
机器学习算法的优化需要依靠代价函数来评估优化方向。《深度学习原理与实践》一书中，以泰坦尼克问题为例根据泰坦尼克号乘客的各种属性判断是否会幸存，这是一个二分类问题幸存或者死亡，采用了求交叉熵的方式来作为代价函数。在已有样本中我们知道针对样本的真实结果为，而且根据上一步我们根据前向传播图也可以知道预测结果为，这里是可以直接调用代价函数得到一个损失值，也就是一个代表预测结果与真实结果的差异值。
 优化算法
使用代价函数得到了损失值，这个损失值，自然是越小越好，这代表了我们的预测正确概率很高。为了降低这个损失值，我们加入了优化算法。书中以随机梯度下降算法举例，还提到一些其他算法，但是笔者这里全都不知道，所以先着重学习了一下梯度下降算法。其实也有查过很多资料，但是觉得很多都不是很适合自己，可能是因为笔者的数学基础比较差。
先抛出自己现在的理解：所谓梯度，和斜率是差不多的概念，如果函数属于线性的，我觉得可以说梯度就是指斜率，导数。如果维度大于二维，那么函数会出现“山谷”，这个陡峭的程度就是梯度。感觉在某一点的梯度，一步一步往下寻找，找到山谷的底端。这有一篇文章，对于梯度下降的理解笔者觉得比较好。  梯度下降法
 迭代训练
有了上一步的优化算法，接下来要做的就是利用这个算法进行迭代训练。我们在迭代中不断从训练样本中抽取样本，代入我们的模型。利用优化算法去把损失最小化，也就是调整我们模型的参数。当迭代结束的时候我们的模型也就训练好了。
 实操

    

   
   
   

 读取训练数据
 = _
 显示数据属性：有多少行多少列以及每列的数据类型等
 

 字段如果时赋值为，否则赋值为
 =      ==   
 缺失字段填充为
 = 

 增加一列身亡
 =    

 提取部分特征字段，数据集为训练数据集，数据集为验证数据集
_ =      
_ = __
_ =  
_ = __

 随机取的数据样本
 _  __
_ _ _ _ = ___ _ _= _=

 _
     定义占位符，因为算子定义时不直接参数运算机制，所以输入就用占位符表示
     =  =   代表可以输入任意条元数据
 =  = 

 _
     声明变量
     = _  =
     =  =
     构造前向传播计
    _ =    
     添加直方图参数概要记录算子
     
     

 _
     声明代价函数
    _ =  _  _   _=  根据交叉熵公式进行计算
     = __  取所有样本的交叉熵平均值作为批量样本代价
     添加损失代价标量概要
     

 使用随即梯度下降算法优化器来最小化代价
_ = 

 _
    _ =   _ 
    _ = __ 
     _

 构建训练迭代过程
   
     初始化所有变量
    __

     创建概要写入操作
     可以通过命令 =来启动
     =  
     方便起见，合并所有概要算子
     = _

     使用保存训练好的模型，不必每次都需要训练
     = 

     进行训练迭代轮
        
        _ = 
           _ 
             = { _  _}
             执行运算
            _  = _  _=
            _ = 
              =  _
                                     _={ _  _}
        _ 
           =     _
      

     评估校验数据集上的准确性
     = _ _={_}
     =   _ 
     = 
          
     =  
 写在最后
这边文章记录一下这个时刻的学习心得，后面或许还有修改，或者追加文章去补充。如果能帮助一起学习的就更好了～如果你觉得有哪里不正确，可以直接指出。作者：团队公众号：腾讯移动品质中心
随着互联网行业的发展，质量管理的方向逐渐向生产过程看齐。年是变革的重要年份，本文拟通过一个宏观的视图，给读者展现此次变革的完整思路，希望能带给大家一些启发。作为 年的重点工作，测试左移在多个团队中已经开展了起来，具体他们是怎么做的，有哪些好的实战案例，我们会陆续挑选一些分享给大家，请各位读者同学们期待。
一、测试行业现状分析

近几年随着移动互联网的飞速发展，整个行业一派繁荣。市场竞争之激烈，业务变化之快速，几乎是前所未有的。由此带来的需求是，产品迭代要快，质量要好，于是大家都依赖测试团队来对质量把关。测试团队的规模越来越大，分工越来越细。但是，这样做的结果是，开发只管生产，至于质量，交给测试同学吧。表面看来，测试团队岂不是更受重视？但是，测试团队已然变成了一个彻底的下游团队，它的价值在于上游团队的工作没做好。开发团队逐渐失去了质量意识，因为他们知道有人会为他们兜底。对于整个组织来说，质量的成本不断的被拉高。即使很多人不在意前几个问题，但是在如此激烈的环境中，测试团队真的做得很“愉快”吗？
回顾软件测试的历史，会发现它几乎是和软件开发同时诞生的，并且，测试一直都是伴随着编码活动的。软件测试工程师这个职业，也是随着软件工程的分工越来越细后分化出来的。
再看看以 为代表的世界一流互联网公司下文简称“”，他们只是通过非常少甚至没有，因项目而异的测试工程师来保障质量。这里就不详细说是如何做测试的了有需要的可以去读读《   》这本书。
从国内行业的趋势来看，这样的理念已经开始落地了。国内很多公司都陆续组建了团队，大家熟知的有阿里、滴滴、美团等。要做到的水平，不是一蹴而就的，有文化的因素，有人的能力工程素养的因素，行业环境的因素。就像很多年前，敏捷开始从国外传入到国内，很多人都说咱们国内的情况不一样。但是到现在你看大家都是在做敏捷，并且都能找到适合各自的敏捷研发模型。所以，第一这个事不是不能做，只是它还比较新，大家需要有一个过程；第二，也不能完全照搬，得找到适合自己的方式。
但同时，我们也要有清醒的认识，这并不代表我们不需要测试工程师这个岗位了。我们想做的，是想把质量这样的事情，重新放回到开发的过程中，同时对测试同学的未来发展，开辟一条新的道路。好了，道理说起来总是容易的，关键还得从一点一滴做起。从年开始，就提出了“测试左移”，团队转型的思路。
注：研发流程图都是从左侧画到右侧，测试一般都在右面，所以叫做“测试左移”。
二、研发现状分析
基于此，分析了的大部分产品研发的模式，和做了一番对比。
、品质管理的理念
的品质由开发团队负责，产品的品质主要通过开发人员在开发阶段来保障。高质量代码是开发人员追求的重要目标之一，少量专职测试人员的职责是协助开发人员提升这部分工作的效率，简言之，的理念是“品质是开发出来”的。
目前的现状是品质由测试团队负责，产品品质主要通过开发提测后，大量专职测试人员含正式和外包找出产品在开发阶段引入的并转交开发人员去不断修复而逐渐提升，最终达到发布标准，简言之，我们的产品“品质是测试并修复出来“的。虽然经历多年的积累和沉淀，这种模式也运行得很好，但终究不是最优的。 
、质量成本投入
在的研发模式下，缺陷都是及早的被发现并被修复，由此带来的成本非常低。通过侧面的一个数据可以反映：的开发测试比几年前就是，如今只会更高；一开始就没有专职测试，据说近年来才有极少量的专职测试。
在目前的研发模式下，需要通过测试和开发的工作产出交互，一方面测试需要花很多时间来测试，开发工程师消耗在 相关工作上的也非常多，而且问题发现越晚，修复代价越高。同样对比测试团队的规模，我们的体量是非常大的。
、测试周期
的产品质量在开发阶段就已经达到很高水准，所以有些产品直接可以做到自动化的持续交付。即便需要专职测试人员介入的，因为交付给测试人员的产品质量已经很高，所以测试周期相对开发周期来讲也很短。
相对于，从测试介入到版本发布，测试周期相对是较长的，这就从一定程度上将产品的交付周期拖长了。
、缺陷修复的时机
由于的开发团队对产品的质量负责，在开发周期内绝大部分应该消灭的缺陷都被发现并修复了。
的大部分产品的缺陷修复时机，集中在开发完成后，留给上线后的风险更大。
综上所述，的研发体系在品质管理层面与相比有很大的差异，也意味着有很大的提升空间，所以我们要向学习，将品质管理和相关工作向研发的上游逐渐左移过去。一方面需要提升开发和产品团队的质量意识、开展相关工作，一方面也需要改变专职测试团队现有的工作职责、方式和能力模型。
三、工程生产力  
这个词有不同的叫法，有的叫工程效能、研发效能，本文还是按照字面意思来，叫做工程生产力。细心的读者可能会发现，这个词里面没有提到质量，因为质量是伴随着你的产品的必备属性，意思是高质量的效率。
回到根本问题上来，如果让开发团队来承担质量的责任，对开发团队来说有哪些好处？
、质量成本降低：降低在产品基础品质保障上的资源相对投入，即在产品品质不变甚至更好的前提下获得更高的开发测试比。也就是说，或用更少的专职测试资源支撑现有规模的开发团队的产出，或用现有的专职测试资源支撑更大规模的开发团队的产出；
、节省开发资源：开发团队从代价更大的后期修复问题变成代价更小的前期避免或修复问题后，节省的开发资源可用于更多有价值的开发；
、缩短交付周期：由于提测质量变高，会有效缩短测试周期，若迭代新功能规模不变，则可以有效缩短整个研发周期，让产品新功能具备更快交付给用户的能力。当然，理想情况下，如果做到了持续交付，交付周期则更短。
四、测试团队的发展
大伙也许会问，你们这样做，不是把自己搞得失业了吗？当然不是这样。我们的目的是赋予了测试团队新的价值和使命，让质量回归到最合适的人和环节。外部的环境前面也讨论过了，如果不这样做，按现在的趋势，过不了几年，我们将会被动的被调整。有一句话说得好：与其等着被革命，还不如自己起来革命。
具体一点来说，对于团队的发展方向，有几条思路：
、提升价值：为提升整个产品团队的研发能力服务，而不是做质量的把关者；
、提升员工全栈能力：敦促团队成员提升开发能力，改进现有能力模型，向全栈工程师方向发展，扩大工作类型的适应范围；
、调整人力结构：减少投入在基础质量上的人力，着眼未来，投入到前沿的、大数据评测中。
五、未完待续
前面说了这么多，这个事情具体怎么落地呢？在此打算把一些思路分享给大家，我们打算分几步走：
第一步：自己做。
在已有的测试方法和技术之外，探索有效果，投入产出比高的方法，目标是为了第二步。比如单元测试， ，可测性，测试工具和平台等。
第二步：教开发做。
在第一步的基础上，寻找工程能力比较好的团队，合作推进，目标是让开发团队学会怎么做测试。当然这一步需要组织由上而下的推动。
第三步：技术服务。
随着越来越多的开发团队承担质量责任，对相关的测试基础设施有更高的要求，测试团队需要进一步提升自己的工具能力，要具备产品化的能力，最终转型为提供技术服务，而非人力服务。

想知道更多测试相关干货 请关注我们的微信公众号：腾讯移动品质中心。一、背景
目前业界对话系统一般分为自然语言理解、对话管理及自然语言生成模块，而又分为对话状态跟踪及决策模块。模块一般基于当前的对话状态，决策一个行为，有用规则的，也可以用模型实现。本文介绍运用深度强化学习模型学习决策，基于当前的对话状态运用模型决策行为。
二、深度强化学习
关于强化学习，强烈建议阅读 的强化学习的，有时间最好看他在上的课程。深度强化学习，运用深度学习强大的刻画能力和目标拟合能力，大大提高了强化学习解决问题的效率。这里仅简要列下我们的技术方案中运用到的 及 技术。
、  
  强化学习的样本的产生一般是顺序的，比如围棋一步一步的、对话一轮一轮的进行，这样收集到的样本也是顺序相关的。这种样本的相关性不符合独立同分布的假设，深度学习模型也很容易学习到这种相关性，为了消除这种相关性，建立一个  ，在模型训练的时候随机的从中样本来进行模型训练。

、 
强化学习的学习目标不是来自监督的，而是来自反馈，而反馈可能不能立即到达，比如围棋要下完一盘棋才知道输赢，基于任务式的对话要到对话片段结束才知道任务是否完成。这时可以建模的收益为当前的，加上后续的经过一定衰减的收益之和，也即方程的形式。这里我们建模后面一步的收益时，用一个旧版本的网络去预测，区别于在进行优化学习的决策网络，避免偏差。

三、技术方案及实现
我们设计了用户模拟器 ，用于和对话机器人对话，不断的产出样本供在线训练模块 进行模型训练。这里重点介绍下 及 。

、 
 进行对话模拟，每个对话片段有一个对话目标，比如基于时间、地点等订电影票等，模拟器需要判断当前对话是否成功完成或者失败退出，给出反馈信号。模拟器会以一个可配置的概率回答错误对话机器人的提问，也会以一个可配置的概率提前退出会话。具体可以看后面的示例。
、 
 和对话机器人在线对话产生的样本，实时流入  ， 不断的从样本池中采样的样本进行模型训练。冷启动时，以一定概率走规则决策模块，以不断得到正反馈的，指导模型学习，同时运用算法，在各种下探测不同的，随着模型的训练，不断降低，直至最终模型收敛。
四、实验结果分析
下面以一个简单的小任务说明 和对话机器人进行对话模拟供模型训练以及训练效果。
对话任务目标为收集用户和他她对象的属相槽位，然后给出感情相关的属相分析。
模型刚开始训练时，会进行不断的探测，导致比较多的错误，如下图：

第一个错误为对话刚开始时应该执行 ，而却错误的决策执行了感情分析的 ： ，外部服务。第二个错误为用户没有主动提出退出时执行了退出的。第三个错误同第一个，第四个错误同第二个。最后一个错误为对话任务没完成就执行了结束。可见刚开始训练时，无论是模型预测错误，还是算法的随机探测，都会导致比较多错误的，而这些错误越多样性越有利于强化学习模型的训练。
经过模型若干轮迭代后，模型预测准确率大大提高，算法的随机探测比率降低，决策错误的大大减少。如下图所示：

看下这个模拟对话片段，可以看到模型成功学习到，首先进行 ，然后询问用户属相，用户答非所问回答属猫时，机器人没收集到用户属相所以又询问了一次，收集到用户属相后进行了感情分析的 。然后询问用户对象的属相，收集到用户和用户对象的属相后，执行综合属相感情分析的 ，最后进行结束。
这里由于中间步骤的合法的是一个比较小的负值惩罚，而最后成功执行任务会得到一个比较大的正向奖励，能够保证模型收敛到用最少的步骤完成任务。
我们也可以看到后面两个对话片段，用户随时主动提出不想聊时，模型也能决策出合适的退出。
下图为模型训练过程中每轮对话平均的变化图：

下图为模型训练过程中对话片段成功率的变化图：

这里稍微提一下，每轮对话的平均和对话片段的成功率不一定是单调递增的，因为算法在不断的探测。随着模型的不断学习，的不断衰减，最终模型会收敛。
五、总结及展望
基于当前对话状态决策行为的问题，对比监督式的模型，强化学习模型无需标注样本，借助模拟器产生大量样本进行模型训练，模拟器仅需提供对话片段的成功或者失败的反馈，可以大大节省人工标注的人力投入。
在实验过程中，我们也发现，强化学习模型的学习过程，依赖深度学习模型的拟合能力，实验过程中经历过一次模型的调优，大大加速了强化学习模型的收敛速度。随着样本的不断模拟产出，强化学习模型不断迭代，正确的会得到一个较大的正向反馈，错误的也会得到一个较大的负向反馈，而中间过程的合法也会不断迭代得到一个合理的正向的反馈。
同时，我们在实验过程中也发现强化学习的探索效率也是有待提高的，本质上，强化学习就是不断探测，得到各种下各种的正负反馈，而且如果探测不够充分，学出的模型会决策出一些错误甚至是危险的行为，强化学习的安全性问题也有相关学术论文探讨，比如 提出约束型策略优化新算法。后续我们计划先训练一个策略网络，再用强化学习进行不断探测优化，同时在线根据用户反馈进行优化，这里在线的用户反馈的客观性也是个问题，而可能的安全性问题可以通过 解决。
目前我们的是经过模块，得到意图、槽位等，经过更新得到当前对话状态的。这里用户原始输入经过模块不可避免会有损失、错误，长期来看，可以端到端的建模，直接输入用户的原始输入，决策得到行为，再进行对话生成。
参考文献：
  ü ö ü  Ç                  
               
                     
 完善强化学习安全性： 提出约束型策略优化新算法
            
 深度 |  全面解读深度强化学习：从基础概念到基本原理
的是通过的协助，从集群异步往集群写实现的。可以实现典型的模式和模式。经过简单的配置即可实现类似下图中的集群复制：
其原理直接引用社区中的架构图就可以看明白，主集群的中记录了所有针对的变更目前不支持的复制，通过实时读取中代表事务的来解析变更的数据然后发送到从集群中去。
 
   实现
 使用的是社区版的主从功能。
因为当前不支持，所以两个集群都需要提前建立相同的表结构：包括相同的表名和列族。
确认都可达，使用的对等网络

这里需要注意的是，主从集群的网络不能使用同一网段。
使用对等网络跨地域时，测试 大概是左右。
当前私有网络创建和跨地域的对等网络有支持。
如果非跨地域的集群共用集群，需要配置不同的。
在主从集群上，确认开启配置是
在主集群上，用 命令：_把从集群作为一个
_  _
 ： 是一个唯一的字符串，不能包括连字符
_ 包括从集群的访问地址和对应的
比如：
_  
查看命令
_
也可以使用命令：_   _   _ 来管理从集群。
在主集群上，使用命令__来表示哪些表需要复制。
这条命令可能会出现两个集群表不一致情况，先用命令  查看是否一致
主要可能是_不一致，更改方法为：
  _

 _ { = _ = }

  _
如果复制开始后，打开了可以看到日志：
       
验证是否成功
可以直接查看几条记录是否复制过去
 

__ 

 

  
 要检查复制的数据是否完整，可以利用提供的小工具 
  = =  
参数调优参考

 默认值为， 这样导致集群里只有对外提供转发服务。如果客户的从集群完全用于容灾没有读请求，可以考虑更改成。

，默认值是，增大可以提高主从的吞吐量。
 默认是。在时一次复制包多大数据。和参数一起使用，表示最多发多少个包，默认是。一次太多可能会有问题。参考阿里云使用的是，个。
监控
可以使用 命令  ‘’ 来监控复制状态
 
这个命令会显示出的，并显示这些当前的传输状态。
在源端的：  复制连接  上一次复制数据给的这个指标更详细说明请参考源码分析   当前复制队列的数量   上一次复制数据给的时间戳    复制延迟时间
在目的端上次复制的 ：上次获得的时间戳
  

     

 


 
可以采集在全局以及即是从集群级别的监控数据：拉取的监控即可以看见，直接看也可以到对应的上 拉出当时的数据，也可以去采集这些数据出来监控。
 
或者使用直接查看对应的监控记录
 ====
比较方便的方式是直接上任意一台机器使用 的 ‘’查看集群状态，如果发现比较长或者时延比较高，再使用接口查看具体的集群状态
最后上机器查看日志。一般可以查出问题所在，实在不行只能通过源码分析问题了。也就是传说中的监控日志源码
故障处理
在中故障包括的挂了新增以及的挂了新增。其中的新增和挂了比较简单：因为的是通过异步写的方式，当有新增时由分配新的写即可；当有挂了的时候在的尝试多次写失败后就会认为这个挂了，剔除掉后通过 使用其他的。的如果有新增，会在增加一个并为之分配对应的队列。最为复杂的是如果有挂了：当有挂了，其他的会去住对应的，并把其中未完成的的传输挂到自己的名下，再把原来的的删除。

更详细的原理解析可查看另一篇源码解析的文档。
最近发布了，有三个和相关的安全更新需要去研究下是否有影响
==
参考
__

腾讯云沙龙继月成都站，将于月日来到深圳站，与游戏厂商和游戏开发者，畅聊游戏加速。
游戏全球化“蓝海”的竞争将日益激烈，全球环境下，网络延迟所引发的卡顿、更新包难以顺利下载等问题却让游戏玩家逐渐远离您的游戏。本期腾讯云沙龙深圳站，我们将与您探讨实时对战类游戏网络优化、全球游戏加速和游戏更新等话题，期待您的光临！

腾讯游戏云产品总监王永和将分享腾讯游戏云生态产品规划及最新进展。腾讯云游戏业务中心除了为游戏提供灵活而稳定的部署解决方案外，同时也秉承腾讯公司”开放“的战略理念，将腾讯内部领先的游戏开发技术和丰富的游戏服务资源，向外部游戏开放，并共享大平台优质渠道资源、以及提供丰厚的专项扶持金，助力您的游戏业务腾飞。
腾讯游戏云高级产品经理张小华将分享如何打造多快好省的游戏更新体验。腾讯云整合平台的技术优势和海量自研游戏的开发运营经验，为手游和应用开发者提供专业、稳定的应用程序和游戏资源更新服务，解决客户端大、更新流量消耗大、更新时间长、渠道审核时间长且多样化管理复杂等问题。
腾讯游戏运营部新终端中心资深工程师宁斌辉将针对实时手游的网络优化探索进行分享。实时竞技手游为代表的移动游戏对网络稳定性和延迟要求严格，腾讯游戏与运营商、终端厂商合作，在移动网络稳定性方面做了诸多优化实践，通过腾讯云向游戏行业开放“智营网优”服务，为用户提供优质网络体验！
腾讯游戏云资深产品经理马亮将分享腾讯云全球游戏加速方案。随着类游戏和全球同服游戏需求的增长，游戏厂商如何让全球玩家共同竞技无卡顿、让玩家就近接入、实现跨区吃鸡？腾讯云全球游戏加速服务提供全面的网络层解决方案，让玩家连接更稳定、更高效、更安全。
参会指南：
报名方式：识别下方二维码，或访问 填写报名问卷。我们将在会前发送确认短信给参会嘉宾。如有关于沙龙参会与合作的问题，欢迎联系和。

访问沙龙官网 ，了解最新沙龙资讯和更多往期回顾。稍熟悉的朋友对于肯定不陌生通过他我们可以知晓某个类型或者实例的内存大小以字节计但是如果深入一下计算的细节想来大部分朋友就不会那么熟稔了不过平心而论平日的工作中其实也很少需要准确计算类型的内存大小当然定性的估算类型内存占用还是需要的但是了解一下底层的计算方式并没有什么坏处甚至于可能对我们的灵魂都有益处      ’ 网上关于这个话题的信息其实挺多的但是大多比较零散自己尝试写了一篇算作是一个总结吧。
 基本类型
像   等基本类型的  大小应该属于基本常识了值得注意的一点是部分基本类型在位系统和位系统中具有不同大小譬如  类型在位系统中一般为字节大小而在位系统中一般为字节大小简单起见后面的示例我们尽量限制了基本类型的使用并且有以下约定
 = 字节
 = 字节
 = 字节
 = 字节其中指代任意的指针类型
 结构类型
通过定义结构我们可以组合使用基本类型考虑以下代码
 
{
     _
}
的大小是多少呢很简单对于只有单个成员的结构其的大小便是其成员的大小拿来说
 = _ =  = 字节
那么如果有多个成员呢考虑以下代码
 
{
     _
     _
     _
}
如果你简单做个试验你会得到  = 字节 的结果综合之前的讨论我们似乎可以得出以下结论

结构体  的大小等于  中各成员的大小之和 

写成公式可能更直观些假设结构体  的各成员分别为   … 

 =     …   

既然有了公式计算结构体的大小便简单了仍然考虑之前的我们稍稍改动一下他的定义_成员由类型改为了类型
 
{
     _
     _
     _
}
按照之前总结的公式我们有

 = _  _  _ =      =      = 字节 

但实际上如果你再次试验一番你会发现  仍然是 字节我们究竟遗漏了什么
其实这里面有一个数据对齐问题
不同的计算机平台对于数据在内存中的存放位置是有限制的一般要求数据的内存地址是其大小的整数倍譬如  数据的大小是  字节则其地址也应该是  的整数倍例如等等如果违反了这个存放限制一些平台需要多次访问内存才能完整读取数据影响效率一些平台则会直接产生错误。
由于存在上面的数据对齐问题编译器在为结构体生成内存布局的时候会在结构体的数据成员之间填充数据以使结构体的各个成员都能满足内存对齐需求。
而关于编译器填充数据的规则一般都要求填充的数据越少越好核心的方法如下假设结构体  的各成员分别为   … 
首先假设结构体的起始地址为对于任意的数据类型都是对齐地址
依次考虑  … 来计算的大小例如对于其中考虑之前所计算的结构大小是否满足的对齐需求不满足则填充数据

规则看上去比较抽象我们拿之前的来试验一下
 
{
     _
     _
     _
}
假设的起始地址是依次考虑各个数据成员
考虑 _由于当前地址是满足对齐规则我们不需要填充数据的大小更新为 _ = 
考虑 _由于当前地址是而_的大小是地址是的整数倍所以_满足对齐规则不需要填充数据 的大小更新为   _ =    = 
考虑 _由于当前地址是而_的大小是地址不是的整数倍所以我们需要填充字节来使地址增长为的整数倍即再加上_的大小 的大小更新为   填充  _ =      = 
一图胜千言下面关于的内存布局示意图可能更直观一些其中深色部分为填充数据

图：内存布局 
其实上述的计算过程是可以用公式来表述的虽然公式不是封闭形式而是递推形式但仍然比文字描述来的清晰
我们定义函数 ’  为结构体  考虑了第  个成员后计算所得的大小则有  = ’  假设有个成员
’  = 
’  = ’      \    其中为向上取整函数 
我们再来利用公式计算一下的大小
’  = 
’  = ’   _  _  _ =        = 
’  = ’   _  _  _ =        = 
’  = ’   _  _  _ =        = 
’  =  = 
可以看到通过使用公式我们清晰化了之前的计算流程
我们继续考虑下面的定义增加了成员_
 
{
     _
     _
     _
     _
}
此时的大小是多少呢简单我们套用之前的公式计算即可
’  = 
’  = ’   _  _  _ =        = 
’  = ’   _  _  _ =        = 
’  = ’   _  _  _ =        = 
’  = ’   _  _  _ =        = 
’  =  = 
公式计算的结果是但实际上如果你试验一下的大小应该是我们又遗漏了什么吗
其实这里还有一个结构体连续存放的问题
考虑结构体数组定义  并且我们假设的起始地址是对于结构来说其各个成员都在对齐的内存地址上但是对于结构来讲其各个成员就未必在对齐的内存地址上了
就拿上面的举例如果我们在各个成员对齐后不再做任何填充操作那么他的大小便是我们刚才通过公式算出的那么对于的数组定义  
的各成员都是满足内存地址对齐的但是由于结构的大小为这将导致的起始地址为遂而导致中的部分成员譬如_违反内存对齐原则…
怎么解决这个问题呢方法就是在对齐结构体的各数据成员之后再根据结构体中最大成员的大小来填充结构体这里有个前提就是成员大小都必须是的幂次或者说最大成员大小一定要能够整除其余成员大小
继续拿之前的举例我们计算出了他的大小为但这只是各个成员经过内存对齐之后的结果我们还需要对进行一次“整体”填充考虑到中最大的成员大小为_和_由于并不能整除所以需要在结构体末尾再填充个字节到达所以的实际大小应为
依然给张示意图其中深色部分为填充的数据

图：内存布局 
综合以上因素我们可以继续完善结构体大小的计算公式
我们定义函数 ’  为结构体  考虑了第  个成员后计算所得的大小假设有个成员
’  = 
’  = ’      \    其中为向上取整函数 
 =   …  其中为最大值函数
 = ’    \  
 结构中的结构
有了上面的基础我们接着来看下如果结构中嵌套结构那么其的大小应该如何计算呢考虑下面的代码
 
{
     _
     _
     _
     _
}

 
{
     _
     _
}
这次我们要来尝试计算的大小一开始的尝试自然是套用之前总结的公式
首先对齐各个成员
’  = 
’  = ’   _  _  _ =        = 
’  = ’   _  _  _ =        = 
然后做一次整体填充
 = _ _ =   = 
 = ’      =      = 
套用之前的公式我们得到的大小为但实际上试验后的大小为看来我们又再次遗漏了什么东西…
这次的问题是出在我们之前总结的公式上由于之前我们仅考虑了基本类型所以公式中大量使用了这种形式但实际上我们真正需要的是这种表达即某个成员变量的对齐值而之前的运算之所以正确完全是因为对于基本类型来说和是相等的而现在我们引入了结构体形式的成员变量 = 这个前提便不再成立了套用之前的公式自然也无法获得正确答案…
不过我们依然可以通过来修正之前总结的计算公式注意和的使用
我们定义函数 ’  为结构体  考虑了第  个成员后计算所得的内存大小假设有个成员
’  = 
’  = ’      \    其中为向上取整函数 
 =   …  其中为最大值函数
 = ’    \  
借助这个修正后的公式我们再来计算一遍的大小
首先对齐各个成员结构体的对齐值是其成员的最大对齐值
’  = 
’  = ’   _  _  _ =        = 
’  = ’   _  _  _ =        = 
然后做一次整体填充
 = _ _ =   = 
 = ’      =      = 
这次我们得到了的正确大小
继续给张的内存示意图

图： 内存布局 
我们接着来考虑以下的结构定义
 
{
     _
     _
}
这里结构体中出现了数组的定义我们应该如何计算其大小呢其实我们只要将数组看做一种特殊的结构即可大小为 数组元素大小 \ 数组元素个数 对齐值为 数组元素对齐值
据此我们依然可以套用之前的公式来计算的大小
首先对齐各个成员
’  = 
’  = ’   _  _  _ =        = 
’  = ’   _  _  _ =          = 
然后做一次整体填充
 = _ _ =   = 
 = ’      =      = 
如果成员是更复杂一些的结构体数组仍然可以使用相同的方法进行处理只是这时候的数组元素是结构体罢了
 
除了之外中我们还可以定义考虑下面的定义
 
{
     _
     _
     _
}
的大小为多少呢由于联合体需要共用内存所以其大小是其成员的最大大小再加上根据联合体对齐值进行填充的数据大小需要填充的原因和结构体一致而联合体的对齐值则跟结构体一样为其成员的最大对齐值
使用公式依然会更清晰一些假设联合体  的各成员分别为   … 
 =   … 
 =   …     
套用这个公式我们来计算下的内存大小
 = _ _ _ =    = 
 = _ _ _     =        = 
继续考虑下面的定义其中包含了数组和结构
 
{
     _
     _
     _
     _
}

 
{
     _
     _
     _
}
初看上去有些吓人该联合中甚至包含了结构数组但是套用公式的话我们依然可以简单的计算出联合的大小我们已知的大小为对齐值为
 = _ _ _ =    = 
 = _ _ _     =            = 
  位域
除了在中还可以通过设置位域来实现数据的紧凑存储考虑下面的定义
 
{
     _  
     _  
     _  
     _  
}
那么应该如何计算呢一般来讲相邻并且类型相同的位域数据成员会被打包在一起存储直到成员的位宽之和超过类型大小或者遇到不同类型的数据成员包括非位域数据成员其中也会进行成员的内存对齐和最后的结构填充
现在让我们根据上述的规则来计算一下的大小以下计算的单位为位
首先假设的起始地址为对齐地址
考虑 _由于其类型为大小为字节 = 位而 _ 的位宽为  累计位宽为    =  可以打包进一个单元
考虑 _类型为与上一个成员类型相同 _ 的位宽为  累计位宽为    =  = 可以打包进一个单元
考虑 _类型为与上一个成员类型相同 _ 的位宽为  累计位宽为    =  = 可以打包进一个单元
考虑 _类型为与上一个成员类型不同需要重新分配单元先考虑对齐由于上一个数据类型是地址变更为字节字节可以整除字节所以不用填充对齐数据之前的累计位宽被清
继续考虑 __ 的位宽为累计位宽为    = 可以打包进一个单元
尝试填充整个结构这里可以使用之前总结的公式  = 字节  字节  字节 = 字节其中字节 =   字节是的对齐值即的对齐值
实际上位域的相关细节还有很多不同编译器之间的实现也有不少差异有兴趣的朋友可以继续了解一下
  和 
引入了对齐相关的  说明符和  运算符其中的作用其实和我们之前自己定义的函数相似用以获取类型的对齐值而则提供了一种让我们自行设置类型对齐值的方法
考虑下面的结构定义
  
{
     _
      _
     _
      _
}
结构体开头的  尝试设置了的对齐值之前我们讲过结构体的对齐值为其成员的最大对齐值即假设结构体  的各成员分别为   … 
 =   … 
引入了之后结构体的对齐值变为
 =    … 
注意这里函数的运用因为结构体的对齐值取得是及各成员对齐值中的最大对齐值所以设置的数值不一定就是结构体的对齐值同样的对于结构体成员的对齐值我们也可以使用设置也依然遵循选取最大对齐值的规则
根据这个规则我们来计算一下的大小依然可以套用之前的公式需要注意的计算
首先对齐各个成员
’  = 
’  = ’   _  _  _ =        = 
’  = ’   _  _  _ =        =  _ =  
’  = ’   _  _  _ =        = 
’  = ’   _  _  _ =        =  _ =  
然后做一次整体填充
 =  _ _ _ _ =      = 
 = ’      =      = 
的内存布局如下

图： 内存布局 
    
很多网上的文章一上来都会提到   或者  之类的设置其实是不恰当的一是因为这些都是非标准的编辑器扩展二是因为这些设置现在基本都能使用标准的进行替代
值得一提的是   这个扩展他同类似可以设置结构体的对齐值但是使用的是最小值规则考虑以下定义
 
 
{
     _
     _
}
 
我们使用 尝试设置了包括其各个成员的对齐值为那么有
_ =   = 
_ =   = 
 =  _ _ = 
进而我们可以使用公式计算得到的大小为
这种类似压缩的效果是使用标准的无法实现的因为使用了规则所以在某些场景下可能还需要使用  
    
为了实现多态使用了虚拟函数表每一个包含至少一个虚函数的类型都会有一张虚函数表每一个对应类型的实例都存有一个虚函数表指针指向该类型的虚函数表一般来讲虚函数表指针都放在类型实例内存布局的首部
考虑以下代码
 
{
     _
      {}
}
由于有虚拟析构函数所以的实例会包含一个虚拟函数表指针简称为按照之前的约定指针类型的大小为字节大小也为字节在计算的内存大小时我们仍然可以沿用之前的计算公式
首先对齐各个成员
’  = 
’  = ’        =        = 
’  = ’   _  _  _ =        = 
然后做一次整体填充
 =  _ =   = 
 = ’      =      = 
的内存布局如下

图：内存布局
接《 知多少 下》腾讯云沙龙继月广州站后，将于月日来到上海站，与游戏厂商和游戏开发者，畅聊游戏实时社交互动。期待您的光临！
游戏社交化是近年来游戏行业发展的重要趋势，实时互动的实现和社交平台的能力是游戏社交化的两大关键。游戏中玩家的沟通协作从最初的文字交流，逐渐发展为音、视频结合的多场景下的实时互动，是游戏中社交关系建立和维持的关键因素。另外，游戏社交需依托于平台，如何构建玩家间的社交网是各大游戏厂商的重要考虑点，这对平台的能力提出了很高的要求。
此站沙龙将和来宾分享在游戏音视频领域，腾讯的技术积累和布局、业内知名游戏厂商代表的实践经验；还邀请到腾讯运营专家，分享如何借助移动首次开放的社交资源和能力，帮助游戏提升用户价值。

腾讯游戏云产品总监王永和将分享腾讯云游戏生态产品规划及最新进展。腾讯云游戏业务中心除了为游戏提供灵活而稳定的部署解决方案外，同时也秉承腾讯公司”开放“的战略理念，将腾讯内部领先的游戏开发技术和丰富的游戏服务资源，向外部游戏开放，并共享大平台优质渠道资源、以及提供丰厚的专项扶持金，助力您的游戏业务腾飞。
腾讯互娱研发部项目和产品负责人李大为将介绍服务于百款腾讯精品手游大作的专用语音组件。作为游戏语音领域的绝对领先者，团队在语音核心技术研发，以及如何贴近游戏玩法进行技术应用等方面均有深入体会。本次分享将配合数款游戏的典型应用案例，揭秘研发逻辑，为你阐述是如何做到一款“懂游戏的语音引擎”，同时此次分享也会揭开关于游戏视频服务的面纱。
腾讯游戏云架构总监崔博将通过《部落冲突》等全球同服游戏席卷海内外的案例，来剖析腾讯云如何帮助游戏厂商更好的应对全球化挑战。本议题从全球化游戏语音功能为切入点，全面介绍腾讯云为全球同服游戏架构提供的相关解决方案。
上海犀牛互动网络科技有限公司音乐舞蹈手机游戏《舞动青春》制作人，将从《舞动青春》游戏运营一年的经验出发，分享如何更好地使用游戏语音技术助力游戏的实时社交。
腾讯手游与文学业务总监林海强，将针对手游上的社交能力、用户规模、运营效果，介绍腾讯游戏如何运用社交能力为玩家构建完整的生态闭环。同时，手游将通过腾讯云首次向广大游戏厂商开放核心社交资源，帮助游戏在手游平台深度挖掘用户价值。
参会指南：
报名方式：访问 填写报名问卷。我们将在会前发送确认短信给参会嘉宾。如有关于沙龙参会与合作的问题，欢迎联系和。游戏来源背景
年春节期间，一款来自东洋霓虹的游戏开始在微博、朋友圈火了起来，这款游戏就是《不要停！八分音符酱》。八分音符酱之所以能够火起来，是因为它不通过手工操作，而是通过声音来控制游戏的行走和跳跃，这样会让用户感觉很新颖。其有趣的玩法也在网上产生了很多段子，如”要不是邻居来敲门，我早就通关了“等等，现在网上都有人通过乐器来玩这个游戏。

一开始八分音符酱只有版本，目前又好像开始有了、版，相关资源可以自行搜索下载。本文则尝试使用，结合端音频处理接口，实现一个版本的《不要停！八分音符酱》。本人也是第一次写小游戏，文章中出现的不足比如游戏建模、代码实现也麻烦读者们批评指正，共同学习。
开始
先看下游戏的截图吧，体验地址由于系统兼容问题，建议复制地址在微信内打开 

玩法
连接耳机后，最好在微信或手打开这个页面系统需，同意获取麦克风权限。然后对着麦克风大声说几句话，如“啊……”，然后游戏里面的就会开始走了，声音大到一定程度，就会跳起来，掉坑则输。
游戏建模
本质上这应该是一个碰撞模型的游戏，碰撞模型中几个主要的概念是

目标物体：游戏中方块
碰撞物体：游戏中的坑
输赢条件：目标物体与碰撞物体部分体积重合则判为输

根据以上的概念我们可以开始设计这款游戏了。
游戏设计
先看一张初始设计图吧


目标物体

图中棕色物体为目标物体，是我们视觉中的操作对象，可以进行行走或者跳跃

目标物体的载体

图中蓝色框则为游戏中的路，承载了物体的行走。游戏中的路是一个整体，我们实际在代码操作的对象，可以对下方的路整体移动，在视觉上感觉是目标物体的移动。移动后如下图


碰撞物体

碰撞物体其实就是游戏路中的坑。目标物体移动的时候，游戏会给物体设置障碍，目标物体必须跳过这些坑，否则就游戏就失败重来了。
游戏实现

游戏建模设计后就可以开始实现了，由于这个是单页面且动作相对简单，所以采用单体的设计模式实现。
实现部分分两块介绍，第一部分介绍游戏的总体实现思路，这部分相对比较容易。第二部分主要介绍游戏中的声控部分，这部分是游戏的核心。

实现思路

参数配置

游戏中涉及到一些参数的配置用来控制游戏的状态，具体的配置可以在编写的时候生成，这里有本文部分的配置信息。


{
    障碍物宽
    大容器宽
    容器障碍物数目
      难度
    
    锁定移动
    坑来了，开始判断
    危险区域碰撞区域
    
    
    音量大小
    
    
    
    走的音量临界值
    起跳的音量临界值
}

初始化

初始化主要是生成载体，填充到页面中。本文主要根据游戏容器的宽，生成初始载体的个数，填充到容器中。
  {初始化障碍物宽高，初始化载体
      
       =     
        障碍物容器宽
      创建并填充
  }

创建载体

本文游戏中的各种物体设计采用的是来实现，当然也可以采用或其他实现。载体移动到一定距离便在容器后面插入一个载体，插入的载体有可能是路，也可能是坑。插入后要把前面移动过的载体删了，以免过多造成的能性能问题。
    {创建障碍物，个数
    其他代码
      
  }
    {获取障碍物
        = 
        =     {
           =  =  ===      = 》
      }
       
  }

目标物体移动和跳动

当音量达到一定条件，目标物体在视觉中就开始移动，实际我们移动的是目标物体下面的载体。
  {达到条件行走或者跳跃
         {走
        
            {跳
            
        }
    } {停
        
    }
}

碰撞检测

碰撞检测就是对目标物体和碰撞物体之间距离的检测。在本文这个游戏中，采用一个数组来更新碰撞物体，碰撞物体来的时候添加，离开的时候再更新一次。边移动边检测。
{是否失败，碰撞检测
    其他代码
     == {更新碰撞物体
    其他代码，更新，计分
    }
    
      =  {判断是否在区间
          = 
             = 
         =    = {是否达到碰撞条件
            
        }
    }
}

失败重置

游戏失败后会重新初始化设置参数，重复以上步骤
  {输了掉坑了
    啊！掉坑了！重新来一遍吧！一下是重置部分
    
     = 
    {}
      {
         = 
        
        
        
        大声点！不要停！八分音符酱
         = 
        _
    } 
}
利用控制游戏的行走和跳跃

获取麦克风跟音量大小

在中获取麦克风可以通过获取，不过目前在移动端只有才有这个功能，目前还没有提供这方面的接口给调用。目前国内部分手机厂商的默认浏览器对这个权限也有限制，或者有兼容问题，建议用微信、手等采用浏览器内核的进行体验卖了个广告。
在的兼容一般是
 =  ||
            ||
            ||
           

获取麦克风的大小需要用到的相关接口的了解可以参考笔者之前写的介绍 

简要介绍

是制定的用来处理音频的规范。核心是  ，  是处理音频的核心对象，所有的处理接口以节点方式连接。如下图所示，描述了一个源节点到目标节点的音频处理过程。


录音音频返耳

音频返耳指的是在录音的过程中，麦接收的音频在耳机的实时反馈。
利用的可以获取到麦克风的音频数据，将音频数据再输出，就会有返耳效果。
实现过程：获取到麦克风音频源后，连接到节点，可以获取音频输入数据，并将音频实时输出，从而达到返耳效果。

 =
  用于录音的节点
   =
  节点的连接
  ={正在录音
        = 
        = 
         =      {
            = 音频输入
            = 
             =      {
             = 返耳
          }
      }
  }

音频振幅信息

获取音频振幅可以理解为获取音频的音量大小。
利用的接口可以获取到音频经过傅里叶变换后的数据，这些数据包含了音频振幅等信息。如果要实时获取音频振幅大小，需要在  中获取数据。由于麦克风获取到的音频噪音成分有点大，此处作一个加权处理，平均后的值作为目标振幅值。最后根据处理后的音频振幅进行游戏的行走和跳跃。
  = 音频解析器


 设置数据
 = 频道数量
 = 
 =  每个频道的频率
={
        获取振幅信息
        加权振幅
    }
}
由于不同硬件之间的差距，返耳效果的延迟有所区别
由于跟手机硬件有所区别，实际的振幅值，会明显高于手机
以上就是本文游戏的主要设计的相关思路。
结束语
本文从游戏《不要停？八分音符酱》的灵感出发，描述了其简易版本的开发思路，游戏的设计许多不足，请读者们批评指正。
笔者开发版本《八分音符酱》的意图不只是为了把的游戏用来实现，而且想通过这么一个在玩法上有些创新的游戏，来完成一个的。目前正在蓬勃发展，也出了许多新的标准，如，，，等，这些都在发展阶段，在实际的应用中还没有广泛应用。所以希望通过这么一个，能够有更多想法，利用做出更多好玩有趣的应用。

游戏地址

代码

参考


  
及应用案例分析 大数据已经是个非常热门的话题，文智平台正是基于大数据的背景，利用并行计算系统和分布式爬虫系统，结合独特的语义分析技术 一站式满足用户、转码、抽取、全网数据抓取等中文语义分析需求的开放平台。现有的研究、工程应用方向基本上都是围绕着大数据的存储、计算等方面展开，但是对于一个基础环节——数据获取却很少有相关的介绍。本文重点围绕如何获取垂直海量数据展开讨论。
一引言
数据的作用不言而喻，在各行各业中，分门别类的数据为用户的在线生活体验提供了基本的素材，附近的餐馆、即将上映的电影、最近热门新闻等等能够涵盖我们生活的方方面面。同时所有的这一切也成就了今天在各个垂直领域诸如大众点评、豆瓣、今日头条等专业的公司。具体到搜索业务来说，无论是多么优秀的架构、精准的算法，最终也是需要依赖完备、准确、及时的数据作为落地基础。
从搜索业务来看，数据的价值主要体现在如下几个方面：

直接提供搜索数据源。海量的数据为检索提供了必不可少的素材。为此数据工作的一个基本目标是数据完备性。完备性可以从两方面来理解，一方面是实体本身的完备，是和的关系，这是刚性需求，例如你搜索《来自星星的你》，如果没有这部片子，那么结果显然不能满足用户需求；另一方面是实体内部信息的完备，例如《来自星星的你》如果缺少了演员字段，那么你搜索“金秀贤”的时候可能依然得不到想要的结果。另外要提的一点是完备性通常还对时间有约束，热点资讯、突发事件等如果不能在第一时间呈现，那么对于用户来说都是个硬伤。

改善相关性质量。干净、精确的数据可以使得在相关性计算阶段减少歧义，改善召回品质，互联网中的数据鱼龙混杂，各个网站的水平也是良莠不齐，不做去噪直接使用的话往往会适得其反。通过高质量的数据补充，对最终结果的排序也有良好的辅助作用。例如豆瓣的影评分数、热度因子可以在视频搜索中辅助结果排序，并且可以改善数据刚上架时由于点击量缺失造成排序上不来这种冷启动的过程。

丰富搜索产品特性，满足搜索直达需求。当数据完备、及时、准确之后就可以对数据做关联聚合，在这个时候超越文本本身的各种语义特征、知识关联等一些高阶应用相继涌现，大家常常听到的的 、的 以及百度知心搜索等都是建立在这一个基础之上。将散落在互联网上碎片化的知识整合起来形成直观答案显然是一种更“懂”你的方式。如图，搜索王菲老公的体重，知识图谱搜索可以直接输出想要的结果。图、搜狗知识图谱搜索结果


总体而言，数据获取工作主要围绕快、准、全三个要素以及一个高阶的关联需求展开。本文重点分析数据如何发现、抓取、更新等方面做一个介绍。
二数据发现
互联网中的数据良莠不齐，如何从纷繁复杂的互联网中发现有价值的数据是一个有趣的问题。通常数据发现的过程中存在几个难点：

数据海量，无法遍历穷举；

鱼龙混杂，需要甄别出高价值的数据；

存在死链、无效参数、作弊、陷阱等页面使得数据获取的过程中存在各种坑。


问题这里我们需要结合不同的场景做一些不同的策略，一般在目标对象很清晰的情况下可以通过人工手段做一些规避，因此这里不展开讨论。我们重点讨论和这种海量网页中发现高价值数据的问题，有了这个清晰的目标后，接下来就转换为另外两个问题：

从哪个网站获取？

如何得到这个网站内有价值的链接？


问题：如何获取有效站点？通常有下面几个办法：

垂直榜单数据，一般领域内的热门站点都会存在于各大垂直榜单数据中，以视频站点为例，可以监控类似类似  上的垂直分类数据做提取收集图垂直榜单数据
关键字提取，通常可以利用关键字到综合搜索引擎、百度等中获取。这里有个问题就是关键字如何获取，一方面可以垂直引擎中的零结果的关键字或者其他低关键字，另一方面可以利用已经积累的数据构造，例如想要获取音乐铃声类的站点，可以以“最炫民族风  铃声”构造出特定特征的关键字。图、关键字获取
同类垂直综合站点中爬取，以获取新闻站点为例，可以到  中将其中的链接抽取汇聚成特定的一些站点。图、综合类站点页面

问题：如何从网站内得到高价值的链接呢？
一般的都有一些显著特征，通常可以利用前面的方法，利用大量的到综合搜索引擎中做检索获取大量同站点内，这里基于一个假设就是搜索引擎能召回的数据都是亿万链接中尽量有价值的展现给用户，召回的结果已经融合了用户点击、数据本身质量、站点权威等因子在这里，是一个综合权威的结果。得到同站点后我们可以分析其特征，对于一些显著特征占比的可以认为是高价值链接的特征，例如百度百科 和 类似这种特殊的片段。在得到高质量的特征的后可以对库内已经抓取的数据做链接分析，反转父链子链关系汇聚出一些能产生高价值数据的父链作为种子持续发现高价值数据。图展示了通过库内链接关系可以分析出作为一个高质量种子页持续发现高价值数据。图、高质量种子页面
三、数据抓取
前面我们介绍了如何获取有价值的，得到后通常需要将其抓取下来做后续的处理，如果量小可以使用库或者直接搞定，这里面临两个比较大的问题：

速度如果控制不好会导致被目标站点封禁；
或者直接构造请求只能获取到静态页面，对于动态页面只能获取到原始的一些代码。

为此，我们需要一种爬虫引擎能够优雅、柔性的抓取，同时尽可能模拟浏览器的行为，使得抓取的结果能尽可能的完整。对于问题可以有两种办法：

有效的压力控制，这里的压力是指单位时间内对目标站点的访问量，一是压力的计算需要根据对方站点规模参考排名、量以及当前爬虫的规模做一个适当的计算，同时可以根据不同时间段做合适的调整，例如晚上通常目标网站的小我们可以适当提高我们抓取压力；

提高出口代理，尽量复用出口，由于外网的资源非常珍贵，需要提高出口的管理，按照运营商、地域、段进行分散管理，同时可以从外网获取一些公用的代理地址做补充。


对于问题，则通常需要模拟浏览器的行为，研究浏览器的解析、运行的一些行为，通常可以研究做一些异步拉取的填充，使得抓取的页面尽可能的和浏览器中访问看到的一致，这里并不展开引擎的开发使用。
在回答了前面这两个问题后，介绍我们目前爬虫引擎的一个基本结构，主要由以下几部分组成：

：接入模块，主要用于屏蔽多业务入口，在这里主要做屏蔽多业务入口，对外屏蔽后台各种处理逻辑，同时将归一化后按照子域到对应的模块中处理；

 和 ：主要是存放请求解析的结果和解析的结果，采用 的存储方式加上淘汰策略，另外后台有逻辑定期更新。

：引擎核心控制模块，控制了下发的速度，在收到请求后会先请求和，用以获得目标网站以及是否在范围内允许下载，对允许下载的送入到排队队列中进行排队，同时对上游发送的超额做过载截断，使得系统满足压力控制，同时在这里对排队长度做一定的控制，降低排队时长，使得系统可以尽量的满足实时抓取的需求。

：纯粹的抓取模块，负责处理抓取中存在的各种问题，例如死链、跳转、压缩解压、接受等问题，同时带有的解析引擎会负责模拟浏览器行为对动态页面做解析抓取。

主控：负责各个模块心跳检测，配置下发等一些控制模块


整个系统是一个完全无状态设计，尽量多逻辑做简单，除了一些系统内必备的重试之外其余的出错尽量在上层做重试。图、爬虫引擎结构
四数据抽取
有了抓取的数据之后需要对原始网页中的信息进行有效信息的加工提取，源于部门多年技术积累，我们对爬取的数据可以做两类抽取：
基于机器学习规则实现的通用抽取方案，该方案通过预处理、建树和渲染等过程先对进行解析，之后根据事先训练好的模型对网页进行分型操作，例如识别出新闻、论坛、小说等网页结构，最后根据文本长度、文本位置、标签名称等特征对网页进行分块抽取得到相关的信息。该方法是一个通用的解决方案，主要能够实现标题、正文抽取，网页结构分类等一些基础的抽取需求。对于一般常见的抽取服务即可满足需求。图、通用抽取部分抽取结果
基于模板的结构化抽取方案，前面基于机器学习的方案只能满足通用的、相对粗糙的信息提取，无法对精准的字段做抽取。为此我们提供一种精确到字段的结构化抽取的方法，该方法的主要思路是事先配置好需要抽取内容的模版模版可以是正则表达式或，然后基于进行精确的模版匹配，最后将匹配结果输出即可。这里主要的难点在于的配置的便捷性以及后续一些噪音的处理过程，这里不再展开赘述。图、结构化抽取结果
五数据更新
通过前面的步骤我们可以完成数据的发现、抓取到入库，通常这个时候已经可以满足使用需求，但是对于影视类、知识类等数据常常是在更新变化的，对于此类数据为了保证数据的时新性、权威性需要进行不断的更新。更新的难点通常还是由于库内的数量巨大，如果需要全量短时间内更新的话在现有的资源规模基本上难以实现，通常主流的办法都是按照一定的策略做选取，选取出候选更新集做更新，之后再同步到全量数据集合中。图、数据更新
选取策略通常需要结合不同的业务特性做不同的策略。以视频为例，通常视频的剧集更新都是在一定的时间范围，国产剧集一般是每天凌晨点，美剧则是周一周二，综艺则是周六周日。为此每次新抓取的数据都记录一个更新时间，通过分析库内连续剧集更新时间我们可以推断出下一次更新的时间，那么我们可以经过一轮大的选取，从全量数据中选取出当天可能会更新的数据，对这一批量小的数据进行更新。图、视频更新策略
另外对于一些剧集，各大视频播放网站正在热播的数据则需要做到分钟级别的更新，一般这种量比较小，但是由于热度很高，所以其更新频率需要做到更高，为此对于榜单数据，我们通过分析抓取各垂直站点的热门榜单及分析微博数据，得到热门资源列表。图、榜单数据
更新则主要是体现在两个方面：一是页面发生变化，例如字段发生更新等情况；二是页面失效，变成死链。页面变化更新通常例如电视剧追剧、应用版本的升级相应的内容发生变化。一般这里重新走一遍之前结构化抽取的流程即可。对于页面失效、死链这种可以从页面展现形态区分为页面级死链和内容级死链。页面级死链可以通过返回码直接识别。对于内容级死链我们通常有两个步骤同步进行验证：

死链特征提取，通过分析出死链样本学习出一定死链特征模型
竞品交叉验证，例如古剑奇谭如果检测到风行这个站点死链，那么可以到风行、、百度这些视频站点进行搜索比对，做一次竞品间的比对。

通过前面这两个步骤基本可以完成一轮失效检测。为了进一步修正模型，提高失效置信度，我们外加了一层人工抽样审核，并且将结果反馈到模型中，指导下一轮迭代运行。图、失效检测
六总结
总体而言，对于一个垂直的数据获取平台我们构建了如下的一个流程，主要分为下载发现、离线存储、抽取清洗三大块。调度发现包括了前面提到的页面发现、数据抓取、压力控制等内容，抓取后的数据主要由、等存储介质进行存储，之后我们有一套结构化抽取平台和通用抽取平台对数据进行规整、关联聚合形成独立供业务使用的结构化数据。图、垂直数据获取流程
数据抓取平台是我们一个基础平台，后续我们也会开放出相应的服务，并且持续对体验做优化，希望我们的服务能够更广泛的应用，为业务提供更大的价值。

相关推荐
【文智背后的奥秘】系列篇——自动文本分类
【文智背后的奥秘】系列篇——基于的人名识别
【文智背后的奥秘】系列篇——分布式爬虫之
文智调用快速上手指南
大数据处理套件引言
和是在两种典型的有状态的集群服务。首先和都需要存储盘来保存有状态信息，其次和每一个实例都需要有对应的实例需要需要来作为集群内部每个成员的标识，集群内节点之间进行内部通信时需要用到这些标识。
在上文中，已经介绍了如何基于 搭建和服务。本文将介绍如何基于腾讯云容器服务已经支持的  存储和 创建和有状态集群服务。
方案整体介绍
目前腾讯云容器服务支持在服务的上挂载盘，异常挂掉后，会重新创建新的，此时盘也会随着迁移。通过这种方式，可以使用盘来存储服务实例的状态信息。
服务支持通过服务的域名解析得到服务所有实例的，如果服务实例数为，则可以得到服务对应实例的。
这样在和服务创建时，将每一个服务实例拆分成一个独立的服务。这样每个服务实例可以单独设置环境变量，配置和服务实例需要的实例。通过在每个服务实例上挂载盘，则可以存储服务实例的状态信息。通过服务，服务实例之间可以通过的直接访问。
具体的方案架构如下图所示：
服务创建
如整体方案图所示，将服务每个实例拆分成对应的服务，默认实例数为，分别为服务。目前容器服务暂时不支持创建 ，这里先在控制台的服务页面创建。然后再通过命令行创建对应的 。后期，支持在控制台直接创建 从而可以直接创建对应的服务实例。
创建对应的
第一步： 选择对应的数据卷
由于容器中将程序和的数据存放到了不同目录。所以需要选择挂载两个不同的目录。其中日志目录较小使用一个左右的小容量盘。
第二步： 选择镜像
选择 为的公有镜像。
第三步： 设置环境变量
由于服务的不同示例是单独部署的，所以可对不同服务实例设置不同的环境变量。服务需要设置的环境变量为__，_。其中__设置为对应的每个实例的。_都设置成=  =  =。其中为拆分后的服务名称。
第四步： 设置数据卷的挂载点
在容器中分别将盘和盘，映射到目录和目录
第五步： 选择服务的访问方式
由于只希望创建，所有这里选择不启用服务访问方式。后期可以支持直接选择方式访问。具体的服务访问方式介绍可以参考服务访问方式设置。
在控制台中依次创建这三个服务，创建完成后通过命令行可以查看到对应的信息。
   
                  
                                                
                                                
                                                

创建对应的 
在创建完后，可以创建对应的 来提供和之间直接的访问能力。   创建的示例如下：
 
 

  
     
   
   

   
  
    
     
  
     
   
   

依次创建，对应的 
     
  

    
                     
                                
                                
                                

查询对应的信息如下：
       
                                        
                        
                        
                         

查看中的域名信息
    
  
          

    
  
          

    
  
          

对集群进行简单测试
这样的服务就搭建完成。下面登录到服务对应的中，下面进行简单的测试。
   

    


     
 

    
 

服务创建
服务搭建完成后，开始采用同样的方式搭建服务。
创建对应的
第一步： 选择对应的数据卷
在这里，由于容器中将的日志和的数据存放到了不同目录。所以需要选择挂载两个不同的目录。其中程序的日志数据量较少，使用一个左右的小容量盘。
注意：由于在的镜像中，会对这样的环境变量进行解析，为了避免错误的解析，所有特意将服务名称设置成。
第二步： 选择对应的镜像
按照上图创建服务，选择 为的公有镜像。
第三步： 设置环境变量
由于服务的不同示例是单独部署的，所以可对不同服务实例设置不同的环境变量。设置的环境变量如下所示：
__=
__=
__=
___=

其中__和___根据服务实例的不同，需要设置不同的值。
第四步： 设置数据卷的挂载点
第五步： 选择服务的访问方式
同的部署选择不启用服务访问方式。
创建对应的 
在创建完后，可以创建对应的 来提供和之间直接的访问能力。  创建的示例如下：
 
 

  
     
   
   

   
  
    
     
  
     
   
   

依次创建，对应的 
     
  

    
                     
                            
                            
                            

查询对应的信息如下：
       
                                           
                       
                        
                        

查看中的域名信息
    
  
       

    
  
       

    
  
       

对服务进行简单的测试：
创建测试
   \
    \
    \
    \
   
  

创建生产消费测试
     

     

  
  

在消费者侧显示为：
  
  

扩容操作对于的扩容，可以通过增加一个服务的方式扩容。在本例中增加服务，将实例数增加到个。
     
                                            
                        
                         
                         
                         

   
                     
                            
                            
                            
                            

创建一个个副本的测试
  \
   \
   \
   \
  
   

说明实例个数，已经从个扩容到了个。
总结
通过上挂载盘的方式，能够存储有状态服务中的状态信息。同时通过将服务实例拆分成对应一个个的服务，可以单独对服务实例配置对应的信息，从而对服务实例进行标识。再结合 实现服务实例之间，直接通过域名进行访问。这种方式，对比的方式不需要依赖底层的 和  机制。同时，可以对单个服务实例进行升级和配置变更，升级和配置变更更加灵活。作者：马莉

精准测试之精简用例之为什么要精简
背景
  手机管家目前有年多的历史了，一直在持续不断的加入新特性，每次发布前除了新增功能之外，旧的核心功能也是发布之前必须确保的。
 、当前用例情况年的沉淀，虽然每次版本都会用例存档，但是日积月累下来，出现了以下几个问题：
、新增功能的用例直接添加上去存档，并不会修改优先级，当前版本新增功能中有些路径的优先级是，级，但是站在整个版本上来看或许并不是这么重要。
、旧功能的修改或删减，对已有功能做出修改或者是废弃，用例也是直接归档，并没有对之前的用例修改或删除，虽然用例后面都有写最后需改的版本，但是因为数量太过庞大，想要找到那个点修改也是力不从心。鉴于以上两点，用例越来越多：

碰到的问题
由于有这么多的用例，每次集成，主线集成，上线前都需要多这么多用例，带来了以下个思考：
、旧功能测试的时间过长，性价比不高
这些旧功能不是本次版本的重点，值得花多于新功能的时间执行吗？
、新人学习成本大
功能用例都是外包执行，外包的流动性非常大，如果是一个新人外包，让他在短短的时间内执行这么多用例，数量大且有很多用例不知道怎么执行，需要咨询的时间，这样算起来在计划内的时间根本执行不完，还需要申请资源支持，可是这么做值得吗？
、外包工作量化
当面对如此庞大的用例时，新人时期可能会一条一条执行，但是熟悉之后，经验会告诉他哪些可以不执行，那么接口人如果按照量级去分配任务，是否不合理呢？
精简的收益与目标
鉴于以上分析，用例精简值得做，且会有很大收益
预期获得的收益
、缩短测试时间：
可以减少集成，主线集成，上线前的测试时间。
、减少新人学习成本：
只保留最“精“的用例，去除不必要的用例，划分清晰的模块，利于新人学习和执行。
、外包工作量化：
做到外包实际做的和接口人预估的符合，不会有太大的水分。
精简的目标
集成阶段的用例缩减至少，执行时间缩减为，包括集成，主线集成。
上线前用例缩减到以内，执行时间缩减为，包括定位问题的时间。
解决的思路
知道了精简的必要性之后，思考要怎么去执行，时间成本最小的做法，我认为如下：
充分利用经验，把经验转化为可见的东西，即运用集体智慧
第一轮：人工筛选，由于是要善于利用外包同学的经验
力度：粗，不必要太精细，每个模块的要大胆删除
工具辅助：代码覆盖率知识库
通过工具辅助来补充人工的不足和冗余完善整个模块的知识库，便于后续利用
方法：经验沉淀＋代码覆盖率＋知识库
精准测试之精简之执行，收益与维护
改造用例
了解实现原理，将用例按照代码实现方式来分类，比如手机管家。
代码实现方式：插件
划分功能用例功能模块
尽量完全独立，与其他功能模块少交互，这样才有利于第三部的划分，有耦合的也没有问题，只是相对应的插件会更多，见第三点
理清功能模块与插件的关系
、一般一个插件是一个主要的功能模块，这是最理想的状态
、事实是，大部分的插件也会遵循一个插件是一个主要的功能模块，但是为了减少代码量或是其他原因，有时候会做一些移动，把某些的代码放到其他名字看上去完全不相关的插件里
、要做的就是把上述点，哪个功能模块的实现分别在哪几个插件中的对应关系整理清楚
修改功能用例的模块
按照第三点都把功能用例对应的功能写清楚，基本全部能够直接对应到插件，这样后面的执行有利于筛选
分配功能模块的优先级
按照功能的重要性，分配每个功能模块的优先级，功能复杂的模块用时会多些，最后按照优先级以及耗时制定计划。制定计划清晰又有每个阶段应该做什么怎么做，避免浪费时间。
  用例与计划都准备好之后，就可以开始精简之路了。
开始精简
精简方法：经验沉淀＋代码覆盖率＋知识库
采用先减后加，放开胆子去删的思路覆盖率采用方法覆盖，工具为的二次开发工具—代码覆盖率平台
级用例删减
级用例的删减，采用采供过滤的方式，后面再查缺补漏即可。
、级用例中与当前版本不符的用例降级
分析这些用例应该是级还是级，确定之后标注好，这里尤其要注意那些历史问题，这一步完全可以让外包同学做，接口人就好。
、执行用例，查看代码覆盖率
此时一般都在左右，因为主路径基本都已涵盖
需要注意的是，这步做完还不需要具体去分析没有覆盖到的代码，毕竟级用例的占比不会太多，为了能够减少工作量，下文会提到什么时候才是合适的时机去分析没有覆盖到的代码。
级用例删减
 现在开始进行级用例的删减，一般来说级用例是量最大的，级和级用例都只占一小部分而已，所以最大的工作量在这里。
、人工删减
人工删减级用例要做到大胆的删，原则是只留属于主路径和重要的异常路径，其他全部降为级
、执行，查看代码覆盖率
这时代码覆盖率一般都在左右，接下来要开始分析代码了。
小：我做了个插件，最后得出我认为最快捷的方式，举例为代码，分析路径。
第一步的目标
消除所有的，即每个的覆盖不为，一般最多次
  找出所有的分析，可以自己走读代码，也可以咨询相应对模块的开发，为了省时，我在开始精简代码开始之前已经找过开发负责人，每个插件都有对应的开发负责人接口。
、查看下的每个，分析百分之的原因，确认这个的作用，有以下三种操作冗余
忽略
例如：数据库升级
覆盖安装及对应的读写数据库
其他完全不相关的插件调用使用的
确认遗漏的，补充和的知识库，添加模块相应注释
、根据注释补充用例，并确定优先级
、执行，检查覆盖率是否还有
还有为的要分析为什么之前补充的用例没有覆盖到？
注释有误，修改用例，接着重新执行
模块已废弃不用，路径跑不到，因为历史遗留代码的问题，开发对于代码的反应一般都是害怕错删，标注冗余
这一轮一般做轮左右就了，如果执行的时候大于轮，那要好好思考下第三点所提到的没覆盖的原因，是否是需要提高注释的质量等。
第二步的目标
全部的覆盖率达到以上，即每个的覆盖大于等于，次数在次以内
、，根据覆盖率分为类，大于，小于
小于的，按照从小到大的顺序排序划分
再将每个中的的覆盖小于的的按照从小打到的顺序划分
分析下覆盖为的，具体分析方式跟为一致详见
分析下覆盖小于的
做完和描述的步，一般覆盖率就达到了左右。
第三步的目标
每个的覆盖于大于等于左右，一般要次左右
这个过程是整个流程中耗时最长，但增加最少的阶段，因为牵扯到细节，所以要耐心，全局查看覆盖从小到大的挨个分析。整个过程最好保留基线和已上传的，一直更新，再查看。
第四步的目标
人工审核，查缺补漏
覆盖率只是个数据，并且是辅助工具，如何做到上线前的，主线集成的用例够精简且不会遗漏，精简后还需要再人工审核一遍，我的具体做法是：
、主路径：
打开，按照插件来检查每个模块的用例，中能看到的所有入口必须涵盖在级用例中。
、用户常用场景：
将用户常用场景按照模块列出来，对照相对应的用例，级用例必须全部涵盖。
、运用集体智慧：
人的经验转换，一起共同测试的同学聚在一起，按照模块一起用例，觉得哪里有遗漏，按照经验什么地方经常出问题，是否需要增加用例，之后觉得合理的加入。
、线上缺陷线上反馈：
版本发布后，根据线上缺陷线上反馈来检查，是否是测试用例遗漏造成的，分析线上缺陷的根因，根据严重等级和用户反馈数来决定是否要添加用例，以及应该添加到哪个阶段最合适。
精简收益
用例精简效果，远大于目标

测试时间，精简之后的用例，历经个版本，集成时间在内，上线前时间。
后期验证与维护
维护：
与当前版本不符的级用例，即历史某个版本的级用例，尤其是本次新添加的用例规避：每次版本结束后归档时，新增内容优先级修改，集成，主线集成，上线前的用例明确，不要再留有历史级用例
验证：
主线集成，上线前，灰度，线上跟进，看是否有是因为精简用例而造成的缺失，分析并查缺补漏，目前已经历了个大版本，截止目前为止只有灰度期间发现的个一般问题，补充上线前用例条。

相关推荐【腾讯】快给你的用例做减法吧 【腾讯】测试分析？就这么简单！ 可以以单复制集的方式运行， 直连  读取数据。
单复制集的方式下，数据的水平扩展的责任推给了业务层解决分实例，分库分表， 原生提供集群方案，该方案的简要架构如下：

集群是一个典型的去中心化分布式集群。集群主要为用户解决了如下问题：

元数据的一致性与高可用   

业务数据的多备份容灾由复制集技术保证

动态自动分片

动态自动数据均衡


下文通过介绍  集群中各个组成部分，逐步深入剖析  集群原理。

 元数据全部存放在中， 是由一组至少三个实例组成的集群。
 的唯一功能是提供元数据的增删改查。和大多数元数据管理系统，类似，也是保证一致性与分区容错性。本身不具备中心化的调度功能。
与复制集
 的分区容错性和数据一致性是复制集本身的性质。
 的读写一致性由  和  两个参数保证。
 
 
两者组合可以得到不同的一致性等级。
指定  可以保证写入数据不丢失，不会因选举新主节点而被回滚掉。
   可以保证强一致性的读
   可以保证最终一致性的读
 对全部指定 的写入方式，因此元数据可以保证不丢失。
对  的读指定了  的方式，在  中舍弃了与得到了元数据的强一致性读。

数据自动分片
对于一个读写操作， 需要知道应该将其路由到哪个复制集上，通过将片键空间划分为若干个区间，计算出一个操作的片键的所属区间对应的复制集来实现路由。

 被划分为个，其中
 包含，   包含  的数据，放在上。
 包含   包含  的数据，放在上。
 的信息存放在 的实例的  表中，格式如下：
{   
    _  _\\   
         
         
         
      {              }   
      {              }   
      
}
值得注意的是：是一个逻辑上的组织结构，并不涉及到底层的文件组织方式。
启发式触发分裂
 默认配置下，每个大小为。超过该大小就需要执行分裂。分裂是由发起的，而数据放在处，因此无法准确判断每个增删改操作后某个的数据实际大小。因此采用了一种启发式的触发分裂方式：
在内存中记录一份 _  _ 的哈希表。
对于和操作，估算出_的上界 当_超过阈值时，执行分裂。值得注意的是：

 __ 是维护在内存里的一份数据，重启后丢失
 不同之间的这份数据相互独立
 不带的 无法对 __ 作用

因此这个启发式的分裂方式很不精确，而除了手工以命令的方式分裂之外，这是自带的唯一的分裂方式。
分裂的执行过程

 向对应的 发起 命令，获得一个的可分裂点
  拿到这些分裂点后，向发起 命令

执行过程：

 计算出的文档的 =  
 计算出分裂后的中，每个应该有的数， _ =      
 线性遍历 的 对应的的 __ __ 范围，在遍历过程中利用_ 分割出若干

执行过程：

 获得待执行的分布式锁向 的中写入一条记录实现
 刷新向读取本的版本号，检查是否和命令发起者携带的版本号一致
 向中写入分裂后的信息，成功后修改本地的信息与的版本号
 向中写入变更日志
 通知操作完成，修改自身元数据

分裂的执行流程图：

问题与思考
问题一：为何在接收到的返回后，执行 要放在执行而不是中呢，为何不是自己执行完了再通知 修改元数据？
我们知道元数据在三个地方持有，分别是，，。如果元信息由更改，则其他与都无法第一时间获得最新元数据。可能会发生这样的问题，如下图描述：

对元数据的修改还没有被与其他感知，其他与的版本号保持一致，导致其他写入错误的。
如果元信息由更改， 先于所有的感知到本的元数据被更改，由于对的写入请求都会带有版本号以发起者的 持有的版本号，发现一个读写带有的版本号低于自身版本号时就会返回 ，从而避免对错误的进行读写。

对读写的路由
读请求：
将读请求路由到对应的上，如果得到，则刷新本地的元数据从读取最新元数据并重试。
写请求：
将写请求路由到对应的上，如果得到，并不会像读请求一样重试，这样做并不合理，截至当前版本，也只是列出了一个__
                        
               
迁移
迁移由模块执行，模块并不是一个独立的，而是的一个线程模块。同一时间只有一个模块在执行，这一点是在中注册分布式锁来保证的。

 对于每一个的 分布，计算出这个需要进行迁移的，以及每个需要迁移到哪个上。计算的过程在 类中，比较琐碎。
迁移
 对于每一个，尝试获得该的分布式锁向申请，如果获得失败，表明该已有正在执行的搬迁任务。这一点说明对于同一张表统一时刻只能有一个搬迁任务。如果这张表分布在不同的上，完全隔离的条件可以提高并发，不过并没有利用起来这一点。
如果获得锁成功，则向源发起 命令
迁移
 执行命令

 源 根据需要迁移的 的上下限构造好查询计划，基于分片索引的扫描查询。并向目标发起 指令，让目标 开始进入数据拉取阶段。
 源对此阶段的修改， 将字段在内存里类，为了防止搬迁时速度过慢无限制增长，大小设置为，在搬迁过程中的更改量超过大小会导致搬迁失败。
 目标 在接收到命令后

 基于的，将本上的可能脏数据清理掉
  向源发起_指定，通过中构造好的基于分配索引的扫描查询得到该 数据的
 拷贝完后，向源发起_命令，将中维护在内存中的修改
 源在收到_后，通过记录的查询对应的，将真实数据返回给目标。
  目标在收完_ 阶段的数据后，进入状态，等待源接下来的命令。这里有必要说明的是：用户数据源源不断的写入，理论上_ 阶段会一直有新数据，但是必须要找到一个点截断数据流，将源的数据搬迁对应的的数据设置为不可写，才能发起路由更改。因此这里所说的“_阶段的所有数据”只是针对于某个时间点，这个时间点过后依然会有新数据进来。
 源心跳检查目标是否已经处于状态，如果是，则封禁的写入，向目标发起_命令，之后源的上就无修改了。
 目标收到_命令后，拉取源上的修改并执行，执行成功后源解禁路由并清理源的数据

 流程图如下：
 
总结
经过分析，我们发现在迁移方面有很大的待提升空间

 一张表同一时间只能有一个在搬迁，没有充分利用不同机器之间的隔离来做并发提速。
 搬迁时需要扫描源的数据集，一方面会与业务争，一方面会破坏如果是引擎热点读写的
 启发式分裂的方式极不靠谱，重启后，启发信息就丢失了，而且部分常见的写入模式也不会记录启发信息

经过团队的测试，自带的搬迁方案处理的数据需要小时。团队分析了自带的搬迁方案的缺陷，自研了一套基于备份的搬迁方案，速度有倍以上的提升敬请期待！

相关推荐复制集原理 引擎分析安装部署与高可用作者介绍：，腾讯高级安全工程师

随着大量外挂、辅助、工作室等非法盈利团队借由移动游戏产业迅猛发展的东风趁虚而入，对游戏开发商和玩家来说都造成了不小的伤害，安全问题成为手游发展不容忽视的前提。本文告诉你如何从技术的角度来提前曝光这些安全问题和外挂风险。
安全无小事安全测试开展思路
随着智能手机的全面普及和市场泛娱乐化，移动游戏行业发展迅猛，无论是市场收入还是用户规模，手游在游戏市场上已经占据了半壁江山。如此火热的市场吸引了大量外挂、辅助、工作室等非法盈利团队，严重影响了游戏的收益、平衡，缩短游戏的生命周期，下面我们来看看外挂对手游有哪些危害。

安全无小事，如何从技术的角度来提前曝光这些安全问题和外挂风险呢？腾讯，安全雷达，腾讯手游安全测试的专项技术方案手游安全测试团队从年初开始对手游安全这个领域进行探索和技术积累，旨在通过提前发现游戏版本的安全漏洞，预警风险，帮助提高腾讯游戏的品牌和口碑。
安全测试，与项目发布同行
为了帮助项目在发布前发现并修复安全问题，在游戏版本转功能测试的阶段手游安全专项测试就介入。

手游安全测试经过若干轮的效率优化，已经将一轮安全测试的时间压缩至天，可以输出《手游安全测试报告》。项目修复漏洞后，仍由专项团队进行安全漏洞的回归检查，并确保项目按版本计划进行发布。
提早揭露安全漏洞，可以帮助项目在开发阶段进行安全对抗和策略加固，避免在项目运营时，与外挂对抗的被动局面。同时，也从根本上降低了外挂带来的玩家流失和运营损失。

专家测试
根据手游安全测试的需求，主要涉及到手游项目中的测试范围及测试内容的规定。提供专家手游安全测试服务，会有腾讯内部的手游安全测试专家进行测试、问题沟通跟进、处理优化检查等等。

测试设计，根据相应游戏的内容进行测试设计，找出游戏中的获利点，结合安全检查项，可以对游戏的内容进行完整覆盖
专家互评，对风险检查点进行查漏补缺，保证完整覆盖
测试执行，依据风险检查点，使用工具执行测试检查，主要进行函数修改、协议修改、内存修改、变速、脚本修改、静态漏洞扫描
提交漏洞，测试专家按照漏洞模板提交漏洞，依据《漏洞评级标准》进行漏洞定级和内容的审核
安全报告，由安全专家根据发现的问题和游戏整体对安全性进行评估并输出安全测试报告
漏洞回归，漏洞修复后，从新提交修复版本进行回归，评估漏洞修复情况并反馈结论

自动化测试

宕机漏洞扫描服务，通过智能分析协议来填充模糊测试，发送到服务器，测试服务器的可靠性、健壮性
协议函数风险扫描，通过算法学习安全风险模型，读取游戏函数、协议数据后进行智能分析，具备小时输出安全测试报告的能力

安全测试技术方案
根据以上的规划思路，团队聚焦在漏洞挖掘的能力和效率提升上进行手游安全测试技术创新。整个技术方案最大的难点在于，手游与传统的差异很大，不同游戏的玩法、技术实现都不一样，我们如何研发一套普适的方案，来满足不同游戏的安全测试需求。经过几年的研发与优化，团队终于做到了，兼容了数百款腾讯自研、代理游戏，打造了业界领先的手游安全测试技术方案。
独创的安全测试技术

业界独创的动态修改手游客户端程序的安全测试技术、基于对象的手游内存安全测试技术
多种领先的自动化风险扫描技术
拥有多项国家级技术专利



手游安全测试团队将审核的内容分为静态安全漏洞和动态安全漏洞。不同类型的问题测试思路和分析手段会有不同，对测试工具和测试方法也会有差别。


静态漏洞扫描
主要通过静态扫描的方式，对游戏中配置档、资源文件、脚本文件、、文件，通过自动扫描的方式来进行检查项的确认。目前此块内容已集成到手游安全测试方案中，覆盖了条安全检查项和信息安全测试项 
动态风险分析
动态安全测试涉及的内容广泛，主要是根据游戏特定的内容和玩法，针对性地分析安全风险点，通过协议、函数、内存、脚本等技术，多维度检查游戏服务器对相应的风险点是否有完善的校验或反外挂策略。

根据对漏洞类型的提炼，手游安全测试团队总结了根据游戏中的获利点而生成的风险点，然后在不同的游戏中，结合具体玩法，又推导出相应的获益方式。通常根据风险点分析的方式，可以完整覆盖到游戏中涉及到安全的部分，结合检查点，就生成了可以在实际操作中执行的用例，形成闭环。

手游安全测试对于技术的要求也是非常高的，需要专业的技术人员进行逆向分析和工具支持，否则上述的测试点很有可能是纸上谈兵，但毫不夸大地说手游安全测试已经拥有了这些技术积累。根据对测试检查点的分析，我们需要的安全测试工具包括：函数修改、内存修改、变速修改、协议修改、脚本修改。
手游安全测试深度解密
在工具最新的版本上已经集成了所有安全测试的辅助功能。下面从技术实现和工具效果上来展示各大功能的情况。
双端协议修改


工具通过直接注入游戏的组包函数，自动解析协议结构，免去了需要依赖测试人员分析二进制数据进行协议破解。在没有协议结构文件时也能自动解析协议结构。手机和端都可以进行协议数据展示，在手机上可以实施地显示协议发包的效果，在上可以动态一键修改相应字段，互补不足。


从目前支持和接入的游戏来看，工具已经对目前腾讯在研和运营的游戏达到了的支持，从协议类型上支持和引擎类型来看，也基本覆盖了当前所有的游戏类型：

函数动态修改


对于单局类玩法的手游，函数动态修改具备最强的漏洞能力。但是早期的测试方法效率非常低下，需要每个函数单独编写函数、定义函数指针变量、申请独立资源、重新编译代码。同时，使用门槛很高，只有专业的安全专项测试人员才能操作。函数动态修改通过动态通用技术，不需要测试人员再进行函数编码。


方案效果：

函数动态修改方案共覆盖安全检查风险项项
安全审核单个版本时间由天减少到天
函数修改测试成本降低

内存对象修改

业界首创手游内存修改技术，为测试人员直接展示出游戏中对象列表、对象属性名称、属性值等信息，并且可以对象为单位进行搜索，以革新方式告别传统手游内存测试工具搜索“内存数值”方式定位目标内存地址的低效方案，实现该项测试成本降低。

内存对象 一目了然

获取内存中所有对象、对象名、地址、属性值

对象数据 动态更新

动态更新内存对象

动态修改 实时生效

直接修改对象属性，游戏内即时生效
协议字段模糊测试：
拒绝服务攻击即攻击者想办法让目标机器停止提供服务，是黑客常用的攻击手段之一。玩家的异常操作、黑客异常发包、批量发包等都可能导致服务器宕机，影响游戏的正常运营，玩家不能正常游戏。早期的协议测试中有设计异常发包，检查是否会导致服务器宕机。但是这种方式测试效率很低，覆盖的异常点非常少。结合外网模糊测试工具和长期协议测试积累的宕机，研发了这套系统。字段模糊测试的覆盖的协议用例类型包括：

通过对于字段类型的分析后，自动填充相关的字段的异常类型值，来组包发送给服务器，进行服务器的模糊测试。解决了传统协议测试执行效率低、定位问题慢、覆盖分支少的问题。
测试流程如下：

模糊测试执行过程中不需要测试人员过多参与，就可以发现大量的安全问题。支持设备并发执行，智能分配测试机执行任务，执行任务的效率之高。发现问题后可以智能定位协议与字段，帮助开发人员快速定位问题。扫描覆盖检查规则项，包括数值溢出、注入、格式字符串、缓冲区溢出，已经完全覆盖协议模糊测试的类型，且数据还在不断增加中。
自动化效果：

通过自动化扫描发现服务器宕机问题例
检查所有协议字段的异常值填充，平均每款游戏执行协议异常用例条，填补手工测试无法完成的空缺
单个游戏小时内可测试用例条以上，效率提升巨大
扫描覆盖检查规则项，包括空指针、数值溢出、注入、格式字符串、缓冲区溢出等测试项

函数风险扫描技术：


对大量安全漏洞进行风险定义、特征定义与分类，引入模式识别技术，建立手游安全风险分析模型，自动分析出游戏高危风险函数，有效帮助测试人员省掉最为耗时的风险分析环节，实现单个手游版本漏洞测试时长从个工作日降低到个工作日。
手游安全测试支持项目情况：

手游安全测试方案在工具上已经支持所有腾讯在研和运营的手游项目，依靠自身的技术积累来提高专业程度，持续保持漏洞的发现率。目前在手游安全测试团队过审的项目漏洞发现率为，得到了越来越多的项目认可。通过对腾讯高星级手游的安全测试发现个安全漏洞，且整体的数据呈上升的趋势。各大手游厂商在关注运营留存，收入的同时，这些数据同样值得思考！

通过数据统计我们发现，高危的漏洞反而在手游安全测试的过程中更容易被发现，带来的风险也是更致命的。在腾讯内部，通过手游安全测试的推动，这些安全问题也在项目组得到了修复，为腾讯游戏创造了一个公平竞技，安全运营的游戏生态环境。现在手游安全测试正式入驻腾讯，正式将安全测试能力开放对外，有需要的厂商可以联系腾讯预约服务。
和大家分享部分案例，案例中的所有问题都已得到了解决。
【案例】模式中，动态修改游戏进程中多处代码逻辑，实现“无敌全屏秒杀外挂” 

【案例】韩信 无情冲锋技能超远距离释放，利用漏洞进行全图范围内的突进功能。
无情冲锋属于子弹型技能，即释放时需要指定一个突进的方向。将技能类型强制修改为指定施法坐标的类型，指定技能落点位置坐标，就能够获得全图突进效果。

【案例】
篡改攻击对象与伤害逻辑，造成全屏秒杀效果

【案例】
篡改使用物品协议请求中消耗数量，实现无限开箱子刷装备

安全漏洞说明：以上安全漏洞在正式环境中都已修复，或加入了反外挂机制。本文以白帽渗透测试的角度，介绍在游戏版本发布前的测试阶段，通过“黑盒测试”的方式逐步分析游戏业务逻辑中的风险点，主动挖掘潜在安全漏洞，最大程度避免最终发布版本中的游戏外挂风险。
手游安全测试提供的服务
【专家安全测试】
无漏洞不收费，只需要提供包，可在约定时间内拿到一份安全评估报告
【安全测试工具】即将开放
开放腾讯安全测试专业工具，降低企业手游安全测试技术门槛

腾讯手游安全测试团队经过对手游安全领域多年的探索和技术积累， 打造出了业界领先的手游安全测试技术方案——手游安全测试方案，在工具上已经支持所有腾讯在研和运营的手游项目，依靠自身的技术积累来提高专业程度，持续保持漏洞的发现率。目前提供了专家测试和自动化测试，希望通过提前发现游戏版本的安全漏洞，预警风险，帮助提高腾讯游戏的品牌和口碑。
目前腾讯手游安全测试限期开放免费专家预约！点击链接立即预约！
商业转载请联系腾讯获得授权，非商业转载请注明出处。互联网所催生的新一轮产业革命，移动不断地连接“人“，创造了一个个基于人的应用场景；物联网传感器在不断的连接着”物“，也在创造一个个基于物的应用场景。在这样的一个连接的时代诞生的微信，它不仅仅成为我们连接人的日常沟通交流的工具，已经成为了中国整个社会的信息基础设施。
在国内，由于微信在实时的连接每一个人，它已经成为一个最强大的入口，我本身从事微信支付的后端清算业务，能够深刻的体验到微信的强大引力，同时我也在运营微信公众号。公众号，服务号和企业号的诞生已经让微信开始连接后端的企业系统，小程序正在发展过程中，小程序让微信连接后端的企业系统打开新的窗户。但是这些后端的企业系统很多都是用开发的，正好的开源项目   成为平台上进行微信的快速开发的一个好工具，让开发者更好的对接后端的企业系统。
  从诞生起就采用开源模式持续更新，  是目前使用率最高的微信  ，也是国内最受欢迎的  开源项目之一，已经支持几乎所有微信平台模块和接口，同时支持       。 很早我知道本书作者苏震巍在众筹写一本《微信公众平台快速开发》的书，在小程序对外正式发布的时候，我找他约稿了一篇小程序的文章发在我的微信公众号，那篇文章也是这本书的其中一章内容，最近这本书接近发稿了，有幸为这本书写序。
认识苏震巍多年，知道他不仅是技术专家，也是热心公益、乐于分享助人的好朋友。就如他自己所言，促使他开始他准备这本书的初心是要帮助朋友，帮助更多有理想的开发者实现价值，倡导开放共享的开发生态圈，助力中国开源事业，同时也感恩一路上给我们提供帮助的朋友们。
阅读完苏震巍传给我的书稿，这是一本比较全面地介绍微信公众号开发技术的图书，是一本从实践总结出来的实战类书籍，各章节的安排具有一定的知识层次，推荐给广大开发者，非常感谢苏震巍夜以继日的辛苦努力，能让广大开发者拿到详实的微信开发指南和参考资料。我很高兴能为这本书作序！可以说，《微信开发深度解析：公众号、小程序高效开发秘籍》这本书是这个时代带给中国开发人员的及时雨，不仅仅告诉我们微信公众平台、小程序的开发和使用，也为我们设计应用系统提供很好的参考和借鉴的经验。
张善友，微软最有价值专家，腾讯高级工程师

现在有天限时团购优惠 折！，  京东自营连接： 游戏社交化是近年来游戏行业发展的重要趋势，实时互动的实现和社交平台的能力是游戏社交化的两大关键。游戏中玩家的沟通协作从最初的文字交流，逐渐发展为音、视频结合的多场景下的实时互动，是游戏中社交关系建立和维持的关键因素。另外，游戏社交需依托于平台，如何构建玩家间的社交网是各大游戏厂商的重要考虑点，这对平台的能力提出了很高的要求。
本期腾讯云沙龙，与您一一探讨！
演讲主题：懂游戏的音视频引擎——技术分析和场景应用
嘉宾简介：
 
李大为 腾讯互娱研发部项目和产品负责人在腾讯任职年，专注于游戏基础服务领域的产品，致力于将打造成游戏行业领先、开放、全球化的平台。
演讲概要：游戏出海增长迅猛，新兴市场增长比例超过，全球同服架构渐渐成为游戏的标准框架，如何满足游戏厂商新兴市场的布局需求，如何让全球同服架构更简单、更安全、更可靠，游戏云全球化实践为您解读腾讯云全球化最佳的解决方案和案例分享。
下载：
关于：系列沙龙由腾讯云主办，旨在为游戏开发者提供一个自由的交流分享平台。沙龙将围绕游戏行业趋势、研发技术、运维和推广等热点进行探讨。每期沙龙将邀请国内外游戏领域专家，分享游戏开发及运营过程中的思考和实践。
访问沙龙官网 ，了解最新沙龙资讯和更多往期回顾。作者：陶海军；腾讯通讯充值与彩票业务部 高级工程师
引言：  谈起区块链前世今生，我们不得不先说一下比特币。因为比特币和区块链如鱼水之间一样有着太多的关系。

比特币的起源
年，一位化名为中本聪的人，在一篇为《比特币：一个点对点的电子现金系统》的论文中首先提出了比特币。中本聪结合以前的多个数字货币发明，如和，创建了一个完全去中心化的电子现金系统，不依赖于通货保障或是结算验证保障的中央权威。关键的创新是利用分布式计算系统称为”工作量证明”算法每隔分钟进行一次的全网”选拔”能够使用去中心化的网络同步交易记录。这个能优雅的解决双重支付问题即一个单一的货币单位可以使用两次，此前，双重支付问题是数字货币的一个弱点，并通过一个中央结算机构清除所有交易来处理。
比特币打开了区块链大门
  区块链技术是比特币原创的核心技术。在比特币被发明之前世界上并不存在区块链这个东西。 
  比特币发明之后，很多人参考比特币中的区块链实现，使用类似的技术实现各种应用，这类技术统称区块链技术。用区块链技术实现的各种链即为区块链。
区块链技术的巨大价值
其实区块链技术最核心的就是解决信任成本的问题，去中心化去中介是区块链技术的核心概念。区块链藐视一切禁锢我们头脑的旧思维，它将颠覆交易执行的管理方式和集中型控制模式。区块链松开了信任的缰绳，这缰绳曾经牢牢控制在各种中心机构的手中，例如银行、政策制定者、清算中心、政府、大公司等。区块链让人们摆脱了这些老旧的控制节点。例如，交易双方完全可以在区块链上进行交易的认证，而不再需要一个清算中心。信用的实现应该是无偿的，更不应该掌握在某种集中型的权威手中，这种权力要么利用信用收税，要么肆意操纵，玩弄各种形式的费用、访问权、许可权等等。所以我相信未来的区块链遍地开花之时，将引爆一个新的纪元。
什么区块链技术？
从本质上讲，区块链技术，是一种交易记录的存储技术。它对交易记录进行永久性存储，而且存储之后永远无法删除，只能按照次序加入新的交易，由此对所有的交易历史进行永不结束的记载。这个看似简单的功能描述，实则含义深刻。它促使我们，重新思考如何去创建交易、存储数据和交换资产。它是一场巨大变革的起点。
一句话描述区块链技术？
 基于密码学安全的分布式账簿网络技术。
区块链技术核心点

一个点对点分布式网络各网络节点同步数据
一份所有交易的账簿数据区块链
一个去中心化的交易验证基于密码学交易安全、脚本验证交易实现合约或智能合约
一个去中心化的定量货币发行分布式挖矿、矿池挖矿协议、工作量证明生成新区块

一、点对点的网络  
 网络工作原理

新的交易向全网进行广播
每一个节点都将收到的交易信息纳入一个区块中
每个节点都尝试在自己的区块中找到一个具有足够难度的工作量证明 
当一个节点找到了一个工作量证明，它就向全网进行广播
当且仅当包含在该区块中的所有交易都是有效的且之前未存在过的，其他节点才认同 该区块的有效性 
其他节点表示他们接受该区块，而表示接受的方法，则是在跟随该区块的末尾，制造 新的区块以延长该链条，而将被接受区块的随机散列值视为先于新区快的随机散列值

 区块链网络组成部分

 区块链网络详细流程图

二、区块链 
 区块链原理及简介
区块链的实现方案首先提出一个“时间戳服务器”。时间戳服务器通过对以区块形式存在 的一组数据实施随机散列而加上时间戳，并将该随机散列进行广播，就像在新闻或世界性新闻组网络的发帖一样组成一个楼层链条。显然，该时间戳能够证实特定数据必然于某特定时刻是的确存在的，因为只有在该时刻存在了才能获取相应的随机散列值。每个时间戳应当将前一个时间戳纳入其随机散列值中，每一个随后的时间戳都对之前的一个时间戳进行增强， 这样就形成了一个链条。
区块链形象图

 区块链的连接
矿工会根据工作量证明每过特定时间挖到新的区块如比特币：根据难度系数，工作量证明算法全网算力大概分钟左右才能产生一个新区块；难度系数会根据全网算力的增加而调整，永远保证大概分钟产生一个新的区块。节点会在”父区块哈希值“字段找出包含它的父区块的哈希值。这是节点已知的哈希值，也就是如下图中第块区块的哈希值。故这个区块是这个链条里的最后一个区块的子区块，因此现有的区块链得以扩展。节点将新的区块添加到链条的尾端，使区块链变长到一个新的高度。
下图展示了三个区块的连接：

 区块链  比特币创世区块信息

三、交易
我们定义，一枚电子货币  是这样的一串数字签名每一位所有者通过对前一次交易和下一位拥有者的公钥  签署一个随机散列的数字签名，并将这个签名附加在这枚电子货币的末尾，电子货币就发送给了下一位所有者。而收款人通过对签名进行检验，就能够验证该链条的所有者。
 复式记账薄式交易

 交易中的输入与输出
一笔数字货币的交易是一个含有输入值和输出值的数据结构。该数据结构植入了将一笔资金从初始点输入值转移至目标地址输出值的代码信息。数字货币交易的输入值和输出值与账号或才身份信息无关。你应该将它们理解成一种被特定密钥信息锁定的一定数量的数字货币。只有拥有者这个密钥信息的人可以解锁。
 交易流程图

一般交易，最常见的交易形式是从一个地址到另一个地址的简单支持。这种交易也常常包含给支付者”找零“。

集合型交易，是集合多个输入到一个输出的模式，相当于现实生活中将很多硬币和纸币兑换为一个 大额面钞。

分散型交易，是将一个输入分配给多个输出，这类交易类似于老板给员工发工资的情形，从一个账号转账给多个账号。

 交易数据 
下图为比特币的交易数据结构

四、工作量证明
 工作量简介
为了在点对点的基础上构建一组分散化的时间戳服务器，仅仅像报纸或世界性新闻网络组 一样工作是不够的，我们还需要一个类似于亚当·柏克 提出的哈希现金 。在进行随机散列运算时，工作量证明机制引入了对某一个特定值的扫描工作，比方说  下，随机散列值以一个或多个 开始。那么随着  的数目的上升 找到这个解所需要的工作量 将呈指数增长，但是检验结果仅需要一次随机散列运算。
我们在区块中补增一个随机数，这个随机数要使得该给定区块的随机散列值出现 了所需的那么多个。我们通过反复尝试来找到这个随机数，找到为止。这样我们就构建了一 个工作量证明机制。只要该  耗费的工作量能够满足该工作量证明机制，那么除非重新完 成相当的工作量，该区块的信息就不可更改。由于之后的区块是链接在该区块之后的，所以想 要更改该区块中的信息，就还需要重新完成之后所有区块的全部工作量。
 挖矿
  挖矿是增加数字货币供应的一个过程，挖矿同时还保护着数字货币系统的安全。
  矿工们在挖矿过程会得到两种类型的奖励：创建新区块的新币奖励，以及区块中所含的交易费。
 矿池挖矿
在激烈的算法竞争的环境中，个体矿工独立工作挖矿是没有一点机会。他们可以通过矿池协议合作组成矿池，共同协作挖矿分享奖励。
五、区块链常用术语
比特币
首字母大写的用来表示比特币的概念或整个比特币网络本身。例如：“今天我学了些有关协议的内容。”
而没有大写的则表示一个记账单位。例如：“我今天转出了个。”该单位通常也简写为或。
比特币地址
比特币地址就像一个物理地址或者电子邮件地址。这是别人付给你比特币时你唯一需要提供的信息。然而一个重要的区别是，每个地址应该只用于单笔交易。
对等式网络
对等式网络是指，通过允许单个节点与其他节点直接交互，从而实现整个系统像有组织的集体一样运作的系统 。对于比特币来说，比特币网络以这样一种方式构建——每个用户都在传播其他用户的交易。而且重要的是，不需要银行作为第三方。
哈希率
哈希率是衡量比特币网络处理能力的测量单位。为保证安全，比特币网络必须进行大量的数学运算。当网络达到秒的哈希率时，就意味着它能够进行每秒万亿次的计算。
交易确认
交易确认意味着一笔交易已经 被网络处理且不太可能被撤销。当交易被包含进一个块时会收到一个确认，后续的每一个块都对应一个确认。对于小金额交易单个确认便可视为安全，然而对于比如美元的大金额交易，等待个以上的确认比较合理。每一个确认都成 指数级地降低交易撤销的风险。
块链
块链是一个按时间顺序排列的比特币交易公共记录。块链由所有比特币用户共享。它被用来验证比特币交易的永久性并防止双重消费。
密码学
密码学是数学的一个分支，它让我们创造出可以提供很高安全性的数学证明。电子商务和网上银行也用到了密码学。对于比特币来说，密码学用来保证任何人都不可能使用他人钱包里的资金，或者破坏块链。密码学也用来给钱包加密，这样没有密码就用不了钱包。
签名
密码学签名是一个让人可以证明所有权的数学机制。对于比特币来说，一个比特币钱包和它的私钥通过一些数学魔法关联到一起。当你的比特币软件用对应的私钥为一笔交易签名，整个网络都能知道这个签名和已花费的比特币相匹配。但是，世界上没有人可以猜到你的私钥来窃取你辛苦赚来的比特币。
钱包
比特币钱包大致实体钱包在比特币网络中的等同物。钱包中实际上包含了你的私钥，可以让你消费块链中分配给钱包的比特币。和真正的钱包一样，每个比特币钱包都可以显示它所控制的所有比特币的总余额，并允许你将一定金额的比特币付给某人。这与商家进行扣款的信用卡不同。
区块
一个块是块链中的一条记录，包含并确认待处理的交易。平均约每分钟就有一个包含交易的新块通过挖矿的方式添加到块链中。
双重消费
如果一个不怀好意的用户试图将比特币同时支付给两个不同的收款人，就被称为双重消费。比特币挖矿和块链将就两比交易中那笔获得确认并被视为有效在网络上达成一致。
私钥
私钥是一个证明你有权从一个特定的钱包消费比特币的保密数据块，是通过一个密码学签名来实现的 。如果你使用的是钱包软件，你的私钥就存储在你的计算机内；如果使用的是在线钱包，你的私钥就存储在远程服务器上。千万不能泄露私钥，因为它们可以让你消费对应比特币钱包里的比特币。
挖矿
比特币挖矿是利用计算机硬件为比特币网络做数学计算进行交易确认和提高安全性的过程。作为对他们服务的奖励，矿工可以得到他们所确认的交易中包含的手续费，以及新创建的比特币。挖矿是一个专业的、竞争激烈的市场，奖金按照完成的计算量分割。并非所有的比特币用户都挖矿，挖矿赚钱也并不容易。
聪
是标明一个比特币的最小单位的常用单位 聪等于 比特币 为什么要用和路由管理
的概念其实出现已经很久了，记得笔者读大学的时候，接触到的概念，总觉得不重要，多此一举：

我掌握好通信这个利器和协议族原理，什么功能不能实现？

就跟本地函数调用一样写代码，确实开发效率比较高；我自己把相关函数好好封装一下，让代码复用起来，开发效率也很高。

不懂或者不关注网络通信底层原理，光会函数调来调去，这样的程序员太没有出息了！


后来，笔者开始带团队，亲身经历了一些团队协作和服务运营过程中的故事，才发现非常关键。这里分享我经历过的很早以前的两个故事。
故事一：有一个基础模块，被非常多的其他模块远程调用，模块的门户提供协议文档、、调用示例代码，每当有人来申请使用，模块负责人就会给调用方一组接口机的，调用方可以给这些发网络请求。
重视可用性的有追求的调用方，通常在拿到后，会把写在配置文件里，并且自己在代码里实现一定的容错逻辑：如果某个请求连续失败多少次，就一段时间内不要给它发请求了。这个容错逻辑做好可不简单，涉及到很多细节。
大多数的调用方，是把写死在代码里，简单的轮询请求这些。
如果模块的某台接口机死机了，或者网络局部故障导致某些接口机不可达，很多调用方就会跳起来：你们怎么回事？你们的服务水平怎么这么差！
如果机房裁撤，一些机器要下架，模块负责任会非常头疼：

首先不知道有哪些人在请求这个。读者说：傻啊，抓包看一下不就知道有哪些调用方了？但是要知道有的请求不是持续的，是不定期的访问一下模块。

模块的负责人要大范围的邮件通知调用方改路由通常要改代码编译发布，过一段时间后，抓包看还有哪些调用方没有改，再挨个敦促修改路由

有时候某个下架了，过了几天，突然有个调用方跳起来：我们还在用呢！我们是写死的，代码找不到了，只能拿二进制可执行文件“硬”改


故事二： 一个团队里，通常有很多技术能力、服务意识和责任心都非常强的同事，他们的工作产出质量非常高，每个远程调用都有次数和成功率的上报简单的说就是上报到一个监控系统，可以通过监控系统界面查看曲线图，请求报文中的一些重要但不强校验的字段也都认真填写例如染色标记，所以他们负责的模块，如果出现异常，很容易通过监控系统和日志监控到，并能快速定位到问题。
但是，也有一些同事责任心和能力不那么突出，重要的监控上报缺失、请求包里一些重要的字段没有填写。有时候服务的故障有异常了很久，被用户投诉才发现，事故报告里总是会出现这样的改进措施：增加对的监控上报，增强服务运营意识。 
类似的事故通常会反复出现，管理干部就会拉起一次运动式的梳理和整顿，但过一段时间，肯还会出现。
通过这两个事故可见：如果没有很好的实现和路由管理，系统服务质量会过度的依赖人的意识，而这个通常成本非常高、效果也不好。
毫秒服务引擎 取英文名    的首字母组合是腾讯一个开源框架，其创作冲动和构建经验，来自后台团队超过年的运营思考。和路由管理是毫秒服务引擎设计的重要考量点。
毫秒引擎里是怎么做的？
首先，毫秒引擎将每个服务部署在哪些上这些信息集中管理起来，即使是调用外部的非标准服务我们叫异构服务，也需要将该外部服务的接口配置到毫秒引擎管理系统里。这样涉及到的信息就不会散落在代码和各种配置文件里了。
服务之间的调用，统一采用函数的方式，避免代码千奇百怪；按服务名字调用和接口名调用

背后的路由算法对于单机故障、网络局部波动等异常，自动容错。简单的说，路由算法按一定的规则轮转的选择被调用模块的接口机，并统计过去一段时间的调用成功率、时延信息，根据这些信息调整该接口机被选择到的比例。如果某个接口机故障了，那么就不会发送请求给它，从而实现自动容错。
毫秒引擎框架本身，在执行的时候，就上报了很多基础属性和日志，这样保证了服务监控和告警等运营措施不依赖与人的意识。下图是叫做这样一个调用的请求数和成功数，这些是不需要业务开发者工作就自动上报。
每个请求有唯一来标识，通过该，毫秒引擎可以在框图中直观的呈现该请求经过的模块、模块间的名字等信息，这个同样不需要业务开发者的工作就自动实现：
结语
互联网服务的后台，硬件通常是由大量的廉价机器组成；软件架构通常采取大系统小做、分而治之的思想。这就决定了业务逻辑涉及到大量的网路，同时单机故障、网络局部故障是运营的常态。那么，和路由管理就显得尤其重要了。毫秒服务引擎为此提供了一个完整的解决方案。详细的可以见腾讯云服务市场、毫秒服务引擎官网，或者微信公众号

相关推荐 谈谈存储集群的设计要点 谈谈后台服务的灰度发布与监控作者：王少鸣

前面给大家分析过     的通信机制，这次我们从源码出发，分析下的启动过程。启动过程基于通信机制，涉及通信机制原理大家可以查看前一篇文章，本篇不赘述。
上面是    工程师分享的启动时序图，整个过程比较清晰，先启动终端运行时，随后由终端上下文去启动的运行时，进而布局，最后再由终端进行渲染，最后将添加到上。那接下来，我们先理解几个概念，方便后续我们对整个启动过程的理解。
模块：
模块即暴露给调用方的集合，在存在两种模块。
一种是层暴露给层的集合模块，即，如或是创建的。业务方可以通过实现自定义模块，通过重写将模块名暴露给层，通过注解的方式将暴露给层调用。
另一种是层暴露给层的集合模块，即，如等。业务方可以通过继承接口自定义接口模块，申明与层相应的方法即可。
无论是还是，在层存在与之相互映射同名的，层通过引用。
模块注册表：
各模块信息统一收集到模块注册表。同样，在中存在两种模块注册表，一是由集合所有层模块接口信息的，另一种是集合所有层模块接口信息的。在启动后，终端将注册表信息存入与前端互通的全局变量__ 中，使得层与层存在同样的模块注册表。

正如上面攻城狮提出的时序图，从终端启动，入口是，在构造后，进而通过去创建，这部分主要创建了及其对的注册表，负责与通信的高层接口等。在创建完后，通过获取并调用其启动 。整体流程如下：

接下来进入正题，从源码来分析的启动为阅读方便，源码适当裁剪
 ，通过初始化上下文。是与前端约定好所要启动的  。是终端启动前端可选的传入的参数。

  
 
  
     
     
       {
  

   = 
   = 
   = 

    {
    
  }

      {
    
     = 
    
  }  {
     = 
  }
}
`
最终调用到。这里会创建两个   。继承自，在加载会加载的，并且，在初始时会调用去初始层与的通信框架等。缓存了的信息，封装了上层加载相关接口，通过其间接调用去加载文件。

  
 
   {
  
       
       
}
创建完后， 继续初始化。

  
 
  
     
      {

    =
        
    {

      =  
    
     = 
  }  {
     = 
  }
}
为创建的核心类，在执行初始化前会销毁先前的上下文，保证只存在一个上下文。随后，调用进一步创建。在创建完 后会调用，进而通知更新上下文，更新生命周期，将做为 传递给，调用的去启动 等。

  
 
    
       {
  
     {
      =  {
      
       = 
    }
  }

  
      {
     =        = 
     {
        = 
        
    }    {
                   
       
    }
  }

  
      {
     {
      
    }    {
      
    }  {
       = 
    }

           
      =  {
      
          
          
       = 
    }
  }
}
在中，主要有以下个 

通过构建上文概念讲过的及；
创建。继承自，主要缓存了 ， ，处理消息的三个下篇讲述，还有就是全局控制调用导致  的，在初始化的时候传入，并且要关闭后才可以启用，假如不传，则默认交由去处理；
创建。主要通过、和等去创建本地模块，模块及视图组件等。分为的和业务方可选的基础，封装了大部分通信，调试核心类，如，这个负责控制层到 的核心类；
创建。并不直接面向开发者，开发者通间接操作。持有对的引用，主要通过这个类去实现层与层的通信，由的创建。同时初始化的时候调用了创建了通信的两个线程 ；
调用进一步将创建完的及线程等缓存在中；
调用加载解析；


  
 
     { }   { } 
 
  
     
      {

   = 
    =  
    =  

    =  
    {
    
  }

    =
           
     

       {
         
  }

   = 
   = 

    =  = 
       
       
    =  
      
      
      
      
      
      

   = 
    =  {
    
  }
  
  

   
}
由的创建。

   
 
 
      
      
      
      
      
      {
   = 
      
       
   =  
   = 
   =   
   = 
   = 
   =  

   {
     = 
          {
          
               {
            ____ 
             {
                
            }  {
              ____
            }
          }
        }
  }    {
          
  }
}
将注册表信息存入与前端互通的全局变量 __ 中，使得层与层存在同样的模块注册表。

   
 
  
     
      {

    =    
      

  ____ 
  
      __
       
  
      __

   
}
调用加载解析。假如在解析过程中出现，统一交给处理，建议开发者设置自己的，可以归避部分   ‘‘ 或     。

   
 
   {
   {
     = 
          {
          
               {
            
             {
              
              
            }    {
              
            }  {
              ____
            }
             
          }
        }
  }    {
      
  }
}
在创建完 后会执行的，从而调用，会将做为 传递给，此后通过创建的都会到该上。

  
 

    {
  
  {
    ___  
    
                  
                   
        =  {
       
    }
  }{
    ___  
  }

}
在绑定完后，通过获取这个后，进一步调用启动 。

  
 
  
     
      {

  
  _

    = 
    = 
     = 
    =  = 
       
       
    = 

    =  
   
   
   
}
 中与通信不再赘述。至此，启动层的启动 。

 

      {
  
              
        
    ____ ===   ____ 
          ____     
          ____    
  
  
      
                
              
        
  
  
}

相关推荐
    架构初探
   项目实战总结作者：

的魅力在于可以创造一个自己的世界，但相比较来说，除了物体的移动旋转变换完全依赖矩阵增加了复杂度，就连生成一个物体都变得很复杂。
什么？！为什么不用？等库确实可以很大程度的提高开发效率，而且各方面封装的非常棒，但是不推荐初学者直接依赖，最好是把各方面都学会，再去拥抱等相关库。
上篇矩阵入门中介绍了矩阵的基本知识，让大家了解到了基本的仿射变换矩阵，可以对物体进行移动旋转等变化，而这篇文章将教大家快速生成一个物体，并且结合变换矩阵在物体在你的世界里动起来。
注：本文适合稍微有点基础的人同学，至少知道，知道如何画一个物体在画布中
为什么说生成物体麻烦
我们先稍微对比下基本图形的创建代码
矩形：
   


和环境代码忽略

  = 
      
      
      
      


  =      

_ 
_   _
     

   

__ 
__   _

  _ 

完整代码地址：
结果：

圆：
       



 
  
  =   
  = 
  = 
  =   =   {
     =       
     =   
     =   

      

      

    
}

   =   一下

_ 
_   _
     

   

__ 
__   _

  _ 

完整代码地址：
结果：

总结：我们抛开中的代码和初始化环境的代码，发现比就是麻烦很多啊。光是两种基本图形就多了这么多行代码，抓其根本多的原因就是因为我们需要顶点信息。简单如矩形我们可以直接写出它的顶点，但是复杂一点的圆，我们还得用数学方式去生成，明显阻碍了人类文明的进步。相比较数学方式生成，如果我们能直接获得顶点信息那应该是最好的，有没有快捷的方式获取顶点信息呢？有，使用建模软件生成文件。
文件简单来说就是包含一个模型信息的文件，这里信息包含：顶点、纹理、法线以及该模型中纹理所使用的贴图。
下面这个是一个文件的地址：

简单分析一下这个文件

前两行看到符号就知道这个是注释了，该文件是用导出的。是一款很好用的建模软件，最主要的它是免费的！

 指的是该文件所使用的材质库文件
单纯的生成的模型是白模的，它只含有纹理坐标的信息，但没有贴图，有纹理坐标也没用

 顶点
 贴图坐标点
 顶点法线

 使用材质库文件中具体哪一个材质

是面，后面分别对应 顶点索引  纹理坐标索引  法线索引
这里大部分也都是我们非常常用的属性了，还有一些其他的，这里就不多说，可以搜一下，很多介绍很详细的文章。
如果有了文件，那我们的工作也就是将文件导入，然后读取内容并且按行解析就可以了。
先放出最后的结果，一个模拟银河系的文字效果。
在线地址查看
在这里顺便说一下，文字是可以通过分析获得文字模型数据的，将文字写到上之后读取像素，获取路径。我们这里没有采用该方法，因为虽然这样理论上任何文字都能转，还能做出类似输入文字，展示的效果。但是本文是教大家快速搭建一个小世界，所以我们还是采用去建模。
具体实现
、首先建模生成文件
这里我们使用生成文字

、读取分析文件
  = {  这里正则只去匹配了我们文件中用到数据
    _ \\|\|\|\||\\|\|\|\||\\|\|\|\||  顶点
    _ \\|\|\|\||\\|\|\|\||\\|\|\|\||  法线
    _ \\|\|\|\||\\|\|\|\||  纹理坐标
    ___ \\\\\\\\\\\\\\\\\\\\\\\\  面信息
    __ \\|\|\  依赖哪一个文件
    __ \\
}

   {
      =  

      

     =  {
         ===  {

            
        }
    }

    
}

  {
      = 
     = \

      =      {
         ||  {  注释部分过滤掉
             

            
        }
    }

     
}

   {
      = 
     
     

     ===  {

         = 

         ===     = _ ==  {
                加入到对象顶点数组
        }   ===    = _ ==  {
                加入到对象法线数组
        }   ===    = _ ==  {
               加入到对象纹理坐标数组
        }

    }   ===  {
         = ___ ==  {
              将顶点、发现、纹理坐标数组变成面
        }
    }   = __ ==  {
          加载文件
    }   = __ ==  {
          加载图片
    }
}

代码核心的地方都进行了注释，注意这里的正则只去匹配我们文件中含有的字段，其他信息没有去匹配，如果有对文件所有可能含有的信息完成匹配的同学可以去看下中部分源码
、将中数据真正的运用对象中去
 =  {
       
       
       
}

 =     {
     {
          
    }  {
             
    }
}

 =     {
     {
        
                        
                        
                        
        
    }  {
        
                        
                        
                        
                        
                        
                        
        
    }
}

 =     {
     {
               
               
               
    }  {
               
               
               
               
    }
}

这里我们考虑到兼容文件中行中个值的情况，导出文件中可以强行选择只有三角面，不过我们在代码中兼容一下比较稳妥
、旋转平移等变换
物体全部导入进去，剩下来的任务就是进行变换了，首先我们分析一下有哪些动画效果
因为我们模拟的是一个宇宙，文字就像是星球一样，有公转和自转；还有就是我们导入的文件都是基于点的，所以我们还需要把它们进行平移操作
先上核心代码

 =   自转的角度

  = 
  = 

 公转相关数据
  =     是全局的时间
  =   



      
            
            
            
            
         
            
                
                
                
                  是偏移的位置
            
                
                
                
                
            
        
    


一眼望去模型矩阵里面有三个矩阵，为什么有三个呢，它们的顺序有什么要求么？因为矩阵不满足交换率，所以我们矩阵的平移和旋转的顺序十分重要，先平移再旋转和先旋转再平移有如下的差异
下面图片来源于网络
先旋转后平移：
先平移后旋转：
从图中明显看出来先旋转后平移是自转，而先平移后旋转是公转
所以我们矩阵的顺序一定是 公转 × 平移 × 自转 × 顶点信息右乘
具体矩阵为何这样写可见上一篇矩阵入门文章
这样一个文字的大行星就形成啦
、装饰星星
光秃秃的几个文字肯定不够，所以我们还需要一点点缀，就用几个点当作星星，非常简单
注意默认渲染是方形的，所以我们得在 中加工处理一下
  

  {
      = _    计算距离
       {
        _ =         
    }  {
          丢弃
    }
}

结语
需要关注的是这里我用了另外一对，此时就涉及到了关于是用多个 还是在同一个中使用 ，这两者性能如何，有什么区别，这里将放在下一篇相关优化中去说。
本文就到这里啦，有问题和建议的小伙伴欢迎留言一起讨论 今天，我和同学一起开发一个软件的时候，想弄一个开源服务器来实现我们软件的通讯聊天，但是由于网上教程的不够详细和大部分教程都是转账同一个博客的博文，这样对于我们一些学习者来说就会导致出现很多的错误而又要花大量的时间来。这样的结果令人很烦，我就是这样，所以，今天我把我搭建的详细步骤和说明给大家看一下。
 前提条件：我们在腾讯服务器上已经安装好了数据库。因为下面的开源服务器的安装使用的不是自带的数据库。
 环境下载安装腾讯云服务器上没有，要自己下载安装下载地址：
下载好后，默认安装完成就了。
然后我们开始下载的压缩包或安装包，我下的是安装包。下载地址：=___   。
接下我们开始安装，点击下载好的安装包。安装步骤如下
 
 
 
 

 这里的域就是你要配置服务器的名字，不要有空格，最好字母名字。不然出现了错误报错。

这里我用的是标准数据库连接，网上的教程都是第二个。
 
这里要说一下，我们在软件出现的默认数据库中。要填写自己服务器的，然后
要填写你所要接入的数据库名字，务必注意。用户名就是数据库名字，密码是数据库密码。

这里默认下一步初始设置就行。

这里随你自己了，记住就好，待会登陆用。点击下一步，安装完成，登陆管理页面。
用户为，密码就是你刚设置的。登陆完就是如下。


相关推荐
【腾讯云的种玩法】、、服务器虚拟主机配置
【腾讯云的种玩法】服务器配置系列一服务器的配置
高性能高稳定云服务器作者简介： 薛伟， 腾讯专家工程师。

 引言
距离笔者上次发文章已经过去两年多的时间了，两年的时间对于一个团队和一个产品来说确实不算短了。在过去的数年中，团队一直聚焦在精准推荐，特别是效果广告推荐上，持续耕耘技术，和产品一同成长。在年和年两次作为项目联合团队成员获得了公司年度大奖年广点通项目团队，年社交效果广告项目团队，在年作为联合团队成员获得了公司级的技术突破金奖效果广告实践中的全流程实时计算框架体系。
技术钻研如逆水行舟，不进则退。公司的广告业务发展非常迅猛，有目共睹，激烈的外部竞争和客户越来越高的期望，都要求我们的技术不断进步；与此同时，我们也的确在生产实践中遇到了不少的技术问题和挑战，这些都促使我们在技术上不断的尝试突破。经过两年多时间的技术钻研和应用实践，同发表上一篇文章时的技术状态相比，团队和项目在技术架构和一些关键技术点上都向前迈进了一大步。我们打算通过几篇文章做一个简单的经验分享，这些文章会按照在线学习和深度学习两个技术方向做一个大致的划分。笔者会以两篇文章作为整个系列的开头，团队的同学会陆续有文章发表来不断充实这个系列。作为开篇，笔者的文章会更偏向于问题分析和技术思路阐述，主要是文字内容，更多的技术细节会放在后续的文章中来介绍。  
 从模型快速更新到在线学习
从某种意义上来说，本文是笔者前文的后继。在前文中，我们已经分析了类似效果广告点击率预估这种场景下的模型快速更新的需求，给出了在当时看来比较稳妥的一套技术方案。这套方案本质上仍然是离线训练，其中训练数据是流式生成的，以分钟级延迟落地上；模型训练的算法跑在上，利用的内存计算能力使离线模型训练的速度提升一个数量级；待模型训练结束后，立即将得到的模型推送到实时推荐引擎上，完成模型的部署。
如今，模型快速更新的需求仍在，这已经成为广告精准推荐领域内的一个共识，感兴趣的同学应该能够在上找到不少推荐方面的文章或多或少的共享这一个观点。在过去两年中，我们从数据，算法和系统三个方面对上面这套方案做了持续的改进，在架构不变的情况下挖掘其潜力，持续地支持了产品效果的提升。但是我们也越来越深刻地感受到这套方案的局限性，简单列举如下：

数据先落地，然后再从加载，存储开销较大且随着训练数据量的增加而增加。
训练数据需要加载到集群各节点的内存中供模型训练迭代使用，内存需求量大，且随着训练数据量的增加而增加。这不仅对集群机器型号的要求高，也在一定程度上限制了方案的伸缩性。
随着训练数据量和特征的增加，模型尺寸会越来越大，训练过程中的通信开销和计算开销都会增加，这也限制了方案的伸缩性，使得模型的更新速度变得不那么迅速了。

上述局限性已经严重制约了点击率预估模型的进一步优化，要求我们在技术上做出突破。
随着人类积累的数据量越来越大，种类越来越多，蕴含的商业价值越来越高，大数据成为了一个很热的技术和商业话题。大数据分析和挖掘是大数据变现的核心环节，因此也受到了很多的关注。若从大数据的视角来看，效果广告是公认的典型的大数据应用之一，而效果广告点击率预估则是典型的大数据分析和挖掘，我们需要在遇到瓶颈时升级我们的方案来持续释放大数据中蕴含的效果提升潜力。
近年来离线大规模机器学习技术在大模型训练方面进展颇多。出现了像和这样的系统和平台，支持超大规模训练数据集和超大模型训练，它们部分地解决了上面提到的一些局限性。但是从使用角度来看，它们毕竟还都是离线训练，如何在数据量持续增加的情况下做到快速乃至实时的模型更新，这并非它们的首要技术目标，因此也就无法完全解决我们面对的挑战。
思虑至此，我们很自然地就会选择走另一个方向——在线学习 。实际上，正如末尾提到的那样，我们在研发上一代方案之初便认识到，线上模型更新  是未来很有前途的模型快速更新方案，这方面的尝试我们也一直在做，并在年成功应用于线上生产系统，带来了显著的效果提升。
在线学习并不是一个新概念，相对于有限的存储和计算资源来说，数据量太大的问题其实一直都存在，人们很早就在思考在线算法 和机器学习的结合，也就是在线学习。同传统的离线批处理式的机器学习相比，在线学习的最大特点在于数据的到来和用于模型训练都是在线进行的，模型训练程序无法一次性拿到和存储所有的训练数据，对训练数据的访问只能是顺序的。因此，在线训练是一种流水线的处理方式，也就无需使用巨大的存储空间，而且计算的延迟和通信的延迟可以彼此有效的掩盖，天生具有良好的伸缩性，可以支持超大的数据量和模型。从某种意义上来说，如果我们可以用在线学习的方法来解一个机器学习问题，我们就大大抬高了处理问题规模的天花板，而这种天花板的升高带来的好处是显而易见的。
在线学习的理念虽然出现的较早，但是其受到广泛关注并在较多的领域取得成功应用还是最近十年的事情，这其实也是得益于数据量和模型规模的增长，或者说，大数据的发展。一方面，面对前面列出的那些问题，大家不约而同地选择了在线学习的方案来应对，另一方面，大数据的无处不在也使得在线学习的优势可以得到充分的发挥。
值得指出的是，在线学习只是一个机器学习的范式，并不局限于特定的问题，模型或者算法。因为有实际的工业需求在，这个领域的研究发展很快，不断有新的模型和算法被提出。对在线学习做完整的综述显然超出了本文乃至本系列文章的范围。本文要分享的是我们在解决生产问题过程中所做的一些思考和经验摘要。感兴趣的同学可以继续看我们的后续文章和参考文献。
 技术方案和应用效果
图 在线学习技术方案架构简图
 架构
读到这里，其实在线学习的整个方案架构已经比较明确了，如图所示，类似的图很多见。流式训练数据生成的环节还会继续保留，原有的流式训练数据生成拓扑后面会直接接一个流式模型更新的拓扑，训练数据不是先落地然后再从加载，而是直接用于模型更新。架构中会有一个逻辑上的参数服务器用来存放模型，不同的在线学习模型和算法需要在参数服务器和流式训练拓扑中编写代码来实现特定于该模型和算法的更新方法。随着训练数据生成拓扑和模型更新拓扑的运行，参数服务器中存放的模型会得到持续不断的更新。与此同时，这样的更新也会同步给实时推荐引擎，从而立即用于线上的推荐。
可以看到，从事件点击曝光转化等等发生，到形成一条日志，再到形成一条训练数据，再到模型更新，再到用于线上推荐，整个过程都是流式的，从头到尾的平均延迟可以做到秒级。与此同时，无论是训练数据生成和模型更新两个拓扑，还是参数服务器，都具有良好的伸缩性，可以支持大规模的模型和大数据流。
 模型和算法考量
正如前面提到的，可以划到在线学习这个范式里面的模型和算法有很多，而且还在不断增加。比较著名的有和，这两个都是工业界有过大规模应用的，自然是被竞相效仿的对象。关于它们的原理和实现的细节可以阅读原始文献，本系列的后续文章也会有介绍。
依个人浅见仅供参考，这两个模型和算法代表了两大类实现在线学习的思路，这里我们粗糙地借用一下的分类法。一类是所谓的对抗学习模型 ，可归入此类，这类模型和算法的目标是在在线的场景下最小化“后悔”。这个思路也常被称作是在线随机优化  。另一类是所谓的统计学习模型  ，按照的说法，这类模型和算法的目标是最小化期望“风险”。然而，个人认为这个思路放到贝叶斯推理 的框架下才能释放其最大价值。实际上，适用于各类概率图模型  的贝叶斯推理算法有很多，其中不乏适用于在线学习场景的，就是一个例子。无论是在线随机优化，还是贝叶斯推理，背后都有比较完善的理论支持，且有大量的文献。作为初窥门径的实用主义者，笔者在这里斗胆提到它们，只是为了分享寻找，设计和选择在线学习模型和算法时的一点思路。
 系统考量
架构，模型和算法，最后还是要系统来承载。数据平台部经过多年的技术积累，手边可堪一用的系统颇多，当我们着手实现上述架构的时候，更多的是从现有系统中挑选和改进，而不是从头来。
先来看参数服务器，在线学习需要怎样的参数服务器呢？第一，其存储结构应该可以包容多种算法模型；第二，应该性能优异且支持平行扩展，从而能够容纳大模型并对其计算做负载均衡；第三，应该支持小时不间断运行，高度可靠，有充分的容错机制；第四，应该可以方便地扩展接口，实现特定于算法的逻辑功能。目前开源社区有很多机器学习平台都有自己的参数服务器，然而完全满足上述四条需求的并不多，特别是对高可靠运营的需求，盖因社区的参数服务器大多针对离线模型训练的场景，而非不间断在线学习的场景。数平有一个经过多年大强度运营考验的全内存分布式系统——完全满足上面的四个要求，所以我们选择在的基础之上来开发参数服务器，通过扩展的功能来支持各种在线学习的模型和算法。
再来看前端模型更新所用的系统，如图所示，这是一个流式的处理过程，数平的实时计算平台里面的就是干这个的，此外还有 可以实现同样的处理功能，它们都是久经考验的可靠系统。在实际生产中我们选择了，道理很简单，因为上游的流式训练数据生成一直用的是，继续使用比较方便。我们在上为每种模型和算法实现了专门的拓扑，支持从零训练一个模型并且一直更新下去的全流程，以及从尺寸、预热历史长度、特定于算法的参数，到模型质量实时监控的全套配置，系统的伸缩性和容错也是久经考验的。后续文章会有详述。
最后来看在线学习与实时推荐引擎的对接。此前我们采用的是模型文件推送模型动态加载的机制来将新训练出来的模型推送到线上。当模型变成在线学习之后，这个推送的频率可以更高。目前线上的生产系统仍然还是走这套机制。然而，最终的方案将是随着模型更新实时地推送模型到推荐引擎，为此我们将引入可靠的消息中间件来完成这最后一公里的推送，最终贯通全流程。这一实现将在不远的将来用于线上生产系统。
值得在本节末尾再提一句的是，整个系统架构的升级不仅抬高了处理问题规模的天花板，也大大降低了模型训练端到端的资源消耗。在数据量，特征量均有显著增加的情况下，实际使用的机器资源有成倍的减少，省出来的资源可以拿来支持压力越来越大的在线预测，可谓是雪中送炭。
 生产运营考量
从离线模型训练发展到在线学习，这个改变的影响是深远的。天花板抬高了之后，模型会变得越来越复杂，越来越准，反应越来越敏捷，也就会越来越敏感。端到端流式处理的数据流中，任何一个环节的非正常波动或者故障，都有可能给模型训练或模型预测造成干扰，进而导致点击率预估效果的波动，甚至直接影响实时的现网收入。在广告收入快速增长的今天，剧烈的波动是要尽力避免的。面对各种可能的波动原因，我们需要从全流程的各个环节着手应对。
首先来看模型和算法，实际上实用的在线学习模型和算法，不论归属于哪一类，一般都会在原理上提供一些手段来应对训练数据中的波动的。例如，支持自适应学习率和正则化，这都有助于抑制模型的剧烈波动。使用贝叶斯推理的概率模型更是可以利用适当的先验设定和大数据量来抑制模型的剧烈波动。工业界有一些做法是通过引入较粗粒度的历史统计量作为特征，或者直接将其用作平滑手段。这种方法我们使用的不多，一方面是因为我们用的模型的原始特征相对较多，交叉维度更多，计算历史统计量的开销也不低，而且不恰当的设定可能反而不利于发挥模型的拟合能力；另一方面是因为历史统计量本身也面临波动的影响，我们更希望依托模型和算法本身的能力。
再来看系统，正如前面提到的，无论是参数服务器、还是实时推荐引擎，都提供了久经考验的容错和故障恢复机制。然而对于叠加其上的在线学习逻辑来说，上述机制只是基础保障。我们规划并实现了一些应用层的容错和故障恢复机制作为补充，后续文章会有介绍。
除此之外，我们也在全数据流监控上下了一番功夫。模型、算法和系统的耐受力毕竟是有限的，快速准确的捕捉到波动和故障的源头对于控制和减少损失十分重要。目前，日志数据量、训练数据量、各主要特征的分布指标、模型实时质量指标、线上效果指标等均在监控之列，关键指标还配置有告警。
 应用效果
截止年年末，在线学习的模型和算法已经覆盖了广点通超过一半的流量，在年末的效果放量中取得了 的提升，部分重点广告位取得了以上的提升，有力地证明了在线学习用于效果广告点击率预估的实用价值。
 展望
从模型快速更新到模型在线学习，这是一个自然的发展过程。技术天花板抬高了，以前无法处理的大数据量、大特征量和大模型，现在都可以有效处理而不会导致模型更新变慢，这对效果提升的好处是显而易见的。我们已经实现了这样一套具有良好伸缩性和可靠性的在线学习系统，并且在生产实践中取得成功应用。纵观业界，不少公司也在生产中使用了各种在线学习的模型和算法。同在线学习的广阔空间相比，目前我们的实践还是很初级的，未来我们一方面会去继续发挥在线学习的优势，拥抱更多的数据和特征，另一方面还会尝试更为复杂的模型和算法。
从业务需求和痛点出发寻找技术思路，这是我们一贯的做法。在线学习解决了我们遇到的一些痛点，还有其他的痛点，所以，本系列后续文章除了继续介绍我们在在线学习方面的实践细节之外，还会谈一谈我们把深度学习应用于效果广告点击率预估的工作。

参考文献
 快速模型更新及其在腾讯精准推荐中的应用
                         ’                     
                                   
                   
                                            
     ñ                  ’     
                    
   
 腾讯实时计算平台系列之一：初识
【系列系统介绍】分布式高可靠消息中间件
 效果广告点击率预估近期实践：深度学习


相关推荐
效果广告点击率预估近期实践：深度学习
人人都可以做深度学习应用：入门篇上导语 大家一起来学习 

安装
系统还是之前 
  
 创建源
  

= 
=
=
=
=

安装
  
  
  
测试
   
 会显示  
部署程序
案例还是用 之前的  的示例项目 详情参考《 部署  实践》
拷贝到另一个文件夹
   
创建

备注 这里有两个坑
因为程序是基于 所以必须用 我开始创建的时候 用的当容器运行的时候 就变成 这时候用      可以显示容器运行的时候输出的日志 然后修正 基于就了
镜像里面监听   不然在 外部访问出现错误    
 如下
 
  
  
 
 
 
    
构建
    
 不要漏了后面一个点
构建完成后就可以用   查看了

运行容器
       
指定容器名称指定端口资源映射 还可以指定磁盘映射
使用    查看运行的容器
显示在运行中
访问一下 我们部署的 程序

配置

这次映射的端口
重启  
  
成果
外部浏览器访问结果 该页面我特别在上面加一个区分旧项目


相关推荐  使用指南 一—— 基本操作 【腾讯云的种玩法】 部署  实践 如何构建镜像是否会有这样的场景：在有需要测试数据的时候，你不知如何生成一些已包含测试数据的文件；或者你是临时需要一个小的程序，可以让你生成不同大小的文件比如大于少于，不需要从网络上去搜寻查找如何生成，这里有一些简单的方法帮你偷懒。
当你不需要关心随机文件的内容，只需一个固定大小的文件

、  等系统中指令，可以产生指定大小的文件，而上则没有例子：   

可以用指令，是一个特别的文件描述符可以通过它返回值例子： = = = =产生  字节的文件，此方法生成随机文件的好处在于效率高产生文件大概创建的文件大小精确到字节坏处也有使用字符来填充文件内容，文件统计时没有行  为


当你不需要关心随机文件的内容，但期望测试文件能有统计的行
 将改为，是下的随机数生成器
关于跟两者的区别就不在此详细讨论，大概就是，前者是不受系统的限制，即使没有足够的它也能通过随机数生成器产生足够的输出值；而后者如果用在上，它不能被或者 中断，如果的值较大时，产生的随机值不足而长期占用。虽然说产生的随机数会更随机些，但与混用还是建议用效率更高。
缺点跟比当然是效率会更低些了，生成个的文件需要秒左右，而且文件并没有可读的内容，一般的情况基本上是满足了。
漏了说句，是与都支持的指令。
当你关心文件的随机内容行数，而不关心内容是否有所重复
这里的思路就是找一个参照文件比如说行，将文件重新定向到新的文件，再覆盖保存，外加一个循环。为循环次数，产生的文件行为
 例子假设先建立一个文件，里面含有 和 两行   {}           
由于是阶乘，=左右已经是行，效率会下降地比较厉害
当你关心随机文件的内容，而不想出现重复内容行情况
这种情况下系统的指令应该是不能满足了，或者可以通过操作系统的指令写一大串脚本也可以达到，但不建议这么做，因为可读性和维护性考虑，你应该要引入或者类的脚本语言帮忙了但还是要借助些系统的东西来帮忙
思路：里面有记录一些单词，一共行，每行一个单词 可以从里面挑选一些作为文件的内容 加循环达到我们想要的随机文件要求
举例：  =  =          
为随机文件需要的行数，为从中读取的单词，虽说组合成一句的命令，还是可以读懂的；从标准输入中重复读取个单词，写入到列表中，然后再通过空格连接内容写入到标准输出文件中
这样基本很少会有重复的行了，而且生成的效率与其他方法对比还是可以的，秒生成文件。欢迎大家讨论。
参考：
 的  官方文档  的   

相关推荐 系统云服务器运维手册前言
“在一次正常的活动促销之后，客服开始陆续反馈有用户反应在抢标的时候打不开网页或者 ，在打开的时候标的就已经被抢光了。
刚开始没有特别的上心，觉得抢标不就是这样吗，抢小米手机的时候不也是这样吗？
随着活动继续推进，有更多的用户强烈抗议，用户领了加息券或者抵现券之后抢不上标的，认为是平台作假故意不让他们使用以达到节省资源。
分析过程
以前也会有陆续的用户反馈不减少的情况，给客户以小米抢手机为例子解释就过去了，这次用户反馈太过强烈，才让我们重视了起来。
我们前端一共有三款产品：、官网和 ，其中  使用量最大，官网其次， 平时使用量极少但是做活动期间流量会暴增活动一般都是  游戏居多， 也便于推广营销。
前端的三款产品都是分别使用  负载到后端的两台  服务器中如下图，这次用户反馈基本在  和  端，所以重点观察这四台服务器。

首先怀疑网络带宽是否被涌满，找到网络工程师通过工具来监控，在抢标的时候带宽最高使用率只有  左右，随排除之。
再次怀疑  服务器是否抗不住了，使用  命令查看官网负载的两台服务器，在抢标的瞬间会飙到  左右，抢标后也慢慢的恢复了正常， 两台服务器高峰到 ，随后也恢复正常。
跟踪  服务器业务日志，发现在数据库更新层报请求不到新的数据库连接或者数据库连接已经用完，认为是数据库的最大连接数太小，于是调整  数据库最大连接数为以往的  倍。
下次抢标的时候继续观察业务日志，发现已经不报数据库连接的相关错误了，但还是很多用户反馈抢标时候打不开页面。
继续跟踪  服务器，在抢标时使用命令 | | 查看  的连接数有  左右，随机查看  配置文件中设置的最大连接数为  默认的最大连接数为 。
原来抢标期间连接数已经到达最大连接数，很多用户在抢标的过程中已经获取不到  连接导致页面无响应或者  一直在等待中。于是调整  配置文件中的最大连接数为 。
在抢标过程中继续观察， 的连接数在抢标的时候仍然可以飙到  之间，根据客服反馈，仍然有很多用户反馈抢标的问题，但比之前稍微好一点，但是有零星的用户反馈已经抢到标的，最后又给回退了。
然后继续观察数据库服务器，使用  命令和   查看  主库和从库的各项负载吓一跳如下图， 服务器主库的各项指标均已经达到峰值，而从库几乎没有太大压力。

跟踪代码发现，三端的业务代码全部连接主库，从库只有后台的查询业务在使用，于是立刻启动改造。
将除在抢标过程中的查询外，其他页面或者业务的所有查询改造为查询从库，改造之后观察，发现主库的压力明显减少，从库的压力开始上来了。如下图：

根据客服的反馈，改造之后抢到标回退的问题几乎没有了，抢标过程中页面打不开或者打开慢的问题有一定的缓解但仍有部分用户反馈此问题。
根据上面各项目分析得出结果：

负载的两台服务器均已经达到处理的极限，需要配置更多的服务器来负载。
 主库的压力明显减少，但是从库的压力却上去了，需要将现在的一主一从一从改为一主多从的模式。
彻底解决这些问题，需要综合考虑平台的整体优化，如：业务优化去掉业务中热点、增加缓存、部分页面静态化可以使用雅虎和谷歌的前端优化规则，网上也有很多的测试网站可以评测等等。

当时根据这些情况写了一份优化的报告，见下文：
优化报告
背景
随着公司业务不断发展，业务量和用户量的激增，官网  也从最初的  到现在的 ， 活跃用户更是大幅增加。
因此对平台目前的技术架构提出了更大的挑战，特别是近期平台标源紧张的情况下，满标的时间更是越来越短，服务器的压力也越来越大。因此需要升级目前的系统架构，以支持更大的用户量和业务量。

用户访问示意图
目前平台面向用户的有三款产品面：平台官网、平台  和平台小网页，其中平台官网和平台  的压力比较大。
存在的问题
用户抢标的时候问题集中在以下几个方面：

网页或者  打不开。
网站或者  打开慢。
抢标过程中转账成功后，因为服务器负责压力大更新失败，再次退款。
数据库连接数用完，导致满标后添加投资记录失败，回退标的进度。

分析
通过对近期的服务器参数、并发量，以及系统日志等进行深入的分析得出：

平台官网、平台  抢标过程中服务器压力巨大，平台  问题更加突出，抢标高峰期间单台  服务器  最大连接数已经接近 ，接近  最大的处理能力。
数据库服务器压力巨大。

数据库压力主要在两个时期比较突出：

当平台做活动的时候，官网、小网页、 访问量巨增，导致数据查询量跟着巨增，当到达数据库处理极限时，就会表现出网站打开慢等问题。
当用户抢标的时候，用户抢标的压力又分为两个阶段：抢标前和抢标中。抢标前，因为满标速度很快，用户提前打开抢标页面不断刷新，这样数据库的查询压力会不断增大，如果抢标的用户量非常大，会导致在抢标之前将数据库连接数用完。抢标中，单次购买大概会涉及  张左右表进行更改查询，每个标的份额  万大概每次会有  人左右购买完成满标，以中间值  人计算，在几秒的时间内需要对数据更新  次仅仅是更新，不包括查询 ，产生大量并发，可能会导致更新失败或者连接超时，从而影响到用户投标和系统正常满标。

解决方案
 服务器解决方案
单个用户访问  服务的示意图，如下：

目前网站和平台  均是采用了两台服务来做均衡负载，每台服务器中安装了  来做服务端接受处理，每台  最大可以处理大约  条连接。因此理论上目前网站或者  可以处理大于  个用户请求。
如果要支持同时  的请求，则需要  台  服务器来支持因此目前缺少  台  服务器。
升级服务器后的访问示意图，如下：

数据库解决方案
当前数据库的部署方案，如下图：


主从分离解决主库  的查询压力。目前平台官网、 均连接  主库导致主库压力倍增，把服务中的查询全部迁移到从数据库可以大量减轻主库的压力。
增加缓存服务器。当从库查询到达峰值的时候，也会影响主从的同步，从而影响交易，因此对用户经常使用的查询进行缓存以达到减少数据库的请求压力，需要新增三台缓存服务器搭建  集群。


其他优化

官网首页静态化，从  统计来分析，首页占比网站的整体访问量的  左右，对于首页不经常变动的数据通过静态化来处理，提升官网打开的流畅度。
 服务器的优化，开启  压缩，配置合理的链接数等。
去掉投资过程中的更新热点：标的进度表。每次投标成功或者失败都需要对标的进度表进行更新，多线程更新的时候就会出现乐观锁等问题。去掉过程中的更新，只在满标后将标的进度信息保存在标的进度表，优化投资过程中对数据库的压力。

服务器升级方案
平台最大的压力来自于数据库，需要将现在的一主一从，改为一主四从。官网小网页产生的大量查询，由虚  分发到三台从库，后台管理查询走另外的一个从库。
数据库需要新增三台服务器，数据库升级后的示意图如下：

通过增加缓存可以减少数据库的压力，除了需要新增两台大内存的缓存服务器，还需要新增三台  服务器分解用户访问请求。

 需要新增两台服务器
在抢标过程中  服务器压力最大，需要新增两台服务器，配置完成后的示意图如下：

官网需要新增一台服务器
官网在抢标过程也有一定的压力，需要新增一条服务器，完成后示意图如下：

总合计之后需要购置  台服务器，其中有两台要求有大内存 以上，所有优化方案投产后，问题解决，抢标无忧！

作者：张强纯洁的微笑，曾经先后在互联网金融、第三方支付公司担任高级  工程师、架构师、技术经理、技术负责人等职务。在互联网金融工作期间，从零参与公司技术平台建设，组织平台进行过四次大架构升级。目前在一家第三方支付公司做架构师，负责支付公司大数据平台建设。
编辑：陶家龙、孙淑娟出处： 技术栈 微信公众号 、本文作者：  原文出处：社区 未经同意，禁止转载   

做页面，需要测试其性能。我们不能认为用浏览器打开该网页得到的数据就算它线上的性能，因为的环境，其性能和浏览器还是有所差距的。最近一直做相关工作，积累的一些小经验，这里分享出来。
打点
统计线上页面的性能，本质上还是打点上报。打的点一般参考属性。一般页面最开始给一个初始绝对时间点作为参考，其余的点减去这个初始时间就是页面渲染的相对时间了。如果没有客户端给初始时间点，可以用作为初始时间点。我这里根据上报情况看，和客户端给的绝对初始时间差距并不大。另外，如果页面有重定向，参数就不为，将这个参数值作为初始时间应该更加合理。文档的加载时间：

  
这个时间点并不太稳定，如果需要统计执行的时间点，还是自己打点比较好。更加详细的打点属性可以参考这篇文章
性能测试
由于是页面的性能测试，我们不可避免的无法进行白盒测试。如果需要测试页面滚动的、、内存使用情况该怎么办嗯？只能借助一些小工具来完成本地测试。这里列出一些多半是针对，因为不越狱就很难获取相关信息：
渲染的第一印象
要分析一个页面的卡不卡，可以先看看现在的渲染情况。打开设置开发者选项呈现模式柱形图。可以看到屏幕上出现杂乱柱状图，靠近底部的绿色的线代表，也就是每秒帧的阈值，如果一个柱状条很高很高，上部的黄色部分很小，就说明这里有几帧被丢掉了。因为没有在规定的时间内提交。
打开知乎，随便滚动一下。发现一柱擎天，说明有一帧丢掉了。 

这里简单说下各种颜色的柱状条代表什么。更加详细的可以的官方文档

绿色： 你的主线程的运行时间，在这个时间里，你的业务代码正在飞速转动
深蓝色：线程的方法的执行时间，最终生成。
浅蓝色：加载图片资源的时间。实际上是将内存中的位图资源转换到显存中的时间。如果你非要将一张的图片渲染到大小，这段时间就会变长。
红色： 将转换成原生渲染命令，并且发送到一个队列里。如果深蓝色的过程很长，这一部分也势必很长。不过，可以缓存，渲染命令不能缓存。
黄色：时间。完成了上面的红色时间，将所有渲染命令 丢到队列里面就直接转到下一帧的渲染任务上去了，如果不够快，那么这个队列就会满，如果队列满了，就会等待入队渲染命令。黄色区域就是的等待时间。如果像上图一样，一直存在时间。说明的渲染是滞后的。不过没关系，你看到的页面同样是流畅的。的渲染数据
上面的柱状图只能看到一个直观的印象，如果你想获取这些柱状图的数据，需要安装开发包。 安装后，插上手机，在终端运行命令：


    _ 
具体的参照这篇文章
页面的流畅性
要保证页面滚动和动画的流畅，可能第一想到的指标是，没错，但是还有另外一个衍生的指标也很重要：帧方差。帧方差就是序列的方差，越小，说明页面滚动越平滑。
黑盒测量
以下的手机可以用软件来进行测试。非常方便，每秒统计一次，直接生成以待分析。或者用工具来测试：
  
   =      
将改变将改变监控测试时间。 然后打开你的，出发动画和滚动，直到测试结束。
这个时候本地文件中将出现文件，点开看一看可以发现像时间线一样的视图数据。需要提取数据用命令：

    |   \      
然后进行后续的分析。
数据分析
假设现在拿到了第一手，需要进行加工处理。一开始着手这样工作的时候真是没少走弯路。主要是：

本以为用分分钟搞定的数据处理任务，但花了数倍的时间还未搞定。
缺少养眼的统计图表模板，画出来的统计图表像倒退了年的产品。

这里安利一个统计工具 语言。做毕设的时候浅度用过。主要是你想要某种统计效果时候，它并不耽误你的时间。比如：以分析的框架时间为例：读取数据：

 = = =
查看平均值：


看看框架时间的分布：

 = =

！居然有些用户框架时间超过了秒，这怎么能忍？统计一下！
 
   
可见的用户的框架时间高于，太慢了。能不能统计一下，是不是和的版本有关呢？绘图按照分类一下：

 = = =  =  = 
很明显，可以去调研下有颜色的这三个版本，它们比较慢。

更多的是一个方便的表单数据处理工具，用来分片、筛选、算总数、平均、方差等等常用的操作实在太方便了。伴随着你的思考，几条命令就可以实现了。用熟悉了是很节省时间的事情。



原文出处：社区 未经同意，禁止转载作为云计算服务的重要组成部分，云服务器以其简单高效、安全可靠、弹性扩展的特性成为核心力量，构建了包括计算、网络、存储在内的综合服务平台。以腾讯云服务器为例，不仅提供了镜像复制、快照备份等功能，还可以按实际使用计算费用。借此，用户可以在数分钟内获取并配置腾讯云服务器计算实例。值得一提的是，腾讯云服务器对于前沿的高性能计算也有较好的支持。今年初，腾讯云推出了高性能异构计算基础设施云服务。

配置腾讯云服务器只需这几步图片来自
腾讯云服务器在云中提供可扩展的计算容量，避免了使用传统服务器时需要预估资源用量及前期投入的情况，用户可以在短时间内快速启动任意数量的云服务器并即时部署应用程序。腾讯云服务器支持用户自定义的资源包括、内存、硬盘、网络、安全等，并且支持在访问量和负载等需求发生变化时进行调整。
腾讯云服务器搭载的云硬盘拥有三副本专业存储策略，可以消除单点故障，简化了传统运维工作中为保障数据高可靠带来的额外工作量，节约额外的投入成本。同时，其借助网络虚拟化技术和网卡绑定技术确保了网络的高可用性。另一方面，安全组和网络设置则能控制进出实例和子网的网络入出站流量并进行安全过滤。
用户可以使用同一个镜像启动不同类型的实例。实例类型决定了用于实例的主机硬件配置。每个实例类型提供不同的计算和存储能力，用户可以基于需要提供的服务规模而选择实例计算能力、存储空间和网络访问方式。实例启动后，用户即可像使用传统计算机一样使用，对启动的实例有完全的控制权。配置方面，腾讯云服务器搭载了英特尔下一代至强处理器。
据了解，腾讯云服务器可以将实例放在多个位置，位置由区域和可用区构成。可用区是专用于隔离其他可用区内故障的独立位置，可向相同区域中的其他可用区提供低延迟的低价网络连接。通过启动独立可用区内的实例，用户可以保护应用程序不受单一位置故障的影响。区域由一个或多个可用区组成，其地理位置分散分布于独立的地理区域或国家区域。
安全及稳定性方面，云监控可以显示资源利用情况、操作性能和整体需求模式包括利用率、磁盘读取和写入以及网络流量等度量值。云监控能够汇集并存储监控数据，这些数据通过服务和访问，便于用户进行分配应用程序访问流量负载均衡，以及实例弹性扩缩容弹性伸缩等操作。
做好初始配置 腾讯云服务器铺好路
使用腾讯云服务器之前，用户需要进行初始配置，首先就是注册腾讯云账号。注册完成后，部分产品需要通过资质认证方可使用如按量计费类型云服务器、、等，通过资质认证后默认可以使用腾讯云所有服务特定需要单独申请开通的除外。此外，用户还可以根据自身需求创建密钥、私有网络、安全组、云密钥等功能。

进入用户中心
准备工作做好后，我们以系统云服务器为例介绍一下配置及操作流程。用户要根据所在地理位置选择地域，云服务器与访问客户端距离越近，越能获得较小的访问时延和较高的访问速度。需要注意的是，不同地域之间的云服务器不能通过内网互相通信通信需经过公网，收费，相同地域下的云服务器可以通过内网相互通信内网通信不收费。
配置方面，腾讯云推荐了两种配置：入门型，核内存，带宽选择或使用流量，适合个人博客等小型网站基础型，核内存，带宽选择，适合企业官网等简单的应用。当然，用户也可依据所需灵活配置方案。
创建云服务器时，用户可选择包年包月或按量付费的计费模式，两种付费模式一个按整月计算、一个按实际使用的秒数计算。如果是需要多台云服务器，那么不同可用区则可以达到容灾效果。根据底层硬件的不同，腾讯云服务器提供了系列标准型、高型、内存型和系列标准型、高型、内存型、计算型两种不同的实例系列。对于刚开始使用腾讯云的用户，可以选择公共镜像，其中包含正版操作系统，后续运行环境自行搭建。操作系统选 ，并根据需要挑选版本。至于硬盘，腾讯云提供了云硬盘和本地硬盘两种类型，前者采用一盘三备的分布式存储方式，后者则时延较低，但存在单点丢失风险。

选择实例规格

挑选版本
网络方面，基础网络适合新手用户，同一用户的云服务器内网互通，私有网络适合更高阶的用户，不同私有网络间逻辑隔离。最后，确定服务器数量和购买时长，并选择安全组，注意确保登录端口开放，完成支付后即可进入控制台查收云服务器。

选择网络
登录阶段，只要购买了公网带宽流量的腾讯云服务器，就可以从本地机器登录云服务器。在本地机器上，点击【开始】【运行】，输入命令可打开远程桌面连接对话框。在输入框输入服务器的公网登录云服务器控制台可查看云服务器的公网点击【连接】，在新打开的界面中输入帐号和站内信中的初始密码或修改后密码即可登录。无论是否购买了公网带宽流量及本地操作系统，云服务器均可从控制台登录。在云服务器列表的操作列，点击【登录】按钮可通过连接至云服务器。

可通过连接至云服务器

通过在左上角发送命令进入系统登录界面
腾讯云服务器环境配置 和为例
使用过程中，用户需要根据服务器用途进行相应配置。当然，也可以通过获取服务市场的镜像来启动云服务器，很多服务市场镜像都集成了必要服务，免除了安装配置工作。下面介绍几种环境下基本的软件安装和环境配置，用户可以根据需要自行选择是否安装。以  环境为例，安装配置和时，先点击底部栏【服务器管理器】【角色】，点击【添加角色】按钮。此时系统可能会要求重启，按系统指示操作

添加角色

选择【服务器角色】【服务器】

选择功能，勾选需要的角色服务
选择完成后点击【下一步】，确认信息后点击【安装】按钮，等待安装结束后，通过在本地浏览器访问云服务器的公网来验证安装是否成功。

安装验证
通过【信息服务管理器】【网站】【 】【高级设置】【物理路径】来设置网站根目录默认为：

设置网站根目录
由于角色服务已选择，此时可以开始基于的网站开发了。使用进行测试，注意文件存放目录必须为网站根目录下：

测试

调试成功
 在腾讯云服务器平台的应用
通常情况下，系统经常使用 数据库，但由于 属于收费产品需要用户自行授权。以为例，首先下载安装包运行安装程序，选择典型安装方式。

选择典型安装方式

选择【自定义安装】，选择服务器类型、数据库类型、安装路径、链接数、端口、字符集

步骤如图所示

步骤如图所示

步骤如图所示

步骤如图所示

步骤如图所示

步骤如图所示

设置运行方式建议两种都选择上以便使用命令行管理

设置密码

完成配置，进行安装

通过设置的密码在命令行下登录
不同使用规模下 腾讯云服务器的方案
总体来说，对于小型应用或网站，通常在初始阶段访问量会维持在较低水平。用户可以从购置一台较低配置的服务器开始，将应用程序代码、配置文件、静态文件、数据库和其他资源全部部署在这台服务器上。腾讯云服务市场提供种类丰富的镜像、应用软件及运维工具，按需获取。

应用或网站方案
对于高并发高安全应用架构，弹性计算能在访问量增加时快速拓展，以便用户在控制台调整云服务器配置、内存、磁盘容量、带宽，或者增加云服务器数量并搭配负载均衡创建流量分发的横向扩展系统。

海量图片视频等大文件流媒体应用
而在用户经常读取大数据场景下，可能会成为云服务器瓶颈。此时，只需将静态文件添加至对象存储服务中，结合内容分发网络的回源能力及负载均衡，实现海量存储、高效分发、极速网络，减少用户访问等待时间，克服经常读取大数据场景下的瓶颈。可以看到，针对任意规模的使用场景，腾讯云服务器均有相对应的解决方案。原文链接：商业转载请联系腾讯  获得授权，非商业转载请注明出处。

一、项目背景
、 高价值 
龙之谷 ，一款优秀的端游移植到手游平台，凭借的丰富的游戏内容和优秀的游戏品质，公测首日便在畅销榜登顶，取得了巨大的成功。
游戏内容不仅继承了端游的内容，还根据手游操作方式以及平台特性进行了改进，使之更适合移动用户操作，界面分部也更加合理。
、初期兼容性问题较多
龙之谷与其他游戏产品一样，版本初期暴露的兼容性问题很多，类似无法安装以及必现的  等致命问题多次出现外，还存在着大量  错位、资源加载异常、屏幕分辨率适应差等严重级别的兼容性问题。
二、定制测试方案
游戏品质方面龙之谷将测试划分做到了极致，从多个角度出发将各项指标都进行专业测试，其中  平台负责支持了兼容性测试部分，为了保证兼容性方面的质量从轻测版本到运营上线做了  余次全量人工兼容测试以及上百次的自动化测试，目的就是保证产品在兼容性方面的质量。
、个性化用例
随着内容不断丰富和完善，我们也针对性的制定个性化的用例，进行某一模块及机型的测试，如将游戏功能部分进行拆分，例如：界面  测试与战斗系统测试分步进行，更是将社交功能如拍脸、分享单独进行测试，将兼容性测试化整为零，使得测试覆盖面更加完善。
低配机型测试
低配机型是兼容性问题的易发点，针对这个现象适配中心采取专项测试，对性能数据更加严格的监控并加入一部分极限测试，将更多有帮助的信息反馈给项目组。如今大环境下很多  产品已经放弃了对  以下内存设备的支持，但腾讯大盘数据显示三月  游戏机型中  以下内存机型仍存在  部，总用户占比 ，龙之谷考虑到这部分用户，针对低配机型反馈的问题进行了修复优化，最终完成了对低配设备用户的支持。
支持主流模拟器
目前重度手游产品有部分用户在  端使用模拟器进行游戏，龙之谷用户也不例外，也存在一批模拟器用户，适配中心也对模拟器测试进行了支持，虽然模拟器测试不属于常规手游兼容性测试支持范围，但为了更好扩展产品的支持度，搭建测试环境以及安排对模拟器原理和使用熟练人员，达成对几款主流模拟器的测试覆盖，通过测试结果来排查下问题原因，尽可能做到支持覆盖。
注：兼容性  未出现严重及以上问题
兼容性  出现非必现的严重及以上问题
最后一点就是在保证测试质量的前提下，尽快的完成测试。由于兼容性测试阶段属于版本测试流程的尾部，所以兼容性测试报告出现延迟极可能导致整个版本发布时间的变动，造成无法预估的损失。兼容测试团队在接受到任务提测后， 小时完成报告，报告内容包括整个测试流程各个设备的状态以及操作截图、性能日志和缺陷总结等，将完整的测试数据直观的展示给相关人员。
三、最终效果
在项目测试阶段，兼容性测试团队累积为《龙之谷手游》挖掘出了  个兼容性问题，其中  个致命级问题， 个严重问题，将  、无响应、 问题等揭露出来，提前进行修复或对问题进行评估，规避了适配风险，为游戏正式开启不删档运营，为用户良好的游戏环境提供了坚实的支持和保障。

关于  兼容性测试团队
腾讯  兼容性测试团队积累了  年的手游测试经验，旨在通过制定针对性的测试方案，精准选取目标机型，执行专业、完整的测试用例，来提前发现游戏版本的兼容性问题，针对性地做出修正和优化，来保障手游产品的质量。目前该团队已经支持所有腾讯在研和运营的手游项目。
服务目前已经对外开放，欢迎前来使用：
 兼容性测试团队期待与您交流！ ， ！   是 ， ，陈松等以及陈莉君老师团队正在致力于打造的一个开源项目，其宗旨在于便利的程序员，以最快最直接的方式，定位到系统里面一些的源头，以及一些性能瓶颈的原因。
这篇文章的内容涉及用  监控 电路板网络流量，观察负载均衡、和，以及用提高高网络负载情况的网络带宽。
项目组欢迎开源爱好者加入和参与。关于项目的最新演讲与文章：

【终南山内核问道】性能剖析的可视化
宋宝华：易用剖析器 是什么为什么以及怎么办

本案例演示观察到负载不均衡情况下，电路板测试网络带宽发挥不出来，并实施负载均衡后，看到网络带宽重大提高。
怎么烧录镜像
在  项目下载，用解压后得到，写入的卡卡拔出后，以读卡器插入电脑。
  = = 是你的卡在你电脑的路径
实验方法
开机后电路板的地址自动已经配置为，将电脑与电路板网线直连，保证本机可以访问的地址。登陆电路板可以用命令：
 
无密码。电路板上也集成了版本的，位于，运行方法：
 
浏览器端设置方法：

运行服务器：
 
电脑运行客户端每秒报一次网络带宽：
           |
 
均衡前
此时里面监控到严重的负载不均衡现象：

如果不做任何工作，均衡前电脑上上的周期：

浏览器的显示其中在严重地看热闹：

均衡后
在电路板运行负载均衡脚本
 
该负载均衡脚本内容如下，是关于和的配置：
   _
   _
  ___
   __
此时电脑上带宽报告：

此时命令状态：

此时端浏览器显示
我们看到的线迅速下跳不再看热闹了：

开始处理包：

稳定观察一段时间后两个在均衡处理网络：

再次恢复恶劣状态在电路板运行负载不均衡脚本就是默认状态
 
电脑上上的带宽再次严重下降：

均衡前后对比






带宽




均衡前
 忙 闲
 忙 闲



均衡后
 忙 忙
 忙 忙





文章来源于微信公众号  作者：
导语： 分群是精细化运营的常用方式。通过用户分群设置，将用户群切割成更细粒度，以推断并定位对关键事件指标有明显影响的因子。

数据分析对于运营来说是一个数据抽象的过程。现实情况是连续的、复杂的、互相影响的，而数据抽象的过程，就是将这些复杂多变的现实情况简化为数字量，搭建数据模型，计算相关因子，推断事件归因，并推进自身改进优化。
由于现实的复杂性，我们作为产品、运营或者数据分析师，在实际问题处理时，就需要做归因分析，需要屏蔽其他因子的干扰，因此我们常常使用用户分群。
分群后，我们的用户群可能简化为：

在每一个分群下，我们可以简化地对比某个因素对关键路径或者关键指标的影响因素。分群是手段，是工具，简单来说，分群分析就是通过聚类的方式，把相似的人群合并，考察同一事件或同一指标在不同人群上的表现，以推断并定位对该事件指标有明显影响的因子。
那么，用户分群与用户特征分析如何结合使用？接下来，我们举个案例进行说明

某电商，现在面临的问题是用户成交量较低，与投放推广的成本相比，较低。

这个问题，我们应该如何分析？
首先，我们想看看成交的这部分用户与大盘用户之间有什么区别。我们在用户中选出成交的用户，建立用户群对比大盘用户。
这里，我们需要使用腾讯移动分析自定义事件。设置“付款成功”为一个自定义事件，然后使用中的用户分群功能，将自定义事件中满足“付款成功”的用户群筛选出来，命名为“成交用户”；我们还可以设置一个叫做“高价值用户”的用户群，将“付款成功”且付款金额=的用户筛选出来。

图：此处定义高价值用户为成交单价元的用户
、用户分群分析
得到了三个用户群之后，我们使用数据分析工具，比如腾讯移动分析，对比这三个用户群特点间的区别。以下为三个用户群特征的对比：


从图中我们可以发现，大盘用户中男性较多，但实际成单与高价值用户中，都是女性偏多，且此部分用户对购物类、金融类的兴趣要明显高于大盘用户，表现出了较强的消费能力。
现在我们的问题是投放回报率较低，不符合预期。
那么，我们可以初步判断，可以优化的有以下两个方向：
、 用户引流渠道可能有问题，需要调整渠道引流策略，包括渠道选择、人群针对性优化等，引入与消费行为匹配的新用户群，提高销售量；
、 商品定位的调整：现有产品对男性的吸引力不足，导致大量大盘用户并没促成成单，这也是导致较低的另一方面原因，可能需要调整的包括商品品类、商品推荐等；
其中，第一种优化方式的见效周期较短，而第二种调整方式相对影响层面较大、周期较长。我们优先实践第一种优化方式，以调整渠道引入流量为主，优化引入人群的匹配程度，实现提高的目标。后续还需要斟酌是否需要优化产品定位，比如打造针对男性的亮点频道，进行产品改善迭代。
、渠道优化策略
那么，渠道应该如何做改善？我们先对单周渠道引入量的数据，进行初步评估。

图：成交率数值应用的是漏斗模型的渠道筛选功能此处渠道只列了支较典型的渠道样本数据，实际渠道分布更多
从图表上看，我们当前主要的流量渠道是渠道与渠道，而且渠道的留存率很高，可以认为是我们的优质渠道。
但从成交上看，我们认为渠道其实有很大的潜力，虽然现在的引入量较小，但与成交人群重合度较高，考虑到渠道的获客成本低于渠道，加大投放之后很可能会有一个不错的收益，能够实现我们提高的目标。
、渠道人群特征验证
我们对渠道人群进行特征分析，女性比例高达，其用户群对购物类的兴趣也高于大盘用户，与我们高价值人群特征匹配度较高。


现在渠道给我们带来的流量还比较小，但由于其渠道收益上比例较高，且其群体画像与我们高价值用户的特征吻合度高，表现出了很高的投放潜力。
我们的改善方法是：调整渠道投放的比例，减少渠道、渠道的投放，增强渠道的投放，以周为单位，迭代优化渠道投放效果，并监测的变动。
、渠道投放优化效果
在投放一周后，对新增用户有了增长，我们临时决议再次加大渠道的投放比例。这里是一个月的时间周期内，我们的新增用户数在渠道上的分布有了显著变化。

优化投放渠道前后，购买转化漏斗转化率的改变：

由于渠道的平均客单价约是渠道的，我们的投入产出比例得到了优化。这主要依赖于通过数据分析找到了优质低价的渠道，降低了获客成本。
那么这个转化漏斗中，是否还有其他优化的空间？我们还能做什么改善？请关注我们下周的案例分享《数据运营实战二》。一、插件 —— 打印方法运行时间
首先申明下，此非 彼是由语言实现的静态网站生成器。
插件作用 ：

能够计算并打印一个方法的输入参数和函数的运行时间

插件应用场景：

处理 应用卡顿问题


先看实例
 在对应方法处标注

处标记
插件计算的运行时间

插件计算的运行时间
第一行：打印执行方法及其参数
第二行：方法执行时间
常规日志打印运行时间

常规日志打印运行时间
 插件配置
在 的中添加依赖地址
 
插件

使用开关配置
方式一 ：

 {

 

}
方式二 ：
|
备注 ：    暂时好像还不行
插件详细资料可参考 ： 插件  地址
二、 插件 ——  隐患扫描工具
是一款专门针对无线代码隐患的静态扫描工具，能够对 和  两个平台代码进行检查，同时支持 、、三种操作系统。
扫描规则源自项目案例代码分析，扫描准确率高达以上，针对 应用，已经提供了  插件版本。
 插件配置
配置项
配置输出报告格式类型、编码格式、输出路径 可配置到输出

配置项
扫描规则配置

扫描规则配置
白名单配置
详情可参照 ： 使用说明
其他静态扫描工具
 代码规范神器 使用全面解析
代码缺陷扫描神器——
三、  —— 显示栈顶信息
背景介绍
在日常需求开发中，经常碰到不太熟悉的模块，如何快速定位相应页面？一般有以下几张方式：
根据项目中的模块划分及命名，在项目目录中搜寻；
使用   工具定位所在模块页面某个控件

   工具定位
缺点：项目中不是所有控件在中都写上了 ，特别是组里现在使用后。
使用  工具
查看当前  ：     |  =

其他相关操作：
查看当前栈顶的 ：    |  
查看当前栈顶的的 ：    
  
 在这里介绍一种更为简便的工具查看栈顶，  ，是一个查看栈顶的简易工具。
使用效果如下 ：

专辑详情页
相关地址：

源码地址

下载地址


四、开发助手 —— 方便切换开发者配置
开发助手 ——  大神佳作，在此不过多介绍，详情请看： 应用开发调试利器——开发助手，数十倍效率提升
开发助手主界面导语
如果在日常开发中有些模块需要在反复运行调试，但是又依赖了框架的组件，需要启动框架后才能正常执行，放在里用发起调用不够简单方便，使用  的话每次修改又得退出后重新进入才能生效，也是比较麻烦。本文提供一个简单可行的方案简化了这个调试过程其实用的主要也是  这个工具。
问题
先举个例子，文件路径为，主要的代码如下
 
   

 __
      = ==
     

  如果想要调试上面这个方法，一般会这么写
 ____==____
      __
这样的话，直接运行起来会一般会报这样的错误
   __             __      
就是提示找不到对应的配置。因为此时框架的代码都没有启动，相应的全局配置都没有加载到，自然是用不了的。
解决方案
这个方案主要采用的还是  这个工具，利用环境变量来判断是否要执行调试的代码。

首先，在配置文件中设置环境变量，例如这里用到的配置文件是 
_ =   默认框架启动时初始化为，即不启动

修改需要调试的脚本里的判断逻辑，例如，将改为

 
   

 __
      = ==
     

 这里的判断逻辑由原来的判断模块名改成判断_这个开关是否开启
 _== 
      __

接下来，利用  这个工具就可以做一些事情了，只要执行以下命令就可以执行上述的脚本啦

  \_=\ |  通过管道命令的方式就可以直接在命令行里执行这几句语句，通过改变了环境变量然后再引入需要调试的模块的方式，就可以不用启动框架执行相应的调试代码其实  还是有启动框架了，只是说这样可以直接一行命令执行而不用先进入 里再执行多次

但是上面这个命令用起来不方便，于是写了个脚本简化一下_



_ {
      `` 
}
   =  

    _
     


=` `
_=____
_=
_={_\}
_={_\}

    _
 _=  _
  _ _
 _|  

 _

然后，只要在项目的根路径下即跟相同的目录下，执行该脚本对应的脚本的相对路径即可， 例如_ 这样一来，调试起来是不是简单很多了呢前面有篇文章《 缓存淘汰机制》已经讲解了的主要缓存淘汰，即过期淘汰和基于的淘汰。
过期淘汰是一个定时事件，在事件库中会定时执行，而基于的淘汰则是每次执行命令的时候进行检查内存和策略再进行淘汰。本篇文章主要是对的淘汰进行一个简单的介绍，在淘汰中对和文件等操作就不详细介绍。
触发
是在每次执行命令的时候对使用内存进行检查，当端使用的内存超过了在配置文件中配置的最大可用内存的时候，就会触发淘汰。
 
淘汰机制
在中，它支持如下几种淘汰机制，注意都是所用内存达到配置中最大可用内存的时候

直接返回错误，当客户端尝试执行会让更多内存被使用的命令大部分的写入指令，但和几个例外

 尝试回收最少使用的键，使得新添加的数据有空间存放。


  回收随机的键使得新添加的数据有空间存放。

 尝试回收最少使用的键，但仅限于在过期集合的键使得新添加的数据有空间存放。

 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键。

 回收在过期集合的键，并且优先回收存活时间较短的键使得新添加的数据有空间存放。


可以看到上面回收策略有俩个纬度，

回收的键的范围

过期集合

不区分是过期集合

回收策略

随机

基于


然后基于上面俩种纬度，做个组合就是四种主要策略。
需要注意的这里提到的过期集合，翻译并不是特别准确。它并不是指的这些键是已经过期了，而是指存放着含有过期时间的键；如果一个键没有过期时间，那么就不会存在在该集合中。中可以对键设置过期时间，只要是设置了过期时间的键都会存放在中专门的一个数据结构。
淘汰逻辑
淘汰的主要执行逻辑是在方法 。在方法执行期间，客户端发出的命令会被阻塞住。阻塞命令执行也是为了避免更多的内存被使用。
算法主要逻辑：


｛
           
         ｛
                根据配置的淘汰策略
                选择最适合的
                释放资源
          ｝

｝  已经释放的小于需要释放的
选择最合适的这一步操作就要结合上面所说的，设置的几种淘汰策略。根据设置的淘汰策略，选择出需要淘汰的，然后通过释放起资源。
需要注意的是在这里的也不是严格的算法，它是基于一个配置的大小值_，循环遍历，随机获取然后找到一个最合适的，然后把该删除掉。网上也有文章分析，在这种类算法下，基本和真正的算法的性能没有太大差异，但是相比较于真正严格的效率要更高。
判断那个是最合适是通过比较该的时间和里维护的_差值。在定时事件中会被定时循环更新，会更新成和当前时钟值有个倍数关系的值。
             
        
    {
      =  {
             ___
    }  {
         ___     
                    ___
    }
}为什么要服务标准化
一套互联网后台服务的开发和运营涉及到非常多的细节：

访问其他服务模块，服务端如何管理？网络报文格式是怎样的？

有哪些配置文件？ 用到哪些第三方的库？

业务逻辑和基础框架是如何分离的？

对外提供怎样的网络接口？怎么对外提供接口和文档？

运营机器上的安装目录准备怎么安排？  有哪些运维脚本和工具？

应该监控哪些指标？应该记录哪些日志？

还有很多…


上面种种细节，每个程序员实现起来都有不同的做法。经验证明，如果后台各个模块没有标准化和规范化，可能导致：

同一个团队开发的服务，千差万别千奇百怪，负责运维的同事面对的多个模块“长”的都不一样，程序框架完全不一样，安装目录乱七八糟，无法规模化的高效运维

服务的质量完全依赖团队成员的技能和意识，有的成员可能会做得比较好，配置文件命名易懂、文档及时更新与代码保持一致、有对服务做细致的监控上报和日志记录，提供了运维脚本，但是也有的成员的工作让人抓狂

每当有团队成员离职和工作交接，交接本身就是工作量很大，交接时间长，交接质量不好，文档缺失，很多信息在交接过程中丢失，运营事故往往频发

经验难以得到传承，一块石头反复绊倒各个成员和业务模块，运营事故雷同、频出，团队挫折感倍增、服务可用性低下

也曾经有过做事比较规范的时候，但是这些规范通常靠耳提面命、人口相传，靠管理者运动式的整顿，有时候管理焦点没有持续跟进，或者随着人员更替，团队又把这些宝贵的经验丢弃了，变得无序


所以服务标准化是后台技术团队组建开始的第一要务。
几个误区
误区一：找几个开源的组件用起来就好了呗
通常的开源的组件，只是在某一方面上规范了服务，有的是规范了网络调用，有的是规范了如何监控，有的是规范了如何记录远程记录，其实这还远远不够，例如配置文件、接口定义、使用到的外部库、安装目录的结构等非常多的细节，必须统一管理、有唯一出处。
误区二：你说的我都懂，我们团队刚起步，业务需求多，时间紧，先野蛮生长，打破条条框框，后面再规范再改
一开始没有标准化，后面当代码和模块都多起来了，且都处于运营状态，再改再标准化，难度非常大，成本非常大，风险非常大；另外工欲善其事必先利其器，一开始就标准化好，其实可以让业务跑的更快
毫秒服务引擎 取英文名    的首字母组合是腾讯一个开源框架，其创作冲动和构建经验，来自后台团队超过年的运营思考。服务标准化是毫秒服务引擎设计的重要考量点。
毫秒引擎怎么实现服务标准化？
首先，每个服务的配置都化、集中管理起来，包括：

部署在哪些上？



有且只有一个配置文件



 的接口定义文件



引用了哪些外部库？例如



业务逻辑和基础框架分离，业务逻辑以插件形式提供


然后，每个业务模块部署的目录结构都是确定的：

如上图所示，

业务部署的目录都是一级业务名二级业务名

都包含   等几个目录

里面是启停脚本、业务插件和外部库如果有

里面是配置文件

里面是本地的日志文件


另外，程序员不能随意打破上面的方式。例如临时的另外搞一个自己配置文件什么的，他如果这样做，那下次发布的时候目录会被覆盖，个性化的东西会被删除掉
结语
由于篇幅和时间的限制，这里不能展开阐述。详细的可以见腾讯云服务市场、毫秒服务引擎官网，或者微信公众号

相关推荐 谈谈后台服务的灰度发布与监控 谈谈后台服务的和路由管理在上一节我们实现了对接抓取淘宝商品的过程，这是一种抓取渲染页面的方式，除了使用还有同样可以达到同样的功能，本节我们来了解下对接来进行页面抓取的方式。
环境准备
首先在这之前请确保已经正确安装好了并正常运行，同时安装好了库，如果没有安装好可以参考第一章的安装说明。
开始
接下来我们首先新建一个项目，名称叫做，命令如下：
  
随后新建一个，命令如下：
   
随后我们可以参考的配置说明进行一步步的配置，链接如下：。
修改，首先将_配置一下，在这里我们的是在本地运行的，所以可以直接配置本地的地址：
_ = 

如果是在远程服务器运行的，那此处就应该配置为远程的地址，例如如果运行在为的服务器上，则此处应该配置为：
_ = 

接下来我们还需要配置几个，代码如下：
_ = {
    _ 
    _ 
     
}
_ = {
    _ 
}

在这里配置了三个 和一个 ，这是的核心部分，配置了它们我们就可以对接进行页面抓取，在这里我们不再需要像对接那样实现一个 ，库都为我们准备好了，直接配置即可。
接着还需要配置一个去重的类_，代码如下：
_ = _

最后还需要配置一个存储_，代码如下：
_ = _

配置完成之后我们就可以利用来抓取页面了，例如我们可以直接生成一个对象并传递相应的参数，会将此请求转发给，对页面进行渲染加载，然后再将渲染结果传递回来，此时的内容就是渲染完成的页面结果了，最后交给解析即可。
示例用法如下：
  _
    ={
               
         
              
         _       
                 
    }
    =     
    _=        _


在这里构造了一个对象，前两个参数依然是请求的和回调函数，另外还可以通过传递一些渲染参数，例如等待时间等，还可以根据参数指定渲染接口，另外还有更多的参数可以参考文档的说明：。
另外我们也可以生成对象，关于的配置通过属性配置即可，代码如下：
  _ ={
     {
         {
                
             
             
                  
             _       
                     
        }
          
               
        _          _
        _ __
        _ {}               
        __      
        __       
        _         
    }
}

两种方式达到的效果是相同的。
本节我们要做的抓取是淘宝商品信息，涉及到页面加载等待、模拟点击翻页等操作，所以这里就需要脚本来实现了，所以我们在这里可以首先定义一个脚本，来实现页面加载、模拟点击翻页的功能，代码如下：
  
   = {
    ==
    =
    =
  }
  _ = 
  
  
   =    =   _ 
  
  
   


在这里我们定义了三个参数，请求的链接、等待时间、分页页码，然后将图片加载禁用，随后请求淘宝的商品列表页面，然后通过方法调用了代码实现了页码填充和翻页点击，最后将页面截图返回。我们将脚本放到中运行一下，正常获取到了页面截图：

可以看到翻页操作也成功实现，如图所示即为当前页码，和我们传入的页码参数是相同的：

所以在这里我们只需要在里面用对接这个脚本就好了，实现如下：
   
   
   
 _  

 = 
  
  _ = 
  
  
   =    =   _ 
  
  
   



 
     = 
    _ = 
    _ = =

     _
           
                _  
                 = _  
                  = = ={_     }

在这里我们把脚本定义成长字符串，通过的来传递参数，同时接口修改为，另外参数里还有一个_字段用于指定脚本内容，这样我们就成功构造了一个，对接的工作就完成了。
其他的配置不需要更改，、 等设置同上节对接的方式，同时回调函数也是完全一致的。
接下来我们通过如下命令运行爬虫：
  
由于和都支持异步处理，我们可以看到同时会有多个抓取成功的结果，而的对接过程中每个页面渲染下载过程是在 里面完成的，所以整个过程是堵塞式的，会等待这个过程完成后再继续处理和调度其他请求，影响了爬取效率，因此使用爬取效率上比高出很多。
因此，在中要处理渲染的页面建议使用，这样不会破坏中的异步处理过程，会大大提高爬取效率，而且的安装和配置比较简单，通过调用的方式也实现了模块分离，大规模爬取时部署起来也更加方便。
本节源代码：导语
自动化测试是一个老生常谈的话题，往往应为界面变化太快，测试脚本更新跟不上需求变化而作罢。所以打算引入能自动生成测试脚本的  这一开源工具。并且配合使用  来加快测试环境的部署。
现状
自动化测试的重要性大家都有共识，在  前端领域大家做的比较完善的基本上还是在基础类库和公共方法上的单元测试。因为这一块代码比较稳定，单元测试的工具也比较完善。但是前端的大部分工作是在和界面打交道，把打比喻成一种特殊的  软件也会会更形象一点。所以模拟用户操作的自动化测试能更多的覆盖我们的业务逻辑。
那为什么目前的自动化测试普及率还是不高呢？这里引入业界的一个公式：
自动化的收益 = 迭代次数  全手动执行成本  首次自动化成本  维护次数  维护成本
往往就是因为写测试用例的耗时首次自动化成本加上需求变化维护次数大，导致自动化的收益回报低。所以业界一直在探索一些工具来降低这些成本。
 
经过一些调研，觉得 这套开源工具方便易用，能通过让使用者自己跑一遍测试流程而自动生成对应的测试脚本，简化编写脚本的过程。于是决定尝试尝试。
使用  需要 、 的环境。在环境准备好后通过
   
 命令安装，然后新建一个文件夹在其中使用
 
 初始化配置后就可以开始录制脚本了。
具体使用可以参考它的文档和这个  视频介绍，这里就不赘述了。
录制脚本生成之后可以手动跑一跑刚才的 
 启动  服务：
  

  
  在新窗口运行单个脚本：
  
 然后我们就可以看到测试运行的整个流程。
通过使用录制的方式生成脚本，能大大加快我们开发测试用例的的速度，一旦需求界面发生变化，我们可以迅速同步测试用例。
引入 
解决了脚本生成的问题，我们还想让整个测试的体系更加高效敏捷。我们知道前端的另一大苦逼之处就是要做浏览器兼容，各大浏览器都通过了才算大功告成。所以自动化测试也需要在各个浏览器下运行。
因为自动化测试时独占的，所以往往需要一个浏览器部署在一个测试机上来并行测试。而这样导致太多的资源的消耗，也成为自动化测试普及的一个瓶颈。
庆幸这是一个好的时代！我们有了  这一神器。 有秒级启动、应用隔离、良好的可移植性的优点，完全使用沙箱机制，相互之间没有任何接口。而且性能开销小，可以很容易地在机器和数据中心中运行。最重要的是 他们不依赖于任何语言、框架或系统。
很自然的，我们想尝试尝试这两者结合起来的力量。
生在开源时代的  也自带开源属性，在  上我们能找到非常多的镜像地址，不需要我们一步一步的从零开始构建我们自己的镜像。
使用 
回到我们的主题，我们需要的是利用  来构建我们的测试环境，这样可以很方便快速的部署到测试机上，并且后期扩展也非常容易。
要跑我们的测试用例需要  和浏览器的环境，  上有专门的一个镜像系列：
这里面包含了基础环境的镜像，包含各种浏览器   的镜像。我们先使用  和  来试试水

 运行    的镜像

 包含  的   镜像需要连接    使用


首先我们把这两个镜像拉去到本地：
  
  
 然后先后把两个镜像跑起来：
       
 这个命令解释一下几个参数：

 如果在   后面追加 = 或者 ，那么容器将会运行在后台模式。

 容器识别参数，如果你在执行   时没有指定 \，那么  会自动生成一个随机字符串  作为标识符。所以有个  会非常方便，这里我们指定  为 。

 发布特定端口，显式将一个或者一组端口从容器里绑定到宿主机上


          

 多容器应用程序里使用 \ ： 在消费和服务容器之间创建链接

然后在跑  的项目中的  文件中，修改  的  参数：
  {
         
         
         
    }
 这里的   就是在上面的  启动命令中指定的。接着使用之前   的命令 启动就可以看到  跑起来了，而且本地浏览器并没有启动。因为这是的浏览器是启动在  容器中了。
下一步
之前的尝试中，最后一个测试环境也就是  的测试环境并没有在  容器中，其实我们也可以吧组后的环境也  成一个  容器，这样部署起来才更畅快。接下来会继续尝试这一步的改进，并真正部署到测试环境中，并结合定时脚本，邮件报警机制完善我们的流程。
且看下回分解。 命令简介
 命令是  数据库的客户端应用程序，用于解释执行  语句。
 的六种子语言
  是结构化查询语言，也是一种高级的非过程化编程语言。 语句可用于增删查改数据以及管理关系型数据库，并不局限于数据查询。
关于  的组成部分，网上的资料也是众说纷纭，有些将  分为四个子语言， 纳入  的一部分，也有些没有 ，因为没有参考到较权威的资料，目前按照百度百科的说法， 主要由六个子语言组成，分别是 、、、、和 ，下面将一一讲解。 
   ，数据定义语言 
 用于定义数据库的三级结构，包括外模式、概念模式、内模式及其相互之间的映像，定义数据的完整性约束、安全控制等。使我们有能力创建、修改和删除表格。也可以定义索引和键，规定表之间的链接，以及施加表之间的约束。 不需要 ，主要操作有：  
  创建  修改  删除  截断  注释  重命名
   ，数据查询语言 
其语句，也称为数据检索语句，用以从表中获得数据，确定数据怎样在应用程序给出。保留字  是 也是所有 用得最多的动词。常用的关键字有：  
从数据库表中获取数据  指定从哪个数据表或者子查询中查询  指定查询条件   结合合计函数，根据一个或多个列对结果集进行分组  对分组后的结果集进行筛选   对结果集进行排序  对结果集进行  限制输出  结果集纵向联合  结果集横向拼接
   ，数据操作语言 
供用户对数据库中数据的操作，包括数据的增加、删除、更新，载入等操作。
  更新数据库表中的数据  从数据库表中删除数据   向数据库表中插入数据  载入数据
   ，数据控制语言 
用于对数据库，数据表的访问角色和权限的控制等。  
  授权  撤销授权  拒绝授权
   ，事务控制语言 
又名   事务处理语言，它能确保被  语句影响的表的所有行及时得以更新。 语句包括：  
  或   开始事务  在事务中设置保存点，可以回滚到此处  回滚  提交  – 改变事务选项
   ，游标控制语言 
游标是  为用户开设的一个数据缓冲区，存放  语句的执行结果。游标控制语言对游标的操作主要有：  
   申明游标   打开游标   取值    更新游标所在的值   关闭游标
下面将从上面的六个子语言来陈述  的常用  语句和  的相关命令。
 常用命令
本人使用  版本是 ，下面所有的命令均在本版本  测试通过，如遇到问题，请留言探讨！
 准备篇
 连接到本机上的 
首先打开  命令终端或者命令行程序，键入命令    ，回车后提示你输密码。注意用户名前可以有空格也可以没有空格，但是密码前必须没有空格，否则让你重新输入密码。  
或者直接给出密码：
   中括号中的变量需要替换指定值
如果刚安装好 ，超级用户  是没有密码的，故直接回车即可进入到  中了， 的提示符是： 。
 连接到远程主机上的 
假设远程主机的  为：，用户名为 密码为 。则键入以下命令：
      
注： 与  之间可以不用加空格，其它也一样。
 退出 
 
或者
 
 查看  版本
  
或者
 
 篇数据控制篇
 新建用户
命令格式
      

示例
      
      
      
   
说明： – 你将创建的用户名  – 指定该用户在哪个主机上可以登陆如果是本地用户可用  如 果想让该用户可以从任意远程主机登陆可以使用通配符  – 该用户的登陆密码密码可以为空如果为空则该用户可以不需要密码登陆  服务器。
 删除用户
命令格式
   

示例
   
说明：删除用户时，主机名要与创建用户时使用的主机名称相同。
 给用户授权
命令格式
      

示例
      
      

最后不要忘了刷新权限
  
说明：
  —是一个用逗号分隔的赋予  用户的权限列表，如      等详细列表见该文末附录 。如果要授予所有的权限则使用 ； – 数据库名，表名，如果要授予该用户对所有数据库和表的相应操作权限则可用表示，如。
使用  为用户授权时，如果指定的用户不存在，则会新建该用户并授权。设置允许用户远程访问  服务器时，一般使用该命令，并指定密码。  
示例
         
 撤销用户权限
命令格式
      

示例
      
      
说明  
    – 同授权部分。
假如你在给用户  授权的时候是这样的或类似 的      则在使用       命令并不能撤销该用户对  数据库中  表的  操作。相反如果授权使用的是       则       命令也不能撤销该用户对  数据库中  表的  权限。
具体信息可以用命令     查看。
 查看用户权限
方法一：可以从  表中查看所有用户的信息，包括用户的权限。    
     = 
方法二：查看给用户的授权信息。
命令格式
    

示例
    
    
说明：不指定主机名称，默认为任意主机。
 修改用户密码
方法一：使用  语句。    
命令格式：
    = 

示例
    =
如果是当前登录用户：   
   = 
方法二：使用服务端工具  来修改用户密码。
命令格式
    

示例
    
 篇数据定义篇
 创建数据库
命令格式
   

示例
   
 删除数据库
命令格式
   

示例
   
 查看所有数据库
  
 查看当前数据库
  

或者
 
 连接数据库
命令格式
  

示例
  
 创建数据表
命令格式：  
    表名   字段名   类型        

 
说明：上面的建表语句命令格式，除了表名，字段名和字段类型，其它都是可选参数，可有可无，根据实际情况来定。  表示该字段是否允许为空，不指明，默认允许为 ； 表示该字段是否是主键，外键，唯一键还是索引；  表示该字段在未显示赋值时的默认值； 表示其它的一些修饰，比如自增 _； 表示对该字段的说明注释； 表示数据库存储引擎， 支持的常用引擎有 、、、 和，不显示指明默认使用 ； 表示数据表数据存储编码格式，默认为 。
存储引擎是什么？其实就是如何实现存储数据，如何为存储的数据建立索引以及如何更新，查询数据等技术实现的方法。
以学生表为例，演示数据表的创建。
学生表设计：



字段
类型
可空
键
默认值
其他




学号
 



_


姓名







学院







年级







专业







性别







建表语句是：
      
          学号 _
         姓名
         学院
         年级
         专业
         性别
     
=  = _=
说明： 上面的建表语句需要注意三点。第一，可以使用    来判断数据表是否存在，存在则创建，不存在则不创建。第二，设置主键时可以将   放在字段的后面来修饰，也可以另起一行单独来指定主键。第三，设置自增时，可以指定自增的起始值， 默认是从  开始自增，比如  号是从  开始的。
关于  支持的数据类型，可参考  数据类型
 查看  支持的存储引擎和默认的存储引擎
查看所支持的存储引擎
  

查看默认的存储引擎
      _
 删除数据表
   
 查看数据表结构
  

或者
  
查看上面创建的  数据表的结构如下：

 查看建表语句
    
 重命名数据表
     
 增加、删除和修改字段自增长
删除字段自增长
命令格式
      

示例，取消  的自增长
       
说明：注意列名称要重复一次，即需要将列的名称写两次。
增加字段自增长
命令格式
      _

或者与上面删除字段自增长相反
       _

示例，添加  自增长
       _
说明：添加自增长的列必须为   及  属性。如果不是，需添加相应定义。
修改自增长起始值
命令格式
    _=

示例，设置  从  开始自增
    _=
注意：设定的起始值  只能大于已有的 _ 的整数值，小于的值无效。    _ 或者     可以看到 _ 这一列现有的起始值。
 增加、删除和修改数据表的列
增加列
命令格式
      

示例，为数据表  增加家乡 
        家乡
删除列
命令格式
     
重命名列
命令格式
      
修改列属性
命令格式
      

示例，修改  类型为  且不允许 
        
 添加、删除和查看索引
添加索引
命令格式
      字段名 字段名 …

示例，为数据表  数据列  添加索引
      _
或者
     
说明： 上面示例的第二种方法，如果不显示指明索引名称的话，默认以列名称作为索引的名称。添加索引是为了提高查询的速度。
查看索引
    
删除索引
命令格式
      

示例
      _
 创建临时表
命令格式
     表名   字段名   类型        

示例
     
说明：创建临时表与创建普通表的语句基本是一致的，只是多了一个  关键；  
临时表的特点是：表结构和表数据都是存储到内存中的，生命周期是当前  会话，会话结束后，临时表自动被 ；
注意临时表与  表内存表的区别是：  
   表的表结构存储在磁盘，临时表的表结构存储在内存；  
    看不到临时表，看得到内存表；  
 内存表的生命周期是服务端  进程生命周期， 重启或者关闭后内存表里的数据会丢失，但是表结构仍然存在，而临时表的生命周期是  客户端会话。
 内存表支持唯一索引，临时表不支持唯一索引；  
 在不同会话可以创建同名临时表，不能创建同名内存表。
 创建内存表
与创建表的命令格式相同，只是显示的在后面指明存储引擎为 。
命令格式
     表名   字段名   类型        =

示例
    =
 修改数据表的存储引擎
    |=

示例，将数据表  存储引擎设置为 
    =
或者
    =作者： 

一、前言
在  中进行图片压缩是非常常见的开发场景，主要的压缩方法有两种：其一是质量压缩，其二是下采样压缩。
前者是在不改变图片尺寸的情况下，改变图片的存储体积，而后者则是降低图像尺寸，达到相同目的。
由于本文的篇幅问题，分为上下两篇发布。
二、 质量压缩逻辑
在中，对图片进行质量压缩，通常我们的实现方式如下所示：
  =  
 为～，表示最小体积，表示最高质量，对应体积也是最大
  
在上述代码中，我们选择的压缩格式是，除此之外还有两个选择：
其一，，  格式是无损的，它无法再进行质量压缩， 这个参数就没有作用了，会被忽略，所以最后图片保存成的文件大小不会有变化；其二， ，这个格式是  推出的图片格式，它会比  更加省空间，经过实测大概可以优化  左右。
由于项目原因和兼容性选择了，因此接下来的分析也将是围绕  展开。
将  图片转成  格式之后不会降低这个图片的尺寸，但是会降低视觉质量，从而降低存储体积。同时，由于尺寸不变，所以将这个图片解码成相同色彩模式的  之后，占用的内存大小和压缩前是一样的。
回到最初的代码示例，函数  经过一连串的  层调用之后，最后来到了一个  函数，如下：

  _     
                                   
                                    {

     
     

      {
     _
         = _
        
     _
         = _
        
     _
         = _
        
    
         _
    }

      {
         _
    }

      = 

    _   
      {
         _
    }

    _ 
      {
         
        
         =   
    }
       _  _
}
可以看到最后调用了函数  编码保存本地。该函数是调用  引擎来对图片进行编码压缩，对  的介绍将在后文展开。
一段完整的示例代码如下：
  为  图片
  =  
 {
    保存压缩图片到本地
      =   
      {
        
    }
      =  
      
         
    
    
}    {
    
}    {
    
}
查看压缩之后的  大小
  =  
  
  = 
  =   
   =         =   
首先，我们来看看  参数被设置为 ，质量压缩前后的图片对比，可以看到其尺寸大小并没有变化，但是视觉感受也可以明显地看到图片变的模糊了一些。
　
通过日志也可以看到，在质量压缩前后图片转成  之后在内存中的大小也并没有变化，这是在保持像素的前提下，改变图片的位深及透明度等：
压缩之后图片占用的存储体积
 = 
在内存中压缩前后图片占用的大小
 =     = 
对比二者，保存前的图片存储体积是 ，质量设为  并且保存为  格式之后，图片存储大小就只有  了，并且质量设的越低，保存成文件之后，文件的体积也就越小。
三、  图像引擎
在上文中，提到的是 的重要组成部分。
 是一个  自己维护的  实现的图像引擎，实现了各种图像处理功能，并且广泛地应用于谷歌自己和其它公司的产品中如：、、 等，基于它可以很方便为操作系统、浏览器等开发图像处理功能。
 在  中提供了基本的画图和简单的编解码功能，可以挂接其他的第三方编码解码库或者硬件编解码库，例如  和 ， 等等。因此，这个函数调用，实际会调用  动态库进行编码压缩。
最终  编码保存图片的逻辑是  层函数→ 函数→函数→对应第三库函数例如 。所以  就像一个胶水层，用来链接各种第三方编解码库，不过  也会对这些库做一些修改，比如修改内存管理的方式等等。
 在之前从某种程度来说使用的算是  的功能阉割版，压缩图片默认使用的是  ，而不是  ，也就是说使用的是默认的哈夫曼表，并没有根据实际图片去计算相对应的哈夫曼表， 在初期考虑到手机的性能瓶颈，计算图片权重这个阶段非常占用  资源的同时也非常耗时，因为此时需要计算图片所有像素  的权重，这也是  的图片压缩率对比  来说差了一些的原因之一。
四、图像压缩与  算法
这里简单介绍一下哈夫曼算法，哈夫曼算法是在多媒体处理里常用的算法之一。比如一个文件中可能会出现五个值 ，它们用二进制表达是：
     
我们可以看到，最前面的一位数字是 ，其实是浪费掉了，在定长算法下最优的表达式为：
     
这样我们就能做到节省一位的损耗，那哈夫曼算法比起定长算法改进的地方在哪里呢？在哈夫曼算法中我们可以给信息赋予权重，即为信息加权，假设  占据了 ， 占据了 ，  占据了 ， 都是 ：
          
在这种情况下，我们可以使用哈夫曼树算法再次优化为：

所以思路当然就是出现频率高的字母使用短码，对出现频率低的使用长码，不出现的直接就去掉，最后  的哈夫曼编码就对应：  通过权重对应生成的的哈夫曼表为：

定长编码下的：    ，使用哈夫曼树加权后的编码则为   ，这就是哈夫曼算法的整体思路关于算法的详细介绍可以去查阅相关资料。
所以这个算法一个很重要的思路是必须知道每一个元素出现的权重，如果我们能够知道每一个元素的权重，那么就能够根据权重动态生成一个最优的哈夫曼表。
但是怎么去获取每一个元素，对于图片就是每一个像素中  的权重呢，只能去循环整个图片的像素信息，这无疑是非常消耗性能的，所以早期  就使用了默认的哈夫曼表进行图片压缩。
五、 与 _
 在压缩图像时，有一个参数叫 _，关于这个参数， 有如下解释：

                                                                               

由上可知，如果设置 _ 为 ，将会使得压缩图像过程中，会先基于图像数据计算哈弗曼表。由于这个计算会显著消耗空间和时间，默认值被设置为 。
那么 _ 参数的影响究竟会有多大呢？查阅一些博客资料介绍，使用相同的原始图片，分别设置 _= 和  进行压缩，发现  时的图片大小大约是  时的  倍。换言之就是相同文件体积的图片，不使用哈夫曼编码图片质量会比使用哈夫曼低  倍。
关于这个差异我们再去查阅其他资料，发现有两篇讨论非常热烈：  “_”    ，  _，甚至 的官方人员也参与了讨论，他据此测试了两组数据：

                                  
                                 

可以看到效果并不是  倍的体积差距，最多也就在  倍而已，有国人也测试了一下，结果一致：  。
尽管如此，社区里对此的疑虑并没有彻底打消，最终，官方人员修改了这个默认的实现：      。在 _ 文件中给 _ 赋值了一个默认值 。
六、 与 _
那么在  中有没有使用哈夫曼变长编码呢？查阅了  源码，如下：
         
_ = 
可以看到注释里面很清楚，默认是哈夫曼变长编码，而不是算数编码。同时去查阅  年时的   源码，发现依旧如此。
对于_，早期的  考虑到性能瓶颈，将其设置为 。但是，现在  手机性能比以前好很多，所以目前性能往往不是瓶颈，时间和压缩质量反而成为更重要的指标了。为此， 在   版本左右，也做了相应修改，如  和  源码所示：


七、    
经过上面的介绍大家应该了解了为什么  的  图片压缩率会比  小一些，那么还有另一个问题就是为什么同一张  图片设置成同样的压缩质量压缩成  之后， 输出的图像质量会比  差一些呢，经过相关资料的查找，发现造成这个结果有两方面的因素。
第一个因素是  编码过程中有一个步骤是颜色空间    的转换，之前的  版本同样考虑到性能问题， 引擎写了一个函数替代了原来  的转换函数，好处是提高了编码速度，坏处就是牺牲了每一个像素的精度。
第二个因素是离散余弦变换有三种方式， 引擎选择了 _，_ 是最快的变换方式，当然也是精度最差的一种。
上面两种因素第一个会造成色调偏差，第二个会造成色块的出现，所以如果需要提高压缩之后的图像质量，可以考虑从这两方面入手。
八、总结
首先，从   版本开始，_ 标示已经设置为了 ，也就是默认使用图像生成哈夫曼表，而不是使用默认哈夫曼表。而至于这个标志所产生的体积差距也没有  倍那么大，大约可以在原图的基础上缩小 ～ 的体积，经过修改前后不同  版本实测，数据吻合。
其次，如何提高  的压缩率，这里需要提到两个库，一个是 ，另一个是 ，前者是一个来自  实验室的  图像编码器项目，目标是在不降低图像质量且兼容主流的解码器的情况下，提供产品级的  格式编码器来提高压缩率以减小  文件的大小，后者相当于是一个  的增强版，前者也是基于后者，在后者的基础上进行了一些优化。
所以想要提升图片压缩率的可以从这两个库着手，网上资料也不少，后续有机会可以测试一下这两个库，然后给大家分享一下。　　最后，编码方式除了哈夫曼之外，还有定长的算术编码，这个算法的详细介绍大家可以网上查阅一下。对比哈夫曼编码和算术编码，网上相关资料显示算术编码在压缩  方面可以比哈夫曼编码体积小 ～，所以需要提升图片压缩率的同样也可以尝试从切换成算术编码这方面入手。
九、参考

为什么的图片质量会比的差？_ 
   
     
  _    = 
  _ 作者：徐思彦 腾讯研究院高级研究员


“加快建设制造强国，加快发展先进制造业，推动互联网、大数据、人工智能和实体经济深度融合，在中高端消费、创新引领、绿色低碳、共享经济、现代供应链、人力资本服务等领域培育新增长点、形成新动能。”——十九大报告
十九大报告关键词系列解读之三·人工智能
科技进步正在成为推进经济发展的重要推动力，对中国经济发展的贡献率已经上升到。面对正在兴起的人工智能浪潮，如何占据行业发展制高点，如何促进与实体经济深度融合，形成新增长点？
 人工智能的再度崛起
年世界围棋冠军李世石在与 的比赛中投子认输，让人们惊觉人工智能的力量已经不容忽视。过去的十年，算法、数据和计算三大要素助推了人工智能的再度崛起，互联网存储了二十多年的数据终于找到了它的历史使命：训练机器。本轮以机器学习、深度学习为主的浪潮被认为是当前面临的最为重要的技术创新和社会变革的驱动力，以算法为核心的时代来临。
与互联网、移动互联网一样，人工智能是基础能力。人工智能并不是单一的技术或者赛道，它将融入现有的生产中，在垂直领域加深数字化的影响，影响到所有和数据相关的领域。深度学习算法使机器拥有自主学习的能力，被应用于语音、图像、自然语言处理等领域开始纵深发展，带动了一系列的新兴产业。通过提高生产力以及创造全新的产品和服务，这是经济竞争和经济升级的迫切需求。
人工智能底层技术的不断发展，已经让智能机器逐步实现从“认识物理世界”到“个性化场景落地”的跨越。科技公司将人工智能视为数字革命的下一站，各大科技公司都在积极布局争取通往世界的“船票”。巨头之外，大量资金流入，中国在企业层面的融资金额已接近美国。在国家层面，各国政府正在不遗余力地推进人工智能技术发展，其在经济建设以及国家战略层面的作用日益重要。
近年来，中国政府对人工智能重视程度不断提高，持续从各方面支持和促进人工智能发展。在今年的“两会”上，“人工智能”第一次出现在政府工作报告上。随后，国务院印发《新一代人工智能发展规划》，标志着人工智能的发展成为国家战略。其中，实体经济是发展的根基，是国民经济的基础，也是中国走向未来的基石。推动人工智与实体经济结合，是加快实体经济转型升级的必然发展方向。
 六大领域助力实体经济
人工智能不是一个遥远的概念，新一代人工智能的繁荣，衍生出了众多应用型的技术。从技术层面来看，机器人、自然语言处理、计算机视觉与图像、语音识别、自动驾驶等技术领域是产业热门的分支，创业热情火爆，技术突破及应用创新层出不穷。现在应用型已经渗透到了各行各业，多种技术组合后打包为产品或服务，改变了不同领域的商业实践，使垂直领域商业化进程加速，掀起一场智能革命。

图片来源：腾讯研究院整理
根据此前腾讯研究院发布的《中美创投报告》中整理的中国渗透行业热度图显示，医疗行业成为目前应用最火热的行业，汽车行业借势自动驾驶辅助驾驶等相关技术的发展脱颖而出，位列第二。第三梯队中包含了教育、制造、交通、电商等实体经济标志性领域。在各行各业引入人工智能是一个渐进的过程。
从最基础的感知能力，到对海量数据的分析能力，再到理解与决策，人工智能将逐步改变各领域的生产方式，推进结构转型。根据人工智能当前的技术能力和应用热度，我们展望了人工智能将如何助力以下六大实体经济领域。
 健康医疗，从辅诊到精准医疗
历史上，重大技术进步都会催生医疗保健水平的飞跃。比如工业革命之后人类发明了抗生素，信息革命后扫描仪、微创手术仪器等各种诊断仪器都被发明出来。
人工智能在医疗健康领域的应用已经相当广泛。依托深度学习算法，人工智能在提高健康医疗服务的效率和疾病诊断方面具有天然的优势，各种旨在提高医疗服务效率和体验的应用应运而生。
医疗诊断的人工智能主要有两个方向，一是基于计算机视觉通过医学影像诊断疾病；二是基于自然语言处理，“听懂”患者对症状的描述，然后根据疾病数据库里的内容进行对比和深度学习诊断疾病。一些公司已经开始尝试基于海量数据和机器学习为病患量身定制诊疗方案。人工智能将加速医疗保健向医疗预防转变。充分理解如何应用到各个医疗场景将对未来的人类健康福祉有重要的意义。
 智慧城市，为城市安装智慧中枢
人工智能正在助力智慧城市进入版本。大数据和人工智能是建设智慧城市有力的抓手。城市的交通、能源、供水等领域每天都产生大量数据，人工智能可以从城市运行与发展的海量数据中提取有效信息，使数据在处理和使用上更加有效，为智慧城市的发展提供了新的路径。
在城市治理领域，人工智能可以应用于交通状况实时分析，实现公共交通资源自动调配，交通流量的自动管理。
如今，生产自动驾驶汽车已经在梅赛德斯奔驰等老牌钢铁巨头与科技巨头之间展开竞争。未来无人驾驶也将大幅提高城市整体通行效率，建设综合交通运输体系。
计算机视觉正在快速落地智能安防领域。腾讯的优图天眼系统正是是基于人脸检索技术和公安已有的海量大数据建模，面向公安、安防行业推出的智能安防解决方案。
 智能制造，自动化的下一站
制造业是实体经济的支柱产业。人工智能时代到来，为中国制造计划进一步深化带来了重大机遇，推动中国制造业转型升级。制造从自动化走向智能化。
第一种含义是机器换人，智能化成为当前机器人的发展方向。传统的机器人只是数控的机械装置，不能适应变化的环境。与人类的交互成本也非常高。高精度、高效率、能够主动适应的机器人将能够为制造业中小批量、多品种等场景提供解决方案，使大规模定制化成为可能。
其次，人工智能不仅意味着制造业中完成某一环节工作的实体机器人，也是未来制造业的智能工厂、智能供应链等相互支撑的智能制造体系。通过人工智能实现设计过程、制造过程和制造装备的智能化。智能化将不断赋予制造业新能量，赋予制造业更高效率，甚至带来生产和组织模式的颠覆性变革。
 智能零售，实体店加速升级
零售行业将会是从人工智能发展创新中受益最多的产业之一。在 的带动下，各类无人零售解决方案层出不穷。随着人口红利的消失，老龄化加剧，便利店人力的成本正在越来越高，无人零售正处在风口浪尖。无人便利店可以帮助提升经营效率，降低运营成本。
人脸识别技术可以提供全新的支付体验。《麻省理工商业评论》发布的“全球十大突破技术”榜单中，中国的“刷脸支付”技术位列其中。基于视觉设备及处理系统、动态追踪、遍布店内的传感器、客流分析系统等技术，可以实时输出特定人群预警、定向营销及服务建议，以及用户行为及消费分析报告。
零售商可以利用人工智能简化库存和仓储管理。未来，人工智能将助力零售业以消费者为核心，在时间碎片化、信息获取社交化的大背景下，建立更加灵活便捷的零售场景，提升用户体验。
 智能服业务，“懂你”的服务入口
是建立在信息平台上与我们互动的人工智能虚拟助理。在未来以用户为中心的物联网时代，会变得越来越智能，成为下一代移动搜索和多元服务的入口。在生活服务领域，可以通过对话提供各式各样的服务，例如天气预报、交通查询、新闻资讯、网络购物、翻译等。在专业服务领域，借助专业知识图谱，也可以配合业务场景特性准确理解用户的行为和需求，提供专业的客服咨询。
虚拟助理并不是为了取代或颠覆人，而是为了将人类从重复性、可替代的工作中解放出来，去完成更高阶的工作，如思考、创新、管理。
 智能教育，面向未来“自适应”教育
人工智能对教育行业的应用当前还处在初始阶段。语音识别和图像识别与教育相关的场景结合，将应用到个性化教育、自动评分、语音识别测评等场景中。通过语音测评、语义分析提升语言学习效率。人工智能不会取代教师，而是协助教师成为更高效的教育工作者；在算法制定的标准评估下，学生获得量身定制的学习支持，形成面向未来的“自适应”教育。
目前，一批中国人工智能企业正在蓄势待发改造各行各业。在智能革命的影响下，旧的产业将以新的形态出现并形成新产业。人工智能合实体经济的融合，既是产业的产业化路径，也是传统产业升级的风向标。

 三个层面扩大对实体经济的影响
从经济学的角度，新技术的经济影响要通过全要素增长率来衡量。人工智能有望变革经济发展的基础，对社会产生广泛的、颠覆性的影响，创造出更多经济效益：
第一，提高生产效率
作为一种全新的生产要素，人工智能创造了一种虚拟的劳动力，能够解决需要适应性和敏捷性的复杂任务。传统的自动化只针对特定的任务，基于人工智能的智能自动化将能够灵活解决多领域的问题，提高实体经济运行的效率，降低生产成本，开辟崭新的经济增长空间。
第二，进一步降低交易成本
互联网平台模式通过降低信息不对称，降低了传统经济活动中的交易成本。随着机器学习的引入，可以实现更精准的服务匹配。进一步优化资源分配。
第三，人工智能将带来数据经济
据英国政府测算，年，数据产业将为英国带来亿英镑的增长。只有通过人工智能才能处理分析数据产业的快速发展带来的海量数据。这些数据金矿也将为经济带来不可预测的增长点。
 推动与实体经济融合
世界发达经济体在面临人工智能技术变革时，充分认识到其中蕴含的磅礴力量。人工智能起起落落六十年，本轮人工智能革命终于走出实验室，成为下一轮产业革命的驱动力。政府从战略层面加强顶层设计，企业从底层应用提速发展，布局产业生态。国务院在此前发布的《新一代人工智能发展规划》中，明确表示了中国成为强国的雄心，提出了在年中国在人工智能领域达到世界领先水平的任务。凭借人口和数据的优势，中国在这场全球人工智能革命中有天然的优势。对于中国而言，现在是把握机遇，实现弯道超车的契机。为了释放人工智能带来的经济潜力，各界需要合作推进行业的发展，推动与实体经济融合。
 人才培养，推动技术进步
当前，人工智能领域的竞争，主要体现为人才之争。与发达国家相比，中国在人工智能领域尚存在人才缺陷，其中既包含人工智能领域的专业学术、研发人才，也将包含未来人工智能行业中大量的低技能劳动力。需要建立核心技术人才培养体系，加强人工智能学科建设，加强企业和学术界的人才流通，打造坚实的人才基础，推进产业健康发展。此外，政府还应当创造多元的技能培训计划，并且提高全民的科技素养，甚至制定“终生学习计划”，应对多变的未来。
 加大数据开放，推进数据治理
数据是人工智能产业发展的核心。中国虽然是世界上数据总量最大的国家，但在数据开放和数据交易方面还远未形成生态。
今天，世界各国政府都宣称“信息公开是常态，不公开是例外”，而且正纷纷从“信息公开”走向“数据开放”。政府一方面要加大数据开放，另一方面要促进企业、高校、公共部门之间的数据交换，推动合作及共享，为人工智能的技术发展培育世界一流的土壤。
同时，人工智能的发展也为开发者和政府对于数据治理提出了新的问题，在数据开放和隐私保护之间取得平衡，从而增强人工智能领域的信任。
 加深实体经济领域的场景探索
人工智能的发力需要深度和广度。从实验室到实际应用，人工智能需要迈过商品化鸿沟。十九大报告中在提到“人工智能”时，强调与“与实体经济深度融合”，也正是要推进人工智能在应用层面落地。技术和数据本身需要找到有价值的场景进行应用才能形成产品或解决方案，实现价值。目前我们还处在人工智能的应用早期，已有大量可以与现行人工智能结合的行业与领域。尤其在实体经济，还有许多细分领域需要进一步了解人工智能的能力，对细分行业的流程进行重整，通过数据和应用的不断优化，分场景逐个突破，最终形成人工智能社会的新版图。简介
最近有个需求是与视频聊天相关，之前有看到过腾讯云有视频直播的产品，不清楚是否也支持视频聊天。经过一番查找，发现除了直播的，还专门有一个视频聊天的，于是便下下来研究一下。
这是文档：
这是视频直播工程：__
这是视频聊天工程：__
本文只讨论视频聊天的，下载下来简单配置一下，工程就能跑起来。注册两个账号后，就可以互相呼叫了。这里注意一下，需要开启相机权限，否则会是一片黑屏。界面大概是这样的，会有两个渲染窗口，一个自己的，一个对方的，右边一些操作的按钮，可以操作美颜、切换摄像头等等这里只有自己的窗口。

遮罩与蒙层
工程跑起来以后，就要做一些定制的事情了。需求要求有遮罩和模糊的效果不要问为什么，反正有就是了。遮罩比较简单，直接盖一层就好了。模糊的话，如果要做高斯模糊，就要对视频数据进行处理。首先尝试一下用最简单的盖一层黑色蒙层看一下效果如何。为了方便测试，在右侧加了两个操作的按钮。在布局里面添加了对应的。

遮罩的效果：

蒙层的效果：的黑色蒙层

灰阶、旋转、模糊
从效果上看，蒙层确实差，看来只能从视频数据入手了。翻了一遍文档，终于找到定制视频的方法。 有两种方式可以处理视频数据，来达到想要的效果。
、拦截的相机数据，进行处理后，再传回到。
、自己采集相机数据，进行处理后，传给进行上传。
尝试使用第一种方式，需要调用来拦截相机回调的数据，注意视频数据格式为视频数据格式相关知识可以参考这篇文章《图文详解数据格式》， 而且需要在相机初始化以后调用，否则会失败。
针对视频数据，首先尝试了灰阶化和旋转的修改。
灰阶化：


旋转：注意宽高也要反过来


模糊：
真正的高斯模糊性能要求较高，比较难达到实时的要求，需要使用来实现，这里打算先体验一下模糊的效果，所以选择最简单的方式来实现。为了进行模糊操作，需要先转换为格式，处理完了以后再转换为数据。流程是这样的：     ，这里的采用近似的算法来代替网上找到方法。对于数据转换的方法，可以参考这篇文章《图像与格式互转介绍》，测试了一下，腾讯云的数据是而不是，所以这里采用的是、的转换。


模糊半径：
模糊半径：
模糊处理耗时：  
后续工作
本文使用的都是直接在层进行处理，数据处理起来性能效率很差，界面会很卡掉帧。要真能用于实际的业务，必须要使用第二种方式来进行数据处理，就是自行采集数据，利用硬件进行数据处理，然后提交渲染和传输，方能达到性能与效果的平衡，当然这种方式开发量和质量保证的难度也会相应地增加。
详细代码请查看附件。
参考文献
腾讯云文档：数据格式：与转换：蘑菇街电商技术架构师白辉分享了蘑菇街从导购到垂直电商的转型历程，揭示了电商应如何破解技术架构老旧与业务野蛮增长的难题。
蘑菇街电商技术架构师白辉七公
在发展过程中，蘑菇街“社交游戏化”导购平台的定位导致了数百款轻量级、零碎化的社交游戏使得系统难以维护。而越发复杂的业务生态也使得蘑菇街必须向沉淀用户数据转型。为保持陡峭曲线性的业务增长，蘑菇街搭建出集中化的系统架构，以最低的成本支持众多业务需求的快速交付，以满足在控制开发与维护成本的基础上快速响应产品需求。
此后，在业务量激增带来的挑战下，蘑菇街自研等新的中间件，并对服务框架进行了配套升级，以保证产品迭代速度和平台稳定性。白辉称，当电商业务体量达到几百亿调用量的阶段，基础服务中间件的改造就至关重要。在引入系列中间件之后，蘑菇街获得了业务层面上的解耦，商品、交易逐步完成服务化，创造了基础的用户服务、交易服务以及支付服务，并针对不同的业务保障级别搭建相对应的链路集群，保证流畅稳定的客户体验。年，蘑菇街的服务可用性达到了。
 而在从垂直电商转型为电商平台的新战略阶段，电商平台的技术架构需向更深层次的积木式、无状态、云化发展。利用、、小程序等前端组件和后端的数据做灵活绑定；关注不同平台的定制化需求，增强平台隔离性的能力；搭建有灵活数据组装能力的后端，在应用层搭建配套的技术框架体系，增强灵活编排的能力。白辉表示，过去，蘑菇街一直致力打造服务自身的私有电商云；未来，蘑菇街将开放自身云的和部分层能力。作者：

本地模式
 
 
使用的外网这个是可以支持的
测试：
 执行
    
    
 
创建队列
：队列名字，在单个地域同一个帐号下必须唯一。 
队列名称是一个不超过个字符的字符串，必须以字母为首字符，剩余部分可以包含字母、数字和横划线


进行了简单的测试，队列名称都是符合文档规则
发送消息


批量发送消息
消息正文。表示这一批量中的一条消息。目前批量消息数量不能超过  条
 
这块有个问题就是：都是编译成功了的
自己写了批量发送消息循环，当发送消息数最大值为时候，会直接报异常
当消息数最大值为时候，隔了左右，报出异常
当消息数最大值为时候，等了分钟还是没有报异常出现。直接强制关闭
这块觉得应该可以加一判断，如果消息数据大于的时候。快速报出
在服务器上也进行了测试：
 
接受消息
 用于消费队列中的多条目前最多条消息
 
在可以正常获取到
 
因接受消息时，调用了删除消息的函数故在控制台不会显示
 
不可见消息里面也是没有的
 
同样方法中文字符也是可以正常发送和接收的


每次最多只能发送条消息，个单程依次发条数据
不到六分钟  平均时长：  
接受条数据，在五分钟左右。每条数据
获得消息的速度是比发送消息快一些
以上是在服务器上手动配送脚本测试的
如果我公司想要使用该中间件=的话，由于保证了绝对的一致性，在对交易数据是很有必要的。但是流量数据相对来说不需要完全保证一致性，丢很小一部分的数据也是可以接受的。毕竟效率会很快。
备注
今天收到腾讯云  产品经理针对文章里的问题特意发来的邮件回复：

同时谢谢腾讯云提供的内测体验资格！

相关推荐 腾讯云分布式高可靠消息队列架构 消息队列概述 消息服务当前浏览器不能支持视频播放，请采用或以上浏览器
大家好，这节课，我们来看一看负载均衡的最佳实践。
虽然说我们明白了，负载均衡是什么和能干什么，但是想要真正用好负载均衡还是差一些火候，这里，我们来给大家介绍一些负载均衡的最佳实践。
双向隐藏

双向隐藏基于私有网络来进行构建，实现了如下功能：

当云服务器集群需要出访公网时，配置路由表并通过一个  网关进行  转发。对于  上的资源来说，请求的地址始终为  网关的公网，上的资源对后端服务器集群完全无感知。

当上的资源访问云服务器上的服务时，必须通过统一的负载均衡服务进行访问。负载均衡器负责将所有请求使用一定的策略分发到后端的服务器上，对后端服务器集群完全无感知。


简单的来说，就是进出各一个，减少暴露在外侧的，给用户展示的是一个完整的黑匣子。
在这种情况下，我们需要将我们的云主机放在私有网络，同时在外侧部署一个负载均衡器，负载均衡将请求分发到两台云主机上，对外只显示负载均衡器的。同时，在私有网络内设置，所有的流量都通过网关流出，这样保证对外也只有一个，这样的情况下，就保证整个应用，对外，只展示一个
流量分发

流量分发是最常见的使用场景。用户通过负载均衡访问云主机，负载均衡将海量的用户请求分发给不同的云主机。这种情况下，云负载均衡 和云主机构建了一个高性能的接入层，即使存在海量请求，也可以正常的处理请求。负载均衡将保证请求会均匀的转发到每一个接入层服务器，接入层服务器可使用廉价的、配置一致的虚拟机，或容器来承载。
横向拓展

在这种模式下，负载均衡作为对外的唯一，可以保证接入层可以方便快捷的横向拓展，用户可以根据自己的需要，调整接入层的业务机器的数目，方便云主机对外提供服务。在调整的过程中，可以保证业务不停止。新增主机只需要在负载均衡中添加后端服务器即可。删除主机也只需要先删除负载均衡中的后端服务器配置，再删除云主机即可。
拓展阅读：
负载均衡 的最佳实践 ：私有网络快速入门：网关：

相关推荐
免费为您提供最佳上云实践机会借助腾讯云开启全站及问题解决分享导语 通常情况下，我们难以注意到运行着的  程序内  的实例化情况。这些字符串的创建，销毁的时机是否合理，是否存在有重复 相同内容的字符串，冗余 存有已不再有意义的垃圾字符，低效  远大于 ，以及泄漏 没有在期望的时机及时销毁 的情况就更容易被忽视了。

在最近的开发中，遇到了一个关于的问题，使用自制工具，可以发现  游戏运行时  内有大量重复的字符串，如下所示：

手动 
对  特性有了解的同学，应该知道  同  一样，提供了一套内建的   机制，能够在后台维护一个字符串池，从而保证让同样内容的字符串始终复用同一个对象。这么做有两个好处，一个是节省了内存 重复字符串越多，内存节省量越大，另一个好处是降低了字符串比较的开销 如果两个字符串引用一致，就不用逐字符比较内容了
但是为什么上面的  程序内仍然有大量的重复字符串呢？
查看他们的地址，发现彼此各不相同，说明的确没有引用到同一块内存区域。由于  语言实现以静态的特性为主，俺推测，也许只有编译期可以捕捉到的字符串 也就是通常用字面字符串   来构建时 才会 。
做个实验吧：
  = 
  =  

 ==  
 
 运行上面的代码，输出结果分别是  和 。嗯，也就是说，即使运行时内容一样 == 返回 ，手动在运行时拼出来的字符串也不会自动复用已有的对象。查看游戏代码，发现很多重复字符串是通过解析   或   构造出来的，这样就解释得通了。
手动  一下试试吧。
  = 
  =  
  = 
  =  
  = 

 ==     
 ==     
 ==     
 ==     
   
   
   
   
注意， 并没有提供“清除已经  的字符串”的接口。也就是说，如果不由分说地把产生的字符串都扔进去，会造成大量短生命期字符串 如某个地图上特有的特效名 在全局池内的堆积。解决这个问题并不难，手写一个可清除的版本就可以了。
可清除的   
下面的  类除了提供两个与  和  一致的接口外，还提供了  接口用于周期性地释放整个字符串池，可在地图切换等时机调用。这个类通过判断参数来确认，是将字符串放入全局的系统池，还是支持周期性清理的用户池。
 
 

  
{
      =            
                  
           =   
    {
          == 
             

          = 
          = 
             

         
        {
                    
            _ 
             
        }
        
        {
             
        }
    }

            
                    ``
              
    {
          == 
             

          = 
          = 
             

         _  
             

         
    }

           
       
    {
        _
    }

        
      
        _ =       
}
 通过参数  我们可以指定使用默认  还是 。显式地指定后者的字符串将可被随后的  清理。
效果
使用上面的机制在关键点加了几行代码简单地优化后，内存中的字符串从  条降低到  条左右 仍有很多重复存在。

小结
直接写在代码里的常量字符串 即所谓的   会在启动时被系统自动  到系统字符串池；而通过拼接，解析，转换等方式在运行时动态产生的字符串则不会。避免在  代码里写多行的巨型  ，避免无谓的内存浪费。常见的情况是很大的  代码块，很密集的生成路径，大块  等等，见下面的例子。已经被自动或手动  的字符串在之后的整个生命期中常驻内存无法移除，但可以使用上面提供的  类实现周期性的清理。
下面是一些不合理的常见的代码内的常量字符串的情况 都是常驻内存无法释放的
  =   
     
      = 

 __ = 
      = 
            
              
             
        
             
        
    


  =   { 
    _ 
    _ 
    _ 
    _ 
    _
}作者：
团队：移动品质中心

导语
如果你和我一样对单元测试感兴趣，如果你对单元测试的重要性有困惑？如果你对如何开展单元测试无所适从？如果你和我一样，在互联网的今天要求测试全栈，感受压力山大，又想要快速上手单元测试，那么本文可以帮助到你。通过这段时间对单元测试的学习，结合自己在项目内部实施单元测试得到的一些启发，期望本文可以抛砖引玉，为我们系统地理解单元测试提供可借鉴的信息。
本文首先从理论层面对单测进行理解，包括澄清自己对单测的误解以及解惑单测的意义既然要开搞，必须要真正认同并系统认识它；接着结合自己的实际工作，阐述了单测是如何开展的。本文所涉及的内容，仅仅是个人的片面见解哈，如有表述欠妥的地方，欢迎指正，谢谢！
一、一起来认识单元测试
从不同的角度，测试有着不同的分类。而从研发过程主要强调发布前的研发过程来划分，主要包括单元测试、集成测试、系统测试、回归测试。这种测试是软件全生命周期持续不断的事情，并不是一个阶段性的事情。尤其要注意的是，这种测试都有自己的侧重点，如下图所示：

从上图可见，单元测试是软件测试中第一个测试阶段，是软件测试的基础。因此，单元测试的效果会直接影响到软件的后期测试，最终在很大程度上影响到产品的质量。今天就来详细聊聊单元测试。下面分别从单元测试的概念，单元测试的理解误区，单元测试的意义三个维度来阐述下单元测试。
、单元测试的概念
教科书式单元测试的定义是：单元测试是对程序代码单元进行函数级别的测试，是面向最小软件设计单元的验证工作。它是软件最小组成单位的测试，是软件开发过程中的最基本的测试。它处在软件开发过程中实施的最低级别的测试活动，即检查单元程序模块有无错误。它是在编码完成后必须进行的测试工作，也可以称之为模块测试。
于我而言，单元测试不仅仅是写单测代码。实际上，它的手段是多样化的：你可以通过现成的工具检查单元是否正确，可以通过人工检查单元是否正确，当然你也可以编写测试代码来检查单元是否正确，等等。这些方法，我觉得可以统称为单元测试。在实际项目实践中，我们可以灵活使用这些方法。关于这点，在后面的单元测试策略里面也会提到。
在传统的应用中，单元测试集中在最小的可编译程序单位——子程序如模块、子例程、进程；在面向对象软件中，最小的可测试单位是封装的类或对象。它的目的在于检验每个软件单元能否正确地实现其功能，满足其性能和接口要求等。
、单元测试的误区
很多人对单元测试的执行存在误区，包括我自己。常见的单测误区可以归结为以下种：

第一，浪费的时间太多；
一旦编码完成，开发同学就会迫不及待地进行集成工作，而实际上系统能正常工作的可能性很小，更多情况是充满了各种。这些包含在独立的单元里，其本身也许很微小，但在集成后去修复它却会加倍开销。在等大型公司，每写一行程序，都可能要测试很多遍。由此可见单元测试是应该受到重视的，绝对不能认为这是在浪费时间。
第二，软件开发人员不应参与单元测试；
理论上，单元测试需要和编码同步进行，即每完成一个模块就应进行单元测试，确保其能实现相应的行为或功能。在对每个模块进行单元测试时，我们不能完全认为其单元独立，它极有可能和其他模块存在直接或间接的逻辑上的关系。若仅由测试人员进行单元测试，往往周期长，耗费大，事倍功半。因此，站在测试人员的角度，我们鼓励开发同学担负起程序的单元测试，在测试同学的辅助下，争取事半功倍。
第三，我是很的码农，不需要进行单元测试；
如果我们真正很，就应当不会写出，但这只是一个神话。缺乏测试包括开发自测的代码可能包含许多，甚至因为修复而引入新的，如此便会恶性循环。为避免产生恶性循环，代码必须有一张安全网来保护，随时进行的单元测试就是这张安全网。
第四，不管怎样，集成测试或验收测试将会抓住所有的；
集成测试的目标是把通过单元测试的模块拿来，构造一个在设计中所描述的程序结构，通过测试发现和接口有关的问题。在实际项目中，我们或多或少遇到过提测后的软件不可测，有的甚至导致系统崩溃或是死机。回归测试时又发现新的问题，使得测试工作很难开展或进度缓慢。最后只能忍痛加班，得不偿失。这种不通过单元测试将所有模块预先结合在一起，作为一个整体来进行测试，过程往往是苦不堪言。
第五，单元测试效率不高；
实践证明，缺陷发生到被发现之间的时间和发现到改正该缺陷的成本是指数关系。频繁的单元测试能使开发人员排错的范围缩得很小，大大节约排错所需的时间，同时错误尽可能早的被发现和消灭会减少由于错误而引起的连锁反应。在《实用软件度量》，—一书中，有数据显示，针对某一功能点上进行准备测试、执行测试和修改缺陷的时间，单元测试阶段的成本效率大约是集成测试的倍，系统测试的倍如下图所示。

、单元测试的意义
单元测试非常重要。有研究证明，单元测试可以发现整个软件开发过程中的的缺陷，其价值不容小觑。而下图也从四个方面凸显了单元测试的重要性。

单元测试要写代码，因此不论效率高低，手速快慢，总是会占时间的。所以如果只是考量开发时间的话，开发的时间肯定会延长。但是如果把考量的时间长度延长到开发自测测试上线线上反馈，那单元测试带来效率方面的益处就能体现出来了。另外，个人认为：单元测试是构筑产品质量的基石。我们不要为了节约时间放弃单元测试，这会在后期花费加倍的时间来弥补。尤其是，任何软件开发团队都不愿意因为节约了早期单元测试的时间，而导致开发的整个产品失败或重来。
二、如何开展单元测试
上面说了很多单元测试的好，那单元测试方便开展吗？该何时开展呢？本质上，单元测试是针对代码进行的测试，其工作量和难度都比较大。在时间上，单元测试的开展是越早越好，应该与编码同时进行，最好在提测之前完成。教授利用’理论，发起了一个关于单元测试实践的调查。调查对象来自于全球个公司里面的个代表，调查的主题围绕”单元测试的定义，应用单测的优势和劣势困难”展开，最后归纳得到了一些结论。我就直接窃取他的结论如下表，希望对我们有一些参考意义。关于调查详情，参考文献：《    》。

注：’ 理论是从个方向进行问题分析。对表格内容的简单归纳如下：
单测的定义：他们认为单测是针对最小单元或单元集进行的结构化测试，而且单测最好以自动化形式呈现，由开发同学来主导实现，可以针对整个展开；单测必须要快速运行，并及时查看结果，保障被测功能的正确性。
开展单测的优势：单测开展后，识别系统的单元便于理解单元的功能细节，有助于我们深刻地理解系统各个单元间的逻辑关系、时序关联以及功能依赖。而且，单测运行在整个系统环境下，可以快速发现其它模块的变化。目前也存在一系列的单测自动化框架，它们方便单测的展开，特别是遇到连续的回归测试时，自动化的单测收益更明显。另外，部分商业安全要求的软件对安全标准有要求，也需要开展单测。而针对敏捷开发，单测用例集可以作为技术说明文档沉淀。
开展单测的困难：针对测试，单元不独立、大数据结构的被测对象展开单元测试非常困难所以我们尽量选择逻辑层、比较独立的单元进行单测。如果单测的代码量很庞大，后续的维护也很困难。
需要说明的是，单测实现需要涉及文档化的工作，而且框架不是直接拿来就可以用的，可能需要适当的裁剪。在回归测试阶段，单测用例集的选择没有明确的方法论。在单测的效果度量方面，目前还没有合适的模型。瓶颈点在于，单测对测试人员的能力要求非常高，有时候只能是开发自己决策。
此外，单测做到何种程度可以停止也没有明确的或者可借鉴的标准，这需要公司内部针对不同的产品进行测试积累和经验沉淀。
还有就是，单测的投入成本和带来的收益无法估算或量化。这些都是开展单测可能面临的困难，也是单测缺少驱动力的原因吧。
、单元测试开展六步法
开展单元测试有它的优势，也有它的劣势。那么在实际的项目中，应该怎样比较恰当地开展单元测试呢？如果你所在的团队准备要开搞单元测试了，下图是根据我的理解总结了六个主要步骤：

第一步，环境准备；
单元测试必须要有自己的自动化框架支撑。公司内部推荐使用。
必须和开发确认好单测代码的管理方式。有两种方法。方法一：新拉一条分支线管理，和开发线代码保持同步；方法二：与开发共用一条代码线，新增加工程的方式。各团队需要根据自己的团队特色进行合理的选择。但是，不论选取哪种方法都需要新增加一个编译选项，专门用于单测代码的编译。
优先确认好助力分析的静态工具。工具能够导出程序的控制流程图，给出程序环路复杂性如复杂性度量等；能够输出单元模块的组成和相互间的调用关系；能够生成单元结构的控制流程图。推荐使用\\。
第二步，开发输出详细设计文档；
单元测试的主要依据是详细设计文档。单元测试需要从程序的内部结构出发设计测试用例。因此，开发同学在进行编码之前一定要树立单元测试意识，输出有指导意义的详细设计说明书这里受限于我们的敏捷迭代，在实际操作中，可以口头沟通以的形式，不强制要求专业的文档化，对被测对象的可测性需要重点考虑，便于单测人员确定重点测试单元并针对性设计单测用例。
第三步，选择单测测试对象；
工作中，我们一般采用测试需求驱动测试方法，需要对重用性高、调用频繁或核心功能的单元模块优先选择。根据八二法则，的代码错误，可能存在于的代码中；这，就是算法密集度高的代码，也就是功能逻辑复杂的代码。我们选择具备这些特色的代码作为单测的对象。
第四步，设计单元测试策略；
在测试过程中，我们应该灵活运用工具代码走查、人工代码走查和功能测试这三种方法。它们的有效组合能提高测试效率，避免很多重复的工作，从而减少测试工作量。尤其在测试资源极为有限的情况下，这种方法的性价比高，可以达到较好的测试效果。
运用工具代码走查方法中，白盒测试工具对代码进行检查是一种代价很低的测试方法。在选定要检查的规范后，整个检查过程只需几分钟。我们使用了以及自研的一个小工具该工具专门针对代码书写或使用的不规范进行检查，挖掘可能存在的资源泄漏，感兴趣的同学可以联系提供技术支持。
人工对代码进行走查，可以静态走查，也可以动态走查调试。人工走查主要依赖于个人技术和经验，建议成立走查小组来覆盖开发和测试同学。走查发起人可以是当前迭代的开发负责人。他她负责对走查会议进行良好的策划和组织，不需花费太多的时间，但可以达到很好的效果。
功能测试是代价最高的测试方式。它可能面临多次回归测试，周期较长，而且需要测试人员编写维护测试驱动程序和桩程序，对测试人员的编程能力也有一定的要求。除此之外，它对测试用例的设计和维护也是一项很繁琐的工作。因此，功能测试需要和前两种方式搭配好。
第五步，设计单元测试用例编码；
单元测试可以从单元功能、单元接口、数据结构、语句／分支覆盖等维度进行单元函数测试。对单元功能的测试是保证单元模块具有完成符合设计要求的功能；对单元接口的测试是保证在测试时进出程序单元的数据流正确；对数据结构的测试是保证存储的全局数据、局部数据在算法执行的过程中的完整性；对语句分支覆盖的测试是保证单元函数在极限边界条件能够正确执行函数的每条语句和每个分支，消除无用代码。单元函数是由各种语句组成的程序代码，对各种语句测试用例的设计是单元测试的关键。关于单元测试用例的设计，在小节会进行详细的介绍。
编码工作是在设计好单元测试用例后立即开展的工作。理论上开发同学完成一个函数的编写，对应的单元测试也应该准备就绪，这样才能发挥单测的最大效果。但在实际操作过程中，我们期望单元测试的编码工作需要在整体功能提测之前完成。
第六步，单测效果验收；
度量单元测试的效果收益目前业界还没有一个公认的模型。结合我们的项目实践，这里的可以参考花费时间，可以参考覆盖率贡献度、迭代周期的长度、测试独占时间的占比、提测后千行代码的缺陷率以及线上质量包括和用户反馈等。这些数据之间的关联模型目前还没有。单测过程采用覆盖率工具，这个是毋庸置疑的，否则用例执行后无法对被测对象做进一步的分析。推荐免费，且操作简单，桌管内部的也是可以的，目前正在内测阶段，届时上线也欢迎使用。
、单元测试用例设计方法
在实际开发中，每个编写代码的人都自觉或不自觉、或多或少做过所谓“单元测试”，如编码规范、逻辑功能检查、编译查错和调试等，但是这些还不能算严格意义上完整的单元测试。无序或无组织的所谓“单元测试”，容易造成对单元测试认识的偏差，难于提高软件单元的质量。单元测试到底该该如何设计明确单元测试的测试内容和范围，这是单元测试的基本要求。
进行有计划的单元测试，应根据需求和详细设计文档的要求。如下图所示的类测试项将是我们在实施单测时需要考虑的内容：

在实际项目实践中，使用者可以根据自己的项目复杂度以及需求，挑选其中的进行参考。
三、单元测试实践
前面两部分洋洋洒洒说理论，终于把我认为的单测里面几个核心的要点讲完了，也算是对单元测试有了基础宏观的理解。这部分就是理论到实践了。在拿到被测对象后，我将重点介绍如何选择单测对象，以及如何设计自己的单测用例。
、单测对象的选择
按照我们_描述的方法，尽量利用工具辅助我们分析。
首先，利用工具得到单元模块间的关系。我们的工程比较简单，该功能的重点类是和，因此主要是针对这两个类进行单测且这两个类是本次修改的。

其次，利用代码度量工具对目标模块进行了度量。按照圈复杂度进行排序，我们得到并选择圈复杂度高的文件，如下图：

和的复杂度分别是和。需要说明的是，上图有其它复杂度高的，但不是本次需求变更的范围。本例中，我们重点进行差异测试。将上面两个类详细展开看，如下图由于篇幅原因，仅截取部分内容：

接着，我们选择圈复杂度以上的函数进行筛选。依据重要性、重用性、和可测性选择待测对象。
最后，邀请开发同学，发起单测对象评审，确定被测函数对象。
、单测用例的设计
对单测函数列表的函数分优先级，逐个进行单测用例设计。这里以函数为例。该函数的功能主要用于实现添加桌面快捷方式位置的监控。根据该函数的程序流程图如下使用工具绘出：

针对该单个函数，我们使用了基本路径、判断条件、数据划分和边界值四种基本的方法进行用例设计：
基本路径：按照逻辑结构的路径分支进行覆盖，得到如下的条：
第一条：
第二条：
第三条：
第四条：
第五条：
第六条：；
判定条件：对复合两个以上的判定条件进行用例设计， ||  == \ ||  ||  ==\ ||  ||  ==\，使用判断条件的用例设计方法覆盖所有条件，得到如下的条：
第一条：为空指针，和均非空；
第二条：为空串，和均非空；
第三条：非空，为空指针，非空；
第四条：非空，为空串，非空；
第五条：和非空， 为空指针；
第六条：和非空， 为空串；
第七条：，和均非空。
数据划分：也就是使用等价类划分法对输入数据进行划分上面的已经覆盖，有效字符串和无效字符串划分。
边界值：不涉及。
由此可见，针对函数可以设计条来覆盖基本路径和判定条件存在交叉。
四、总结
可能大家会有疑问，最开始不是说单测由开发同学来实现最合适吗，怎么最后还是测试同学来主导了？但是现实总是很残酷，这个推行起来的确困难重重。正所谓，己所不欲勿施于人。新政策推行前只能先推己，再及人。我们选择奉行这个观点。只要是为了把质量做的更好，我们多做一点又有何妨？再者，面对严峻的行业形势，这正是一个很好的机会来提升我们的能力，我又何乐而不为呢？
从单元测试的效率角度来考虑，开发人员的知识结构、对代码的熟悉程度，这两方面他们都具有一定的优势；而从单元测试效果的角度考虑，测试人员又具备了他的天然优势。首先，从目前我国实际现状来看，测试人员质量意识要高于开发人员，测试人员参与单元测试能够提高测试质量；其次，对被测系统越了解，测试才有可能越深入，测试人员参与单元测试，将使得测试人员能够从代码层面熟悉被测系统，这对测试组后期集成测试和系统测试活动非常有帮助，会很大的提升集成测试和系统测试质量。因此，单元测试这件事情不能绝对地说由哪种人来做。一种比较被认同的观点是：在允许条件下，由测试和开发共同来做，测试负责制定规范、培训并检查测试效果，开发负责具体的实施，最好是边开发边测试。如果能达到这样的配合，应该是最能实现单元测试的效果与效率上较好的综合和平衡。
总的来说，单元测试应该不仅仅是白盒测试，可以结合黑盒、灰盒，利用静态、动态结合。不仅仅是人工执行，也需要工具和自动化，未来期望可以可视化自动生成单测用例。据说 ，简称，就是一款可视化的单元测试工具，还没来得及用，抽空可以试一下。此外，单元测试收益的模型也将是后续的研究方向。
综上，文章主要阐述了单元测试的重要性，以及如何比较正确地在项目组内部开展单元测试，所述内容也只是单元测试的冰山一角。后面还需要更多的实践来丰富自己的认知，期待有大牛们的指导！
单元测试的要领你到了吗？
获取更多测试干货，请搜索微信公众号：腾讯移动品质中心！写在前面：在个别时候可能需要查看当前最新的事务 ，以便做一些业务逻辑上的判断例如利用事务  变化以及前后时差，统计每次事务的响应时长等用途。
通常地，我们有两种方法可以查看当前的事务 ：
、执行    ，查看事务相关信息

=====================================
    
=====================================
        



     当前最大事务 
            
   
     
     该会话中执行    ，不会产生事务，所以事务  为 
              
    
    非活跃事务，还未开始
      
               
 _  __ 

   
               

          活跃长事务，运行了  秒还未结束，要引起注意，可能会导致大量锁等待发生
      
            
               
  __ 
、查看 __、_、__ 三个表，通过这些信息能快速发现哪些事务在阻塞其他事务
先查询 _ 表，看看都有哪些事务
    __\
   
 _   当前事务 
 _    处于锁等待状态，也就是等待其他会话释放锁资源
 _  
 ___   欲请求的锁
 __  
 _   大意是该锁影响了  行记录
 ___    中的线程 
 _  _  =  = 
 __   
 ___ 
 __ 
 __ 
 ___ 
 __ 
 __ 
 __ 
 __  
 __ 
 ___ 
 ____ 
 ___ 
 ___ 
 ___ 
 ___ 
    
 _ 
  _ 
 _  
 ___ 
 __ 
 _ 
 ___ 
 _ 
 __ 
 ___ 
 __ 
 __ 
 ___ 
 __ 
 __ 
 __ 
 __  
 __ 
 ___ 
 ____ 
 ___ 
 ___ 
 ___ 
 ___ 
再看 _ 表，看看都有什么锁
    __\
   
_  当前锁 
__  该锁对应的事务 
_   锁类型，排它锁 
_  锁范围，记录锁： ，其他锁范围：间隙锁： ，或者  记录锁间隙锁
_ ```_`
_  加载在哪个索引上的锁
_ 
_ 
_ 
_ 
   
_ 
__ 
_ 
_ 
_ ```_`
_ 
_ 
_ 
_ 
_ 
最后看 __ 表，看看当前都有哪些锁等待
    ___\
   
__  请求锁的事务 等待方
__   请求锁 
__   阻塞该锁的事务 当前持有方，待释放
__   持有的锁 
关于 _ 中和  有关的表用途描述，可以查看手册： _   
、利用  分支的特性，查看当前最新事务 ，该特性从  版本开始引入，执行下面的  个命令即可查看
  |  ___
或者
     ___
最后，交代下问题的来源其实是这样的，有位朋友和我讨论问题，说在  连接池中，发现  个事务的事务  是一样的，测试的  代码：
   =  =   __     =  =   __
这串代码不能折行，中间的  停留 不能太大，也就是模拟足够快的情况下，检查  次事务的  是否有变化。可以发现，时间足够短的话， 次查询到的事务  是一样的，并没有发生变化。大家也可以在自己的环境下试试。 简介
 是  公司  年推出的前端框架，是一个  组件，主要负责将数据展现给用户，不带任何业务逻辑，所有显示的数据都是通过属性来提供，它允许将代码封装成组件，然后像使用普通  标签一样使用这个组件，大大提高了代码的复用性，也便利了团队的分工与合作。
 有用的知识点
 安装
 的安装包可以去官网下载，在使用的页面直接用包含就可以了，一般要包含 ，， 或者  等，但是在实际应用中会在服务器部署  进行转码。
 语法
 使用 ， 是一个类似  的  语法扩展，使用  执行更快编写模板更加简单快速。
组件形式
 允许将代码封装成组件形式，这个组件可以像普通的  标签一样被  结构引用，它们的区别是通过首字母大小写来区分的， 标签使用的是小写的字符串，而  组件使用大写开头的字符串。
  =  {
       
    
       ={}
            ={ }
       ={}
                      ={ }
    
  
}
上面代码中  和  都是自定义的组件，首字符都是大写。
 和 
 可根据用户与应用网站的交互来改变，当用户与网站应用进行交互，会得到不同的 ，不同的  会触发更新用户界面和数据。 是组件的属性，它不可更改，只可读，用来传递数据，如上面例子中的 ={}。
 方法
 方法是组件唯一一个必需的方法，它会创建一个虚拟 ，用来表示组件的输出。需要注意：

只能通过  和  访问数据；

只能返回一个节点，如：


  = {
  {
    
      
     
   
}
}
上面的方法是错的，因为有两个节点，正确的写法如下：
   = {
  {
    
   
      
     
   
   
}
}
组件的生命周期
组件分为已插入真实 ，正在被重新渲染，已经移出真实  等三个状态。 为每个状态都提供了两种处理函数， 函数在进入状态之前调用， 函数在进入状态之后调用，对应的方法有：


   
   

一个简单的弹窗组件
   { }  
 
   = {
    
    
 }
     {
   {
   = 
   = 

      =
           =
           =
             = ={}
          
          
   }
 }
  = {
    
 }
  = {
    
 }
   导语：这是一篇力争让所有人都看懂的云计算短文。



个人介绍：柴大木， 年加入腾讯，负责 ， 等内部重要基础平台的运营。具有接近  年的微软技术经验，之前在微软卖过  公有云，最近从  跳到 ，从  跳到 ，与小伙伴们一起，为  贡献力量。

云计算像自来水么
我相信，大多数人在听到云计算时，总是会听到一个比喻，说云计算像自来水，我认为这个比喻还是蛮贴切的。云计算的一个初衷就是希望计算能够像电和水一样，变成一种普遍普通的资源，随时可用，唾手可得。使用云计算与我们使用自来水的情况非常类似：首先，当我们把水龙头打开的时候，水立刻就流淌出来了，这与云的快速敏捷相对应，在公有云上申请的资源一般可以在  分钟内就绪，这与传统的从购买服务器开始的资源准备模式简直是云泥之别。同时，需要多少水是我们自己决定的，随时可以将水龙头开大关小来满足需求，云计算的弹性伸缩与其对应，资源可以快速的按照所需扩展或缩减；最后一点，就是水费，使用多少水，就付多少水费，云计算也是一样。，内存，磁盘空间，流量，以及各种你能想到的和想不到的东西，统统具有一个基础定价，用掉多少资源，就付多少费用，童叟无欺。我认为，不能提供完善资源基础定价的云，都不能算做一朵优秀的云。

如何玩转云计算
在互联网时代，想法的产生极其迅速，如何用低廉的成本快速试错，则成为制胜的关键。 就具有如此的前瞻性，在云计算发展初期就开始使用云计算的特性来节省运营成本并快速试错了。
 上有很多应用，它们一般会被先放到公有云上进行运营，一段时间后根据实际表现情况再决定下一步的动作，这样做有诸多好处：
首先，就是上线速度快，不管放在欧洲，美洲，还是亚洲，速度都一样快，他们并不需要去亚洲自建机房来承载服务，而是选择直接就近使用公有云资源。产品完成后很短的时间内，就可以在全球发布，这种敏捷灵活在互联网时代是至关重要的。
其次，就是云的弹性扩展，因为没人知道这个应用到底会不会火。一般来讲，应用会面临三种情况，第一种情况就是爆发增长后回落，并保持平稳很长一段时间，类似开心农场，云可以发挥弹性扩展的优势，用户激增就扩容，很好的应对最火爆的那段时间，当趋于稳定后，就逐步缩容，并考虑是否把这迁移回自己的私有云上继续运营。第二种情况，就是爆发增长后，快速消亡，类似围住神经猫，短期内异常火爆，但在几周后，就彻底消亡了，这种情况云也可以很容易的应对，火爆时扩容，消亡时关闭。第三种情况，没有什么爆发，不久直接消亡，可以参考任何一个策划失败的例子，而对于这种情况，云依旧可以应对自如，当决定终止时，直接关闭就好了。
最后，就是与弹性优势息息相关的价格，用多少资源，付多少钱，对于失败的案例，云上运营的费用极其低廉，所以使用云，给  带来了极大的成本优势。  

当今云版图
公有云
这是  年的公有云 基础架构即服务的魔力象限图：

亚马逊 ，当之无愧的行业龙头，以其强大的创新能力、极高的敏捷性成为公有云用户最稳妥的选择。
微软 ，在新的  纳德拉上台后，发展更为迅猛，正在逐步缩小与亚马逊  的差距，并且其在私有云中同样具有很强的竞争力。
谷歌，正在成为第三个公有云领导者，其具有众多的数据中心，注重可移植性及创新引擎，有望在未来获得成效。
阿里云，最近一段时间，阿里云的发展势头非常凶猛，一跃成为除前三外的佼佼者，但其取得的成绩基本都在中国本土，在中国之外的市场，表现平平。
，基本已经退出公有云市场，已经从最新的魔力象限中消失，但其正在与  合作，以相互取长补短的方式进军混合云市场。
私有云
，以其早期的易用性和后续不断的发展，积累的大量的用户，仍旧是当今市场占有率最大的  虚拟化基础设施提供商。
微软，一直在追赶 ，同样发展着私有云，从早期的  ，到当今发布的大杀器  ，其实微软一刻都没有停歇。  是一套直接落地的私有云产品，连接电源和网线后，只需要一个  帐号，即可完成自动化部署。
 阵营
 最大的优势在于开源以及开放性，在近几年快速崛起，成为重要的私有云解决方案，很多大厂商也在其社区贡献力量，例如腾讯自己的基于  开发的  也正在快速成为政府及企业的私有云解决方案。
混合云
我认为，混合云的局势相对明朗，从巨头上来讲，就是   对抗微软自家的   ，这将是从现在到  年底非常有看头的一场对决。在国内市场，腾讯，阿里和华为在混合云发展上都已经具有较为明确的发展目标，就看谁能更快的形成规模并占据主要市场。
云的发展，真是非常迅猛，大概  年前，我参加过一个微软的会议，当时微软展示了用  写的控制面板，实现了几台服务器上虚拟机的启动，关闭，性能监控，租户网络隔离，计费等基础功能，当时微软的意思是希望合作伙伴来架设公有云，将微软的生产力工具做成软件即服务的模式，来租给客户使用。当然，在那个时候，没有合作伙伴买账，谁也不愿意去吃个螃蟹，所以微软铁了心要自己来运营公有云，这么多年过来，微软稳居第二。现在想想，当时我看到的那个异常简陋的控制面板，就是现在微软公有云的雏形，就像看着一个丑小鸭变成了白天鹅，让人感慨不已。
云稳定么
今年初，亚马逊和微软的公有云就接连出现故障，尤其是亚马逊那次故障，导致  等很多网站无法访问，相关网站的程序员束手无策，因为他们发现，应用的前端在云上，数据库在云上，连管理工具也在云上，所以除了等待亚马逊恢复外，并没有什么可做的。所以针对这种情况，我们就得思考一下，如果把应用放在云上，如何避免这种束手无策的情况，保证业务更高的可用性？
方案一，混合云。把前端放在公有云上，后端数据库放在自己的私有云上，当公有云宕机的时候，我可以把应用快速切换到私有云上继续提供服务。然而混合云的维护成本会变高，并且与公有云的连接，一般是公网 ，速度不稳定，可能会成为带宽瓶颈，为了应对这个瓶颈，部分公有云提供了直拉专线到公有云机房的方式来形成混合云，这个成本就很可怕了。
方案二，多个公有云。一个宕了不怕，还有另一个。几个月前，微软与阿里的公有云一起进行了一项测试，让两个公有云连接成一体来提供服务，测试是成功的。同样的，可以进一步提高可用率，但会增加管理和运营成本。
当然，公有云的整体可用性仍旧是非常高的，公有云一般在全球具有众多的数据中心，而出故障也仅限于一个数据中心，所以平均下来，总是能达到他们承诺的可用率。在选择时，除了重要服务需要有备用方案外，普通服务基本可以放心使用公有云。
云安全么？
很多用户在谈到公有云时，总是因为担心其安全性而进行全盘否定。而从我的观察来看，公有云的安全性远远高于自建机房或者托管计算中心。举个例子：
位于深圳的某计算中心，我之前有去过一次，其宣传材料上有列举出各种参观情况，以及接受组团参观的话语。也就是申请参观的人员可以进入机房，并进行相关的活动。与之对应的是某公有云的云计算中心，某个大客户购买了海量的云计算资源后，提出了一个额外请求，希望参观下公有云计算中心，结果遭到拒绝，理由很简单，数据中心的安全规范禁止一切参观活动，禁止无权限人员进入数据中心。
当然，我想大家都清楚，企业中总是有些数据，只能放在自己家里，这种用户就非常适合私有云或者混合云。
身边的云
本文的最后，我想讲一个自己亲身经历的故事， 年前，我在山东老家买了一台康佳电视，当时各大电视厂商都在以云电视为卖点，买回家我立刻就开始了探索，我拿着遥控器，尝试安装一个应用商城里提供的应用，好像是  大小的一个应用，然而点击下载后，就开始了漫长的等待，等了足足有  分钟，才下载了一半，我叹了口气决定继续等待时，下载中断了，这就是当时康佳云电视的体验，我再也没有兴致去尝试第二次了，就仅用作普通电视来看了。 年半前，我在做云计算售前，正好康佳电视就是客户之一，康佳其实也知道自己的云电视体验不好，已经在研究迁移至云的可行性，当时我跟团队一起，给康佳做讲解，演示，测试，协助上线，最终康佳在仅仅修改了少量代码的情况下，将云电视的后台无缝迁移到公有云上。从那一刻起，康佳的云电视，就真的成为云电视了，体验真的是天壤之别，当我再回老家的时候，发现电视整个系统都升级了，不管是下载软件还是做相关的一些操作，体验都极其流畅。
这就是云的神奇之处，不知不觉中，它就已经在你身边了。导语：               ！

初识
 翻译是操纵木偶的人，利用这个工具，我们能做一个操纵页面的人。是一个的库，支持调用的来操纵，相比较或是它最大的特点就是它的操作可以完全在内存中进行模拟既在引擎中处理而不打开浏览器，而且关键是这个是团队在维护，会拥有更好的兼容性和前景。
功能
利用网页生成、图片爬取应用，并生成预渲染内容即“” 服务端渲染可以从网站抓取内容自动化表单提交、测试、键盘输入等帮你创建一个最新的自动化测试环境，可以直接在此运行测试用例捕获站点的时间线，以便追踪你的网站，帮助分析网站性能问题
安装 
  
    
可能会遇到 无法下载 问题
是因为在执行安装的过程中需要执行，这里会下载官网建议是进行跳过，我们可以执行 — 忽略这个执行
    
接下来我们需要去下载，的版本我这里已经下载好了直接解压缩附件中的到 _中就可以了。
执行下我们创建一个文件，文件内容
  = 

  = {
        =  
      =  
     
     { }
    
}
这段代码会打开  并截图，我们运行
  
如果看到目录下有生成图片的话，恭喜你，我们可以开始继续往下学习了。
体验第一个数字专辑自动购买的自动化测试
这里测试的功能是自动拉登录购买一张数字专辑，并在购买成功后跳转到铭牌页，先看下整个流程吧。
首先我们先创建一个设备，文档中我们能看到，默认支持的设备数量还是很多的，除了这些默认的设备之外，我们还可以自定义自己的设备，后面在调用方法时会提到：
我们这里暂时先创建系统提供的设备，完了我们定义一个延时的函数
  = 
  = 
  =  
  =   {
         = {   
            = {   
                   {
                      
                  }   {
                      
                   }
           } 
     }
 }
接下来我们创建一个浏览器实例，并打开一个页面，细心的你一定发现在创建浏览器的时候我们传了参数，如果设为的话就能可以在不打开外部浏览器的情况下完全利用引擎来进行页面的测试，简单说就是页面以及完全在内存中，就连浏览器事件也是在内存中去模拟触发。
   =  {
       这里我设置成主要是为了让大家看到效果，设置为就不会打开浏览器
 }

   =  
创建好浏览器实例之后我们需要让页面模拟成，这里的函数的参数你也可以自定义参数
 
参数
 {
       设备名
                  
     {
       屏幕宽度
       屏幕高度
       缩放比例
       是否是移动设备
       是否支持事件
       是否横屏
    }
  }
好接下来我们就可以写我们的测试步骤了。
第一步我们打开页面，考虑到有数据需要异步加载，我们在延迟后调用方法截图留作日志。

进入页面
 _==_=
 
 {
      
 }
第二步 模拟触发点击 立即购买按钮，这时候会因为没有登录态而打开登录。

点击立即购买按钮
 __
 {
     
 }
第三步在输入框中输入帐号密码，模拟输入需要我们先调用方法模拟点击输入框，参数就是元素再用方法进行输入输入完了之后在模拟点击登录按钮，登录完了之后我们延迟一段时间截图，顺利的话我们就能重新回到之前的售卖页首页，而底下因为有了登录态也展示了出来。

登录
  直接操作选择器，是不是很方便
 

 
 这里密码就不展示了哈

 

 

 {
      
}

登录成功
第四步跟第一步一样，点击立即购买按钮，这里会出现一个购买选择浮层然后我们点击立即支付之后需要加载米大师，故这里我们延迟。

点击购买
点击立即购买按钮
 __

 {
     
}

点击支付浮层上的立即支付
 __

 
第五步在拉起米大师支付浮层之后，我们需要去点击提示中的确定按钮，由于米大师是在中打开的，所以我们需要先获取到我们当前页这个可以调用刚创建的页面实例的方法即可获得如果我们需要获取子的话也只需要调用来进行获取。在获取到米大师对应的之后就可以调用_类的方法进行元素的获取，之后再模拟点击。


进入 米大师支付浮层
 {
      
}

  = 
 _ = 获取到对应的

点击确定 米大师支付浮层测试环境提示 的确认按钮
  =  _ 
 

 {
     
}
第六步：点击币支付

点击 米大师支付浮层 确认支付按钮
 =  _ 
 

 

 {
     
}
第七步点击完成进入铭牌页，测试完毕，关闭浏览器实例

点击 米大师支付浮层 支付完成
 =  _ 
 

 

已购铭牌页
 {
      
}

最后在项目目录中，我们看到，各个步骤的截图都已生成。

体验第二个页面性能检测   
  主要是利用 ，生成页面性能追踪的文件 在 开发者工具中上传该文件，就可以对里面的火焰图去做分析。事例代码：
  = 
  = 
  =  

  = {
          =  

          =  

         

         { }
         _==_=
         

        
    }   {
        
    }
}
首先，这段代码执行的是模拟打开林俊杰的《丹宁执着》数专售卖页，并进行性能的分析。主要使用 ，生成文件


接下来我们打开的开发者工具，进入到栏目下，把刚才的拖上去就能看到数据了
总结
通过上面两个例子，我们看到了可以做自动化测试和页面性能检测，其实他的功能远远不止于此，比如还可以做爬虫，去爬取的文章或是掘金上的博客，总之，自己也是初次尝试，肯定会有更多的功能能够被挖掘出来，希望大家多多交流。本文作者：  

的设计模式是针对于整体代码的设计是否合理，给出了一些具体的解决办法。 而重构代码就是依赖于设计模式而实现的一个必要手段，可以说设计模式就是重构代码的目标，但他的手段却不仅仅只有设计模式这些大而全的，同样存在小而精，我们随处可以使用的。
封装功能块代码
我们通常在写代码的时候，一开始，并不需要考虑太多。在后期可以进行修改和提炼。 比如，我有个业务需求，是创建一个并且渲染数据到页面上并且根据的不同，改变的状态
{
          = 
         = 
        
        {
                 = 
        }{
                 = 
        }
}
但事实上，这个函数里面还有一个代码块，就是根据改变的状态我们可以对其进行封装。
{
          = 
         = 
        
        
}
 {
         = 
}
提取公因式
这里主要针对于，多次重复调用同一个封装代码块函数。
{
        ==={
                
        } ==={
                
        } ==={
                
        } ==={
                
        }
}
根据向反方向移动，可以看出，里面都有用到了这个方法，要知道，分支语句是最不利于程序阅读的，而且我们要尽可能的减少和简化分支语句里面的程序量，让阅读者耗费在分支语句上的时间降到最少。上面代码可以这样写。
{
         
        ==={
                 = 
        } ==={
                 = 
        } ==={
                 = 
        } ==={
                 = 
        }
        
}
恩，当然，这样写也是违反人性的。我们可以使用命令模式进行重构。 这就涉及到另外一个
将分支转化为函数
上面代码里面的分支完全可以使用函数来进行代替。
{
        
}
  = {
          = {
                
        }
          = {
                
        }
          = {
                
        }
          = {
                
        }
         {
                
        }
}
这样，虽然增加了一个对象，但是代码确实清晰可见的。 这就是通过命令模式，来重构代码，完成性能和阅读的优化。 但有时候，使用分支，会比这样更简洁，那当然可以使用分支啦。 而使用分支还要主意一个就是
不要过度嵌套
这里想说的就两点，一是，尽可能不使用分支，二是，如果嵌套分支，尽量改为不嵌套。 不使用分支的情况上面已经说了，如果使用分支，那么请不要嵌套，或者说不要过度嵌套。因为一个分支已经很难阅读了，你再加个嵌套，你还让不让人读了。 而解决过度嵌套的方法真的是千千万万，我这里就介绍一个比较简单的。使用 提早退出嵌套。
 {
        {
                {
                        {
                                 
                        }
                }{
                         
                }
        } {
                 
        }
}
这，看着爽不爽。 如果，我遇见这样的代码，我第一反应就是，要！死！啦！ 所以，为了让你的程序人性化，我们可以使用 语句进行改写。 我们可以对条件判断的逻辑进行分析，可以看出，里面如果条件不满足都是返回那么我们可以将的情况提取出来。
 {
        {
                 
        }
        {
                 
        }
        {
                 
        }
         
}
这是这个。当然，追求极致的话，我们可以看出 ，是完全一致的，当然可以将条件合并
 {
        ||||{
                 
        }
         
}
其实如果你数学学得好的话我还行吧，嘿嘿嘿。 这样提取条件的事是轻而易举的，可以看出，上面那段古老的代码完全可以变为现在这个样式，而且读起来，真的不是一个档次的。
减少参数数量
减少参数数量的方法，当然永远不会===， 因为每个人站的角度不同，得到的答案当然也不一样。所以这里只介绍两种比较通用的。

使用对象来代替参数列表。
将需要额外计算的参数忽略。

使用对象代替参数
这个最突出的特点就是在写模板的时候。
 {
         `   {}   {}       {}`
}
有一个模板，上面需求的参数有三个，但是，事实上，这个是完全不靠谱的。 因为一个人不仅仅只有 肯定还有别的参数，这样，造成的后果就是，你一直在维护模板的同时，还需要维护参数列表。而且，还要维护，传入参数的顺序的正确性。所以这里强烈推荐使用对象来代替多参数。
 {
         `   {}   {}       {}`
}
现在这个模板函数与外界的耦合性已经降低了不少。而且非常易于维护，就算外面你的对象有多余的参数，也不会妨碍我使用我需要的数据。
忽略额外计算的参数
这种情况主要是在做的时候可能会遇到，即，想绘制一个数据的时候，需要将一个数据矩形的高，宽以及面积传入一个函数，进行绘制。
 {
        矩形的宽度为
        矩形的高度为
        矩形的面积为
}
而，这样做是完全没有必要的，因为函数参数越少，给人的感觉当然越好。 我们可以修改为这样
 {
          = 
        矩形的宽度为
        矩形的高度为
        矩形的面积为
}
而且在插件设计中，也应该准遵守这个原则，函数的参数应该在能力范围内，把它降至最少。
链式调用
这个应该算是比较高级的用法。使用过的同学应该印象最深刻。 即，我们可以这样来使用一个功能而这样实现其实并不难，只要在每个方法的后面返回该对象就可以实现这个技能。 我们来模仿一下。
  = {

}
 = {
        创建一个
         
}
 = {
        显示
         
}
  =  

这样不仅可以实现对象的细粒度，而且也满足单一职责原则。 同样，我要说的是，以为的使用链式的时候，记住，使用一个功能块链式调用一定要分行，不然，调会调哭的。
  = {

}
 = {
        创建一个
         
}
 = {
        显示
         
}
 = {
        隐藏
         
}
 = {
         是 
         
}
  =  
  表这样做
上面是个反例，正确的做法，应该分开。




像这样调用，万一出个你也应该知道这个在哪一个函数块内。 大部分重构的小技巧差不多介绍完了智商有限如果，大家有什么更好的建议欢迎留言反馈

原文出处：社区 未经同意，禁止转载月日，腾讯云在「云未来」峰会上推出了战略新品——智能云，宣布将腾讯积累近年的能力向政府、企业和开发者开放，其中首批开放计算机视觉、智能语音识别、自然语言处理的三大核心能力。腾讯云技术社区将陆续推出系列文章，介绍普通开发者如何快速接入并使用这三大  能力。
本文将为大家讲解如何上手腾讯云提供的智能语音识别服务中的实时流式语音识别，主要是  开发  的一些使用经验。
 获取
实时流式语音识别的   的下载地址： 
更多示例可参考 ： 
开发准备

只支持   及以上版本，不支持  版本；
实时流式语音识别，需要手机能够连接网络、 或  网络等；
从控制台获取  、、，详情参考基本概念。

 配置
 导入
  压缩包名称为： 。压缩包中包含了一个 静态库和一个头文件文件夹 。
工程配置
在   中设置   ，加入参数 。

在工程 文件中设置：

    类型，然后在   下添加   类型 ，值设为 ；

在程序中初始化  的实例对象  ， ；程序可以支持 

在工程文件中添加     ，获取系统的麦克风的权限；

在工程中添加依赖库，在       中添加以下库：





签名获取
移动端  中用到的签名，建议由业务服务器来生成，并由移动端向业务服务器请求。业务侧服务器需要进行签名的生成，具体生成和使用请参照签名鉴权 。识别签名必须实现的  的协议，对由 提供，进行加密处理；
 获取请求的签名
 
初始化
引入上传  的头文件  ，使用目录操作时，需要先实例化  对象。
方法原型
       
参数说明



参数名称
类型
是否必填
说明






是
项目，即  




是
项目的 




是
项目的 



：初始化 
示例
 =     
：开始语音识别
 ；
示例

  =     
   = 
    {
          ==  {
              = 
               {
                 = 
                 = 
            }
            =  
        }{
            语音识别失败= 
        }

    }
      {
          = 
          ==  {
             =  状态：识别中 
        }  == {
              =  状态：识别停止 
        }  == {
             = 麦克风权限未开，识别失败
        }
    }
：停止语音识别
 的性能瓶颈
虽说关系型数据库，如已经足够满足我们大部分活动开发的需求，然而有些时候你可曾面对产品看似普通且合理的需求，例如：、能否让网页活动拉取用户的游戏好友关系链从而更精准的推送？、判断用户是否在所有大区都没有角色这类需求时却感到了深深的蛋疼，？
在现有条件下，我们处理需求时的方法通常是用从中拉取用户好友信息并以如下可能的两种方式建库存储：

左边的表结构是将每个用户的一个好友作为一条记录插入库中，通常我们也就是这么做的。然而如果有百万、千万级的用户，每个用户又有着多个好友。且不考虑单台服务器能否承载如此大的数据，从如此庞大的数据中检索出单个用户好友的语句的效率可以想象。右边的表结构虽然每个用户只有一条记录，查询效率不错，但是不可行。因为关系型数据库的表结构是固定的，我们无从得知一个用户会有多少个好友，因此无法确定字段数。肿么办？
需求的通常处理方法同需求，不仅效率低拉数据还有着一天的数据延迟，用户体验极差。什么？你说可以通过接口来实时查询用户是否有角色？如果你觉得炫舞个大区发条指令可以不超时的话可以那么做…
简介
为了解决上述问题，我们决定引入，是一个稀疏的，长期存储的，多维度的，排序的映射表，采用方式存储数据。这张表的索引是行关键字，列关键字和时间戳。每个值是一个不解释的字符数组，数据都是字符串，没类型，属于非关系型的分布式数据库。
如果采用，存储用户各大区注册时间信息的表结构可以变成这样：

 ：是用来检索记录的主键，其作用类似于中的主键。访问 中的行，只有三种方式：
 、通过单个 访问
 、通过 的
、 全表扫描 
 行键  可以是任意字符串最大长度是 ，实际应用中长度一般为 ，在内部， 保存为字节数组。
列族
   表中的每个列，都归属与某个列族。列族是表的的一部分而列不是，必须在使用表之前定义。列名都以列族作为前缀。
：中通过和确定的一个数据存贮单元称为。每个 都保存着同一份数据的多个版本。版本通过时间戳来索引。时间戳的类型是 位整型。时间戳可以由在数据写入时自动 赋值，此时时间戳是精确到毫秒的当前系统时间。时间戳也可以由客户显式赋值。如果应用程序要避免数据版本冲突，就必须自己生成具有唯一性的时间戳。每个 中，不同版本的数据按照时间倒序排序，即最新的数据排在最前面。
：由{   =   } 唯一确定的单元。中的数据是没有类型的，全部是字节码形式存贮。
由于采用的存储格式，将用户号作为就能高效的查询到所对应的信息字符串，加以解析即可得到我们所需要的结果。由于是非关系型数据库，在水平方向有一个或者多个 组成，一个 中可以由任意多个组成，即 支持动态扩展，无需预先定义的数量以及类型。在中，表结构还可以是这样的：

需要注意的是，中所有的行都按照字典序进行排列，字典序对排序的结果是如下图：

行的一次读写是原子操作 不论一次读写多少列。这个设计决策能够使用户很容易的理解程序在对同一个行进行并发更新操作时的行为。
不支持条件查询和 等查询，读取记录只能按 及其或全表扫描，因此 需要根据业务来设计以利用其存储排序特性按 字典序排序如提高性能，如果我们希望将行按自然顺序排列，可以在最左边补。
上述看起来似乎还是没解决问题，如果存放海量用户的关系链数据，单台服务器还是难以负载，又是如何解决数据的存储与检索问题的呢？
的数据存储与检索原理
在行的方向上可以分为多个，一个类似于一张中的表与表的不同之处在于随着数据不断插入表，不断增大，当增大到一个阀值的时就会等分会两个新的。当中的行不断增多，就会有越来越多的。

是分布式存储的最小单位，数据存放在不同服务器上的的中，而一个只可能存放于一台服务器上，那么当我们需要从中查询数据的时候，它又是怎样从分布在不同机器上的中检索数据的呢？
这是由于每个都记录了的和，并由交给相应的进行管理存储，如下图所示

那么是如何得知所要查询的数据存放在哪个上呢？在中表记录了每个上存放数据的 和 以及地址等信息。
现在假设我们要从里面查询一条是的数据。那么我们应该遵循以下步骤：

从表里面查询哪个包含这条数据。

获取管理这个的地址。

连接这个 查到这条数据。


然而问题也随之而来，自己也是一张表，虽然它记录了数据在中的位置信息，如果表的实在太多导致表中的数据也多到让其自身分割为多个存放于不同机器上我们该如何寻址？因此在表之上还有一层表，它用来存放所有表的信息且只有一个，再由记录表的位置。因此假设要检索某条数据，大致流程如下

存储系统的架构
分布式数据库，只是分布式存储系统中的一部分，其系统组成包含、 、节点、集群等四大部分。各部分的具体功能如下描述：

 底层存储上依赖于，保证了的高可靠性。为 和节点提供分布式存储服务，同时保证数据的可靠性，主要功能如下：
、提供元数据和表数据的存储
、数据多副本保存，保证数据的高可靠性和高可用性
节点主要负责：
、为 在中称之为 分配。
、负责整个集群的负载均衡
、维护集群中的元数据
、负责监控整个集群，发现失效的 ，并重新分配其上的
节点主要负责：
  、管理分配的，处理来自客户端对的读取工作。

  、切分在运行过程中变的过大的。

  、负责和底层的交互，存储数据。
节点功能：
  、保证集群中仅仅存在一个能够运行。

  、监控 的状态，通过回调的形式通知 的上下线的信息。

  、存储寻址的入口地址。
存储系统基本上按照 的论文来实现，基本上的架构如下：

——不仅仅是存储性能的提升
由上图可知，存储系统的底层存储依赖于分布式文件系统，分布式的存储方式决定了它优于普通数据库的海量数据存储能力，可是它优秀的仅仅只是存储性能吗？！
假如有一个活动，产品想提出所有于某日之后新玩家所有大区均无角色名单，并为他们发放新手礼包。按照我们运营开发的传统思想，只可能通过从里拉取注册玩家信息，并通过定时脚本遍历该玩家所有大区的角色信息。且不谈这数据量之大是否能够承受，即使能承受，从如此海量的数据找出我们所需要的答案，仅凭脚本所在的一台机器，这个脚本要跑到猴年马月？
既然一台机器的运算能力不够，那多台机器又如何呢？考虑到中的数据存储于多台服务器中，如果能在每台服务器中执行脚本得出结果，再将结果进行合并岂不是能大幅度提高运算效率？
谷歌的 编程模型为我们提供了解决方法，它通常把一个问题分成两个子步骤： 函数被用来采用大输出并将其分为若干个更小的块，然后将此数据交给其它空闲并且能够用它做一些事情的进程。而 函数的功能则是将单一答案从所产生的若干个中间输出中化简并带给最终输出。对于上述假设活动，如果运用处理该需求的过程如下：

对于活动开发来说不仅仅是提供了大数据的存储能力，还提供了高效的离线并行计算、数据分析能力，对于将来的活动开发有着极大的意义。
  上述就是我总结的一些知识小结，希望大家积极分享、拍砖共同学习。的业务使用同学反馈了一个问题：在安卓手的空间里，打开小游戏，然后进入空间宠物，聊天窗口，发送消息。这里会注册一个回调，发送消息后，回调后，小游戏页面会报一个的，比较奇怪，报错截图如下：

报错信息倒是很明确，是因为方法未定义导致的异常；触发条件是因为宠物聊天用的是，所以最初怀疑是否和有关，就由我和一起在跟进这个问题；庆幸的是问题必现，这样我们就可以复现和构造各种场景；下面简单总结下定位的过程：打开了页面，页面用了进行聊天打开了输入法控制面板，页面没出现异常，但是页面的报错了；
根据报错信息最初是想确认为什么页面会收到这个回调？明明是在页面的操作啊？于是赶紧拉上了客户端同学和的开发同学进行定位，可是没有什么头绪和进展，客户端同学觉得没问题啊，调用，客户端正常的执行了一段回调；的请求对象如下：

{_=_=={____________好红红火火恍恍惚惚___}_____} 客户端
客户端处理后，调用的代码如下：
      || {    } _____ {\\\\\_\=_=={\\\\\\\\{\\{\\\\{\\{\\\_\\\\\}\\{\\\\\小宠的语文阔是数学老师教的哦 诗词歌赋样样精通！你想考我吗！\\\\\\\\\\\{\\\\\\\\\\\\\\\\\\\\\\}\\{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\}\\\\{\\\\}\\{\\\\\\\\\\\\\\\\\\\\\\\\\\}}\\\\\\}}\\{}\\{\\\\\__\}\\\__=\}}{\= _\ =    }}
看起来调用没啥问题啊，问题重新回到了我们这边；
我和同学开始了错误的重新定位过程，既然报错是来自页面，一定是和的什么事件监听有关，之前我处理过文件，先定位到和这个错误有关的代码，是在中注册的，如下图：

那我们代理上这个，然后在这个方法中加上看看调用栈，会不会有帮助？
同时我们在页面有涉及到等方法的地方，能加上的，我们统一都加上测试代码，比如类似的代码，如果页面有执行这个，我们可以从对应的和入手查：
  =  
 = 
结果上面的的请求根本没发出来，而且我们在中设置的错误信息，只有的日志，这个是合理的，因为打开页面，调用的就是，我们感觉有些没辙了。。。客户端没问题，也没问题，问题在哪？明明有报错，而且也很怀疑是和事件监听有关，可是我们能做的比较有限；
峰回路转：
在和重现错误的时候，碰到一个常见的联调问题，就是缓存，经常需要重新清理缓存，而且也可能代理不到本地，给重现带来一定的困扰；比如打开，如果加上了_=走到了，可能都没有请求，这样我们设置的什么代理都没用，清理缓存也不一定行。。。很焦急的看着时间慢慢流逝。。。没办法，只能先把地址修改下，去掉_=，在聊天消息框中打开对应的，总算可以代理上了，可以看到正常的的日志信息，意外出现了，在聊天窗口打开的页面，居然没有报错？？？为什么？目前来看已有的信息，就是为什么从好友动态进入，一定会报错，而从聊天点击链接进去就不会报错？都是同样打开的，的代码没变，那我们唯一可以确定的就是有什么差别；
只能继续求助于客户端，客户端保罗大神根据这个线索，对比了代码，结果如下：

空间和里面打开，用的都是一个，但是确实里面打开的不会有问题。
里面打开的：
{= __= _= ___= = __= = =返回 __= __= = __= = = = = = =_=_=__== _= _= = = =}
空间的
{= _= __= = =返回 __= = = _=空间 = =_=_=__== = _= _= = = = = _=}
我们都发现了下面多了一个，这个是干嘛的？代码如下：

在浏览器中插入了一个的命名空间，这个是啥？是个大插件，里面东西太多了，保罗发现干掉这个插件就了，那证明问题就出在这个插件上；找到源头我们也感觉有了一丝丝希望；在客户端同学努力下，问题根源找到了：
输入面板关闭的时候，会发出一个广播，而这个广播的接收者在初始化的时候就被创建了，所以每个页面都可以收到。。。所以问题的原因我们来回归下：
我们从小游戏页面进入宠物页面，在宠物页面聊天的时候，会调用这个方法，同时也会注册一个回调；关闭输入框会执行一下这个，方法名是上面的报错的哪个匿名方法，这个回调方法命名规则就是_这个的值自增生成，在页面因为没有注册这个回调方法，但是在页面却收到了这个广播，这个是浏览器层面的事件监听，但是没有对应的回调方法，所以报错了，不过不影响功能，只是影响了的统计；客户端同学也已经修复了这个，在下个版本会兼容处理；
通过这次的问题定位，对我们未来碰到类似的问题进行解决的时候，提供了思路，就是客户端可能会在浏览器加载的时候，不时的插入一些包括，事件等等，如果没有相应的代码进行辅助证明，可以从这个角度去定位，举一反三下 这一步其实内容不错，但是我还是独立成一篇文章来写。
前情回顾
打造黑苹果一组装硬件的选择与组装 打造黑苹果二制作黑系统安装盘
设置
要将你的硬盘模式调整为  有可能默认是，也可能不是。开启支持  启动。一般默认是开启的。设置 你的 盘为第一启动盘，一般有两个，一个是带  开头的，还有一个是你的盘本身的名字。要选择  开头的。如果你的  支持 ，关闭它如果你的不能设置为中文，则关闭的英文为如果主板支持 ，关闭它如果主板支持   ，关闭它如果里面有 这个一个选项，设置为  。我在技嘉和华硕的主板里都遇到这个东西。如果主板支持  ，关闭它设置   为 开启 英文为 关闭   ，安装好系统后，可以开启，如果开启后系统不能进入，就关闭掉吧。保存并重启上面的内容基本和说的一样，那我也不是干翻译工作的呀，我简单说一下需要注意的事项以及相关知识点。
相关知识点以及注意事项
是芯片，电脑启动的时候回从这里读取启动信息。 是烧录在  里面的程序，这两点不要搞混。我们说的升级  是在  重新烧录程序。反正我没干过升级  这个事儿，就不评价了。各大主板的  页面都是不一样的。但是我遇到的华硕以及技嘉的主板，都是可以设置为中文的。一般按 键 进入  设置界面，如果你的电脑不是，请注意开机的时候的提示。笔记本一般为 键。但是笔记本不推荐黑，驱动很难整，特别熬人。建议不折腾。设置项基本上是没有每个字母都能和教程对得上的。以我优先的英文水平，只有对比字母和单词，不断的猜，然后不断尝试。设置好之后按  键进行保存并重启。找一个靠谱的朋友帮忙是最好的。本文由原创，允许转载，但转载必须附注首发链接。谢谢。近日，腾讯云安全中心情报侧监控显示，目前云上部分用户、和等服务器仍然存在的未授权安全漏洞，黑客可利用此类漏洞发起新一轮勒索攻击，会导致您的服务器中的数据被擦除，并被索要赎金，同时网站服务器有被入侵控制等风险。
为避免您的业务受影响，防止被恶意攻击者勒索索要赎金，腾讯云安全中心建议您及时对照自身数据库服务应用开展安全自查和加固，加固建议如下：
未授权访问
【风险描述】：开启服务时不添加任何参数时，默认是没有权限验证的，登录的用户可以通过默认端口无需密码对数据库任意操作而且可以远程访问数据库。【修复建议】：临时方案：配置，做好访问认证。打开配置文件，设置为=；修改访问端口和指定访问。使其只监听私有或本地，不监听任何公网或；官方方案：具体可参考：
未授权访问
【风险描述】：会默认会在端口开放的接口，用于数据库的管理功能。任何连接到服务器端口上的人，都可以调用相关对服务器上的数据进行任意的增删改查，其中通过修改配置文件，可进一步导致执行任意系统命令，获取服务器权限！【修复建议】：为设置复杂密码字符串，数字，特殊字符，并且长度超过位；修改默认的用户名，默认用户名为，请对其进行修改；做好网络隔离。不开启外网访问。
未授权访问
【风险描述】：会默认会在端口对外开放，用于提供远程管理数据的功能。任何连接到服务器端口上的人，都可以调用相关对服务器上的数据进行任意的增删改查。【修复建议】：增加验证，官方推荐并且经过认证的是插件，也可使用，插件；使用搭建反向代理，通过配置实现对的认证；如果是单台部署的，端口不要对外开放；使用以上的版本；年月日月日， 数据库领域的国际顶级学术会议   在德国慕尼黑召开。 腾讯开源项目团队的论文《：      》，入选了今年的 ，并获邀在大会上进行 。

 
点击文末“阅读原文”直接访问


：高性能分布式机器学习平台
是腾讯对外开源的第一个项目，是一个基于参数服务器 理念开发的高性能分布式机器学习平台。它由和开发，能在社区的上直接调度运行，并支持  ，未来将会支持图计算和深度学习框架集成。
于年月日开源，数三天过千，受到了广泛的用户好评，吸引了来自华为、微博、小米和上海外企的开发者参与项目，并在 全球机器学习技术大会、  、新浪微博机器学习团队等线下分享，吸引了大量的机器学习爱好者。
由腾讯数据平台部和北京大学联合开发，兼顾了工业界的高可用性和学术界的创新性。之前已经在、、等顶级国际会议上发表了多篇论文，这次在发表，是又一个重要的标志性事件。
  基于的大规模高性能主题模型系统
主题模型是一个对文本建模的概率图模型。在主题模型中，每个文档被看成一个话题 的分布，将每个话题看成是一个在词语上的分布   。通过主题模型对文本进行建模，文档被表示成一个话题分布 ，从而可以对文档进行聚类等分析。主题模型的应用场景非常广泛，可以用于多个领域，比如推荐系统、广告预估，用户兴趣分类……但是在工业界的场景下训练主题模型，经常会遇到三个问题： 

训练的数据规模非常大，大小的样本，亿个，要求在几个小时内跑出结果
数据和参数复杂，在各种各样的数据和参数配置下，都必须要有较好的性能
系统需要具有较高的可扩展性和鲁棒性，才能应对现网集群中的复杂情况

为了解决这些问题， 基于，从模型和工程上都进行了针对性优化，得益于开放的参数服务器架构、良好的扩展性以及优秀的编程接口设计，解决了在复杂的数据环境中采样性能的鲁棒性以及词倾斜分布带来的巨大网络通信流量这两个难题，具备了广泛的适用性和良好的性能，可以轻松处理级别的数据和十亿维度的主题模型。
优化：基于吉布斯采样的 
吉布斯采样是一种基于马尔科夫蒙特卡罗的采样方法，常常用于求解大规模主题模型，但是在大规模数据以及话题个数较多的情况下，吉布斯采样的求解效率非常低下。 
目前业界已有的解决方法，包括 简称和  简称。采样法使得采样复杂度降低到，的上限是文档的长度_和话题个数中的较小值；采样法的采样复杂度为，但是因为存在接受率π，概率上需要π次采样才能得到一个样本；而采样法每次采样都能够产生一个样本。
因此，采样法和采样法之间存在一个。团队做了详尽的实验找到了、两种采样法的交叉点， 有效地将采样法和采样法结合起来，设计了一个新的 。

“它采用了两个启发式的规则来构建这个 。在第一个规则中，将数据集分成两个部分，文档较长的数据集和文档较短的数据集，然后使用来采样较短的文档集合，使用采样较长的文档集合；在第二个规则中，将两个具有不同收敛速度的结合起来，在一次迭代中，每个话题的采样都能产生一个样本，因此对于来说，需要动态地设定其步长，而对于来说，则不需要进行任何改变。

根据实验， 在所有的数据集上和参数配置下，都能获得最好的性能。
优化：非对称架构，实现模型并行
主题模型的训练常常需要大规模的数据集和较大的话题个数，因此分布式训练常常用于进行大规模的主题模型训练。已有的系统，包括，和，其实都是采用参数服务器的架构来进行分布式训练，但是由于词分布的倾斜特性，标准的参数服务器架构会在端产生较大的网络通信开销，因此每个几乎都需要把整个词话题矩阵模型从上拉取下来，这个对性能会有很大的影响。
在实际的测试下，由于词分布的倾斜性，导致大部分的网络开销都产生于长尾的词语，这些长尾的词语产生的网络开销造成了在数据量和模型参数较大时带来的性能损失。因此， 对于这类长尾词语进行了特殊的处理，将一部分长尾词语的采样推送到端进行，从而避免了对词话题矩阵的拉取操作。由于在这样的架构中，不仅仅作为一个分布式存储，还参与了一定的计算任务，从而某种程度上实现了模型并行，这种架构为非对称架构。依托于良好的接口设计和功能，的这种非对称架构可以非常轻松的实现，而不用对进行任何的修改。
性能数据：在腾讯真实的推荐数据集上最高是原有系统的  倍
为了进行全面的评测， 和之前开源的，以及微软的，在个数据集上进行对比。一个是开源的，一个是腾讯真实的推荐数据集。实验结果表明，在数据量越大的情况下， 的优势越明显。

数据集上，的速度，分别是和的倍



在腾讯真实的推荐数据集上， 是的倍，是的倍。

大规模生产数据为了更好的体现 的性能，在腾讯内部生产集群上， 使用更大的数据集进行训练。从下图的数据集可以看到，最大的一个数据集有亿个，大约的数据量。在所有的任务中，话题数设置为。

数据集规模如下
测试性能如下 能够在资源充足的情况下，能得到非常好的扩展性，并且能够扩展至数千个，即便对级别的数据进行训练，时间可以控制在小时级别，很好的满足了生产系统的需要。



请在上 项目，与我们探讨
除了算法，还提供了 、 、等业内常用的高性能算法。未来，伴随着开源的发展和推广，希望业界会有更多的公司，能够从中受益，轻松拥有构建大规模模型的能力。也欢迎对机器学习有兴趣的同仁一起贡献代码。
 

转载自【腾讯开源】公众号，腾讯官方开源资讯，期待您的关注。据报道，在亚太峰会上，腾讯云互联网行业总经理答治茜作了题为《的智能计算时代》主题演讲。答治茜认为，随着人工智能时代的到来，也在亟需技术的快速变革，腾讯云认为将全面进入智能计算时代。
图为：腾讯云互联网行业总经理答治茜
年腾讯云在亚太峰会上提出了云的概念，腾讯云认为不再是单纯的在做内容缓存、分发一些职责，答治茜认为未来一定是云和融合发展的时代。他表示，去年腾讯云提云概念的时候也是看到了行业这一趋势，虽然从腾讯云过往的判断来看，未来一定是融合，一定是云和融合发展的时代，但究竟概念该怎么去做、该怎么落地。腾讯云这一年沿着这条道路坚定不移的做一些探索。
今年腾讯云也带来了一些在云方面的尝试和思考，并且在观察去年热点事件中得到一些结论，我们认为将会进入智能计算时代：
第一是随着直播的发展，腾讯云过往单纯流量的分发类已经远远不能满足直播的需求，比如假如说现在有十万个主播的话，对数据中心资源的需求将会比过去大好多倍，大概有上千台的服务器需要做类似于转码、截图、录制、鉴黄等等这样一些计算的需求。随着未来应用中类似于互动直播场景的出现，大量的转码需求也随之出现，不仅仅是过往流量业务的不断增长，而是随着流量业务的蓬勃发展，相应也带出了很大量的计算类的需求。
第二是随着基础算法的完备和完善，在图像、音频和自然语言处理这方面的夯实，腾讯云看到的实际应用场景也在为企业的服务，包括也进入了终端消费者的场景。从过往一年的历史来看，腾讯云在这块的市场份额、规模同时增长了大概倍，在增长的同时也带来了大量的计算类的需求。
从整个行业发展的热点和趋势来看，随着上层应用的越来越多、越来越完备，下面计算类不仅产生了大量的需求，在带宽类的需求产生的同时，计算的资源生产也非常非常大，呈指数型的爆发增长。这种计算资源的增长引来的矛盾是什么呢？ 
行业的发展对计算资源的苛求会越来越旺盛，但同一时间的整个网络和基础设施的计算资源是有大量冗余的。如何解决矛盾，云企业怎样调和这两者之间的均衡度，腾讯云在这一年里做了很多尝试：
、视频直播
视频直播整个行业的做法都是由边缘节点接入，流量回归到数据中心，在数据中心里完成推流、转码和截图的过程，最后分发到观众。目前腾讯云做了一些优化，现在的模式变成了主播产生的数据，举个典型的场景，比如同城直播场景。腾讯云现在的做法是主播产生的数据接入边缘节点之后直接做推流和转码的工作，把原来数据中心里边重的操作下沉到边缘节点去，这样做带来的好处有两点：首先边缘节点和数据中心之间的穿越流量将会变的比这种模式显而易见的会下降很多。其次、过往腾讯云一直提现在行业的趋势对于计算资源的苛求会越来越明显，但腾讯云数据中心的计算资源始终是有限的，同时的网络沉淀了大量的沉睡的计算资源，这种做法可以让腾讯云可以同时满足成本的下降，穿越流量的下降，数据中心资源在合理范围内，同时边缘节点的沉睡资源也可以唤醒。
、智能鉴黄
腾讯云每天大概有超过十亿次的鉴黄的请求，过往腾讯云对待鉴黄的请求基本上是用户在用户端产生的内容，内容直接推到数据中心做计算类鉴黄。过往的模式带来的问题有几个，首先用户产生的内容中，的内容都是正常内容，只有的内容是违规内容，腾讯云因为这种极少量的不正常内容要消耗大量的资源做计算。其次，对于大部分的正常内容，腾讯云要做出判断只是需要非常轻量级的计算就可以了。所以过往腾讯云把所有的请求都推到数据中心去做，现在进行了优化，基本上是分两层，第一层是在边缘节点做极速的鉴黄模型旨在回答，腾讯云准确的告知这一定是个正常内容，对话请求已经被处理。当腾讯云在边缘节点上判断不出来的时候，才会把可疑的内容推到数据中心里去极优鉴黄模型，做更深度的计算。腾讯云有运营的数据表明，通过这样优化之后会把的请求都挡在边缘节点去完成。
、智能物联
腾讯云认为未来有几个最热的潮流，除了大数据，除了，还有正在发生的热点：万物互联。在万物互联的时代，腾讯云应该做什么样的准备？答治茜讲了腾讯云的考量。
现在或者未来，万物互联的时代有可能联到数据中心的终端是百亿级的，到万物互联的时代，作为个体有十个设备，到智能家庭的设备数字可能是几百亿级别。百亿级的设备并不会实时的产生有效数据，而是有大量的空闲连接和空闲设备，这种大量的空闲连接和空闲设备完全回到数据中心，路由层面是解决不了的。但是天生可以做这样场景的应对，因为本身是分散的，几百个节点，每个节点都可以去接入和管理设备的连接。连接上来之后把有用的、真正产生价值的数据合并了汇聚之后再送给数据中心，这一点是有天然的应对百亿级物联设备连接挑战。
腾讯云一直在探讨是纯的缓存或者流量的业务，这是上层的应用决定的。那时候无论、还是时代还是移动互联网时代，对内容的获取都希望有更好的体验。未来无论是物联的时代、鉴黄的时代、时代，整个场景都发生变化了，大家不仅是对流量的诉求、不仅是对速度的诉求，而是有大量的设备、大量学习的任务、大量计算的任务。
答治茜认为，未来有三大类特征的计算会搬迁或者会移动到边缘计算上来
、有区域性计算特征的，直播里的转码或者录制有区域性计算特征的计算场景，更适合用边缘网络去完成和解决。
、跟深度学习相关的，但是不依赖于大量的历史陈旧数据，只依赖于深度计算学习到的一些模型数据，比如鉴黄场景。
、万物互联时代对上百亿级连接的处理，对空闲连接的分散，对无效请求的过滤，这样一些场景会移动到边缘节点上来。
答治茜认为，单纯的数据中心的发展、单纯的发展已经远远不能满足行业对于计算、对于传输、对于海量的连接、对于海量请求的处理的需求，未来一定是云和的协同发展，或者说就是云计算的一部分。大家好！作为一队苦苦挣扎在鱼塘里的萌新，我们的队员们几乎都从未接触过此类广告点击率预测比赛。队伍经过近一个月的苦苦挣扎，踩过无数坑，尝试了各种特征，仔细研究周冠军们的分享，翻看官方群聊天记录，终于在初赛结束前夕取得了较前排的位置离前十还较远，哈哈，在这里写下我们一路来的经历，也希望可以帮助到为比赛而感到困惑的选手们！ 
因为曾经有使用过，所以在比赛伊始，我们就尝试使用它来搭建模型，相对于其他常用模型和，它在训练速度上更快，并且能够获得不俗的预测效果，也不需要对离散特征，处理起来更加简单。下图是三种模型优缺点对比：

相信了解机器学习的孩纸们一定都听说过一句话“数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已”，在选完模型之后，就是最棘手的特征工程了。首先，我们并没有使用全部的数据，我们使用数据集后几天的数据来训练，将第天的数据作为测试，这样不仅训练更快，同时效果也不会差。
相信大家最头痛的一定是不知道如何使用_和__了，我们也在这两个文件上花了大量时间，但收效并不明显，我们主要统计了近天用户的安装数和截至观察期内安装数。同时统计出用户观察期内安装的各种对应的。有大神提到使用，我们还没来得及尝试，应该是个不错的选择。同时，我们使用了较多的统计特征，如近天的安装率，转化率等等。
最后，也是最重要的，就是关于的问题，比如最近公众号上提到重复数据的处理问题，下面是号发生转化的实例统计情况表，经过观察可以发现，如果用户在一天内多次点击广告，那么转化大多数都发生在第一次，所以如果将这个重复性次数作为特征标记出来，应该能给大家的分数带来大幅度提升。

额，如果说这本是周冠军的舞台，那么我想我们队离这个舞台实在相去甚远，在这里为大家分享经验，确实感觉水平不够！同时希望大家也多多交流，共同进步，在本次比赛中取得优异成绩！在语音识别中的应用，要从的《     》这篇论文开始说起。首先看下面简单的图，它是一个有向图，状态转移弧上有输入符号、输出符号以及对应的权重值。下图中的输入符号和输出符号相同，当然在多数情况下它们是不相同的，在语音识别中，输入可能是发声的声韵母，输出是一个个汉字或词语。 

的基本操作
是基于半环代数理论的，详细的半环理论可以看上面的论文或者找其它资料学习。简单的一个半环代数结构定义为，它包含元素集合，两个基本操作和两个基本单元。半环必须满足以下定理：

在语音识别中经常使用的有半环和热带半环：

⊕     ⊕  = −−  −
合并操作
合并操作用于将两个合并成，合并可以用于存在多个时，将它们合并到一个，用于语音识别中。如下，将和


组合操作
组合操作用于合并不同层次的，用于将前一个的输出符号同后一个的输入符号做合并，生成由前一个的输入符号到后一个输出符号的状态机。假设 中有一条转移弧，输入，输出，权重是； 中有一条转移弧，输入是，输出是，权重是，那么和的组合后，就会生成一条输入是，输出是，权重为。下图为对和做组合操作

确定化操作
确定化操作用于去除的冗余，对于的每一个状态，它的每一个状态对于同一个输入符号，只有一个转移弧。确定化的加权有限状态器的优势在于它的非冗余性，对于确定化的加权有限状态器，一个给定的输入符号序列最多只有一条路径与其对应，这样可以降低搜索算法的时间和空间复杂度。下图为对做确定化操作，得到

权重推移
权重前推操作将转移弧的权重都向加权有限状态器的初始状态推移，这样在采用搜索算法去找到最大或者最小路径时，可以在早期就丢弃一些不可能的路径。下图为对做权重前推操作，得到

在语音识别中的应用
在语音识别中，隐马尔可夫模型、发音词典、语言模型都可以通过来表示。对于语音识别，其目标函数是：

其中|为声学模型，为语言模型。将上述公式贝叶斯展开：

其中是音素序列，|表示单词的发音概率。另外，|的概率只与有关，| = |
在语音识别中，通常会对概率取运算，所以上式等同于下面：

基于上述公式，可以将语音识别分成三个部分，如下：



表达式
知识源
权重意义
表示





语言模型
→




发音词典模型
→




声学模型
→




采用知识源的方式替换上述的公式，得到：

一个完整的语言识别加权有限状态转换器可以表达为：。在引入音素窗后，上式在后增加音素窗的变化。
通常的组成由后往前进行，先进行的组合，再进行的组合，最后进行的组合，即 =       。
语言模型
在语音识别中，语言模型用模型表示，常用的有、。模型与一个阶马尔可夫链相似，所以可以用来表示。如下是一个简单的语言模型” ”和“ ”转成的示例：

发音词典模型
发音词典模型表示一个单词有哪些音素序列串构成。当用来表示模型时，输入是音素串，到达终止状态时，输出一个相对应的单词。

上下文相关音子模型
上下文相关音子模型用于将三音子序列转换为音素序列，这通常很容易构造，只需要输入三音子串，输出其音素即可。
声学模型
声学模型用来进行建模，对于输入的特征，通过或者计算出当前帧对应的发射态的概率。
将上述的通过组合以及相关的操作后，得到一个完整的解码图，配合或者模型去计算每一帧对应状态的概率，采用或者算法，可以得到完整语音对应权重最小的文本，即为最后的解码结果。月日，在「云未来」峰会的  大数据专场上，腾讯云副总裁王龙先生在现场发布了大数据与  的新品，数智方略。以下是王龙先生在云未来峰会 与大数据专场的演讲全文。

大家早上好，欢迎参加我们这个分论坛。我先简单地做个调查，在座的有谁已经部署了大数据系统？我看到大概只有，比我想象的少很多，说明大家目前还处于观望阶段，这刚好说明了腾讯云的未来价值。
言归正传，我对腾讯云团队过去一年的工作感到非常的兴奋，加入这个团队也感觉压力很大，因为他们去年的事情确实令人赞叹，在去年数智方略的时候，我们只做了一个腾讯大数据的套件，这个也是挺复杂的。也是腾讯过去数十年积累的输出，在过去的一年中，我们在公有云上全面布局，然后我们在私有云上不断地进化、改进，我们在公有云上也全面布局，基本上完成了整个大数据相关体系的建设。
今年我们做的第一个大的东西，是弹性，已经存在在这个市场上很多年了，我在这里简单说一下，刚才大家也都举手表示了你们对的熟悉程度，它作为一个分布式系统，它其实是比较复杂的，它需要专业的知识，无论是安装、调优、运维等等各个方面，都需要专业的知识。大家都明白云的本质是什么，云的最核心的本质就是降低成本、提高效率。它怎么降低成本呢？它利用一系列的技术手段，把安装、部署、运维、调优放在云里面来做，大家就不需要找到很昂贵的数据科学家，甚至你也不一定能找得到，比如说贾佳亚教授，在全世界就一个，你想找也找不着，所以你就可以把所有的工作交到公有云里面，这是和生态，和公有云结合的一个重要的优点。
用于离线数据分析
我们这个系统推出以来已经有不少的成功案例，比如说微众银行，通过了系统管理超过个节点，典型的好处是他们原来部署这样一套系统大概需要两周，这个两周时间是指服务器已经买到了，再去做软件系统；现在它差不多在一小时之内就能完成个节点的部署，部署完了之后，它的运维人力也不需要像以前一样要铺上所有的人，他现在的运维人力只要原来的，这是典型的和云结合之后带来的好处。在移动互联网领域，我们和猎豹移动合作，管理超过个节点。除了这些好处之外，猎豹移动还有一个很特殊的需求，它到每个月末或者季末的时候，需要有大量的要求非常高的计算，我们也基于这个，实现了在几分钟内从个节点扩展到个节点的能力，这也是云的巨大的价值，叫高弹性。
谈完了，我们再来看看数据工坊，它可以理解为我们的大数据套件的公有云版本，既然是公有云，我们就加了一些东西，比如说安全沙箱、多租户，可以实现很好的隔离，而且都可以横向拓展。其他的包括拖拽式数据管理、列级权限、数据查询，这个跟数据仓库很多功能都是一样的，在云上有一个巨大的好处就是监控，监控是运维的一个很好的组件，我们在云上提供监控，可以大大减少运维的压力。

商业智能分析也是一个典型的  套件，它的功能跟传统的套件相比是不同的，它是云上的，云的所有好处它都有，我们选择的这些技术体系，不管是通用的组件、展示组件、挖掘组件都是业界最优的，从展示的能力上，数据建模的能力上都是秒级甚至毫秒级的。
这是一个非常核心的东西，也是通过我们的数据平台部门输出的。腾讯有众多的数据，可是我们内部的各个部门对数据分析的要求是非常高的，我们有着亿的用户数据，我们怎么样满足这么多内部用户的需求？这是一个很大的难题，过去十年我们一直在这方面深耕，现在我们把这些数据包装出来，贡献给大家，它是结合列存储技术，实现实时的构建，还支持实时的索引，可以实现在级的数据内，我们返回毫秒级的数据挖掘的结果，这对公安、金融都是刚需，这种在大数据的要求岩石性比较低的分析场景下是非常有用的。
除了前面说的数据本身的存储和处理之外，我们还提供了两款产品，我现在也没想好它是还是，我就假定它是和的结合，它叫文智公众趋势分析。它是干什么的呢？我们有一个爬虫系统在网上爬，爬了大概全国三四千个最流行的网站，我们利用自然语言处理去做文本分类、句法分析，提取关键词，然后进行标注，然后就可以实现热度分析、口碑分析、参与者分析。在政府领域要做的舆情监测，对于他们有很大的帮助。过去一年自媒体也很火，自媒体经常要蹭热点，不然这个公众号就没有吸引力，通过这个分析也可以给他们提供帮助。在金融方面也是一样的，通过数据分析，可以大概知道什么地方有些什么突发的事，对它的金融风险的管控是非常有用的。　　　智能推荐服务，昨天大概提了一下，我这里再稍微深入讲一点。我们有亿的用户数据，我们针对这些用户做了画像，这个画像的数据和用户的数据结合起来，它就能够实现一些内容广告的推荐机制。我们昨天已经说了，很多广告的点击率、转化率都提升了、。我们现在和一些电商合作，电商把它的库存，把它自己的数据传递给我们，我们给它定制一套推荐算法和推荐模型，这个效果还是非常不错的，比如说分期乐，它的首页的限时秒杀订单的转化率提高了百分之百，返利网也提高了以上，所以这个效果还是非常明显的。这个服务因为涉及到数据，有一些敏感性，所以我们目前是一个内测的状态，仅对部分有资质的合作者开放。
接下来是一个大数据可视交互系统，这也是腾讯的一个首创或者是比较有竞争力的地方，我们做完了这个商务智能以后，接下来看到是要展示结果，你们现在应该在我们的主会场那边展厅里看到了，我们有一个大屏幕显示，还是很酷的，实时地图，在地图的某个节点发生了什么事，或者说它的交通情况怎么样，它的温度、湿度、压力、传感等等，这些都是基于我们的大数据可视交互系统，它是利用数据进行实时渲染、高清数据呈现，实现实时的可视化交互能力以及场景化渲染能力，向决策领导层提供实时可视化决策能力。
讲完了大数据，我们再来看看在这一块，腾讯做有天然的优势，又有数据，又有腾讯云的大规模集群做后盾，然后又有顶级的科学家提供最优秀的算法，基本上我们是世界上比较前沿的。当然我们也要聚焦，所以我们打造的是三大核心能力：计算机视觉、语音识别和自然语言处理。大数据服务是数智方略中的数智，可以看到我们有一个新的东西——，今天我们的专家也会详细介绍的特性，在其它方面我们就是增加原子化的服务，不停地提升性能。
是什么呢？可以理解它就是一个网上的深度学习开发组件，我前面说过云的一个很重要的特性就是降低门槛，提供一个可视化的开发平台，作为开发者来说，你不需要理解太多的底层技术，你到腾讯云上来，就可以通过拖拽来组合一些算法、数据源、模型等等。它的本质对小白来说，快速入手，对专家来说，减少他们的一些重复的、没有意义的工作量。
这是我们在机器视觉上不断发掘的能力，可以看到行业应用，这是我们已经投入的一些行业应用。再看这个基础研究，其实就是原子化的服务，就是我们到底应该提供什么样的。然后平台数据，就是基于我们的优势，这一块我就不一个一个念了，你们到官网上看，或者是接下来我们可以再聊。
语音服务也是一样，我们不停地去发掘我们的底层数据实例，然后应用在场景上。自然语音处理也用得很多。
下面再来看下的实际应用的场景，前面说的计算机视觉、语音识别，我们在社交娱乐上的应用还是非常广泛的。简单说一下，你现在用的智能手机有一个功能，它会给里分类，说你的是人像照片，还是景物照片，文字识别也一样，一个照片拍出来知道这是在巴厘岛还是在北京。还有人像增效，这个主要是美颜，当然贾教授也在领导我们做去美颜的功能，这是最简单的图片上的应用。在直播方面，去年直播非常火，在视频直播领域，我们的合作伙伴接入腾讯云的大部分都在使用腾讯云的鉴黄服务，做一些敏感词的界定，甚至做一些血腥图片的鉴定。
安防监控方案也是比较重要的一个刚需，腾讯云提供了天眼系统，在公安、安防中有很多的应用。像主会场上和邱总他们都谈到过寻找走失小孩的案例，实际上在真实的安防应用中，如果想找到一个特定的人，通过我们的系统都能实现这种秒级、毫秒级的返回。
智慧法院解决方案，这个东西昨天讲过，我不再赘述。昨天说的只是一个记录，利用语音识别和图象识别做一些记录、存储、识别。现在很多智慧法院也在做远程的审理，来减少法院的负担。远程审理就面临一个问题，你怎么知道他是他呢？这时候包括人脸核身，通过视频里的动作、声音来核定身份，进行一些证据的确定，我们已经加入进来，目前已经有客户在使用这个方案。
智能客服解决方案，我们目前看到的最常用的场景是两部分，一部分是问答机器人，你遇到什么问题，或者是你需要什么服务，然后我们用技术来解析，当然也有一些语音的机器人也在不断地推进当中，通过打电话，用语音的方式来交互做一些服务。另外一个是客服质检，比如说你有人的话务中心，你要确定他们的服务是符合规定的，客服质检，就是我们用一些技术确定他说的是不是够专业，是不是有不恰当的关键字，通过这些方式来更好地监督客服团队的运行。
我们的人工智能和大数据其实是很像的，它本身有云端的部署，直接使用我们公有云的，也可以把一些模型放到终端里，做离线的一些事情，我们也可以做一些私有化的部署，就是出一些敏感数据的保护，把我们的能力输出到用户自己的数据中心里去。
展望我们将来要做什么，我觉得最重要的一件事就是了解我们的用户到底是谁。我们会沿着三种不同类型的用户，去服务这三种用户，第一个是终端用户，这是真正使用这些服务的用户。第二是开发者，就是用我们的能力为用户打造解决方案的人。第三类是合作伙伴，在能力上和我们互补，一起为用户创造价值。围绕着这三种不同类型的人，我们去开放我们的能力，然后根据这三种情况去判断我们应该输出什么样的技术能力，应该做到什么样的结果。这是我们对未来一年的展望。月日， 借助深度学习的力量又一次战胜了人类中国棋手柯洁，而且该版本  的计算能力、学习能力更强了。相信众多开发者，乃至普通大众都对深度学习这个话题产生了强烈的兴趣。因此我们从腾讯云社区的优质文章库中，梳理了一些深度学习的干货，帮助你快速入门深度学习。
总览式入门
深度学习被视为当前人工智能领域最热门的一种技术，学好深度学习需先从了解人工智能轻松入手。腾讯   张潼主任和腾讯云技术总监携手带你快速了解人工智能。
腾讯   张潼主任带你轻松   新知识腾讯云总监手把手教你，如何成为  工程师？
看完以上两篇，是不是对人工智能跟深度学习有了大致的理解，开始坚信人人都可以做深度学习。
人人都可以做深度学习应用：入门篇上人人都可以做深度学习应用：入门篇下
实战式入门
深度学习人门实战
本系列从实战的角度出发，介绍如何使用、以及利用线性回归模型进行手写识别的训练。
深度学习入门实战一像  一样算法生成梵高风格画像深度学习入门实战二用  训练线性回归深度学习入门实战三图片分类中的逻辑回归
使用腾讯云学习深度学习
本系列文章主要介绍如何使用腾讯云服务器进行深度学习运算，前面主要介绍原理部分，后期则以实践为主。目前正在腾讯云技术社区火热连载中。
使用腾讯云  学习深度学习系列之一：传统机器学习的回顾使用腾讯云  学习深度学习系列之二： 简明原理使用腾讯云  学习深度学习系列之三：搭建深度神经网络使用腾讯云  学习深度学习系列之四：深度学习的特征工程
实际应用
看完以上的文章对深度学习有了更深的认识，接下来让我们看一下如何利用深度学习做一些实际应用？
机器学习  算法在火影手游的实践老司机用神经网络带您安全驾驶我们教电脑识别视频字幕
结语
是不是还觉得看得不够爽？快到腾云阁，点击上方的搜索按钮，查看更多有关深度学习的干货吧！腾云阁还会继续分享有关深度学习的实战经验，同时也欢迎大家在社区一起交流，优秀经验分享会有惊喜哦！导语
刚来公司，接手的第一个任务是，开发网站项目的一个功能模块，需要用到、、，在这之前，还算比较熟悉，、完全没使用过，项目基于，也是没有用过。因此整个开发过程比较坎坷，边学边用，踩过了很多坑之后，才基本上手了。
比较好的是项目的大框架已经有了，有很多代码可以借鉴和学习，因此降低了入门的难度。从月号到月号历时二十来天，整个功能初步完成，现在总结下一些关键内容和踩过的坑。
、功能模块背景和需求
在视频点播业务中，视频的资源分布在全国各地的机房中，机房的磁盘有和两种类型，我们需要尽量将用户请求的视频资源保存在磁盘。主要原因有：

读取速度快，读取速度慢，在播放高码率的视频文件时，有可能会出现读取速度跟不上，导致视频播放出现卡顿；
读取速度慢，在有大量请求时，系统不能及时处理，导致系统负载增大，以至于最后可能挂掉；
比更贵，控制成本的原因只有部分为，提高命中率使得现有资源可以同时处理的请求更多。

因此，对于机房来说，最主要的优化之一就是提高的命中率。我这里做的事情就是，汇总所有机房的命中率，然后在页面上进行展示，以方便观察各种优化措施是否有效。
这里对命中率，有两种计算方式得到的结果：

计算方式一：根据机房的进程数据计算，结果以接口提供，可以按照机房名称、时间等信息去拉取数据，数据按照一分钟进行计算的，拉取时需要分别拉取机房的命中率和总流量两个接口。
计算方式二：根据访问的流水日志进行计算，保存的日志文件是十分钟一个，数据组用平台计算出这十分钟日志里面，每个机房的流量、流量，将每十分钟的数据导出到数据库的表中，机房数量大概是。

具体展示需求有：

可以对比两种计算方式的命中率汇总结果和实时曲线。
查询特定机房的命中率实时曲线。
查询特定机型的命中率汇总结果和实时曲线。
查询特定运营商的命中率汇总结果和实时曲线。
查询时间段可选。

下面将对功能模块中主要的部分进行介绍。
、拉取数据接口数据
上面提到的计算方式一，需要从接口拉取数据，数据接口示例：
=__=__=_
中包含了请求的各种参数，示例如下：
= {_下载{_  _  {东莞电信大朗}} }
一开始没考虑太多，想到的是利用的直接请求数据接口，获取数据展示出来，处理代码全部用完成。请求和处理代码大概是这样：
 ____{
        __是根据接口文档构造的字符串  
        _ = ___
    { 
         _
         
          
          
         
         
    } {        
          省略
         
    }
     {
        查询出错
         
    }
     
}
问题：
访问拉取数据接口，请求出现以下错误：
        
无法跨域，按照网上建议，将=””改为了””，解决了上述错误，但是得到请求后出现：    
原因是返回的是格式，和格式不匹配。
解决办法：
不使用直接跨域请求数据接口，改用请求数据接口获取数据，处理后返回数据到页面中。中获取数据接口的数据很简单，直接用包就可以了。这时对应的请求部分代码改为：
 ____{
    { 
         ___
         
         _ 传递的参数
          
          
         
         
    } {        
         
         
    }
     {
        查询出错
         
    }
     
}
 部分代码：
 ___
    _ = 
    _ = 
     _   == 
         = 
         = 成功
        _ = _ 
        _  = _ 
         = _ 
         _ ==   _ ==    == 
             = 
             {} _=
        
             = ___ _  根据参数构造和前面类似          
             =  得到的内容
              最好添加对的处理
              _=
    
          {} _=
 这样的话，在后端处理代码，还可以做很多处理工作，直接返回需要的内容即可。代码中间省略了一些处理，这里只是说明大概的处理流程。
、数据本地缓存
在开始进一步设计前端展示界面和编写后端代码时，考虑到数据的本地缓存，主要有以下两个原因：

当需要获取任意多个机房数据时或者汇总数据时，需要在中加入一个特别长的请求参数，可能会出现参数超过长度限制，如果拆分成多次请求，会花费大量时间。
另一种计算方式的结果，是每十分钟一个表存到数据库中的，每张表的数据记录是多条机房数量  ，是因为机房里面还分、影视，但是大多数的查询是按天查询，因此需要多表查询，比较耗时。

基于以上两个原因，分别对这两种方式的数据进行汇总缓存，考虑用脚本，每天定时获取前一天所有机房的数据，汇总保存到一个表中。定时任务用命令，设定每天定时运行一次。
数据接口数据缓存
对于数据接口的数据，获取所有机房列表，然后构造对应的请求，请求数据，得到的数据是每分钟的，进行汇总为每十分钟的，和另一种计算方式结果保持一致。主要的流程代码如下：
 _____ 
    数据库连接
      = 
    _ = __   
    创建表
    _  _ 
    数据接口得到所有的机房名称
    _ = ___ 
    _ = 
       _
        _ = 
        根据机房名称确定运营商
         = ___
        命中率和流量是两个不同的接口，因此需要分别拉取
        根据参数构造请求命中率和前面类似 加了一个获取的目标
         = ___   
         = 
        __ = 
        根据参数构造请求流量和前面类似 加了一个获取的目标
        _ = __   
         = _
        _ =     
        根据每分钟的流量和命中率，计算每十分钟的流量和命中率
         = ______  __ _
        保存到数据库
        ____  _ 

 ____ == ____
     = 
     =    = 
     =  昨天的日期
    _____
 流水日志数据缓存
对于流水日志导出的数据，因为已经是存到数据库表中了，只需要将多个表进行汇总就行了，比较简单：
 ____
    数据库连接
      = _
    得到一天中，每隔十分钟的时间序列，从、到
    _ = ___
     = ____  
       _
        _ =   
        得到这个时刻表中所有的记录
         = _  _    
             
    _ = __  
    __  _ 

 ____ == ____
     = 
     =    = 
     =  昨天的日期
    ____
问题：
保存数组到数据库时，执行以下代码时：
 =     _             

     
    
   
    
     
 出现错误：
       
原因：
插入的数组太大，分为多次插入即可。
    
         = 
             
                
            
       
        
         
、下拉选项框处理
开发的功能是嵌入到之前的一个项目中，展示的下拉选项框组件为了一致，直接和前面一样，用的这个组件。但是在使用时，发现这个组件有一个问题。
问题：
组件设置了为，即打开了全选选项，如图所示的“ ”：

在点击 的时候，所有选项都会被选中：
 
再次点击时，所有选项都会被取消，看似没有问题。但是官网上说明，点击和取消时，分别会调用函数和，为了针对处理，这两个函数都写了，但在使用时，发现函数没有被调用。
原因和解决办法：
这是前期自身的，点击查看 同样问题的回答。项目中使用的版本比较老，是还没有修正的，去下载最新版进行测试，发现调用没有问题。但是刚把新版的放到项目中，发现其它页面的显示严重错误，猜测可能是还有其他地方做了修改。为了不对之前的页面产生影响，放弃使用新版组件。
最后使用了最麻烦的方法，直接自己添加一个“全部”选项，在方法中，进行判断，如果为“全部”选项选中，则在参数列表加入其他所有选项，如果为取消，则将所有选项从参数列表中去除掉。具体实现中初始化代码：
____{
         
          
         请选择一个机房
         
         
           {
            _ = { 汇总}
            __ = { 全部}
             = ____
            _ 函数处理点击后的各种情况，汇总、全部和其它选项
             = _   __ _ __
                ___ __ ___ 
            ___ = 
            __ = 
            ___ = 
            
        }
    }
 这里除了全选，还加上了汇总选项，上面调用的_函数代码包含了对下拉框的汇总、全部等选项的所有处理过程，因为机房、机型、运营商下拉选项框都有类似的处理，因此进行了提取，代码流程如下：
 _   _ _ __ __ _ __ _{
      ==  {
         = {}
         = 
         = 
          == __{
            选中全部时  
        }    == _{
            选中汇总时  
        }  {
            选择其它选项时，这里得判断汇总、全部是否被选择，如果是则取消
             __ == {取消选择全选
                 __
                  
            }
             _ ==  { 取消选择汇总
                 _
                 
            }
            选中其他时  
        }
        这里处理三个下拉选择框的联动刷新，改变选择框的选项
        ____ _
    }    ==  {
          = 
          == __ {
            再次点击，取消全部选项   
        }   == _{
            再次点击，取消汇总选项   
        }  {
            再次点击，取消其他选项   
        }
        这里处理三个下拉选择框的联动刷新，改变选择框的选项
        ____ _
    }  
     __ _ __
}
上述中，调用的函数__，处理三个下拉框之间的联动刷新，因为对每个不同的组件，刷新有很大的差别，将在这个函数里做区分处理。联动刷新的三个选择框如下：

中普通的省市区三级联动代码网上很多，因为省市区是固定顺序刷新的，选择省刷新市选择市刷新区，并且数据固定也不是很多，对应关系可以保存在数组里，比较简单一点。这里不同的是，需要任意点击一个下拉框选项，其余两个都会刷新，机房数量并且会变化，机型种，运营商数量，因此只能动态的根据选项变化获取其余两个选项框应该展示的选项框。处理代码比较细节和繁琐，但都是判断和逻辑层面的，这里就不进行说明了。
、可翻页的曲线图表集合效果
需要做出的效果类似下图：

才用不久，总想着用现成的组件，结果发现没有类似的。在查询资料后，发现翻页组件可以用的，每个图表的显示可以用，多个图表的处理，只能自己写函数动态的处理。
自己编写的代码处理流程是：
、先获取数据，项目中是从数据库查询的数据，这里做测试时，直接构造的数据。、传入需要显示的页码，根据每页图表数和图表总数，计算总页数刷新翻页组件，翻页组件中点击某个页码之后会调用进行处理，这里直接跳回到步骤、计算当前页需要显示的图表起止索引绘制图表曲线。
以下是做测试的主流程代码：
     ___ = 每页的图表数量
      = 
     _ = 
     = __ 构造数据
    _ _ ___    
    第几页，总图数，每页的图表数量
     __ _ ___{
         _ = _  ___总页数
         =_
        
        __ _ _   
         _ = ___  _  
         _ = ___ ___ _ _
        当前页需要展示的最后一个图表的索引
           = _   _  {  
            =   = \_   \ =\\ 
          
        }
        __ _   
    }
    刷新翻页组件，在点击某页之后会调用函数进行处理
     __ _ _{
         _=_
        _
         _=     
        _{
             _
             _
              {
                _ _ ___
            }
        }    
    }   
    绘制图表曲线
     __ _ {
          = 
           = _   _ {
            _ = _             
              _
              = _
            的配置表面、曲线名、轴、轴数据
             = __   
                
        }
    }
、时间段查询功能
保存的表是按照天进行存放的，查询时间段的功能可以选择开始日期和结束日期，查询多天的汇总结果和实时曲线结果。因此需要多表查询：

目前的处理办法是：直接按照每天进行查询，最后将结果进行拼接汇总起来，比较简单。
缺点：多表查询会比较慢，特别是在时间段跨度稍大一点的时候。
优化思路：每天的记录大概是万，一个月下来是万，可以加索引优化的字段是时间和机房名称，这个数量级的情况下做好优化，还是挺快的。因此后面会考虑将数据库缓存改为按月存放，测试优化前后的速度对比。
、各种问题汇总

问题：脚本运行出现语法错误：        ，但是文档中每一行都严格对齐了。
原因：代码中存在键和空格混用的情况，代码不支持代码对齐中，混用和空格。
解决办法：使用，打开文档，依次视图显示符号显示空格与制表符，可以发现混用的地方。建议代码统一用空格对齐，在不同环境下缩进空格数不一样。
设置替换为空格：设置 ⇒ 首选项 ⇒ 语言 ⇒ 标签设置，勾选 替换为空格
设置替换为空格：
 =
 


问题：经过跳板机连接测试机，要从本机传文件到测试机，执行文件失败，文件大小左右，在上传一部分后停止并退出显示一行乱码，执行多次，仍然无法成功。
解决办法：中间有控制字符的原因，加参数忽略控制字符， 。常用命令方式： 。

问题：代码中用了解数据库进行操作，出现以下错误：
             
原因：编码冲突
解决办法：以下两步
、
 


、数据库连接时：
 = === ==
 = 
  
、结语
这篇文章主要介绍了在功能模块中的一些关键处理思路和流程，以及一些比较典型的问题，都是比较基础的东西。其中的内容，相信各位大牛还有许多更好的处理方式。水平有限，总结的内容可能存在不足，欢迎大家指正！前言
前段时间内，在  大会上吹了一帮使用做机器学习，说是仿照的来写的，看着很有诱惑性

有一些算法可能官方文档里面没有，但是官方仓库里面是都有代码的，比如和
第一弹，我们介绍基本的分类模型的使用，会主要介绍\\ \  ，会由浅至深在每个算法中分别讲述需要注意的点。

数据集描述
先描述下这里做实验的数据集，下载地址  ，是收集美帝的收入的记录，是一些个人信息包括工作、年纪、学历水平、家庭情况等等大概个维度，标签是是否年收入在以上，即一个二类分类器。后面所有算法都是使用的相同的数据来做实验。
数据读入
数据集格式为，使用可以快速读入数据，并格式化为，做一些基本的预处理操作，如下，是从文件中读入数据的操作因为内部会自动判断类型为类型 值为，这类数字的值，在使用之前需要做转换，转为类型，：

_ = 
_ = 

_ = __ = =
_ = __ = =
_ = _= =
_ = _= =
_
    __ __ 
    ____ _
 = _
    __ __ 
    ____ _

_
    __ __ 
    ____ _
 = _
    __ __ 
    ____ _


__ = 
    __    
__ = 
    __    
 = _
从硬盘读入数据之后，如何标记每个维度的属性比如 还是 ，这个在上是很方便使用可以很方便的处理，内部也有类似的逻辑，相对会比较复杂
__ = ____
_=__ __=
__ = ____
    _=__ __=
__ = ____
    _=__ __=
 = ____
    _= __=
_____ = ____
    _=_____ __=
_ = ____
    _=_ __=
__ = ____
    _=__ __=
__ = ____
    _=__ __=
 = ____
    _= __=
_ = ____
    _=_ __=
 = ___
    _= = 
___ = ____
    _=___ __=
__ = ____
    _=__ __=
_____ = ____
    _=_____ __=
__ = ____
    _=__ __=
___ = ____
    _=___ __=
___ = ____
    _=___ __=
____ = ____
    _=____ __=
____ = ____
    _=____
    __=
____ = ____
    _=____ __=
____ = ____
    _=____ __=
____ = ____
    _=____ __=
____ = ____
    _=____ __=
_____ = ____
    _=_____ __=
____ = ____
    _=____ __=
__ = ____
    _=__ __=
___ = ____
    _=___ __=
___ = ____
    _=___ __=
___ = ____
    _=___ __=
 = ____
    _= __=
____ = ____
    _=____ __=
_____ = ____
    _=_____
    __=
_ = ____
    _=_ __=
 = ___
    _= = 
   
 = __
_ = _
     =         
__ = ____
_ = ___
_ = ___
__ = __
    __
_ = ___
___ = __
    ___
____ = __
    ____
__ 主要做连续性的特征，对 这里有两种处理方式：一种是___；另一种是____，把对应的 转换为对应的数字。
 _
                
               
    _ = {
         
           _
    }
               
              
    _ = {
         
            =     
            =
            _= 
           _
    }
          
    _ = _  _
            
     = _
           
     _ 
在经过特征的处理之后，由于我们这里数据没有直接格式化分开成、，所以我们要做一个_的处理，将输入处理，参考仓库源码，将连续性特征转换为列名和值的，转化为特殊格式的格式。
模型训练
数据处理好之后，做模型训练就比较容易了，如下图，配置好对应的_和要保存的路径就好了
 __
     __

 __
     __

_ = _

 = 
    _=_ _=_
_=__ =
 = _=__ =
   
        
最终结果如下图：

这里，我仅仅是使用的做了一个小的，后面会有其他算法，之后会加上更多的小技巧，如何更方便的在中用好机器学习。具体代码见__
  
支持向量机使用方法差不多，基本上可以复用_中的代码，这里有三个比较不同的地方：

需要有一个_的列需要指定，所以我们需要在_中将其加上；

的调用底层有一个的，我在玩的过程发现了，具体描述在这儿大概原因是对连续值特征比如个数是，而值的是而非 ，提了个    ==          后面也有类似的问题，等着后续修复，暂时的解决方法是原先的_修改为：_ = {     _}；

模型替代：


_ = ‘__’
 = __=’_’
_=_
_=_
_=__ =
 = _=__ =
   
“ ”   
的代码见
_
一个重现    的例子 
最终个的结果：

随机森林的模型和的使用接口也有点差异，模型定义和训练的地方改为：
_ = {
    
    
        _=_
        _=
        
    
    
        _=_
        _=
        
    
    
        _=_
        _=
        
    }

 = __
    _=
    _=
    _=
    _=_  _
 = _ _=_ =__=

_=__ =
 = 
    _=__ = =_
 
   
        
而且由于在训练的时候，前面和都是没有任何输出，不是很友好，查了的文档，可以在训练过程中输出相关信息，只需要加一行_就可输出训练过程中的信息

当然这里是很粗糙的另外不知道怎么的的没有的输出，为了输出相关的信息，我这里定义了_传递给即可，后面在  的实验中会详细描述，最终结果：

的源码见：_
  
  可以很方便的在中定义使用，比较复杂的是做的一些处理，如 一般对实数列做处理，如_ = _ =         ，这里需要给定，将连续值离散化，这里不知道是否有不需要指定的或者按比例自己计算的，这个我后续调研下，离散后之后，可直接为列，但是通常会做更多的 ：_=_ __ __=这里为了代码的简单，我就只错了两个维度的_，以以前的经验来说，通常在特征维度上 这种效果提升会比较明显，尤其是这种线性模型。
的列通常不需要对连续性特征做多少处理，主要对 在离线化之后需要向量化，通常会使用__和_，通常__会对、这类值很容易穷举的，可取值不多，而_会重新向量化 ，官方源码里面有对这部分进行说明_具体里面的算法暂时还不太清楚，后面我会来细细研究下。
基本上的处理就是这样，然后就是模型了：
_ = {
   
    
        _=_
        _=
    
    
        _=_
        _=
    
    
        _=_
        _=
    }
_ = _=__ 
    __= =_ _=
 _ == 
     = _=_ 
        _=_ =__=
 _ == 
     = _=_ _=_ _=  =__=

     = 
        _=_
        __=_
        __=_
        __= 
        ____=
        =__=

_=__ =_ =_
 = _=__ =
   
         
这里我仿照了里面的写法，根据传参来定义不同模型，包括 、  和    ，在跑模型的过程中，配置为，只能打印，信息量太小， 这里使用，使用这里有个，必须要设置_=才行， 上有个专门提到过    _ ，但是没有修复，原因是后续会使用来替代，哎，动不动就重写，真是任性，这里为了使用，需要配置才行，这里我每保存下，也可以用更多的策略来配置，也可以在中配置 ，使在对应的变差时，及时停止训练：

最后实验的效果：

另外，某个的 的可视化界面：

这里本来想做下性能对比，但是因为没有对这个的数据集做过特别深的分析，所以就先不做性能对比了，这里只是试下怎么在下做常规的机器学习应用，还有后面会继续关注下怎么更好的使用这个工具
总结
最后，照例总结一下，的机器学习工确实可以实现它所吹的   ，但是到目前为止来说还是有一些不方便的地方，尤其是在数据处理方面相对于的生态还不是很强大，不过这本身就不是的强项，希望有第三方的公司能够开发出更方便做数据清洗、预处理的工具
而对比来说，无论是在算法模型的支持还是各种训练、验证的工具来说，还是差距很大的，当然也有其本身的优势，如支持、很容易扩展到集群看起来很容易，还没有测试、与的支持，希望能够把这套工具做下去，不仅仅是算法的支持，希望能有更多的文档还有一些小的做的工具，另外留一个坑在这儿，不知道怎么能够直接读的数据，考虑到当数据量特别大的时候可能内存放不下 ，是不是也有在训练深度模型的异步策略， 暂时还未发现，有了解的请告知下，谢谢，后续会做更深的一些分析，大家一起学习，所有的代码都在接《 点击率预测综述  上篇》
 几种常用点击率模型介绍
  
是微软内部竞赛出来的一个算法，也被后续很多算法作为对比的 。

这个算法的细节可以直接去看原文，这里只对优劣做一个简单介绍。该算法的基本思想是参数  是一个先验分布为正态分布的分布，参数为 、ó；在贝叶斯框架下，每一个样本都是在修正对应的分布参数 、ó；对应的更新公式为
该模型的优点是基于贝叶斯模型，因此可以做到在线学习，每个样本都可以对参数进行微调，同时   带来了在线学习的能力，可以及时应对用户兴趣的变化。
不足之处在于每个  对应权重都需要两个参数来描述，模型的尺寸是  的两倍，在复杂模型场景下这个成本可能比较难接受。
 
从文末的评测来看， 和朴素贝叶斯相比， 能在比较宽的  维度很好的拟合经验点击率的情况。
  
是  年  出的一篇  领域非常经典的论文， 年去北京参加 大会时，机器学习方向的演讲几乎都提到了这篇论文，可见该方法的成功。
前文提到，随着特征的增加，特征组合这件事将变得尤为困难，人力很难应付。假如一个点击率预测的系统涉及到  个特征，则熟悉二项式定理的同学可以心算出来所有可能的组合特征接近 ；这个数据有多恐怖呢？一张纸对着  次对应 ，出来的高度是  米，大约是几十万个珠穆朗玛峰那么高。而特征组合是在特征离散化以后做的，稍微几个特征分桶可能就不止  了，再组合，特征就会爆炸掉。
特征爆炸带来两个问题，一是不太可能再用人力的方式去做特征组合的事，这简直就是太平洋里捞一个水分子了。另一个问题是维度灾难，这个可以参考我  另一篇文章。
就是尝试提出一种解决特征组合问题的方案，基本思路是利用树模型的组合特性来自动做特征组合，具体一点是使用了  的特征组合能力。整体架构如下：

先在样本集上训练一个  的树模型，然后使用这个树模型对特征进行编码，将原始特征  对应的叶子节点按照  编码，作为新的特征，叠加到  模型里再训练一个  模型。预测的时候也是类似的流程，先对原始特征  通过  计算一遍，得到叶子节点情况，以途中为例，如果  落到第一棵树的第二个节点，第二棵树的第一个节点，则转换后的输入特征为、、、、；
 模型确实明显优于单独的  模型，我们在浏览器多个场景做了测试， 都有非常明显的提升，接近  个百分点。从训练来看， 也确实像 所说那样，很容易过拟合，但叠加  以后却能去的很不错的性能。 因为是在函数空间对残差进行连续的逼近，所以优点和缺点一样的明显；优点是可以逼近几乎任何函数的任何精度，缺点就是很容易过拟合，需要根据业务场景注意在树的棵数和深度上做一定的裁剪，才能平衡精度和过拟合。详细的推导请参看论文，我也只大概看明白原理，因为对泛函还不熟悉，以后有机会再来细讲这个模型的原理。
  
 是从 、 等针对  的在线学习算法改进而来，主要是工业界强烈的在线学习的需求驱动而来。有意思的是前面提到的微软的  也是一种天然的支持在线学习的算法。为什么要做在线学习？有哪些注意点呢？
在线学习背后的理念是每个人的兴趣是  的，离线训练的模型在线上可能不能快速对用户最新的行为作出反应。为了解决这个问题，一种做法是我们加快模型的频率，比如原来一天更新一次，现在一个小时更新一次，这种做法有很明显的瓶颈，比如如果我们的时间窗设置的比较长，用一个月或者两个月数据来跑模型，则可能导致模型在更新间隙内完不成训练；如果我们采用增量训练的方式，则增量时间窗的设置是个技术活，太短，很多曝光对应的点击还没有上来，导致训练数据的无效曝光比例偏高，如果太长，可能跟不上节奏；这也是在线学习的一个难点，在线学习一般也不会每一个回流数据立马更新模型，这会导致模型震荡频繁，攒一小段时间是个不错的选择，为此  的系统里有一个   的组件来做曝光和点击的归约。
今日头条披露的资料来看，在模型更新方面他们采用了增量更新定时校准的策略；类似于在线学习定时离线校准。这种策略应该也可以用到点击率的场景。
在线学习另外一个要重点解决的问题是学习率；离线训练的时候  往往使用一个公用的学习率η，但是在线学习这样做会带来问题的；因为样本分布不均衡，某些覆盖不是很高的特征对应的权重因为样本少得到的更新次数比较少，如果使用相同的学习率，则这些权重的收敛势必落后于覆盖率高的样本的特征对应的权重，尤其是有做学习率衰减的情况下；因此我们需要针对不同的权重来设置不同的学习率，做法也比较简单，基本思路是统计该维度样本数，多的衰减快点，少的衰减慢点以期能做到基本持平，详见 ，相关的 、 已经是前浪了，没时间可以不看，有时间酌情。
这里也顺带提一下  和  的关系， 主要是针对  部分的  ； 是两种不同模型的级联，这两个方案是可以很方便的糅合在一起的变成 ；但这里  的更新没法做到  ；可以做定期更新。理论上这种做法可能会效果更好一点。
  
提出的  是一种可以自有设置特征组合度数的回归算法，通常 = 的 拟合公式如下

选择一种损失函数后很容易用  之类的优化算法来计算  和 ；原文这块的论述有点模糊，没有指明目标函数的情况下对拟合公式使用了 ，有兴趣的同学可以一起探讨。
 的优势是因为可以自动进行特征间的组合，这解决了两个问题，一个是系数数据因为特征组合而能得到不错的   效果；另一个是特征组合解决了人工组合的尴尬， 与此有异曲同工之妙，因此  常常和  来一起讨论；从应用范围来看，业界  的使用范围应该是比  要广的；国内我所知只有世纪佳缘 是使用  替代了 。
 的另一个优点是会算出每个  对应的向量 ；这个向量可以看做对  的一种 ，例如后面  的场景，或者是  里对   做 ，后者我们正在计划尝试；前者因为可以通过   直接学习最佳的  向量，所以一般不会单独使用  来对  做 。
 的不足之处是在  数据集情况下，反而可能表现不佳，鱼与熊掌不可兼得啊！
  
介绍了  在美团的一些应用，个人理解是  的一个小改版，不多说。
 新用户：、、泛精准
对于系统的一个新用户，在没有历史消费数据的情况下，想要预测用户的点击率是一件比较困难的事；这里提供一种按照数据丰富度划分阶段的思路；义工划分为四个阶段：全新用户；少量消费数据用户；一般消费数据用户；充分消费数据用户；每一个新用户和系统的交互分为这四个阶段，分段的标准可以根据具体场景的实验数据来拍一下脑袋，在不同的阶段，我们是用不同的策略来进行用户数据的获取。
全新用户阶段，将用户和广告的匹配看做一个多臂老虎机问题，可供使用的  方法有 、汤普森采样 等。这两者的区别在于  几乎没有随机性，根据预估收益率置信度作为总的排序 ，选择最高的悬臂；汤普森采样是贝叶斯框架，将每个悬臂的收益概率  视为一个  分部；根据历史情况修正分部的参数，而需要选择的时候则对每个悬臂的分布进行采样，根据采样结果排序来选择悬臂，保持较好的随机性；在一些内容推荐系统也会经常使用汤普森采样来解决  问题。在点击率场景的全新用户阶段，我们使用  不失为一个选择。
在少量消费数据阶段，我们可以使用 ， 的核心思想是给用户展示他消费过的物品最相似的物品，比如一个用户消费了盗梦空间，则他有可能想继续观看泰坦尼克号。 的难点在于对物品向量化。
对于第三个阶段的用户，有一定的数据又不是很多，此时可以采用 这种降级的  模型，并且对其中的一些特征使用  技术，如贝叶斯平滑、指数平滑等；可以参看后面部分的接受。
第四个阶段就是常规用户，使用我们前面提到的各种点击率模型就好了。
新广告：、相关广告信息挖掘
新广告的点击率预测是另一个比较大的话题，这里我先简单分为两类，一类是临时性投放，比如某个新广告主偶然来试投一下汽车广告。如果广告主能提供一批种子用户，我们可以使用  的方法来优化之，可以参考  的，我理解是一个迭代处理，先基于种子用户和采样用户训练一个 ，然后用  对采样的用户做一轮 ，把得分高的用户刨除掉，剩下的用户定义为有效负用户，然后再和种子用户一起训练一个新的 ，将这个  作为候选  并圈取用户的指示器。
另一类新广告是广告主或者代理商在广告投放系统里投放的一个新的素材，这个时候虽然广告是全新的，但是我们任然可以从系统里挖掘出大量相关的信息，比如该广告对应的  的历史信息，对应的  的信息，对应类比的信息等，具体可以参考 。
  ：贝叶斯平滑、指数平滑
这节单独介绍下 这篇论文，和  不同，这篇文章主要是针对发生频率比较低的事情的一些优化，可以用于新广告，但也可以用于比较老只是频率低的广告。
想法的初衷是我们经常需要使用一些点击率特征，比如曝光两次点击一次我们可以得出  点击率，另一个广告是曝光一万次，点击五千次，也可以得到  的点击率，但是这两个  代表的意义能一样吗？前者随着曝光的增加，有可能会快速下滑，为了解决经验频率和概率之间的这种差异，我们引入平滑的技巧。
中使用了指数  和  分布平滑两种技巧，这两个技巧也可以一起使用。对于 ，既可以将历史信息融入到特种里，又保持了对历史信息的以往速度。是一个不错的平衡，从各个实践来看，使用平滑对模型性能都会有显著的提升。
 介绍
随着深度学习的火爆，在图像识别、推荐系统等领域都出现了深度学习的模型，那么深度学习是否可以应用到点击率模型呢？答案是肯定的，在国内公开的资料中可以查到深度学习点击率的资料应该是  所作，之前  也在内部做过一次分享，主要的出发点是  的这篇 核心的图片截取如下

从这张图可以看出，在最上层还是使用了  模型，和  对比可以看出两个模型的相似性和区别，前者使用  来做特征的组合，     后者使用两项不同的技术来处理，首先是对   进行 ，然后和   一起  成一个向量，通过三层  网络来做特征的表示学习；另一方面对于   还可以进行人工交叉组合，与左边网络自己学习到的特征一起加入到顶层  模型里作为最终的特征。
这里需要提到的一点是对于   的 ，没有使用独立的  之类的方法，而是通过   直接学习出来的，具体做法是对最  层使用类似  的做法，固定  后使用  训练向量，交替进行。和  之类独立训练的  向量相比，为什么联合训练的向量可能会更好呢？这个思想起源是哪里呢？
第一个问题我认为联合训练的  向量确实会比  单独  出来的要好，原因比较细微，熟悉  发展流程的同学应该知道，对传统   和   的一个改进就是将  系数替换为可以联合训练的 ，以  到数据之间  信息。详细的介绍可以参考我下一篇关于  的综述。
使用了类似   以同时获得  向量和权重矩阵的还有 。有兴趣的可以参考。
关于  的性能，普遍认为会比传统  高两位数百分点，浏览器正在尝试在  推荐场景下做一个横屏，从目前初步结论来看， 相比于纯  大约是两位数的提升，而  还没有看到明显效果，不过我们会进一步在参数调优上下些功夫，以期取得更好的效果。
 的缺陷主要体现在两方面，一方面是在线  时的性能瓶颈决定不能使用太宽、太深的网络，另一方面是如果做  ，这个问题据说百度凤巢是有做过，具体方案不得而知。
 强化学习
对强化学习做了基本介绍，而国外对强化学习投入比较大也引起足够关注的应该是  以及阿尔法狗了。个人看来强化学习和监督学习的关系有如随机过程和概率论的关系。前者强调的是动态过程，后者强调的是静态概率。从这个角度讲，前面所有的点击率模型都是在追踪静态概率，哪怕使用   也只是做了某种程度的 。
是否可以直接使用强化学习来做点击率或者推荐呢？答案我觉得是肯定的。这方面阿里应该是走在前沿，中提到因为采用深度强化学习和自适应学习的技术，阿里的双十一销量有 的提升。这是一个非常恐怖的数字，尤其是在阿里这样的体量下。请允许我引用其中一段文字来做个简单说明
“  年双  通过排序特征实时，引入商品实时转化率，实时售罄率模型进入搜索  和 ，让售罄商品额无效曝光大幅减少，并实现了成交转化的大幅提升； 年双  推出双链路实时计算体系，在特征实时的基础上，引入排序因子的在线学习，预测，以及基于多臂机学习的排序策略决策模型，在预热期和双  大幅提升了搜索流量的成交转化效率； 年实时学习和决策能力进一步升级，实现了排序因子的在线深度学习，和基于强化学习的排序策略决策模型，从而使得淘宝搜索的智能化进化至新的高度，并在今年的双 ，分桶测试效果表明，成交金额取得了近  的大幅提升。”
从这段描述可以看出阿里的技术演进思路，特征实时化。这套方案能否在鹅肠或者浏览器内部找到落地场景是我比较感兴趣的一个地方，接下来也会花一些时间来调研强化学习的。
结语
本文主要对笔者一段时间一来的阅读做一个小结，在机器学习领域，书籍出版是远远落后于业界知识更新的，这就逼迫我们每个从业者都需要大量阅读资料和论文，对一个已经工作几年的后台开发来说，是一个不小的挑战。
笔者为此做了不少的准备，包括花了两年的晚上时间把数学分析、概率论、线性代数、数值计算等数学基础复习一遍；然后才能够相对比较顺利的阅读 。在领略了一些点击率和算法的文章以后，深深感觉大家能看到的书籍太少，因此尝试做一个总结，试着梳理一个脉络，给后来者一个学习的 。然而由于本人生性驽钝，错误不实之处在所难免，唯望方家莫笑，以此顽石引出美玉，提升自己造福后人，如是而已。以上。
引用

        ；

          ’   ；

        ；

     

       

 







     

  ；

        

        

      ；

     

 ：  



      是一个全用户态 的高性能的网络接入开发包，基于、协议栈、微线程接口等，适用于各种需要网络接入的业务，用户只需要关注业务逻辑，简单的接入即可实现高性能的网络服务器。
本文介绍的详细架构及如何解决了内核协议栈面临的问题。
传统内核协议栈的性能瓶颈
在传统的内核协议栈中，网络包处理存在诸多瓶颈，严重影响网络包的收发性能。性能瓶颈主要包括以下几个方面


局部性失效  一个数据包的处理可能跨多个核心、缓存失效、不友好 一个数据包可能中断在，内核态处理在，用户态处理在，
 这样跨越多个核心，造成局部性失效，缓存失效，
 同时可能存在跨访问内存，性能受到很大影响。

中断处理  硬件中断、软中断、上下文切换 当网络中数据量很大时，大量的数据包产生频繁的硬件中断请求，
 这些硬件中断可以打断之前较低优先级的软中断或者系统调用的执行过程，
 如果这种打断频繁进行的话，将产生较高的性能开销。
 用户态内核态的上下文切换和软中断都增加了额外的开销。

内存拷贝  内核态和用户态之间的内存拷贝 网络数据包从网卡到应用程序需要经过如下的过程：
     数据从网卡通过等方式传到内核开辟的缓冲区；
     数据从内核空间复制到用户态空间。
 在内核协议栈中，这个耗时甚至占到了数据包整个处理流程的一半。

系统调用  软中断、上下文切换、锁竞争 频繁到达的硬件中断或者软中断都可能随时抢占系统调用的运行，这也将产生大量的上下文切换开销。
 内核中一些资源如表等都需要加锁处理，大量的并发操作造成很大的性能浪费，特别是大量短连接的创建。


总体架构
无共享架构

使用了多进程的无共享架构，每个进程、网卡队列绑定，具有无竞争、零拷贝、线性扩展、友好等特点。

各进程绑定独立的网卡队列和，每个节点使用独立的内存池，请求通过设置网卡散落到各进程进行处理，解决了局部性失效的问题。
使用的轮询模式，排除中断处理造成的性能影响。
使用作为网络模块，将数据包从网卡直接接收到用户态，减少内核态到用户态的内存拷贝。
请求平均分配到每个核上，通过设置的 函数保证相同、的请求落到同一个核上。
各进程拥有独立的协议栈、表等资源，消除了协议处理过程中的各种资源竞争。
进程之间不共享内存，通过无锁环形队列_传递通信，如包等。


用户态协议栈
移植协议栈至用户态。
通过外加头文件、宏控制、以及相关实现进行的移植，对源代码的修改不到行，对后续的跟进社区，升级版本非常友好。


内存分配相关函数重新实现。当前使用和，后续会替换成_和_
定时器使用_驱动，定时更新，定时执行。
移除内核线程、中断线程等，统一进行轮询处理。
移除文件系统相关的绑定。
移除内核中的所有锁，用空的宏替换掉。
其他 。

类接口和微线程框架
提供了类接口和微线程框架，方便现有应用接入，替换接口。
后续我们会提供类似_的方式，使得现有程序尽量无改动迁移到。
微线程框架，移植自腾讯开源的毫秒服务里使用的_。
具有同步编程、异步执行的特点，无需处理复杂的异步逻辑。

问题及优化

 
  由于使用的轮询模式，使用率会一直是，
  后续会引入的轮询中断模式，当连续几次轮询没有收到包后，
  转为中断模式，有包后持续轮询，直到又没包进来。
常规网络工具如、、等无法使用
  由于接管了网卡，所有的数据包都运行在用户态，常规的网络工具都无法使用，
  为此我们对一些工具进行了移植，目前已经完成了、。
  抓包可以在里配置开启，抓包文件也可以在里直接分析。
 
  当前的是运行在__模式下的，
  各个进程互不关联，无法使用原有的命令。后续会进行修复。

最佳实践

使用性能高的多核，配置里的_进程运行在哪些上运行多个进程。
使用、、的多队列网卡，支持硬件卸载功能，支持的队列数越多越好。
配置尽可能多的。
配置关闭抓包。




继续移植各种网络配置工具，方便在各种网络环境如等隧道下的部署使用。
移植的用户态驱动至，提升磁盘性能。
增加对数据流的点镜像等，方便对数据包进行自定义处理。
提供协议栈的相关优化模块，如加速、防护等。
类接口提供_方式，简化已有应用的接入方式。
提供等语言的接口封装，方便相关服务的快速接入。作者：

输入在移动端是一个很常用的功能，那么输入框必然是一个很重要的部分。然而，移动端输入框总会遇到各种各样的问题，无论是样式还是和两端体验不一致都是很让我们头疼的问题，那么如何使移动的输入框体验更贴近原生也成了一个需要我们多多思考和研究的问题。
一、文字输入限制问题
我们拿最多可输入个字为例。当输入字数注意，不是字符长度超过字时，会触发  提示，并且不能继续输入。
办法一： 可以使用  进行输入字数限制。但是这个办法只能单纯的限制  ，有时并不能真正的结局问题。
办法二：在将第二个办法之前先来讲讲下面的几种情况：
、非直接的文字输入
什么叫做非直接的文字输入呢？

当输入汉字时必然会是非直接输入，需要我们点选才能正式输入。
当我们字数限制为个字，需要实时检查是否到字。输入文字时，当有非直接的文字输入时，监听  事件和  事件都会直接触发判断字数逻辑，会截断我们正在输入的文字。
解决办法：
监听  当直接的文字输入时触发这时，当没选中中文的时候不会进行字数判断。        ``
      {
          = 
            {
             提示超过字
        }
    }
、 表情的输入
当输入  的时候，但是，当输入  表情的时候， 中判断  表情的  为，因此  正常应该最多只能输入个，但是  端却把  的  算为，可以输入个  。这样就导致了两端的体验不同。因此需要在  中来进行字数限制。
再加上汉字输入问题，那么就加入一个标记位，来判断是否是直接的文字输入。然后监听  ，限制字数，当超过字数限制的时候，把前个字截断显示出来就了。
``

 
  {
     = ；
}
  {
     = 
}
  {
      {
            = {
              =  
            
             超过字提示
        }
    }
}
二、置底展示问题
 中的输入体验永远伴随着一个问题，就是当唤起键盘后，整个页面会被键盘压缩，也就是说页面的高度变小，并且所有的全部变为了。效果：




使用  定位。
可见  中唤起键盘是覆盖在页面上，不会压缩页面。
在  上的效果： 




那么如果我们需要将输入框固定在屏幕下方，而当键盘被唤起同时输入框固定在键盘上方如下图样式该如何解决呢？


首先我们来看下  的表现。

可以看出，键盘会将页面顶上去。那么如果希望可以将输入框和键盘完全贴合，我们可以使用模拟一个假的输入框，使用定位将真正的输入框隐藏掉，当点击假的输入框的时候，将真正的输入框定位到键盘上方，并且手动获取输入框焦点。
在实现过程中需要注意下面几个问题：
、真正的输入框的位置计算：
首先记录无键盘时的 ，当键盘弹出后再获取当前的  ，两者的差值即为键盘的高度，那么定位真输入框自然就很容易了。
、在  下手动获取焦点不可以用  事件，需要使用  事件才可以手动触发
    ``

        {
         = 
        
    }
、当键盘收起的时候我们需要将真输入框再次隐藏掉，除了使用失去焦点方法，还有什么方法可以判断键盘是否收起呢？
这里可以使用  监听，当当前  和整屏高度相等的时候判断为键盘收起。注意：键盘弹起需要一点时间，所以计算当前屏幕高度也需要使用。
、因为  中的文字不能置底显示，当输入超过一行需要自动调整高度，因此将赋值给的。当删除文字的时候需要也有变化，因此每次都先将置，然后再赋值。
     
     
未完待续由于工作原因，经常要帮人选择云服务器系统和进行部署环境的设置及安全管理。所以每次开通一个新的云服务器后，都要花比较多的时间上去一个一个软件的安装测试调整及打补丁。但后来发现在只要用镜像功能就可以完整地将之前的配置好的服务器镜像导入到新的服务器中，简便了不少效率。
好吧，上干货，首先你必需拥有一个已经有自定义镜向存在的帐户我们先称为帐号。在 帐号里的云服务器中镜像，选择自定义镜像中共享。见下图

点击共享后会弹出一个框，让您输入对端账号唯一如下图，这个对端账号唯一其实就是要准备安装配置的另一帐号上的我们先称为帐号

那这个帐号中的“对端账号唯一”又怎么获得？秘密就在用帐号中登录上腾迅云后，在帐户信息里的帐号，就是我们需要的“对端账号唯一”

我们再回到帐号中，将刚才获得的帐号中的帐号，填入到“对端账号唯一”，点击“共享”，然后见证奇迹的时候开始了。

回到帐号上，在云服务器镜像中的共享镜像就会看到刚才帐号上的镜像，是不是很神奇呢，小伙伴们，赶紧尝试一下吧。引言
如题，普通工程师和高级工程师的差别在哪里？
工作年限？经验？老板重视程度？是否做出重大业绩？
首先，工作年限长的技术就一定更加高深么？
不见得！
这个世界上不知道有多少人，每天只是做着重复性的工作，毫无长进。虽说吃过的盐比其他人吃过的饭都多，但就是没记性，不断的重复着过去的错误。甚至伴随着年龄的增长、激情的磨损，反倒一年不如一年。
其次，工作经验，盖过个房子的一定就比只盖过个房子的更有经验么？
不见得！
有些人只需要盖过一个房子，就会对房子的地基、门窗、水暖管道、强弱电走线、等等了如指掌。而有些人，盖了一辈子的房子，连插头左右哪个是火线哪个是零线都分不清楚。

至于老板重视程度，这是结果，而非原因。技术高深，自然就受到重视；而不是相反的：受到了重视，所以技术才变得高深。
是否做出重大业绩，这确实是一个足够客观的衡量指标，但依然只是结果。更何况，如果是一群人共同做出的业绩，如何区分大家彼此之间的技术高低呢？
那么，普通工程师和高级工程师，差别到底在哪里呢？什么样的水平称得上高级工程师，什么样的水平只能称得上普通工程师？什么样的人一看就知道是高级工程师，什么样的人一看就知道最多是普通工程师？
初级工程师与门外汉的区别
初级工程师面对技术任务，至少是知道从何处入手的。
比如说修汽车，门外汉连空气滤清器在哪里都不知道，更不要说如何拆卸，如何安装了。
计算机软件专业的毕业生，至少明白做一个手机上的软件是需要安装编译环境的，一个门外汉对于几行代码变出来的游戏界面感到颇为神奇。
但是作为一个软件工程师，我真的很好奇一大堆黄豆是如何变成液体豆汁而后突然变成固体豆腐的。
所以，初级工程师对自己所从事的行业，至少是有大概的了解的，甚至具有一定的工作经验，可以在高级别同伴的带领下完成最为基本的操作。
初级工程师与普通工程师的区别
初级工程师刚刚入门，能够在师傅的指导下完成最最基本的流程化操作。但是由于熟练程度不足，完成任务的速度和质量无法保证；稍有遇到自己没做过，或者不熟悉的技术问题，都需要花费更多的时间学习。
在一个行业内做过许多事情之后也可以是一个大事情内部的许多细分小事情，对各种技术问题都有接触，并都有成功解决的经历。于是，大部分的技术问题不再陌生，甚至非常熟练。自然而然，成长为普通工程师。
两者最典型的区别有：
、行业相关的众多技术点，是否都有了解；
、行业相关的众多细分工作，是否都有“熟练”操作过，完成的质量是否有足够保证；
、行业相关的不同任务，能否给出明确的工期预测；
普通工程师与高级工程师的区别
大部分人会停留在普通工程师的状态，因为伴随着大家对自身工作内容的逐步熟悉，伴随着大家日复一日重复同样操作的逐渐熟练，这些知识和技能足以满足通常的工作需要。
很少有人会考虑：
、更快效率：目前的操作流程是否是最快的？如何改进？
、更好效果或性能：目前的解决方案是否是最佳的？能否进一步提升性能？
、更省成本：什么样的方式能够降低人力成本、财物成本？
会做炸鸡的厨师很多——初级；
努努力做出口感好的炸鸡，也不是太难，只要肯卖力练习就行——普通级；
尽心专研，做出超级口感的炸鸡，真的需要好好专研、总结的——更好；
像肯德基那样，让入门级的厨师甚至门外汉都能够做出口感好的炸鸡，则需要对炸鸡的油温、时间等等做出仔细的研究，然后制作出对应的设备、操作流程。这是对一个行业的彻底颠覆。这样的级别，就不仅仅是高级了，而是专家级别。
如何最快速的成长
如何最快速的从初级到高级？区别明确了，问题就好办了！
、争取做自己不熟悉、不会做的；——不熟悉的熟悉了，不会做的会做了，自然就成长了；
、多做自己不熟练的、有难度的；——不熟练的熟练了，有难度的变得轻松了，自然就进步了；
、习以为常的操作，多考虑一下是否能够换个方式做得更快、更好、更省；自己琢磨也好，参考业内高手也行
、可以的话，思考一下如何让门外汉或初级员工更方便的做这个事情；
、尝试解决那些大家都解决不了的甚至被认为根本不可能解决的问题。
从初级到普通级别，勤学苦练足矣；
从普通级别到高级，则需要多动动脑子，多思考，多对比，多总结，多摸索。
越是有难度的问题，越是没人能够解决的问题，越是从来没有人考虑过的问题，价值越高！
如何面试考察对方的级别
、你做过这个事情么？或者：简历里你印象最深刻的事情是哪个？
、做的过程中遇到过什么问题？
、你是如何解决这些遇到的问题或者其它一些奇葩的问题的？
、类似的事情重新让你做的话，大概需要多久？
、你们做过的这些工作，都有哪些地方可以继续改善提升的？
、业内的通常做法是怎样的？为什么？有没有更好的方案？
初级工程师的自我介绍是这样的：我会做十道凉菜、三十道热菜；
普通工程师的自我介绍是这样的：我一小时能做二十道菜；
高级工程师的自我介绍是这样的：打从我来到饭店后，客人更多了，赚钱更多了；
专家工程师的自我介绍是这样的：你听过这道菜么？是我第一个搞出来的。
以上内容来自本人个人公众号【水滴的声音】关注企业文化、团队管理深度学习应该这一两年计算机圈子里最热的一个词了。基于深度学习，工程师们在图像，语音，等领域都取得了令人振奋的进展。而深度学习本身也在不断的探索和发展中，其潜力的极限目前还没有被看到。

当然，深度学习也不是万能的，比如有很多问题的特征是易于提取的，我们可以直接使用 决策树的算法来取得很好的结果。而深度学习并不能提供太多的帮助。还有一些问题，我们并没有足够数量的数据，我们也很难通过深度学习算法来得到可用的模型。此外，有些问题对计算资源和时间的要求比较严苛，在深度学习小型化没有取得突破性进展的时候，它们也不是首选方法。

 判断一个项目适不适合上深度学习的正确姿势 图片来源   深度学习防骗指南   
反过来说，虽然目前深度学习在个性化推荐，计算广告领域上还没有很大的突破，但是我认为推荐系统有很大概率会是深度学习的最重要的应用场景之一。理由有以下几个方面：

现在的推荐系统都要面对海量的数据，要提取上万乃至上亿维的特征。而深度学习本身就是一个很好的表示学习的框架，从海量的数据中学习到人类无法提取的特征组合，是其擅长的事情。


 图片来源   深度学习防骗指南   

数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。现有的推荐系统依赖于特征工程的效果。而特征工程建立在不断的深入理解问题和获取额外的数据源上。然而根据数据人能抽象出来的特征总类很有限，新数据源和新特征的获得会越来越难。随着人工特征工程的深入，投入的人力和时间越来越长，得到的新特征对系统的提升却越来越少。这个时候，使用深度学习来做特征表达，在成本上也许是一个更好的选择。


图： 系统的精度提升曲线。可以看到一开始的时候结果提升的特别快，后面一点点的提升都要付出很大的努力，
因此我们基于在某个业务上做了的尝试，跑通了整个流程，积累了一些经验。也比原有的模型在线上有了多的提升。希望这些代码也可以帮助各位同学快速的在自己的业务上实现一套深度模型的框架。

图： 在预估的一般框架
一般来说，我们可以先选择一个比较简单的框架来跑通整个流程，然后再慢慢增加模型的复杂度。通常我们可以选用下图的框架，把我们用到的数据分为两类：连续的，和离散的特征。
对于连续的特征，需要做一些归一化；对于离散的特征，则一般要做一个，把一个离散的特征转成一个维的向量。这个向量的长度一般来说是和该向量的取值空间成正比的。这个的过程可以用来实现。 在我们的代码里，是通过自动_实现的。
所以把用户数据和推荐的物品数据放一起分成两类，然后把之后的离散特征 和 连续特征组合在一起，作为神经网络的输入，输出就是 是否点击。这里面我们就直接调用的。这个网络可以设计层数，每层的大小， 激活函数，学习率等等。
         = _=
                                    =
                                    =                 


         = _=_
                                           _=_
                                           _=  
                                            = 
                                           _=         
                                           = 
所以后面就是一个不断调参的过程，当然这个调参也是有一些技巧。网上有很多，在这里就不一一来说了。

深度学习调参师 图片来源   深度学习防骗指南   
总的来说，深度学习没有那么神秘，它是一个很有效的工具。在个性化推荐上应该已经有很多团队进行了很多尝试。在这里，我们给出了一个简单和有效的基于的实现方式，也希望可以帮助一些想要尝试深度学习的一些团队。

 图片来源   李沐 来一起动手学深度学习吧    前言
本文是对初始接触  开发的入门介绍，说明如何搭建一个比较完整的  开发环境，如何开始应用相关工具，基于如下场景：

使用   存储数据；
使用  进行并行计算；
使用  开发应用程序；
使用  工具对  代码进行构建管理；

其中前两项属于  计算环境搭建，后两项属于  编程。文中如有错误或者不当之处，敬请指正。
 方案简介
分布式计算有两个基础性问题：计算的并行调度与数据的分布存储，我们使用  来解决计算并行调度的问题，使用   解决分布式存储的问题。简述下原因：

为什么选择 ？

 具备简洁优雅的数据抽象 编程接口简洁明了；
能支持多种计算模型批处理、流式、图计算等，其它计算框架往往侧重一种模型 侧重批处理、 侧重流式计算，选择  可以在一个框架内解决多种类型的任务，节省学习成本；
较之于其它计算平台，没有明显的性能短板其批处理性能要大大优于  ；


为什么选择  

  是当前应用广泛的一款分布式存储软件，其生态系统完善， 对其的支持也很好，这也是一个比较自然的选择；



   搭建
首先搭建    是  项目中的一个组件，本文中说明的部署方式仅为在单机上搭建完整开发环境只包含一个  和一个 ，无  支持，生产环境会复杂一些，请参阅  官方文档。搭建过程如下：
 准备
先确认已安装  以能保证程序运行需要，但开发环境还是需要安装 ，如果没有，请从  站点下载安装商业版本，不要使用公司主机    安装的 。如果是直接解压  包安装，安装后请设置环境变量：
      
 _=
 =_

  生效配置
  
本例中，使用  用户进行操作， 用户目录为 。
 安装

在  官网下载最新版本  软件  当前是  直接解压即可安装，本例中安装目录为 
安装后  目录结构如下：
  
  |
     工具程序目录
     配置文件目录
     服务程序目录，主要为服务程序启停脚本
      其它暂不关心


 配置
如果我们只需使用 ，有如下几个配置配置文件需要关注：







、 配置  进程运行时的相关环境变量，对于搭建开发环境，只需要设置一个配置项：
      _=
在准备工作中，我们已经将其加入到  环境变量中了，但在运行  脚本时，这个环境变量并不能带给脚本程序。
、 配置  服务公共配置项，目前也只需要配置一项：
     
     
             
             
     
     
             
             
     
 
 和  均是全局的，影响  服务、管理工具以及其它  组件。通过这两个参数，可以配置  对外服务地址以及数据的存储路径，存在如下推导关系：
    
     {}
     {}
、 保存  专有配置
     
     
             
             
     
 
开发环境只启动了一个  实例，因此每个数据块只能有一个副本。
、 配置  主机列表  安装包已经将  节点加入了。
、  日志配置，开发环境可以将日志设置为  级别。
     =
 启动准备
配置  了，很兴奋，就可以将服务跑起来了。且慢，还需要做两个准备操作。
、  初始化
        
初始化过程中会自动创建所需要的目录。初始化完成后，已经可以启动  服务了，但为了操作更方便些，还需要处理下面步骤。
、 公钥免密登录授权
 是一个集群服务，我们可以在  节点上操作所有的  节点， 是通过封装  远程  实现的  内通过  远程起停  节点上的服务。虽然我们的开发集群只是一个单机节点，但任然需要开通本机 对本地 的  免密登录，方便集群管理，具体设置方式这里不再赘述，如不了解，可自行搜索相关资料。
 启动服务
 
启动集群只需上面一行命令，如果没有什么端口冲突，应该是一切顺利了。万一有端口冲突，也没关系， 这里可以查询所有  服务端口配置项，结合日志，更改下冲突项目就行。
现在，我们可以看到运行了如下  相关服务进程：
 

 
 
 
除了   外，另外还多出一个  进程，这个名字容易让人误解，它并非是  的备份，而是为了更可靠维护  元数据信息而提供的服务实例，定期将修改合并到元数据存储文件，目前我们可以忽略它。
类似的，停止集群也是一行命令：
 
 导入数据
    
     
    
  
               

    
          
 
通过上面列出的操作，我们在  建立了目录  并将本地文件系统的  文件上传到了 如果集群中存在多个  则文件数据将会分布在多个主机上。  工具的使用方式与  类似，其帮助信息有对用法的详细说明，这里不再赘述。
 挂接到本地文件系统
上面通过  工具的方式访问  有两个弊端：

不如直接使用    等命令操作本地文件系统方便；
每次执行都需要重新启动  虚拟机，启动时间长，开发过程中可能存在大量临时访问，影响工作效率。

对于上述问题， 已提供了解决方案。 提供了    可以将  以  方式挂接到本地文件系统中，以支持常规  命令的访问，由于   服务是常驻服务，也就避免了反复启动  虚拟机，大大提升了临时操作的效率。下面简述下设置过程，更多的信息可以参考  官方文档。当然，如果您想快点开始  编程，也可以略过此节。
   配置
基础功能只需在  加入：

    
        


    
    

这里配置  用户授权，需要注意的是  需要替换为当下启动   的  用户名本例中为 ，上面配置表示允许运行在所有主机上的、以 用户启动的网关访问任意  用户组下的文件 文件。
 启动  
     
 
 

       
    
   

         
      
        
     

  
  
      ==  

  
  
 
      月    
       月    

    
      
     
 小结
到这里，我们已经搭建好了一个最简化的  集群，可以支持进行开发测试，下面介绍  的搭建与编程。
 搭建  服务
部署一个单机环境的  服务很简便，这里简单介绍下，更多关于  的部署介绍可以查看官网：
 安装
首先在官网下载最新稳定版本，目前是 ，解压到目标目录即完成安装，本文中安装目录为   解压后主要包含如下子目录：


        |
             工具程序目录
            配置文件目录
              包目录
             目录
            服务程序管理脚本目录
不做任何配置，此时已可以启动  服务
 
 
 
 
如果没有端口冲突，一般都能启动成功。本例中这种运行模式  称之为 独立模式，不依赖其它服务构成集群，这种模式一般包括一个  实例和多个  实例，能以最简单的方式建立起一个集群，方便开发和构建小规模集群。 还支持  和基于通用资源管理器  的集群两种运行模式，分别适用于开发调试与大规模集群部署两种场景。关于运行模式的更详细说明参见官网。
 配置
虽然可以零配置启动服务，但为了开发时对系统有更多控制，简单说明下开发中可能会修改的几个基础配置。
、日志级别 
 预装了配置模板  将其拷贝为 ，即可修改日志配置。
      日志设置为  级别
 = 
、系统配置：
该文件为系统主要配置文件，服务和工具程序都可能会使用到，在初步使用时，可能会配置到如下参数：
        服务绑定地址
                      
  配置执行器占用内存默认 ， 存在于  进程中
  内存总量 为系统最大并行存在执行器数目。
  开发时可能修改改值，以获得适当的执行器数目
             
  工具简介



交互式  编程环境，使用  语言。 启动时，会导入相关依赖库，并创建名称为  的  对象，这个对象是通向  世界的向导，我们已经可以在交互环境开始第一次  分布式计算之旅了。
      
  
   = 
    = 
   =      
    =  =   =  _   _
    =     
  
    =     
  
   = 
  
 
  后提供了新的切入点  类 在  启动时会创建名称为   对象， = ，关于    等  编程核心概念这里不做展开，在网络上很容易获得相关介绍资料。
 中输入  可以退出  输入 可以获取帮助。
上面例子中，对本地的  文件使用  做了单词计数。如果  规模巨大，难以在单台服务器对其进行单词计数，我们只需增加服务器，将  和  扩展为一个多服务器集群，先将数据导入的 ，就可执行分布式并行计算了。对于复杂的数据与计算的分布管理，则交给  和  去处理，我们在编程上，与本地计算代码几乎没有区别。下面是分布式集群环境计算的代码：
      _    
  
    = 
    =  =   =  _   _
  
 需要替换为多主机集群环境下，实际   服务访问地址。



功能与  相同，提供支持  交互式编程环境。我们可以通过设置环境变量 _ 启用习惯的  ，譬如 。
       _=
  
  
         
    
   
    
同样的，  也会在启动时预建名称为   对象，作为调用  集群功能入口。

其它

 在  目录下还提供了其它一些核心工具，这里简单列举下，进入到  的世界后，自然也会掌握它们的用法。
  提交  到  执行
   交互查询工具， 支持以  语句描述数据处理过程
   语言交互编程环境
 小结
本节中，我们搭建了一个最简单的单机独立模式集群，并通过  提供的交互编程环境执行了单词计数的任务，感受到了  对分布式计算优雅简洁的描述。 自身主要采用  进行开发，提供     等语言编程接口。一般而言，使用与系统实现语言相同的  语言进行应用开发，在保障最大化运行时性能的同时  程序会被编译直接在  上运行的代码，  程序运行时存在虚拟机之间的交互，也能获得很好的开发效率，另外，掌握  编程，也有助于对  进行更深入的学习理解。下一节简单介绍下  编程环境的搭建。
  开发环境搭建
如果要开发正式的应用，一个好用的构建工具是必须的，不然光是管理  包繁琐依赖就会耗费大量时间，另外，各个版本的  运行时库可能不兼容，支持多目标版本编译也需要专业工具支持才行。
所谓搭建  开发环境，也就是选出这个工具，并安装配置好。 开发可选则的构建工具主要有    这三个。我这里选择 ，原因是这三者虽然功能上难分伯仲，但  与  具备天然的亲和性，它自身是使用  编写的，其工程定义文件实际也是一个  程序，使用它构建  项目更加简洁纯粹。
  简介
 官网  在这上面有有很详细的  中文文档。
 从官网下载最新版本，开箱即可使用，其安装说名这里不再赘述。 解压后的主要内容如下：


  |
            执行工具路径
           配置目录  全局工作选项以及  启动   参数 
            预装  包
  工程样例
将上面在交互模式下运行的单词计数使用独立的  程序实现。
、首先创建  工程 建立如下结构的目录与文件：
                                   
 
      |
                               工程定义文件
                                选项与编译扩展插件目录，当前留空 
          源代码
关于更多  工程目录结构信息，可以查看官网文档。
、配置 
        =   
     
        = 
        = 
        = 
     
上面语句实际就是一行  代码    语句生成了一个  工程对象，之后调用其  函数，设置工程属性。使用程序语言定义工程会非常简洁灵活，具备非常好的可扩展性。
重要：  必须与当前  使用的  版本一致，否则生成的  包不一定能在  环境中运行，这个版本可以通过查看 _ 文件名称获取到。
、编写 
      

   {
        {
           = 
           
           
           

           = 
         
            =  
            =  
           _   _
           

         
     }
 }
、关联  本地  包依赖
 工程依赖分为托管依赖  与非托管依赖 。托管依赖指在远程组件仓库  等管理的依赖包，工程中定义声明下使用的版本，编译时直接从远程下载。非托管依赖只存在于本地的依赖包，默认为工程根目录下  子目录。 工程依赖  的  包，已存在于  安装目录下，因此直接在工程目录下建立如下软连接是最便捷的完成依赖包设定的方式：
   
 会首先从本地库中寻找寻找被引用组件包。
、编译与打包
      
执行上述命令，完成编译打包，生成  文件，到这里，第一个独立打包的   已孵出了。
、提交运行
终于可以  了
  之前已经通过  将  挂载到本地文件系统中，先删除  目录，避免程序结束时保存结果冲突
    

  提交 
     _

  查看结果
   
     _
   
 
 
 
 
  
 全文小结
到这里，我们已经走完了从开发环境搭建到应用工程建立与测试的历程，在  之海的浅滩处小游了一下：

搭建了单  的  集群，数据的分布是分布式并行计算的基础；

以  模式运行了一个  集群，对分布式计算调度进行管理；

使用  编写了单词计数的程序，使用  进行构建管理，将其提交给  集群执行，真实感受到了  编程接口的简洁优雅。


但毕竟还是在浅滩，要真实使用  解决比较大规模的计算任务，我们还要持续向  之海的深水区探索：

生产环境需要构建可靠集群，解决     单点问题；

需要更全面的理解  对分布式计算的抽象：      … 这里有几篇很好的网文：

 为什么需要 
   之比较
   


需要学习一门新语言： 另外也需要了解  虚拟机运行时；

需要了解更多  工具使用问题：依赖管理、多模块定义、插件扩展等。导语
共同好友作为一种社交特征的典型代表，被广泛用于推荐、广告、游戏领域。当用户量达到海量的场景，通常是按月计算全量共同好友列表，时效性较低，甚至因为计算资源消耗过大而无法计算。相比而言，计算新增共同好友有着更大的价值。本文介绍一种千亿关系链下的日新增共同好友挖掘算法算法。该算法基于分治的思想，将新增共好友计算问题，转换为更易于运算与实现的三角形计算问题。该算法也可十分便捷的移植到其他需要计算新增共同好友的场景。

作者： 

背景与思路
对于大多数场景，通常都会将共同好友数作为衡量用户亲密度的重要依据。然而，共同好友本身的挖掘有更大的意义。这里共同好友的挖掘是指计算用户三角形如有共同好友，则存在好友三角形。在社交化推荐中，根据场景用户的偏好，能够为非场景用户提供推荐依据在广告场景中，共同好友间会经常查看动态和互动，覆盖到三者中的一个可以起到推广到三者的目的在游戏场景，稳定关系的可能会经常开黑，当，入坑王者荣耀后，为推荐这款游戏应该有不错效果。
可见，无论是推荐场景、广告场景还是社交运营场景，共同好友都有极其重要的意义。在用户量关系到达百亿甚至千亿的时候，共同好友计算需要消耗大量资源，通常都是按月例行。这样无法发挥新增关系的时效性。在这类场景中，计算新增共同好友的挖掘计算更为重要。
模型介绍
计算新增共同好友的过程，实际上可看作是一个计算新增三角形的过程。例如，用户和，都新添加好友实质是新增三角形。
这里，我们设计了一种新增三角形挖掘算法   简称算法。该算法根据新增边的个数，将新增三角形分成三角形条新增边，三角形条新增边，三角形条新增边。然后分别采用不同的计算模式，计算不同类型新增三角形。这里三角形的新增边实际是业务新增关系链，非新增边是业务已有的历史全量关系链。整个计算模式如下图所示。

图：计算模型 
为了减少三角形的重复存储和计算，我们计算的新增三角形都是有序三角形，即值。
算法实现
  三角形计算
三角形的三条新增边都来自新增关系链，计算量是三类新增三角形中最小的。这里我们采用基于的   算法，计算新增关系链所形成网络结构中的三角形。具体过程为：
 收集邻居信息
首先需要读取新增关系链数据作为边，建立初始图如下图左侧所示。简单起见，可以直接将关系链两端点的场景用户_作为点。这里用表示顶点值。完成建初始图操作后，遍历图中各点，收集邻居信息存于顶点属性如下图右侧所示。

图：聚合邻居信息 
这里我们用圈表示顶点，用矩形表示顶点属性。如顶点有邻居、、、 则、、、存于的顶点属性。
 计算共同好友
完成邻居信息的收集后，就可以进行共同好友的计算。这里我们遍历图各边，比较边两端点的属性值，计算其中的共现_，即为共同好友。

图： 计算共同好友 
如图所示，计算边时，的属性值和的属性值无交集，表示与没有共同好友这里用表示；计算边时，的属性值和的属性值有交集、，则表示和有个共同好友、。
 计算好友三角形
为了避免同一条形成的相同好友三角形被多少统计。共同好友计算完成后，将计算的共同好友和边端点组成有序三角形，发送给值较小的顶点。

图：计算好友三角形 
如图所示，边计算出的共同好友与端点组成有序三角形 顶点值大小，并发送给顶点值较小的端点；边计算出的共同好友和，与端点组成有序三角形和发送给顶点值较小的端点。
 聚合好友三角形
度大于的顶点，可能在多个边形成好友三角形。按边计算完好友三角形后，需要按顶点聚合所在不同边的三角形。

图：聚合好友三角形 
如同所示，会收到形成的三角形和和边形成的三角形。在顶点对信息进行合并去重后，将有效三角形序列和存于的顶点属性。
值得注意的是这里好友三角形，依然存在重复存储点和点都存有三角形。最终按顶点输出好友三角形后需要做去重操作由于已经是有序三角形了，去重操作的计算量会大大减少。
算法不仅可以用于新增三角形计算，对于场景内关系链量级在百亿以内的场景，都可以直接用于三角形计算，从而计算共同好友列表。并且在计算共同好友列表的过程中，可以同时计算共同好友数。
  三角形计算
三角形由条新增边和条全量边组成。它的特殊在于需要计算全量关系链，建图较为困难；但又不涉及全量链之间的操作。因此我们采用基于新增链的   算法计算新增边与全量边组成的三角形。具体过程为

新增关系链集合   找到两边 在中的三角形序列集合
对进行操作，转换为非新增关系链为主键形式 
转换后的   为最近一次更新的全量关系链 找出在中的三角形

算法的计算过程较为简单，这里不作过多描述。
  三角形计算
由条新增边和条全量边组成，是三类三角形中计算量最大的。为了减少计算量，这里采用新增边全量边的结果，再去一次全量边的整体思路。由于计算过程中边端点在前后都需要保持有序，因此我们采用基于的   算法计算新增边与全量边组成的三角形。具体过程为：
连接单向边读取新增关系链集合和历史全量关系链集合，筛选单向关系链  。

图：单向边连接 
如图所示，从新增关系链取有序边与全量关系链取的有序边做连接，得到以为主键的元组。
有序过滤
由于最终计算的是有序三角形，这里先根据元组的非主键部分，进行筛选过滤，保证非组件部分成有序。

图： 有序过滤 
这里筛选非主键部分的元组，得到。从而不仅确保了元组中三个单元的大小关系，而且对于输入集合有交集的扩展场景存在=，可以去除=的元组。
主键转换
为了判定边是否在全量关系链中，需要将上述结果与集合做连接操作。在之前需要对元组进行主键转换，让成为主键。

图：主键转换 
这里以为主键相当于为添加一条虚链不确定是否存在。
三角形计算
最终将第步的结果集与进行连接，从而筛选出边在中的元组。对该元组进行转换操作即可得到有序的三角形。

图：三角形计算 
由于根据前面的过滤筛选，已经得知了三者的大小关系。在与连接得到边在中的元组后，经过简单的转换操作，即可得到有序三角形。
算法调优
这里列举几个实现过程中值得注意的地方
读表后先再处理
考虑到直接从读取的数据可能存在分布不均匀。 表中的数据后，先进行 或  操作，可以在一定程度上解决数据倾斜问题。
充分利用和内存
这里三角形计算任务对内存消耗较大，较容易出现应用组内存资源不足，负载未满的情况。为了充分利用和内存数平规定，二者负载都满了，才能追加资源啊，可以根据需要将_ 设置为或
边分区策略代替点分区策略
当边数量太大的时候，采用默认的点分区策略，计算代价都非常高。因此这里采用边分区策略建图。
大任务拆分成多个小任务
这里主要是针对单任务迭代过程可能由于量大，导致内存溢出。遇到类似问题，可以考虑采用分治的思想，将任务拆分成若干小任务。
附录
三角形计算

                                   
                                  
                             
                     我在腾讯云服务器上跑了一个爬虫，定期监测某个网站的文章更新，使用的数据库是 具体是  版。我最近想在本地端直接连接到服务器上运行的那个数据库进行查询，但是  在安装时并没有默认开启允许远程访问，必须要进行额外的配置。
本文介绍的就是如何开启  数据库远程访问的具体步骤和方法。本文所列操作，也适合希望使用云服务器自建数据库的同学。
第一步：登陆数据库所在服务器
由于以下大部分操作都需要在数据库所在的服务器上完成，因此请先确保能够通过  客户端登陆到服务器，并切换到  用户下。
 _
      下默认创建  用户时可能没有设置密码，需要通过能够执行  命令的用户切换
第二步：启用客户端验证
 的客户端验证由一个名为 _ 的配置文件控制， 的意思是「基于主机的验证」 。按照官方文档的解释，该文件一般位于数据库目录中的  子目录下。
不过在我的线上环境中，这个文件位于  下。
_ 文件的格式是一组记录，每条记录一行。记录的格式如下：
               
可选的形式共有  种，上面只列了本文将用到记录格式，其余内容详见官方文档。

：表示匹配使用  进行的连接
：指定该条记录匹配的数据库，可设置为 
：指定该条记录匹配的数据库用户，可设置为 
：表示连接时进行验证的方式，常见的选项有：
：无条件允许连接，意味着任何人都能够访问
：要求客户端提供  加密过的密码
：要求客户端提供未经加密的密码



由于我们的目的是希望能够从任意公网  访问数据库，不限制用户和数据库，并且确保密码不会轻易泄露，因此输入以下记录：
 
 _  在文件的最后加上以下记录
    
所以，最后在实际连接时，切记对用户密码进行  加密。
第三步：启用  连接
接下来，我们还要开启  允许通过  进行连接的特性。这主要通过  配置文件控制，该文件和 _ 处于同一目录下。
 
然后，将配置中的监听  地址设置为 ，表示要监听来自所有  的连接请求。
_ = 
第四步：重启 
完成以上两个核心步骤之后，我们基本的配置工作就完成了。接下来重启数据库服务。
  
第五步：安全组设置
最后，由于我们使用的是腾讯云服务器，会通过安全组设置来控制对外开放的端口。我们要确保数据库所使用的  端口是打开的。
打开安全组的控制台页面。选择目前服务器正在使用的安全组，然后进行编辑。
安全组配置主要包括入站规则和出站规则的配置，示意图如下：

结语
至此，我们就完成了所有配置工作。以后，就可以在本地通过命令行或者  工具直接连接到远程数据库，查询最新的数据情况了。不过根据数据量的大小和带宽限制，查询的时间可能会比较长。编译 | 科技大本营参与 | 史天，胡永波，鸽子

我的天啊，这些少年们，让身为多年程序猿，却还在吃草的我们，情何以堪，情何以堪哥也只剩下最后一点自信了，那就是

说点正事那个
你知道啥叫变分自编码机吗？
你知道为啥你需要懂变分自编码机呢？
你知道如何以最快的速度搞懂变分自编码机吗？
啥也不说了，还是让这位岁的天才少年讲给你听吧。
 是加州 的一名高中生，他年级轻轻便已写出两篇论文，并且对生成式模型颇有研究。他的成名作是一个名为的项目。
现在，他正在以实习生的身份在做强化学习方面的研究。
本文是   用自己写的实例来讲解变分自编码机，对于自编码机与变分自编码机的工作原理、使用变分自编码机时的优缺点，他都做了特别细心的解释，是了解变分自编码机不可多得的一篇好文。
下面，我们就来看看这个高中生的实力到底有几何：
我曾经讲解过一次生成式对抗网络，谈的是用它来生成逼真图像的一个简单例子。
但这中间有些问题，即单纯使用存在两大不利因素。
首先，这里的图像生成自某些随机的噪点。如果你想生成的是一张特定细节的图像，除了遍历初始噪点的整个分布范围，你没有别的办法来找出它们的值。
其次，生成式对抗模型只能区分出图像的“真”、“假”。你没有办法强制它所生成猫图必须看起来像猫。这就造成了一个问题，就是它所生成的图像不是参照真实的物体，而是参照的他们在图片中的样子，风格上不会特别写实。
如何解决这两个问题呢？
我会在本文中介绍另一种神经网络——变分自编码机，来解决这两个问题。
什么是变分自编码机？
要理解变分自编码机，我们要先从一个简单的网络开始，一步一步添加部件。
描述神经网络的常见方法，是把它解释成我们想要建模的功能的某种近似。然而，它们还能被理解为储存信息的某种数据结构。
假设有一个由数层解卷积层构成的神经网络，我们把输入设定为单位向量，然后训练该网络去降低其与目标图像之间的均方误差。这样，该图像的“数据”就包含在神经网络当前的参数之中了。

现在，我们用多张图像来尝试这一步骤。此时，输入不再是单位向量，而要改用独热向量。比如，输入     可能是生成一张猫的图像，而输入     则可能生成一张狗的图像。这是可行的，不过这样我们只能存储最多张图像。让网络记住更多的图像则要使用更长的向量，同时也意味着越来越多的参数。
为此，我们需要使用实向量，而非独热向量。我们可以把它视为某个图像所对应的编码，比如用向量     来表示猫的图像，而用向量     来表示狗的图像，这就是 编码解码 这一术语的来源。这一初始向量便是我们的潜在变量。
像我前面那样随机选择潜在变量，明显是个糟糕的做法。在自编码机中，我们加入了一个能自动把原始图像编码成向量的组件。上述解卷积层则能把这些向量“解码”回原始图像。

这样，我们的模型终于到了一个能有用武之地的阶段。根据需要，我们可以用尽可能多的图像来训练网络。如果保存了某张图像的编码向量，我们随时就能用解码组件来重建该图像，整个过程仅需一个标准的自编码机。
不过，这里我们想要的是构建一个生成式模型，而非仅仅是“记忆”图像数据的模糊结构。除了像前面那样从已有图像中编码出潜在向量，我们还不知道如何创造这些向量，也就无法凭空生成任何图像。
这里有个简单的办法。我们给编码网络增加一个约束，迫使它所生成的潜在向量大体上服从于单位高斯分布。该约束条件使得变分自编码机不同于标准自编码机。
现在，生成新的图像就变得容易了：我们只需从单位高斯分布中采样出一个潜在向量，并将其传到解码器即可。
实际操作中，我们需要仔细权衡网络的精确度与潜在变量在单位高斯分布上的契合程度。
神经网络可以自行决定这里的取舍。对于其中的误差项，我们归纳出独立的两种：生成误差，用以衡量网络重构图像精确度的均方误差；潜在误差，用以衡量潜在变量在单位高斯分布上的契合程度的散度。
_ = _  _  
_ = _ _  
 = _  _
为了优化散度，我们要用到重新参数化的一个简单技巧：生成一个均值向量一个标准差向量，而非直接生成实值向量。

我们的散度计算就变成这样：
  _  _       
_ =   __  _  _  
在计算解码网络的误差时，我们只需从标准差中取样，再加上均值向量，就能得到我们的潜在向量：
 = __=  
_ = _  _  
除了能让我们生成随机的潜在变量，该约束还能提高网络的泛化能力。
形象地说，我们可以把潜在变量视为数据的变换系数。
在   的区间内，假定你有一系列的实数名称对，一个实数代表一个物体的名字。例如，表示苹果，表示香蕉。当有人给你数字时，你肯定知道他们是在谈论苹果。本质上，采用这一方式可以编码无限多的信息，毕竟   之间的实数是有无数个。
然而，如果每当有人给告诉你一个新数字，它的高斯噪点也会增加一个时，情况会变成怎样？比如说，你收到数字是，其原始数值则应在  之间，那其他人所说的真实数字就有可能是香蕉。
所增噪点的标准差越大，其均值变量所能传递的信息就越少。
用此相同的逻辑，我们就能在编码器和解码器之间传递潜在变量。对原始图像的编码越有效，我们在高斯分布上所能取样的标准差就越大，直至为标准正态分布。
这一约束迫使编码器变得非常高效，从而能创造出信息丰富的潜在变量。它所提升的泛化能力，让我们随机生成或从非训练图像编码而来的潜在变量，在解码时将能产生更好的结果。
的效果有多好？
我在手写数据集上做了一些测试，从中可以看出变分自编码机的效果有多好。

左：第世代，中：第世代，右：原始图像看起来很不错！在我那没有显卡的笔记本上运行分钟后，它就生成了一些很好的结果。
的优点：
由于它们所遵循的是一种 编码解码 模式，我们能直接把生成的图像同原始图像进行对比，这在使用时是不可能的。
的不足：
由于它是直接采用均方误差而非对抗网络，其神经网络倾向于生成更为模糊的图像。
也有一些需要结合和的研究工作：采用相同的 编码器解码器 配置，但使用对抗网络来训练解码器。

研究详情参考论文
本文代码
原文链接作者：

上周我们提到了通过分群分析进行渠道转化数据的监测，调整了渠道投放策略，最终提升了渠道的结果。
首先，我们回顾一下我们的目标问题：

某电商，现在面临的问题是用户成交量较低，与投放推广的成本相比，较低。

这个问题，我们应该如何分析？
上周已经讲过：
通过数据挖掘，我们发现了优质渠道，其用户群与我们的高价值用户比较吻合，同时平均客单价约是原有主要渠道的，我们的投入产出比例得到了优化。这主要依赖于通过数据分析找到了优质低价的渠道，降低了获客成本。
漏斗改进效果如下图：

复习请戳→数据运营实战一
那么，这个漏斗是否存在其他可以改进的地方呢？
当然有！
我们的现实世界并非是简单的数据逻辑结构，很多结果都是多种原因综合导致的，我们可以用多种角度去分析同一个问题。
下面我们将结合漏斗分析与用户分群来做一个深度分析，通过漏斗的细致拆分和交叉对比，定位问题所在。
漏斗分析
那我们就从这个漏斗开始分析：从上面都是漏斗中，我们可以看到，加入购物车之前的转化率都较高，但在购物付款的流程中，转化率急剧降低至，这里应该也有改进的空间。

我们再看页面浏览数据，可以发现，用户在订单确认页面停留的时间长达秒，这与我们平时的认知不相符。

漏斗拆分
为了验证我们的假设，我们建立两个小用户群——“确认要付款的人群”“成功付款的人群”，即把漏斗中“订单人群”到“付款人群”进行了拆分，把确认付款的动作独立出来。

我们能够发现，在“确认要付款”到“成功付款”确实是损失转化的主要环节。
分群分析
我们看这群“确认付款”“未成功付款”的人群：

我们姑且把这个人群叫做“付款失败”组。
在中你可以通过设置用户分群设置来实现这一步的处理，如下图。

通过几个人群的对比，我们发现“付款失败”组的人群离线环境陡增约，另外，其、网络的比例要高于大盘人群  ，且设备品牌中，相对机型较小众、低端。


我们实际测试了品牌和品牌的实际几个机型，主要针对的就是付款页面的页面体验，存在以下问题：
、 机型适配性较差，开发时主要考虑的是现有主流机型适配，对小众机型的关注度较低；、 页面卡顿严重，长达秒以上的空白页面，严重消耗了用户耐心。
于是我们做了以下改善：、 紧急修复版本，在小众机型的主要推广渠道上升级了版本适配性的；、 页面加载量优化，包括切割、压缩、删减图片，框架优化，预加载等策略，恶劣网络下加载速度提升至约秒；、 加载等待页面设计，增加了动画的等待页面，给用户卖个萌，增加用户等待的耐心。
效果验证
页面优化后，我们的漏斗转化流程有明显改善：

我们针对这群“付款失败”用户群所做的改善，为转化漏斗提高了的转化效率，这是非常大的一个收益。
另外，我们在后续的漏斗改进中，还尝试结合了页面点击页面流转的分析，删去了付款页面中不必要的信息、按钮，保证了付款流程的顺畅性，对于提升漏斗也有一定的作用。
好了，今天的分享就到这里啦
总结一下，数据运营的优化思路其实就是通过细致拆分，把复杂的、多因子的事件分析拆分为独立的、单因子的归因分析，以确定改进的思路。
下一篇将会带来数据埋点的内容，敬请期待哦作者：张浩然 

一现状
现在网络优化的瓶颈是什么？你可能会说，带宽。也许在年前，决定性能的关键是带宽，但是在今天以及以后，瓶颈都不会是带宽，而是延迟。

从图中可以看出，随着带宽的增长，页面加载时间   在到的区间得到了很大的改善，但是再提高带宽，带来的提升就很小了，属于非线性改善；反观延迟，延迟这里是指多个时间相加的总和的改善对于页面加载时间是属于线性改善。
 
连接是需要三次握手的，同时，多个连接也会给服务器带来资源的消耗，在中，每个请求回复都是一次连接未开启的情况下，并且，同时传输多个资源时，会有队首阻塞的问题，造成网络资源无法有效利用。
 安全
对于大多数人来说，下图的情况几乎都有遇到过电脑或手机里。万恶的运营商或者网络接入提供商劫持我们的网络，修改网络的内容，给我们带来了很大的困扰。

二
现在，出现了。其实是支持 版和 版，由于现有支持的浏览器都是实现的 版，故本文的都是讲的是版。
  版

客户端向服务端请求假设此时是，带有以下头： 

服务器端返回：状态码，转换协议；   或者 


   版

客户端向服务器端请求     

服务器端返回 握手 并返回支持的协议


 握手详细过程

 协商过程
参考握手过程图，下面是增加协商的具体过程：
客户端添加一个字段，包含支持的协议到消息中；
服务器端查看字段后通过消息返回字段，表明被选定的协议；
通过实现，不再需要单独请求一次服务器带上 。
  
通常情况下，使用会搭配使用 ，客户端在完成握手前提前发送加密后的应用数据，将两次 握手减少为一次；不过需要同时支持已经很少用啦和前向安全性。
 
   简称为是一个安全功能，告诉浏览器只能通过访问当前资源，禁止方式。
如果用户输入域名， 浏览器首先会去请求 请求过程是明文非加密的，此时容易被中间人攻击，让网路恶意中间商直接接触到用户信息；而是用户请求时，服务器告诉客户端，下次来请求直接请求 ，而不要再请求服务器来跳转到。
同时，开启后，如果证书认证不通过比如遭到中间人攻击，浏览器此时强制无法打开该网站。
 名词解释
流：一个是包含一条或多条信息，和优先级的双向通道；
消息：消息由帧组成；
帧：帧有不同的类型，并且是混合的。他们通过 被重新组装进消息中。
 概念解释
 二进制帧

的二进制帧是字节 
长度：，也就是理论上可以携带字节的数据。但通常由于___的设置，不能发送超过字节的数据；
类型：，决定了该帧的类型；

  数据帧
  头部帧
  设置流的优先级
_  终止流
  设置连接参数
_  服务器推送模拟请求帧
  用来计算时间和看是否服务器挂了的
  告诉对方停止再向当前连接创建
_  流量控制

保留字段：，一般为。
 ：，标识，理论上可以有，超过这么多怎么办呢？
如果是客户端无法再创建新的 ，可以直接创建新的连接， 被重置。
如果是服务器端无法再创建新的 ，服务器将会给客户端发一个 帧，客户端无法再向该服务器创建，不得不新建连接。
 新特性
 多路复用

中，数据在发送端被切分为更小的数据帧用以高效利用链接。
 时代，再不开启的情况下，每一个请求会占用一个连接，而将请求和响应消息拆分为各自独立的帧，交错的发送，然后再在接收端重新装配组合。有什么好处呢？
交错的多个请求响应之间互现不会被阻塞

时代的也是保持同一个连接，但是由于请求接收有先后，后面的请求资源会被前面的资源阻塞没收到响应时不会发新的请求，如下图最左和最右边所示，即便是相比管道，优化也是巨大的：


减少了不必要的延时，改善了网路的利用率多路复用和资源优先级依赖关系搭配使用，使得页面重度依赖的资源优先传输；
 头部压缩
使用来给头部压缩；

值通过霍夫曼编码；

之前发送的值都被索引起来，之后使用时发现之前发送过该字段，并且值相同，就会沿用之前的索引来指代那个值；

：在中，也将会变为键值对索引起来，而不是一长串字符串。


可以看看我们组同学的之特性科普篇——头部压缩，里面有截图部分的数据讲述压缩后的效果。

这里需要讲解一下伪头部字段：
请求：






响应：



所有的伪头部字段都是在所有的前部；
 资源优先级依赖关系
资源优先级依赖关系通过权重和来设置。

通过上图可以看到，有一列是叫作，初始设置是根据来设置优先级的，比如是，是，然后是。
 权重值可以设置为到之间。
可以明确的表示依赖关系。
注意，一定要理解权重和依赖，权重值和依赖关系是作为带宽资源服务器客户端处理资源的建议值，但并不能保证他们有特定的传输顺序。让我们来看一张 的依赖关系和权重图：

中的都默认是依赖于一个根其实不存在。权重值是针对同级来计算的，不同级是不用来计算的；
 流量控制
与的流量控制类似，不过的流量控制可以到具体帧，而是连接层面上的。注意：流量控制目前只对帧有效！流量控制的算法没有具体要求使用哪一种，但是大概实现的功能是这样的：

两端收发保有一个流量控制窗口；

发送端每发送一个帧，就把窗口的大小递减，递减量为这个帧的大小，要是窗口大小小于该帧的大小，那么这个帧就必须被拆分。如果窗口值等于，就不能发送任何帧。流量控制的初始默认窗口值大小为字节理论上可以设置字节也就是字节大小的窗口值；

接收端可以通过发送_帧给发送端，发送端以帧内指定的窗口大小增量加到窗口大小限制上。


  
 的资源同样需要遵守同源策略，通过来判断。

如里所示，如果在服务器端设置当请求时就推送，现在我们来看抓包：

说明：
当客户端请求服务器时此时的请求路径已经设置好推送，服务器发回一个_和两个 ，从 可以看出，第一个的 是，也就是复用请求的来返回这是文件的返回响应。第二个就是推送文件的响应。
根据定义，由客户端初始化发起的的标识符是奇数，由服务器端初始化发起的是偶数，图中可以体现；
那么 和 的顺序如何保证呢？说明文档里有这样一句话：

       

也就是说，服务器将要推送的资源依赖于触发推送的请求，根据依赖的功能，只有被依赖的加载完后才会去加载接下来的。
 有什么好处呢：
推送的资源可以被客户端缓存；
推送的资源可以被不同的页面复用；
推送资源也是支持多路复用的；
推送资源可以被客户端拒绝掉客户端接收到_后，可以选择发送_来拒绝接收，告诉服务器端不要再发送了，当然，此时可能已经有部分内容已经发送过来了；
同时， 配合流量控制，可以实现很多很神奇的功能，这里卖个关子，然后会在下一篇讲解 
参考
之特性科普篇《   》—— 《性能权威指南》李松峰翻译   中的专题 协议 中英对照——百度
文章来源于公众号：小时光茶社 

相关推荐 一篇文章为你深度解析 协议  学习笔记分布式由高性能库底层技术支持。 、 、 论文《      》。
分布式原理。分布式集群 由多个服务器进程、客户端进程组成。部署方式，单机多卡、分布式多机多卡。多机多卡分布式。
单机多卡，单台服务器多块。训练过程：在单机单训练，数据一个批次一个批次训练。单机多，一次处理多个批次数据，每个处理一个批次数据计算。变量参数保存在，数据由分发给多个，计算每个批次更新梯度。收集完多个更新梯度，计算平均梯度，更新参数。继续计算更新梯度。处理速度取决最慢速度。
分布式，训练在多个工作节点。工作节点，实现计算单元。计算服务器单卡，指服务器。计算服务器多卡，多个划分多个工作节点。数据量大，超过一台机器处理能力，须用分布式。
分布式底层通信，   。，谷歌开源高性能、跨语言框架。协议，远程过程调用协议，网络从远程计算机程度请求服务。
分布式部署方式。分布式运行，多个计算单元工作节点，后端服务器部署单工作节点、多工作节点。
单工作节点部署。每台服务器运行一个工作节点，服务器多个，一个工作节点可以访问多块卡。代码指定运行操作设备。优势，单机多间通信，效率高。劣势，手动代码指定设备。
多工作节点部署。一台服务器运行多个工作节点。
设置__环境变量，限制各个工作节点只可见一个，启动进程添加环境变量。用指定特定。多工作节点部署优势，代码简单，提高使用率。劣势，工作节点通信，需部署多个工作节点。__ 。
__=  _ _= _= _= _=
__=  _ _= _= _= _=
__=  _ _= _= _= _=
__=  _ _= _= _= _=
分布式架构。 。客户端、服务端，服务端包括主节点、工作节点组成。
客户端、主节点、工作节点关系。，客户端会话联系主节点，实际工作由工作节点实现，每个工作节点占一台设备具体计算硬件抽象，或。单机模式，客户端、主节点、工作节点在同一台服务器。分布模式，可不同服务器。客户端主节点工作节点。客户端。建立计算图，建立与集群交互会话层。代码包含。一个客户端可同时与多个服务端相连，一具服务端也可与多个客户端相连。服务端。运行实例进程，执行任务集群一部分。有主节点服务 和工作节点服务 。运行中，一个主节点进程和数个工作节点进程，主节点进程和工作接点进程通过接口通信。单机多卡和分布式结构相同，只需要更改通信接口实现切换。主节点服务。实现接口。通过服务程序连接工作节点，与工作节点服务进程工作任务通信。服务端，_为作业。工作节点服务。实现_接口，本地设备计算部分图。服务端，所有工作节点包含工作节点服务逻辑。每个工作节点负责管理一个或多个设备。工作节点可以是本地不同端口不同进程，或多台服务多个进程。运行分布式执行任务集，一个或多个作业。每个作业，一个或多个相同目的任务。每个任务，一个工作进程执行。作业是任务集合，集群是作业集合。分布式机器学习框架，作业分参数作业 和工作节点作业 。参数作业运行服务器为参数服务器 ，管理参数存储、更新。工作节点作业，管理无状态主要从事计算任务。模型越大，参数越多，模型参数更新超过一台机器性能，需要把参数分开到不同机器存储更新。参数服务，多台机器组成集群，类似分布式存储架构，涉及数据同步、一致性，参数存储为键值对。分布式键值内存数据库，加参数更新操作。李沐《     》 。参数存储更新在参数作业进行，模型计算在工作节点作业进行。分布式实现作业间数据传输，参数作业到工作节点作业前向传播，工作节点作业到参数作业反向传播。任务。特定服务器独立进程，在作业中拥有对应序号。一个任务对应一个工作节点。集群作业任务工作节点。
客户端、主节点、工作节点交互过程。单机多卡交互，客户端会话运行主节点执行子图工作节点､。分布式交互，客户端会话运行主节点进程执行子图工作节点进程､。《      》 。
分布式模式。
数据并行。_ 。负责梯度平均、参数更新，不同训练模型副本 。基于训练样例子集训练，模型有独立性。步骤：不同分别定义模型网络结构。单个从数据管道读取不同数据块，前向传播，计算损失，计算当前变量梯度。所有输出梯度数据转移到，梯度求平均操作，模型变量更新。重复，直到模型变量收敛。数据并行，提高效率。 样本，切成多份，模型复制多份，在多个模型上同时计算。多个模型计算速度不一致，更新变量有同步、异步两个方案。
同步更新、异步更新。分布式随机梯度下降法，模型参数分布式存储在不同参数服务上，工作节点并行训练数据，和参数服务器通信获取模型参数。同步随机梯度下降法，同步更新、同步训练，训练时，每个节点上工作任务读入共享参数，执行并行梯度计算，同步需要等待所有工作节点把局部梯度处好，将所有共享参数合并、累加，再一次性更新到模型参数，下一批次，所有工作节点用模型更新后参数训练。优势，每个训练批次考虑所有工作节点训练情部，损失下降稳定。劣势，性能瓶颈在最慢工作节点。异楹设备，工作节点性能不同，劣势明显。异步随机梯度下降法，异步更新、异步训练，每个工作节点任务独立计算局部梯度，异步更新到模型参数，不需执行协调、等待操作。优势，性能不存在瓶颈。劣势，每个工作节点计算梯度值发磅回参数服务器有参数更新冲突，影响算法收剑速度，损失下降过程抖动较大。同步更新、异步更新实现区别于更新参数服务器参数策略。数据量小，各节点计算能力较均衡，用同步模型。数据量大，各机器计算性能参差不齐，用异步模式。带备份的  。 、 、 、 、 论文《   》 。增加工作节点，解决部分工作节点计算慢问题。工作节点总数，为集群工作节点数。异步更新设定接受到个工作节点参数直接更新参数服务器模型参数，进入下一批次模型训练。计算较慢节点训练参数直接丢弃。同步更新、异步更新有图内模式 和图间模式 ，独立于图内、图间概念。图内复制 ，所有操作在同一个图中，用一个客户端来生成图，把所有操作分配到集群所有参数服务器和工作节点上。国内复制和单机多卡类似，扩展到多机多卡，数据分发还是在客户端一个节点上。优势，计算节点只需要调用函数等待任务，客户端随时提交数据就可以训练。劣势，训练数据分发在一个节点上，要分发给不同工作节点，严重影响并发训练速度。图间复制 ，每一个工作节点创建一个图，训练参数保存在参数服务器，数据不分发，各个工作节点独立计算，计算完成把要更新参数告诉参数服务器，参数服务器更新参数。优势，不需要数据分发，各个工作节点都创建图和读取数据训练。劣势，工作节点既是图创建者又是计算任务执行者，某个工作节点宕机影响集群工作。大数据相关深度学习推荐使用图间模式。
模型并行。切分模型，模型不同部分执行在不同设备上，一个批次样本可以在不同设备同时执行。尽量让相邻计算在同一台设备上完成节省网络开销。 、 、 论文《      》 。
模型并行、数据并行，中，计算可以分离，参数可以分离。可以在每个设备上分配计算节点，让对应参数也在该设备上，计算参数放一起。
分布式。 。创建集群，每个任务启动一个服务工作节点服务或主节点服务。任务可以分布不同机器，可以同一台机器启动多个任务，用不同运行。每个任务完成工作：创建一个，对集群所有任务进行描述，描述内容对所有任务相同。创建一个，创建一个服务，运行相应作业计算任务。分布式开发。{__}。创建集群描述信息，、为作业名称，_、_为作业任务所在节点地址信息。传入参数，作业和任务间关系映射，映射关系任务通过地址、端口号表示。
结构 {}
可用任务 ､。
结构 {}
可用任务 ､ ､ ､ ､ 
__。创建服务主节点服务或工作节点服务，运行作业计算任务，运行任务在_指定机器启动。
任务 
 = {}
  = _=_= 
任务 
 = {}
  = _=_=。
自动化管理节点、监控节点工具。集群管理工具。___。设定指定设备执行张量运算，批定代码运行、。
指定在所在机器执行操作运算 
 
  _ = …
  _ = …
分布式训练代码框架。创建服务器集群，在该集群分布式计算数据流图。_ 。
 
 
   
 = 
 _
   第步：命令行参数解析，获取集群信息_、_
   当前节点角色信息_、_
  _ = _
  _ = _
   第步：创建当前任务节点服务器
            
   = { _  _}
           
   = 
                           _=_
                           _=_
   第步：如果当前节点是参数服务器，调用无休止等待；如果是工作节点，执行第步
   _ == 
    
   第步：构建要训练模型，构建计算图
   _ == 
            
     __
        _=  _
        =
        
       = 
      _ = ____
      _ = 
           _=_
            
     第步管理模型训练过程
    =_=
           
                
        
     =
                                           _=_ == 
                                           _=_
                                           =  _
        __
             
          ``      
           
         _       
         训练模型
        __
 ____ == ____
   = 
       == 
       
  _
      _
      =
      =
      =    
  
  _
      _
      =
      =
      =    
  
  _
      _
      =
      =
      =   
  
       
  _
      _
      =
      =
      =     
  
    = __
  = =  
分布式最佳实践。__ 。数据集分布式训练。开设个端口作分布式工作节点部署，端口参数服务器，端口工作节点，端口工作节点。参数服务器执行参数更新任务，工作节点､工作节点执行图模型训练计算任务。参数服务器 ，工作节点 ，工作节点 。运行代码。
 _ _= _=
 _ _= _=
 _ _= _=

 ____  _
 ____  
 ____  _
 
 
 
 
   
   _
 定义常量，用于创建数据流图
 = 
__ 
                        
 只下载数据，不做其他操作
__ 
                              
                          
 _从开始。代表用来初始化变量的第一个任务
__ 
                          =  _=  
                             
                      
 每台机器个数，机器没有为
__ 
                           
                              
 同步训练模型下，设置收集工作节点数量。默认工作节点总数
___ 
                            
                        _    
                     _
__ 
                              
 训练次数
__ 
                           
__    
__   
 使用同步训练、异步训练
__ 
                       _    
                             
                          
 如果服务器已经存在，采用协议通信；如果不存在，采用进程间通信
_
    _        
                
             
    
 参数服务器主机
__
                        
 工作节点主机
__ 
                        
 本作业是工作节点还是参数服务器
__     
 = 
_ = 
 _
   = ____ _=
   _
    
   _    _ == 
         `_`
   _    _ ==
         `_`
    =   _
    =   _
        
   读取集群描述信息
  _ = _
  _ = _
       
  _ = _
   创建集群描述对象
   = {
       _
       _}
   为本地执行任务创建 对象。
    _
            
     创建本地对象，从这个定义开始，每个节点开始不同
     根据执行的命令的参数作业名字不同，决定这个任务是哪个任务
     如果作业名字是，进程就加入这里，作为参数更新的服务，等待其他工作节点给它提交参数更新的数据
     如果作业名字是，就执行后面的计算任务
     = 
         _=_ _=_
     如果是参数服务器，直接启动即可。这里，进程就会阻塞在这里
     下面的__代码会将参数批定给_保管
     _ == 
      
   处理工作节点
   找出的主节点，即_为的点
  _ = _ == 
   如果使用
   _  
           _  
           
     = _  _
     分配到指定上运行
    _ =   _ 
   如果使用
   _ == 
           
     把分配给
     = 
    _ =   _ 
            
              
           
   用__将涉及变量操作分配到参数服务器上，使用。将涉及非变量操作分配到工作节点上，使用上一步_值。
   在这个语句之下定义的参数，会自动分配到参数服务器上去定义。如果有多个参数服务器，就轮流循环分配
   
      __
          _=_
          _=
          =

     定义全局步长，默认值为
    _ =  =_ =
         
     定义隐藏层参数变量，这里是全连接神经网络隐藏层
    _ = 
        _
            _  _ _
            =  _
        =_
    _ = _ =_
         
     定义 回归层参数变量
    _ = 
        _
            _ 
            =  _
        =_
    _ =  =_
            _
     定义模型输入数据变量
     =   _  _
    _ =   
     构建隐藏层
    _ = __ _ _
     = _
     构建损失函数和优化器
     = __ _ _
    _ = __  __  
     异步训练模式：自己计算完成梯度就去更新参数，不同副本之间不会去协调进度
     = _
     同步训练模式
     _
       __  
        __ = _
      
        __ = __
       使用作优化器，并且是在图间复制情况下
       在图内复制情况下将所有梯度平均
       = 
          
          __=__
          __=_
          =__
    _ = _ _=_
     _
      __ = ___
       _
         所有进行计算工作节点里一个主工作节点
         主节点负责初始化参数、模型保存、概要保存
        __ = __
      ____ = ____
                _ 
       同步训练模式所需初始令牌、主队列
      __ = ___
      __ = ___
    _ = __
    _ = 
     _
       创建一个监管程序，用于统计训练模型过程中的信息
        是保存和加载模型路径
       启动就会去这个目录看是否有检查点文件，有的话就自动加载
       没有就用_指定初始化参数
       主工作节点负责模型参数初始化工作
       过程中，其他工作节点等待主节眯完成初始化工作，初始化完成后，一起开始训练数据
       _值是所有计算节点共享的
       在执行损失函数最小值时自动加，通过_知道所有计算节点一共计算多少步
       = 
          _=_
          =_
          _=_
          __=__
          ____=____
          __=
          _=_
    
       = 
          _=_
          =_
          _=_
          __=
          _=_
     创建会话，设置属性__为
     所有操作默认使用被指定设置，如
     如果该操作函数没有实现，自动使用设备
    _ = 
        __=
        __=
        _=   _
        _==     
               
     主工作节点，_为节点初始化会话
     其余工作节点等待会话被初始化后进行计算
     _
           _
    
              
            _
     _
      __ =   __
            __
       创建会话对象，用于执行图计算
       ____需要参数初始化完成且主节点准备好后，才开始训练
       = ______
                                            =_
    
       = ____ =_
          _
     _  _
                   
      __
      __ __
      
     执行分布式模型训练
    _ = 
         _
    _ = 
     
        
       读入训练数据，默认每批次张图片
      _ _ = __
      _ = { _ _ _}
      _  = _ _ _=_
      _ = 
       = 
                
             _ _ 
        = _
        
    _ = 
         _
    _ = _  _
          _
      
     读入验证数据，计算验证的交叉熵
    _ = {  _ }
    _ = _ _=_
           =  
          _ _
 ____ == ____
  
参考资料：《技术解析与实战》
欢迎推荐上海机器学习工作机会，我的微信：作者：

先是环境：在上用安装了，用运行终端。可以用文件共享、网络文件共享、、实现两个操作系统的文件共享
主目录配置文件保存在： 
如果换一台电脑，我只需要    就可以拿到以前的配置文件
的插件可以用  来管理，只要在用   指明需要的插件，随后用 


自动安装新插件
下面是我的  插件配置的部分，随后介绍各个插件的用途
 
 
 =
 
 
 
   
 
 
 
 
 
    
    
    
 _   
   
 
   
   
   
 
 
 
 
 
 
 
   

 
 插件管理插件
 
 基础库
 
插件的替代品，函数名称等的预览窗口，如果要预览，需要安装命令
 用此标记可能无法支持
 
 
 
使用  搜索文件
 
 
内置文件目录树的替代品
 
注释代码
 
代码对齐
 
 _
 
 代码模板，里也有，但的更灵活强大，基本是脚本了。
 
 
  插件，可以  等，下面是  
 
 窗口里的快捷键
 
个人版自动补全空格
 
自定义标头
 
格式化代码，需要命令的支持  
 
点命令  重复上一次修改的扩展
 
括号、引号、标签等的快速修改，比如
 ‘’  “”
  =         = 
强烈推荐《实用技巧》：


原文链接：


相关推荐腾讯云主机介绍【腾讯云的种玩法】如何使用腾讯云构建自己的云桌面办公平台插件网络相关接口的应用作者：王少飞

  作为   的加速器，其算法上的改进优化是  整个界面渲染的基础，以及性能提高的保障，同时也是  源码中最神秘、最不可思议的部分，本文将剖析   的不可思议之处。
 中最值得称道的部分莫过于   与  的完美结合，特别是其高效的  算法，让用户可以无需顾忌性能问题而”任性自由”的刷新页面，让开发者也可以无需关心   背后的运作原理，因为   会帮助我们计算出   中真正变化的部分，并只针对该部分进行实际  操作，而非重新渲染整个页面，从而保证了每次操作更新后页面的高效渲染，因此   与  是保证  性能口碑的幕后推手。
 策略
、  中  节点跨层级的移动操作特别少，可以忽略不计。   
、拥有相同类的两个组件将会生成相似的树形结构，拥有不同类的两个组件将会生成不同的树形结构。
、对于同一层级的一组子节点，它们可以通过唯一  进行区分。
以上三个策略， 分别对  、  以及   进行算法优化，事实也证明这三个前提策略是合理且准确的，它保证了整体界面构建的性能。
 
基于策略一， 对树的算法进行了简洁明了的优化，即对树进行分层比较，两棵树只会对同一层次的节点进行比较。
既然  节点跨层级的移动操作少到可以忽略不计，针对这一现象， 通过  对   树进行层级控制，只会对相同颜色方框内的  节点进行比较，即同一个父节点下的所有子节点。当发现节点已经不存在，则该节点及其子节点会被完全删除掉，不会用于进一步的比较。这样只需要对树进行一次遍历，便能完成整个  树的比较。            
如果出现  节点跨层级的移动操作，因为该节点已经不在原来的  树层， 所以会直接删除该节点，在移动后的  层重建该节点， 可见这种操作的性能代价非常大，所以不推荐这样做。 可以通过  样式控制节点的隐藏和显示来代替节点跨层级移动的操作。  

 
  是基于组件构建应用的，对于组件间的比较所采取的策略也是简洁高效。
如果是同一类型的组件，按照原策略继续比较   。
如果不是，则将该组件判断为  ，从而替换整个组件下的所有子节点。
对于同一类型的组件，有可能其   没有任何变化，如果能够确切的知道这点那可以节省大量的  运算时间，因此  允许用户通过  来判断该组件是否需要进行 。
如下图，当   改变为   时，即使这两个  结构相似，一旦  判断  和  是不同类型的组件，就不会比较二者的结构，而是直接删除  ，重新创建   以及其子节点。虽然当两个  是不同类型但结构相似时，  会影响性能，但正如  官方博客所言：不同类型的  是很少存在相似   的机会，因此这种极端因素很难在实现开发过程中造成重大影响的。

 
当节点处于同一层级时，  提供了三种节点操作，分别为：_插入、_移动和 _删除。

_，新的  类型不在老集合里， 即是全新的节点，需要对新节点执行插入操作。  

_，在老集合有新  类型，且  是可更新的类型， 已调用 ，这种情况下 =，就需要做移动操作，可以复用以前的  节点。

_，老  类型，在新集合里也有，但对应的  不同则不能直接复用和更新，需要执行删除操作，或者老  不在新集合里的，也需要执行删除操作。


开发者对同一层级的子节点，可以添加唯一索引进行区分，这样在  时，涉及到只是位置变化的，可以只移动元素，避免删除创建等重复的操作。

参考资料


原文链接： 官方网站上给出的示例里面有个 用  构建   的例子 我在腾讯云的主机上实验了一下 中间添加了一些优化 把实验过程记录如下 希望对大家有帮助。
一 相关的文件
 新建一个目录和一个 
 
 
  的内容如下
  
 
 

 使用  的源
  
   

 设置  密码
   | 

 安装 
    
  

          
  \\_  _  

     
   =  

 添加公钥如果没有公钥可以省略
  
   __  _

 容器启动后运行的程序
  

 打开  端口
 
 的内容如下
    
    

    
    

   
   
   
   

    
    
   
   
二构建 
使用   来生成镜像
 参数是给这个镜像的 
     
       
     
    
  
    
   
  
     
   
  
      
   
  
      | 
   
  
       
   
  
     
   
  
     \\_  _  
   
  
      =  
   
  
     
   
  
      __
   
  
     
   
  
    
   
  
  
使用   命令查看镜像 确认镜像构建成功了
  
                                                      
                                          
                                             
                                             


就是我们刚才构建的镜像
三创建 
使用   来用镜像创建一个 
    使  在  模式运行
  把  端口映射到主机的网卡上 格式  |  | 
–  给  指定一个名字 一旦指定了名称这个名称就和这个  绑定了 可以用    列出来
        
我用的外网端口是  可以根据需要修改 下一步需要确认  是否正常执行了
  
                                                                                     
                                      
看来执行成功了 连接试试看看
  
        
    
         
          

         
          
   

          
 


已经成功连接进入  了
四关闭 
      是    的缩写 只要能够唯一标识这个  就可以了。或者   
五运行 
   

相关推荐 容器服务 如何构建镜像 如何搭建私有镜像仓库大家好，笔者是“南七技师”队，作为一支全部由萌新组成的队伍，一路走来虽步履维艰但却收货颇丰。同时也非常感谢腾讯公司举办这次社交广告高校算法大赛，为笔者提供了良好的学习途径与机会。
下面主要分享笔者在比赛过程中的心得体会：
    数据探索以及数据预处理
刚拿到数据，笔者就对其进行了一些探索性的分析，包括对数据变量之间的联系和数据分布情况的统计，并对其进行了可视化。进行可视化之后，就可以对原始数据有进一步的了解，然后进行数据的些清洗工作，包括对缺失值的处理以及对离群点的去除等。
    特征工程
笔者在特征公共步骤进行了几次尝试如下：
    选用前天的数据作为训练集、后天的数据作为测试集，结果发现效果并没有使用全部的数据集效果好。原因分析：数据量减小。
    选用所有天的上午、下午数据作为训练集，来分别预测上午、下午的结果。
原因分析：数据量减小。
    把所有的数据都转化合成了一张表，并且把低维度的特征进行了处理，将这些特征全部加入到了模型中进行训练，成绩并不是特别理想。
原因分析：只是单纯的加入所有的特征，并未选择有效特征。
经过几次尝试之后，笔者着手于对数据作统计分析，对于一个特征是否真的有意义是需要看特征的分布比例，在正负样本中所占的比例越大就表明该特征的对正负样本的区分度较好。同时，笔者还进行对特征的组合，计算出其中的转化率。然而，特征之间必然是会有重复的，这将会导致过拟合的现象出现，给模型造成不必要的干扰，笔者解决这种问题的方法就是逐一测试特征是否有效。
    技巧
在实验过程中，通过分析原始数据背后的真实意义，以及观察提交结果的反馈，总结了一些有用的技巧，如下：
    笔者对转化回流时间做了一些小处理。因为回流时间是从用户点击到广告系统得知用户激活，而且转化数据是由广告主提供的，就可以计算出广告主上报到广告系统这期间的时间，这个特征也提升了有万分之五。
    尝试了，效果也有提升。
    通过观察数据发现，可以发现存在很多重复点击的数据，同一个广告被连续多次点击后转化只在最后一次点击上，由这个笔者构造出的特征一下子让笔者的成绩提升了千分之三。
    总结
由于笔者团队是个新手团队，没有参赛经历，因此开始比赛的时候第一步就是了解数据，各个字段的含义联系等等。然而过了这段时间，笔者就埋头进入了所谓的“业务”分析的方向，再也没有仔细看过数据，不断地更换模型更换参数构造各种的特征，然而取得的效果却并不和消耗的时间成正比。后经提醒，笔者将目光转移回了初始数据，这才有所斩获。这可能是新手往往会经常犯的错误吧，以后的比赛过程中还是要多多花点时间在数据上面。最后祝大家取得好成绩！作者：程柳锋

目的

统一团队   日志标准，便于后续代码  ，版本发布以及日志自动化生成等等。
统一团队的工作流，包括分支使用、 规范、 等。

 日志参考案例






总体方案

 日志基本规范
 
 

 

对格式的说明如下：

代表某次提交的类型，比如是修复一个还是增加一个新的。所有的类型如下：
： 新增
 修复
 仅仅修改了文档，比如  等等
 仅仅修改了空格、格式缩进、都好等等，不改变代码逻辑
 代码重构，没有加新功能或者修复
 优化相关，比如提升性能、体验
 测试用例，包括单元测试、集成测试等
 改变构建流程、或者增加依赖库、工具等
 回滚到上一个版本

格式要求：
 标题行：个字符以内，描述主要变更内容

 主体内容：更详细的说明文本，建议个字符以内。 需要描述的信息包括

  为什么这个变更是必须的 它可能是用来修复一个，增加一个，提升性能、可靠性、稳定性等等
  他如何解决这个问题 具体描述解决问题的步骤
  是否存在副作用、风险 

 尾部：如果需要的化可以添加一个链接到地址或者其它文档，或者关闭某个。
分支与版本发布规范

基本原则：为保护分支，不直接在上进行代码修改和提交。
开发日常需求或者项目时，从分支上一个分支进行开发或者分支进行修复，功能测试完毕并且项目发布上线后，将分支合并到主干，并且打发布，最后删除开发分支。分支命名规范：
分支版本命名规则：分支类型  分支发布时间  分支功能。比如：___
分支类型包括：、 、三种类型，即新功能开发、修复和代码重构
时间使用年月日进行命名，不足位补
分支功能命名使用 命名法，即下划线命名。


包括位版本，前缀使用。比如。命名规范：
新功能开发使用第位版本号，修复使用第位版本号
核心基础库或者中间价可以在大版本发布请使用灰度版本号，在版本后面加上后缀，用中划线分隔。或者后面加上次数，即第几次：
 





版本正式发布前需要生成文档，然后再发布上线。

如何接入？
接入参考项目。具体步骤如下：

第一步：在工程跟目录下的文件加入如下代码所示的和内容，版本号为位版本号。

  {
     
     
     {
       
        
              
    }
     {
       
       
       
       
    }
  }


第二步：在工程根目录新建文件，并且文件内容为

{
   \        \
   
    
    
    
    
    
    
    
    
    
  
   
   
}

接入后的 操作流程

第一步：创建一个分支或者分支
    __     切换到一个分支或者 分支


第二步：将代码提交到本地仓库，并填写符合要求的 格式
                                   
                                  此处不要加任何参数，比如

如下图所示：




第三步：将代码同步到远程仓库    __     将修改发布到远程仓库


第四步：自动生成，并打发布                        使用 中的命令直接从元数据生成日志。
   
    




原文链接：


相关推荐使用自动部署简单网站如何写好   本文作者： 程柳锋 
背景
随着开发团队规模不断发展壮大，在人员增加的同时也带来了协作成本的增加，业务项目越来越多，类型也各不相同。常见的类型有组件类、活动类、基于的业务项目、项目、项目等等。如果想要对每个项目进行一些规范的约束比如提交规范、规范简直难于登天。所有的这些，只因为缺少一个好用的工程化工具。从项目创建、开发、构建、代码规范检查到最终项目上线，通过可以提升效率，同时保障开发规范的实施。

实现的基本原理
关键点在于里面的字段。模块全局安装，对于类系统，在目录创建软链接；对于系统，在\\\\\目录创建软链接。 模块局部安装，会在项目内的_目录创建软链接。
现代化工程的生命周期
随着前端工程的不断演进，一方面工程变得日趋复杂，同时对规范和质量的诉求在不断增加。现代化工程应该包含以下几个阶段：初始化、开发、构建、检查、发布。如下图所示：
痛点：项目拷贝
项目拷贝存在的问题显而易见，大致有以下三个方面：

容易出错；一旦某个关键文件拷贝丢失或者错误，很可能需要耗费半天到一天的时间排查环境问题。
不同场景下对目录结构要求不同；平时开发过程中，工程通常会分为运营活动、业务、入口级别的项目对性能和体验有极致和苛刻的要求。需要基于或者的首屏直出，还有常用的业务组件等的开发。
新的和难以同步；某个同学开发过程中增加的新方法或者解决的很难传递给其它同学并且沉淀成经验积累下来。社区里面提供了完美的解决方案，它是为了自动化项目的创建而生。创建项目包括以下几个阶段：
 初始化一些状态之类的，通常是和用户输入的  或者  打交道
 和用户交互的时候命令行问答之类的调用
 保存配置文件如  等
 生成模板文件
 安装依赖
 结束部分，初始代码自动提交

我们只需要继承的类做模板定制化，基于的脚手架设计思路应该如下图所示：首先，开发者会和进行交互，开发者会告诉需要创建哪一种类型的项目，收到命令后。从本地已经安装的脚手架里面选择某种类型的模板。然后，会调用 在远程创建仓库并且授予开发者权限。接下来，会根据实际业务场景需要，自动化申请一些打点信息，常见的如离线包，监控告警等等。之后，在本地目录生成代码并且安装项目依赖的包，最后将本次初始化生成的所有代码自动提交到远程仓库。
痛点：运营配置频繁修改
基于组件化开发方式中，一个页面或者是由多个容器组件拼装后渲染而成。某个组件通常是由：模板、数据和事件组成。理想情况下，开发和产品和平共处，你可以把一个组件写成下面这个样子，比如规则组件：
 {
     
         =
             =
                活动时间：
                月日～月日
            
             =
                活动规则：
                、活动期间，在 上录制小视频，上传成功后即可参赛。
                、根据参赛小视频获得的点赞数进行排行。
                、按照城市评选，分别评选“明日之子”仅限男性参加和”闪亮女神“仅限女性参加。
            
        
    
}
咋一看，上面的写法没什么问题。实际确很可能是、次的文案修改，甚至对外入口开放后仍然要修改文案或者图片等静态数据。然后，你需要走代码发布流程。更好的解决思路是：在开发某个业务组件之前，结合以往的经验，分析哪些静态数据很可能是需要高频次的修改。将这些高频次修改的静态数据抽离出来，对于万年不变的数据则没有必要抽出来。那么，如何将静态数据动态化呢？答案是：   ， 开发组件之前先设计，通过生成一个表单，达到静态数据和模板分离。如果使用开发，可以基于定制。静态数据和模板分离之后应该如下图：
痛点：缺少协作规范
此处以 规范为例子进行相关改进介绍。良好的 规范有以下优势：

加快的流程
根据元数据生成
后续维护者可以知道被添加的原因此处采用 项目的提交作为参考，整理出 的解决方案：具体的提交格式要求如下： 
 

 

对格式的说明如下：代表某次提交的类型，比如是修复一个还是增加一个新的。所有的类型如下：
： 新增
 修复
 仅仅修改了文档，比如  等等
 仅仅修改了空格、格式缩进、都好等等，不改变代码逻辑
 代码重构，没有加新功能或者修复
 优化相关，比如提升性能、体验
 测试用例，包括单元测试、集成测试等
 改变构建流程、或者增加依赖库、工具等
 回滚到上一个版本
一键生成版本日志：痛点 缺少代码规范
一次血淋淋的生产环境事故：年月日，腾讯高级工程师小圣在做充值业务时，修改了苹果支付配置，将配置增加了重复的。代码发布后，有小部分使用了手机的用户反馈充值页面白屏，无法在 内进行充值。最后问题定位是：手机使用了系统自带的而没有使用内核，解析时遇到重复报错，导致页面白屏。

分析：现代化的浏览器对于里面的重复会做兼容处理，但是某些老旧的浏览器内核并不会，比如此处的手机，导致代码直接出错。那么，如何避免类似问题再次出现呢？
此处不得不提及，于年月推出最新版本，是一款适用于和的代码规范检查工具，相比和而言，它更加灵活，支持自定义配置、插件扩展和配置错误级别。虽然接入会给团队的同学增加不少代码修改的成本，但是从长远来看，收益肯定是大于付出的。
规范制定的原则：

不重复造轮子，基于 配置并改进
能够帮助发现代码错误的规则，全部开启
配置不应该依赖于某个具体项目，而应尽可能的合理
帮助保持团队的代码风格统一，而不是限制开发体验
有对应的解释文档

为了更好的定制和维护规范，我们创建了的 。一方面，我们觉得 里面的部分配置定义的错误级别过于严格，比如代码里面出现了会导致校验错误，另一方面，它没有包含的最佳实践和其它规则。我们定义的部分规则解释如下：



规则名称
错误级别
说明




 

 循环的方向要求必须正确




必须有返回值，并且禁止返回值为 比如 




允许在循环里面使用




允许在代码里面使用




直接调用对象原型链上的方法




函数注释一定要遵守规则


 

在字符串里面出现{和}进行警告




和没有成对出现时给出警告


 

对于数据相关操作函数比如  等，必须有




把关键字看成块级作用域，防止变量提升导致的




要求在里面合理使用，如果某个方法没有使用则应该申明为静态方法


 

关闭代码复杂度限制




 语句里面一定需要分支



的执行可以接入到 里面，步骤如下：
 安装
    

 集成进 
{
   {
     
         
  }
}
设计
的作用是将工程开发过程中遇到的一系列痛点问题连接起来，提升开发效率，同时保障规范的实施。
插件设计
插件实现原理
这里有一个非常巧妙的设计，通过使用提供的和模块，可以通注入全局变量来访问到的实例。从而能够访问上的各种属性，比如 和一些等。
   {
      = 

      = {

        =  
       = 
       = _

        {
           
      }

       =  {
           _ 
      }

       = 
       = _
       = _

         
      =    __ __ { 
           }

        =  

            
      }
  }
命令注册：
命令需要以进行注册，比如：
     {
     
       
}
说明：

有个参数，第一个是子命令名称，第二个是命令描述说明信息，第三个是对应的子命令执行逻辑函数。
会将命令行参数解析成对象，传递给插件处理函数

配置
可以通过获取当前的版本， 获取跟目录在用户目录下的，通过 获取插件目录
日志
通过来进行相关命令行日志输出
  = 
     提示日志，控制台中显示绿色
    调试日志  命令行增加可以开启，控制台中显示灰色
     警告日志，控制台中显示黄色背景
    错误日志，控制台中显示红色
    致命错误日志，，控制台中显示红色
最后
感谢源创汇提供的交流机会，能和广大开发者分享和交流学习。直播团队的工程化解决方案如下：

主页：
码云主页：


原文出处：社区 未经同意，禁止转载腾讯“云未来”峰会
主题：连接、智能、未来
年月日，由腾讯发起的“云未来”峰会将在深圳盛大举行。本次峰会由马化腾先生领衔，云集国际知名科学家、产业家、创新家，探索人工智能与产业结合的新趋势。
世界正在被前沿科技深刻地改变。云计算、大数据、人工智能等新技术浪潮风起云涌，“智能云”新生态已然来临。在这片新的蓝海中，我们期待与您并肩携手，共同迈入智能未来。
时间：
地点：中国深圳
主论坛嘉宾部分，分论坛稍后更新
马化腾，腾讯董事会主席兼首席执行官  ，伯克利教授，人工智能领域专家 ，密码学家，图灵奖获得者郑义陶，英伟达公司亚太地区销售与营销副总裁张首晟，斯坦福大学物理教授，美国国家科学院院士汤道生，腾讯高级执行副总裁，社交网络事业群总裁邱跃鹏，腾讯副总裁，腾讯云总裁张潼，腾讯 主任，机器学习领域专家贾佳亚，腾讯优图实验室杰出科学家田民，顺丰集团，顺丰科技李斌，蔚来创始人，董事长吴甘沙，驭势科技联合创始人，
图文活动详情：
报名地址报名后会筛选，需要登录 近日，腾讯开源线下沙龙分享会在广州举办。分享会邀请了多位腾讯开源项目作者，分享自己在开源方面的经验心得。
会上，腾讯知名前端开源项目的开发系统地介绍了一个开源项目从立项、生长、曝光到社区维护等各方面积累的经验。
项目
是团队为开发人员提供跨平台支持和环境准备的前端工作流开发工具，目前已支持微信游戏、微信·朋友圈广告、微信·城市服务等第三方合作团队的前端构建工作。帮助合作商在微信快速部署业务和高效迭代，开发出的产品不仅布局优雅、界面精美，还具备易扩展、易接入、开发门槛低等优势。

作者，黄自力，来自腾讯微信事业群，高级工程师，主要负责微信的界面相关工作，参与了开源项目的开发，是腾讯开源社区里的活跃用户之一。


拥抱开源的初心
我在很早以前，就已经有做开源的想法。在互联网上，我一直以的名称“混”在开源圈，运营属于自己的账号，发布了一些项目，也吸引了很多人一起参与。对我来说，接触开源圈最大的鼓励，是自己在写的文章被圈子内的开发者翻译成多个语言版本。这些，都成为我拥抱开源的原动力。
一个项目的开源历程应该分为个阶段和个结果。项目经过了生长，运营推广和社区维护三个阶段的努力之后，就能达到提升影响力的结果，最终把项目搞大、搞火。
何为影响力？
衡量影响力应该从这三个指标入手：知名度、口碑好、逆背书。
知名度
对于新用户来说，当我们的项目知名度提高之后，他们面对技术选型或遇到开发问题时，会优先想到我们的开源项目作为其备选方案。同时，开源项目知名度提高之后，才能在社区里引起开发者的关注，给它做贡献，使其更加健壮。
口碑好
对于已经使用我们开源项目的用户来说，口碑好显得尤为重要。因为项目的好口碑使这批用户不自觉地向身边的同事或其他项目组推荐，成为我们项目的“自来水”，达到良好的二次推荐效果。
逆背书
这个词看着陌生，换句话说，一个明星团队会做出很多明星产品。能够产出明星产品的团队，同样也是优秀的团队。所以，运营出影响力大的开源项目，可以佐证这个团队出的是精品，是对团队与个人实力的认可。

项目生长
产品立项——直击痛点，有吸引力
我们必须为产品找到一个痛点，才能吸引开发者来使用。

深入调研我们要明白自己做的是什么。是一个轮子，还是一个新的轮子？
产品定位我们的产品是给小白用户用的，还是给高级开发者用的？我们要做简单易用的东西，还是高端的模块？这些在项目开始时就应该定位好。
明确受众我们产品受众的是公司内的产品或业务线，还是为整个开源圈做贡献？相信大部分人都认为，开源项目首先要满足业务线上的需求。当满足大项目的需求之后，再把项目开源出去，用户就会觉得，“大项目都能用了，我的项目自然能用得如鱼得水”
规划未来梦想还是要有的。我们的每一个小项目开源出去，都有可能开花结果。所以项目初期，我就对它的未来做畅想，说不定它就成为下一个像微信一样优秀的产品。


快速迭代——注重体验，有竞争力
每进行一次迭代，都需要关注功能体验，尽力给用户“用起来很顺手”的感觉。这样我们的产品才能在同类竞品中闪闪发光，保持竞争力。

尽早发布最小的可用版本不要一开始就追求完美，等到做出版本才去发布。我建议，版本就可以发布出去。这可以在市场有一次很好的试水，看看开发者的反馈。通常开发者会有两种表现。一是“好像别人已经做过了，你去看一下吧”。如果别人确实做得比自己好，这个项目就可以砍掉了。二是开发者对你的项目提出各种各样的点子，说明项目击中了痛点，打到了实处。
合理制定功能迭代优先级我们需要把自己要做的每个需求做简单地分类，哪些是要做的，哪些是用户真正用到的。把它们列起来，这样会显得非常直观。
可回溯的版本号和发布日志不能每个版本都是版。这里我推荐语义化版本网址 ，它会告诉你和版本的区别是什么，如何按照这样的约定进行版本命名。大家以后管理项目版本的时候可以使用这个工具。
打磨细节，优化体验细节决定成败。往往很多时候，产品的一个细节，一个闪光点就可以秒杀竞品。如果他在这一点上的体验不如你，用户马上就会向你倾斜。

运营推广
假如我们已手握一个好产品，它的结果会是怎样呢？有句话说得好，“酒香也怕巷子深”。现在是卖家市场，越来越多的东西都需要推广出去，才能被用户接触到，否则很多好的产品都会被埋没。
推广曝光：以量取胜
简单来说就是拉新，拉拢新用户。我们要以量取胜，让更多人知道我们的开源项目。无论他是不是我的目标受众，他都会知道，有个产品叫，是给前端使用的。这样，产品曝光的目的就达到了。

一份引人入胜的一开始的虽然很清晰，但用户不能一眼就看出来我们是怎样的软件。所以，我就做了官网 ，用户可以很清晰地知道，下载之后到底是什么东西。用户看到的软件时就望而却步了。因此我们必须要解决这个问题。

方便优雅的使用体验我们把整个软件的界面展示给用户看，把整个功能教程也放到里面。用户可以一条一条地去使用，不会有太多门槛。

发表技术文章前期我们会在科技媒体，社交网络，热门论坛发表项目相关的技术文章。用和别人撕逼的方式去博得关注度是不可取的，有效的方式是诚恳地向别人介绍我们的项目，开源社区也会很快地接纳，并给出公正的评价。
会议分享，线下沙龙在线下与开发者交流，跟主办方取得联系，同样可以起到推广的作用。
优化下载渠道对于软件来说，下载和分发的速度不太快。所以我们需要用到比较快的，把常见的如位位的版本单独封装好，打包，提供各种下载渠道，尽量让用户点完就可以用。
小技巧：统计数据这个功能藏得非常深，需要账号登录到项目首页才能看到这些数据。数据呈现的是访问量，还有每一条链接来源于何处。这样你就可以看到，你在多个渠道发布的文章，哪些点击率更高，哪些渠道可获得更多的用户来源，利于后续开源项目的运营指导。


口碑打造：留存核心用户
留存，留住旧用户。经过推广曝光之后，就会有一大批用户涌入进来。一旦用户使用了我们的产品，那他就是我们的目标受众，是产品的核心用户。我们必须想方设法留住他，解决他使用过程中遇到的问题。

详尽的，完善的文档我们对项目的每一个功能点都写了一篇详细的文章去介绍它，并配有截图。同时我们还配备英文版，因为开源项目受众于的用户来自全世界。
及时的社区答疑，保持 跟进对用户的反馈，即使不是你所能接受的，但不能表现出“爱理不理”的姿态。我们要把用户在提出的每条记录下来，解决之后进行回复。
保持更新迭代频率一个项目需要保持一定的更新频次，因为很多公司或者项目组的选型的时候，他们发现一个项目八个月没有更新了，即便是很好的项目，他们也会觉得很多漏洞没有人修，就会放弃使用。比较好的更新周期应该是三个月以内有一次小的迭代，或者一个 这样的补丁。

社区维护
开源项目经过推广和运营之后，可以得到一小撮核心用户和帮我们做宣传的“自来水”人群，这样就形成了一个初步的社区。那么，接下来就是社区维护的工作。
保持活力

扩大开源范围：设计、交互开源不仅局限于代码。我们的定式思维是，只有代码才能开源。其实不是的，在前端项目中，我们完全可以把交互甚至产品阶段的草稿都对外开源。这样会有更多不同角色的人参与到你的项目中，为你添砖加瓦。就像整个设计稿都是开源的，对用户非常友好。平时在做一些交互稿的时候，我都会去参考，很方便，交互也很舒服。
集成自动化，使用徽章因为我们的项目不是每天都能去管理和维护的，比如团建或者周末的时间。如果集成了自动化，再使用一些徽章，例如图中的，，还有我们的一些依赖，都用徽章的形式放在项目头部。当集成自动化之后，有人在社区里提出 ，它会直接影响头部徽章的变动，可以很直观看到自己的贡献发生了作用。这对社区贡献者是很好的激励作用，所以我是非常赞成大家用徽章的方式管理这些开源项目的。
寻求跨界合作＆周边产品当你的项目规模到一定程度的时候，就可以寻求跨界合作和产出周边产品。你可以基于开源项目生成一堆好玩的周边，发给项目的忠实贡献者，例如贴纸、文化衫。大家肯定也会非常的喜欢，感觉自己为开源事业做出了贡献。


注入血液

提供简明的贡献方式曾经我做开源项目的时候，只做了简体中文、英文、繁体中文版本，我没精力去做其它语言包。而我给开发者做了语言包贡献的指引，之后便收到社区里日语翻译包，这让我非常欣喜。
国际化，多语言考虑开源社区的国际化。我们的开源项目首页基本都用英语写，然后提供中文版的入口。这样全世界的开发者都能看得懂你的项目。
及时处理 对于改动很大的，必须先给代码做，才能合上去。
收集用户反馈及新需求我们需要把用户反馈的需求都收集下来，并对需求的紧急程度做优先级排序，再考虑要不要做。

总的来说，要运营好自己的开源项目及整个开源社区，要“怀揣一个热情的心”，并保持一种激情，去迎接每一次改动。一个成功的开源项目，首先它必须是直击用户痛点的，其次也离不开好的运营方式，否则就没机会得到曝光了。这样，我们就能形成友好，有生命力的社区，产生该有的影响力。这就是我认为的，成功开源项目的必经之路。
点击可以直接访问开源项目。 如果觉得的分享很不错，还可以关注他的账号， 向大神学习运营开源项目的技巧吧原文：       
我们会通过本文介绍下书写  的最佳实践，包括各个主题，像是命名路由、认证、黑盒测试以及对相关资源使用合适的缓存头。
对于来说最流行的一个用例就是用其来书写 。尽管如此，当我们使用监控工具来帮助用户排查问题时，我们总是能感受到在 上开发者们有很多的问题。
我希望这些最佳实践能够对你有所帮助。
 使用方法和路由
设想一下你正在构建  用以用来创建、更新、获取或者删除用户。这些操作已经有可以胜任的工具集：   或 。
作为最佳实践，你的路由应该一直使用名词作为资源。涉及到用的资源相关的，路由机制也可以这样：

  或者   来创建新用户

  来获取列表的用户

  来获得某一个用户

  来修改已有的用户记录

  来删除一个用户


 正确地使用状态码
如果处理请求时出了问题，你必须在响应里设置正确的状态码：

，如果一切都

，如果资源被移除

，如果因为服务器错误导致请求无法实现 例如请求一个不存在的资源

 如果测出现问题 例如异常发生


如果你正在使用，设置状态码就是这么简单 {    }。 和使用很类似：
查看    以寻求完整列表
使用头来设置
使用头把加到要发送的负载上。像这样的头可以是在如下信息的上：

页码

速率限制

或者是认证


标准化头的列表可以在 这里 被找到。
如果你需要在你的相应头里面设置任何自定义的，给它们加上前缀是最佳实践。例如，之前如果你在使用 时，把其命名为是很普遍但不标准的做法。无论如何随着 的发布，这些都已经被废弃了。新最好不要使用会和其他应用发生冲突的名。例如，在它们的前加上了：
  
  

需要注意的是标准里并没有任何尺寸限制的定义；然而，出于实际原因对对象添加了大小的限制。

“不要让 包括状态行超过___。这一检查是为了保护嵌入机免受拒绝服务攻击，这一攻击里攻击者可以给我们发送一个没有结尾的，这会导致嵌入机一直缓冲”
来自   解析器

 为你的  挑选合适的框架
挑选最适合你用例的框架是很重要的。
，  亦或是 
，和 可以被用来创造浏览器应用，同样的，它们支持模版和渲染 —— 只需要来命名几个特性。如果你的应用也需要提供用户界面，使用它们很有必要。

另一方面，致力于帮助你构建服务。其存在的意思便在于让你构建“严格的”可维护可观察的服务。同样可以和自动化的协作支持你所有的。
主要被用于像或者的应用生产里。
接下篇《十个书写  的最佳实践下》