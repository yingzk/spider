翻译 | 科技大本营参与 | 周翔、_、
随着   的发布，利用深度学习进行人脸识别预计将逐渐成为智能手机的标配。然而，除了身份认证之外，最近还涌现出很多研究，探讨通过“刷脸”是否能预测人的性格，甚至是人的行为。
 年年底，上海交通大学的武筱林教授和他的博士生张熙发表了一篇论文——《基于面部图像的自动犯罪概率推断》。该研究认为，通过学习，机器可以通过照片分辨出谁是罪犯，谁是守法公民，且准确率在以上。
这篇论文在  界引起了轩然大波：人的面部特征真的能用来预测人的行为和性格吗？这种研究真的不涉嫌歧视吗？
近日，斯坦福大学助理教授   及研究生   的一篇论文——《在通过面部照片判断个人性取向的问题上，深度神经网络比人类更准确》              ，同样引起了极大的争议。
这项研究发现，在“识别同性恋”的任务中，深度神经网络的表现要比人类更好，前者的准确率在男性中为 ，在女性中为 。
此外，最可能为男同性恋者的典型脸部特征更趋于女性化，而女同性恋者则更男性化。通常，男性的下巴较宽，鼻子较短，前额较小；而男同性恋者下巴较窄，鼻子较长，前额较大，脸部毛发较稀少。相反，女同性恋者的脸部通常比女异性恋者的脸部更像男性脸部下巴较宽，前额较小。而且，同性恋者和异性恋者在梳洗打扮方面确实不同。
这项刊登在著名的心理学期刊上的研究成果，遭到了前所未有的批评，除了学术界的质疑，该论文作者还受到各种谩骂，甚至收到了威胁邮件。

“ ：     
你好，
我刚刚读完你的关于检测人类性取向的深度学习项目。我认为这样的一个研究是要被禁止的。一个人的性取向应该是他或她的隐私。
你肯定知道在一些国家，同性恋是犯罪行为。所以我认为你是一个支持谋杀同性恋者的恐同混蛋。如果不是，请你销毁所有跟这个话题有关的工作，否则，我希望能来个人杀了你，因为你的工作将使很多人受到折磨，甚至死亡。
请你拿起刀，给自己来个痛快吧！
   ”

对于这封“死亡信件”，论文作者是这样回复的：

“亲爱的 ，
您说您读了我的项目，但您真的理解这个项目吗？在送我去死之前，您能不能抽点儿时间，真正读一读您写给我的您想要另一个人去死的那段话。仅仅根据传闻去评判别人，不管您是不是  编者注：=女同性恋 男同性恋 双性恋跨性别 非异性恋或不认同出生性别的人，都不应该口出此言。
如果您真的读了我的项目并想提供您的想法意见，我将倍感荣幸。我也真的很珍惜。而且，如果在认真读完之后，您仍然希望我自裁，那我就有可能更加认真地对待这样一个有根据的要求。您可以在这里找到这个文件：
您也可以从我的笔记开始：

  ”

为了消除外界的质疑，论文作者对网上的各种批评一一回复，科技大本营对其原文进行了不改变原意的编译。看完这些回复，或许你会对作者的研究初衷和研究成果会有更深刻的理解，甚至会对同性恋的成因和表现形式有一定的了解。
一、研究结果总结
我们并没有创建一个侵犯隐私的工具。我们只是研究了已经被科技公司和政府部门广泛使用的现有技术，并判断它们是否存在侵犯  人群个人隐私的风险。
令人不安的是，我们发现这些技术确实存在这样的风险。
我们的工作其实很有限：我们只研究了自称是同性恋或者异性恋的人群。然而，这些限制并不会让研究成果或者其传递的核心信息无效：广泛使用的技术对  人群的个人隐私构成威胁。
在反驳之前，希望你们能够考虑这些证据。
我们的主要发现是什么？
在进行的  项研究中，我们展示了一种可以通过人脸准确检测这个人的性取向的算法。如果有两个测试对象：男同性恋者和直男，或者女同性恋者和直女，我们的算法  的时间能正确区分男同性恋者和直男， 的时间能够正确区分女同性恋者和直女。
要知道，乳腺钼靶线影像的准确率才 ，帕金森病现代诊断工具的准确率也才 。
我们的数据集包括  张同性恋以及异性恋的图片，这些图片都来自一个公开的数据集，而且用户自己已经标记了自己的性取向。在一个图像子集上，我们的算法取得了前所未有的精度。我们确保算法的预测不受年龄和种族差异的影响。
此外，我们还对  个人资料图片的独立样本进行了测试，并取得了相近的结果。
相比之下，人类的判断并不比随机猜测更准确。我们认为，这是  胜过人类的又一个例子。这项研究经过了同行的评审，并最终在“      ”心理学领域的顶尖期刊上发表。此外，在我们将这篇论文正式发送给同行进行评审前，已经有十多位性学、心理学和人工智能领域的专家对草稿进行了审查。该研究也已经获得内部审查委员会的批准。
什么特征被用来预测性取向？
分类器使用的是固态和瞬态面部特征。同性恋者和异性恋者不仅面孔形态不同，而且表情和修饰风格也不相同。
你肯定错了——这是伪科学！
我们得到了很多这样的反馈。坦白说，如果我们的结果是错的，我们会很高兴。这样的话，人类会少一个问题，我们可以继续写写畅销书，比如微笑如何让你更快乐等等。
这些调查结果对隐私有什么影响？
算法根据人脸来预测人的性取向会造成严重的隐私隐患，这是事实。因此，控制什么时候、向谁透露个人性取向的能力，不仅对于人类的福祉，而且对于人类的安全也至关重要。
在某些情况下，个人性取向被公开可能会危及生命。 社区的成员仍然会受到来自政府、邻居、甚至家人身心上的虐待。许多国家将同性性行为定为犯罪行为，在某些地方，发生同性性行为的人甚至会被判处死刑。发布这些结果，作者担心吗？
我们真心对这些结果感到不安，花了很多时间考虑是否将它公开。在结果发布后，我们收到了各种警告，这正是我们当初不愿看到的。
然而，最近的新闻报道显示，政府和企业已经在使用通过面部来判断亲密特征的工具。数十亿人的面部图像存储在数字和传统的档案中，包括约会平台、照片分享网站和政府数据库。默认情况下，、、 上的个人资料图片都是公开的。而 闭路电视摄像头和智能手机都可以在未经许可的情况下拍摄他人的脸部照片。
我们认为， 目前迫切需要让决策者和  社区意识到他们面临的风险。科技公司和政府机构很清楚计算机视觉算法工具的潜力。我们相信，人们应当了解这些风险，并采取适当的预防措施。
在结果发布之前，我们确保我们的工作不会为那些可能侵犯他人隐私的人提供任何好处。我们使用了很多现成工具、公开数据和计算机视觉从业者所周知的标准方法。我们并没有创建什么侵犯隐私的工具，而是想表明，一直以来人们广泛使用的基本的方法都会造成严重的隐私威胁。
为什么要研究面部特征和性格之间的联系呢？
就像前面说的那样，这具有重要的隐私意义。群众和政策制定者应当知道他们将面临的风险，并且应该有机会来采取预防措施。
从科学的角度来看，这种联系也很有意思。识别面部特征和心理特征之间的联系可以帮助我们了解广泛的心理、生物和文化现象的起源和本质。否则，许多可以从人脸很容易估计到的因素——如产前和产后激素水平、发育史、健康、环境因素和基因——都将将难以测量。因此，将面部特征与其他现象联系起来，可以帮助我们产生很多可以用其他科学方法进行探索的假设。将性格特质与面部特征联系起来的潜在机制是什么？
有三种。首先，性格可以影响人的脸部外观。例如，性格比较外向的女性往往随着年龄的增长，外观会变得更具吸引力。
其次，面部外观可以影响人的性格。例如，好看的人会得到更积极的社会反馈，因此往往变得更加外向。
第三，许多因素会同时影响人的外观和个性。包括产前和产后激素水平、发育史、环境因素和基因等等，例如，睾丸素的水平会显著影响人的行为例如权力欲和面部外观例如面部宽度和面部毛发。怎样解释脸部特征和性取向之间的关联？
通常情况下，科研工作者会使用普遍认可的产前激素理论来预测脸部特征和性取向之间的关联。根据 ，因为雄性激素负责胎儿的性分化，因此男胎形成同性性取向的成因是由于其受雄性激素影响不足，女胎则是过度受雄性影响。由于相同的雄性激素还负责脸部的两性异形， 预测同性恋者一般具有性别非典型面部形态  。换句话说，男同性恋者的脸部形态趋于女性化，而女同性恋者的脸部特征一般趋于男性化。
母体产前雄性激素水平还会影响胎儿成年后行为和取向的性分化。因此， 预测同性恋者一般会选择性别非典型的面部修饰、表达和打扮方式。

图：被归类为最可能是同性恋者或异性恋者的典型脸部  轮廓生成的合成脸部和典型脸部轮廓。
与  理论的预测一致，最可能为男同性恋者的典型脸部见图更女性化，而女同性恋者更男性化。通常，男性的下巴较宽，鼻子较短，前额较小；而男同性恋者下巴较窄，鼻子较长，前额较大，脸部毛发较稀少。相反，女同性恋者的脸部通常比女异性恋者的脸部更像男性脸部下巴较宽，前额较小。
同性恋者脸部的性别非典型特征不只体现在形态上。女同性恋者化眼妆以及穿着暴露衣服领口较低的情况通常较少，她们毛发的颜色更深——女性特征较不明显的打扮和风格。另外，女异性恋者一般较常微笑，而女同性恋者则不然。
此外，该理论还印证了美国文化中棒球帽与男子气概之间的关系：异性恋男性和女同性恋似乎都喜欢戴棒球帽观察图人物前额上的阴影；人工检测单一图像证明了这一结论的正确性。
如何解释该算法的准确性？
该分类器的准确性怎么样？分类准确性的解释很重要，而且结论往往与直觉相反！
假设一个由  名男性组成的样本，其中包括  名男同性恋者，利用准确度为 = 的分类器评定他们的脸部对比本研究中男性脸部图像每人张图像分类实验。
分类器虽然不能指出哪个检测对象是同性恋，但是可以标记每个检测对象是同性恋的概率。我们需要决定的是分界点在哪里——或者说概率超过多少才能将某一对象标记为同性恋者，这一点很重要。
如果你想选择少数同性恋者作为样本并保持很小的出错率——将概率最高的少数对象标记为同性恋者，这样就可以得到很高的准确度例如，一小部分标记为同性恋者的对象，但是同时查全率会较低例如，会“漏掉”很多男同性恋者。如果扩大概率范围，就会“检测出”更多的男同性恋者，但是被错误标记为同性恋者的异性恋男性也会增多这就是所谓的“ ”。也就是说，追求高准确度会导致查全率降低，反之亦然。
回到包括  名男同性恋的  名男性样本上。如果从这个样本中随机选择  名男性，预计其中只有  名男性是同性恋——随机抽样的准确度为 样本中每  名男性中有个  名是同性恋者。
用分类器进行分类。根据分类器检测结果，在是同性恋的概率最高的  名男性中，有  名是同性恋准确度 =  = 。换句话说，分类器可以将随机抽样的准确度提高近倍。
我们还可以通过缩小子样本进一步提高准确度。在是同性恋的概率最高的  名男性中，有  名是同性恋准确度 =  = ； 查全率 =  = ，相比随机抽样的准确度，提高了  倍 = 。在同性恋概率最高的  子样本即前  名中，被确认的同性恋者有  名准确度为：随机抽样的准确度提高了  倍。但是实现这么高的准确度的代价是查全率较低：只有   = 。要想提高准确度，就必须牺牲一定的查全率。
二、你肯定错了——这是伪科学！
像其他科学研究一样，我们的研究也可能存在不完善的地方。为此，我们单列了一些大家关心的问题，并予以回复：
“你肯定错了；这个实验的对象全是白种人”
虽然我们力求获得一个更加多样的样本，但是本研究的对象仅限于美国境内的白种人。
这并不能证明本研究的结论无效。本研究证明，你可以区分同性恋者和异性恋者。
虽然本研究并不能证明该结论同样适用于其他种族，但我们发现该结论有适用的可能性。相同的生物学、进化和文化因素促进了同性恋者和异性恋者之间差异的形成，这些因素也很可能会影响其他种族。
“你肯定错了；该分析未考虑双性恋者。”
是的，我们并未探究是否可以通过脸部预测某一对象为双性恋。
但这并不会使我们的结论失效。我们仍然证明了我们可以区分同性恋者和异性恋者。某些被归类为异性恋或同性恋的对象可能实际上是双性恋。不过，纠正此类错误可能会提高分类器的准确度。
重要的是，不考虑双性恋者或变性者并不代表我们否认他们的存在。
“这肯定错了；研究使用的样本是公开性取向的约会网站会员”
这是一个合理的限制因素，我们在论文中围绕该因素进行了详细地讨论。的确，从约会网站收集的图像数据似乎有这样一个问题：性取向信息特别明显，但是本研究并不止于此。
首先，我们用从  上收集图像组成了一个外部样本，再用这个样本测试我们的分类器，结果准确度并不亚于用约会网站图像做样本时的准确度。这表明  个人档案图像与约会网站上的图像传达出的性取向信息一样明显。
其次，我们让研究参与者根据这些对象脸部判断其性取向。相比以往研究中人类判断实验室精心标准化的图像的准确度，这些参与者的准确度并没有好多少。这表明，本研究中使用的图像性取向信息并不是特别明显——至少，对人类而言是这样。
最后，本研究使用的深度神经网络经过了特别训练，只学习轻易无法改变的固定脸部特征，例如脸部元素的形状。这有助于减小分类器发现研究中同性恋者和异性恋者脸部图像存在某些与脸部无关的表面差异的风险。
“你肯定错了；众所周知，脸部特征和性格特质之间没有关联”
不幸的是，这个说法并没有依据。
很多研究证明，人类可以判断他人的政治观点、个性、性取向、品质以及其他特质，但是准确度不高。在判断这些时，准确度不高并不一定代表脸上没有体现这些特质的明显特征，而是人类可能无法发现或解释这些特征。
“你肯定错了，你的分类器在预测的时候一定选了一些和人脸特征无关的东西作为判别依据”
我们也考虑了很多相关的事情。而且，我们非常希望未来的研究能够更有说服力地证明或反驳利用人脸来预测性取向的可能性。当然，我们自己也做了很多努力来提高这项研究的严谨性和说服力。

首先，我们的模型专门针对那些人脸不容易改变的固定特征——比如面部元素的形状——来进行训练。我们使用的深度神经网络也是针对一项完全不同的任务来进行训练的：即通过图像来识别同一个人。这些能帮助我们降低风险，减少分类器在研究所用的同性恋和异性恋脸部图片之间发现的表层差异，那些差异甚至和脸部都没有关系。

其次，我们在外部样本上对结果进行了二次验证。

第三，我们研究了脸部图像上哪些元素可以用来预测性取向，从而确保这些元素确实是脸部特征而不是其他因素。正如你在论文中了解到的，即使所有的视觉信息都被删除，分类器仍然可以根据脸部的轮廓进行相当准确的预测。

第四，我们仅仅让分类器检测脸部区域，并且删除了图像上面部以外的背景区域。我们还进行了检查，以确保分类器在进行预测时侧重于面部特征而不是背景。下面的热力图从图中可以看出清楚地表明，分类器检测的部分集中在面部区域红色，而不是背景蓝色



图：热力图显示了标记图像上不同的给定部分可以改变分类结果到什么程度。
其中颜色尺度从蓝色不改变一直到红色发生实质性改变分别表示不同的结果。我们使用  高斯滤波对颜色编码的方块进行了平滑处理。
最后，也许最重要的是，分类器发现的男同性恋者和直男在脸部之间的差异与产前激素理论——一个被广泛接受的解释性取向起源的理论——的预测结果是一致的。
“你肯定错了；你的研究结果表明，同性恋者往往是性别不典型——但我明明知道许多性别典型的男同性恋者跟女同性恋者！”
我们也知道存在很多非常阳刚的男同性恋者和很多很有女人味儿的女同性恋者。这就好像，我们知道有很多老男人，但这并不能反驳女性更加长寿的结论。事实上，我们在研究中发现男同性恋者的脸部特征更有女人味儿并不能说明所有男同性恋者都比直男更有女人味儿，或者说不存在很阳刚的男同性恋者女同性恋者亦然。
我们在研究中观察到的有关女人味和男人味儿的差异是很微妙的，并且这些差异存在于很多不同的脸部特征中；虽然人类难以察觉，但对灵敏一些的算法来说，这些差异已经很显而易见了。
“你肯定错了；你实验中的很多参与者肯定在他们的性取向上撒谎了！”
确实，有些跟我们说他是直男的参与者实际上很有可能是同性恋反之亦然。然而，我们相信，那些自愿在约会网站上发布资料寻找伙伴的人，几乎没有在性取向上撒谎的动机。
当然，如果我们的一些参与者确实在他们的性取向上撒了谎，那么拆穿他们的谎言将极有可能进一步提高分类的准确性。
“你肯定错了；唯一的原因是因为同性恋者更在意自己的形象或者说拍的照片更好看！”
我们很容易相信，男同性恋者的发型和胡须造型更好看。就像我们在论文中讨论的那样，同性恋者和异性恋者在梳洗打扮方面确实不同。
然而，他们在形态方面也同样明显不同。我们的算法对只提供脸部轮廓的男同性恋者判别的准确率超过了 ，对于女同性恋者超过了 。

原文地址：导语
从比特率编码方式的角度来看，目前其中一种最常见的音频文件格式，可以再分为两种类型：一种是恒定比特率 ，这种类型的每一帧的比特率都是恒定唯一的；另外一种就是可变比特率 ，这种类型就跟相反，每一帧的比特率是不固定的，帧与帧之间的比特率可能一样也可能不一样。由于存在这样两种类型，播放文件时需要做的一些工作，比如获取音频信息和播放进度控制，就需要分开处理。
一些基本概念的介绍
要明确理解和的具体差异，就需要先了解音频文件的一个重要属性：比特率，比特率又称码率或者位率，是指每秒传送的比特数。单位为   ，比特率越高，传送数据速度越快。音频中的比特率是指将模拟声音信号转换成数字声音信号后，单位时间内的二进制数据量，是间接衡量音频质量的一个指标。
音频文件的比特率单位一般是，  =  。而的比特率默认是 ，但是目前网络下载到的更为常见的是 ，而如果要获取更加好的音质的高清，比特率通常都要到达 ，通常来讲，比特率越高，音质就越好，但占用磁盘的空间就越大。
一般来说，声音片段的音调越高，就需要更多的空间去存储，比特率就越高。传统的文件是编码的，也就是每一帧的比特率都是相同的，这样就带来了一个问题：如果每一帧的比特率是相同的，那么每一帧的数据大小都是一样的，无论这一帧的音调是高还是低，都是使用整段音频中音调比较高的音频帧的存储空间的大小来存储这一帧，但是对于音调低的音频帧，其实并不需要这么大的存储空间。这样就会造成存储空间的浪费，无形中增大了文件的大小。
编码技术的出现，就是为了解决这个空间浪费的问题。技术对每个音频帧选择最适合这一帧的比特率，对于音调比较低的音频帧，比特率会比较低，数据大小就比较小，音调比较高的则比特率就会比较高，数据大小就比较大。这样就能在不损失音频质量的前提下，节省音频数据的存储空间，进一步压缩的文件大小。

上图简要对比了和两种类型的文件的数据内容上的差别。可以看到，编码的，帧与帧之间由于数据内容的差异，比特率不一定相同，通常技术会在 这个范围压缩编码，所以相比整个文件中比特率都是恒定的编码，编码在整个文件中比特率是浮动可变的，这也是可变比特率这个名字的由来。
除了和这两种编码，还存在一种类型 ，平均比特率的编码，它与基本相同，大多数音频帧以指定的比特率编码，但会在个别适当的内容使用高于指定的比特率编码，但是通常这种内容很短，所以在文件大小上跟相比没有太大的差异，因此这种类型并不常见。
技术对比技术存在的缺点
使用技术来编码压缩文件，诚然可以优化文件的大小，但同时在音频信息的获取和播放进度的控制也带来了一些新的问题。
首先是音频时间长度的计算。如果是编码，由于比特率恒定，所有音频帧的数据大小是固定的，所以每一秒播放所需解码的数据大小都是相同的，这样计算音频的时间长度就非常简单。使用以下公式即可：

时间长度=文件总长度 字段总大小如果存在  比特率  
公式中，字段是指放在文件开头或末尾的基本信息字段，通常用来记录音频文件的名字，歌手名，专辑名这三个信息，分和两个版本，只记录上述的三种信息，且大小固定，一般放在文件末尾；则比灵活，记录的信息类型不限于上述三种，且大小不固定，一般放在文件开头。字段是可选字段，文件不一定有，所以计算的音频时间，需要先读取获知是否存在。
对于编码的文件，由于每一帧的比特率是不固定的，所以每一帧的数据大小是任意的。显然这样每秒播放的数据大小都不一样。这样整个音频的时间长度就不能以上述公式计算，需要借助其他的数据字段，这是技术的其中一个缺点：计算音频时长相对困难复杂。
技术还有另外一个缺点，播放音频文件的时候不可避免会有跳到指定时间的位置播放的操作也就是常说的操作，这时就需要把目标的时间位置换算成文件位置，再跳转到这个文件位置偏移读取解码，如果是网络播放的边下载边播放的模式，在操作的时候还需要先计算出这个文件位置，跳转到这个位置先下载一段才能继续播放。对于编码，换算成文件位置偏移也很简单，使用的是以下公式：
文件位置 =  目标时间位置  比特率           字段大小如果存在
但是对于编码，显然也是不能使用这个公式换算出文件位置的。原因也很简单：每一帧的比特率不固定，每秒的数据长度不平均。所以跟计算时长一样，需要借助其他数据字段。
编码计算音频时长和实现操作的方法
为了解决上述的两个问题，编码增加了一些数据字段。目前编码技术主要有两种，一种是公司提出的规范，一种是编码器的规范，由于使用规范的编码不常见，大多数编码都是采用规范，所以本文只对规范如何解决音频长度计算和操作的实现作介绍。
规范的主要内容是头，这是指编码的的开头第一个音频帧不用来存储具体的音频数据，而是用来存储一些额外的音频信息。这些信息以“”这四个字符作为字段开头的标记也有部分文件以“”这四个字符作为头的开头标记。
头在第一个音频帧中的位置，是在标准的个的音频帧帧头之后，在帧头和头之间，会有一段数据内容全是的空白部分，这个空白部分的长度是指定的。解码器在解析到第一个音频帧的帧头之后，就是通过跳过这段指定长度的空白部分，然后判断接下来的内容是否就是‘’或者‘’这四个字符，来判断音频是否编码。
空白部分的长度有版本和声道数决定，具体如下表单位为：



版本
单声道
非单声道




 

最常见


 





下图是编码的的第一帧数据的字段结构的例子：

头的字段结构和存储的信息内容如下表：

现在首先看看如何利用头中的信息来计算编码中音频时间的长度。
如果头中包含总帧数这个信息，那么就先把总帧数读出来，假设文件如上表中举例，总帧数是。然后乘以每帧采样数，得到总采样数。每帧采样数是文件的固定属性，这个数值由版本和版本决定，与编码类型是还是无关。
每帧采样数详细如下表：



版本
 
 
 




 





 






文件是格式，也就是   ，每帧采样数就是，那么总采样数就是
   = 。
现在得到了总采样数，那么总的音频时间就不难得出了，由于采样率也是音频文件的固定属性，假设是 ，所以总的音频时间就是总采样数除以采样率，也就是
   =  
因此，只要编码的头里带有包含总帧数这个字段一般都会有，就能计算得出音频时长。
下面再来看看编码如何利用头的信息实现操作。
编码的操作主要是利用头中的表如果这个表存在，表  是一个长度为的数组，数组中每个元素都代表在音频时长内的一个特定的时间点对应的文件的相对位置。 简单的说，表的组成，就是把整个文件平均分成段，每一段代表一个文件位置，再把总的音频时长平均分为段，每一段代表一个时间点，然后对这个时间点，每一个都找出个文件位置中其对应的那个位置，这个位置是这个位置中的相对位置，取值在，放在表中。
如何使用表实现时间点到文件位置的映射，算法如下：
假设文件持续秒，现在需要跳到秒，文件长度为 ，那么先用以下公式计算出秒对应表的哪个元素：
     = 
然后在根据以下公式算出文件位置：
    
但是上述算法，只能在这种情况有效：目标时间点是时间点，也就是目标时间点在把总时长平均分成份的个时间点之中，对于目标时间点不在这个时间点之中的情况，如果参考系统在解码编码的时候的做法，就是在上述算法的基础上，再算出目标时间点在时间位置上处于那个时间点中的哪两个相邻的时间点之间，假设这两个时间点对应的相对文件位置是和，通过这两个相对文件位置用线性插值的方式算出目标时间点的相对文件位置，进而算出目标文件位置。
系统源码中利用头的表实现音频时间点和其对应的文件位置的换算，代码如下：
 _  _  {
  ==  ||  ||    {
     
}

  =     
 
  =   {
     = 
}    =   {
     = 
}  {
      = 
      
       ==   {
         = 
    }  {
         = 
    }
          {
         = 
    }  {
         = 
    }
     =   
}

  =   

 
}
以上就是编码的播放的操作的具体实现原理。
结语
通过以上的分析介绍，我们可以知道，的和两种编码类型各有优劣：在编解码的复杂程度的角度看，相对简单容易操作；在存储空间的利用率的角度看，利用率更高。由于是目前最常见的音频格式，在做客户端的音频解码工作的时候，对这两种编码类型都要做细致的针对性的处理，这样才能减少播放出现的问题，提高播放的体验。
参考资料：
音频文件格式包括格式详解——转载：
   ：基于，绕过内核的协议栈，移植了协议栈到用户态，在大幅提高性能的同时，常规网络设置分析工具如、、、等都无法直接使用。但是由于在用户态运行了的协议栈，我们可以移植下的这些工具到。
移植的关键是这些工具要能与进程通信，在之前的文章中，我们介绍了如何使用 _来进行多进程的通信，目录就是基于_实现了一个简单的框架。下面以为例，介绍一下如何移植到。
查看  的源码，可以发现是通过系统调用来与内核进行通信的，我们需要替换掉的就是这个函数。
首先在_中，定义了用于通信的结构体 _，暂时只实现了，后续会加上、等其他工具移植需要的系统调用。
      
 __ {
    _ = 
    _
}

 __ {
     
     
     
    _ 
     
    _ 
}

 ___ 

     
 _ {
     __ _
         
     
         
    _ _
         
     _

     {
         __ 
    }
} ____ ____
__中，初始化时会创建单个元素长度为___的内存池_，通信时从_里取出元素，转换成 _，这里有个要注意的地方，_里的指针成员、等必须指向__到____之间的地址__=___ _，不能使用自己申请的内存地址，这是因为用于通信的数据必须使用_中的共享内存，否则另一端会出现未知的错误。
处理流程：从中出队列，取出，判断是_类型，然后执行_函数获取或设置内核的状态参数，最后再把入队列。这里出入的是单生产者单消费者模式的，使用了两个，一个用于出，工具入，一个用于入，工具出。
  
__ _  _ _
{
      = _ 
          
        

        {
         = 
    }  {
         = 
    }

    ____ 
}

  
__ _  _ _
{
     = 
    ____ 
}

  
_ _  _ _
{
     _ {
         _
            __ _
            
        
            __ _
            
    }
}

  
___ _
{
     
      = ____ 

      ==  {
        _ _  _
    }

     
}
然后看下中的处理，这里我们实现了一个新的函数_用来替换原来的系统调用
 __ _      
    _     _ 
因为是多进程架构，并且每个进程都有一个独立的栈，所以新增了一个参数_，用于指定与哪个进程通信，这个算是一个不方便的地方。其他参数都与原生的一样。
_的实现流程：从中获取_对象，设置参数，入队列，出队列，输出返回信息。
 _  = ___

 _ = _
_ = _
 =  _
 = 
  
_ = 



__ _

__ _



___
另外由于是移植的下的，所以它的头文件、结构体在下可能没有，需要根据实际情况进行增删。具体的代码可以查看 和 目录。
运行效果：
除了新增加了一个参数用于指定与哪个进程通信外，其他参数与原生一致，具体可参考 。
根据这个例子，我们可以对其他工具进行移植，如、、等。作者：王连赢

沙箱逃逸是浏览器安全研究的一个重要课题，其中有一类漏洞会借助设置中的白名单程序的缺陷来完成沙箱逃逸。在注册表中有一个和类似的名为策略设置，这引起了我们的注意。在本文中，笔者将以一个攻击者的视角，尝试各种途径来突破沙箱的这一安全策略，通过分析所遇到的障碍，达到对沙箱拖拽安全策略进行详细解析的目的。
 沙箱的拖拽策略
沙箱逃逸技术中有一类是利用中的白名单程序的问题去执行任意代码，在注册表中，有一个和类似的配置，名为，具体注册表路径如下：       \\\ \ \       如下图所示：

 值的含义如下：       ：目标窗口是无效的，拒绝；       ：目标窗口是有效的，但无法复制内容；       ：弹框询问用户，允许后将内容复制到目标窗口；       ：静默允许拖拽。
在一个干净的 系统上，目录下默认有三个程序：  ，它们的值都是。当目标程序的值为时，向目标程序窗口拖拽文件，会弹出一个提示框，如下图所示：
  
 进程的拖拽问题
在从往上拖拽文件时，虽然 值设置为了，不会弹框，但是进程会会弹一个提示框，如下图所示：
  
然而，当我们从中向侧边栏的树形文件夹结构中拖拽文件时，并不会弹框。这应该是程序实现上的一个疏漏。进一步设想，如果我们能够在沙箱中通过程序模拟鼠标的拖拽操作，那么就能够利用的这个问题跨越沙箱的安全边界。
 不使用鼠标完成拖拽
拖拽是一种通用的文件拖拽方式，它采用了的接口设计方法来实现拖拽功能，使得拖拽的实现通用且模块化。拖拽技术包含三个基本接口：

接口：表示拖拽操作的源对象，由源对象实现；

接口：表示拖拽操作的目标对象，由目标对象实现；

接口：表示拖拽操作中传输的数据，由源对象实现。
   下图描述了一个完整的拖拽操作需要实现的关键组件：


 
我们要模拟鼠标拖拽，则只需要实现和接口。正常的拖拽操作的核心是调用函数，该函数原型如下：
 
                
               
                       
                          

   的参数中包含了拖拽源对象和拖拽数据的信息，在函数内部通过鼠标指针位置来获取拖拽目标对象的信息。接下来，笔者给出一种不使用鼠标，而是用代码模拟的方式来完成文件拖拽的方法。要通过代码模拟鼠标拖拽操作，即要将函数中操作的部分剥离出来，找出真正执行拖拽操作的函数，将所需要的参数直接传递给它来完成拖拽操作。这里以上的 为例，说明内部的实现。的主要逻辑如下：
 __ 
      
      
             
          
{
    
     
    
         
         
         
         
         
        

      =  {
          
                
                 
             = 
         }
         
     
}
是构造函数，其中重要的初始化操作包括：
   
 

 
 接下来的循环判断拖拽的状态，最终由完成拖拽，关键的函数调用如下：
   


   
   
   
   
  
  
  可以看到，最终实现拖拽操作的函数是，通过使用函数偏移硬编码函数地址，可以调用到中的内部函数。我们定义了一个函数来模拟鼠标拖拽，输入参数为目标窗口句柄和被拖拽文件的指针，主要逻辑如下：
    
{
    _
    

         = 
      = 
                         _ 
                          
                         

     {
              = 
             = {   }
               = 

          = 
                              
                             _
                              
                              
                             _ 
                              
                              
                              
                             
     {
          = 
                                  
                                 _ 
                                  
                                  
                                 _ 
                                  
                                  
                                  
                                 
       {
                  = _
                  = 
                                      
                                     _ 
                                      
                                      
                                      
                                      
                                      
                                      
                                     
            }
        }
    }
     
}
 目标窗口句柄可以通过函数获得，将被拖拽文件封装成一个并获得其接口指针的方法有两种：

自己编写类实现接口；

使用现有类库中的实现，如： 中均有对拖拽接口实现的相关类。
   笔者这里给出使用类库对文件进行封装并获得其接口的方法，实现代码如下：


  
{
         =  
           
                    = 
                
             
                 
               = { _  _  _ }

     =       
     =  | _ 

      = {
         = 
          = {
             = 
 _
     = 

             =   
             
            
            _  
             =  _
        }
        {
            
             = 
        }
    }
    {
        
         = 
    }
     
}
 沙箱的拖拽实现
当我们在沙箱中用鼠标进行拖拽操作时，沙箱内的 进程会通过将数据转发给沙箱外的主进程，在主进程中完成拖拽操作。也就是说，真正完成拖拽操作是在沙箱外的主进程内。两个进程的函数调用情况大致如下：
   子进程沙箱中：
   
   
   
    … 发送消息给主进程
 主进程：
 … 接收子进程发来的消息
 
   
   
  
 沙箱对拖拽操作的安全限制
  在沙箱中，我们是可以直接调到中的函数的。通过自己创建一个，再由创建一个，我们就可以调到主进程中的函数。调用的实现方法大致如下：
 __  


{
      = 
     
     =  
     {
         
          = 
         
    }
     
}

  = 
 

            _ 
            __
            

            __ 
             
             
            
            
             
             
拖拽功能最终是调用函数来实现的，所需的参数都可以由函数传入参考章节中函数的参数信息。至此，我们已经可以从沙箱内直接走到沙箱外的函数，且传入参数可控。而要模拟鼠标拖拽操作，有两个思路：

使用章节中所讲的直接调用内部函数的方法；

调用改变鼠标位置。



对于第一种方法，由于我们是在沙箱内，只能通过接口的代理才能从沙箱中出来，进入到主进程的进程空间。所以我们并不能调到主进程中的内部函数，进而这种方法是不可行的。
第二种方法，如果我们能够改变鼠标的位置，那么在函数内部通过鼠标位置获取目标窗口信息的步骤就会成功通过，就能够完成模拟鼠标拖拽的目标。然而实验过程中，我们发现在沙箱中是无法通过来改变鼠标指针位置的。下面来具体说明这个问题。
 笔者想到的能够改变鼠标指针位置的方法有两种：
 、通过函数模拟鼠标动作。函数从用户态到内核态的函数调用关系如下所示：
   





 

   
、 通过函数改变鼠标指针位置。函数从用户态到内核态的函数调用关系如下：


 
 


先来看，如果在沙箱中直接调用函数来改变鼠标指针位置的话，会返回拒绝访问错误，这是因为中对函数做了，在函数中做了处理。具体做处理的函数位置如下：
   __

 
这个很容易绕过，我们直接调用即可，不过这个函数没有导出，需要通过函数偏移硬编码它的地址。
直接调用，该函数不返回错误，但是鼠标指针的位置并没有改变。究其原因，函数调用的失败是由于   的限制。调用函数也会出现相同的情况。
是从 开始系统新加入的一项安全特性，它在内核中实现，具体位置如下：
  
在上，这个函数的逻辑如下：
  __
       
            
       
            
{
      
        
            
         = 
        
              ==  
         =  ==  ||
                   ==  ||
                   ==  ||
                  
                      
                      
                      
    
         = 
     
}
这个函数首先判断源进程和目标进程的 ，若源小于目标，则拒绝；若源大于目标，则允许。接着判断属性，若源和目标的相等，且均运行在中，则判断二者是否满足函数的约束，满足则允许，否则拒绝。
 注：和参数都是从结构中取出来的，这是一个内部结构。是中的一个内部函数。
 总结
本文详细解析了沙箱对于拖拽操作的安全策略，先后分析了沙箱的拖拽限制策略、进程在拖拽限制上存在的问题、实现拖拽的内部原理、在沙箱中实现拖拽操作的原理和沙箱对拖拽操作进行安全限制的具体位置和实现细节。沙箱通过在中特定函数和借助系统的特性 以上对拖拽操作进行了有效的安全限制。
参考资料
             
                                                                                       
            
                                                            ===_
致谢
感谢  在逆向上的帮助；
感谢  在思路和技术难点上的指点。导读月日，腾讯“云未来”峰会进入到各专场的环节。来自腾讯技术工程事业群的领导及员工作为演讲嘉宾参加了政企、大数据、开发者个专场，并向行业合作伙伴介绍了在该领域的沉淀和探索。数据平台部负责人蒋杰为大数据专场致辞，来自数据平台部的智能学习组及海量计算组组长、专家黄明发表了演讲。以下为现场内容的整理报道。


数据平台部负责人蒋杰提到，在过去的一年里面腾讯云开放了腾讯数智方略产品，这个产品包含了腾讯年的大数据能力和经验。开放出来给政府或企业进行部署，能够帮助大家避免初涉的问题。在这过程中，腾讯大数据的能力也在不断的提升。就在去年，腾讯大数据参加了具有全球计算奥运大会之称的 全球排序竞赛，夺得和的冠军，刷新了项世界纪录，腾讯大数据的运算能力达到世界级水平。今年腾讯大数据将继续抱着开放的心态，在腾讯云上把轻量的数据服务能力、实时的多维分析能力、的托管服务能力开放出来。更为重要的是，腾讯的智能服务、数字营销服务这样的重量级服务也会一并开放，让整个行业真正感受到数据的价值。

演讲主题：：腾讯云上的深度学习平台
演讲嘉宾：数据平台部智能学习组及海量计算组组长、专家黄明
大家好，今天由分享的是由腾讯数据平台部和腾讯云联袂合作的打造的产品，。这是腾讯云上的深度学习平台，对腾讯云升级为云有着重要的意义。

今天是大数据的专场，大家都知道在过去两年，人工智能得到了迅猛的发展，这主要是因为三个要素：第一个是大数据，从年—年，互联网行业有了丰富的大数据积累，这给人工智能提供了一个充分的训练数据。第二个是大计算，在过去两年，基于的计算能力突飞猛进，给人工智能提供了一个非常好的加速器。第三个就是深度学习，在年到年，各种深度学习的框架、算法和模型纷纷涌现，改变了人工智能的派系格局和研究的方向。基于这三个要素，在过去两年期间，人工智能得到了迅猛的发展。

参考这三大要素，我们来对标一下腾讯云的产品。 首先腾讯云有，这是一款比较经典的产品，目前它的存储量已经达到了＋，这是非常可观的数字，大数据我们已经有了。其次我们有云服务器，这是我们今年刚刚推出的产品，在上面用户可以进行的申请，获得一个单机实例，并进行的计算，这样大计算我们也有了。那接下来就是深度学习平台了，我们推出了，通过它把和连接到一起，打通这两个产品，形成合力。

我们来看一下这个平台的架构。首先我们可以看到是接入到存储的，在上面有丰富的用户数据，包括各种各样的文本、图片、语音和视频。而在的底层，我们通过这个资源管理器，对底层的、、内存和硬盘进行统一化的管理。在上面是框架层，我们结合了三大框架，包括、和，基本可以满足大部分用户的需求。再上一层是算法层，目前我们集成了、、、这几类，在上线之后，我们会根据用户的反馈做进一步的丰富。再上面是模型层，用户对数据计算之后会产生一系列的模型，包括图形模型、语音模型、时序模型、视频模型和模型等等，这些我们会在里面进行一个统一的管理。整体基于这个平台，我们给上层的用户，包括其它中小企业提供更好的服务，包括图像识别、语音识别、精准推荐、实时风控等等。
有些用户可能会觉得，有了和之后，我们其实并不需要这样一个平台，用户也可以在上面玩深度学习，有一个平台反而会束手束脚。那到底会带来什么样的变化呢？接下来，我从个方面来介绍一下带来的变化，包括资源、框架、调度、调参、模型和预测这个方面。

首先我们来看一下资源，如果没有的话，它的资源申请是一个用户到实例的级别，在云服务器上，现在有两个类型，一个是，一个是，用户申请之后是要按月付费的，这是一个比较粗的力度。有了之后，我们现在是基于，它使用和的技术，能够对底层的资源进行优化和管理，这样分配资源的粒度就按照工程和卡数的关系来分配的，它的粒度更细，也更灵活，而且后续也可以做到按照运行时长来收费。

第二部分我们看看框架，在没有的情况下，从运行一个实例到跑出一个算法，如果是没有经验的人折腾一两天是很正常的事情。我们可以看到，在整个的过程，包括了系统准备、安装，安装、安装深度学习框架、对接存储，也就是需要把你的代码和存储做一个对接，当这些打通了之后，算法规程师才可以上传算法，然后启动一个脚本，把这个任务运行起来。这个过程中只有一个是红色的，只有这一步是算法工程师是擅长的，其它几步对工程能力弱的人来说都无疑是很难的，分分钟会可能卡住走不下去，而且这都是重复性的事情，用户做了，用户还要继续做，他们的工作不能被复用。

有了，这个事情就非常简单了，基于一个可视化的拖拽过程，用户只需要拖一个组件出来，然后设置一下参数，包括算法参数和资源参数，点一下运行就可以了，省去了大量重复的劳动，目前我们支持、和三个组件，算法方面我们也支持这样的方式，让用户做到即拖即用，释放一个算法工程师的生产力。

第三方面我们看一下调度，如果没有的话，用户可能写完了一个算法之后，调试好了，它需要定期运行。很传统的做法是用一个或者它的增强工具，这个工具是很灵活的，它有很复杂的配置语法和条件，配合一些奇怪的需要的脚本，其实它是能做很多事情的。但它的缺陷也是很明显的，就是它的可维护性是非常差的，需要人工大量的干预。为此我们在调度上有种驱动方式，除了正常的手工驱动之外，我们还支持定时驱动、重调驱动和参数驱动这三种方式，每种方式都有良好的调试界面可调节，用户可以自主设置三种驱动方式的并发度，让用户得到一个最大的便利性。

第四是调参。我们刚刚留意到有一种调度方式就是叫参数，这是为了深度学习的调参功能，在之前，用户需要写脚本，进行各种各样的参数调节，通过多种循环来进行参数的组合，然后传给具体的任务，达到调参的目的，但是这种方式其实是风险比较高的，对于写脚本的人来说，对他的能力有一定的高要求。而且一旦习惯了这种方式，很多人就会对平台有一个奇怪的要求，希望我们平台可以去支持一个组件，在这个组件里面写一个循环来调、或者，这是非常危险的方式，会让系统形成一些黑洞，这是不好的。为此增加了一个自动化的调参工具，它有个步骤，第一个是它能够进行多参数的循环组合，第二是它会预生成实例，因为参数形成组合之后，它会有很多的组合产生，这时候是预生成的，当系统的并发度满足条件的情况下，我们才会进行这个参数的真实替换，并且生成多实例并发运行。

这里我们举一个简单的例子，在机器学习中是非常简单的，类似于超参数调节的东西，它有两个参数，第一个是数字型的，第二个是字符串型的，提供这样的功能，经过这样调参之后，可以方便用户进行比较。这是目前的自动化调参，后续我们会针对深度学习的超参数调节进一步优化。

第五个模型。在之前，其实用户训练完了之后会有一个模型文件的生成，、和都有自己的格式。用户为了把这个模型进行一个同步和上线，其实有一种最常见的方法就是用，在不同的用户之间来，去，在这里面它没有版本的管理，同时它也依赖具体运维人员的靠谱程度，决定模型的命运，包括它如果覆盖错了，有可能一个效果好的模型，就会被效果差的模型覆盖掉，这时候效果是非常难以把控的。

为此我们推出了一个模型的概念，在中对模型进行了针对性的设计，我们把这个设计叫做小尾巴，目的就是把一个模型具像化，在一个深度学习算法里面，它的左边有一个小尾巴，里边有一个小沙瓶，在算法模型运行的过程中，这个小烧瓶不停地冒泡泡，代表它是在运行，在炼丹，这在机器学习中是一个非常常见的名词比喻。当算法结束之后，这个小烧瓶也就满了，代表机器学习过程完成了。这是一个把模型从抽象到具像的过程，当这个模型训练完之后，它有丰富的行为，我们可以把这个模型进行收藏、导出和分享。收藏模型之后，这个模型就会被收到个人模型这里，成为一个模块，它可以被拖拽出来到画布，而分享模型，你可以把它分享给你想要合作的同事，你的模型就会出现在他的共享模型里面，他也可以直接把它拖拽出来使用。

第个就是预测。其实就是一个训练和预测分离。我们知道深度学习里面，预测是一个非常重要的概念，模型训练完之后只是走了第一步，模型的使用，也就是预测才是更加重要的一个工作。目前我们这样一个模型拖拽出来之后，它会变成一个圆圆的一个大节点，可以对数据进行的预测推理，关于模型的在线预测功能，我们正在加紧上线中。

那综合以上点，我们来看一个预发环境的线上任务流：第一个是六边型数据节点，它会去检查路径上的数据在不在，并将路径传递给下一个节点作为输入；第二个是长方形的算法节点，带着一个模型训练的小尾巴，跑完之后，它的输出继续传给下一个节点；第三个是圆形的模型节点，它是之前训练好模型，用于对上游节点的数据，进行直接批量的预测，得到最终的结果；整体上看，这是一个多元素的任务流，有点复杂，但是相当灵活。门槛不高，用户熟悉了之后，很容易上手。

整体来看，是一个融合了深度学习的框架、算法、模型训练、模型推理和协作的一站式深度学习平台，在它上面可以完成一个深度学习的闭环，直接对之前存储在上的数据快速的进行挖掘，而得到的模型又能够快速的部署，降低人工智能的门槛。作者：胡俊彬

一、背景
互联网产业拥抱成为了当下的热潮：无人驾驶、医疗和智能推荐从实验室走出，融入到工程实业中；腾讯自主研发的王者荣耀等游戏给人们带去了快乐，“绝艺”更是获得了杯冠军；而和海量计算力分不开，绝艺每天的盘数计算量都在亿级，王者每天计算结果均在百，这些业务源源不断的计算力均来自腾讯架平弹性计算平台。该平台是根置于架平存储设备搭建而成，建设中最突出的问题是如何发现并调度异常计算点，本文从的角度来介绍弹性平台的解决之道。
二、
弹性平台中的设备都是在线业务与计算业务混部，尤其是计算，时间片可完全吃满，利用率持续，但利用率反映的是当前机器在某个时间点的运行情况，并不能用于度量程序指令的消耗，因此弹性平台需量化一个指标反映每条程序指令的执行耗时，技术便被引入了弹性平台。
的全称：   ，表示执行某个程序或者程序片段时每条指令所需的时钟周期数。从角度计算程序执行的周期，参考如下公式：
表示指令数，假设程序的指令数一定，程序耗费在上的周期数，取决于值，值越大，时钟周期数越多，反映到业务层的耗时也就越久。下图为计算测试的值与延时的趋势图存在噪点：

三、业务建模
弹性平台采用异常检测算法，使用值监控业务运行状况，运营中捕获异常点。检测算法：监控正常运行的各种程序指标数据，将数据计算一个模型，通过模型的正常范围衡量实时运行的值，超出范围，则为捕捉异常点。
模型定义
弹性平台复用的存储类母机上在线业务使用率特点：稳定的分布在某个小范围内，针对这种情况，构建模型如下：

上图中每个圆代表一簇值，由于映射到同一个使用率区间而聚成簇。对于每一簇值，计算其标准差，作为对应使用率的值所在的分布范围。的_计算所得值分布范围组成模型。检测阶段，对于每个_值对，首先根据_映射到模型中某个簇中，通过值比对标准差，判断该是否在对应的正常范围内。
模型运营模型训练的关键点：如何划分_区段，划分过粗，模型中值的区分度模糊；划分过细，模型中的值失去统计意义。当前的实现中，结合存储业务的特性，_按照每跨度划分，划分在目前看来有效。模型运营中简单的归纳为几个准则： 对于利用率稳定的，宜细分_；跨度大的，宜粗分_，且考虑同时映射到两个不同的簇。考虑最近的簇所代表的使用率，与当前使用率值的差距，如果差距过大基本直接判定为异常分布。现网运营中发现：利用率低，但存在值异常升高的情况，将其定义为噪点因素。而对于存储等稳定的设备，当利用率超过某个值架平存储是，可以拟合出一条线性回归直线，采用训练和检验打分矫正有效性。

四、调度
运行中的运算，持续的吃时间片，虽然采用了公平调度策略，但存储引擎与计算混部竞争，相比于单跑存储引擎，增加了调度和现场恢复等时延消耗。现网运营中还发现，计算火力全开时如下图，存储引擎偶尔会出现获取时间片不够的情况。综上，弹性平台监控存储引擎的标准差，当偏差超过限定的范围，即为异常计算点，平台执行调整或调度操作。

冲突检测
存储引擎的实时值与模型偏差差距可配置倍的标准差，平台计为一次异常，考虑到毛刺的收敛，连续出现多次或者某段时间内出现次，平台置为有效异常点并告警，根据异常的严重程度，平台做调整或者调度操作。
动态调整
监控到异常，平台优先调低计算的值，调整采用“乘性减 加性增”策略，将值降一半，限制容器的时间片分配，若一段时间内，监控未检测到异常，平台加性恢复容器值。
跨机调度
平台统计的异常调整次数超过次，或者值小于值，即可用的能力小于一核，平台执行调度替换操作，并冻结被调度母机一段时间，此时间段内不会创建计算容器。下图为某业务调度月图。

五、总结
平台基于构建的模型监控调度异常点，但由于在线业务的业务量、业务模型、网络环境的变化，会使模型可用性降低。模型需动态更新，可持续性的描述现网业务的运行状态。对此，弹性平台正在做异常告警数据的收集分析，并结合业务侧的时延不断的修正模型。

本文来自：腾讯架构师 公众号汇总国外社区相关文章，覆盖 等内容： 

   ‘  –     ’
链接：
点评： 微软产品组写的免费的微服务 的架构电子书，涵盖了开发微服务的各方面知识
      
链接： 
点评：  写的从转到 的系列文章第一篇
       
链接：
点评： 可以自定义代码风格配置，如何配置
      ’ 
链接：
点评：介绍    一篇短文
     
链接：
点评：安全是一项非常重要的工作，这个  扩展帮助你分析组件的漏洞
    
链接：
点评：微软继续更新  上面的，发布了   

     
链接：
点评：将旧版应用程序迁移到，使用的容器解决旧版本的应用是很不错的方法。
          
链接：
点评：  使新项目更容易入门，本文主要介绍  的基本模板。
     
链接：
点评：  中添加了对页面的支持。为开发人员提供了一种无需借助于整体应用架构就可开始构建应用的方法。鉴于页面是鉴于构建的，这种做法便于不断发展的应用随后转化为适当的解决方案。页面使用指令直接处理请求，无需相应的控制器。
     
链接：
点评：  中的新特性包括、新的 默认配置、简化的日志，还改进了  系统以便于更改认证提供方一命名实体识别
命名实体识别的主要任务就是从输入文本中把含有特定意义的词或者词组挑出来。命名实体根据其特点可以分为两大类，一类是可以根据构词法规则及上下文语境识别出来的，比如人名、地名、机构名；另外一类是可以穷举的垂直类实体，比如影视名，小说名，游戏名等。
命名实体识别是自然语言处理领域的基础任务，对很多应用都有十分大的作用，比如信息检索，文本摘要，信息抽取，文本聚类分类等。拿信息检索来举例，命名实体识别的结果可以在检索端生成完整索引，在端做整体下发，这样既可以提高检索效率，又可以降低检索噪音，提高相关性。    
二人名识别
 人名识别是命名实体识别中比较典型的一类问题，目前业界主要采用的方法是基于统计的。我们可以把人名识别问题看成是一个序列标注的问题，即根据观察序列预测最优隐含状态序列。
 我们把标记定义为：姓用字 ，名中字用字，名尾字用字，其他用字，那么下图的例子中，人名识别的问题可以转化为在已知输入文本“去看谭咏麟演出”，找到一条最大概率的标注序列，即“”。

求解序列标注的模型有很多，这里我们采用了条件随机场 主要是因为他可以任意选择特征，而不像有严格的独立性假设，并且是将所有特征进行全局归一化，最终得到全局最优解。
对于统计的方法来说，最主要的问题就是特征选择与语料获取的问题，下面就这两个问题展开介绍我们的做法。
三特征选择
我们的特征选择主要分为两大类，一类是基本特征：主要有基于构词法的特征，和基于上下文语言环境的特征。
去看陈奕迅演出               陈学友
去看张学友演出               陈德华
去看刘德华演出               张奕迅
去看谭咏麟演出               刘学友
构词法特征：上面加粗字体部分就是构词法的特征，我们从已有语料中知道这四个都是人名，于是这些人名用字的交叉组合也很有可能也是人名。
            去看邓紫棋演出

                            去看汪苏泷演出
上下文特征：还是上面的例子，黑色字体部分就可以看做是上下文特征，即在“去看演出”这样的上下文中，知道部分很大可能是人名。
另外一类主要的特征是泛化特征，之所以添加这类特征主要是因为我们实验发现，仅有基础特征模型的召回是不够的，需要一些泛化的东西来增加召回。
于是我们添加了一个是否为姓名常用字的特征，这个特征可以解决当该名字没有在语料中出现过的时候，也可以根据他的用字特点把新人名识别出来。
比如语料里面有张学友，也有刘德华， 但是没有张学华，于是华 ==   == 张学 = ， 但是 张，学 作为姓名常用字是有的，那么 华 ==   ==    ， 这样就增加了这个人名被识别到的概率。
四语料获取
有监督的学习方法最大的问题就是语料，如何能够获取到又多又准的语料是老大难的问题。现在大部分人都是利用已有标注的熟语料或者人工标注的方法去获取，人名日报是一份比较权威的熟语料，但是我们发现他量小，年份久远，与我们的应用场景网络语料的差距也很大。人工标注语料的成本是很大的，时间长，速度慢，数量小。于是我们想到了一种的语料自动获取方法。
的方法主要思想就是先用个基分类器，然后把他们进行加权融合产生一个最后的结果分类器，在这个基分类器中每个单个的分类器的识别率不一定很高但他们联合后的结果有很高的识别率这样便提高了该弱分类算法的识别率。
这里我们也是采用了类似的思想，将多种人名识别的结果做投票，认为越多的方法识别到的结果则越准确，我们把这种准确的语料补充到训练语料中去，优化我们的模型。这里我们使用了旧版人名识别结果、竞品人名识别结果、机器翻译的识别结果、及我们基础模型的识别结果来做投票。这四类中，旧版结果，竞品结果及我们的结果我想象都不需要再做介绍了，下面对利用机器翻译结果做人名识别简单介绍一下。
利用机器翻译的结果做人名识别的方法是这样的，我们发现中文人名翻译成英文之后 是有明显特征的，首先是两个大写开头的单词，另外这两个单词是中文字的拼音。那么我们利用中文串的中英翻译的结果及他的拼音串做比对，在满足着两个特征的时候，就是发现其中所包含的人名了。

五、结论
我们的模型经过多次特征及语料的调整，最终在开放集合上测试，最终准确率有，召回率有。下一步针对人名识别我们还会对语料做持续扩充，并且增加更精细化的特征，让识别效果进一步提升。

相关推荐 【 文智背后的奥秘 】系列篇：自动文本分类 【 文智背后的奥秘 】系列篇：海量数据抓取 【 文智背后的奥秘 】系列篇：分布式爬虫之背景
高效、完整、易用是的基本原则。前几篇文章分享了的基本用法和修复工具，接下来将更深入地聊聊在易用性上的思考和实践。
对于各类客户端数据库，似乎都绕不开拼接字符串这一步。即便在这样的的数据库中，在进行查询时，也依赖于字符串的语法：

别看小小的字符串拼接，带来的麻烦可不小：

代码冗余。为了拼接出匹配的语句，业务层往往要写许多胶水代码来字符串。这些代码冗长且没有什么“营养”。

难以查错。对于编译器而言，只是一个字符串。这就意味着即便你只写错了一个字母，也得在代码起来之后，通过或断点才能发现错误。倘若所在的代码文件依赖较多，即使改正一个敲错的字母，就得将整个工程重新编译一遍，简直是浪费生命。

注入。举一个简单的例子：



这是插入消息的。倘若对方发来这样的消息：  ，那么这个插入的就会被分成三段进行解析：

它会在插入一句空消息后，将表内的所有消息删除。若内存在这样的漏洞被坏人所用，后果不堪设想。
反注入的通常做法是，

利用的绑定参数。通过绑定参数避免字符串拼接。



对于不适用绑定参数的，则可以将单引号替换成双单引号，避免传入的单引号提前截断。


尽管反注入并不难，但要求业务开发都了解、并且在开发过程中时时刻刻都警惕着注入，是不现实的。
一旦错过了在框架层统一解决这些问题的机会，后面再通过代码规范、 等等人为的方式去管理，就难免会发生疏漏。
因此，的原则是，问题应当更早发现更早解决。

能在编译期发现的问题，就不要拖到运行时；

能在框架层解决的问题，就不要再让业务去分担。


基于这个原则，我开始进行对的接口的抽象。
的组合能力
思考的过程注定不会是一片坦途，我遇到的第一个挑战就是：
问题一：应该怎么抽象？
是千变万化的，它可以是一个很简单的查询，例如：

这个查询只是取出表中的所有元素。假设我们可以封装成接口：

但也可以是一个很复杂的查询，例如：

这个查询包含了条件、分组、分组过滤、排序、限制、聚合函数、子查询，多表查询。什么样的接口才能兼容这样的？
遇到这种两极分化的问题，我的思路通常是二八原则。即

封装常用操作，覆盖的使用场景。

暴露底层接口，适配剩余的特殊情况。


但更多的问题出现：
问题二：怎么定义常用操作？

对于微信常用的操作，是否也适用于所有开发者？

现在不使用的操作，以后是否会变成常用？


问题三：常用操作与常用操作的组合，是否仍属于常用操作？
查询某个字段的最大值或最小值，应该属于常用操作的：

假设可以封装为

但，是存在组合的能力的。同时查询最大值和最小值，是否仍属于常用操作？

若以此规则，继续封装为：

显然，“常用接口”的定义在不断地扩大，接口的复杂性也在增加。以后维护起来，就会疲于加新接口，并且没有边界。
问题四：特殊场景所暴露的底层接口，应该以什么形式存在？
若底层接口还是接受字符串参数的传入，那么前面所思考的一切都是徒劳。
语法规则
显然，基于上述问题，我需要一个理论基础，去支持我的封装是合理的，而不仅仅是堆砌接口。
于是，我找到造成千变万化组合的根源  语法规则：
例如，这是一个语句的语法规则：

按照图示箭头流向的语法规则解析传入的字符串。每个箭头都有不同的流向可选。
例如，后，可以直接接，也可以插入或者。
语法规则中的每个字段都有其对应涵义，其中

、、等等大写字母是，属于的保留字。

、``、等等小写字母是。可以再进一步地展开其构成的语法规则。


例如，在、 、、、后所跟的参数都是，它的展开如下：

可以看到，有很多种构成方式，例如：

：。可以进一步展开，它是纯粹的数值。

如数字、数字、字符串等都是，因此它们也是。


：    。两个通过二元操作符进行连接，其结果依然属于。

如。和都是，因此它们都是，通过二元操作符号连接，其结果仍然是一个。尽管看上去没有实质的意义，但它仍是正确的语法。



以刚才那个复杂的中的查询语句为例：

、   ，符合    的语法，因此其可以归并为
、=，符合   的语法，因此其可以归并为
、     ，符合      的语法，因此其可以归并为
、  ，符合   的语法，因此其可以归并为
、 ，符合   的语法，因此其可以归并为
最终，这么长的条件语句归并为了一个，符合语法规则中 的语法，因此是正确的条件语句。
也正是基于此，可以得出：只要按照的语法封装，就可以保留其组合的能力，就不会错过任何接口，落入疲于加接口的陷阱。
的具体做法是：

将固定的，封装为函数名，作为连接。

将可以展开的，封装为类，并在类内实现其不同的组合。


以语句为例：

在语法规则中，、等都接受作为参数。因此，不管多么复杂，也只接受的参数。而其组合的能力，则在类内实现。

通过构造函数和的偏特化模版，实现了从字符串和数字等进行初始化的效果。同时，通过运算符重载的特性，可以将的运算符无损地移植到过来，使得语法上也可以更接近于。
在对应函数里，再进行的字符串拼接即可。同时，所有传入的字符串都会在这一层预处理，以防注入。如：

基于这个抽象方式，就可以对复杂查询中的条件语句进行重写为：

首先通过创建对应数据库字段的映射，再转换为，调用对应封装的函数或运算符，即可完成字符串拼接操作。
这个抽象便是的语言集成查询的特性    。

更进一步，由于在接口层的封装，使得开发者可以直接通过的方式，拿到字段的映射。因此连上述的转换操作也可以省去，查询代码可以在一行代码内完成。
以下是在接口层和的支持下，对前面所提到的语句的代码示例：


总结
通过抽象语法规则，使得开发者可以告别字符串拼接的胶水代码。通过和接口层的结合，使得即便是很复杂的查询，也可以通过一行代码完成。并借助的代码提示和编译检查的特性，大大提升了开发效率。同时还内建了反注入的保护。
代码提示
编译时检查
虽然在实现上使用了特性和模版等，但在使用过程并不需要涉及。对于熟悉的开发，只需按照本能即可写出对应的语句。最终达到提高易用性的目的。同时，基于的实现也使得在性能可以期待。
后续我们还将分享在多线程管理上的思考。
相关推荐
微信移动端数据库组件系列：基础篇一微信移动端数据库组件系列：数据库修复三板斧二前言
多的项目就一定规范与优雅？文档是应放在中还是 中？越简洁越好，还是越详尽越好？写中文还是英文？此文一网打尽，解读存在你脑海里的开源误区。记不住可是要分分钟被小白教做人哦！
腾讯开源沙龙邀请到了多位腾讯开源项目作者，其中近日开源的微信生物认证平台与标准 作者，以一个开源“小白”的身份，分享自己在开源路上踩过的“坑”。
嘉宾介绍
，叶轩，来自腾讯微信事业群，主要负责腾讯开源项目 生物认证平台的开发、维护与运营。
项目介绍
  是腾讯于年开始制定的生物认证平台与标准，目前已经在微信指纹支付、微信公众号小程序指纹授权接口等场景使用，并得到了验证。接入 之后，开发者可以在不获取用户指纹图案的前提下，在设备上实现可信的指纹认证，获得与微信指纹支付一致的安全快捷认证体验。开源地址：
以下是演讲实录：
 刚开源不久，我就能够受邀参加腾讯开源的沙龙分享，感到十分的荣幸。因此，我以开源“小白”的身份，分享我在开源过程中吸取的教训和经验。作为小白，不得不说踩“坑”真的很多，所以教训是放在经验前面的。
克服开源恐惧
以前，在我看来，只是用来膜拜大神，“借鉴”大神代码，用到自己的项目当中。当然我也尝试把自己写的代码放在上，但并没有很好地管理它，只有个位数。我平时写代码的时候，没打算给别人看，只要自己能看懂就行，所以代码风格会比较粗放。我甚至还有“把当成”的黑历史。我的同事实在看不下去了，提醒我：“这样做是会被人笑话的。”
 开源不仅是我的个人想法，也是公司层面的考虑。一开始做开源的时候，我是相当恐惧的，毕竟是“小白”，没有经验。但当我逐渐想通了以下几点，就不再惧怕开源了：


开源是每个人都能做的事情无论大神还是小白，都可以参与到开源当中，开源对任何人都是没有门槛的。小白把自己的代码贡献出去，社区开发者阅读过后，发现问题，进行反馈。对小白来说，开源不一定能得到“膜拜”，但一定能通过反馈优化代码。
不过度在意数开源的本质是什么？比较谁的数更多？数少了是不是就很丢人？肯定不是。好的开源项目，数自然不会少。但如果舍本逐末，在项目质量都得不到保证的前提下就过度追求数，那才真的很丢人。社区也不会欢迎这样的项目。
给自己信心这里要感谢下我的——。从架构到代码，再到文档和演讲，都事无巨细的对我进行指导，有他撑腰，我不再怀疑自己，这是我给自己的信心，更是帮我建立的信心。
开源提倡相互学习，走出舒适区开源其实相互学习的过程，在微信开源、等项目时，团队发现开源对微信产品的稳定性和功能丰富起到了很好的反哺作用。知道了这点，“小白”自然也不会惧怕开源了，反而更希望拥抱开源。

项目发布
下面介绍的这些，是我开源前从来没想过的一些问题。这些错误“小白”会犯，甚至是数不少的开源项目作者也会犯一些错误。下面我们就一起来做几道选择和判断题。

文档是应放在中还是 中？我在整理代码的时候，发现中有以上都是代码，同事都“嘲笑”我说“就像写了个前端项目”。实际上，我只是把生成的文件都放在 里面，造成了这样的假象。后期，我把一些项目文档，例如，，放在里面，而更详细的介绍，例如原理、安全接入指南等放在  和  里面。这样可以保持的清爽。

是否选择合适的代码检查配置？每个编程语言都有不同的检查规范。代码检查配置，如的在编译期间就已经做好，如果检查不通过的话，编译也是不成功的。这是保证自己代码质量的一种方式，不至于闹太大的笑话。

中英文之间是否有空格？不同的字体有不同的显示，大部分字体中英文之间都不会去做空格处理。但实际上中英文之间有空格，整篇看起来在视觉上会更舒服，不至于太过散乱。

写中文还是英文？答案是：根据目标用户选择。英文的是一定要写的，但中文放在前面还是后面，要根据项目的目标用户决定。比如 主要面向国内用户，国外的手机并不支持，因此我们选择把中文放在前面。在中文最顶处留一个“  ”的链接，可直接引到英文的介绍。但像这些面向全球开发者或设计者的项目，最好中英文都有，实在精力有限也必须保留英文，而且要放在前面。

越简洁越好，还是越详尽越好？写得太多，会让大家对项目望而却步。最好的做法是，告诉别人你的项目是什么，如果需要详细介绍，可以做链接，引导用户前往或者自己的官网。还有做，很明确地告诉用户怎样最简单地去使用我们的项目，给用户传达“噢，原来用你的项目这么简单，我也可以试一下”的信息。正因为“试一试”，你的项目就可能成为别人使用的目标。千万别给用户一种“繁文缛节”的印象。

，你选择炫技还是易上手？如果你的示例代码写得过于复杂的话，同样会让开发者望而却步。用户会觉得“哇，你的项目太高大上，我用不了”“你的代码太复杂，肯定效果不好”，或者开发者会怀疑人生，“是不是我能力不够”。这样你会白白流失一部分用户。


工具推荐
我还是小白，推荐的工具可能也比较入门。我推荐两个，在项目发布初期，我使用到的，个人感觉比较有意思的工具，比如和。
大家都比较熟悉，用于生成项目徽章，相信大家都经常用到。是帮助我们写英文文档的利器。它可以在编辑的时候自动提醒你，或者当你写完很长的英文文档后，把它放在插件中，对拼写和语法进行检查，避免低级错误。

建造与维护
在项目的关注度方面，和自我都是很重要的过程。例如在知乎等比较大的社区推广你的项目，但前提在于，你对项目的质量有十足的信心。
其次，你需要及时解决。如果一直是状态，项目会给用户负面的形象，用户会产生“你的代码写得不错，但为什么一直不维护呢？是不是以后都不维护了？”的疑惑，从而不得不放弃。用户还会根据你的活动来确定项目的更新状态与频率。
最后，你需要时刻记住，尤其是小白更加要留意，和 是无法删除的。所以你对项目做了什么事情，在社区说了什么事情，一定要谨慎，世界上是没有后悔药的。

点击链接可直接访问的开源项目  哦 记得点个，给我们的开源“小白”一个鼓励吧关注“腾讯开源”公众号，其他嘉宾的开源经验分享语录陆续放送，敬请期待！李嘉昕，高级工程师，隶属腾讯架构平台部基础研发组团队，专注于云架构以及云上基因加速方案研发等工作，有将近年芯片和大型系统的设计经验。

行业背景
从云行业角度出发，根据艾瑞咨询统计的中国云服务市场数据，年中国云服务市场交易规模达亿元，相比去年，行业规模同比增长，继续保持高速增长水平。艾瑞预计，未来几年中，云服务市场仍将处于高速发展状态，保持以上的年复合增长率。云市场规模高速增长的同时，市场的竞争也日趋激烈。云计算时代通过售卖机器、计算和存储能力等商业模式很难承载未来企业高速发展的需求和突出云计算的核心竞争力。因此需要打造云计算的核心算力。
从行业角度出发，过去中小企业部署面临诸如硬件成本高、灵活性差、一次性采购投入大、研发周期长、投入和风险高等一系列问题。同时企业还会面临芯片更新换代带来的资源闲置问题。因此需要一种能够提供弹性的新架构。
 云是云计算的核心算力，同时也是一种新型的行业解决方案。首先，它是一种异构计算平台的体系结构，通过并行和流水等设计手段，提高计算性能、能效比和计算实时性，对应用进行硬件加速处理；另一方面，它通过云服务方式为用户提供高附加值的服务，让用户能聚焦于业务的整合和解决方案。在享有性能优势的同时省去了硬件开发板研发和测试等诸多环节，然而传统方式由于硬件开发门槛高，代价大，时间长让很多用户望而却步。
 云解决方案
近年来随着芯片工艺制程的不断发展，性能也在不断的提高，由于其具有超低延迟，高吞吐和快速响应的能力，在基因、大数据、人工智能、金融等领域得到广泛使用。云的未来是一个开放的生态系统。现阶段云已经形成“云行业”的发展思路，并已经在教育、基因等行业率先铺开。
首先，共建生态圈。与合作伙伴共同构建一个完善的生态圈，这包括几层含义。第一，让更多的合作伙伴享受云性能优越、开发便捷、计费灵活等红利，把业务迁移到云。第二，通过建立和壮大第三方的市场，让更多不同行业的以服务方式对外提供，让创新的思路和优秀的解决方案在市场发芽和绽放。第三，整合和规范云软硬件标准。传统开发，每家公司都有自己的一套硬件接口规范、软件驱动和上层接口，除此之外设计往往很难跨平台和器件直接使用，对于每次移植均需面临时间长和难度大等风险。统一标准将是对产业的一次划时代的整合和革新。
其次，“云教育”，通过不断丰富和完善云课堂以及线上实验室等多个主题，最终将云产品落地到各大高等院校的课程和科研当中，目前云已经成功应用在东南大学数字电路课程中使用。后续，还将推动在全国范围内多所高校的合作，让云服务走进校园和科研实验室，助力高校在教学和科研的改革，提升高校人才的整体竞争力。

图：云“生态系统”
 “云基因”则是近年基因行业的一个新趋势。随着对基因数据的高性能计算和存储需求激增，与此同时由于测序产生的数据量极为庞大，导致目前计算速度缓慢以及效率低下。个人类全基因组上几百数据即使在高端服务器运算时间也至少需要天左右时间。“云基因”解决方案通过对流程中的关键算法进行硬件加速来解决生物计算量的性能瓶颈。
表：云行业解决方案

 云通用框架
设计之初，云系统需要解决的一个重要问题就是通用性。通用性包括两层目标。第一，能够做到系统架构的通用。第二，能够做到用户接口的通用。最终让用户的设计“无感知”的运行在不同平台和不同类型的器件，减少移植的代价。
通用框架的重要性和必要性体现在以下两点：
第一，由于各家芯片厂商定义了不同的内部总线互联标准，这样会导致用户在平台上的设计不能直接移植到平台，需要重新针对目标平台修改现有的设计。与软件开发不同的是，重新修改总线接口意味着需要重新设计接口和调整用户的系统结构去适配新的总线带宽和时序模型，里面涉及到系统架构，逻辑设计、仿真和验证等一系列的工作。因为的设计是精确到时钟周期，每个时钟周期不同的模块并发的完成不同的操作，这就会涉及到从上层的系统层到底层的硬件时序的修改，这意味着用户需要花费大量时间和精力在跨平台移植上。
第二，由于各家芯片厂商有各自的底层硬件驱动，如果没有对外提供统一的，用户需要针对不同底层驱动维护不同的上层软件。从用户的角度来说，这种二次开发花费人力的同时并没有带来额外的附加值。
云系统包含两大区域，即静态区域和动态区域。静态区域虽然对于用户不可见，但是它却是整个系统架构的关键，构建起与上层侧的软件和侧动态区用户沟通桥梁，静态区域主要完成包括协议控制器、数据传输、内存控制器、中断处理、地址管理模块和总线管理和适配模块、动态加载模块和一些系统调试模块等。动态区域对应的则是用户的，这里采用业界通用的总线进行互联。如果采用私有的或者不通用的总线进行互联，用户往往需要对总线协议重新进行理解和开发，而且很难做到很好的系统可扩展性。采用统一的外部接口与用户程序交互，用户不需要把精力花在驱动集成、调试和封装等繁琐细节，只需要专注于高附加值的上层应用和服务开发上。

图：云系统框图
 云核心技术
 动态重加载
支持动态可重配体现了云平台的灵活性。它是指在切换设计中的某些部分时，其余部分还能继续保持工作，完全不需停机或者重启等操作，且几乎不影响成本与开发时间。用户能够即时更改对应的功能，无需全部重配置或重建链接，从而大幅提高了灵活性。在关键功能持续运行状态下，用户可以在已经部署好的系统中升级特性集、修复漏洞和演进到新标准的能力，极大地提升了系统的可升级性和可靠性。
具体应用场景主要包括两种。第一种是在不同用户间完成业务的切换，即用户的业务被替换成新用户的业务。第二种是同一用户业务功能进行升级或者问题修复等，例如用户需要增加一个新特性或者在实际运行中出现了，需要立即进行修复等。

图：动态可重配
 通用系统架构
目前主流芯片生产商有因特尔和赛灵思，这两家厂商均有自己的一套驱动和设计的标准，因此需要设计一个通用系统架构去适配不同厂商的接口，并灵活的进行扩展。这主要体现需要兼容不同的总线互联标准、不同的接口和时序等。
由于赛灵思一般采用的总线互联，而因特尔则是采用或者总线进行系统各功能模块互联，因此在静态区域需要增加一个总线适配模块，完成从或者到总线的转换，这样只要用户的满足总线，就可以方便的移植到不同平台中。
主要指的是厂商为了缩短用户的开发时间，提供给用户的不同类型功能模块。例如常见的等部件，不同的厂商往往在接口和时序存在比较大的差异，这对于用户的设计和集成是一件头疼的事情。为了最大限度减少用户的二次开发，采用一个统一的进行封装，提供一个通用的外部接口和遵循业界常用的时序标准，隐藏内部各家厂商的实现细节。
 支持开发
传统硬件开发采用硬件描述语言  ，简称：进行开发，它是电子系统硬件行为描述、结构描述、数据流描述的语言。利用这种语言，数字电路系统的设计可以从顶层到底层从抽象到具体逐层描述自己的设计思想，用一系列分层次的模块来表示极其复杂的数字系统，经过综合工具转换到门级电路网表。然而这要求设计人员必须对硬件架构，电路具体结构和工作原理有深入理论和实践知识，让很多软件开发者望而却步。
 增加高级系统语言的支持，让软件开发人员即便之前没有使用经验，也能受益于 平台的优势。集成设计环境不仅可提供编码模板和软件库，而且还能对各种开发目标进行编译、调试和特性分析。基于或者 开发能够轻松迁移到 上，同时还可在他们熟悉的工作流程中维护和复用、和代码。这样能让设计人员能够集中精力定义算法，而不是重点关注硬件设计的具体电路结构和时序。同时编译器将相同的高级描述转换为流水线，从而发挥了器件的优势。它能够大幅度提高性能，同时降低了功耗。此外，与使用的传统开发方法相比，使用进行软件、算法等开发能够缩短产品的开发时间，让更多的软件开发者能够使用进行开发。
使用描述来开发设计，与基于设计的传统方法相比，具有很多优势。开发软件可编程器件的流程一般包括进行构思、在等高级语言中对算法编程，然后使用自动编译器来建立指令流。面向的提供了设计环境，很容易在上实现应用。如下图所示。

图：高级语言的开发示例
 安全
云系统提供源代码加密保护，用户比特流加密保护以及认证等安全手段。
以赛灵思的为例子，所有的器件都有，这是一个 的二进制序列，在器件生产的时候烧死到芯片里面，每个芯片都是唯一的。这个序列，用户可以通过内部的逻辑直接读出。用户利用唯一性，采用自定义的加密算法来实现的保护。具体过程为：首先根据每个芯片唯一的，经过某种变换加密算法变成另外一串秘钥，同比特流文件一起存储在外部中。然后比特流文件加载后，硬件首先会去读取这，将用户加密电路生成的结果和存储在中的秘钥做比对，如果比对成功，芯片正常工作。如果比对不成功，则停止工作。

图：加密示意图
 其他特性
这些特性主要为了提高系统稳定性，可调试性和可观察性。
提供实时监测电路板以及功耗和温度等功能，在出现异常的情况下进行告警，必要时停止的工作。

提供 进行实验和调试。

提供 进行远程调试和问题定位。

提供各种版本、状态、时间、流量等计数器进行监控和差错处理。


 云“芯”趋势
随着数据中心和高性能计算等系统要处理的数据量不断攀升，需要的带宽不断提高。技术出现可以有效提高内存带宽。而新架构和布线技术出现则可以有效解决用户的时序收敛问题。除此之外，“”新架构的出现将会是未来异军突起的一股新流。
 技术
高速带宽存储器， 可以说是未来高速存储的发展风向标。它通过堆叠硅片互联技术   纵向堆叠了芯片，使用直通硅片过孔   和微焊球将其连接起来。在异构中集成，这种实现方式使得能够将存储器尽可能靠近管芯进行封装，从而缩短了走线长度，以最低功耗实现最大存储器带宽。在因特尔推出了 纳米 芯片集成的 封装预计可带来最高可达的内存带宽。

图：技术示意图
  
与传统的或者自适应逻辑模组中的寄存器完全不同，“超级寄存器”是与器件中每一个布线段相关联；所有功能模块的输入都有超级寄存器，例如、嵌入式存储器模块，以及数字信号处理模块。超级寄存器是可旁路的，支持设计工具在布局布线后自动选择最优寄存器位置，以提高内核性能。在互联上有超级寄存器意味着调整性能不需要其他的资源与传统的体系结构不同，不需要对设计布局布线进行额外的修改，不会增加复杂度。而且，在互联上内置超级寄存器有助于降低布线拥塞。下图显示包括新型超级寄存器的内部结构，互联布线资源与它相连接。在每一水平和垂直布线段的交叉点上，以小方块表示超级寄存器位置。

图：示意图
 “”新架构
英特尔在今年年底将推出系列产品 其中一个最大亮点就是把集成到处理器中，结合通用处理器及专用电路的优势，这样就能最大限度发挥软件灵活性以及定制硬件在性能上的优势。这种定制处理器以至强处理器为基础，首次在单一封装内集成了可编程阵列电路，插槽兼容标准的 处理器。它的性能很强悍，根据业界标准的加速测试，其性能提升了倍，而且接口延迟更低，一致性更好。

图： 新架构
 结语
云是云计算时代应运而生的“芯”力量，在人工智能、基因、大数据等众多领域拥有广阔的前景和业界成功的案例，伴随着近年来云技术和人工智能的热气， 将走进公众的视野。完善的生态圈和成熟的云架构和开发配套将吸引更多云客户愿意尝试这种“芯”技术带来的红利，铸造出扎根于行业的成功解决方案。轻量级的高性能的框架
取名于索尼动画形象音速小子，是腾讯会员 团队研发的一个轻量级的高性能的框架，专注于提升页面首屏加载速度，完美支持静态直出页面和动态直出页面，兼容离线包等方案。目前会员、购物、钱包、企鹅电竞等业务已经在使用，平均日均在亿以上，并且这个数字还在快速增长。
接入后首次打开可以在初始化的时候并行请求页面资源，并且具备边加载边渲染的能力。非首次打开时，可以快速加载上次打开动态缓存在本地的页面资源，然后动态刷新页面。腾讯手机通过框架使得页面首屏耗时平均低于以下。

轻量级的高性能的框架正式开源
官方开源地址：
来给一个吧！

使用前后对比 机器，环境
使用模式前使用模式后
功能
目前框架是市面上支持最为完善的框架，完美适用于静态直出页面和动态直出页面。具有以下几大特性：

快速通过中间层启动子线程并发拉取页面主资源和流式拦截的方式，支持内核边加载边渲染，弱化终端初始化过程耗时的影响，同时对页面进行动态缓存和增量更新，减少页面对网络数据传输的依赖，极速提升页面的加载速度。

省流量支持动态缓存页面内容，通过客户端和服务端遵守一定的格式规范，每次请求仅需要返回变动的数据块数据，大大减少响应数据传输。

良好的用户体验通过预推送以及动态缓存页面，先加载本地缓存页面，用户可以快速看到内容，即使在无网络场景下，依然能看到首屏内容，让页面的体验更加接近原生。

易用框架来自腾讯团队超过一年的优化提速总结，它是一整套解决方案，可以快速在和平台上接入使用，并且后台支持和平台一键部署，无须繁琐配置流程。


体验展翅翱翔的速度，别忘了来给一个吧！

转载自【腾讯开源】公众号，腾讯官方开源资讯，期待您的关注。作者：

原文：
    译
是建立在引擎的基础上。通过保持对该引擎最新发布版的更新，我们可以确保能够将   中的新特性能够及时的提供给开发者们，就像我们借助该引擎保持性能和稳定性的持续改进一样。
所有特性被分为  和 三个部分：

特性是认为已经稳定的特性，默认提供这些特性，而不需要额外的运行时标志位来开启。

特性，是团队认为已经几乎完成但还不够稳定的特性，需要用运行时标志位 _ 或者它的同义词 来开启这些特性。

 特性可以分别通过它们各自标志位来开启例如：_，但是强烈不建议使用它们，除非只是出于测试的目的。


有哪些特性在中是默认开启的不需要设置运行时标志位？

块级作用域中文参考：和命令

需开启严格模式

块级函数作用域需开启严格模式


需开启严格模式，中文参考：

集合类型中文参考：和数据结构







 中文参考：视图

函数中文参考：函数

二进制和八进制表示法中文参考：二进制和八进制表示法

对象字面量增强中文参考：对象的扩展

对象中文参考：对象

字符串的扩展中文参考：字符串的扩展

中文参考：

模版字符串中文参考：模版字符串

箭头函数中文参考：箭头函数

 

中文参考：

变量的解构赋值中文参考：变量的解构赋值


傻逼了，文章都还没写完， 就出来了！号称覆盖的特性！这不是打我的脸嘛！
哪些特性还是在未完成状态
新的特性正在不断地加入引擎。一般来说，虽然这些新特性未来在中落地的时间并不确定，但是我们依然可以抱有期待。你可以通过参数在列出各个发行版中的进行中的特性。但需要注意的是，这些特性并没有完成，并且有在未来被废弃的风险，所以你需要自己承担使用它们的风险。
  |   

我现有的生产环境中已经使用了标志位，我应该移除它吗
标志位在当前版本的中已经成了过去式。在这之后，我们可以使用它的同义词_。如前所述，有一些已经完成的特性，还没有被考虑为状态。如果你想安全地使用它们，特别是在生产环境中使用它们，最好等到和将它们设置为默认属性后，并且可以不再使用运行时标志位来开启它们。如果你坚持开启这个标志位，你需要做好未来升级后会破坏你目前代码的准备，因为有可能改变这些特性的语义，而使它们更加接近标准。
我怎么确定特定版本的  使用的是哪一个版本的引擎
提供了一个简单的方法来列举引擎的版本号：
  


原文链接：


相关推荐译        你可能不知道的 的变化英译导语：文章是  在 上最新发表的关于 论文的翻译版本，详尽的介绍了  设计背后的驱动和思考，以及如何在云上实现一个同时满足高并发、高吞吐量、高稳定性、高可用、高扩展的云数据库。

摘要
是服务的一部分，为业务提供关系型数据库服务。本文介绍了的系统架构以及背后设计上的考虑。我们认为，高吞吐量数据处理的核心问题已经从计算和存储移到了网络。为了解决这个问题，提出了一种新的关系型数据库架构，将日志的处理下沉到一个专门为定制的多租户可扩展的存储服务上。我们介绍了这种架构的一些优点，包括减少了网络流量，可以实现快速的故障恢复，无损的故障切换到备机，提供容错并且自愈的存储服务。接着，我们介绍了如何使用一种高效的异步方法，在大量的存储节点上实现可持久化状态的一致性，避免使用昂贵且沟通复杂的恢复协议。最后，基于在生产环境运维 个月的经验，我们分享了从客户上学习到一些心得：客户期望现代云服务中的数据库层是怎样的。
 引言
业务现在正加速向公有云迁移。这个产业级别的转变背后一个重要原因是，公有云能提供弹性的按需容量，企业将这部分费用作为经营性支出支付，而不用采用资本投入的模式。大量的业务需要支持的数据库，而提供与自建数据库等同甚至更高级的数据库服务，对支持这个长期转变的过程是至关重要的。
在现代的分布式云服务中，弹性和可扩展性可以通过将计算和存储解耦，并在多个节点上提供存储的副本来实现。这样的结构可以让我们更容易的实现一些操作，比如替换掉异常或者不可达的主机，添加副本，主机故障后切换到副本，增加或者降低一个数据库实例的容量。在这种环境下，传统数据库所面临的瓶颈已经发生了变化。由于操作已经分布到一个多租户平台上的多个数据节点的多个数据盘上，单个数据盘或者节点不再是热点。取而代之的是，系统的瓶颈移动到发起这些操作的数据库层，以及真正执行这些的存储层之间。除了基本的和带宽的瓶颈外，这里还存在着流量的放大效应，因为一个高性能的数据库必须并行的将数据写入到存储层。性能最低的节点、数据盘、网络路径决定着整体的响应时间。
尽管数据库中的很多操作存在着交叉，还是有许多场景同步操作是必须的。这就导致了暂停和上下文切换。其中一个场景是，一次由于数据库缓存池未命中引起的磁盘读，这个时候读取线程在磁盘读完成之前是不能继续执行的。一次缓存未命中，可能带来额外的惩罚：将一个脏页剔除并写入到数据盘，腾出位置给新的页。另外，一些后台处理，如建立或者刷脏页的操作，可以减少这种惩罚出现的几率，但是也会导致暂停、上下文切换以及资源竞争。
事务的提交是另外一种性能的干扰项，一个提交的阻塞会导致后面的事务提交的无法处理。用多阶段同步提交协议，如 ，处理提交是一项极具挑战性的工作。在高度扩展的分布系统中，系统中存在着持续的软硬故障，这些协议在这种场景下的支持不够好，并且有较大的处理时延，因为分布式系统中的节点可能分布在多个数据中心。
在本文中，我们介绍 ，一种通过将日志分散在高度分布云服务环境中，来解决上述问题的新型数据库服务。使用了创新的面向服务的系统架构，使用多租户可扩展的存储服务层，来抽象虚拟化的分段日志，并松散的与数据库实例层连接在一起。尽管每个数据库实例仍然包含一个传统数据库内核的大部分组件查询处理器，事务，锁， ，访问方式以及日志的管理，一些功能如日志记录，持久化存储，故障恢复，备份以及恢复数据都下沉交给存储层来做。
相对于传统的数据库，的系统架构有三个重要的优势。首先，通过将存储构建为一个跨数据中心容错且自愈的服务，我们可以保护数据库免遭系统性能抖动以及网络或者存储层的短期或者长期的故障的影响。我们注意到，一个可持久化的故障可以认为是系统长时间不可用的事件，而系统的不可用时间又可以建模为长时间的系统性能抖动。一个设计良好的系统可以无差别地处理这些问题。其次，通过只将日志写入存储层，我们可以将网络的降低一个数量级。一旦我们移除了这个瓶颈，我们可以更进一步地优化其他的竞争点，从而可以在原有的源码基础上有重大的提升。第三点，我们将一些很复杂且关键的功能备份，恢复，从原来是数据库引擎中的一次性的昂贵的操作，转变为均摊在一个大型分布式存储层上连续异步的操作。这样，我们可以实现近乎即时的不需要的故障恢复，以及廉价的不影响前台处理的备份操作。

在本文中，我们首先介绍三个主要贡献：
、如何在云规模上实现可持久性，如何设计一个多数派系统以应对关联故障第二节、如何将传统数据库最下面的一部分下沉到存储层来实现智能的存储第三节、如何在分布式存储中移除多阶段的同步，如何故障恢复以及建立第四节
我们接着在第五节展示如何将这三个想法结合起来设计的整体架构，紧接的第六节是我们的性能测试结果。第七节讲的是我们在这个过程中学习到的心得。最后，我们在第八节简要地介绍了相关的工作。第九节是结束语。
 大规模系统中的可持久性
数据库专门设计来满足一种协议，一旦数据写入，就可以被读出来。不过，不是所有的系统都是这样的。我们在这一节介绍我们的多数派模型以及对数据分段背后的理念，将这两者结合起来，如何既能实现可持久性、可用性、减少抖动，又能帮助我们解决大规模存储层的运维问题。
 复制以及关联故障
实例的生命周期与存储的生命周期不是强耦合的。实例可以挂掉，用户也可以将他们停掉，也可以根据负载升级或者降级实例。基于这些原因，将存储层和计算层分开是有实际意义的。
一旦分离了计算和存储，存储节点本身和数据盘也会故障挂掉。因而，他们必须以某种形式复制来应对故障。在大规模的云环境中，长期存在着低频的节点、数据盘、网络路径故障的背景噪音。每一个故障可能具有不同的持续时间和影响范围。举个例子，可能某一个节点会存在短暂的网络不可用的情况，由于重启引起的短暂的停服，或者也存在着一个数据盘、节点、机架、网络交换设备的叶子或者主干，甚至整个数据中心的永久性故障。
在一个复制系统的里面应对故障的一个方案是，使用基于多数派投票的协议。如果个副本每个都有一个投票权，那么一个读或者写操作必须分别获得读多数派票，以及写多数派票。为了保证一致性，这些多数派必须满足两个规则。首先，为了读到最新的数据，必须满足  。这个规则保证最近的一次写多数派和读多数派至少包含相同的一个节点，从而保证读到最新的数据。其次，为了避免写冲突，感知到最新的写入操作，写操作的涉及的副本数必须满足  。
通常的为了避免一个节点故障的方式是将数据复制三份，设置为，读多数派为=，写多数派为=。
但是我们认为设计为多数派是不够的。为了理解这是为什么，我们必须先理解中可用区的概念。一个可用区是一个地域的子集，与该区域的其他可用区通过低延时的链路连接。可用区之间对很多故障是隔离的，包括供电、网络、软件、洪灾等。将数据副本存放在不同的可用区中，可以保证通常的故障模式只会影响到一个副本。这也就意味着，用户只要将三个副本存放在不同的可用区中，就可以应对大规模的事件和小范围内个别的故障。
我们将设计为能容忍挂掉整个可用区以及一个额外的节点而不影响读取数据，挂掉一整个可用区而不影响写入数据。我们通过将数据复制为个副本，存放在个可用区中，每个可用区个。我们将大多数派模型中的值设为，这样写多数派为=，读多数派为=。通过这个模型，我们在挂掉一个可用区加一个节点仍然提供读服务，挂掉一个可用区仍然提供写服务。确保读多数派，能使我们添加一个副本就可以重建写多数派。
 分段存储
我们考虑一下的方案是否能提供足够的可持久性。为了在这个模型中保持足够的可持久性，必须保证两个不相关故障成对出现的概率平均故障间隔，要比平均修复时间小得多。如果成对故障出现的概率非常高，可能会导致一个故障，从而形成不了多数派。过了某个点之后，很难去进一步降低独立事件的平均故障时间。因而，我们将重点放在通过降低平均修复时间来降低成对故障的影响。我们采用的具体做法是，将数据库的总容量划分为固定大小的数据段，大小为。每个数据段有个副本，组成一个 ，分布在个中，每个 个。一个数据卷通过一组连接而成，物理上由一组挂载本地的主机作为一个存储节点，每个存储节点有多个存储单元。通过分配更多的，可以线性的扩展数据卷的容量，支持的最大数据卷一个副本容量为。
数据段是系统中最小的故障和恢复单元，自动的监控和修复故障是整个服务的一个部分。之所以选择，是因为在万兆网络条件下，恢复一个数据段只需要秒钟。在这种情况，如果要打破多数派，那么必须同时出现两个数据段同时故障加上一个故障，同时故障不包含之前两个数据段故障的独立事件。通过我们对故障率的观察，这种情况出现的概率足够低，即使是在我们现在为客户服务的数据库量级上。
 韧性的运维优势
一旦我们设计了一个能对长时间故障保持韧性的系统，那么这个系统就能轻松处理短时间的故障了。一个存储系统如果能应对一个的长时间故障，也能应对由于停电或者软件故障引起的短时间服务不可用。同理，如果能应对一个多数派中的成员数秒钟的失联，当然也能处理短时间的网络拥塞或者存储节点的高负载。
由于系统对故障有着高度的忍耐性，我们可以通过这一点来处理导致数据段不可用的运维操作。举个例子，热点管理可以变得很直观。我们可以直接将一个热点数据盘或者节点标记为故障，通过将数据迁移到冷存储节点上来迅速地修复多数派。而操作系统和安全漏洞修复对于存储节点来说，就是一个短时间的不可用事件。甚至，存储层的软件升级也可以类似的处理。我 每次处理一个，同时保证同一个内没有两个副本所在的节点同时被处理。基于这些，我们在存储服务上可以使用敏捷方法和快速部署。
 日志即数据库
在这一节，我们阐释了为什么传统的数据库使用分段冗余的存储系统，会引起不能承受的网络和同步阻塞等性能负担。接着，介绍采用的将日志处理交给存储服务层来做的方案，并且用实验数据说明了该方案能显著地降低网络。最后，介绍了存储服务中使用的一些技巧，用于将同步阻塞和不必要的写操作最小化。
 成倍放大的写负担
我们的模型中将数据整体容量分段，并将分段复制为个副本形成写多数派，给整个系统带来了韧性。不过，这个模型会让传统的数据库如对单次应用层的写入产生过多的真实操作，使得整个系统的性能无法接受。高被复制操作成倍的放大，产生的高包量让系统负担很重。同时，这些操作也产生一些同步点，导致数据管道阻塞、延时被放大。虽然链式复制及其变种可以减少网络开销，但是仍然受困于同步阻塞以及延时放大。
我们来审视一下写操作如何在传统的数据库中执行的。数据库系统如将数据页写到数据对象中如堆文件、树等，同时将日志写入日志。每一条日志包含着一个数据页的前镜像和后镜像的差异。将日志应用到前镜像上可以得到数据页的后镜像。

在实际中，一些其他的数据也必须被写入。比如，考虑一对同步镜像的实例，通过部署在不同的数据中心形成主从结构来获取高可用性。在中有一个实例，通过挂载带网络的存储。在中有一个从机，同样通过挂载带网络的存储。写入到主的数据会通过软件镜像同步到一个从上。
图展示了数据库引擎需要写入的不同类型的数据，包括日志，为支持任意时间回档归档到上的二进制日志，被修改的数据页，为了防止页损坏而双写的数据，还有元数据文件。图中同样描述了流的顺序。在步骤和中，会写入数据到主上，同时同步到在同一个中的从上，当两个都写完了才回复确认。接着，在步骤中，写入数据会使用块级别的软件镜像同步到从机上。最后，在步骤和中，数据会被写到从机上挂载的一对主从上。
上面描述的镜像模型在现实中是不可取的，不仅是因为数据是如何写入的，同时也因为有哪些数据被写入。首先，步骤、、是顺序且同步的。延时会因为同步写而累积。抖动会被放大，主要是因为即使是异步写，也必须等待最慢的一次操作，系统的性能由最坏的操作结果决定。从分布式系统的角度看，这个模型可以看作一个写多数派模型，在故障和最坏操作的性能限制条件下很脆弱。其实，由应用产生的用户操作可能导致多种不同的类型的写入，而实际上代表的是同样的信息—比如，为了防止存储基础设施中的页损坏而设计的双写操作。
 日志处理下沉到存储
当一个传统数据库修改一个数据页，会产生一个日志记录，并调用 将其应用在内存中的页的前镜像上产生页的后镜像。事务的提交要求首先必须写入日志，数据页的刷盘可能会滞后。

在中，需要通过网络传输的写数据只有日志。数据库层不会因为后台操作或者建立检查点而写入其他数据。取而代之的是， 被下推到了存储层，用来在后台或者按需产生数据页。诚然，从头开始按每页修改的完整路径来生成每个数据页是相当昂贵的操作。因而，我们在后台不断地使用日志来生成数据页，来避免每次都按需从头生成。注意到，后台的数据生成从正确性的角度来看完全是可选的：因为从存储引擎的角度出来，日志就是数据库，所有生成的数据页不过是日志的缓存。同时，不像建立检查点，只有有一连串修改记录的数据页需要重新生成。建立检查点，与完整日志链的有关，而的数据页生成只与这个页的日志链有关。
我们的方案即使是在由于复制引起的放大写的条件下，不仅减少了网络负载，而且还提供了可观的性能和可持久性。存储服务可以以并行独立任务的方式来扩展，并且不影响数据库引擎的吞吐量。举个例子，图展示了一个集群，包括一个主实例和多个副本，部署在多个不同的可用区中。在这个模型中，主实例将日志写入存储层，并将日志以及元数据的更新一起发送给副本实例。流根据目的地来将日志顺序打成，并将每个传给数据的个副本并持久化到数据盘上。数据库引擎只要收到个中的个回复就形成了一个写多数派，此时可认为这些日志文件被持久化了。每个数据副本使用这些日志将数据页的变更应用在他们的 中。
为了测试网络，我们用跑了一个写压力测试，的数据量写入两个不同配置的数据库：一个是之前介绍的部署在不同可用的区的同步镜像，另外一个是副本在不同的可用区。对两个数据库实例，在 实例上运行测试分钟。
我们的测试结果归纳在表中。在分钟的测试过程中，可以负载比镜像多倍的事务。每个事务所需的次比镜像少倍。我们通过将更少的数据通过网络写，使得我们可以更激进地复制数据获得持久性和可用性，可以并发的请求来最小化性能的抖动。

将日志处理放在存储层可以通过一系列手段来提升可用性，包括减少故障恢复时间，消除由于后台操作如建立检查点、数据页写入以及备份等引起的性能抖动。
我们来对比一下故障恢复。在传统的数据库中，系统必须从最近的一个检查点开始恢复，重放日志确保所有日志都被应用。在中，可持久化日志不断地、异步的应用在存储层，分布在各个数据节点上。如果数据页还没被生成，一个读请求可能会应用一些日志来生成数据页。这样一来，故障恢复的过程被分散在所有的正常的前台操作中。在数据库启动的时候不需要做任何事情。
 存储服务的设计点
存储服务的一个核心设计点是尽可能减少前台写操作的延时。我们将大部分的存储处理操作移到了后台。考虑到存储层从峰值到平均请求的巨大差异，我们有足够的时间在前台操作路径之外处理这些任务。我们也可以使用计算来换存储。举个例子，如果存储节点在忙着处理前台写请求的时候，没有必要运行来回收老的数据页版本，除非是数据盘快满了。在中，后台处理和前台处理是负相关的。这与传统的数据库不同，传统数据库后台的脏页刷盘和建立检查点与前台的负载是正相关的。在这样的系统中，如果后台积累了许多未处理的任务，那么必须扼制前台正常的处理流程才能防止后台任务越积累越多。由于在中数据段被分散在不同的存储节点上，一个存储节点卡死可以轻易被写多数派处理，卡死的存储节点会被看作一个慢节点不影响整体的流程。

我们来进一步看看存储节点的处理流程。如图所示，它包括以下的步骤：收到日志记录并将其加入内存的队列，持久化记录并确认写入，整理日志记录并确认日志中有哪些缺失，因为有些包可能丢了，与其他数据节点交互填补空缺，用日志记录生成新的数据页，不断的将数据页和日志持久化到，周期性的回收旧的版本，最后周期性的对数据页进行校验。
注意上面的步骤都是异步的，只有步骤和是在前台操作的路径中，可能会影响延时。
接《 ：云时代的数据库  中》一、          背景
在工作中我们经常须要构件一些基于的项目，例如内部测试平台、运维系统等。本篇主要介绍如何使用后端  前端的技术栈快速地搭建起一套项目的框架。
为什么使用和
是体系下最成熟的框架之一，由于语言的易用性和受众面广，框架也因其能够快速开发网站应用的特性成为了中小型网站开发框架首选。且具备的数据分析  、任务队列  、     、类似的等一众功能都使得用户在面对任何建站需求时都能够得心应手。
是当下很火的一个 库，它是以数据驱动和组件化的思想构建的。相比于，同样支持双向绑定、标签语法等特性，并提供了更加简洁、更易于理解的，使得我们能够快速地上手并使用。
本篇使用作为前端框架，代替本身较为孱弱的模板引擎，则作为服务端提供接口，使得前后端实现完全分离，更适合单页应用的开发构建。
二、          环境准备
安装环境：
系：
  
 
 
的模块等
推荐相关的模块包括都使用自带的安装器安装。命令：  即可安装最新版本的
系：
 
有关的模块包括我们都使用自带的包管理器安装
三、          构建项目
我们首先使用来搭建后端框架。
、    先在终端敲入命令：
  
目录结构：

、     进入项目根目录，创建一个：
   
目录结构：

、     在下的配置文件中，把默认的数据库换成我们的数据库：
 
 

 = {
     {
         
         
         
         
         
    }
}
并把加入到_列表里：
_ = 
    
    
    
    
    
    
     

、     在目录下的里我们简单写一个如下：
    
 ____  _

   

    
 
    _ = _=
    _ = __=

     ____
         _
只有两个字段，书名_和添加时间_。如果没有指定主键的话会自动新增一个自增作为主键
、     在目录下的里我们新增两个接口，一个是_返回所有的书籍列表通过返回能被前端识别的格式数据，二是_接受一个请求，往数据库里添加一条数据：
    
__
 _
     = {}
    
         = _=_
        
         = 
        _ = 
      
         = 
        _ = 

     

__
 _
     = {}
    
         = 
          =  
         = 
        _ = 
      
         = 
        _ = 

     
  可以看出，在的帮忙下，我们的接口实际上不需要自己去组织代码
、     在目录下，新增一个文件，把我们新增的两个接口添加到路由里：
     
 =     _ _     _ _     

我们还要把下的添加到下的中，才能完成路由：

    
   
   
 

 = 
     
     
     __=


在项目的根目录，输入命令：

   
  
查询数据库，看到表已经自动创建了：


在项目的根目录，输入命令：

  
启动服务，通过测试一下我们刚才写的两个接口：
_

_

四、          构建前端项目
、   先用安装脚手架工具是官方脚手架工具，能迅速帮你搭建起项目的框架：
    `   `
安装好后，在项目根目录下，新建一个前端工程目录：
        安装中把选上，我们须要它来做前端路由
进入目录，运行命令：
      安装所须要的依赖
现在我们可以看到整个文件目录结构是这样的：
 
 、    在目录下包含入口文件，入口组件等。后缀为的文件是框架定义的单文件组件，其中标签中的内容可以理解为是类的页面结构内容，标签中的是的方法、数据方面的内容，而则是样式方面的内容：

、      我们在文件夹下新建一个名为的组件，通过调用之前在上写好的，实现添加书籍和展示书籍信息的功能。在样式组件上我们使用了饿了么团队推出的，这是一套专门匹配框架的功能样式组件。由于组件的  编码涉及到了很多、、的知识，并不是本文的重点，因此在此只贴出部分代码：

、      在目录的中，我们把新建的组件，配置到路由中：

、     如果发现列表抓取不到数据，可能是出现了跨域问题，打开浏览器确认：

这时候我们须要在层注入，用的第三方包来解决跨域问题：
         
 修改：
 = 
    
    
    
    
    
    
    
    


___ = 
  注意中间件的添加顺序
、      在前端工程目录下，输入  启动自带的服务器，浏览器会自动打开， 我们能看到页面：

尝试新增书籍，新增的书籍信息会实时反映到页面的列表中，这得益于的数据双向绑定特性。

在前端工程目录下，输入  ，如果项目没有错误的话，就能够看到所有的组件、、图片等都被自动打包到目录下了：


五、          整合和
目前我们已经分别完成了后端和前端工程的创建和编写，但实际上它们是运行在各自的服务器上，和我们的要求是不一致的。因此我们须要把的指向我们刚才生成的前端文件即可。
  、      找到目录的，使用通用视图创建最简单的模板控制器，访问 『』时直接返回 
 = 
     
     
     __=

、      上一步使用了的模板系统，所以需要配置一下模板使知道从哪里找到。在目录的下：
 = 
    {
         
         
        _ 
         {
            _ 
                _
                _
                _
                _
            
        }
    }

 、     我们还需要配置一下静态文件的搜索路径。同样是目录的下：
   
_ = 
    _ 

、      配置完成，我们在目录下输入命令  ，就能够看到我们的前端页面在浏览器上展现：

注意服务的端口已经是服务的而不是服务的了
六、          部署
由于的跨平台特性，因此理论上只要在服务器上安装好所有的依赖，直接把项目目录拷贝到服务器上即可运行。这里只提一点：如果为项目配置了作为反向代理，那么要在中配置所有的静态文件都指向项目中配置的静态文件，在中可配置路径：
     
 

_ = 
七、          其他
实例项目的原码都可以在该路径下载：
__问题描述：
在环境下 及以上版本中，绑定了辅助后，主动外访时有可能不再走主。
导致后果：往往表现为主机绑了辅助后主动外访不通，但外网被访问时是通的。

因为外网经常是绑在主内网上，如果当对外发送流量不再选择走主内网，而是选择没有绑外网的辅助的时候，网络当然不通。

这与我们的期望不符，我们往往认为网络流量会默认从主出去。
示例案例：
 ：  绑定了外网：
 ： 后来绑上去的
： 
问题原因
微软官方镜像的选择策略发生了变化： 之前的版本，会默认从第一个到网卡的出去。
而  及其之后的版本包括 、 、 、 等，会遵循以下方式：

 ：    

 ：    

 ：    

 ：          

 ：    

 ：          

 ：          

            


根据规则，如果主与下一跳的  前缀匹配 短于辅助与下一跳的   ，那辅助的优先级会高于主， 就会由辅助发送。
本示例案例中，辅助与下一条即网关的   更长，因此流量不再走主。

规避方法
使用标志位用  命令添加时，把标为。
设置方法
 

                 =

 

             =

本示例案例中，对应的命令为：
     以太网  =接    《十个书写  的最佳实践上》
 对你的  进行黑盒测试
测试你的 最好的方法之一就是把它们当成黑盒对待。
黑盒测试是一种测试方法，通过这种方法无需知道应用内在的结构或者工作机制，就可以检测到其功能。因此依赖不会被或者，但是系统会被作为一个整体来测试。

译者注： 和  都是测试的方法

有个可以帮你进行  进行黑盒测试的模块叫做。
一个简单的测试用例，其使用测试运行器检查一个用户是否被返回，可以这么用：
  = 

   {  
      {
     更新的也可以使用
     
      
       
       {
         
          
      } 
  }
}
你可能会问：数据是怎么被构建到服务 的数据库里的？
通常，覆盖尽量多系统状态的方式来书写你测试代码是个很好的方法。然而，有时候你会发现自己处于一个需要准确知道系统状态的情况，因此，你可以果断点，同时达到更高的测试覆盖率。
因此基于你的需要，你可以使用下面的任何一种方法来把数据库用测试数据填充：

在已知产品数据集上运行你的黑盒测试方案

在测试用例运行之前使用构造的数据填充数据库


当然，黑盒测试并不意味着你不需要做单元测试，你依旧必须给你的写单元测试
 做基于的无状态认证
由于你的 必须是无状态的，你的认证层也是。从这点来看，   是完美的。
由三个部分组成：

，包含的类型和散列算法

，包含声明

 不对加密，直接签名就对了！


给你的应用添加基于的认证是很简单的：
  =   
  = 

  = 

{  
    
}

  
 {  
           
   = {
     
  }
}
之后，末端随着被保护。为了使用受保护的末端，你需要在头区域里提供。
     
你可能注意到一件事，就是模块不依赖任何数据库层。事实就是这样，因为所有的 可以自我验证，并且它们也包含存留时间值。
同样的，你要一直确保所有的末端只能被使用了的安全连接通过。
使用条件请求
条件请求是因特定头而异的请求。你可以把这些头想作先决条件：如果他们被碰到，请求会以一种不同的方式执行。
这些头会试着检查存储在服务器上资源的版本是否和同样资源的给定版本一致。由于这个原因，这些头可以是：

上次修改的

或者一个每个版本都不同的实体标签


这些头是：

表明资源被上次修改的时间

表明实体标签

 和头一起用

 和头一起用


让我们一起看下一个例子！
下面的客户端没有任何资源的先前版本，因此当资源被发送时无论还是都没有被应用。然后，服务器带着 和正确地返回设置。

来自条件请求文档
一旦客户端尝试请求同样的资源，其可以设置和的头，因为它现在已经有了一个版本。如果响应是一样的，服务器会直接以   状态码响应，同时也不会再次发送资源。

来自条件请求文档
 接收率限制
接受率被用来控制特定消费者可以发送给的请求数。
为了告知你的用户他们还剩余多少请求，设置如下的头部 

，在给定的时间间隔内允许的请求数

， 同一时间间隔内保持的请求数

， 接受率被被重置时的时间


大部分框架自带或者通过插件支持这一功能。例如，如果你在使用，有个叫的包。
需要注意的是，基于不同的提供者，时间窗口也会有所不同——例如，用的是一个小时，而用的是分钟。
 创建合适的文档
你书写，这样其他人就可以使用它们，并从中收益。给你的  提供文档是很重要的。
下面的开源项目可以帮你给你的创建文档：

  




此外，如果你想使用托管产品，可以试试。
 不要错过的未来
过去那几年里，调用的两个主要查询语言——也就是的和的。但是我们为什么还需要它们呢？
看看下面这个资源请求：
===
这很容易失控——正如你想一直为你的模型获得同样响应格式一样。这就是和发挥所长的地方。
关于
是一个给用的查询语言，其同样也是一个使用你的现存数据填充这些查询的运行环境。提供一个你的数据的完整和易懂的描述，给予客户端能力以获取其所需要的并且绝不多做，随着时间推移让扩展更加容易，并且提供强有力的开发工具。—— 这里可以了解更多
关于
是推动 的创新性数据平台。允许你在服务器端把你所有的后端数据模拟成单个的虚拟对象。在客户端上，你使用熟悉的操作像和来和远程的对象一起工作。如果你了解你的数据，那么你也会了解你的。——在这里了解跟多
令人惊讶的 ，激发你的灵感
如果你正准备开始开发  或者给一个旧的项目开发新版本，我们在这里精心挑选了四个值得 的真实案例

 

 

 

 


我希望现在你对怎么使用书写有一个更好的认知。如果你错过了什么，请在评论里面让我知道。背景
最近用做爬虫，爬取的数据需要入到数据库，本来都是一些小的爬虫程序，也没有用到任何框架，但是等数据入库的时候各种拼接语句，有时候文本中包含“，会直接报错，烦不胜烦，考虑是否有简单的数据库的框架，方便数据库这块的操作，考虑到之前接触过一些的知识，就想从这方面入手。
简介
是一个由写成开源的的应用框架，采用的设计模式。框架的核心包括：一个面向对象的映射器，用作数据模型以类的形式定义和关系性数据库间的媒介；一个基于正则表达式的分发器；一个视图系统，用于处理请求；以及一个模板系统。显然这里我们只需要的对象映射器帮助操作数据库。
单独接入数据库模块
我使用的 是，使用过 的同学一定会对这个的界面很熟悉，因为他们都是开发的一些列的一员，界面风格十分相似，满满都是熟悉的味道。
安装
言归正传，要接入，首先要安装库，在中安装第三方库如下
安装还是很方便的。
在项目中使用
前面说了我们只需要使用的对象映射器操作数据库，并不会使用到其他组建，标准的会有个，等配置，这里其实都不需要。根据我们的需求，其实我们只需要启动一个的环境，然后传入数据库配置，对应的实体映射关系即可。而其实是有这些方法实现我们的需求的。
     所以换不多说，先上代码首先是的内容
 
    
       上午
    
相关的类
   
   
 

外部调用时，需要设置相关环境变量

设置_信息
_ = 
    
     
     
     
     
     
     

设置数据库信息
 = {
     {
            的
                                 数据库名称
                                  数据库用户名
                            数据库密码
                             主机地址
                                  数据库端口号
    }
}
给配置相关信息
= _=_
启动


构造的对象
 _
     = _= _= _=
    _ = _=_

     ____
         _

     
        _ = _
先给出文档中相关内容以供参考
说明
首先从讲起，文档里面说的很清楚：
    __

         __      ’         ’              

      ’      

_ ¶


   

=
       ’                           
大致意思是如果只是临时想使用一下部分功能而不像启动所有的__，可以通过配置，使用可以配置中任意的参数参数名必须大写。至于的参数，可以参考说明，这里只给出上面使用到的两个参数的说明
_
可以看出_类型是数组，数组内容相应的路径，表示在希望使用的或，
_

   

                      

     
    

的类型是一个，字典中是相关的数据库配置，配置需要使用以下第二种


 {}  

                                 

                

                  

 = {
     {
         
         
    }
}
                                  

 = {
     {
         
         
         
         
         
         
    }
}
说明
文档中说的很清楚，如果是启动或，会帮你自动启动环境，但是如果是想独立启动环境，则需要使用
     “”  

 ’     “” –                       – ’    ’      

 ’   __    ’           ’    

 
   
   _

_=_ =


               
   
                           
说明
就比较简单，就是需要将与数据库中表映射的对象，继承的，环境启动后会自动映射到数据库中对应的表。使用起来也很简单
   _
 
     
     = _
     
只需要上面几行代码，就可以读取_表中所有的数据，没有语句的拼接，也没有数据的遍历，是不是很？
总结
使用过程中了很多，虽然有很多都给出了类似的解决方案，但是并没有说明各种设置的意义，最有帮助的还是官方文档，解决了问题也了解了原理，官方文档才是王道，所以抓紧时间找个小伙伴一起学习外语吧！腾讯 计算机视觉中心人脸团队是年月底开始组建和开展工作，我们以研发业界领先的算法为目标驱动，逐步克服人手不足、训练数据不足等困难，不断夯实基础，做既有原创性又能落地应用的国际前沿研究。在上一期腾讯  计算机视觉中心人脸团队近期成果介绍中已经介绍了我们团队的一些研究成果，近期，我们团队有一些新的成果再和大家进一步分享。
 人脸研究进展
人脸研究的两大关键任务是人脸检测与人脸识别。在上一期中，我们主要介绍了我们团队在人脸检测的两个国际权威评测平台 和上的研究成果。近期，我们团队在人脸识别的关键任务上也取得突破，在人脸识别的国际权威评测平台 中取得了国际领先的成果。同时，在人脸检测中，我们进一步提高了检测精度，重新刷新了记录。以下具体介绍。
 人脸识别
人脸识别的国际权威评测平台是由美国华盛顿大学  发布并维护的一个著名的人脸评测平台。它以百万规模人脸注册情况下的和比对作为最重要的性能评定指标。一共有两个： 可以使用任何外部的人脸数据来训练参赛模型，而 严格限定使用官方提供的训练集来训练模型，因此 上的评测结果更能体现参赛的人脸算法的性能。每个都有两个测试集常规识别测试集和跨年龄识别测试集。如表到表所示，我们原创的人脸算法在常规识别测试集和跨年龄识别测试集这两项任务中的所有评测指标：识别准确率  和验证准确率   均取得第一，超过、等对手。该结果已于月底发表在的官网上_ 。 
表   的常规识别测试集的识别准确率结果对比

表   的常规识别测试集的验证准确率结果对比

表   的跨年龄测试集的识别准确率结果对比

表   的跨年龄测试集的验证准确率结果对比

 人脸检测
人脸检测是人脸识别的前提和基础，在做人脸识别之前，需要先做人脸检测以检测出目标人脸的存在和精准位置信息。正如上一期介绍中所述，我们团队之前已经在人脸检测中取得佳绩，近期我们进一步改进了方法，在人脸检测的两大国际权威评测平台 和上取得了更好的结果。
在人脸检测国际权威评测平台 这也是目前国际上难度最大的人脸检测的评测平台上，如图所示，我们的最新方法 在 的验证集和测试集的所有三个子集   上都取得国际领先的结果，超过了美国大学、马里兰大学等人脸研究团队。这个结果新近发布于 官网上_ 。相关技术文档                    也已发布于网站，链接请见  。图是一些人脸检测结果的样例，对于很多极具挑战性的人脸，我们的人脸检测模型也能很好的检测出来。  


图人脸检测国际权威评测平台 上的结果对比。第一行的三张图代表验证集的三个子集   的结果对比，第二行的三张图代表测试集的三个子集   的结果对比。我们的方法 在验证集和测试集的所有三个子集中都领先竞争对手。 


图人脸检测国际权威评测平台 上的人脸检测样例绿框代表我们检测到的人脸，红框代表官方标注的人脸
  在人脸检测另一个国际权威评测平台上，我们也重新刷新了纪录，我们的最新方法 在评测的关键指标：离散得分曲线中，误检数时的召回率达到。这个结果大幅超过了我们之前的结果，进一步刷新了这个记录。更多细节可以参阅我们的技术报告： 和官方网站  。 
 研究进展
在上一期中我们介绍了我们团队在的国际权威评测平台      竞赛里所取得的佳绩，我们当时在的互联网图片 数据集上的两个任务文本定位和单词识别上都取得国际领先。最近，我们在竞赛的另一个核心数据集：对焦自然场景图片   ，也取得突破。以下详细介绍。
  对焦自然场景图片里的文本定位任务比赛     
   是用相机对准自然场景存在的文本拍摄得到的图像，这些文本包括海报、交通标志、告示牌、橱窗、店铺名称、衣服、铭牌等物体上的字符，文本定位任务就是确定图像中文本行的准确边界。该任务的训练集幅，测试集幅。由于自然场景中的文本定位和识别是领域中的一个重要的研究方向，有一些研究机构和个人公布了自己收集和标注的数据集，通过搜集这些公开的数据集获得图像幅，作为补充训练集。在训练网络时，对训练集用了多种手段做了数据增强，实际训练集扩充到幅左右。我们的最新模型在该任务上取得了第一名的佳绩，如下图所示。 

图 对焦自然场景图片里的文本定位任务比赛排名=== 
 部分检测结果如下图所示，全部的检测结果可在网站上查询，网址：===_===



　
　

















图 部分文本检测结果
 对焦自然场景图片里的单词识别任务比赛 ，    
   单词识别任务需要在文本图像中抠出单词区域，四个边界向外扩展个像素点，构成数据集，训练集幅，测试集幅。在训练网络时，使用外部数据集约万幅。采用提取图像特征，采用学习序列关系，并加入机制以改善的性能，进行识别。我们的最新模型在该任务上取得了第一名的佳绩，如下图所示。

图 对焦自然场景图片里的单词识别任务比赛排名=== 
 部分单词如下图所示，这些单词在字体、尺寸、排列间距、倾斜、阴影、背景、模糊等方面都有变化，我们一方面增强网络结构以适应这些变化，另一方面有针对性的生成大量的合成样本用于训练网络，最终克服了这些不利因素，正确识别出单词。

图 部分单词图像
 互联网场景图片里的文本定位任务比赛 ，   
近期，我们改进了用于互联网图片文本检测的网络结构，再一次刷新了互联网场景图片里的文本定位任务比赛上的记录，如下图所示。全部的检测结果可在网站上查询，网址：===_===

图 互联网图片文本检测任务上的排名=== 
互联网场景图片里的单词识别任务比赛 ，   
我们改进了用于互联网图片单词识别的网络结构，加入机制来改善的性能，再一次刷新了互联网场景图片里的单词识别任务比赛上的记录，如下图所示。

图 互联网图片单词识别任务上的排名=== 
 项目合作
人脸与是计算机视觉领域应用非常广泛，受到工业界和学术界高度关注的一个研究领域和方向，不仅难度很大而且竞争非常激烈。因此我们团队研发的原创算法不仅需要在各种国际权威评测平台里验证算法的领先性，而且需要与业务部门开展项目合作，在产品侧落地应用以找出不足、补齐短板、提升性能，并利用海量业务数据不断迭代更新模型，以更好、更专业地服务伙伴部门。
就项目合作而言，我们人脸团队与信安团队以及互联网合作事业部政企项目组都有着深入、密切的合作。由于团队人手紧张，近期我们主要聚焦于互联网合作事业部政企项目组的合作项目中。政企项目组旨在利用互联网技术，简化人们生活中的各种办事流程，让数据多跑路，百姓少跑腿，方便广大人民群众办事。其中，基于上传证件的身份认证是多项业务的基石。这种合作是双赢的，一方面，我们发挥自身的技术优势，提供稳定、准确、快速的证件人脸识别、人脸核对、文本识别等底层功能，政企项目组的同事利用这些功能展开上层业务逻辑，大幅提高服务效率并减少运营成本；另一方面，政企项目组的同事及时反馈合适的样本数据和失败案例给我们，我们则根据这些反馈改进算法和模型，并最终促进自身技术能力的提高。导语 随着近几年文本信息的爆发式增长，人们每天能接触到海量的文本信息，如新闻、博客、聊天、报告、论文、微博等。从大量文本信息中提取重要的内容，已成为我们的一个迫切需求，而自动文本摘要  则提供了一个高效的解决方案。

介绍
随着近几年文本信息的爆发式增长，人们每天能接触到海量的文本信息，如新闻、博客、聊天、报告、论文、微博等。从大量文本信息中提取重要的内容，已成为我们的一个迫切需求，而自动文本摘要  则提供了一个高效的解决方案。
根据的定义，摘要是“一段从一份或多份文本中提取出来的文字，它包含了原文本中的重要信息，其长度不超过或远少于原文本的一半”。自动文本摘要旨在通过机器自动输出简洁、流畅、保留关键信息的摘要。
自动文本摘要有非常多的应用场景，如自动报告生成、新闻标题生成、搜索结果预览等。此外，自动文本摘要也可以为下游任务提供支持。
尽管对自动文本摘要有庞大的需求，这个领域的发展却比较缓慢。对计算机而言，生成摘要是一件很有挑战性的任务。从一份或多份文本生成一份合格摘要，要求计算机在阅读原文本后理解其内容，并根据轻重缓急对内容进行取舍，裁剪和拼接内容，最后生成流畅的短文本。因此，自动文本摘要需要依靠自然语言处理理解的相关理论，是近几年来的重要研究方向之一。
自动文本摘要通常可分为两类，分别是抽取式和生成式。抽取式摘要判断原文本中重要的句子，抽取这些句子成为一篇摘要。而生成式方法则应用先进的自然语言处理的算法，通过转述、同义替换、句子缩写等技术，生成更凝练简洁的摘要。比起抽取式，生成式更接近人进行摘要的过程。历史上，抽取式的效果通常优于生成式。伴随深度神经网络的兴起和研究，基于神经网络的生成式文本摘要得到快速发展，并取得了不错的成绩。
本文主要介绍基于深度神经网络的生成式自动文本摘要，着重讨论典型的摘要模型，并介绍如何评价自动生成的摘要。对抽取式和不基于深度神经网络的生成式自动文本摘要感兴趣的同学可以参考。
生成式文本摘要
生成式文本摘要以一种更接近于人的方式生成摘要，这就要求生成式模型有更强的表征、理解、生成文本的能力。传统方法很难实现这些能力，而近几年来快速发展的深度神经网络因其强大的表征能力，提供了更多的可能性，在图像分类、机器翻译等领域不断推进机器智能的极限。借助深度神经网络，生成式自动文本摘要也有了令人瞩目的发展，不少生成式神经网络模型   在测试集上已经超越了最好的抽取式模型。这部分文章主要介绍生成式神经网络模型的基本结构及最新成果。
基本模型结构
生成式神经网络模型的基本结构主要由编码器和解码器组成，编码和解码都由神经网络实现。

编码器负责将输入的原文本编码成一个向量，该向量是原文本的一个表征，包含了文本背景。而解码器负责从这个向量提取重要信息、加工剪辑，生成文本摘要。这套架构被称作以下简称，被广泛应用于存在输入序列和输出序列的场景，比如机器翻译一种语言序列到另一种语言序列、 图片像素序列到语言序列、对话机器人如问题到回答等。
架构中的编码器和解码器通常由递归神经网络或卷积神经网络实现。
基于递归神经网络的模型
被称为递归神经网络，是因为它的输出不仅依赖于输入，还依赖上一时刻输出。

如上图所示，时刻的输出不仅依赖时刻的输入，还依赖时刻的输出，而的输出又依赖的输入和输出，如此递归，时序上的依赖使在理论上能在某时刻输出时，考虑到所有过去时刻的输入信息，特别适合时序数据，如文本、语音、金融数据等。因此，基于实现架构处理文本任务是一个自然的想法。
典型的基于的架构如下图所示：

图中展示的是一个用于自动回复邮件的模型，它的编码器和解码器分别由四层的变种组成。图中的向量 编码了输入文本信息   ，解码器获得这个向量依次解码生成目标文本  。上述模型也可以自然地用于自动文本摘要任务，这时的输入为原文本如新闻，输出为摘要如新闻标题。
目前最好的基于的生成式文本摘要模型之一来自，在基本的模型架构上，使用了注意力机制 和强化学习 。这个模型将在下文中详细介绍。
基于卷积神经网络的模型同样也可以通过实现。不同于递归神经网络可以直观地应用到时序数据，最初只被用于图像任务。

通过卷积核上图的和从图像中提取特征，间隔地对特征作用 ，得到不同阶层的、由简单到复杂的特征，如线、面、复杂图形模式等，如下图所示。

的优势是能提取出的特征，并且能并行高效地进行卷积操作，那么是否能将应用到文本任务中呢？原生的字符串文本并不能提供这种可能性，然而，一旦将文本表现成分布式向量  ，我们就可以用一个实数矩阵向量表示一句话一个词。这样的分布式向量使我们能够在文本任务中应用。

如上图所示，原文本        由一个实数矩阵表示，这个矩阵可以类比成一张图像的像素矩阵，可以像“阅读”图像一样“阅读”文本，学习并提取特征。虽然提取的文本特征并不像图像特征有显然的可解释性并能够被可视化，抽取的文本特征可以类比自然语言处理中的分析树  ，代表一句话的语法层级结构。

基于卷积神经网络的自动文本摘要模型中最具代表性的是由提出的模型，它的编码器和解码器都由实现，同时也加入了注意力机制，下文将详细介绍。
当然，我们不仅可以用同一种神经网络实现编码器和解码器，也可以用不同的网络，如编码器基于，解码器基于。
前沿
      
这是由研究发表的基于的生成式自动文本摘要模型，通过架构创新和若干提升模型概括长文本的能力，在 、  数据集上达到了新的最佳性能。
针对长文本生成摘要在文本摘要领域是一项比较困难的任务，即使是过去最好的深度神经网络模型，在处理这项任务时，也会出现生成不通顺、重复词句等问题。为了解决上述问题，模型作者提出了内注意力机制 和新的训练方法，有效地提升了文本摘要的生成质量。

模型里应用了两套注意力机制，分别是经典的解码器编码器注意力机制，和解码器内部的注意力机制。前者使解码器在生成结果时，能动态地、按需求地获得输入端的信息，后者则使模型能关注到已生成的词，帮助解决生成长句子时容易重复同一词句的问题。
模型的另一创新，是提出了混合式学习目标，融合了监督式学习 和强化学习 。
首先，该学习目标包含了传统的最大似然。最大似然在语言建模等任务中是一个经典的训练目标，旨在最大化句子中单词的联合概率分布，从而使模型学习到语言的概率分布。

但对于文本摘要，仅仅考虑最大似然并不够。主要有两个原因，一是监督式训练有参考“答案”，但投入应用、生成摘要时却没有。比如时刻生成的词是，而参考摘要中是，那么在监督式训练中生成时刻的词时，输入是，因此错误并没有积累。但在实际应用中，由于没有 ，时刻的输入是错误的。这样引起的后果是因为没有纠正，错误会积累，这个问题被称为 。另一个原因是，往往在监督式训练中，对一篇文本一般只提供一个参考摘要，基于的监督式训练只鼓励模型生成一模一样的摘要，然而正如在介绍中提到的，对于一篇文本，往往可以有不同的摘要，因此监督式学习的要求太过绝对。与此相反，用于评价生成摘要的指标却能考虑到这一灵活性，通过比较参考摘要和生成的摘要，给出摘要的评价见下文评估摘要部分。所以希望在训练时引入指标。但由于并不可导的，传统的求梯度并不能直接应用到。因此，一个很自然的想法是，利用强化学习将指标加入训练目标。
那么我们是怎么通过强化学习使模型针对进行优化呢？简单说来，模型先以前向模式生成摘要样本，用指标测评打分，得到了对这个样本的评价回报后，再根据回报更新模型参数：如果模型生成的样本较高，那么鼓励模型；如果生成的样本评价较低，那么抑制模型输出此类样本。

最终的训练目标是最大似然和基于指标的函数的加权平均，这两个子目标各司其职：最大似然承担了建立好的语言模型的责任，使模型生成语法正确、文字流畅的文本；而指标则降低 ，允许摘要拥有更多的灵活性，同时针对的优化也直接提升了模型的评分。
构建一个好的模型，除了在架构上需要有创新，也需要一些小技巧，这个模型也不例外。在论文中，作者使用了下列技巧：

使用指针处理未知词问题；
共享解码器权重，加快训练时模型的收敛；
人工规则，规定不能重复出现连续的三个词。

综上所述，深度学习强化学习是一个很好的思路，这个模型第一次将强化学习应用到文本摘要任务中，取得了不错的表现。相信同样的思路还可以用在其他任务中。
    
模型由的实验室提出，它的编码器和解码器都是基于卷积神经网络搭建的。这个模型主要用于机器翻译任务，在论文发表的时候，在英德、英法两个翻译任务上都达到了。同时，作者也尝试将该模型用于自动文本摘要，实验结果显示，基于的模型也能在文本摘要任务中达到接近的表现。
模型架构如下图所示。乍看之下，模型很复杂，但实际上，它的每个部分都比较直观，下面通过分解成子模块，详细介绍。

首先来看部分。

这个模型的比较新颖，除了传统的  ，还加入了 ，将词序表示成分布式向量，使模型获得词序和位置信息，模拟对词序的感知。最后的是语义和词序的简单求和。
之后，词语的作为输入进入到模型的卷积模块。

这个卷积模块可以视作是经典的卷积加上非线性变换。虽然图中只画出一层的情况，实际上可以像经典的卷积层一样，层层叠加。
这里着重介绍非线性变换。

该非线性变换被称为   。它将卷积后的结果分成两部分，对其中一部分作用变换，即映射到到的区间之后，和另一部分向量进行乘积。

这个设计让人联想到中的门结构。从某种程度上说，是在模仿和中的门结构，使网络有能力控制信息流的传递，在 被证明是非常有效的。
除了将门架构和卷积层结合，作者还使用了残差连接 。 能帮助构建更深的网络，缓解梯度消失爆炸等问题。
除了使用加强版的卷积网络，模型还引入了带多跳结构的注意力机制 。不同于以往的注意力机制，多跳式注意力不仅要求解码器的最后一层卷积块关注输入和输出信息，而且还要求每一层卷积块都执行同样的注意力机制。如此复杂的注意力机制使模型能获得更多的历史信息，如哪些输入已经被关注过。

像      一样，的成功之处不仅在于创新的结构，还在于细致入微的小技巧。在中，作者对参数使用了非常仔细的初始化和规范化，稳定了方差和训练过程。
这个模型的成功证明了同样能应用到文本任务中，通过层级表征长程依赖 。同时，由于具有可高度并行化的特点，所以的训练比更高效。比起，的不足是有更多的参数需要调节。
评估摘要
评估一篇摘要的质量是一件比较困难的任务。
对于一篇摘要而言，很难说有标准答案。不同于很多拥有客观评判标准的任务，摘要的评判一定程度上依赖主观判断。即使在摘要任务中，有关于语法正确性、语言流畅性、关键信息完整度等标准，摘要的评价还是如同”一千个人眼里有一千个哈姆雷特“一样，每个人对摘要的优劣都有自己的准绳。
自上世纪九十年代末开始，一些会议或组织开始致力于制定摘要评价的标准，他们也会参与评价一些自动文本摘要。比较著名的会议或组织包括，  ，  等。其中的摘要任务被广泛研究，大多数摘要模型在数据集上进行测试。
目前，评估自动文本摘要质量主要有两种方法：人工评价方法和自动评价方法。这两类评价方法都需要完成以下三点：

决定原始文本最重要的、需要保留的部分；
在自动文本摘要中识别出中的部分；
基于语法和连贯性评价摘要的可读性。

人工评价方法
评估一篇摘要的好坏，最简单的方法就是邀请若干专家根据标准进行人工评定。这种方法比较接近人的阅读感受，但是耗时耗力，无法用于对大规模自动文本摘要数据的评价，和自动文本摘要的应用场景并不符合。因此，文本摘要研究团队积极地研究自动评价方法。
自动评价方法
为了更高效地评估自动文本摘要，可以选定一个或若干指标，基于这些指标比较生成的摘要和参考摘要人工撰写，被认为是正确的摘要进行自动评价。目前最常用、也最受到认可的指标是    。是提出的一个指标集合，包括一些衍生的指标，最常用的有，，：

：该指标旨在通过比较生成的摘要和参考摘要的连续的个词评价摘要的质量。常用的有，，。
：不同于，该指标基于最长公共子序列评价摘要。如果生成的摘要和参考摘要的越长，那么认为生成的摘要质量越高。该指标的不足之处在于，它要求一定是连续的。
：该指标综合考虑 = 和 = ，允许的第一个字和第二个字之间插入其他词，因此比更灵活。作为自动评价指标，和人工评定的相关度较高，在自动评价摘要中能给出有效的参考。但另一方面，从以上对指标的描述可以看出，基于字的对应而非语义的对应，生成的摘要在字词上与参考摘要越接近，那么它的值将越高。但是，如果字词有区别，即使语义上类似，得到的值就会变低。换句话说，如果一篇生成的摘要恰好是在参考摘要的基础上进行同义词替换，改写成字词完全不同的摘要，虽然这仍是一篇质量较高的摘要，但值会呈现相反的结论。从这个极端但可能发生的例子可以看出，自动评价方法所需的指标仍然存在一些不足。目前，为了避免上述情况的发生，在时，通常会使用几篇摘要作为参考和基准，这有效地增加了的可信度，也考虑到了摘要的不唯一性。对自动评价摘要方法的研究和探索也是目前自动文本摘要领域一个热门的研究方向。

总结
本文主要介绍了基于深度神经网络的生成式文本摘要，包括基本模型和最新进展，同时也介绍了如何评价自动生成的摘要。自动文本摘要是目前的热门研究方向之一，从研究落地到实际业务，还有一段路要走，未来可能的发展方向有：模仿人撰写摘要的模式，融合抽取式和生成式模型；研究更好的摘要评估指标。希望本文能帮助大家更好地了解深度神经网络在自动文本摘要任务中的应用。

      
      
       
       
   
    
       
       
     
      
      他是顶级的人工智能高手，仅过去一年，就参加了次举办的数据竞赛，其中他设计的能够探索同一平台上重复广告的算法和为视频贴标签的算法均在相关竞赛中获得第二名。他有技术，有激情，是人工智能界一颗冉冉升起的新星
这么牛逼的他，你肯定想不到还是一个高中生，岁！他还是个孩子呀！作为年老阿姨的我……感觉自己的智商受到了来自宇宙万物一万吨的嘲笑！！今天我们就来一起膜拜大神是怎么养成的，跟大神一起飞啦！

翻译 | 周科编辑 | 焦燕
我们的主人公叫 ，岁，目前是一名高中生。他的“走红”源于一个平台——。
是一个流行的数据科学竞赛平台，隶属于云。在这里，人工智能程序员或是数据科学家一同解决某个项目，这些项目对于获胜的解决方案会给出一定的奖金往往都比较高。目前，的注册用户已经超过了万。
在的排名非常靠前。在“”中，排名第二。在过去的一年中，他参加了场比赛。最近，他在一个竞赛中又获得了第二，这个竞赛的目标是设计出一个能够探索同一平台上重复广告的算法。
小小年纪为何能有如此成就？
因为他，有技术！有激情！还有和社区合作的态度！都说“英雄出少年”，简直就是和庞大的人工智能社区中冉冉升起的明星。
更不可思议的是，在机器学习和人工智能方面的编程技能几乎全都是自学的。
自！学！的！骚年，你的脑结构到底是怎？样？的？！开过光么？
的高中课程中，没有任何一门是讲授如何构建人工智能系统的。过去几年里，他运用互联网、阅读文献、观看视频，花费了大量的时间研究人工智能和机器学习：
“网上有大量的免费视频，但是，我实际上并没有参加这些课程。当我面对一个巨大的问题需要解决时，我会先，查找和问题相关的资料。因此，我并没有采用任何预设的学习轨迹。我是在网上了解到，然后，我就想，为什么不尝试一下呢？”满不在乎地说到。
为什么不尝试一下呢…试一下呢…下呢…呢……

没有浪费任何时间，全身心地突入到中，在这里，他把自己描述为“         岁的决策树说客。我喜欢数据，我热衷于挑战”。
在过去的几个月中，参加了各种各样的竞赛，排名逐渐升高。
他协助设计了一个算法，采用计算机视觉技术分析万视频，从而生成精确的标签。他的队伍在支队伍中排名第。这引起了的关注，于是邀请在年计算机视觉和模式识别会议一个在计算机视觉领域方面颇有声誉的会议中展示自己的作品。
这个项目看似简单，却是一个非常具有挑战性的计算机视觉问题。因为设计出的算法需要理解视频中的内容是什么，并挑选出正确的标签。当前，对图像打标签都非常难，更何况是视频，因为缺少公开的数据集可以用于训练算法。
但这似乎难不倒这位天才少年。
说：“我们编写出我们自己的神经网络模型，他们提供了训练数据集，你使用它来训练算法，这样这个算法就可以用于分析新的视频。”
乐意投身于人工智能领域，不过，在那之前，他得先完成学业。他梦想中的大学有：  和。
尽管他有这方面的才能和技能，同时他也清楚自己在人工智能领域还有很多不懂的地方。
“我不知道这些算法背后所有的数学，但是在应用方面，我觉得清晰地知道这些算法工作的逻辑过程是更加重要的。尽管我不能完整得表述这些算法，我还是知道它在做什么，这使得我能够发现在什么场景下可以使用它。”
嗯，这是一个有志向不吹嘘有实力还谦虚的好少年，目测未来要火呀。作为渣渣的你我，只有抱大腿的份儿了。
额，忘了说了，这个未来人工智能明星还有一张高颜值的脸，帅帅哒 原文地址
在前端开发工作中，除了项目开发保质保量上线以外，项目的数据监控也应该配套起来，确保线上的正常运转。如上报  监控项目是否正常运转；测速上报反应项目质量；脚本错误监控作为监控中重要一环，当页面发生报错的时候，通过上报错误信息，能及时发现存在问题，修复优化、减少损失。
本文基于在手  家校群前端脚本错误量优化的方案，致力于打造极致的脚本错误优化。
监控上报
脚本错误主要有两类：语法错误、运行时错误。
监控的方式主要有两种：、。
监控方式
示例 · 
 {
    
} {
运行时错误信息 ↙

}

通过给代码块进行  包装，当代码块出错时  将能捕获到错误信息，页面也将继续执行。
当发生语法错误或异步错误时，则无法正常捕捉。
示例 ·  语法报错

 {
      语法错误
} {
语法错误信息 ↙

}
无法捕捉错误

示例 ·  异步错误
 {
 {
     异步错误
}
} {
异步错误信息 ↙

}
无法捕捉错误

语法错误无法在  中进行捕抓、而异步报错则可以通过为异步函数块再包装一层 ，增加标识信息来配合定位，可以用工具来进行处理，这里不展开。
示例 · 

  {}  错误信息
  {}  出错文件
  {}  行号
  {}  列号
  {}  错误详细信息

 =       {
 错误信息 ↙
{
    
}
}

    

 能捕捉到当前页面的语法错误或运行时报错，是十分强大的。那么  是否不再需要呢？其实并不是。
在使用过程中的体会： 主要用来捕获预料之外的错误，而  则可以用在预知情况下监控特定错误，两种形式结合使用更加高效。
上报方式
监控错误拿到了报错信息，接下来则是将捕抓的错误信息发送到信息收集平台上，发送的形式主要有两种：

通过  发送数据

动态创建  标签的形式


示例 · 动态创建  标签进行上报
   {
  = 
  =   =  
}
监控上报整体流程
监控报错，并将捕捉到的错误信息上报给数据收集平台，如下图

错误信息分析 ·  
有了监控了后，就可以在收集平台上进行查看脚本错误量的日志统计。

发现占据榜首的错误信息 “ ” 具有非常高的比例，没有无具体的错误信息，无法定位问题，而这是怎么产生的呢？
产生   的原因
翻看在  的源码可以看到 “ ” 是浏览器在同源策略限制下所产生的。浏览器出于安全上的考虑，当页面引用的非同域的外部脚本中抛出了异常，此时本页面无权限获得这个异常详情， 将输出   的错误信息。

优化  
  来自同源策略的影响，那么解决的方案之一是进行资源的同源化，另外也可以利用跨源资源共享机制  。
方案一：同源化

将  代码内联到  文件中

将  文件与  文件放到同一域名下


以上两种方式能够简单直接地解决问题，但也可能带来其他影响，如内联资源不好利用文件缓存，同域无法充分利用  优势等等。
方案二：跨源资源共享机制  
跨源资源共享    机制让  应用服务器能支持跨站访问控制，从而能够安全地跨站数据传输。主要是通过给请求带上特定头信息，服务器实现了  接口，就可以跨源通信，从而能够看到具体报错信息。
 为页面上  标签添加  属性。
 = 
增加  属性后，浏览器将自动在请求头中添加一个  字段，发起一个 跨来源资源共享 请求。 向服务端表明了请求来源，服务端将根据来源判断是否正常响应。

 响应头中增加  来支持跨域资源共享。

  表示通过该跨域请求，且该资源可以被任意站点跨站访问。而当该资源仅允许来自  的跨站请求，其它站点都不能跨站访问时，将可以返回：

 指定域名的  的响应头中需带上 。
 字段的作用在于为缓存服务器提供缓存规则及缓存筛选的依据。当增加  响应头后，缓存服务器将会按照  字段的内容，缓存不同版本，在请求响应时根据请求头中的  决定是否能够使用缓存响应。

举例 · 不加  将存在错误命中缓存的问题

上图中，第一个请求 响应被浏览器缓存了，当第二个请求 发起，被错误命中了前一个请求的缓存，收到了  的响应时，将导致资源加载失败。所以当  不是返回为  时，需要加上  返回头来避免引缓存导致的权限问题。
跨域脚本报错产生   通过以上方式进行处理后将能够捕获到具体的报错信息了。在  的实现中主要通过添加以下代码：
 {
 拿到请求头中的 
  =  
  {  不存在则忽略
  
}

 设置  
 

 设置  

  
}
以上为本文所有内容，兄弟篇：脚本错误量极致优化让脚本错误一目了然
查看更多文章： 腾讯云技术公开课专注于云计算方面的技术分享，将定期邀请腾讯云及相关领域的技术专家，通过在线视频直播的方式，与广大开发者分享腾讯云在云计算领域积累的最佳实践和经验。
月日，将举办第一期技术公开课，从计算、网络、存储三个角度，分享公有云如何应对架构不断调整、优化带来的挑战，并介绍腾讯云在架构设计方面的最佳实践经验。现在报名参加技术公开课，还有机会获得价值元的腾讯云代金券！
直播关键词：架构设计，高可用，网络，无服务计算，块存储
直播时间：月日晚
分享嘉宾：刘颖，腾讯云基础产品中心总监
分享概要：

如何构建一个高可用高性能的网络
中国特色混合云带来的挑战和解决思路
从虚拟化到容器再到无服务计算面临的主要场景和解决之道
大规模下海量块存储带来的挑战和解决之道

适合人群：对云计算及架构感兴趣的开发者
活动已结束。为了方便大家回顾直播内容，我们已经剪辑好了相关视频，包括：

嘉宾分享：腾讯云架构演变及经验

当前浏览器不能支持视频播放，请采用或以上浏览器

助教演示：搭建高可用站点

当前浏览器不能支持视频播放，请采用或以上浏览器
以上视频可在腾讯云课堂查看。导语
随着系统的版本更新，现在 的系统占比越来越大，而每一次版本更新都会对系统做一些涉及到开发的相关调整。如果我们不主动升级后面简称的话，一般来说对于就不需要进行大的改动，但是当升级之后，会导致调用的系统行为发生更变，从而影响的使用。  后面简称是腾讯发展海外市场的主要产品之一，目前已发布在个国家并且成为排名第一的音乐，为了能够得到的推荐位以加强的市场地位，需要将提高到，本文主要介绍是如何从 “爬到” 的。
一、入坑
作为一个刚入职不久的工程狮，某天，我像往常一样起床上班，坐在电脑前开始制造新的，但是，这一天注定是不寻常的一天
“小，你过来一下”，像往常一样开始召唤我了。
“交给你一个任务，我们需要将的升级到。”
我“没问题，马上搞定。”
修改这种事情还用浪费什么时间？直接修改到之后直接 ，“彬哥，任务完美完成，请问还有什么指示？”
沉默了一会：“辞职信写好了吗？”
下一秒拿出我单身多年的手速迅速撤回并且回了一句“刚刚好像帐号被盗了，自己乱发消息，您继续忙，我还有没写完，就不打扰您了”。
 
稳住，开始进入正题啦。在开始接到这个任务的时候，确实是没什么经验，感觉很简单的样子，殊不知自己踩进了天坑里。查了各种资料，总算知道升级到需要注意的地方了：

权限问题

本身是 ，但是从 开始区分正常权限和危险权限，而危险权限需要向用户申请授予才能使用，导致在升级到以上并且在手机上运行时，如果没有对应的权限然后执行相关操作的话会。这里列出需要动态申请的权限：
 
具体的可以参考这里：
=

模式

这个问题不属于升级会导致的问题，不过还是提一下。从 开始，为了延长电池的使用时间而提供的一个功能，处于该模式时，系统会抑制的后台任务例如网络，占用等，只允许部分任务能够正常执行来减少耗电。简单来说就是当系统认为用户没有在使用的时候就会自动进入该模式，不过目前还没有碰到过相关问题。这里可以参考空间终端团队的文章：
 新特性   模式详解

私有库访问问题

从 开始，如果中有直接访问或者使用的第三方库有使用到私有库的话，对于 以上的级别即 = 会导致应用，不过低于改级别的运行在系统的手机上也会有相关的弹窗警告。涉及到的库例如_、、 和 等等。
 
具体可以参考链接中的 应用链接至平台库：
=

其他问题

上面提到的问题算是比较主要的几个问题。其他问题是解决过程中慢慢发现的，包含有：
①
②加密
③调用摄像头
④ 后查询进程信息
等等相关问题，后面将会列出它们的解决方案额，可能也没有解决方案
 
二、爬坑
上一节列出了差不多大多数在升级时会碰到的问题，这一节就说一下相关的解决方案啦。

权限问题解决方案

权限问题解决方案这里大家可能在看了相关的之后都感觉没什么问题啦，我也是这样想的但是，对于来说就有点蛋疼了。在的初始化中使用到了相关的危险权限，这时候会发现——在中不能进行请求权限，而且相关的初始化代码暂时没法搬到的中。
这时候怎么办？当然是“凉拌”呀。
 
在这里采用了多进程的方式来获取权限，通过在中判断需要用到的权限是否授权，然后启动子进程来获取权限。而为了完善用户体验，这里通过命令来查询进程信息来同步关闭两个进程像小米提供的长按返回键干掉，只会干掉主进程，而子进程并没有被干掉。然而这样的同步进程状态的方法引出了后面一个大坑那个坑就在上一节列出了，一会会提到它。
 在之后系统的权限授权行为已被纠正，在这之前如果你请求并获得了读取存储的权限，系统会错误的将整个权限组的其他权限也授予你使用，也就是说会同时获得写存储的权限。而从开始如果你只申请并获得了读存储的权限，这时候你不会获得写存储的权限，所以你要主动去申请写存储的权限，不过这次申请系统是不会弹窗给用户确认，而是直接授权给你的。

模式问题

对于来说，经过测试之后并没有发现相关的问题影响，所以大家可以参考前面贴的链接来测试和解决自己碰到的问题咯。

私有库访问问题

这个问题的话只能说是简单粗暴了，要不然不要使用私有库，要不然将用到的私有库放到你的库的路径下打包也行，第三方库的话应该都会有对应的更新。麻烦的地方在于如何找出哪里用到了，可以通过写一个测试类将所有库都加载一遍不过比较麻烦，也可以通过如下命令：
  
工具在目录下的
\\\_\
目录反正我这边是在这里，你也可以通过查找找一下看看



对于，主要是设置的问题， 之后就不推荐使用__和__两个标志位了，大于并且是的系统的话会直接抛出异常，由于以前使用的是这两个，导致在提升之后直接，改成_就可以了。

加密问题

在 后废弃加密方式，具体可以查看：

如果一定要用它的话可以通过如下方式兼容：


查询其他进程信息问题

摄像头调用的话就不提了，网上都是解决方案。这里说一下查询进程信息这就是前面说到的大坑好吧，对于来说。
这天，当我将前面提到的问题都解决了之后，提交代码。当晚正准备提测，为了确认音效在升级之后是否正常，卸掉之后重装，结果一运行就了了┬＿┬。然后自己手动打开权限后就可以正常运行，初步确认问题出在权限获取子进程上。这里贴一下之后的
 
 
这什么？谁知道问题出在哪？最主要的是，包能够正常运行，而包不行经过不断反复的查看打印的之后，发现了一条重要的线索：
 
为什么说是重要的线索？因为代码里面有调用到启动的逻辑。
 由于在没有权限的时候会掉主进程来退出，但是会被系统重新拉起来，因为系统会拉起被强杀的应用栈中栈顶的，所以先启动的话再掉就不会被自动拉起了。这里也提示大家在完全退出的时候如果使用到，这些方法的话先将所有干掉，防止被系统自动拉起。
继续上面的分析，由于当的子进程根据包名查询主进程的存活情况的时候失败了，导致应用一启动就直接执行了退出的代码因为在之后，限制了进程相关信息的访问权限，仅能够获取本身进程的信息了这回是真的所以通过命令或者访问相关文件都不能够获取到其他进程的信息了，不过包可以访问到同一个的所有进程，包访问不到，导致在爬这个坑的时候——非常蛋疼！这也是目前没办法解决的问题。更多了解可以看一下这篇文章：

三、总结
文章提到的问题都是一点一点慢慢爬出来的，虽然说网上的适配文章很多，但是大部分内容都是相同的，当遇到一些比较偏的问题只能说是自己慢慢爬了，写这篇文章也是为了方便大家爬坑。
从前面的问题可以看出对于生态隐私相关方面的控制越来越严格了，从禁止各种访问就可以看出来，未来估计还会继续限制一些私有内容的访问，对于用户来说是件好事，但是对于开发者我来说还愣着干嘛？赶紧去写个压压惊。引言
不知道每天上下班的你坐在地铁公交上会刷哪些呢？也许正为周末和朋友去哪里聚会而挑选餐厅；也许刷着朋友圈看看朋友们有哪些新动态；也许在上浏览着大博主们晒的美照。地铁中信号不理想的状况时有发生，此时的你可能需要等待屏幕中间的小圆圈一直转好一会儿，图片才会加载完毕。解决这样的痛点当然有两种方案：依赖电信运营商铺设更多的基站以及热点来扩大数据信号的覆盖面及提升信号强度；或者，依靠腾讯云不断增强的图片处理能力在给定带宽的条件下提升图片的下载体验。
在今天星罗棋布的互联网环境下，每秒都有几亿张图片飞舞其间，其中万象优图支撑了海量的请求。主流的图片格式包括。每一种格式都有着不同的特点，存在着特性各异的优化空间。我们将分小节为大家拆解其中的奥妙。

图片与其它格式图片最大的区别在于将时间轴这个维度代入到原本静态的视觉表示中，使得信息的表达更加鲜活。不过随着网络带宽及视频技术的突飞猛进，眼看就快要退出历史舞台了。然而，历史往往就是这么吊诡，近年来的表情包文化使得图片起死回生，焕发出了新的活力。总结一下图在表情包应用中的特点包括：内容简单、画质要求不高、兼容性强不需要特定解码器即可在各通用平台上展示。基于此，我们可以为图片进行全方位的“瘦身”：
 利用前后帧的相关性进行优化
动画通常分为视频截图和人工制作两类。人工制作类的有着背景相对固定，色彩数较少以及纯色区域较多的特性。如下图所示：

图 前后帧相关性样例图
这张图通过我们的优化可以在存储时实际只存储为：

图 样例图分解示意图
然后在图像实际展示时再还原为：

图 样例图分解还原示意图
经过合并帧的处理，万象优图中可以在完全没有任何损失的前提下降低图片的存储量。实际效果如下图所示：

图 帧间优化效果示意图
某些极端情况下，如果前后两帧内容完全相同，此时帧间优化的效率最大，如下图所示一幅帧的图，前帧内容相同的时候只通过帧合并手段就可以节省约一半的图片大小：

图 帧合并效果图
 利用画质不敏感的特性做降色处理
图是一种索引色图像。也就是说，每一张图中所呈现的颜色都由一个预先定义好的调色板所决定，颜色数最多为。每帧视频截图间的背景可能存在微小的残差。所谓微小残差，本质就是颜色上的细微差别，但其实是非常相近且人眼不易察觉的。那么如果我们把相近的种颜色合并成为一种颜色的话，我们就获得了进一步压缩图片大小的空间。万象优图提供了接口供用户根据自身的实际情况灵活降低调色板的颜色数，在清晰度和带宽节省上随心搭配，自由权衡。
下图给出了在给定不同颜色数的条件下，压缩后的图片与原图的大小比例曲线：
 
图 降色接口对存储量的作用
同时对于人眼来说，一般程度的降色看起来也毫无违和感，并不觉得图片在视觉上变粗糙很多
 
图 降色操作优化效果图
原图颜色数的多少对降色结果有着非常直接的影响，万象优图的降色接口对原图颜色丰富的比颜色单一的作用效果更为明显。用户可考虑自身情况灵活使用，达到最佳效果。
与
格式的图片由于其支持有损、采用直接色等特色使得其非常适合于存储照片。在现今的网络环境中占据着统治性的市场份额，就如同家用操作系统领域的、个人电脑处理器领域的英特尔等一众行业巨擘的地位一般。对于自然环境类的图片，在人眼视觉几乎不感知的前提下，格式的图片可以用明显更小的体积提供相同甚至更好的视觉体验，因此获得了广泛的支持。
虽然图片已经是各图片格式中最适应于网络环境的选择了，但是业界仍然为了追求更好的体验而在不懈地努力。
团队开发了项目使得在不降低图像质量且兼容主流的解码器的情况下，平均降低的图片大小。
于年发布的图片格式在相同质量下可以比图片节省约的文件大小，该图片格式也加入了万象优图的图片处理武器库中。
图片格式虽然是一把节省流量的利器，但是多数情况下需要用户集成特定的解码器到自己的应用中才能正常展示，这意味着额外的开发维护成本。那么是否存在无需额外开发量就能进一步节省流量的方法呢？
下面敲黑板，划重点的时间到了。最近开源的新型编码器基于新型的视觉感知模型来有选择的丢弃图片细节信息以达到同样视觉效果下更高的压缩率。经过实际测试发现，在相同质量参数条件下编码出的可以节省约的图片大小。最近我们将进行了优化并且将其集成到腾讯云的图片处理系统中，为业务的成本优化提供了一项新的“技能包”。

图 优化效果图
接下来本文将简要描述的原理以及万象优图在这方面所做的优化。
的压缩标准基于的评价体系，其采用三个传统方法没有考虑的原则：
 色彩间的相互掩蔽。人眼对强黄色光附近蓝色光强度变化是不敏感的，因此黄光区域附近的蓝色区域可以用更少的进行编码。
 人眼对蓝光有着较低的空间分辨率，视网膜中用于分辨高清细节的区域没有蓝色光的受体，故高频区域的蓝色光部分可以用更粗的粒度编码。
 纹理掩蔽效应。将图像中的高频噪声区域分辨出来进行粗粒度的编码。
总体来看，的处理优化可以概括为如下三个部分
 
图 优化立足点

通过标准库编码出的所使用的是一套固定不变的，与图像独立的量化表。因此，在量化表优化领域内的论文将优化思路集中于两个套路上：给定图像的目标像素比特率，使得图像的失真最小化以优化视觉体验为目标；或者给定图像的失真容忍度，使得图像的像素比特率最小以减小带宽为目标。采用的是第二种思路。对于失真的评价体系来源于，而对于如何获取到比特率最小的图像结果所采用的方法是按照一定的规则多次迭代尝试。

“选择性丢弃高频信息”和“视觉体验优化”本质上是同一套原理下的不同表达而已。核心原理是基于游程编码的特性：邻近区域内连续值越多，压缩效率越高。首先根据自身定义的算法计算出各系数的权重，然后基于权重和与原图的目标失真距离两个因素大量丢弃不重要的接近于的系数，这部分操作将使得重新编码后的图片的大小大幅降低；当丢弃的流程完成后我们再回过头来同样基于这样一套权重和失真评价体系将之前将少量系数重写以微调局部视觉体验，这部分调整又使得编码后的图片大小有微微的回升，最终产生出所认为的最好的图片返回给我们。这里我们用一个比方也许能更好地让大家理解这一过程。大家都在中学做过用显微镜观察植物细胞壁的实验吧。有一个“粗调”旋钮和一个“微调”旋钮。首先我们会使用粗调方法快速逼近最清晰的视觉效果，当感觉已经接近最佳的时候我们会再用微调的旋钮进行局部微调以达到最好的效果。


通过刚才的描述也许大家也发现了，的编码需要不断地做针对输入图片的迭代、调整、尝试以求得最好的效果，这样做的代价便是与传统方法相比消耗了巨大的计算资源，时延从传统编码器的级到的秒级。于是计算性能的优化势在必行。我们尝试通过减少整个流程的迭代次数、使用并行计算框架等方法目前已能将处理的单张处理时延减少一半以上。这个结果固然已经是巨大的进步，但是与传统相比仍然有着不小的差距。我们会继续努力提升的性能，丰富万象优图的“图片处理军火库”，为用户提供持续增长的价值。是编程语言全新的一个版本，在性能方面获得了极大的提升。官方的文档显示，可以达到版本两倍的性能。同时还提供了很多其他语言流行的语法格式。另外其的兼容性也是非常好的。因此，其他版本向迁移过程中，程序调整不会太大。本文不针对性能提升原因做深入研究，主要是简单描述一下一些新增的特性。
、函数参数支持标量类型声明
在中，可以将函数参数指定为类名、接口名、数组和回调类型中的一种，但是无法将类型指定为标量。中新增了对函数参数声明为四种标量类型的支持，即可以指定参数类型为整型、浮点型、字符串以及布尔型。

    指定函数参数必须为字符串
      
    {
         __{} 
    }

、新增函数返回类型声明
新增了对函数返回类型声明的支持，支持的类型与参数类型相同在中支持返回类型。

    指定函数返回值必须为整型
       
    {
         __{} 
    }

函数参数以及函数返回值支持的类型见下表：

标量的声明有中模式：、严格模式；、强制模式默认。可以在文件顶部通过关键字来修改标量声明模式。强制模式下如果值的类型与声明的不符合，会尽量进行转换到对应类型。但是，如果是严格模式下，值与类型不符合，则会出现一个错误。

     _=
          
    {
         
    }
      

                 
、定义常量数组
及以后版本中可以通过关键字来定义常量数组，中新增可以通过定义常量数组功能。


    中通过定义常量数组
      =    

     中通过定义常量数组数组
     

、生成器返回表达式
中实现了生成器，但是生成器函数不可以有返回值，但是空是一个有效的语法并且它将会终止生成器继续执行。生成器函数只能通过关键字来生成值。中允许在生成器函数中通过使用  语法来返回一个表达式 但是不允许返回引用值， 可以通过调用  方法来获取生成器的返回值， 但是这个方法只能在生成器完成产生工作以后调用一次。
、生成器新增 操作符
可以在外层生成器中使用  ， 就可以把一个生成器自动委派给其他的生成器，  对象或者 。


      
    {
        委派给一个数组
           
        委派给另外一个生成器函数
           
    }

      
    {
         
         
    }

     = 
      
    {
          _
    }
      

输出结果
 
 
 
 
、合并运算符
后端在接收用户传入的数据时通常会先判断变量是否存在，如果存在获取对应的值，如果不存在，在设置一个默认值或者报错处理。这里就会用到 三元运算符和。在中新增了一个语法糖。如果第一个操作数存在且不为则返回第一个操作数的值，否则返回第二个操作数的值。例如：

    获取用户先从_中获取，如果没有从_中获取，如果还是不存在，就默认空
    之前的写法
     = _  _  _  _  

    中新增的语法糖
     = _  _  

、组合比较符
该操作符也称为太空船操作符，用于对个表达式进行比较并返回比较结果。使用语法： = 。如果小于返回，等于返回，大于返回。比较的原则是沿用  的常规比较规则进行的。

      = 
      = 
      = 

输出结果
 
 
 
、新增静态方法
是用来表示匿名函数的类，可以称作为闭包类。任何一个匿名函数都会自动产生一个类的对象。如果需要复制一个闭包对象且调用它，在之前版本，写法较为繁琐，而在可以通过方法来快速实现。


      
    {
          = 
    }

       之前版本的代码
     =  
    {
         
    }

    复制闭包对象，并将该闭包绑定到类的实例化对象上“绑定对象”决定了函数中的取值
    本例中指向了类的实例化对象
     =   
     

       及更高版本的代码
     =  
    {
         
    }
      

未了避免篇幅过长，本文没有列举中所有新特性，其余新特性将在后续文章中陆续补充。
关于文章示例代码说明：本文中代码均在版本中进行了测试。部分代码采用了官网代码。连接池是一个很好的设计，通过将大量短连接转化为少量的长连接，从而提高整个系统的吞吐率。一般各个团队都会对连接池进行封装，只提供简洁的接口供上层使用。在上层看来，并不知道底层是否使用了连接池甚至连访问数据库的和都不知道，只知道调用了一个接口，执行了指定的语句，并返回执行状态和执行结果。
本来是很好的解耦分层设计，但是当上层使用方式不恰当时，就会发生一些奇怪的事。最近我们项目就遇到了这样奇怪的事情，且听我慢慢道来。
 背景
首先交待一些基本背景。我们项目使用了作为 ，并用作为库。提供了连接池功能，时会首先从连接池中查找空闲的连接，如果找不到才创建一个新的连接；当使用完毕之后，可以通过_将当前连接放回连接池中，供保活时间内其他请求使用。
这是公共库中封装的执行函数，上层执行都是通过这个函数实现的。

  
        
 
       = _
       
          
    

         = 
       
                  
    

          
       = _ 
       
                   
    

      

也许有些聪明的同学已经发现了问题了，但是在奇怪的事情发生之前，没有人意识到，而且这个函数也确实稳定可靠的运行了很长时间。
 奇怪的事情
前一段时间，发生了几次用户在页面配置时报错，定位的结果是接口超时，而接口超时的原因是的表被锁住了。本来表被锁住了也很正常，找出加锁的地方看看有什么使用不当就行了。
但是搜索了所有的代码，被锁的表只找到了一处加锁的代码，而日志显示，这处代码的多个线程都在等已有的锁，没有任何一个线程获得了锁。
既然表级锁找不到行级锁已排除，那么是否是数据库级别的锁呢？查看数据库备份的日志，发现的时间点跟锁完全对不上。
这就是那把奇怪的锁，它锁住了我的表，却找不到锁的来源，我把它叫做“神秘的幽灵锁”。
 顺藤摸瓜
作为一个唯物主义者，我决定对的状态进行监控，来捕捉这个幽灵锁。定位的方式很简单：每秒执行几个查询语句，并记录查询的结果，作为问题再现时的定位依据。具体语句如下：

                                      查看当前正在执行的语句
    __         查看当前已开启的事务
    __       查看当前事务开启的锁
    ___  查看当前事务锁的等待关系
至于显式锁表的情况，上述语句不能查询，则通过加日志协助定位 以上版本也可以通过查询。
定位的结果也是相当奇怪：某个地方开启了一个事务，事务锁住了平台的表和业务的表。因为平台的表被锁，导致接口等待超时页面报错。
这就引出了好几个问题，只要能解答这几个问题，幽灵锁就会现出原型。
 什么地方开启的事务？
通过搜索代码发现，平台没有显式使用事务的地方，只有业务侧为了保证操作的原子性，开启了事务，初步怀疑是某个分支没有执行或就退出。查看业务逻辑的代码，所有的异常处理分支已都加上了，这就奇了怪了。
既然代码没问题，那就只能检查运行时问题了。查看的，竟然惊奇的发现接口报错误，而在查找该请求的日志，又找到了错误日志“     ”。真是山重水复疑无路，柳暗花明又一村哈。那么问题很明确了，就是这个接口开启了事务，因为某个异常没有处理导致异常退出，没有执行或者。
 事务为什么会锁表？
首先，事务内并没有显式的加锁，那就只能是数据库本身加的锁了。而数据库会不会加锁，会加什么锁，则跟数据库配置相关。为了验证我的想法，我确认了一下数据库的事务隔离级别：
   _

| _  |

|  |

     
结果表示当前事务隔离级别是“重复读”级别的默认事务隔离级别，那么也就解释的通了。的级别为了保证不允许脏读、不允许非重复读、不允许幻读是的，作为一个成熟的数据库引擎，级别已经解决了幻读问题，当执行等操作时，会对操作影响的记录加上行锁和间隙锁。而业务的语句条件没有索引，所以就导致了全表被锁了。
 事务是基于连接的，在异常退出后，锁为什么没有自动释放？
连接对象是在脚本中创建的，按理说   ，即使句柄没释放，也会被的机制回收才对，事务不可能持续那么长时间。
有一种可能是，该连接对象是一个全局对象，或者是脚本级的变量。因为的加载机制，脚本级的变量，都只会加载一次，并且在脚本退出后生命周期还不会结束，相当于无形中变成了全局变量关于这个特性也是踩过一个坑，后续再专门讲解。但是检查连接对象，确实是函数的局部变量，也就不存在上面这个问题。
最后的最后，突然灵光一闪，我们使用的是连接池，那会不会是因为这个连接没被释放呢？顺藤摸瓜，最后找到了文章开头的那个公共库函数，总算找到罪魁祸首了。因为公共库函数每执行一个后立即将连接放回连接池，而接口异常退出是在开启事务并成功执行语句之后，在调用时抛异常，此时连接已经放回了连接池，自然没有被释放了。
 该事务只操作了业务的表，为什么会导致平台的表被锁？
这是最后一个问题了，其实从前面几个问题的答案，已经基本可以推出这个问题的答案了。因为业务开启了事务的连接被扔回连接池，然后被平台的接口取出执行了语句，导致平台的表也被加上行锁和间隙锁，从而导致任务超时。
 改进方案
幽灵锁已经分析的很清楚了，问题出在上层使用公共库时没意识到底层的连接池，导致使用方式不当。在上层看来是：
开启事务执行
而实际底层实现是：
获取一个连接开启事务扔回连接池获取一个连接执行扔回连接池获取一个连接扔回连接池。
这个过程无法保证每次拿到的都是同一个连接，也就存在了很大的问题。之所以之前一直没发生问题，那纯粹是运气好至于为什么运气能一直这么好，后续文章再揭晓。
那么解决方案也就很简单了，修改业务接口使用库的方式，不用上述封装的函数，直接调用的接口就可以了：
   = _
   
    __


  = 
     = 
   
    __


  = 
     = 
   
    __




   = _ 
   
    __

接口入口获取一个连接对象，使用这个对象执行一系列操作，在接口异常处理或正常结束处将连接对象扔回连接池即可。假如在处理过程中发生了异常导致接口异常退出，连接对象由于不在连接池，其他接口无法获取，并且这个连接对象会被的机制回收，不会造成影响。会在如下几种情况下触发操作，需要注意的是的最小单元是而不是单个。可想而知，如果一个中过多，每次的开销必然会很大，因此我们也建议在进行表设计的时候尽量减少的个数。官方文档总结的刷写时机有种：

级别限制：当中任意一个的大小达到了上限，默认，会触发刷新。


级别限制：当中所有的大小总和达到了上限  ，默认   = ，会触发刷新。


 级别限制：当一个 中所有的大小总和达到了上限 ＊ _，默认 的内存使用量，会触发部分刷新。顺序是按照由大到小执行，先 最大的，再执行次大的，直至总体内存使用量低于阈值 ＊ _，默认 的内存使用量。


当一个 中数量达到上限可通过参数配置时，系统会选取最早的一个 对应的一个或多个进行


定期刷新：默认周期为小时，确保不会长时间没有持久化。为避免所有的在同一时间都进行导致的问题，定期的操作有左右的随机延时。


手动执行：用户可以通过命令  ‘’或者 ‘ ’分别对一个表或者一个进行。虽然总的会有种，细分下的时机有三个：一个是单纯的引起了的变化的，第二个是的引起变化的，第三个是有一个定时线程轮询每一个是否需要，是一个。

第一个会在的时候发生，首先会调用方法检查资源，这个实际上就是检查的大小是否超过一定的阈值，如果超过，则会调用方法发起对该的进行的请求，并抛出异常，阻止该操作继续，后续将要讲的、等数据更新操作也是如此，在开始执行操作前都会调用这个方法来检查资源。而方法核心的方法即是调用的方法。
第二个是的，在做这些级别的操作前，都会直接调用方法有关这个方法在上一篇文档中有详细分析，然后再执行操作。这个比较好理解，因为一个根据对应了一系列的，当发生变更时所对应的的肯定需要做相应调整，所以要持久化刷硬盘。一般这些过程在和的帮助下都进行的比较快。
第三个是来定时的刷。

这个定时任务也比较简单，就是定时去检查对应的以及的是否到达了阈值然后去刷写。
 
需要注意的的刷写会阻塞整个的写，而且这时候很容易发生，这将很影响整个集群的性能，所以在的文档中也建议，在业务低峰期进行手动刷写，保证不在业务高峰的时候触发刷写条件而影响性能。之前一直在用阿里云服务器跑爬虫、小脚本。这两天在朋友的安利下转到了腾讯云上面来，刚好趁这个机会写一写有关于腾讯云服务器上爬虫环境的搭建。
第一步：购买以及简单配置
打开腾讯首页进行注册： 如何注册这里就不说了。注册完了之后可以在这里 进行实名认证，实名认证比较简单只需要用微信或者支付元，实名认证完在 按照你自己的情况领取优惠券。
注册领券完了之后，购买相应配置的云服务器。我这里按照一个爬虫需求的最低要求的配置去演示。
、首先打开：
：选择地域与机型，这里需要注意点是：地域选择离你比较近的地方，可以有效的降低访问延时、提高下载速度。

：选择镜像
靠谱到有百分之八十左右的人用的是系统，于是我这里是用做的演示，当然，你也可以选择其他你熟悉的操作系统。

选择存储与网络
选择配置你需要的数据盘、带宽的大小、服务器数量、购买市场等，如果没有特殊需求，此处可以默认选择，直接点击下一步。

设置相关信息
最后一步就是设置云服务器相关的信息了，包括设置密码、新建安全组。注意：必须新建安全组之后才可以点击完成。

最后一步付款的时候，可以使用第一步领取的优惠券，如果你使用的是最低配置的服务器，使用优惠券之后只需要元月
第二步：登陆云服务器
经过第一步，你已经购置好了云服务器了，在 将会看到你的云服务器状态，刚创建好的云服务器无法立马使用，需要等待分配时间在分钟左右。

点击右边的登陆会跳出登陆界面了，输入在第一步中输入设置的用户名以及密码就可以成功登陆服务器。
网页上进行服务器操作比较麻烦，如果自己电脑是系统，可以搜索本机的远程桌面连接，使用远程桌面连接连接云服务器。

其中的计算机名，就是你自己云服务器的公网

第三步：下载搭建环境
之前搭建过环境的这一步可以直接跳过了，没有搭建过的请继续往下看。在云服务器上访问： 直接下载，如果你不习惯使用，你也可以在首页下载你需要的版本。下载好之后运行，会出现以下界面。
注意：界面下方的    一定要勾选上，勾选之后，选择 。
点击下一步，如果出现，则安装成功。
使用终端，打开终端输入，如果出现以上界面不报错则云服务器环境至此搭建成功。

相关推荐
【腾讯云的种玩法】云服务器搭建爬虫环境
腾讯云主机环境安装爬虫框架过程
腾讯云主机环境安装爬虫框架过程及常见错误微信最近又发布了一些小程序的新能力 ，同时向个人开发者开放注册。预期又会有一些开发者开始投入小程序的怀抱。本文分享的是较早加入小程序阵营的自选股团队的经验分享，讲述他们的一些开发经验和踩过的坑，希望对大家有帮助。
相信最近几天，大家都被微信小程序  内测开始的新闻引爆了朋友圈，甚至因此引发了  的学习狂潮笑。有幸作为早期参与进来的自选股攻关小分队的我们，内心也是激动不已，希望可以尽早给大家分享一些开发经验和踩过的坑。
不过呢，由于  的开发权限还没有完全放开，有一些具体的内容还在保密阶段，我们在征求了微信开平同事的同意后，将开发过程中的一些经验和改进方案整理出来，希望可以对其他开发者提供一些参考。
在此特别提出，对于早期泄露的自选股小程序，我们想说：“真的不是臣妾的锅啊”——而首发当天的泄露版实际上是非常早期的一个版本，当时很多的设计最后并没有被采用，而即使是那样的一个也引起了相当大的反响，尤其是其亮眼的加载速度，让所有人都对小程序寄予厚望，同时也对我们的正式版本充满好奇。于是，在此，我们诚意奉上——微信小程序深度漫游指南。
框架描述：
 冒着生命危险泄漏了微信小程序的框架图↑
引用一段官方介绍：
 是微信提供的一套应用框架，通过封装微信客户端提供的文件系统、网络通信、任务管理、数据安全等基础功能，对上层提供了一套完整的   ，使得开发者能够非常方便的使用到微信客户端提供的各种基础功能，快速构建一个应用。
在页面视图层，我们使用  搭建页面的基本视图框架，使用  控制页面的视图样式。 是  提供的一套类似  的标签语言，同时也提供了一系列的基础组件，帮助我们快速构建视图。在页面中不能使用脚本代码，页面渲染所需要的数据，以及页面的交互处理逻辑都是在  中。我们提供了很方法将  中的数据与页面进行单向绑定，当  中的数据变更时，会主动触发对应的页面组件的重新渲染，这里使用  的技术，加快页面的渲染效率。同时我们为页面组件提供了 、 等事件监听相关的属性，可以与  中的提供的事件处理函数绑定在一起。实现页面向  层同步用户的交互数据。
 是每个  的服务中心，由微信客户端在页面视图层外启用异步线程单独加载运行， 中所有使用  编写的交互逻辑、网络请求、数据处理都必须在  中实现，且  中不能使用  操作相关的脚本代码。应用中的各个页面可以通过  实现数据管理、网络通讯、应用生命周期管理和页面路由管理。
所以有了这么棒的底层框架，我们才更有信心把自选股这么重的应用搬到小程序里。
从零开始推动     图形库支持
微信小程序除了在底层架构的运行机制做了大量的优化，还对重功能 切换、 切换、多媒体、网络连接等实际上是更倾向于使用  组件承载。而对于自选股来说，除了大量的数据，行情图的展示也是不可缺少的一环。而如果没有原生绘图组件的支持，那么这样的重功能一定会影响到速度，从而降低用户体验。
由于自选股的行情图是自研的前端模块，里面涉及到坐标系、几何图形、技术指标等大量模块，我们希望能够在尽可能少的修改代码就可以平滑的在小程序环境下完美运行。因此我们主动与微信开平团队交流，推动了   的组件化流程，并共同构思 了  的语法、图形  的支持。
做过的前端开发一定对截图的语法不陌生。
原生写法 
协商讨论后的支持写法
可以看到，绘图语法基本没有变化，其中是创建并返回绘图上下文对象。 其中，只是一个记录方法调用的容器，用于生成记录绘制行为的数组。跟不存在对应关系，一个生成画布的绘制动作数组可以应用于多个。而是获取当前上存储的绘图动作。输出结果如下：
 
最后一步，使用进行绘图。
 
配合微信小程序的改进
的定位是轻量的、用完即走的，我们也配合着微信贯彻这一理念。随着版本的更迭，自选股小程序也及时调整着自身的方向，越来越凸显出其不同于的特性。
一方面，尽量减少需要多屏互动的场景出现，这也就是说，很多情况下我们需要在一屏上呈现更多的数据，针对大量数据我们做出了如下优化：
数据层优化 自选股产品本来就是数据驱动的产品，而且要求数据实时性很高，在开盘的时候页面股票数据实时更新
优化 ： 函数用于将数据从逻辑层发送到视图层，同时改变对应的  的值
改变
{
     自选股
}
改变
  = {}
  = 
     = 自选股

改变
{
     自选股
}
这里需要注意的是：
、直接修改  无效，无法改变页面的状态，还会造成数据不一致
、单次设置的数据不能超过，请尽量避免一次设置过多的数据
对于以上情况，我们的处理与优化方法是：
、减少的数据量
、对数据分段处理
优化 ：本地缓存，即每个微信小程序可以有自己的本地缓存
对于缓存的获取、设置、清除，小程序分别提供了同步与异步的方法。

为了增强体验，我们在的生命周期 页面加载 页面隐藏 页面卸载函数里面添加缓存载入、设置，提高应用首次展示速度，加快页面与页面之间数据的通用性，提升用户在弱网络环境下体验。
后端优化 另一方面，鉴于本身微信场景的限制，很多 可以使用的特性在这里并不支持，例如…针对这样的实际情况，我们暂时做了如下的兼容方式。
优化：小程序对网络请求接口域名有明确要求。针对种服务器域名、、、每种只能指定一个合法域名。自选股后台业务十分复杂，使用了不同域名对业务进行划分。应对这个限制，自选股通过统一代理方式将域名收敛为一个域名，由代理层将请求转发。
优化：微信小程序文档中要求网络请求发起的是请求，自选股在统一代理层部署证书支持请求，后端机器无需改动。
优化：小程序并发请求数不超过，自选股使用动态接口将页面需要的数据进行合并，通过一个接口获取页面所需数据。
优化：小程序关于登录态与移动应用和网页应用的不同之处是抛弃了_的验证方式，而是采用_加签名的方式，为小程序与服务器交换敏感数据提供了对称加密方法。签名方法对小程序透明，后端服务实现相应的解密程序以及登录态验证和控制能力。
极致体验、极速开发
综上所述，微信小程序有着接近原生的运行速度，做了大量的框架层面的优化设计，对端和端做出了高度一致的呈现，并且准备了完备的开发和调试工具。感谢微信开平的同事，他们的不懈努力为众多开发者们打开了一扇新世界的大门。也很佩服开平的同学们，我们在开发沟通过程中提出来的多数建议都能够快速的响应并支持，给了我们非常大的成就感！
而对于更多的开发者来说，语言的低入门门槛、迅速的调试发布流程、完备的文档和微信强大的平台能力更是让人欲罢不能。我们从诞生至今跟随其一同演化发展，互相促进支撑，过程中框架结构几经山崩地裂的调整，所有页面在前一秒还是好好的，更新开发工具后面目全非。但，很幸运的是，现在工具已经趋于完善稳定，大家可以尽情地“玩耍”啦
最后还是要说，我们的开发过程尽管荆棘满布，我们仍紧追不舍，在短短的两个月时间内，不断推翻、不断重构、不断打磨体验细节，终于完成了自选股小程序的基本核心需求，初步形成了一个闭环。
我们还在不断的优化，你看到的只是冰山一角，敬请期待自选股小程序的正式亮相！

小程序开发者名单

产品：许翩翩前端：张坤、张仁元、窦宁、卓晗后端：宋景凯设计师：郝晓

相关推荐微信小程序之提高应用速度小技巧教你写一个云上 小程序新增线下、、公众号多处入口，小程序会再火起来么？内有福利导语： 由于信息过载，推荐系统基本成为互联网产品的标配， 如何快速的让自己的产品具有推荐的能力呢？稀缺专业人员投入、用户数据积累、用户冷启动问题等等都是自建推荐系统必须跨越的障碍。本文介绍如何接入腾讯云智能推荐， 快速获得上百人专业算法团队、二十亿用户画像、几乎覆盖全部网民的推荐系统能力。

本文介绍如何使用豆瓣图书的抓取图书信息，上报图书信息、用户浏览点击行为到腾讯云智能推荐系统，通过获取推荐结果。主要的步骤包括：

物料准备；

物料上报；

场景申请；

获取推荐结果；

用户行为上报；


    物料准备
首先介绍下什么物料， 物料就是我们需要推荐的物品。推荐系统通过物料的属性、用户和场景的属性以及用户的历史行为，生产推荐结果。
为了方便的获取物料属性，这里我们使用图书获取图书的基本信息。参考：=_
其中，重要的信息包括

 可以作为图书物料的唯一标识；

 与图书相关的重要信息；

： 用户评分；

： 图书的标签；

： 价格



接下来， 我们购买主机和，使用脚本遍历豆瓣图书，我们将感兴趣的属性记录到中， 获得原始的物料库，如下表所示：

    物料上报：
步骤我们已经获取到了物料库， 接下来通过腾讯云智能推荐上报上报物料，详情参考文档。
物料上报协议中， 重要的字段包括：

_：物料唯一标识， 推荐结果将返回物料， 暂时不支持中文； 图书推荐使用图书的唯一标号作为_

_： 自定义物料池， 物料池将物料分类，在获取推荐结果时，可以指定在哪个物料池获取推荐结果， 适配不同的产品场景。同一个物品可以属于多个物料池； 本示例中， 所有物品都可以出现在任意场景下， 所以， 物料没有指定物料池， 需要分物料池时， 可以添加物料池分类， 重新上传物料信息。

： 物料的标签， 是物品推荐使用的关键属性，可以使用物品的标签描述、分级类目名、品牌等等信息， 越详细的信息， 对推荐结果越有帮助。 同时， 每个物品的描述应该具有可区分性，在给用户推荐时，如果每个物品都具有相同的， 那么， 推荐系统将无法通过这个，区分出当前用户对每个物品的喜好， 也就没法产生有效的推荐，所以的描述尽量准确、具有区分性。本示例中，标签使用提供的；


物料上报协议如下所示：
{

       _ 

        \\\\\\

        ___

         \\\\

        

       _  

        

         

        

        

        

       _ 

         \\\\\\\

        

}
    场景申请：
智能推荐的所有行为都是围绕场景展开的， 首先上传适合当前场景的物料，接下来， 拉取当前场景下对用户的推荐结果；再上报用户在当前场景的流量、点击、转换等行为数据， 修正推荐结果。 场景可以理解为产品的一个推荐位， 比如很多产品有猜你喜欢的栏目。
可以在腾讯云官网智能推荐控制台创建场景， 获得场景。 本文规划两个场景： 首页推荐和详情页推荐，申请两个场景。
    获取推荐结果：
物料库上报以后， 就可以通过用户从物料库中生成推荐结果了。这里使用请求服务接口。注意， 请求服务的地址与物料上报、行为上报地址不同。重要的字段包括：

_ 场景， 步骤申请的；

_  物料池编码， 指定在特定的物料池中选择推荐结果； 如果不指定， 默认在全部物料中选择；

： 当前页面物料， 用于详情页获取推荐的场景，使用当前物料。 在本示例中，在详情页场景使用。


推荐结果请求如下所示：
{

       _ 

       _ 

        

       _ 

       _ 

        ___

       _ 

        

}
    用户行为上报：
用户行为上报接口， 上报某个时间点、某个场景下、某个用户发生了特定行为。 利用用户行为可以进一步优化推荐结果。 用户行为包括： 曝光、点击、转化、点赞等等； 行为上报时，需要保证事件发生的时间顺序，严格按照先有曝光，点击，再有转化， 否则系统会认为用户点击、转化行为行为无效。重要的字段：
Ø  _： 用户一系列行为的会话。通过_ 推荐系统可以串联用户行为。 _的生命周期从曝光开始，依次在点击、转化、点赞等行为中传递。 下一次曝光需要生成新的_；
协议如下所示：
{

        

       _ 

        ___

       _  

       _  

        

       _ 

       _  

       _ 

       _ 

       _ 

}作者：腾讯云  团队

前景
随着  这股热潮的发展，业界对人工智能发展的热情逐渐高涨，人工智能也成为了未来发展的趋势。中小型企业也期望搭上人工智能这辆列车。
过去，中小企业部署  面临诸多问题： 硬件成本高、灵活性差、一次性采购投入大，需要高昂的费用和巨大精力进行  的定制和采购，  硬件交易价格不透明，为保障服务稳定需高额的运维  成本，并需配备相应的硬件工程师和软件工程师。
同时企业接下来还会面临  芯片更新换代带来的资源闲置流转问题。虽然  知识产权 ，  提供了业务所需的硬件加速功能，但研发周期长，研发投入和风险高，令诸多企业望而却步。
 是什么
人工智能包括三个要素：算法，计算和数据。人工智能算法目前最主流的是深度学习。计算所对应的硬件平台有：、、、。由于移动互联网的到来，用户每天产生大量的数据被入口应用收集：搜索百度、通讯、微信。我们的 、微信业务，用户每天产生的图片数量都是数亿级别，如果我们把这些用户产生的数据看成矿藏的话，计算所对应的硬件平台看成挖掘机，挖掘机的挖掘效率就是各个计算硬件平台对比的标准。
通用处理器可提供高度的灵活性和易用性，可以低廉的价格生产，并且适用于多种用途和重复使用。但性能相对缺乏效率。
专用集成电路可提供高性能，但代价是不够灵活且生产难度更大。这些电路专用于某特定的应用程序，并且生产起来价格昂贵且耗时。
从灵活性而言，介于  和  两者之间的处理器，使用比较多的异构处理器目前有两个，一个是 ，一个是 。
 属于一类更通用的可编程逻辑设备，  既能提供集成电路的性能优势，又具备  可重新配置的灵活性。简单来说， 是一种可重新配置的「通用集成电路」。
 的灵活性是介于  与  之间。 的核心数量一般是  的成百上千倍，计算能力要比  多出几个数量级，也更适合进行并行计算。但是如果计算里面有大量的分支，或者算法的数据前后存在依赖关系，使得算法无法并行运行，则  的性能优势会被大大减弱。
相比 ， 的可操控粒度更小，具备更高的灵活度和算法适应性。 能够简单地通过使用触发器来实现顺序逻辑，并通过使用查找表来实现组合逻辑。当算法需要并行计算能力时，可以将大部分的逻辑资源都用来做计算，达到更高的计算效率；当算法需要更多的控制流程时，可以将大部分的逻辑资源都用来做控制。实际的  内部也存在大量的硬核来完成固定的功能。正是基于  资源的高可控度，可以带来算法实现时的灵活度。
 全称「可编辑门阵列」   ，其基本原理是在  芯片内集成大量的数字电路基本门电路以及存储器，而用户可以通过烧写  配置文件来来定义这些门电路以及存储器之间的连线。这种烧入不是一次性的，即用户今天可以把  配置成一个图像编解码器，明天可以编辑配置文件把同一个  配置成一个音频编解码器，这个特性可以极大地提高数据中心弹性服务能力。所以说在  可以快速实现为深度学习算法开发的芯片架构，而且成本比设计的专用芯片要便宜，当然性能也没有专用芯片强。 是一锤子买卖，设计出来要是发现哪里不对基本就没机会改了，但是  可以通过重新配置来不停地试错知道获得最佳方案，所以用  开发的风险也远远小于 。



处理器
优点
缺点




通用处理器
高度的灵活性和易用性，可以低廉的价格生产，并且适用于多种用途和重复使用
性能相对缺乏效率


专用集成电路
高性能
不够灵活，生产难度更大


图形处理器
更适合进行并行计算
如果计算里面有大量的分支，或者算法的数据前后存在依赖关系，使得算法无法并行运行，则  的性能优势会被大大减弱。


可编辑门阵列
提供集成电路的性能优势，又具备  可重新配置的灵活性， 可操控粒度更小，具备更高的灵活度和算法适应性
性能没有专用芯片强



腾讯云国内首发 
 月  日，腾讯云推出国内首款高性能异构计算基础设施—— 云服务器，以云服务方式将大型公司才能长期支付使用的  推广到更多企业。
腾讯云带来的革命性进展是：将  部署时间从数月缩短到数分钟，企业可按需付费使用 ，极大降低  的使用成本，实现高性能  硬件加速处理。企业可以通过  云服务器进行  硬件编程，可将性能提升至通用  服务器的  倍 以上。同时腾讯云率先在国内提供第三方  知识产权市场，通过腾讯云服务市场， 开发者和使用者可以更高效地交易。
长期以来， 行业内的提供者和使用者一直缺乏交易平台和信用保证，导致交易环节冗长，很难达成交易。腾讯云服务市场搭建一个简单可靠的  知识产权交易市场。
对于  使用者而言，可以在腾讯云服务市场购买已开发并验证好的  知识产权功能，可节约长达数月的  研发周期，同时采用按需使用付费的模式，能最大化地节省硬件投入成本。
而  开发者可以通过使用腾讯云  的开发框架，显著提升研发效率，更专注于核心功能开发，将图像处理功能、深度学习功能等已有的成熟  知识产权通过简单封装适配，集成并投放到腾讯云服务市场，开放给  使用者使用，分摊  知识产权的研发成本。
 应用案例
 应用案例一

项目背景：随着移动互联网的发展，基于用户社交平台的腾讯每天用户上传的图片越来越庞大，公司目前用于图片转码的业务主要有  相册、微信及其他业务。图片格式中有  格式、 格式等， 图片格式比  图片格式存储空间小 。如果落地存储采用  格式替代  格式，可以减少三分之一存储空间；而传输分发用  格式，还可以降低传输流量，从而提升用户的图片下载体验。而采用  的问题在于  压缩计算复杂度是  压缩的  倍以上，采用  进行  转码成本很高，导致很难在业务中全面推广。为了增强图片转码能力，我们使用  对图片转码进行加速。

项目结果：完成  格式图片转成  格式图片，测试图片大小为 ， 处理延时相比  降低  倍 ，处理性能是机器的  倍 ，机型单位成本是  机型的 。


表  和  的计算性能对比



机型
   





延时




吞吐率张




成本对比





 应用案例二

项目背景：传统上，、百度等搜索引擎公司以  作为预估模型。早在  年开始，百度开始尝试将  算法作用于搜索广告，并在 年  月就开始服务于百度搜索广告系统。近年来异军突起的今日头条在技术上也使用了  算法，提高新闻的点击率。但是  算法对系统的计算量明显增大，如果还是用  进行计算，无法满足系统的延时和吞吐率要求。 算法模型为  的  层模型，要求  个样本的  计算时延要小于 。如果用  计算，    机器的计算时延为 ，无法满足要求计算时间见表。因此，我们用  对  计算进行加速，使  个样本的  计算时延小于 。

项目结果：我们在使用  的  资源的情况下，将  个样本的  计算时延减小为 ，吞吐率达到  集合 个样本为 １ 个集合，不仅达到了系统对低延时的要求，而且极大地提高了系统的吞吐能力，处理延时降低  倍，处理吞吐率提高  倍，成本是  机型的 。说明  在  计算加速上有较明显的优势。


表  和  的计算性能对比



机型
  





延时




吞吐率集合




成本对比





 应用案例三

项目背景：深度学习近年来在语音识别、图片分类和识别、推荐算法等领域发挥了越来越大的作用。深度学习基于深度神经网络理论，用在图片分类的神经网络是其中的一个分支：卷积神经网络。随着移动互联网的发展，基于用户社交平台的腾讯每天用户上传的图片越来越庞大，并且增长速度很快。为了增强图片检测的处理能力，降低图片检测成本，我们使用  对  计算进行加速。

项目结果： 完成  算法的  模型， 处理性能是  机器的  倍， 机型单位成本是  机型的 。


小结
当前  火爆，得益于  的高密度计算能力以及低功耗的特性， 率先在深度学习在线预测方向广告推荐、图片识别、语音识别等得到了较大规模的部署。
用户也常常将  与  进行对比， 的易编程性、高吞吐与  的低功耗、易部署等特性也各有千秋。相较于  以及 ， 的低延时以及可编程性也是其核心竞争能力。
使用腾讯云  云服务，你只需单击几下即可在几分钟内轻松获取并部署你的  计算实例。你可以在  实例上编程，为你的应用程序创建自定义硬件加速。我们为你提供可重编程的环境，可以在  实例上多次编程，而无需重新设计硬件，让你能更加专注于业务发展。

相关推荐
国内首款  云服务器，性能是通用  服务器  倍以上简介
此次席卷乌克兰等全球多个国家的勒索病毒，与之前的  病毒极为相似，二者都会修改受害者电脑的 ，并且在电脑重启后，展示虚假的磁盘扫描界面，同时对磁盘  进行加密操作，在加密完毕后向受害者展示敲诈信息，勒索赎金。然而，有安全厂商仍然审慎地表示，此次病毒并非  勒索软件的变种。
腾讯安全反病毒实验室对样本的加密代码部分进行了分析，着重留意了代码与原始  勒索病毒的异同。

一、文件加密逻辑
之前的  勒索病毒的加密重点在于磁盘数据，在写完恶意  之后，会使系统强制重启，直接进入  引导模式；只有在写  失败的情况下，病毒才会使用备用方案，利用  勒索病毒加密磁盘文件。
而此次爆发的勒索病毒，会使用计划任务执行重启操作，在电脑尚未重启之前，病毒还会开启一个线程执行文件加密操作：

而在文件加密的过程中，只会对文件的前  字节进行加密，以此提升加密的速度：

二、磁盘加密逻辑
磁盘加密整体流程

修改磁盘引导扇区
勒索病毒样本在写入磁盘时，分为四个部分写入不同的扇区。
首先是恶意  代码部分，从扇区  开始一共写入了  个扇区，这部分包含伪装磁盘扫描界面、加密 、显示勒索文字、接受用户输入密码并尝试解密等完整功能：

其后，病毒又写入了 、、 三个扇区的内容：

从后往前看，三个扇区的功能分别如下：
 扇区存放的是病毒一开始从磁盘中读取的原始  内容，与  进行  操作的结果：


 扇区存放的是长度为  字节的  的内容：


在加密过程中，此扇区也会使用与  相同的密钥进行加密，用于在用户输入密钥之后进行解密验证：

 扇区存放的是加密流程中用到的一些配置内容，比如加密密钥等。在之前的  敲诈病毒中，此扇区结构如下：

参考：   
而此次病毒写入内容的格式也基本一致：

所不同的只是显示的暗网地址被换成了比特币地址。
 加载与勒索
 启动后，通过  = 将  到  扇区的内容拷贝到内存  处，并在随后执行。


在经过标志位 扇区中的 的比较，判断当前磁盘是否已经被加密，如果被加密则直接显示敲诈信息，否则则展示虚假的磁盘检查信息


随后，程序会调用  算法对  进行对称加密， 是  大小的 _， 是  大小的 _。



病毒作者还对  算法的初始化参数做了修改，由原始算法的  变成了如下字符串：

通过此算法，最终会把  逐个字节的进行对称加密。加密完成后，密钥会从磁盘中删除，防止加密数据被还原。

而 _ 被展示在敲诈界面上，作为受害者个人标识：

可疑的 _
引起我们注意的即是这个 _。在之前的  敲诈病毒中，此数据是使用密钥经过 、、 等多次运算后得到的一个  字符串，目的是使用此数据与病毒作者手中的私钥一起可以计算出加密  使用的密钥，即前面被置空的 _ 部分。
然而，在此次的敲诈病毒代码中，我们发现，病毒在生成随机数据之后，直接使用此数据生成了  字符串，并没有使用什么复杂的算法，也没有与加密密钥产生任何关联：

这就意味着，即使此次病毒作者在公布的邮箱中获取了受害者的标识，也无法将其与受害者的加密密钥对应起来。很有可能，此次病毒的始作俑者并不想帮受害者解密  部分。
结论
通过前面的分析可以看出，此次勒索病毒的作者使用了与之前  病毒类似的代码，通过  中代码、数据格式、加密流程等多处的高度一致性可以判定，这次的新型  病毒与之前的  病毒有着千丝万缕的联系。同时也可以注意到，与  病毒前几个版本不同的是，新型  病毒一方面使用了其它逻辑加密磁盘文件，另一方面并没有想要为受害者解密磁盘。我们猜测，此次勒索病毒的作者可能并非  勒索病毒的原始作者。一、我们讲什么？
我们讲两个东西：
、背后的工作原理是什么？
、以为例，讲述框架在背后扮演什么样的角色？
二、我们为什么要了解原理？
我们假定你对已经有一定了解，或者用做过了一些东西，这个时候，你可能碰到了这样一些问题：
、很多东西还是做不出来，甚至没有任何思路；
、碰到无法解决，甚至没有方向；
、性能出现问题，完全不知道如何去优化。
这个时候，我们需要了解更多。
三、先了解一个基础概念
、什么是矩阵？
简单说来，矩阵用于坐标变换，如下图：

、那它具体是怎么变换的呢，如下图：

、举个实例，将坐标平移，如下图：

如果这时候，你还是没有理解，没有关系，你只需要知道，矩阵用于坐标变换。
四、的工作流程
、 
在了解一门新技术前，我们都会先看看它的开发文档或者。
查看的绘图，我们会发现它能画直线、矩形、圆、弧线、贝塞尔曲线。于是，我们看了看绘图，发现：

也就是说，再复杂的图形，也是通过顶点，绘制出一个个三角形来表示的：

、绘制流程
简单说来，绘制过程包括以下三步：
、获取顶点坐标
、图元装配即画出一个个三角形
、光栅化生成片元，即一个个像素点

接下来，我们分步讲解每个步骤。
、获取顶点坐标
顶点坐标从何而来呢？一个立方体还好说，如果是一个机器人呢？
没错，我们不会一个一个写这些坐标。
往往它来自三维软件导出，或者是框架生成，如下图：

写入缓存区是啥？
没错，为了简化流程，之前我没有介绍。
由于顶点数据往往成千上万，在获取到顶点坐标后，我们通常会将它存储在显存，即缓存区内，方便更快读取。
、图元装配
我们已经知道，图元装配就是由顶点生成一个个图元即三角形。那这个过程是自动完成的吗？答案是并非完全如此。
为了使我们有更高的可控性，即自由控制顶点位置，把这个权力交给了我们，这就是可编程渲染管线不用理解。
需要我们先处理顶点，那怎么处理呢？我们先看下图：

我们引入了一个新的名词，叫“顶点着色器”，它由 编写，由以字符串的形式定义并传递给生成。
比如如下就是一段顶点着色器代码：
  
  {
  _ =   
}
 修饰符用于声明由浏览器传输给顶点着色器的变量值；即我们定义的顶点坐标；
_是一个内建的传出变量。
这段代码什么也没做，如果是绘制图形，没问题，但如果是绘制图形，即传入的顶点坐标是一个三维坐标，我们则需要转换成屏幕坐标。
比如：  转换为 ，这个过程类似我们用相机拍照。
、顶点着色器处理流程
回到刚才的话题，顶点着色器是如何处理顶点坐标的呢？

如上图，顶点着色器会先将坐标转换完毕，然后由进行图元装配，有多少顶点，这段顶点着色器程序就运行了多少次。
你可能留意到，这时候顶点着色器变为：
  
  
  {
  _ =     
}
这就是应用了矩阵，将三维世界坐标转换成屏幕坐标，这个矩阵叫投影矩阵，由传入，至于这个怎么生成，我们暂且不讨论。 
、光栅化
和图元装配类似，光栅化也是可控的。

在图元生成完毕之后，我们需要给模型“上色”，而完成这部分工作的，则是运行在的“片元着色器”来完成。
它同样是一段 程序，模型看起来是什么质地颜色、漫反射贴图等、灯光等由片元着色器来计算。
如下是一段简单的片元着色器代码：
    
  { 
    _ =     
}
_即输出的颜色值。
、片元着色器处理流程

如上图，顶点着色器是有多少顶点，运行了多少次，而片元着色器则是，生成多少片元像素，运行多少次。
、的完整工作流程
至此，实质上，经历了如下处理流程：
、准备数据阶段
在这个阶段，我们需要提供顶点坐标、索引三角形绘制顺序、决定贴图坐标、法线决定光照效果，以及各种矩阵比如投影矩阵。其中顶点数据存储在缓存区因为数量巨大，以修饰符传递给顶点着色器；
矩阵则以修饰符传递给顶点着色器。
、生成顶点着色器
根据我们需要，由定义一段顶点着色器 程序的字符串，生成并且编译成一段着色器程序传递给。
、图元装配
根据顶点数量，挨个执行顶点着色器程序，生成顶点最终的坐标，完成坐标转换。
、生成片元着色器
模型是什么颜色，看起来是什么质地，光照效果，阴影流程较复杂，需要先渲染到纹理，可以先不关注，都在这个阶段处理。
、光栅化
能过片元着色器，我们确定好了每个片元的颜色，以及根据深度缓存区判断哪些片元被挡住了，不需要渲染，最终将片元信息存储到颜色缓存区，最终完成整个渲染。

五、究竟做了什么？
我们知道，帮我们完成了很多事情，但是它具体做了什么呢，他在整个流程中，扮演了什么角色呢？
我们先简单看一下，参与的流程：

黄色和绿色部分，都是参与的部分，其中黄色是部分，绿色是 部分。
我们发现，能做的，基本上都帮我们做了。

辅助我们导出了模型数据；

自动生成了各种矩阵；

生成了顶点着色器；

辅助我们生成材质，配置灯光；

根据我们设置的材质生成了片元着色器。


而且将基于光栅化的 ，封装成了我们人类能看懂的  。
、顶点处理流程
从工作原理的章节中，我们已经知道了顶点着色器会将三维世界坐标转换成屏幕坐标，但实际上，坐标转换不限于投影矩阵。
如下图：

之前在图元装配之后的结果，由于我们认为模型是固定在坐标原点，并且相机在轴和轴坐标都是，其实正常的结果是这样的：

、模型矩阵
现在，我们将模型顺时针旋转，所有顶点位置肯定都变化了。
 = 

但是，如果我们直接将顶点位置用计算出来，那性能会很低顶点通常成千上万，而且，这些数据也非常不利于维护。
所以，我们用矩阵将这个旋转信息记录下来。
、视图矩阵
然后，我们将相机往上偏移。
 = 

同理，我们用矩阵将移动信息记录下来。
、投影矩阵

这是我们之前介绍过的了，我们用记录。
、应用矩阵
然后，我们编写顶点着色器：
_ =       
这样，我们就在中，将最终顶点位置计算出来了。
实际上，上面所有步骤，都帮我们完成了。
、顶点处理具体流程
所以有了，多次矩阵计算，多次坐标换算。具体是怎么做的呢？

坐标转换流程：
、首先，顶点坐标存储在中；
、随后，如果模型设置了旋转、缩放、移动，那将这些转换信息存储在的模型矩阵里；
、同样，相机转换信息存储在视图矩阵_；
、然后生成顶点着色程序，如上图。
、片元着色器处理流程
我们已经知道片元着色器负责处理材质、灯光等信息，但具体是怎么处理呢？

、完整的运行流程

当我们选择材质后，会根据我们所选的材质，选择对应的顶点着色器和片元着色器。
中已经内置了我们常用着色器。

文章来源： 是一个基于  的深度学习库。 源码库的抽象层次少，结构清晰，代码量适中。相比于非常工程化的 ， 是一个更易入手的，非常棒的深度学习框架。
对于系统学习 ，官方提供了非常好的入门教程 ，同时还提供了面向深度学习的示例，同时热心网友分享了更简洁的示例。
 
不同于 ， 等低层程序库，或者 、 等高层 ， 是一种自成体系的深度学习库图。

图 几种深度学习程序库对比
如图所示， 由低层到上层主要有三大块功能模块。

图  主要功能模块
 张量计算引擎 
 计算引擎，类似  和 ，基本对象是类比  中的  或  中的 。除提供基于  的常用操作的实现外， 还提供了高效的  实现，这对于深度学习至关重要。
 自动求导机制
由于深度学习模型日趋复杂，因此，对自动求导的支持对于学习框架变得必不可少。 采用了动态求导机制，使用类似方法的框架包括： ，。作为对比，， 采用静态自动求导机制。
 神经网络的高层库
 还提供了高层的神经网络模块。对于常用的网络结构，如全连接、卷积、 等。同时， 还提供了常用的目标函数、 及参数初始化方法。
这里，我们重点关注如何自定义神经网络结构。
 自定义 

图  
 是  组织神经网络的基本方式。 包含了模型的参数以及计算逻辑。 承载了实际的功能，定义了前向和后向的计算逻辑。
下面以最简单的  网络结构为例，介绍下如何实现自定义网络结构。完整代码可以参见。
 
 是  自动求导机制的核心类。 是无参数或者说无状态的，它只负责接收输入，返回相应的输出；对于反向，它接收输出相应的梯度，返回输入相应的梯度。
这里我们只关注如何自定义 。 的定义见源码。下面是简化的代码段：
 
      
         

      _
         
 和  的输入和输出都是  对象。
 对象是  的，即可以通过的方式进行调用。其中调用的输入和输出都为  对象。下面的代码示例了如何实现一个  激活函数并进行调用：
 
   

 ：
      
        __

         = =
         

      _
         = _

        _ = _
        _   = 
         _

 
 ____ == ____
         

      _  
       =  

       =  _=
       = 
        

      
        
如果  中需要用到  的输入，需要在  中显式的保存需要的输入。在上面的代码中， 利用__函数，将输入暂时保存，并在  中利用_   对象 取出。
显然， 的输入应该和  的输入相对应；同时， 的输出应该和  的输入相匹配。

由于  可能需要暂存  ，因此，建议不复用  对象，以避免遇到内存提前释放的问题。如示例代码所示，的每次调用都重新生成一个  对象，而不能在初始化时生成在  中反复调用。

 
类似于 ， 对象也是  是，输入和输出也是 。不同的是， 是可以有参数的。 包含两个主要部分：参数及计算逻辑 调用。由于激活函数没有参数，这里我们以最基本的全连接层为例来说明如何自定义。
全连接层的运算逻辑定义如下 
 
   

 

         =
         __  

          =  
             
              = _

          

       _
            = _

         _ = _ = _ = 
          __
             _ = _ 
          __
             _ = _ 
               __
             _ = _

             
              _ _ _
         
              _ _
__ 为一个元素为  型的 ，长度与  的参数数量相同，用来标识各个输入是否输入计算梯度；对于无需梯度的输入，可以减少不必要的计算。
此处为  定义了基本的计算逻辑， 只需要在初始化时为参数分配内存空间，并在计算时，将参数传递给相应的  对象。代码如下：
 
   

 

     ____ _ _ =
          ____
         _ = _
         _ = _
          = _ _
          
              = _
         
            _ 

      
            
需要注意的是，参数是内存空间由  对象维护，但  需要包装为一个 对象。 是  的特殊子类，仅有是不同是  默认_为 。 是自动求导机制的核心类，此处暂不介绍，参见教程。
 自定义循环神经网络
我们尝试自己定义一个更复杂的  ——。这里，我们只定义最基础的  图，基本的计算公式如下：
=⋅⋅−

图 【来源】
更复杂的 、 或者其他变种的实现也非常类似。
 定义 
 
    

 
     ____ _ _
         ____
        _ = _
        _ = _

        _ = _ _
        _ = _ _
        _ = _
        _ = _

        _

     _
         =   _
           
            _ 

       
         =  _ _   _ _
         = 

         
 定义完整的 
 
   

 
     ____ _ _
         ____
        _ = _
        _ = _

         = _ _

       _
        _ = 

         = _
         = 
           _
             =    
            

         
可运行的完整代码见。
讨论
 的  结构是传承自 ，这一点也同样被   所借鉴。 在  等一些早期的深度学习框架中， 是由于若干  ，经由不同的拓扑结构组成的。而在  中没有  和  是区分，一切都是  的 。 的调用的输入和输出都是  由  封装，用户可以非常自然的构造任意有向无环的网络结构。
同时，  的  机制封装的比较浅，可以比较容易的定制反传或修改梯度。这对有些算法是非常重要。
总之，仅就自定义算法而言， 是一个非常优雅的深度学习框架。导语：这两年比较火的几个概念，大数据，云计算，，区块链等经常在我们耳边萦绕。区块链作为比特币等电子货币的底层技术，被誉为继电气革命，工业革命，互联网后又一重大发明。本文是笔者作为小白，参阅了区块链相关书籍资料后了，整理的随手笔记，在项目团队做了分享，比较初级简洁，希望对第一次接触区块链的小伙伴有所帮助。

区块链作为新兴技术，已经受到了各大巨头公司的重视，包括京东、百度、阿里等都有所布局和研究，腾讯作为中国最早一批涉足区块链研究的企业之一，也有专门的区块链团队，前不久对外发布了腾讯区块链白皮书，公司的区块链主页如下，有兴趣的小伙伴可以看下： 。在介绍穿越的原理、技术、方法前，我们先来看看几个背景知识：
 和
网络地址转换  ，早期的指的是 静态，它在技术上比较简单一点，仅支持地址转换，不支持端口映射，这就需要对每一个当前连接都要对应一个地址，因此要维护一个公网的地址池。我们可以看出， 一个比较明显的缺陷就是：同一时刻只能少量位于后面的机器能够和外部交互要看有几个外网。后期的基本都指的是网络地址端口转换了，这种方式支持端口的映射并允许多台主机共享一个公用地址，这样就可以支持同时多个位于后面的机器和外部进行交互了。支持端口转换的又可以分为两类：源地址转换和目的地址转换。下面说的都是指。
 带来的问题
在缓解地址资源的紧张的同时，也带来了不少问题：
 使会话的保持时效变短。
 在实现上将多个内部主机发出的连接复用到一个上，这就使依赖进行主机跟踪的机制都失效了
 工作机制依赖于修改包头的信息，这会妨碍一些安全协议的工作
 限制了使用一些高层协议、、的两端的通信
对于问题，其主要原因是，设备建立的内网、端口到外网、端口的映射的表项是有一个保活期的。如果在一个超时时间内，该映射上没有实际数据的传输，那么会过期并回收这个映射表项给其他通信链路用和端口资源有限，通信的链路是无限。为了避免这种通信链路提前被中断的情况，很多应用层协议在设计的时候就考虑了一个连接保活的机制，即在一段时间没有数据需要发送时，主动发送一个能感知到而又没有实际数据的保活消息，这么做的主要目的就是重置的会话定时器。
对于问题，其主要原因是，对于后面的多主机，在外部看来都是同一个主机设备，于是来之同一个的数据包一定是来之同一个主机的前提判断就会不准确了，这样一下基于这个前提的机制例如：的_的回收和重用都会有问题。
对于问题，其主要原因是，篡改了地址、传输层端口号和校验和。
对于问题，其主要原因是，一般情况下，是不允许外部的节点主动连接或发送数据包给后面的主机的这里的主动指的是，在一段时间内，首先发送数据包的一方为主动方。表现出这样的行为，主要基于下面的几点考虑：
 出于安全考虑，避免来自网络外部的攻击，隐藏并保护网络内部的计算机
 位于后面的很多主机，对于主动进来的数据包，一般不知道该路由给内部的哪个主机设备上没有相关转发表项。
由于这种特性，那么在环境下，实现通信的完整解决方案包括几个部分呢？相关的原理、方法、技术有哪些？对于一个完整的通信解决方案，其实现包括下面两个步骤：
 首先在的协助下，通信两端尝试相互连接，如果两端在尝试互联不成功后，那么就将失败结果反馈给转入步骤
 这个步骤比较简单粗暴了，就是服务器中转，简单的来讲就是将要发给的数据发给，然后由帮忙转发给，同样对于来说也一样。
对于实现通信，步骤是大家下功夫最多的，其原因比较简单，就是步骤需要消耗较多的服务器资源，成本比较高。步骤实现两个节点间的直接通信，在资源消耗和效率上都是比较好的。
 通信穿越的技术、方法
目前常见的通信穿越的技术、方法主要有：
 应用层网关
 中间件技术
 打洞技术 
 服务器中转技术
 应用层网关
应用层网关是解决对应用层协议无感知的一个最常用方法，已经被设备厂商广泛采用，成为设备的一个必需功能。
 原理
利用带有功能的对特定应用层协议的支持和理解，在一个网关检测到新的连接请求时，需要判断是否为已知的应用类型，这通常是基于连接的传输层端口信息来识别的。在识别为已知应用时，再调用相应功能对报文的深层内容进行检查，当发现任何形式表达的地址和端口时，将会把这些信息同步转换，并且为这个新连接创建一个附加的转换表项。这样，当报文到达公网侧的目的主机时，应用层协议中携带的信息就是网关提供的地址和端口。例如：下图，对于使用主动模式的协议方式，就需要的支持了。

由于协议通信需要两个连接，一个是命令链路，用来在客户端与服务器之间传递命令；另一个是数据链路，用来上传或下载数据。如上图，位于后面的 首先发起一个连接命令链路连上外网 ，然后发送报文，说自己在端口接收数据，然后进过处理报文变成，，同建立其一条， —，映射。这样 发往，的数据就会被转到，，从而实现数据传输如果没经过处理，那么 直接连接，是无法连接上的。
 限制
技术是利用本身的支持来进行的穿越，这个方案有很大限制，主要的原因是都是为特定协议的特定规范版本而开发的，然而不管是协议本身，还是协议的数量都在变化，这就使得适应性不强。
 中间件技术
这是一种通过开发通用方法解决穿越问题的努力。与前者不同之处是，技术中网关是这一解决方案的唯一参与者，而中间件技术中客户端会参与网关公网映射信息的维护。就是这样一种方法，中文全称为通用即插即用，是一个通用的网络终端与网关的通信协议，具备信息发布和管理控制的能力。
 原理
只要理解客户端的请求并按照要求去分配响应的映射转换表，不需要自己去分析客户端的应用层数据。网关映射请求可以为客户动态添加映射表项。此时，不再需要理解应用层携带的信息，只转换地址和端口信息。而客户端通过控制消息或信令发到公网侧的信息中，直接携带公网映射的地址和端口，接收端可以按照此信息建立数据连接。网关在收到数据或连接请求时，按照建立的表项只转换地址和端口信息，不关心内容，再将数据转发到内网。
 限制
这种方案需要网关、内部主机和应用程序都支持技术，且组网允许内部主机和网关之间可以直接交换信令才能实施。
 打洞技术 
 技术是工作在运输层的技术，可以屏蔽上层应用层的差异，并且不需要网关特定的支持，因此其通用性比较强，应用性也比较广。
 原理
打洞技术的原理比较简单，就是内网的节点需要在上建立自己的一条转发映射关系这就是所谓的在上打下一个洞，然后外网的节点就通过这个”洞”来进行通信。为描述方便，我们将一对地址和端口信息的组合称之为一个，打洞原理可以简化为下面三个过程：
 首先位于后的节点需要向外发送数据包，以便让建立起内网、和外网、的映射关系；
 然后通过某种方式将映射后的外网通知给对端节点；
 最后往收到的外网发送数据包，然后该数据包就会被转发给内网的
上面三个过程比较简单，然而细心的同学会有些疑问：
步骤中的映射关系的建立有什么规律的么怎样才能获取到映射关系呢？
通知对端节点的方式一般是怎么样的？
步骤一定可以实现么？也就是往收到的外网发送数据包，就一定能够被转发给内网的吗？
对于疑问，如果全部会被转发给内网，那会不会太不安全了，只要知道内网的映射后的外网，就可以给穿透给内网发送数据，这样内网不就很容易遭到攻击了？如果全部都不转发给内网，这样只能向外发数据，而无法收到外面的数据，严重影响的正常通信。那么，这就比较明了了，我们需要的是一部分可以转发，另外一部分不转发。这就涉及到对外来数据包的一个过滤规则了，而疑问提到的映射关系建立的规则，这涉及到的的映射规则。那么问题来了，有什么方法可以知道的映射规则和对外来数据包的过滤规则呢？
 方法
由上面原理的讨论我们知道，要实现打洞穿越，首先需要知道的行为规则的映射规则和对外来数据包的过滤规则，这样才能更好地实现打洞穿越。那有哪些行为类型？有什么办法来侦测的行为呢？
 行为类型与侦测方法
的行为类型和侦测方法是由首先在中定义，英文全称是     协议来描述的，协议包括了、、、几个系列文档。早期的协议是由经典的来描述，其定义的行为类型如下：

     完全锥形
所有从同一个内网和端口号发送过来的请求都会被映射成同一个外网和端口号，并且任何一个外网主机都可以通过这个映射的向这台内网主机发送包。也就是外网所有发往的数据包都会被转发给。由于对外部请求的来源无任何限制，因此这种方式虽然足够简单，但却不安全。

     限制锥形
它是 的受限版本：所有来自同一个内网的请求均被映射成同一个外网，这与 相同。但不同的是，只有当内网曾经发送过报文给外部主机假设其地址为后，外部主机发往的数据包才会被转发给。这意味着，设备只向内转发那些来自于当前已知的外部主机的数据包，从而保障了外部请求来源的安全性

      端口限制锥形
它是  的进一步受限版，与限制锥形很相似，只不过它包括端口号。只有当内网曾经发送过报文给外部包括和端口了，发往的数据包才会被转发给。端口号这一要求进一步强化了对外部报文请求来源的限制，从而较 更具安全性。

    对称
上面的所有的 中，映射关系只和内网的源相关，只要源不变其都会被映射成同一个。而对称的映射关系不只与源相关，还与目的相关。也就是源发往目的的请求被映射为，而源发往目的的请求，则被映射为了。此外，只有收到过内网主机发送的数据的外网主机才可以反过来向内网主机发送数据包。
经典  定义的  行为类型是将的  映射规则和 过滤规则统一来归类的，这样对 类型的归类过于笼统，使得许多  不完全符合由它定义的类型。于是后来，被废弃并由来替代，在中，将  映射规则和 过滤规则分开来，定义了种  映射规则和种 过滤规则，一共有种组合。为什么是种呢？其实理由很简单，对于一个特定的内网源，影响其映射关系的因素不外乎就种情况：
 目的和目的端口都无关
 目的和目的端口都相关
 仅仅目的相关
 仅仅目的相关
对于仅仅考虑一下信息有点鸡肋，基本和差不多，于是把去掉了。同样，对于过滤规则也一样。种  映射规则和  过滤规则如下：
 
  
对于一个内网的，其映射的外网是基本固定的，不会随着通信外部主机的不同而变化。

    
对于一个内网的，如果与之通信的外部为，那么就会被映射成；如果与之通信的外部为，那么就会被映射成。也就是只要之通信的外部为发生变化，那么映射的外网就会变化。

  
对于一个内网的，如果与之通信的外部为，那么就会被映射成；如果与之通信的外部为如果的和的相同，那么同样会被映射成，否则就会被映射成。也就是只要之通信的外部为的发生变化，那么映射的外网就会变化。

 
  
对于这种过滤类型，在在自己的一个外网收到数据包，只要找到与之对应的内网，就会转发这个数据包给相应的内网，不管这个数据包的来源是那里。一般来说，这样过滤规则的是比较少的，因为这样的安全系数比较低

    
对于这种过滤类型，在自己的一个外网收到来源是数据包，这个时候要判断自己是否曾经通过自己的给发送过数据包，如果曾经发过，那么就允许该数据包通过并路由给内网与之对于的内网；如果没发过，那么会不允许该数据包通过。

  
对于这种过滤类型，在自己的一个外网收到来源是数据包，这个时候要判断自己是否曾经通过自己的给和的相同的机器发送过数据包这里会忽略端口，如果曾经发过，那么就允许该数据包通过并路由给内网与之对于的内网；如果没发过，那么会不允许该数据包通过。
只是定义了协议的相关属性、机制、报文结构以及一些相关的安全注意点等等，并有没对怎么进行完整的类型侦测做介绍。而对完整类型侦测过程主要由这个文档来描述。完整的类型侦测的过程主要在文档的和节，主要分为映射规则   和过滤规则   ，下面对具体的侦测过程做介绍：
要进行类型的侦测，需要一个具有双公网的服务器来协助侦测，我们称该服务器为 。假设 的双分别为_和_ 监听的两个端口分别为_和_，客户端的内网和端口分别为_和_。
 客户端以__给 的__发送一个请求， 以__给客户端的__回复响应，响应内容大体为：映射后的地址和端口为：__， 的另外一个地址和端口为：__。这个时候客户端判断，如果__ == __，那么该客户端是拥有公网的，类型侦测结束。

 客户端以__给 的__相对步骤 改变了发送一个请求， 以__给客户端的__回复响应，响应内容大体为：映射后的地址和端口为：__。这个时候客户端判断，如果__ == __，那么是  的映射规则，也就是同样的内网地址__经过这种映射后的__是固定不变的；如果__ = __那么就要进行下面的第步测试。

 客户端以__给 的__相对步骤 和改变了发送一个请求， 以__给客户端的__回复响应，响应内容大体为：映射后的地址和端口为：__。这个时候客户端判断，如果__== __，那么是  的映射规则，也就是只要是目的是相同的，那么同样的内网地址__经过这种映射后的__是固定不变的；如果__= __，那么是    ，只要目的和中有一个不一样，那么同样的内网地址__经过这种映射后的__是不一样的。
以上三个步骤是进行 的侦测，下面两个步骤是进行 侦测
 客户端以__给 的__发送一个请求请求中带 来要求 改变和来响应， 以__给客户端的__回复响应。如果客户端能收到 的响应，那么是 的过滤规则，也就是只要给客户端的__映射后的__地址发送数据都能通过到达客户端的__这种过滤规则的估计很少。如果不能收到 的响应，那么需要进行下面的第五步测试。

 客户端以__给 的__发送一个请求请求中带 来要求 改变来响应， 以__给客户端的__回复响应。如果客户端能收到 的响应，是 的过滤规则，也就是只要之前客户端以__给为_的主机发送过数据，那么在映射的有效期内，为_的主机以任何端口给客户端的__映射后的__地址发送数据都能通过到达客户端的__；如果不能收到响应，是   的过滤规则，也即是只有之前客户端以__给目的主机的__发送过数据，那么在映射的有效期内，只有以__给客户端的__映射后的__地址发送数据才能通过到达客户端的__。
通过以上个步骤就能完成完整的类型侦测。将映射规则和过滤规则组合起来就形成中不同的行为类型。
   和 组合对应于中的  
  和 组合对应于中的  。
   和   组合对应于中的   。
    和   组合是中所说的 。
可见只描述了种组合行为类型中的种。最后一个文档，定义了一些协议的测试数据用于测试 的正确性。
 打洞过程
“打洞”方式穿越有两种形式：”打洞”和”打洞”。原理上，”打洞”与”打洞”是没有本质的区别的。然而在实现上，”打洞”的成功率远没”打洞”的成功率高，其主要原因有三：
 有些防火墙策略对协议不是很友好
有些的防火墙策略不允许来路不明的外部向内网机器发起连接。由于是有连接的，比较容易分清哪些是    内网机器主动进行通信的外部节点，这样防火墙策略比较明确。而是无连接的，没有连接来标明一个数据流，协议比较简单，这样支持的比较多。

 协议本身
由于的_状态引起，同一个后面的其他主机发起的连接被误判。具体可以看下面的文章


 协议的实现
因为标准的  是围绕编程而设计的。这个通过允许一个流套接字初始化一个向外的连接，通过和 监听一个外入的连接，一个套接字不能既用来监听又用来初始化向外的连接。更进一步讲， 套接字通常与本地主机上的端口一一对应：一个套接字绑定到本地主机机上的某个端口后，另一个套接字就不能再绑定到该端口。然而打洞要成功，需要一个本地的端口既可以监听外入的连接，同时又可以发起多个向外的连接。幸运的是，所有主流的操作系统都支持一个特殊的选项_，它运行应用程序绑定多个设置了该选项的套接字到同一端口。系统引入了_选项来控制端口重用，从而把端口重用和地址重用相分离。在这样的系统中，两个选项都需要被设置。尽管如此，要进行打洞需要进行三次握手的同时打开，但是有些的实现，可能不支持这种同时打开的情况，这样也就无法建立连接了。
下面就几种网络拓扑情况下，打洞步骤进行逐一介绍。为了方便描述，假设通信的两个节点分别为 和 ，而辅助穿越的 为 。下面的所有方法都要求 、 都与 保持一条长连接，或者周期性连上 ，以便能够接收 的相关指令，我们称这两个连接分别为，
接《浅析  穿越  的原理、技术、方法  下 》作者 |阮永顺编辑 | 顾乡
鉴于腾讯云主机因弱口令频繁被入侵，通过加固可以避免高危端口暴露在外。
密码账号安全

不使用个人账号申请自研业务腾讯云主机。

能够管理腾讯云的 密码需要符合强密码要求，为避免撞库攻击，不得在其他地方使用过。


服务器安全设置
为避免服务器被爆破

不得使用  等容易猜到、以及基于键盘移位  等弱口令。

避免使用密码，使用证书登录。
选定一台能够访问公网的运维机作为跳板机执行   –  生成密钥对。执行 _ 显示并复制公钥内容。


建议第一种方法：在腾讯云官网添加密钥 

关闭云主机后，将密钥绑定到你的主机实例。腾讯云将会自动关闭密码登录并开启证书登录。

第二种方法：命令行添加公钥 记得将公钥保存一份
在跳板机输入  _ |      _  
或者登录上服务器后直接追加_
使用安全组限制服务器流量出入
为避免服务器被爆破扫描，或限制访问高危服务，或者避免不小心开放高危端口，建议对服务器实施安全组策略，根据业务需要限制网络出入流量。
如图所示，腾讯云已经自带一些安全组，默认都是全开的策略，会导致安全工单的爆发。例如一台默认配置的 服务器扫描结果：

第一步：根据业务特性，先从一个自带安全组克隆出来。注意选定服务器所在地区

 然后编辑如图： 所有是允许，然后限定公司办公网出口可访问，然后剩下所有互联网流量全丢掉。如果你还有或者 需要对外提供服务，就插入一条 或者 的策略，允许

 然后记得检查 “出站规则” ，最顶部要允许，要不然就访问不了外网。保存。
 
最后在云主机列表配置安全组，勾选刚才配置的安全组，再取消勾选默认的安全组。

入侵检测组件安装
前提是使用  ；安装
         
查看状态
     

相关推荐
腾讯云配置免密码登录远程服务器【腾讯云的种玩法】服务器配置系列一服务器的配置公有云提供了很多免费的高级功能，很多中小用户以为自己用不上。实际上稍微研究一下，就能享受很多便利和节省不少成本。 
本方案就是利用弹性伸缩减少服务器成本，几乎适合所有集群式部署的网站。设置也非常简单。
业务场景：
如果您的业务满足以下条件，花分钟配置这个方案，可节省成本：

网站使用集群的方式，且集群超过台以上的服务器；

网站有较长时间的空闲。大部分网站的高峰时间不超过  个小时，剩下的  个小时的时间，完全可以把闲置的服务器作缩容处理。


本文以某休闲类网站为例，该网站 ：： 是访问高峰时段。
方案简述

按非高峰时段的负载部署固定资源，可采用包年包月 ；

高峰时段的不足部分采用按量计费的。通过定时任务在 ： 扩容台，： 缩容回去。


新旧方案的对比：

收益
假设原方案需要两台 核 的 ，改成一台 核 的   每天个小时临时，能节省左右开支。
示例中的小网站每年可以节省元：

具体操作
实例的网站结构比较简单，只有应用服务器一个集群。如果复杂的网站，会有应用服务器集群、前端服务器集群、缓存服务器集群等，每个集群都可进行类似操作，每个集群对应一个伸缩组。

  创建集群机器的自定义镜像
这步非常简单，基于一台现成的集群机器中制作即可。如有疑问可查看 制作自定义镜像 

注：您需要提前部署好镜像中的环境，保证镜像里的应用能随操作系统启动，这样扩容出来的机器就能直接工作，无需人工介入。

  创建启动配置
扩容时  以启动配置为模板创建机器，因此我们事先通过启动配置指定地域、机型、镜像。

登录 弹性伸缩控制台，点击导航条中的【启动配置】。

选择项目和地域，这里要注意选择  应用 所在的项目和地域。




接下来的操作与购买机器类似，您可跟着指引完成启动配置创建。注意自定义镜像中，指定刚才您创建的镜像。


  为机器创建伸缩组
在弹性伸缩控制台，点击【新建】，按如下填写集群的管理信息：

名称：按需起一个名字。比如这里填“应用服务器集群”

最小伸缩数：集群服务器数量的下限。示例这里填  即可。

起始实例数：伸缩组刚创建时，自动创建的机器数量。一般不会刚创建伸缩组就自动创建机器，建议这里填 。

最大伸缩数：集群服务器数量的上限，这里按需填写。这里以  为例，即伸缩组最多有  台机器。

启动配置：选择刚才您创建的启动配置。

支持网络：会话服务器的网络环境，一般选“基础网络”即可。

支持可用区：即选择机扩容器落在哪个可用区里，此处按会话服务器所在的可用区勾选即可。

移出策略：选择默认。

负载均衡：选择集群的负载均衡。



最后点击【确定】，完成创建。
  添加现有机器进伸缩组

在 控制台点击伸缩组名字，进入管理页，在页面下方点击【添加云主机】。



在弹出的对话框中，选择集群已有的服务器加入伸缩组。如果现在是非高峰时期，集群中未充分利用的服务器可以退还，节约成本。



加入后对服务器设置“免于缩容”，这样在缩容活动中，伸缩组不会选择这台服务器缩容。这样集群中这台机器永远在服务， 不会更改它。


  设置扩缩容策略重点！
 支持定时扩容或者基于告警动态扩容，也支持您接收扩缩容通知，以及翻看历史扩缩容详情。一切尽在您的掌控中。

先设置一个：的定时扩容任务


 注： 腾讯云的需要分钟左右创建，如果自定义镜像较大，可能需要更多时间。您可以将执行开始时间提早分钟。

然后再设置一个：的定时缩容任务


至此大功告成！
网站的后台集群变为“台固定应用服务器台高峰时定时创建的应用服务器”。
没加入伸缩组的其他集群机器，大部分时间未充分利用，可以退还掉节约成本。
相关推荐
【腾讯云的种玩法】如何利用腾讯云搭建分布式应用【腾讯云的种玩法】云服务器搭建环境在”从三次握手说起–浅析协议中的疑难杂症“文章中，我们提到第个疑问：的头号疼症_状态，下面我们继续这个问题的解答

_的快速回收和重用


_快速回收。下开启_快速回收需要同时打开__和_默认打开两选项。下快速回收的时间为   ，而一个时间为至。开启快速回收_，可能会带来问题一、中说的三点危险，为了避免这些危险，要求同时满足以下三种情况的新连接要被拒绝掉。
 来自同一个对端的包携带了时间戳。之前同一台机器仅仅识别地址，因为连接被快速释放了，没了端口信息的某个数据在秒之内到过本机器新连接的时间戳小于机器上次到来时的时间戳，且差值大于重放窗口戳__初看起来正常的数据包同时满足下面条几乎不可能， 因为机器的时间戳不可能倒流的，出现上述的点均满足时，一定是老的重复数据包又回来了，丢弃老的包是正常的。到此，似乎启用快速回收就能很大程度缓解_带来的问题。但是，这里忽略了一个东西就是。。。在一个后面的所有机器在看来都是一个机器，后面的那么多机器的系统时间戳很可能不一致，有些快，有些慢。这样，在关闭了与系统时间戳快的的连接后，在这个连接进入快速回收的时候，同一后面的系统时间戳慢的向发起连接，这就很有可能同时满足上面的三种情况，造成该连接被拒绝掉。所以，在是否开启__需要慎重考虑了





_重用上比较完美的实现了_重用问题。只要满足下面两点中的一点，一个状态的四元组即一个连接可以重新被新到来的连接使用

 新连接告知的初始序列号比_老连接的末序列号大 如果开启了_，并且新到来的连接的时间戳比老连接的时间戳大

 要同时开启__选项和_ 选项才可以开启_重用，还有一个条件是：重用_的条件是收到最后一个包后超过。细心的同学可能发现_重用对端来说并没解决大量_造成的资源消耗的问题，因为不管_连接是否被重用，它依旧占用着系统资源。即便如此，_重用还是有些用处的，它解决了整机范围拒绝接入的问题，虽然一般一个单独的是不可能在内用同一个端口连接同一个服务的，但是如果做了端口那就是同个端口了。时间戳重用_连接的机制的前提是地址唯一性，得出新请求发起自同一台机器，但是如果是环境下就不能这样保证了，于是在环境下，_重用还是有风险的。
  有些同学可能会混淆__和_ 选项，认为是相关的一个东西，其实他们是两个完全不同的东西，可以说两个半毛钱关系都没。__是内核选项，而_用户态的选项，使用_是告诉内核，如果端口忙，但状态位于 _ ，可以重用端口。如果端口忙，而状态位于其他状态，重用端口时依旧得到一个错误信息， 指明   ”。如果你的服务程序停止后想立即重启，而新套接字依旧使用同一端口，此时 _ 选项非常有用。但是，使用这个选项就会有问题二、中说的三点危险，虽然发生的概率不大。



清掉_的奇技怪巧可以用下面两种方式控制服务器的_数量


修改___  ___ 控制并发的_的数量，默认值是。如果超过默认值，内核会把多的_连接清掉，然后在日志里打一个警告。官网文档说这个选项只是为了阻止一些简单的攻击，平常不要人为的降低它。



利用包从外部清掉_链接根据规范，收到任何的发送到未侦听端口、已经关闭的连接的数据包、连接处于任何非同步状态  并且收到的包的在窗口外，或者安全层不匹配，都要回执以响应而收到滑动窗口外的序列号的数据包，都要丢弃这个数据包，并回复一个包，内核收到将会产生一个错误并终止该连接。我们可以利用包来终止掉处于_状态的连接，其实这就是所谓的攻击了。为了描述方便：假设和有个连接，主动关闭连接并进入了_状态，我们来描述一下怎么从外部使得的处于 _状态的连接提前终止掉。要实现这个攻击，首先我们要知道在中的端口一般这个端口是随机的，比较难猜到，这也是攻击较难的一个点，利用_这个选项，它可以不属于本地的地址，因此可以从任意机器绑定地址以及端口，然后向发起一个连接，收到了窗口外的包于是响应一个，这个包会路由到处，这个时候的可能已经释放连接了，这个时候收到这个包，会发送一个包，收到包然后就释放连接提前终止_状态了。提前终止_状态是可能会带来问题二、中说的三点危害，具体的危害情况可以看下。中建议，不要用过早的结束_状态。



至此，上面的疑症都解析完毕，然而细心的同学会有下面的疑问：
的可靠传输是确认号来实现的，那么的确认机制是怎样的呢？是收到一个包就马上确认，还是可以稍等一下在确认呢？假如发送一个包，一直都没收到确认呢？什么时候重传呢？超时机制的怎样的？两端的处理能力不对等的时候，比如发送方处理能力很强，接收方处理能力很弱，这样发送方是否能够不管接收方死活狂发数据呢？如果不能，流量控制机制的如何的？是端到端的协议，也就是对端只看到对方，看不到网络上的其他点，那么的两端怎么对网络情况做出反映呢？发生拥塞的时候，拥塞控制机制是如何的？
 疑症的延迟确认机制
按照协议，确认机制是累积的，也就是确认号的确认指示的是所有之前但不包括的数据已经收到了。确认号本身就是不含数据的分段，因此大量的确认号消耗了大量的带宽，虽然大多数情况下，还是可以和数据一起捎带传输的，但是如果没有捎带传输，那么就只能单独回来一个，如果这样的分段太多，网络的利用率就会下降。为缓解这个问题，建议了一种延迟的，也就是说，在收到数据后并不马上回复，而是延迟一段可以接受的时间，延迟一段时间的目的是看能不能和接收方要发给发送方的数据一起回去，因为协议头中总是包含确认号的，如果能的话，就将数据一起捎带回去，这样网络利用率就提高了。延迟就算没有数据捎带，那么如果收到了按序的两个包，那么只要对第二包做确认即可，这样也能省去一个消耗。由于协议不对进行的，建议最多等待个包的积累确认，这样能够及时通知对端，我这边的接收情况。实现中，有延迟和快速，并根据当前的包的收发情况来在这两种中切换。一般情况下，并不会对网络性能有太大的影响，延迟能减少发送的分段从而节省了带宽，而快速能及时通知发送方丢包，避免滑动窗口停等，提升吞吐率。关于分段，有个细节需要说明一下，的确认号，是确认按序收到的最后一个字节序，对于乱序到来的分段，接收端会回复相同的分段，只确认按序到达的最后一个分段。连接的延迟确认时间一般初始化为最小值，随后根据连接的重传超时时间、上次收到数据包与本次接收数据包的时间间隔等参数进行不断调整。
 疑症的重传机制以及重传的超时计算

的重传超时计算交互过程中，如果发送的包一直没收到确认，是要一直等下去吗？显然不能一直等如果发送的包在路由过程中丢失了，对端都没收到又如何给你发送确认呢？，这样协议将不可用，既然不能一直等下去，那么该等多久呢？等太长时间的话，数据包都丢了很久了才重发，没有效率，性能差；等太短时间的话，可能还在路上快到了，这时候却重传了，造成浪费，同时过多的重传会造成网络拥塞，进一步加剧数据的丢失。也是，我们不能去猜测一个重传超时时间，应该是通过一个算法去计算，并且这个超时时间应该是随着网络的状况在变化的。为了使我们的重传机制更高效，如果我们能够比较准确知道在当前网络状况下，一个数据包从发出去到回来的时间——  ，那么根据这个我们就可以方便设置—— 了。为了计算这个，中定义了一个经典算法，算法如下：

 首先采样计算值 然后计算平滑的，称为    ， =           = 

其中：是值的上限；例如：可以定义为分钟，是值的下限，例如，可以定义为秒；                    然而这个算法有个缺点就是：在算样本的时候，是用第一次发数据的时间和回来的时间做样本值，还是用重传的时间和回来的时间做样本值？不管是怎么选择，总会造成会要么把算过长了，要么把算过短了。如下图：就计算过长了，而就是计算过短了。针对上面经典算法的缺陷，于是提出   对经典算法进行了改进算法大特点是——忽略重传，不把重传的做采样，但是这个算法有问题：如果在某一时间，网络闪动，突然变慢了，产生了比较大的延时，这个延时导致要重转所有的包因为之前的很小，于是，因为重转的不算，所以，就不会被更新，这是一个灾难。于是，为解决上面两个算法的问题，又有人推出来了一个新的算法，这个算法叫   参看，这个算法的核心是：除了考虑每两次测量值的偏差之外，其变化率也应该考虑在内，如果变化率过大，则通过以变化率为自变量的函数为主计算如果陡然增大，则取值为比较大的正数，如果陡然减小，则取值为比较小的负数，然后和平均值加权求和，反之如果变化率很小，则取测量平均值。公式如下：其中的是 的意思

 =   α  –   —— 计算平滑 = β  β|| ——计算平滑和真实的差距加权移动平均= µ    ∂  —— 神一样的公式其中：在下，α = ，β = ， μ = ，∂ =  ——这就是算法中的“调得一手好参数”，     … 最后的这个算法在被用在今天的协议中并工作非常好

知道超时怎么计算后，很自然就想到定时器的设计问题。一个简单直观的方案就是为中的每一个数据包维护一个定时器，在这个定时器到期前没收到确认，则进行重传。这种设计理论上是很合理的，但是实现上，这种方案将会有非常多的定时器，会带来巨大内存开销和调度开销。既然不能每个包一个定时器，那么多少个包一个定时器才好呢，这个似乎比较难确定。可以换个思路，不要以包量来确定定时器，以连接来确定定时器会不会比较合理呢？目前，采取每一个连接单一超时定时器的设计则成了一个默认的选择，并且给出了每连接单一定时器的设计建议算法规则：

 每一次一个包含数据的包被发送包括重发，如果还没开启重传定时器，则开启它，使得它在秒之后超时按照当前的值。 当接收到一个确认一个新的数据 如果所有的发出数据都被确认了，关闭重传定时器。 当接收到一个确认一个新的数据，还有数据在传输，也就是还有没被确认的数据，重新启动重传定时器，使得它在秒之后超时按照当前的值。当重传定时器超时后，依次做下列件事情： 重传最早的尚未被接收方的数据包 重新设置 为   “还原定时器”，但是新不应该超过的上限有个上限值，这个上限值最少为 重启重传定时器。

上面的建议算法体现了一个原则：没被确认的包必须可以超时，并且超时的时间不能太长，同时也不要过早重传。规则共同说明了只要还有数据包没被确认，那么定时器一定会是开启着的这样满足 没被确认的包必须可以超时的原则。规则说明定时器的超时值是有上限的满足 超时的时间不能太长 。规则说明，在一个到来后重置定时器可以保护后发的数据不被过早重传；因为一个到来了，说明后续的很可能会依次到来，也就是说丢失的可能性并不大。规则也是在一定程度上避免过早重传，因为，在出现定时器超时后，有可能是网络出现拥塞了，这个时候应该延长定时器，避免出现大量的重传进一步加剧网络的拥塞。

的重传机制通过上面我们可以知道，的重传是由超时触发的，这会引发一个重传选择问题，假设发送端连续发了、、、、、、、、、共包，其中、、这个包全丢失了，由于的是确认最后连续收到序号，这样发送端只能收到号包的，这样在_的时候，发送端就面临下面两个重传选择：

仅重传号包重传号后面所有的包，也就是重传号包

对于，上面两个选择的优缺点都比较明显。  方案，优点：按需重传，能够最大程度节省带宽。缺点：重传会比较慢，因为重传号包后，需要等下一个超时才会重传号包。  方案，优点：重传较快，数据能够较快交付给接收端。缺点：重传了很多不必要重传的包，浪费带宽，在出现丢包的时候，一般是网络拥塞，大量的重传又可能进一步加剧拥塞。
上面的问题是由于单纯以时间驱动来进行重传的，都必须等待一个超时时间，不能快速对当前网络状况做出响应，如果加入以数据驱动呢？引入了一种叫 快速重传 的算法，就是在连续收到次相同确认号的，那么就进行重传。这个算法基于这么一个假设，连续收到个相同的，那么说明当前的网络状况变好了，可以重传丢失的包了。
快速重传解决了的问题，但是没解决重传一个还是重传多个的问题。出现难以决定是否重传多个包问题的根源在于，发送端不知道那些非连续序号的包已经到达接收端了，但是接收端是知道的，如果接收端告诉一下发送端不就可以解决这个问题吗？于是，提出了  ，选择确认机制，是的扩展选项，包括  允许选项==，选项只允许在有标志的包中，  信息选项=。一个的例子如下图，红框说明：接收端收到了，，，的数据了，这样发送端就可以选择重传丢失的，，的包。依靠接收端的接收情况反馈，解决了重传风暴问题，这样够了吗？接收端能不能反馈更多的信息呢？显然是可以的，于是，对对进行了扩展，提出了，也就是利用第一块数据中描述重复接收的不连续数据块的序列号参数，其他数据则描述其他正常接收到的不连续数据。这样发送方利用第一块，可以发现数据段被网络复制、错误重传、丢失引起的重传、重传超时等异常的网络状况，使得发送端能更好调整自己的重传策略。，有几个优点：

发送端可以判断出，是发包丢失了，还是接收端的丢失了。发送方，重传了一个包，发现并没有那个包，那么就是发送的数据包丢了；否则就是接收端的丢了，或者是发送的包延迟到达了发送端可以判断自己的是不是有点小了，导致过早重传如果收到比较多的就该怀疑是小了。发送端可以判断自己的数据包是不是被复制了。如果明明没有重传该数据包，但是收到该数据包的发送端可以判断目前网络上是不是出现了有些包被了，也就是出现先发的包却后到了。



 疑症的流量控制
我们知道的窗口是一个位字段，它代表的是窗口的字节容量，也就是的标准窗口最大为=个字节。另外在的选项字段中还包含了一个窗口扩大因子，为，为个字节，取值范围。窗口扩大因子用来扩大窗口，可把原来的窗口，扩大为。这个窗口是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。也就是，发送端是根据接收端通知的窗口大小来调整自己的发送速率的，以达到端到端的流量控制。尽管流量控制看起来简单明了，就是发送端根据接收端的限制来控制自己的发送就好了，但是细心的同学还是会有些疑问的。

发送端是怎么做到比较方便知道自己哪些包可以发，哪些包不能发呢？如果接收端通知一个零窗口给发送端，这个时候发送端还能不能发送数据呢？如果不发数据，那一直等接收端口通知一个非窗口吗，如果接收端一直不通知呢？如果接收端处理能力很慢，这样接收端的窗口很快被填满，然后接收处理完几个字节，腾出几个字节的窗口后，通知发送端，这个时候发送端马上就发送几个字节给接收端吗？发送的话会不会太浪费了，就像一艘万吨油轮只装上几斤的油就开去目的地一样。对于发送端产生数据的能力很弱也一样，如果发送端慢吞吞产生几个字节的数据要发送，这个时候该不该立即发送呢？还是累积多点在发送？


疑问的解决发送方要知道那些可以发，哪些不可以发，一个简明的方案就是按照接收方的窗口通告，发送方维护一个一样大小的发送窗口就可以了，在窗口内的可以发，窗口外的不可以发，窗口在发送序列上不断后移，这就是中的滑动窗口。如下图所示，对于发送端其发送缓存内的数据都可以分为类

已经发送并得到接收端的已经发送但还未收到接收端的未发送但允许发送的接收方还有空间未发送且不允许发送接收方没空间了。其中，和两部分合起来称之为发送窗口。

下面两图演示的窗口的滑动情况，收到的后，窗口向后滑动个。

疑问的解决由问题我们知道，发送端的发送窗口是由接收端控制的。下图，展示了一个发送端是怎么受接收端控制的。由上图我们知道，当接收端通知一个窗口的时候，发送端的发送窗口也变成了，也就是发送端不能发数了。如果发送端一直等待，直到接收端通知一个非零窗口在发数据的话，这似乎太受限于接收端，如果接收端一直不通知新的窗口呢？显然发送端不能干等，起码有一个主动探测的机制。为解决窗口的问题，使用了  技术，缩写为。发送端在窗口变成后，会发的包给接收方，来探测目前接收端的窗口大小，一般这个值会设置成次，每次大约秒不同的实现可能会不一样。如果次过后还是的话，有的实现就会发掉这个连接。正如有人的地方就会有商机，那么有等待的地方就很有可能出现攻击点。攻击者可以在和建立好连接后，就向通告一个窗口，然后端就只能等待进行，于是攻击者会并发大量的这样的请求，把端的资源耗尽。

疑问点的解决疑点本质就是一个避免发送大量小包的问题。造成这个问题原因有二：接收端一直在通知一个小的窗口 发送端本身问题，一直在发送小包。这个问题，中有个术语叫  糊涂窗口综合症。解决这个问题的思路有两，接收端不通知小窗口，发送端积累一下数据在发送。思路是在接收端解决这个问题，  ’ 方案，如果收到的数据导致 小于某个值，就一个窗口，这就阻止发送端在发数据过来。等到接收端处理了一些数据后  大于等于了，或者有一半为空，就可以通告一个非窗口。思路是在发送端解决这个问题，有个著名的’ 。 算法的规则

如果包长度达到  ，则允许发送；如果该包含有  ，则允许发送；设置了 _ 选项，则允许发送；设置 _ 选项时，若所有发出去的小数据包包长度小于  均被确认，则允许发送；上述条件都未满足，但发生了超时一般为  ，则立即发送。

规则指出连接上最多只能有一个未被确认的小数据包。从规则可以看出算法并不禁止发送小的数据包超时时间内，而是避免发送大量小的数据包。由于算法是依赖的，如果很快的话，也会出现一直发小包的情况，造成网络利用率低。_选项则是禁止发送小的数据包超时时间内，设置该选项后，会尽力把小数据包拼接成一个大的数据包一个 再发送出去，当然也不会一直等，发生了超时一般为  ，也立即发送。 算法和_ 选项提高了网络的利用率，但是增加是延时。从规则可以看出，设置_ 选项，就是完全禁用 算法了。
这里要说一个小插曲，算法和延迟确认 一起，当出现 的时候会引发一个的延时问题，这个问题在 中体现的比较明显。场景如下：客户端在请求下载 中的一个小文件，一般情况下， 都是先发送响应头部，然后在发送响应特别是比较多的实现在发送文件的实施采用的是系统调用，这就出现模式了。当发送头部的时候，由于头部较小，于是形成一个小的包发送到客户端，这个时候开始发送，由于也较小，这样还是形成一个小的数据包，根据算法， 已经发送一个小的数据包了，在收到第一个小包的后或等待超时后才能在发小包， 不能发送这个小包；客户端收到响应头后，由于这是一个小的包，于是客户端开启延迟确认，客户端在等待的第二个包来在一起确认或等待一个超时一般是在发送包；这样就出现了你等我、然而我也在等你的死锁状态，于是出现最多的情况是客户端等待一个的超时，然后发送给 ， 收到包后在发送部分。大家在测 的时候就要留意这个问题了。


 疑症的拥塞控制
谈到拥塞控制，就要先谈谈拥塞的因素和本质。本质上，网络上拥塞的原因就是大家都想独享整个网络资源，对于，端到端的流量控制必然会导致网络拥堵。这是因为只看到对端的接收空间的大小，而无法知道链路上的容量，只要双方的处理能力很强，那么就可以以很大的速率发包，于是链路很快出现拥堵，进而引起大量的丢包，丢包又引发发送端的重传风暴，进一步加剧链路的拥塞。另外一个拥塞的因素是链路上的转发节点，例如路由器，再好的路由器只要接入网络，总是会拉低网络的总带宽，如果在路由器节点上出现处理瓶颈，那么就很容易出现拥塞。由于看不到网络的状况，那么拥塞控制是必须的并且需要采用试探性的方式来控制拥塞，于是拥塞控制要完成两个任务：公平性；拥塞过后的恢复。发展到现在，拥塞控制方面的算法很多，其中是目前应用最广泛且较为成熟的算法，下面着重介绍一下算法。介绍该算法前，首先介绍一个概念 冗余、重复一般情况下一个被称为冗余，要同时满足下面几个条件对于，那么根据的一些信息来进一步判断

 接收的那端已经发出了一些还没被的数据包 该没有捎带 该的和位都是的，也就是既不是包的也不是包的。 该的确认号等于接收那端已经收到的的最大确认号 该通知的窗口等接收该的那端上一个收到的的窗口

算法包含个部分：慢热启动算法 –   拥塞避免算法 –   快速重传    快速恢复算法 –  。的拥塞控制主要原理依赖于一个拥塞窗口来控制，根据前面的讨论，我们知道有一个接收端通告的接收窗口用于流量控制；加上拥塞控制后，发送端真正的发送窗口= 。关于的单位，在中是以字节来做单位的，我们假设每次传输都是按照大小来发送数据，因此你可以认为按照数据包个数来做单位也可以理解，下面如果没有特别说明是字节，那么增加也就是相当于字节数增加个大小。

慢热启动算法 –  慢启动体现了一个试探的过程，刚接入网络的时候先发包慢点，探测一下网络情况，然后在慢慢提速。不要一上来就拼命发包，这样很容易造成链路的拥堵，出现拥堵了在想到要降速来缓解拥堵这就有点成本高了，毕竟无数的先例告诫我们先污染后治理的成本是很高的。慢启动的算法如下全称 ：

连接建好的开始先初始化 = ，表明可以传个大小的数据。每当收到一个， 呈线性上升每当过了一个， =  呈指数让升还有一个慢启动门限  ，是一个上限，当 = 时，就会进入拥塞避免算法   根据，如果   ，则 = 如果   ，则 = 如果  =  =  ，则 = 一篇的论文《    ’   》建议把 初始化成了 个。 后采用了这篇论文的建议。


拥塞避免算法 –  慢启动的时候说过，是指数快速增长的，但是增长是有个门限一般来说大多数的实现的值是字节的，到达门限后进入拥塞避免阶段。在进入拥塞避免阶段后，值变化算法如下：

每收到一个，调整 为     个字节每经过一个的时长，增加个大小。

是看不到网络的整体状况的，那么认为网络拥塞的主要依据是它重传了报文段。前面我们说过的重传分两种情况：

出现超时，重传数据包。这种情况下，就认为出现拥塞的可能性就很大，于是它反应非常强烈    调整门限的值为当前值的。   自己的值为   然后重新进入慢启动过程。在超时前，收到个 进行重传数据包。这种情况下，收到个冗余后说明确实有中间的分段丢失，然而后面的分段确实到达了接收端，因为这样才会发送冗余，这一般是路由器故障或者轻度拥塞或者其它不太严重的原因引起的，因此此时拥塞窗口缩小的幅度就不能太大，此时进入快速重传。


快速重传    做的事情有：

 调整门限的值为当前值的。 将值设置为新的的值 重新进入拥塞避免阶段。

在快速重传的时候，一般网络只是轻微拥堵，在进入拥塞避免后，恢复的比较慢。针对这个，“快速恢复”算法被添加进来，当收到个冗余时，最后的步骤进入的不是拥塞避免阶段，而是快速恢复阶段。

快速恢复算法 –   ：快速恢复的思想是“数据包守恒”原则，即带宽不变的情况下，在网络同一时刻能容纳数据包数量是恒定的。当“老”数据包离开了网络后，就能向网络中发送一个“新”的数据包。既然已经收到了个冗余，说明有三个数据分段已经到达了接收端，既然三个分段已经离开了网络，那么就是说可以在发送个分段了。于是只要发送方收到一个冗余的，于是加个。快速恢复步骤如下在进入快速恢复前， 和 已被更新为： =  ， = ：

把设置为的值加，重传 指定的数据包如果再收到  ，那么 =  如果收到新的，而非 ，那么将重新设置为【】中的的值。然后进入拥塞避免状态。

细心的同学可能会发现快速恢复有个比较明显的缺陷就是：它依赖于个冗余，并假定很多情况下，个冗余的只代表丢失一个包。但是个冗余也很有可能是丢失了很多个包，快速恢复只是重传了一个包，然后其他丢失的包就只能等待到超时了。超时会导致减半，并且退出了 阶段，多个超时会导致传输速率呈级数下降。出现这个问题的主要原因是过早退出了 阶段。为解决这个问题，提出了 算法，该算法是在没有的支持下改进 算法改变的确认机制，把乱序等信息会全部告诉对方，本身携带的信息就可以使得发送方有足够的信息来知道需要重传哪些包，而不需要重传哪些包，具体改进如下：

发送端收到个冗余后，重传冗余指示可能丢失的那个包，如果的通告接收端已经收到发送端的全部已经发出的数据的话，那么就是只丢失一个包，如果没有，那么就是有多个包丢失了。发送端根据的判断出有多个包丢失，那么发送端继续重传窗口内未被的第一个包，直到 内发出去的包全被了，才真正退出 阶段。

我们可以看到，拥塞控制在拥塞避免阶段，是加性增加的，在判断出现拥塞的时候采取的是指数递减。为什么要这样做呢？这是出于公平性的原则，拥塞窗口的增加受惠的只是自己，而拥塞窗口减少受益的是大家。这种指数递减的方式实现了公平性，一旦出现丢包，那么立即减半退避，可以给其他新建的连接腾出足够的带宽空间，从而保证整个的公平性。 
至此，的疑难杂症基本介绍完毕了，总的来说是一个有连接的、可靠的、带流量控制和拥塞控制的端到端的协议。的发送端能发多少数据，由发送端的发送窗口决定当然发送窗口又被接收端的接收窗口、发送端的拥塞窗口限制的，那么一个连接的传输稳定状态应该体现在发送端的发送窗口的稳定状态上，这样的话，的发送窗口有哪些稳定状态呢？的发送窗口稳定状态主要有上面三种稳定状态：

【】接收端拥有大窗口的经典锯齿状大多数情况下都是处于这样的稳定状态，这是因为，一般情况下机器的处理速度就是比较快，这样的接收端都是拥有较大的窗口，这时发送端的发送窗口就完全由其拥塞窗口决定了；网络上拥有成千上万的连接，它们在相互争用网络带宽，的流量控制使得它想要独享整个网络，而拥塞控制又限制其必要时做出牺牲来体现公平性。于是在传输稳定的时候发送端呈现出下面过程的反复

用慢启动或者拥塞避免方式不断增加其拥塞窗口，直到丢包的发生；然后将发送窗口将下降到或者下降一半，进入慢启动或者拥塞避免阶段要看是由于超时丢包还是由于冗余丢包；过程如下图：



【】接收端拥有小窗口的直线状态这种情况下是接收端非常慢速，接收窗口一直很小，这样发送窗口就完全有接收窗口决定了。由于发送窗口小，发送数据少，网络就不会出现拥塞了，于是发送窗口就一直稳定的等于那个较小的接收窗口，呈直线状态。

【】两个直连网络端点间的满载状态下的直线状态这种情况下，两端直连，并且只有位于一个连接，那么这个连接将独享网络带宽，这里不存在拥塞问题，在他们处理能力足够的情况下，的流量控制使得他们能够跑慢整个网络带宽。
通过上面我们知道，在传输稳定的时候，各个连接会均分网络带宽的。相信大家学生时代经常会发生这样的场景，自己在看视频的时候突然出现视频卡顿，于是就大叫起来，哪个开了迅雷，赶紧给我停了。其实简单的下载加速就是开启多个连接来分段下载就达到加速的效果，假设宿舍的带宽是，一开始两个在看视频，每人平均网速是，这速度看起视频来那叫一个顺溜。突然其中一个同学打打开迅雷开着个连接在下载爱情动作片，这个时候平均下来你能分到的带宽就剩下，这网速下你的视频还不卡成幻灯片。在通信链路带宽固定假设为，多人公用一个网络带宽的情况下，利用协议的拥塞控制的公平性，多开几个连接就能多分到一些带宽当然要忽略有些用协议带来的影响，然而不管怎么最多也就能把整个带宽抢到，于是在占满整个带宽的情况下，下载一个大小为的文件，那么最快需要的时间是，难道就没办法加速了吗？
答案是有的，这样因为网络是网状的，一个节点是要和很多几点互联的，这就存在多个带宽为的通信链路，如果我们能够将要下载的文件，一半从通信链路下载，另外一半从通信链路下载，这样整个下载时间就减半了为，这就是加速。相信大家学生时代在下载爱情动作片的时候也遇到过这种情况，明明外网速度没这么快的，自己下载的爱情动作片的速度却达到几，那是因为，你的左后或右后的宿友在帮你加速中。我们都知道模式下载会快，并且越多人下载就越快，那么问题来了，下载加速理论上的加速比是多少呢？


附加题：理论上的加速比
传统的模式传输文件，在跑满带宽的情况下传输一个文件需要耗时，如果有个客户端需要下载文件，那么总耗时是，当然啦，这并不一定是串行传输，可以并行来传输的，这样总耗时也就是了，但是这需要服务器的带宽是个带宽的总和。模式一个明显的缺点是服务要传输一个文件次，这样对服务器的性能和带宽带来比较大的压力，我可以换下思路，服务器将文件传给其中一个后，让这些互联的自己来交互那个文件，那服务器的压力就减少很多了。这就是网络的好处，利用各个节点间的互联，提倡“人人为我，我为人人”。
知道传输的好处后，我们来谈下理论上的最大加速比，为了简化讨论，一个简单的网络拓扑图如下，有个相互互联的节点，并且每个节点间的网络带宽是，传输一个大小为的文件最快的时间是多少呢？假设节点有个大小为的文件需要传输给，，节点，一种简单的方式就是：节点同时将文件传输给节点，，耗时，这样大家都拥有文件了。大家可以看出，整个过程只有节点在发送文件，其他节点都是在接收，完全违反了的“人人为我，我为人人”的宗旨。那怎么才能让大家都做出贡献了呢？解决方案是切割文件。

首先，节点 文件分成个片段 ，接着将发送给，发送给，发送给，耗时；然后，执行“人人为我，我为人人”的精神，将自己拥有的分别发给没有的其他的节点，这样耗时完成交换。

于是总耗时为完成了文件的传输，可以看出耗时减少为原来的了，如果有个节点，那么时间就是原来的，也就是加速比是，这就是加速的理论上限了吗？还没发挥最多能量的，相信大家已经看到分割文件的好处了，上面的文件分割粒度还是有点大，以至于，在第二阶段传输过程中，节点无所事事。为了最大化发挥大家的作用，我们需要将在进行分割，假设将它们都均分为等份，这样就有…、…、…，一共个分段。于是下面就开始进行加速分发：

节点将分段，，分别发送给，，节点。耗时，节点将分段，，分别发送给，，节点，同时节点，，将阶段收到的分段相互发给没有的节点。耗时，。。。。。。节点将分段，，分别发送给，，节点，同时节点，，将阶段收到的分段相互发给没有的节点。耗时，节点，，将阶段收到的分段相互发给没有的节点。耗时，于是总的耗时为  =   ，当趋于无穷大的时候，文件进行无限细分的时候，耗时变成了，也就是当节点是的时候，加速比是。这就是理论上的最大加速比了，最大加速比是网络节点个数减。


附加题：系统调用 的参数指的是什么
要说明参数的含义，首先需要说一下的协议栈维护的连接的两个连接队列：半连接队列；连接队列

半连接队列：端收到的包并回复包后，该连接的信息就会被移到一个队列，这个队列就是半连接队列此时连接处于 非同步状态 连接队列：端收到包的包后，就会将连接信息从中的队列移到另外一个队列，这个队列就是连接队列这个时候连接已经建立，三次握手完成了用户进程调用系统调用后，该连接信息就会从中的队列中移走。

相信不少同学就的具体含义进行争论过，有些认为指的是和两个队列的和。而有些则认为是指的是的大小。其实，这两个说法都对，在  之前指的是和两个队列的和。而以后，就指的是的大小，那么在 以后，的大小怎么确定的呢？两个队列的作用分别是什么呢？

半连接队列的作用对于半连接队列的大小是由___这个内核参数控制的，有些内核似乎也受的参数影响，取得是两个值的最小值。当这个队列满了，会丢弃新来的包，而端在多次重发包得不到响应而返回  错误。但是，当端开启了，那么半连接队列就没有逻辑上的最大值了，并且___设置的值也会被忽略。

连接队列连接队列的大小是由参数和内核参数共同决定，取值为两个中的最小值。当连接队列满了，协议栈的行为根据___内核参数而定。 如果___=，在收到_的包后，协议栈会丢弃该连接并回复包给对端，这个是会出现   错误。如果___=，在收到_的包后，直接丢弃该包。这个时候认为连接已经建立了，一直在等的数据，直到超时出现 错误。



参考资料_
文章来源于公众号：小时光茶社 导语
对于大型矩阵的分解，我们往往会想到用算法。然而当矩阵的维数与奇异值个数上升到一定程度时，分解法往往因为内存溢出而失败。因此，文本介绍一种 算法，相比于，它更能适应大型矩阵分解的要求，且速度更快。实验发现，在平台相同的资源配置下，同样的矩阵分解任务，算法运行失败，而 算法在复杂的迭代计算过程下也仅耗时。
  算法原理介绍
  基本原理
简单的说， 算法也是一种矩阵分解算法。之前的文章《矩阵奇异值分解法介绍》中详细介绍了分解算法，本文的 分解算法是在算法基础上实现的，下面将详细介绍该算法的原理。
 算法主要是在文章中提出来的，它的主要计算过程分为两步：
构建一个能够捕捉到原始矩阵”行为”的低维子矩阵将原始矩阵限制在低维子空间，并计算其标准的矩阵分解，例如上述两步的详细步骤为：

 从原始输入矩阵的列空间中获得一个近似基，并满足如下条件：

其中，矩阵的列向量是正交的，指定的行数与列数分别为和上述过程中最关键的就是求取满足要求的矩阵，文章中给出了具体的方法，即使用随机采样方式构建矩阵：通过设置需要获得的奇异值个数以及过采样参数，构建一个由  个维的随机列向量组成的矩阵 Ω，要求   = {}，每一个列向量中的值均采样自标准正态分布，因此，这些采样的列向量线性独立进行矩阵乘积运算=Ω，由于向量集合也是线性独立的，因此，形成了矩阵的列向量空间通过求取向量集合的正交基，从而得到的近似基

 

构建低维矩阵，满足：

计算低维矩阵的分解，使得
从中的公式我们可以看到，是一个行列的矩阵，相比初始矩阵，的行数非常小，更易于进行分解
计算矩阵实际的左奇异向量
通过以上的步骤就实现了初始矩阵的分解，可以看到，与之前的分解过程相比， 算法主要多了一个构建随机向量的过程。
  算法的一般过程
根据上述的算法原理，我们知道 的计算过程为：

算法一： 算法的一般过程 行列的初始矩阵，奇异值个数，过采样参数，要求满足=， 的分解结果，分别为左奇异向量   ，奇异值矩阵Σ，以及右奇异向量

构建一个∗维的高斯随机矩阵Ω进行矩阵乘积运算=Ω利用分解获得的正交基=构建低维矩阵= 矩阵的分解，Σ=用更新左奇异向量，=
得到最终结果=Σ=Σ=
  算法的改进
当矩阵的奇异值衰减较快的时候，算法一的表现非常好。然而，当我们遇到较大的矩阵，或者矩阵的奇异值下降缓慢时，算法一的结果往往不准确。这主要是由于较小的奇异值对应的奇异值向量干扰了计算的结果。为此， 算法提出了改进算法，主要是通过矩阵的多次   乘积运算来减小这些奇异值向量相对于主要奇异值向量的权重。对照算法原理，主要修改了 阶段的过程。下面主要阐述 阶段的过程。

算法二： 算法的 迭代过程

 行列的初始矩阵，奇异值个数，过采样参数，要求满足=，，指数 的近似基
构建一个∗维的高斯随机矩阵Ω交替使用与 构建轮的迭代过程= Ω 利用分解获得的正交基=
另外，为了避免上述的迭代过程中数值较小的奇异值所携带的信息在计算过程中丢失，文章中进一步提供了改进策略，即每次进行或者的乘积运算时，都对采样矩阵的列向量进行正交化。具体的过程见算法三。

算法三： 算法的子空间迭代过程

 行列的初始矩阵，奇异值个数，过采样参数，要求满足=，，指数 的近似基
构建一个∗维的高斯随机矩阵Ω矩阵乘积运算=Ω，并通过分解获得其正交向量 =  
进行轮的迭代过程，  = …

= 
  算法的分布式实现
以上就是 算法的原理，接下来我们主要探讨 算法的分布式实现。当矩阵的维数非常大时，我们通常都会想到将这个矩阵进行分布式存储，并且采用以为平台实现的算法来对矩阵以分布式的方式进行分解，目前这个算法已经发布在平台，然而这种分解方式不光会占用大量的时长，同时还有内存溢出的可能，特别当矩阵的列数非常大，或者要求奇异值的个数非常大时，这种分解任务往往失败。因此，下面我们重点分析 在上的实现原理。
在上文的原理介绍中我们知道，利用个随机采样的向量可以将原始矩阵的维数缩减至维。当原始矩阵的维数非常大时，将远小于，这时矩阵被缩减成一个非常小的矩阵，甚至不需要像原始矩阵那样采用分布式的方式存储，而是可以直接存储在本地。这种缩减方式将极大的降低算法的空间复杂度，同时由于分解过程在维数较低的矩阵上进行，因此也节约了整个算法的运行时间。
 分解的分布式实现
通过以上分析我们总结 算法在上的实现过程。首先当原始矩阵很大时，我们采用分布式的方式存储。其次 算法的关键就在于对原始矩阵的降维，从算法一、二到三我们可以看出，这就需要原始分布式矩阵右乘一个本地矩阵Ω，这在上是比较容易实现的。乘积的结果是一个分布式矩阵，所以接下来要对分布式矩阵进行分解，注意这里要分解的矩阵是一个行列的，由于远小于和，因此分解的分布式方式通常可以满足要求。分解的分布式实现主要参考了文章，这里简要介绍一下原理。
我们可以把一个分布式矩阵看做如下的形式：

那么矩阵就可以分解为如下形式：

继续对等式右边的第二个矩阵进行分解：

上述等式右边的矩阵中最右边的矩阵就是分解矩阵中的，那么矩阵就可以通过矩阵右乘以的逆得到
根据以上公式我们可以看到，当把分布式的矩阵划分成多个本地矩阵，并对每个本地矩阵进行分解，以及整合他们的矩阵再进行分解就可以并行的获得最终的矩阵。这也是分解的分布式实现的主要思想。
当然，如果整合的多个矩阵依然比较大时，我们还可以继续借用这种思想。如下：

这里对整合的矩阵进行分布式的分解。因此，按照上述思想继续分解，则矩阵的分解最终将转化为如下形式：

下面是行列矩阵的分布式分解示意图

 两个大型矩阵乘积的实现
解决了分布式矩阵的分解问题，接下来我们继续分析。由于分解的矩阵仍然是一个分布式矩阵，接下来这个矩阵行列将与原始矩阵行列进行乘积运算。由于这两个矩阵都非常大，这个过程将非常占内存，对于算法二来说，这种矩阵乘积方式将执行次，比较耗时。对于算法三来说这个乘积过程不光要执行次，同时每次还需要进行分解，这就会占用更多的时长。因此对于算法二和三来说，这个过程是实现的重点。考虑到算法二和三比算法一的准确率更高，使用场景更广，因此，上的 算法主要根据算法二和三来实现。接下来我们重点阐述这里的实现过程。
算法二和三的过程基本上是相似的，都需要进行两个大型矩阵的乘积，在实际问题中，大型矩阵通常分为稀疏型和稠密型，稠密型的较多。由于稀疏与稠密矩阵的存储方式有较大差异，实现时也分为两种方式。先说稠密型矩阵， 是两个大型矩阵乘积的表达形式对于算法二，=Ω。实现时将与都按行进行分布式存储，并根据矩阵乘积原理，将两个矩阵通过每行的索引采用连接起来，再按矩阵的列计算乘积结果的每一行。示意图如下：

对于稀疏型矩阵，由于仅存储了存在的数值，占用内存较小，因此可以将整个矩阵存放至本地，再根据等式 Ω=  ，求取矩阵的逆并以分布式的方式存储，然后将本地矩阵广播至每个节点，与矩阵的逆的每一行进行乘积运算，在相乘时，仅需要遍历稀疏矩阵上存在的数值，这极大地较小了时间复杂度。乘积的结果是一个本地矩阵，对本地矩阵进行转置即可获得结果。示意图如下：

根据稠密型与稀疏型矩阵的不同实现原理，我们可以看出，与稀疏型的计算方式相比稠密型的仅适用于行数与列数相对较小的矩阵，过大的行数与列数很容易造成内存溢出，这也是使用时要注意的地方。
 本地矩阵的分解
以上步骤得到了矩阵的近似基后，的任务已经完成。接下来我们只需要采用同样的分布式矩阵乘积方式计算= ，得到本地矩阵即可，然后对这个矩阵采用常规的分解等过程，得到最终的左奇异向量 ，奇异值矩阵Σ ，以及右奇异向量 。然而实际应用中往往没有这么顺利，这主要是由于矩阵的列向量过大导致的。经过推导我们知道是一个行列的矩阵，而远远小于，这样矩阵将是一个行数远小于列数的矩阵，同时当很大，例如万维左右，直接对矩阵进行分解会因为计算格莱姆矩阵 导致内存溢出。直接计算是不行的，这里考虑将矩阵进行转置，这样计算的格莱姆矩阵是 ，维数将大大减小，非常有利于计算接下来的特征值与特征向量。然而，矩阵转置后的分解不能直接用来计算最终的结果，我们还需要对其进行转化。推导如下，
如果的分解表达为：=Σ ，则 =Σ  =Σ 可以看出，转置后的左、右奇异值向量将发生互换。
根据以上原理，我们得到矩阵实际的左、右奇异值向量，再根据算法一中的、步得到最终矩阵的各个分解结果。
 上的 算法
 算法使用介绍
上现已发布了 算法，见如下位置：

在使用方面，我们提供了样例，具体参考如下模块

该模块可以自动识别输入的矩阵是稀疏的还是稠密的，并据此采用节中的方式进行计算。下面介绍使用中需要特殊注意的地方。

矩阵乘积的迭代类型同上文所说，为了达到较为精确的结果， 模块根据算法二和三进行实现。因此，在中，我们提供了两种迭代方式：与，通过矩阵乘积的迭代类型来选择，其中，代表每轮的矩阵乘积过程中都要采用分解，即算法三的过程；代表每轮矩阵乘积无需进行分解，是算法二的过程。如下图：



矩阵乘积的迭代轮数同时，模块提供了迭代指数：矩阵乘积的迭代轮数，默认情况下选择“”，表示模块将根据奇异值个数与矩阵行数， 矩阵列数  进行比较，值较小，则迭代轮数为，否则为。上述规则是根据经验给定，后期可做相应修改。当然除了默认的情况外，用户也可以自己给定迭代轮数。

 运行情况比较
在对比 算法与算法的运行情况时，使用了两种类型的数据：稠密型与稀疏型。各配置如下：

行列的稠密型矩阵，进行值为的矩阵分解，其中 算法的迭代类型选择，过采样参数为，迭代轮数为。其他参数同算法；
万行万列的稀疏型矩阵，进行值为的矩阵分解，其中 算法的迭代类型选择，过采样参数为，迭代轮数为。其他参数同算法。在相同的资源配置下，运行时长的结果对比如下：


除了时长对比，在计算结果的数值对比上，稠密型矩阵的两种算法的计算结果相同。根据实验结果可以看到，与算法相比， 算法在矩阵较大以及值较大的情况下有很大优势。
致谢
感谢海量计算组游遵文同学以及业务安全组的彭思翔、钱淑钗同学为算法提出的宝贵建议以及在实现上带来的帮助。同时感谢海量计算组全体工作人员对本工作的支持。
参考文献
                                                     –               作者：韦玮
转载请注明出处

随着大数据时代的到来，人们对数据资源的需求越来越多，而爬虫是一种很好的自动采集数据的手段。
那么，如何才能精通网络爬虫呢？学习网络爬虫的路线应该如何进行呢？在此为大家具体进行介绍。
、选择一款合适的编程语言
事实上，、、等常见的语言都可以用于编写网络爬虫，你首先需要选择一款合适的编程语言，这些编程语言各有优势，可以根据习惯进行选择。在此笔者推荐使用进行爬虫项目的编写，其优点是：简洁、掌握难度低。
、掌握的一些基础爬虫模块
当然，在进行这一步之前，你应当先掌握的一些简单语法基础，然后才可以使用语言进行爬虫项目的开发。
在掌握了的语法基础之后，你需要重点掌握一个的关于爬虫开发的基础模块。这些模块有很多可以供你选择，比如、等等，只需要精通一个基础模块即可，不必要都精通，因为都是大同小异的，在此推荐的是掌握，当然你可以根据你的习惯进行选择。
、深入掌握一款合适的表达式
学会了如何爬取网页内容之后，你还需要学会进行信息的提取。事实上，信息的提取你可以通过表达式进行实现，同样，有很多表达式可以供你选择使用，常见的有正则表达式、表达式、等，这些表达式你没有必要都精通，同样，精通个，其他的掌握即可，在此建议精通掌握正则表达式以及表达式，其他的了解掌握即可。正则表达式可以处理的数据的范围比较大，简言之，就是能力比较强，只能处理格式的数据，有些形式的数据不能处理，但处理数据会比较快。
、深入掌握抓包分析技术
事实上，很多网站都会做一些反爬措施，即不想让你爬到他的数据。最常见的反爬手段就是对数据进行隐藏处理，这个时候，你就无法直接爬取相关的数据了。作为爬虫方，如果需要在这种情况下获取数据，那么你需要对相应的数据进行抓包分析，然后再根据分析结果进行处理。一般推荐掌握的抓包分析工具是，当然你也可以用其他的抓包分析工具，没有特别的要求。
、精通一款爬虫框架
事实上，当你学习到这一步的时候，你已经入门了。
这个时候，你可能需要深入掌握一款爬虫框架，因为采用框架开发爬虫项目，效率会更加高，并且项目也会更加完善。
同样，你可以有很多爬虫框架进行选择，比如、等等，一样的，你没必要每一种框架都精通，只需要精通一种框架即可，其他框架都是大同小异的，当你深入精通一款框架的时候，其他的框架了解一下事实上你便能轻松使用，在此推荐掌握框架，当然你可以根据习惯进行选择。
、掌握常见的反爬策略与反爬处理策略
反爬，是相对于网站方来说的，对方不想给你爬他站点的数据，所以进行了一些限制，这就是反爬。
反爬处理，是相对于爬虫方来说的，在对方进行了反爬策略之后，你还想爬相应的数据，就需要有相应的攻克手段，这个时候，就需要进行反爬处理。
事实上，反爬以及反爬处理都有一些基本的套路，万变不离其宗，这些后面作者会具体提到，感兴趣的可以关注。
常见的反爬策略主要有：
限制
限制
限制
资源随机化存储
动态加载技术
……
对应的反爬处理手段主要有：
代理池技术
用户代理池技术
保存与处理
自动触发技术
抓包分析技术自动触发技术
……
这些大家在此先有一个基本的思路印象即可，后面都会具体通过实战案例去介绍。
、掌握、等工具的使用
有一些站点，通过常规的爬虫很难去进行爬取，这个时候，你需要借助一些工具模块进行，比如、等，所以，你还需要掌握、等工具的常规使用方法。
、掌握分布式爬虫技术与数据去重技术
如果你已经学习或者研究到到了这里，那么恭喜你，相信现在你爬任何网站都已经不是问题了，反爬对你来说也只是一道形同虚设的墙而已了。
但是，如果要爬取的资源非常非常多，靠一个单机爬虫去跑，仍然无法达到你的目的，因为太慢了。
所以，这个时候，你还应当掌握一种技术，就是分布式爬虫技术，分布式爬虫的架构手段有很多，你可以依据真实的服务器集群进行，也可以依据虚拟化的多台服务器进行，你可以采用分布式架构手段，也可以采用架构手段，都没关系，关键是，你可以将爬虫任务部署到多台服务器中就。
至于数据去重技术，简单来说，目的就是要去除重复数据，如果数据量小，直接采用数据库的数据约束进行实现，如果数据量很大，建议采用布隆过滤器实现数据去重即可，布隆过滤器的实现在中也是不难的。
以上是如果你想精通网络爬虫的学习研究路线，按照这些步骤学习下去，可以让你的爬虫技术得到非常大的提升。
至于有些朋友问到，使用系统还是系统，其实，没关系的，一般建议学习的时候使用系统进行就行，比较考虑到大部分朋友对该系统比较数据，但是在实际运行爬虫任务的时候，把爬虫部署到系统中运行，这样效率比较高。由于的可移植性非常好，所以你在不同的平台中运行一个爬虫，代码基本上不用进行什么修改，只需要学会部署到中即可。所以，这也是为什么说使用系统还是系统进行学习都没多大影响的原因之一。
本篇文章主要是为那些想学习网络爬虫，但是又不知道从何学起，怎么学下去的朋友而写的。希望通过本篇文章，可以让你对网络爬虫的研究路线有一个清晰的了解，这样，本篇文章的目的就达到了，加油！
本文章由作者韦玮原创，转载请注明出处。
作者相关书籍推荐
书籍名：《精通网络爬虫》

定位：零基础入门、中级
特点：知识点较系统、全书结合项目实战
不足点：出版周期时间限制问题，第一版中未涉及等其他工具的使用，暂未涉及分布式爬虫技术，这些额外的知识已通过博文补充。最近对的系统比较感兴趣，特拿来了 来尝试下对其内核版本升级一下，并做了笔记供需要的同学参考。

前几天在对张宁网进行更新改版，配置的时候碰见个问题：面板自带的所编译的版本过低导致有漏洞，对服务器运维十分危险。经过先期自我修复，并上报给官方对漏洞进行临时处理与预警。官方也及时解决了此版本过低导致的系列环境软件的隐患虽然官方处理速度还可以，不过态度有点那个，早先还以为是小白把端口了俩呢。不过对于已经停止更新的 ，这样的问题仍然存在。
于是，今天我突发奇想，何不装一个 来实战一波升级配置呢。说干就干。


关于 
简介
先来看看的介绍：

 是国内首个开源的主机面板，使用开源软件协议。 实现平台化架构设计，高可扩展灵活性，所有功能软件可选择定制下载安装。 支持用户自由弹性组建运行环境与切换环境，您可以下载安装不同版本的服务器、数据库、脚本软件自由组合创建您需要的运行环境。例如，您可以创建 、、、、等不同应用环境。环境支持所有版本共存，包括、、、、、

看上去还是很牛的嘛。不过这介绍已经仅适用于 版本的了。那么 是什么情况呢？

  为独立的一套虚拟主机面板，安装请使用纯净系统。编译安装方式 安装时间至分钟 编译安装支持的系统 支持目前 、、 以下版本   、  、  、  、  、  、   、   

实际安装 之后，我们看到其所带组件的情况如下：
：
   
  
        
   
  = = = __ ___ __ __ __ __ __
：
   
       
     
       

    |  
  =    =  = = = =            = = 

     
 
           \
     
    

          

         
        

本次任务
我们这次的目的是，将升级到 ，并解决引起的漏洞。同时将升级到 。
准备工作
对库进行升级更新
   
安装编译接下来几款软件时需要的依赖包
            
查看版本
  
    

这里，如果不是 或，则需要升级至上述版本。本服务器使用的是 ，鉴于服务器情况，需要升级到。

升级安装
  
  
   
   
   
    

修改历史的文件设置备份
   
   

设置软连接使其使用新的版本 刚刚安装的默认安装在
    
    

更新动态链接库数据
    
  
再次检查版本信息
  
     
如果是 ，则说明更新成功。
升级
下载、编译与安装 
请先回到主目录
 
备份备份旧版本的
    
下载 ，并解压后进入该目录
  
   
  
开始配置
   =  = = =            = = = =   
编译
    
出现如下所示内容，可判断是升级完毕：
 
     

       
           
          
           
           
          
       
           
          
       
             
         
   
   
               
   
   
    
    
             
测试——非必须操作
  
可能需要加上执行权限  
    
额外的配置
在、、三个文件中插入如下内容：
 = 
 = 
 = 
三个文件的路径如下：
 
 
 
另外，在文件中，也需要增加一点东西：
搜索_标签，在其下方加入如下内容：
=_
注意，这个需要看安装后给的  ，并确保这个路径内有_文件。
使升级的生效
重启
   
   
如上述命令无效，可以执行如下命令
     = =
   
 
查看是否启动成功
   |  
查看版本
  
升级
下载、编译与安装 
请先回到主目录
 
备份现有运行程序与配置文件。
   
下载 ，并解压后进入该目录
  
   
  
重新编译 ，这里我们参考新版 的，调整下编译的参数如下：
  = = = __ = ___  __  __ __ __ __ __
执行，这里我们不选择 ，因为我们只需要替换执行文件。
 
使升级的生效
停止相关应用：
   
接下来，我们需要备份旧版本的可执行文件并复制新的已经编译好的执行文件：
   
   
检测文件版本及编译情况：
   
  
        
       
   
  = = = __ = ___ __  __ __ __ __ __
启动以及相关应用：
   
  
如果显示  ，则说明已经启动，升级成功。
升级完成确认
可以通过 后台的查看升级后的结果，如图：

可以看到，检测到的  为 。

搜索相关参数，可以找到当前服务器软体版本为 。本次升级圆满完成。
小结
本来想升级到的，结果一直都不行。感觉配置上可能是和的动态链接库出问题了。不过因为最近有考试，就没再弄。
另外也是由于上述最后一个原因，时间问题，并没有尝试升级 的。等有兴趣了再说吧。不过看了下 的安装脚本，感觉集成环境的配置挺好玩的，等回头有空了研究下。

相关推荐
【腾讯云的种玩法】关于服务器反向代理 的一点思考脚本
腾讯云下从迁移到过程
 基本入门作者 | 王相军编辑 | 京露

王相军，腾讯助理工程师，毕业于哈尔滨工业大学，腾讯征信中心员工，乐于分享，希望大家一起学习，共同进步！

导语
花了一下午时间学习了周志华教授的新——《        》，论文主要介绍了一种新的集成机器学习方法——，其核心思想是：利用级联森林决策树集成方法去学习生成模型，一定程度上可以弥补的部分劣势！强烈说明：作为一个小菜鸟，里面有很多都是自己的个人理解，不对的地方希望看到的大神多多指教，感激不尽！！！ 
一、和的优缺点

需要大的样本集，在小样本数据集上表现不可观；
本身就是复杂的模型，所以训练过程很复杂，需要大量的复杂计算；
参数太多，需要花费大量的调参时间。坊间流行一句话：的训练更像是艺术，而不是科学或者工程；
在大数据集上的效果确实很好。

在大数据集上的表现和分庭抗礼，在小数据集上也表现很好；
参数少，调参简单，在很多领域的不同数据集上，使用默认设置，结果都很好；
训练过程简单、理论体系更易懂；
执行效率高，在一台上的效率相当于在机器上的效率；
并行度高，作为，有着天然的高并行性。
二、的方法论
的核心主要包括两大块：级联森林 和多粒度扫描 。
、级联森林 
级联森林的构成：级联森林的每一层都是由好多个森林既有随机森林，又有完全随机森林组成，而每一个森林又是由好多个决策树 组成，所以这种组合是集成的集成！其中每一层的随机森林和完全随机森林保证了模型的多样性！具体的级联森林结构如下图所示。

图  级联森林结构图
图中的级联森林每一层包括两个完全随机森林黑色和两个随机森林蓝色。每个完全随机森林包含个完全随机的决策树，每个决策树的每个节点都是随机选择一个特征做分裂，直至每一个叶节点包含的实例属于同一个类，或者实例数目不多于个；每个随机森林也是个决策树，每个决策树的生成是随机选择个特征输入的总特征，每次选择值最高的做分裂。
级联森林的迭代终止条件：迭代到效果不能提升就停止！！！
级联森林中每个森林是如何决策的呢？
每个森林中都包括好多棵决策树，每个决策树都会决策出一个类向量结果以类为例，下面也是，然后综合所有的决策树结果，再取均值，生成每个森林的最终决策结果——一个维类向量！每个森林的决策过程如下图所示。

图   每个森林的决策过程决策树中的叶子颜色代表不同的类
这样，每个森林都会决策出一个维类向量，回到图中，级联森林中的个森林就都可以决策出一个维类向量，然后对个维类向量取均值，最后取最大值对应的类别，作为最后的预测结果！
、多粒度扫描 
多粒度扫描是为了增强级联森林，为了对特征做更多的处理的一种技术手段。具体扫描过程如下图所示。

图  多粒度扫描过程
图是分别对序列数据和图像数据的原始输入特征做 处理的过程。
对于序列数据，假设我们的输入特征是维，扫描窗口大小是维，这样就得到个维的特征向量，每个维的特征向量对应一个分类的类向量，即得到：个维类向量！最终每棵森林会得到维的衍生特征变量！
于图像数据的处理和序列数据一样，图像数据的扫描方式当然是从左到右、从上到下，而序列数据只是从上到下。
当然，可以用各种尺寸不等的扫描窗口去扫描，这样就会得到更多的、更丰富的特征关系！
三、整体实现
整个实现过程附上一张大图。

图  算法的实现流程图
四、结果分析
、在大数据集上，分别和类、、、等算法做了对比。
图像分类数据集：：略低于，基本持平与；
人脸识别数据集：：人脸图像数量不同时，都最好；
音乐分类数据集：：最好；
手部运动识别数据集：：最好；
情感分类数据集：：最好。
、在几个小数据集上表现和很好。
五、总结
作为小菜鸟新人，自己写这篇文章的初衷只是简单的学习分享，把自己看到的觉得还不错的东西记录下来，以供交流学习；自己对的了解也有限，所以，这篇文章也没有任何要抨击的意思，自己也没有这个实力这是重点，哈哈哈！
最后，如果本文有写的不对的地方，请看到的大神不吝赐教！谢谢。


阁主点评：现在几乎人人都知道深度神经网络，但很少了解也有自己的劣势。作者王相军分享的这篇文章，让我们快速地学习了周志华教授的新论文，了解了这个新概念。我们腾讯云近期推出了深度学习平台，尝试集成一些最前沿的深度学习技术开放给广大开发者使用，推荐有需要的朋友尝试。

相关推荐
深度学习平台人人都可以做深度学习应用：入门篇上人人都可以做深度学习应用：入门篇下作者简介  ，叶轩，来自腾讯微信事业群，主要负责腾讯开源项目 地址：， 生物认证平台的开发、维护与运营。

提到指纹支付，你会怎么做？
假如有一天，产品经理安排你做指纹支付，并且要下版本就上，你会怎么做？
如果是产品大哥，就从工位下面抽出一把指甲刀架在他脖子上，让他跪在墙角唱征服；
如果是产品妹子，就让她请你喝咖啡，然后谈天说地，趁此机会告诉她“还是选择世界和平吧，比做指纹支付简单多了。”
当然，想象还是太温柔了。真正做过指纹支付项目的在下，经常会在半夜三更回忆起当年做指纹支付需求时候的噩梦，在梦里，我就给自己加戏，手撕产品经理。
也许产品大大们会发出抗议：“指纹支付而已，客户端现成的接口，有何难？”
系统接口行不行？
从年 第一款带有指纹识别功能的上市以来，“指纹支付”这个词就开始频繁出现在各个产品的列表排期中。但是， 以前的设备，并没有一个统一的指纹认证接口。这也就意味着如果你是一个苦逼的程序猿，那么你就要一家家适配各自的指纹方案，并且还要维护厂商的接口升级。如果结合市场的碎片化来看，想要全机型覆盖，简直就是 。实际上，在项目初期，微信便尝试了一家家接入，结果仅仅接入华为 和荣耀，便用了整整三个月！这种投入显然是得不偿失的。
好在，从 开始，系统提供了标准的。这一重大利好，让做着类似需求的程序猿们仿佛在黑暗中看到一丝光明，因为这个接口看上去是那么简单易用。无论你是什么品牌的手机，只要是 或更新的系统，按照下面的写法，就可以实现指纹认证功能：
  = 
     {} 
设计本身也很简单：

系统认证接口
看上去很完美，仿佛实现指纹支付根本不用开发个版本，只用小时，对不对！
但是仔细看下这个接口，感觉哪里不太对：接口仅仅返回认证成功失败，如果直接信任这个结果，手机被了，岂不是随时可以将认证结果从改为？
那我们换一种思路：的手机不让用指纹支付行不行？
傻孩子，那你怎么判断手机是不是呢？不也是通过接口获取的值么？这个值一样可以被改掉。
支付安全不可儿戏，一旦出问题，就是重大事故。所幸的是，也意识到了这个问题，所以在发布指纹认证接口的同时，增强了原本的接口，和接口联动代码实现可参考官方，链接：：

安全架构
这张图看上去不明觉厉，原理其实并不难：在 之后，允许用户在应用中生成一对非对称密钥，将私钥存储在中什么是？稍后会讲，任何人，包括应用自己甚至系统都无法获取私钥，除非用户使用指纹授权才能使用，签名或者加密传入的数据，然后输出密文。这样的话，就可以利用密钥的签名验签机制小白不懂什么是签名验签？下咯或者看这篇文章解释签名的部分，只有用户使用指纹签名之后，才能产生正确的签名，后台验签即可，这样就能保证链路安全。
这个设计非常巧妙，但是百密一疏：如果黑客在密钥生成的时候就拦截了请求，替换为自己的密钥，那么后面签名和加密，用的也是黑客的密钥，那么整套系统的设计也就崩塌了。

示意
另外还有一个问题，如果仅仅返回，那么只要是录入到设备内的指纹，就可以假冒你的身份支付。这对于家里有熊孩子的家长来说，简直就是银行卡噩梦。雪上加霜的是，对于设备而言其实也是一样，只要知道了锁屏密码就可以录入新的指纹。如果支付后台直接信任指纹认证结果，就相当于将原本非常秘密的支付密码，退化到了锁屏密码的级别。这样，无论支付后台做了多么严密的风控策略，按照木桶原理，从根本上整个系统就是不符合支付安全的。
当然，当时也有类似于链接： 之类的认证联盟，但是整个流程过于复杂，甚至还要求在应用后台植入。而且，类似方案的中心服务权限过高，会导致如支付笔数、开通用户数等关键指标为人所知，因此也就无法使用。并且支持设备数实在太少，也并无接入动力。
研究过这些之后，发现并不可直接使用任何一个方案，场面一度尴尬。没有合适的轮子，怎么办？
没有轮子，能造轮子么？
让我们回头看看系统的指纹接口设计：

方便的指纹接口，完美！
创造性得将指纹模块与密钥模块结合起来，使得用户授权即签名变得可能，完美！

那没有做到什么呢？

由于没有一个可信的信任根，导致密钥很容易被替换；
无法从认证结果中获取到底是哪一个用户授权本次认证请求；

同时，我们意识到，在生物认证领域这个千亿级市场中，缺乏一个统一、安全、易接入的认证标准，微信有这样的需求，其他应用也必然如此。微信有能力解决这些问题，实现自己的业务需求，也希望将成功经验复制。既然这样，借此机会制定一个生物认证标准，提供一个生物认证平台，微信责无旁贷，这就是的起源。
如果以做标准的要求来实现，那么除了刚刚所述的系统接口缺陷之外，系统设计时还需要考虑：

后台不存储任何敏感信息，包括对称密钥、非对称密钥私钥，更不能将指图案以任何形式传输或存储，防止应用后台被脱库；
如果有后台交互，不暴露应用方核心商业隐私，如认证次数、业务开通次数；
应用接入门槛低，客户端无须集成重量级，后台无须集成；
简单易用，第三方应用只需要操作上层接口，无须进行复杂的底层开发。

如何产生一个可信的信任根设备根密钥？
信任根的重要性之前已经说明。如果一个系统依赖密钥签名，有一个可以信任的根密钥，才有可能构建安全的信任模型。但是，如果一台手机出厂之后才产生根密钥，那么中间有足够时间窗口给到黑产从业者替换掉它。因此，常规方式产生根密钥一定是不行的。所以，我们有了一个大胆的想法：直接与厂商合作，在设备出厂之前，产线上生成设备根密钥，公钥通过厂商服务传输给微信密钥服务——。这个想法虽然对厂商改造比较大，但是由于我们直接通产业链上游高通、等合作，研发出了一套统一的解决方案，以及产线工具，成功说服厂商对产线做了最小化的改造。’     

设备根密钥流程

厂商在产线上对设备下发生成设备根密钥命令；
中生成一对设备唯一的非对称密钥，私钥存储在设备区域，没有任何厂商或者应用方可以读取包括微信与设备厂商，公钥以及设备导出；
公钥和设备上传到厂商服务器，之后通过公众平台安全接口，传输到微信公众平台；
微信公众平台将公钥与设备传输到微信服务器。
这里，我们又遇到了我们的老朋友：  ，后面我们也会多次与这个名词打交道。如果想要看详细的介绍，可以参考这里链接：__。 当然了，我相信大部分同学都跟我一样，只想要一个形象的解释。简单地说，你的手机中，除了类似这样的操作系统之外，还有一个独立的环境。这个环境目前并无行之有效的破解方法，也就是说即使了系统，都无法破解中的数据。如果将整部手机比作房子的话，操作环境就是客厅，就是你的保险箱。可想而知，如果将所有的数据都存储在，关键操作也在内进行，岂不美哉！当然了，这样的话，所有从中出来的敏感数据，就一定要添加上使用可信密钥对其的签名了。

有了设备根密钥之后，认证链的构造逻辑就清晰了很多：采用密钥链的形式，用已认证的密钥来认证未认证的密钥就可以了！
如何构造完整认证流程？
方法论有了，实施就变得简单。
但是，依然有一个问题需要思考：到底需要多少层密钥呢？密钥层数少，那么每一次都需要前往中心服务微信验签，对第三方应用而言，会更担心泄露自己的商业逻辑；密钥层数越多，会增加了传输复杂度和失败率。经过多方讨论，决定使用三级密钥，除了产线预制的设备根密钥之外，增加定义应用密钥每一个应用生命周期内只需要存在一对和业务密钥每一个业务需要一对。事实证明，这是一个明智的选择：这样既保证了流程的流畅度，又保证应用的关键商业隐私不暴露。为什么？往下看。
架构

架构图
我们十分欣赏的指纹和密钥模块接口设计，因此，我们与厂商合作，在此基础上添加包，即可迅速实现整个上层架构。
准备应用密钥

准备应用密钥流程示意图

应用第一次启动时，或者在第一次使用业务之前，请求生成设备根密钥
密钥生成之后，私钥在被保护，加密存储
公钥和设备等相关信息，在内直接被设备密钥私钥签名之后，返回给应用
应用将公钥相关信息和签名传输至应用后台
应用后台通过微信公众平台后台接口，请求验签
使用对应的设备密钥公钥验签，通过之后返回给应用
应用后台存储对应的应用公钥。

传输给后台的原串示例：


注：自设备出厂即在中存储。每一次相关操作都会使该值自增，后台存储该放重放因子。如果后台发现本次请求防重放因子比已记录的值小，则可认为是非法请求。
注：本意为系统中用户，在系统中，一般而言每一个应用都有一个，可用于区分应用以及权限控制。注意，不同，对应的应用密钥与业务密钥均不同，后台应将与_一起区分密钥。
准备业务密钥 

准备业务密钥流程示意图

应用在开通业务时如指纹支付，请求生成业务密钥。同时，在生成时声明该密钥除非用户指纹授权，否则私钥不可使用。
密钥生成之后，私钥在被保护，加密存储
公钥和设备等相关信息，在内直接被应用密钥私钥签名之后，返回给应用
应用将公钥相关信息和签名传输至应用后台
应用后台使用对应的应用密钥公钥验签，无须请求微信中心服务
验签成功之后，应用后台存储对应的业务密钥。

传输数据与含义与应用密钥相同，不再赘述。
认证流程
认证流程示意图

客户端请求后台，获取挑战因子
获取挑战因子之后，将挑战因子送往，准备签名结构体，准备签名；
应用请求用户指纹授权；
用户指纹授权后，直接将本次认证使用指纹在本设备内的索引传输给密钥模块，在内使用业务密钥私钥签名挑战因子以及该索引。

应用获取原串与签名串后，传输至应用后台。应用后台使用对应的业务密钥公钥验签，如果成功，则此次认证或者开通请求合法。
传输给后台原串示例


流程是否符合要求？
轮子造好了，我们在自我欣赏的路上越走越远。回过头来看，是否满足了我们的要求呢？

添加信任根：在工厂环境中传输设备根密钥，保证信任根安全
可区分指纹：认证之后，内部直接传输本次使用的指纹，可使应用自由选择是否区分指纹
后台不存储敏感信息：后台仅存储设备和公钥，从此即使后台设计再烂，也不再害怕脱库
后台交互不暴露隐私：独创应用密钥，保证业务开通、业务使用量等不需要经过应用服务器
后台不需要：后台使用成熟的公众平台接口，文档丰富，学习成本低，更无须。

当然了，我们的方案得到了各大厂商、芯片上的认可，在短时间内，已经拥有了数亿设备的支持，覆盖几乎所有的主流手机品牌，因此应用接入完全无须考虑是否需要多设备适配，或者质疑适配不足。顺便，我们支持了和的指纹机型，即使系统本身不具有统一的指纹接口。
然而，还有最后两点没有做到：

客户端接入门槛低，客户端轻量，甚至不需要；
简单易用，客户端无须进行深度开发即可使用。

解决这两个问题的方法只有：开源！
我们开源了什么？
为了满足不同应用的不同场景，我们开源了：

客户端核心接口：内部操作密钥、调用指纹的直接接口。大小约，对安装包大小增量可忽略不计；
客户端过程封装接口：封装了具体流程以及适配问题机型。大小约，安装包大小增量更少；
快速上手的客户端，从零开始，帮你短短几行代码实现指纹支付；
完整的客户端文档和后台接口文档；
完整的原理剖析和快速入手。

这一切，尽在 地址：。
使用最快能多块？如果你只需要做锁屏之类对安全性要求不高的需求，只需要：

添加依赖在项目的中，添加 依赖
 {    
          
           
       
}

声明权限在 中添加使用指纹权限
 =_

初始化初始化过程整个应用声明周期内只需要进行一次，用于生成基本配置和检查设备支持情况。你可以选择在的中，或者在使用之前进行初始化。
  =  
  场景值常量，后续使用该常量进行密钥生成或指纹认证

   {} 

准备密钥需要在使用指纹认证之前生成相关密钥
  {}    

进行指纹认证密钥生成完毕之后，可以使用封装接口调用指纹传感器进行认证。


  =  
                                      
                                      
  
                                       
    {}
  {} 
当然了，如果你想要实现指纹支付、指纹登录等高安全性场景，还有一些其他工作要做，具体可以参考我们的示例代码链接：和安全接入文档链接：。
地址：开源之后，已经有包括微众银行在内的多个应用已经接入，这些应用接入的时间均不超过一个版本。使用的场景也从指纹支付，到指纹登录、指纹解锁。用过的，都说好。
那么，让我们再回顾下开头的场景：“我们要做指纹支付，下个版本上…”，想必你已经知道怎么做了，括弧逃

原文来自：腾讯开源一、前言
时值建军周年之际，相信大家的朋友圈都被好友的“军装照”引爆刷屏。而在运维圈，则更多是被腾讯织云运维平台的运维能力所深深折服，并燃起熊熊的探索欲望。然而，在内部，系统的最后端，还活跃着一群低调、坚韧的攻城狮没错，就是我们的团队。社交网络运营部的数据组，负责着、、相册、以及腾讯云等整个产品的数据运维，保障、空间等社交产品的稳定运行，以及腾讯云上对外数据库产品的日常运维。目前数据团队拥有亚洲最大的分布式数据仓库，日均数十亿的访问，过万台的机器设备。这么庞大的体量、繁复的工作，我们是怎么完成的呢？
二、提升效率
随着业务的不断发展，新产品的不断开发，数据容量也不断增大：仓库数量也由原先的几十个逐步增长到几百个，机器数量也达到了惊人的几万台。随着等数据库组件在腾讯云上售卖，面对的网络环境由原先的自研网络逐步扩展到腾讯云、私有云等网络环境，网络差异带来的运维工作量和复杂度也直接翻倍。日常设备维护、机器上架、组件版本升级、仓库扩缩容等，这么庞大的体量和工作量，给我们团队提出了严峻的挑战。
相对于层和逻辑层等无状态、轻量级的组件，数据层组件则显得沉重很多。数据层组件有状态、重资产数据，很多的运维操作过程复杂，更多的涉及数据搬迁。既然数据层对状态维护、准确性、一致性有着苛刻的要求，又希望能够适应业务的发展而做出快速调整，团队依托织云利用织云提供的，如命令通道、包发布等研发了自己的数据库管理平台：鹦鹉螺。鹦鹉螺将所有的运维操作分解为细粒度的原子操作，再通过流程把原子操作串联起来完成复杂的功能。前端用户发起的运维操作最终落到后端具体的原子任务或流程上。
例如对仓库接入机的扩容操作，用户在前端只需填入需要上架的机器列表，提交后由后端作业平台自动发起扩容流程并负责调度。
 
三、系统总体架构
 
    上图是鹦鹉螺系统的核心模块，主要包括、变更中心即作业平台、数据中心、决策中心，还有前端的展示模块等。其中记录了仓库相关的配置信息，如仓库包含的机器设备、所在网络区域，接入的业务信息，机器的角色信息接入机角色、配置中心角色、角色等等。变更中心也就是作业平台，是实现运维操作的关键，鹦鹉螺系统对现网的所有操作都通过这个模块完成。数据中心包含了现网仓库的运行数据、指标数据、和相关告警数据，这也是决策中心的数据来源。在决策中心中，完成一些告警的预处理。对于常见的有预处理方案的告警，可以在这里设置，当告警发生时，由决策中心发起相应的处理措施。
四、变更中心作业平台
变更中心，也就是鹦鹉螺系统中的作业平台。它是一个分层的架构，从下往上，依次是底层工具层、任务层、流程层，总体架构图见下图。采用分层结构，任务层、流程层并存，主要是基于实际的运维场景需求。为了实现快速调整的能力，这里把所有的运维操作场景，都分解为最小粒度的原子任务原子操作，再由原子任务原子操作串联组合成流程来完成复杂的运维操作。
 
基础设施层主要是对一些基础工具和周边系统接口进行封装，方便上层模块调用。其中不同网络的差异也在这一层进行抽象适配，例如远程命令通道，对上层应用暴露统一的通道接口，在接口内部再根据目标所在网络区域不同分别调用不同的命令通道处理。
任务层主要是负责原子任务的托管、调度。一个原子任务是一个最小粒度的操作，它可以独立运行可以在上发起，或者通过平台提供的发起执行，也可以同其他原子任务组合形成流程依次执行。在鹦鹉螺的作业平台中，原子任务划分为两类：本地任务和远程任务。远程任务，顾名思义，即需要到目标机器上执行的任务，它可以是一个脚本或者脚本，执行时需要用户给定目标机器列表，由框架将任务脚本分发到目标机器上发起执行，并把执行结果整理返回。本地任务，同远程任务相对应，即不需要在远程目标机器上执行，而是在运维系统的管理机上执行。在我们实际工作中，个别运维场景会使用到这类任务。原子任务的编写，我们做到了平台无关性，即用户编写原子任务时无需关心平台框架的任何东西，只需完成原子任务所要完成的功能即可。
流程层主要是负责流程的管理和调度。一个流程就是若干个原子任务的编排。在实际业务中，大多数运维场景都不会是简简单单的一个操作就能完成，复杂的业务操作需要由若干个原子任务按一定顺序组合而成。在流程支撑模块中，可以根据不同的业务场景，制定不同的任务执行策略，流程的执行支持失败重跑、部分成功等。
无论是原子任务还是流程，作业平台都提供了统一的调用接口，以达到任务、流程复用的目的。整个作业平台，是鹦鹉螺的基石和核心，所有对现网的操作，都是通过任务、流程来完成。
五、数据中心
数据库组件在运行过程会产生很多的运行数据，这些数据对我们了解组件的运行状态、服务情况起到至关重要的作用。在内部，数据库组件在开发的过程中会定义好若干个一般有几百个属性，如收到的请求量、处理耗时、主备同步差异等等，并在现网运行过程中将这些属性值上报到织云监控中。因此对这些数据的分析、计算，是我们掌握数据库运行状态的最佳数据来源。鹦鹉螺中数据模块的大致架构如下：
 
数据总线采用方式收集组件各个属性的实时数据，按照一定的规则对数据进行简单的过滤清洗，最终将数据落地到本地数据库中。计算单元从本地中读取相关的元数据，按照预设的算法、规则，对元数据进行实时计算、聚合，产出具体的指标数据或告警数据。前端可以从这里拉取指标数据进行实时的绘制，告警数据则可以按设置的规则发送给业务负责人或发送到决策中心进行告警预处理。
六、决策中心
目前我们的决策中心主要是一些告警的预处理决策。我们对那些常见的、有既定排查和处理方案的告警抽象为可识别的规则，配置到决策中心。外部网管产生的告警或数据中心计算产生的告警，首先发送给决策中心，决策处理模块根据告警的类型，在规则库中查找对应的预处理方案。当需要对现网发起变更时，则调用作业平台上相应的原子操作或流程进行变更。
七、未来方向
正如上面说到的，我们的组件在代码层面就做了很多的埋点，组件在运行过程中会以分钟为粒度上报每个属性值，因而我们有大量的元数据可供分析每天上亿条元数据。按照以往方式在代码层面写算法，分析数据，显然不能够充分发挥现有数据的价值。在未来，我们计划引入机器学习，将落地到实际运维场景中，比如访问量、流量的异常检测；异常发生时的根因分析、关联分析等等。在决策模块引入，利用有监督、无监督抑或强化学习等，打破预设专家规则模式的局限，进一步强化决策能力。事实上，我们也已经在机器学习上迈开了步伐，探索的未来。作者：

导语
写下这篇文章的缘由是因为在项目过程中，碰到了一个使用处理  类型数字的坑。
与大部分现代编程语言包括几乎所有的脚本语言一样，中的数字类型是基于   标准来实现的，该标准通常也被称为“浮点数”。使用的是“双精度”格式即位二进制。
较小的数值
不仅仅是，所有遵循   规范的语言都会碰到如下问题：
   ===   

从数学角度来说，上面的条件判断结果应该是，可实际上却为。
这是因为，二进制浮点数中的  和  并不是十分精确，它们相加的结果并非刚好等于  ，而是一个比较接近的数字  所以条件判断的结果为。
那么该如何处理这种语言上的缺陷呢？
最常见的方法是设置一个误差范围，通常称为“机器精度” ，对的数字类型来说，这个值通常是。
从  开始，该值定义在中，我们可以直接拿来用，也可以为  之前的版本写：
  {
     =  
}

可以使用来比较两个数字是否相等在指定的误差范围内：
   {
         
}

  =   
  = 

   
   

中能够呈现的最大浮点数大约是 这是一个相当大的数字，它定义在 _中。最小浮点数定义在 _中，大约是，它不是负数，但无限接近于！
中整数的安全范围
上述数字的呈现方式决定了“整数”的安全范围远远小于 _。
能够被“安全”呈现的最大整数是  ，即 ，在  中被定义为__。最小整数是 ，在  中被定义为__。
实际上，在前端的应用场景中正负    是一个绝对够用的安全整数范围，然而在的服务端开发中就不一定了，如数据库中的位现在号已经需要用来存储了。由于的数字类型无法精确呈现位的数值，所以比较将它们保存转换为字符串。
我遇到的坑
上个项目，在使用 协议下文简称协议与其他语言的后台服务通信的过程中关于 协议的介绍可以参考本人的这篇文章，需要将从服务拿到一个类型用户帐号的整数透传给服务。
其实之前也在协议中遇到过类型定义的字段，但是当这个整型小于__时，我们将它当作正常的类型处理是完全没有问题的。不过，这次我遇到的字段的值全都大于__，这时我还将它当作类型来处理，导致服务中根本查询不到我传过去的用户帐号。
例如，我从服务拿到的实际用户帐号是，当我将它转换成后，变成了，传给服务后，服务告诉我系统中没有这个用户。。。没有之前我还以为是服务出了，因为我啥都没做，就是数据透传而已啊！
解决方案
当我们确实需要在中对大数值进行处理时，目前还是需要借助相关的工具库。
实际上在使用进行通信时，我会使用这个库帮我处理到的类型转换，而本身是依赖了一个工具库  来对  和  进行处理， 会将上述两种类型转换成类型对象实例。提供了很多供我们操作，比如将类型对象实例转换成其他类型，，，或者将一个其它类型转换成类型对象实例，具体的可参考  
例如，当我从服务拿到一个类型的值，此时并需要进行处理时
  = 

  {
     {
           正确
    }
     
}

  {
     {
           错误！很可能大于__，转换成后会不精确。
    }
     
}

 已经是一个类型对象实例： {      }
 =    正确！
  =    错误！

然后再将通过协议传给服务时，要做一次类型转换，将类型转换成类型对象实例。
 =  

参考资料

《你不知道的中卷》
 使用技巧

广告时间
你现在看到的文章，是由搭建在 实惠好用的腾讯云服务器 上的前端社区所提供！

原文链接：


相关推荐包学会之浅入浅出：开学篇一个只有行代码的流程框架随着  公司的崛起，深度学习和强化学习已经成为了人工智能领域的热门研究方向。除了众所周知的  之外， 已经与著名的游戏公司  合作，准备挑战热门的即时战略游戏  。之前  已经成功地使用   和   来搭建能够自行玩游戏的人工智能，并且成功挑战了  的一些游戏。虽然目前还没有成功地使用  来战胜   的顶尖职业玩家，但是  却能够带给大家无穷的想象力和期待。
那么强化学习到底是什么呢？其实，强化学习其实是一个交叉学科的产物，本质上是为了学会自动进行决策，也就是“ ”的问题。在计算机领域就体现为机器学习算法，在经济学领域就体现为博弈论的研究，在神经学领域体现在理解人类大脑如何做出决策。这一类问题本质上都是一个问题，人为什么能够并且如何做出最优决策。强化学习是一个序列的决策问题，需要选择一系列连续的行为，在这些行为结束之后能够获得最大的收益。一开始并没有任何标签告诉算法应该怎么做，是通过这个持续动作的行为来调整之前的结果。通过不断地持续调整，强化学习算法就能够学习到在什么样的情况下选择什么样的行为可以获得最好的结果。
与机器学习相比，泛函分析已经是数学史上一门传统而经典的学科。泛函分析是分析学的一个分支，其研究的主要对象就是由函数构成的函数空间。它是从变分问题，积分问题，理论物理的研究过程中逐步发展起来的。那么泛函分析是怎么和机器学习中的强化学习结合到一起的呢？本篇文章将会从强化学习的定义出发，一步一步地给读者介绍强化学习的简单概念和基本性质，并且会介绍经典的  算法。文章的最后一节会介绍泛函分析的一些基本概念，并且使用泛函分析的经典定理    来证明强化学习中   等算法的收敛性。一、从移动迈向  时代
本届   开发者大会于北京时间年月日凌晨点，在美国加州山景城的海岸线圆形剧场准时开始。本次   大会现场参与人数超过人，在个国家同步直播，全球开发者们一起见证  带来的科技盛宴。
在过去的一年中，全球已经有亿人在使用的服务，有超过亿人使用 ， 全球活跃  设备量已超过亿台。在移动时代， 无疑是行业巨头，而在今年，   宣布， 正式从移动时代跨入  时代。
那在网民口中充满不确定性的  大会今年有哪些亮点内容呢？一起来看看。
二、亮点解析  的人工智能时代
在今年的  大会上， 宣布从移动互联网时代进入人工智能时代。在过去的一年中， 在  的研究以及应用上投入了很多资源，比如智能语音，图像识别，硬件设备等。在今天的    大会上， 展示了  在现有产品的应用。

自动深度机器学习模型
、  图像识别系统
  是一个人工智能与大数据结合的图像识别系统。  可实时识别摄像头感知到的一切，并能结合   将图像内容与网络数据链接，完成与人的交互。

 功能展示
、   室内导航
 在人们日常生活的应用非常丰富，比如户外导航。但今天  像世界介绍了新一代定位系统 。 是 、  与   技术的结合应用，能提供室内的  导航能力。以往的  导航，你可以找到某一个地点。但在  中，你可以直接精确定位到室内的某一个物体。


室内导航产品模型
 、智能语音与图像处理
在今年， 将智能语音服务更加细化，比如在   与   中，可根据不同人的声纹自动区分语音指令从而进行基于声纹的帐号管理。你根本不需要切换帐号来保护隐私。
今年  将图片人工智能技术应用到   中，从而丰富了   的产品形态。例如新增了智能推荐分享、智能影集等创新功能。并且将  、 以及   结合，能更加智能的对图像进行识别，正如 所说：“  比你看到的更多”。
、
 是  所有  研究与产品的集合。包括研究、硬件、应用等领域。目前  的  技术已经应用于生物医疗领域，例如癌症诊断等。

 产品概念图
 还发布了二代机器学习处理器 ， 性能更优，可提供高达每秒  的运算速度。为了分享这一技术，让更多人体验  的进步， 将   上线到  云。开发者可以在  云上使用 、 、   等不同的机器学习处理器。

二代机器学习处理器 
三  看点与安全性
  在月发布了预览版本，于是今天的  大会  占的篇幅较小，从这一点  就展现了   的策略。今天  从以下几个方面像我们简短介绍了  的改变。
、   新特性
、  画中画模式  现已支持  的画中画模式。 是一种多窗口显示模式，多用于视频播放，即你可以一边发微信一边看视频。
画中画模式其实并不是一个新鲜的事情，以往用户可以在第三方应用中体验到，但这次  将其内置到系统特性中，增强了  与系统操作的衔接性。

模式演示
、 自动填写服务
  的自动填写服务，帮助管理应用间的帐号密码。解决了用户在登录不同  时重复输入用户名密码的操作。
、   智能选中服务
智能选中服务基于  的智能文字识别技术，可以自动识别短语、邮箱、电话、地址等，并能结合   做出交互响应。
 
   演示
、   性能与安全性
一直以来  系统的性能问题就被用户所诟病。此次发布的   优化了    使开机速度提升了倍，应用的运行速度也得到了提升。
在安全性上，  针对内部  做了优化，例如应用的  对象将在多进程模式下运行。网页内容在独立的进程中处理，此进程与包含应用的进程相隔离，以提高安全性。
在   中，也增加了对手机的威胁监控，每天会扫描超过亿的应用，发现恶意已经会立即清除。

 威胁监控
、支持 ，无缝兼容 
  正式支持  开发语言。是有  研发的基于  的编程语音。除了无缝兼容  以外， 还对  进行了扩展和封装，使接口调用更方便。这一举动体现了  一直以来的开放，世界各地的开发者也对此次兼容非常兴奋。

开发者态度
、推出   系统
 还推出了一款面向新兴市场的   系统，  是轻量级的  ，主要让用户在低端机型上也能流畅使用  系统以及应用程序。 并且针对低端机型的内存管理和流量管理做了定制优化。
四 总结
除了以上内容外， 还发布了很多新产品，例如新一代  设备 。例如  的   等，都是与  结合的产品。
每一届   大会都是科技与互联网领域的风向标。今年  发力 ，在  上上投入了很多研究资源，期待  明年能待着更好的  产品归来。
同时，腾讯作为中国安卓绿色联盟的创始企业，也不断为  生态做出贡献。目前   已经正式上线，腾讯云乐固团队也已全面兼容  ，欢迎广大开发者体验使用。作者：
团队：腾讯移动品质中心

导读
随着互联网浪潮的推进，手机进入了高速发展期，随之而来的“不可替代性”也越来越弱化。有数据显示，用户对出现问题的容忍度呈现越来越低的趋势，在这种背景下，自身的质量就显得尤为重要。
我们总是希望在产品发布前发现所有，但这对测试来说根本无法做到，因为理论上来说，总有要到产品发布后才能发现。
、测试资源的有限
作为测试，经常被要求测得“又快又好”，在有限的测试时间里，我们需要沟通新需求、设计测试方案、执行测试用例、回归已解决问题、评估版本风险等等。紧凑的发布节奏下，决定了测试内容是有取舍的，比如我们常用的办法是把的时间投入在验证新功能和产品的核心功能上，从而会忽略一些我们自认为的“不重要”测试项。
、终端环境的多样
你的在一种测试环境下运行正常，就代表发布之后质量吗？当然不是！用户终端的多样性决定了几乎所有产品都不可能做到覆盖完全，最常见的有网络、系统、机器品牌等，一旦出现问题，发布后影响的是该类环境下的所有用户。
、实验室数据的不可靠
我们设计测试场景时，总是尽可能把自己想象成真正的用户，从他们的视角去测试。但不得不承认，很多时候测试结果和发布后用户的反馈是不相符的。比如性能测试，我们制定了各种方案保证产品的快和流畅，但发布后还是有不少用户反馈慢和卡。这不是谁的错，用户数据的复杂性是任何发布前的实验室数据无法完全模拟到的。
既然发布后有 是不可避免的，那我们能做的，就是在正式发布前让尽可能的暴露，避免流落到更大范围的群体中，影响用户体验和产品口碑。
这里有两个要点，第一，为了更贴近实际效果，我们需要一批“真正的用户样本”而不是几个测试人员做测试；第二，区分于论坛等渠道，我们希望这批用户有更积极的反馈动力，能主动帮助我们快速获取产品的短板，优化和提升产品质量。
众测的出现恰恰满足了这个需求。众测用户分散在全国各地、各行各业，他们在生活中就是我们产品用户里最普通的一份子。但另一方面，不同于普通用户，他们充满探索精神，乐于尝试新产品，而且在众测奖励制度的推动下，他们乐意主动反馈使用过程中的问题。
什么样的测试任务适合放众测
、有效率要求的
众测的核心优势之一在于使用灵活，可以结合任务自身的需要调整，快速获取想要的结果。一类典型的使用是 上手门槛低，但数量庞大的任务，通过发挥众测用户的人数优势，可以快速完成任务。相比人工测试，效率高很多。 众测使用举例：数据标注。
、有环境要求的
这种适用于 对机器覆盖度、测试人群、运行环境有要求的测试任务。这类任务可以利用众测环境多样化的优势，有选择的对特定用户群分发任务，相比人工测试，可供选择的测试资源更加丰富，环境覆盖更加全面。 众测使用举例：问题复现、兼容性测试。
、有客观性要求的
测试人员不可避免会带有一定主观性，通过众测的形式能充分利用众测人群年龄职业性格的多样化，对汇总的测试结果综合计算，给出更客观的评估结果供产品决策。 众测使用举例：标签准确性判断。
军团的使用
军团是众测为长期任务培养的固定用户群体，也是众测服务的亮点之一。军团的最大优势在于团员长期接同类任务，对测试内容的熟悉度和理解程度会比普通成员更高，反馈的有效性也会更理想。
、军团的培训
结合测试内容的特点，以任务的方式对军团发布学习文档，并辅助以考题检验军团学习成果，提升军团对基础技能的理解和掌握，从而提升反馈有效率，减少无效、无关反馈。
、团长审核
要求团长对军团反馈的问题做验证和筛选，标注“重点关注”，减少我们的审核投入。 团长复现：团长用自己手机对重点问题做复现，二次确认复现概率 输出报告：团长汇总输出众测结果，给到提测方。
、军团自运转
通过添加方式，对众测军团定向下发灰度包，团长把控测试节奏和输出报告，达到“自运转”的效果。
众测结果的保障
、反馈正向激励
积分奖励是驱动用户测试的最直接原因。众测的积分体系可以激励用户积极领取任务和反馈问题。在此基础上，众测的等级制度，能鼓励和支持有能力的用户承担更多的管理和汇总工作。
、无效反馈惩罚
为了保障测试结果的可靠，我们会对测试结果抽样检查，一旦发现与反馈不符，有严格的惩罚机制，以此来提升众测用户反馈的有效性和准确性，减少消极用户。
、测试过程监控
一种理想的状态是用户提交反馈时，我们能够获取他的测试范围，这有两个好处，第一我们能以此评估他测试结果的可靠性，比如一个用户没有跑测试场景就给出的结论，我们可以判定他的反馈无效，第二对于有效反馈，我们能够拿到用户的问题出现路径，进一步定位解决。
、线上反馈重合度
产品正式发布后，结合线上反馈对众测结果进行和重合度分析，进一步优化众测策略，形成良好的循环。
众测的使用分级
参考的 ，我们将众测分级为几大类，每类对应一些指标，众测的使用者可以尝试以此定级，朝着更高级别去努力。以下是几个重要的衡量指标：
任务类型：越能体现众测与外包测试优势的任务，级别越高；
使用阶段：我们知道，发生的越早，解决的成本就越低，鼓励众测尽可能在早期应用；
测试准备：对测试环境的限制越少，越贴近用户的真实使用场景，级别越高；
反馈要求：对用户反馈内容依赖性越低的，级别越高。
 
任务类型：用例执行、悬赏、场景覆盖 使用阶段：产品集成以后 测试准备：要求用户在指定的测试包或环境下测试。
反馈要求：需要用户提交反馈信息。
 
任务类型：功能探索、风险评估；
使用阶段：增量测试期 发布准备：自动下发，用户无需准备测试环境；
反馈要求：提测包预埋，用户反馈时自动回收。
 
任务类型 用户数据收集；
使用阶段：需求体验期；
发布准备：模拟环境比如云测试；
反馈要求：后台长期监控。
军团进阶使用—从有用到好用
什么是军团？
军团是众测的一种特有模式，简单来说，根据任务需要，将众测用户分组成立军团，并配备团长，定制化的为提测方提供服务。
军团适用于哪些任务模式？
、同类型任务
有一类任务特点是：数量大，类型比较相近。 比如三方测试，内核发布时，我们需要大批量测试线上头部个，确保新内核的发布不影响线上合作方的基本功能。
【使用技巧一】
由于军团是长期测试人员，对他们进行基础知识培训，不仅有利于提升反馈有效性，更重要的是，可以发挥众测用户的能动性，帮助我们进一步定位问题。 举个例子：基础知识手册里解释了和系统内核的差别，在此基础上，我们请用户在反馈的同时，对比系统浏览器，区分“合作方”和“ ”，从而能快速筛选出相关问题，提升跟进效率。
【使用技巧二】
团长审核是军团任务中非常重要的一个环节。好的团长可以承担大部分审核工作，大大减少提任务方的后期投入。当然，不同任务对团长的要求以及侧重点是不一样的，我们建立了团长规范，明确指引团长反馈定级、复现、以及报告输出。此方法对我们这种一次提测二三十个的任务方，效果还是很明显的。

、长期任务
长期任务适用于长线的、重要的，需要长期关注的测试内容。 举个例子，前一阵的合作方王者荣耀，部分用户出现登录不上的问题，通过定位排查，发现是网络层一个随机问题。本身随机且发生概率不高，但是王者荣耀用户基数巨大，登录又是个非常关键的入口，因此问题优先级很高。
这之后，一方面，我们跟众测合作，召集众测用户中的王者荣耀玩家，成立“王者荣耀军团”，建立长线任务，收集王者荣耀相关反馈，另一方面，我们对这部分用户添加，发布时，第一时间对军团成员下发最新内核。这样做有三个好处：
【效果一】针对类型划分军团，类似于用户画像，能收集到真正的用户，更高效。比如建立购物类、游戏类、音乐发烧友等
【效果二】我们将测试左移，提前发现真正用户的问题； 
【效果三】军团用户可作为反馈复现的定向下发群，随机跟进问题。
、自运转
“自运转”是军团进阶的最理想状态。 以为例，我们知道，产品是合作应用的和内核结合的特殊形态，双方在发布上是解耦、互不干扰的。因此我们跟众测合作，建立五大“自运转军团”：
“游戏迷”：某某荣耀，某某助手，某某联盟，某某火线 ；
“购物狂”：某东、某某会 等；
“视频达人”：某某视频、某某直播 等；
“音乐王子”：某某音乐、某某歌 等；
“工具高手”：某某宝、某某天气、某某相机 等。
这样做的好处有几点： 
我们只要将军团加入灰度集合，则可自运转，不再需要每版本专门提任务； 
相比原来的“提任务”模式，不限制测试期限，有可能发现一些潜在的问题； 
同类型的场景有相似性，更适合发现类似问题； 
一旦有线上反馈，我们能更精准的找到合适的人群来帮助复现。
搜索微信公众号：腾讯移动品质中心，获取更多测试干货！导语   在上周发布的中，最吸引我的，不是那蠢萌的兔耳朵，而是苹果的。在苹果用取代的背后，是强大的视觉算法支持，让有能力识别各种欺骗和伪装，从而敢于将作为最重要的安全校验手段。


正如大家所知晓的，深度学习算法最近迅猛发展，推动着人工智能的发展。年在数据集上的成功，使沉寂已久的卷积神经网络   再次获得人们的关注，，等一系列模型的提出赋予了计算机接近人类的视觉能力。循环神经网络   在自然语言处理和语音识别等领域的应用，突破了传统模型难以把握时序数据的瓶颈。深度学习作为一种基础能力，推动着迁移学习、强化学习等一系列相关学科的发展，当然，这里面也包括了视觉相关的变革。
为此，我们将多个经典的深度学习算法和模型，融入到算法库中，并通过平台给大家使用。目前的深度学习类目，已经集成了种不同算法，分布于如下大类：

本文将会重点介绍计算机视觉领域的几种经典算法，包括其原理、模型和适用场景。其他领域之后也会陆续有文章，请大家要持续关注哟～
计算机视觉概要
计算机视觉是一门研究如何使机器“看懂”世界的科学。计算机视觉采用图像处理、模式识别和人工智能技术相结合的手段，着重于对一幅或多幅图像进行分析，从而获得需要的信息。因此计算机视觉也可以看做是研究如何使人工系统从图像或多维数据中“感知”的科学。具体来说，计算机视觉包含物体的检测和识别、物体跟踪、图像恢复移除噪声等和场景重建等。
从年摘下视觉领域竞赛的桂冠以来， 便一发不可收拾，每年都不断被深度学习刷榜。下图中的这些模型，代表了深度视觉领域发展的里程碑。随着模型变得越来越深，的错误率也越来越低，在上的结果已经达到了附近，而在同样的数据集上，人眼的辨识错误率大概在，也就是说深度学习模型的识别能力已经超过了人类。


经典算法和模型
、等网络不仅在上取得了很好的成绩，而且还可以被用于其他场景。为了方便用户能灵活快速地训练这些模型，我们在中，集成了这些算法。用户可以在上直接拖出对应算法节点，无需再编写复杂的网络定义和模型训练代码，就可以对相应的图片进行训练，得到一个基本可用的模型。当然了，如果要效果好的话，还是要自己耐心慢慢调试的哈～
 
的网络结构如下图所示，可以看到在大体结构上仍遵循了传统的原则，由卷积、下采样和全连接层逐一构成。图中诡异的“上下分层”的画法其实是指的并行。


在上能取得较好的成绩，除了利用较深和较宽的网络结构来增强学习能力外，在数据处理和训练技巧上还有以下几点值得借鉴：

 

 数据增强是一种在基础数据上进行一系列操作，从而得到更多数据，来增强数据集的多样性的手段，可以在一定程度上减少过拟合。在上训练时用到的数据增强方式有以下几种：
   水平翻转
   随机裁剪
   颜色光照变化等




是指在深度学习网络的训练过程中，对于神经网络单元，按照一定的概率将其暂时从网络中丢弃。对于随机梯度下降来说，由于是随机丢弃，因此可以看做每一个都在训练不同的网络。它是防止网络过拟合，增强模型泛化性的一个有效方法。

下图左边是常见的层连接，每一次都相当于从原始的网络中找到一个更“瘦”的结构，像右图那样。在训练阶段，我们设定一个因子，范围为，表示在前向计算阶段需要随机断开的连接的比例，并且在反向传播时只更新没有断开的权重值。在测试阶段则需要使用全部的连接，但这些权重都需要乘上。
需要注意的是，每一次的断开和更新都是以的概率随机实现的，因此每次迭代时的断开都不一样。对于一个有个节点的神经网络，假设因子=，那么在前向的次数足够多的情况下，在整个训练过程中会得到种连接组合，也就相当于训练了个模型，最后得到的是个模型的组合。



激活函数

激活函数与传统的或函数相比有以下几个优点：
  前向计算和反向求偏导的过程都非常简单，没有复杂的指数或除法之类的操作
  不像和那样有” ”，因此不容易发生梯度弥散的问题
  关闭了左边，可以使很多隐层输出为，因此使网络变得稀疏，有一定的正则化作用，可以缓解过拟合
函数的缺点也体现在被关闭的左边部分，如果某些节点的输出落在函数左边，那么其将“永无翻身之日”。为了解决该问题后来又出现了等改进的激活函数，即给函数左边也赋予一定的梯度，在保证非线性的同时不至于让某些节点“死掉”。



局部响应归一化  


神经生物学上有一个概念叫做“侧抑制 ”，指被激活的神经元对相邻神经元有一定的抑制作用。

就是借鉴侧抑制的思想来对局部神经元的活动创建竞争机制，使响应比较大的值相对更大，从而提高模型的泛化能力。有两种归一化模式：通道内和通道间，具体可以参考该篇文章。在论文的的实验中，可以降低的错误率，但从我们在其他数据集上的实验来看，提升训练效果并不是那么显著，因此可以看到的操作并不是适用于所有场景的，还是要多实验才能出结果。

交叠的

顾名思义，就是指在做的时候也会存在的部分。一般来说是将输入的结果进行分块处理，通过提取该块的最大值 或平均值 来实现下采样的过程，这里的块间是相互不交叠的。在中却会有的部分。和一样，这个不一定适用于所有场景。
综合以上几个技巧，整体来看，还是非常经典的一个算法。所以我们将集成到的深度学习算法的视觉类目下。在实现上，我们根据原本的构建和训练方式、参考发表的《       》这篇文章，做了如下几个事情，包括：

移除了层，并将参数的初始化改成方式。
激活函数使用函数
正则化选择正则化
在和两个全连接层使用系数为的操作
自动：在数据的输入上，给定的输入图像是的大小，如果读取到的图像大于该尺寸，则会将其随机到，如果读取到的图像小于该尺寸，则会将其到。

另外，我们对输入图像也提供了一些 的操作，包括水平翻转、颜色、光照变化等，文章后部分会有相关参数的描述。
 
继承了的框架，但其通过加深卷积层数的方法获得了比更高的图像识别率，是一种比更深的网络结构，如下图所示，更详细的网络结构参数可以参考该论文。

 
与相比，明显的不同之处在于：

连续的块和较小的 

通过网络结构图可以看到，中含有多个连续的操作图中黑色框部分，而这些卷积层的卷积核大小都为，相比的小很多。可以理解成通过降低的大小，同时增加卷积层数来达到同样的效果。

           ×             ×  

较小的卷积核在一定程度上减少了需要训练的权重个数假设输入和输出的数都为，在大小的卷积核下，该层的权重个数为=，而此时中连续的个卷积层的权重个数为=。权重个数的减少有利于网络的训练和泛化。

通道数增多

对比和可以发现的数明显小于。如此一来，网络可以对输入提取更丰富的特征。之所以能够达到更高的准确率，与通道数的增多有较大关系。
也被集成到的深度学习算法的视觉模块下。除了网络结构的定义不同外，其他都与相似，包括全连接层的设置，激活函数和的正则化。
 
和上面小节所述的其实出自同一篇论文，是一种方法的两种不同配置。的网络结构与非常相似，差别在于在第、、个“卷积块”里分别加多了一个卷积层，因此比多了个 。这里就不再赘述。
除了上述的和系列的网络结构外，还会逐步集成，等，欢迎大家持续关注。
自定义网络
经典算法虽好，但是总会有一定的局限性的。为了提供更好的灵活度，上还集成了基于卷积神经网络的分类和回归算法，其最大优点是可以对网络结构进行灵活的自定义，从而满足不同场景下的需求。
在中定义一个卷积激活层通常需要如下几行代码：
 _  
   = _    == =
   =  = == =
   =       =
   = _ 
这还只是一个卷积层的构造，如果我们要构建的网络由十几或者几十层组成，则估计要敲好几百行代码了，而且重点是你就算复制黏贴相同性质的层也不一定找得准眼花缭乱的参数啊。
好在也支持一些接口的高级抽象如、和等，这样一个卷积层就可以一句话写完，比如在可以如此定义一个卷积层操作：
 =      = =
尽管这些高级接口使网络的定义简便了不少，但如果在训练过程中要多次调整网络结构，这样的形式则仍然很不方便。
鉴于以上，我们在上实现时，将网络结构单独抽出来作为一个可修改的参数传入到算法中。该网络参数其实是一个文件，文件中的每一行表示一个层，最后几行表示数据输入的一些信息。
一个的网络结构如下图所示：


将该转成我们自定义的文件后示例如下：
{
    {     _  _  _ _    _ } 
    {  _ _ __ _  } 
    {     _ _ _ _   _ } 
    {  _ _ _ _ _  } 
    {     _  _ } 
    {     _  _ } 
    {    }
  __  __ 
  __  __ 
      __  
}
还有更懒的亲们甚至可以直接复制这份模板，然后按自己的网络定义更改一下里面的参数就可以了。在界面运行时，如果需要修改网络结构，可以直接在界面右边的参数配置编辑该文件，不需要再修改并上传代码啦
基于上述的自定义网络结构的特点，我们配置了的分类和回归两种算法。
  
基于卷积神经网络的分类算法。支持如上所述的网络结构自定义，可以适应不同场景下的图像分类任务。
  
基于卷积神经网络的回归算法，与 类似，区别在于训练时用的是欧氏距离损失函数，可以接受类型的标签。注意在配置网络结构时最后一层的 个数为，而不是分类中的类别数。
视觉算法的使用
目前，主要通过平台透出，其训练和使用都非常简单，总体来说可以分为三个步骤：数据准备、模型训练和模型使用
 数据准备
在开始训练前，我们需要准备好训练集和测试集数据。对于目前计算机视觉目录下的算法，输入都为图像数据，并且都需要转换成的格式。

打开的工作界面，在输入数据源下拖出数据集节点，点击该节点，完整填写界面右边的参数配置选项，便完成了一个数据节点的配置。转换节点可以加在数据节点之后。为了方便用户使用，我们会提供一个的转换工具，放在输入数据转换目录下。
 模型训练
在工作流界面从左边的深度学习算法下拖出想要训练的算法节点。点击该节点，右侧会出现参数配置选项，包含算法参数，算法参数和资源配置参数。

资源参数

指定模型训练时所需的和资源。




算法参数

用于指定数据集、模型存储和保存的路径，这里我们只需要指定数据集所在路径，而模型存储和路径由默认指定。
如果算法节点上有对应的数据集节点，则该数据集节点的数据路径会自动匹配到算法的数据输入路径，不想拖数据集节点的用户也可以手动填写算法的数据输入路径。






参数名称
参数说明
默认值




继续训练模型
指定模型所在的文件夹路径包含文件，则训练会从该模型开始；如从头开始训练则填



数据输入
训练集数据，须为格式
无


测试数据
测试集数据，须为格式
无




算法参数

用于指定训练过程中所需的参数。深度学习各算法的参数有一部分是相通的，如批处理大小、学习率和迭代次数等。但不同的算法也可能有自己特殊的参数。在下面的介绍中，我们将会在各算法的详细介绍链接里找到对应的参数解释。






参数名称
参数说明
默认值




批量处理大小
图片批量训练大小，也就是 



迭代次数
训练过程中总的迭代次数



测试间隔
每隔轮迭代做一次测试



初始学习率
初始学习率



学习率衰减步数
每隔轮迭代衰减一次学习率



学习率衰减因子
学习率衰减因子



正则化因子
正则化因子，采用正则化



模型保存间隔
每隔轮迭代保存一次模型



类别数
分类任务中的类别数



原始图像高度
指从中读取到的图像的高度，可能与输入到网络中的图像大小不同、等操作



原始图像宽度
指从中读取到的图像的宽度，可能与输入到网络中的图像大小不同、等操作



原始图像通道数
指从中读取到的图像的通道数，若是彩色图像则为，黑白图像为



水平翻转
是否对数据随机进行水平翻转
否


亮度变化
是否对数据随机变化亮度
否


对比度变化
是否对数据随机变化对比度
否


标准化
是否对数据做标准化处理
否



对于 算法来说，由于支持网络结构的自定义，因此参数与上表会稍有不同。以工作流右侧的参数配置项目为准。
配置完各参数后，右键点击该算法节点，选择起点运行即可开始训练模型。在训练过程中可通过控制台查看信息和可视化，便于把握训练走向。

 模型收藏和使用
模型使用指用训练好的模型做预测工作。除了在刚训练完成时对模型做预测外，还贴心地提供了模型收藏功能，可以留待以后再做预测。
模型收藏：在模型操作下选择收藏模型可以将模型收藏到界面左边的个人模型目录下，下一次需要使用的时候可以直接拖出模型节点，填写相应的配置参数，右键选择起点运行即可。

结语
本篇文章介绍了计算机视觉领域比较经典的几种深度学习算法，同时展示了如何在平台上快速灵活地训练和使用深度学习模型。在算法下有各个算法的样例工程供大家参考。
最后，再一次提一下苹果的。的成功启用无疑是计算机视觉领域在人类生活应用中的一大进步，其低于指纹解锁的破解率与背后的机器学习尤其是深度学习算法密不可分。当然，背后的人脸识别技术肯定比本文中简单介绍的几种算法复杂的多，这里我们就不深入探讨了，因为就算你问我我也不知道呀，呵呵 不过，苹果在去年的上发表了一篇的文章《        》，有兴趣的可以看一下。另外，苹果在去年的上宣布会开始公开他们的研究成果，相信这一决定会给学术界和工业界带来很多惊喜，大家可以期待一下。
最后，本文由和指导完成，这里表示感谢。如果在使用算法时遇到相关问题，欢迎咨询我或者，也墙裂欢迎各种批评指正意见！
参考文献
                     
                
                           
              
                     指标
工具





= = =




 ==  ==  可用空间=
  



  
 



：缓冲区不挤压 无丢包 ：重传率
    



一、
良好状态指标

利用率：  = ，  = ，     = 

上下文切换：与利用率相关联，如果利用率状态良好，大量的上下文切换也是可以接受的

可运行队列：每个处理器的可运行队列=个线程


监控工具

  最常用 略

 


    表示  输出一次
     
                                      
                                 
                                   
                                   
                                  
                                   
重要参数：

 ， ，可运行队列的线程数，这些线程都是可运行状态，只不过暂时不可用；
，被的进程数，正在等待请求；
，，被处理过的中断数
， ，系统上正在做上下文切换的数目
，用户占用的百分比
，内核和中断占用的百分比
 ，完全空闲的百分比

上例可得：
高低，以及高频度的上下文切换，说明应用程序进行了大量的系统调用；
这台核机器的应该在个以内，现在在个线程以上，此时负荷很重。

查看某个进程占用的资源        |  __   
      
           __
           __
           __
           __
           __
           __
……


二、
良好状态指标

   == ，   == 
应用程序可用内存系统物理内存 =  

监控工具

 

  

     
                                       
                                       
                                 
                               
                              
                                 
重要参数：

，已使用的  空间大小， 为单位
，可用的物理内存大小， 为单位
，物理内存用来缓存读写操作的大小， 为单位
，物理内存用来缓存进程地址空间的  大小， 为单位
，数据从  读取到  的大小， 为单位
，数据从  写到  的大小， 为单位

上例可得：
物理可用内存  基本没什么显著变化，逐步增加，说明最小可用的内存始终保持在 物理内存大小  ％ =  左右，当脏页达到％的时候就开始大量使用。
  
     
                                      
                               
                                
                            
                            
                           




 
                                         
                                     
        
               
单位。可以用  选项要求输出单位为。
我们使用、、、、 等名称来代表上面统计数据的各值，、 分别代表第一行和第二行的数据。

：表示物理内存总量。 
：表示总计分配给缓存包含 与 使用的数量，但其中可能部分缓存并未实际使用。 
：未被分配的内存。 
：共享内存，一般系统不会用到，这里也不讨论。 
：系统分配但未被使用的 数量。 
：系统分配但未被使用的 数量。 与 的区别见后面。 
：实际使用的 与 总量，也是实际使用的内存总量。 
：未被使用的 与 和未被分配的内存之和，这就是系统当前实际可用内存。 

 和 的区别：
：高速缓存，是位于与主内存间的一种容量较小但速度很高的存储器。
由于的速度远高于主内存，直接从内存中存取数据要等待一定时间周期，中保存着刚用过或循环使用的一部分数据，当再次使用该部分数据时可从中直接调用这样就减少了的等待时间提高了系统的效率。
又分为一级 和二级 ， 集成在内部， 早期一般是焊在主板上现在也都集成在内部，常见的容量有或  。
：缓冲区，一个用于存储速度不同步的设备或优先级不同的设备之间传输数据的区域。通过缓冲区，可以使进程之间的相互等待变少，从而使从速度慢的设备读入数据时，速度快的设备的操作进程不发生间断。
中的和：它们都是占用内存
  作为 的内存，是块设备的读写缓冲区
 作为 的内存，文件系统的
如果  的值很大，说明住的文件数很多。如果频繁访问到的文件都能被住，那么磁盘的读 必会非常小。

           
           
                
          
……


这台服务器总共有  物理内存， 左右可用内存，左右用来做磁盘缓存，左右用来做文件缓存区。用命令也可以查到这几个值，注意单位是。
三、磁盘
良好状态指标

   提高命中率的一个简单方式就是增大文件缓存区面积，缓存区越大预存的页面就越多，命中率也越高。 内核希望能尽可能产生次缺页中断从文件缓存区读，并且能尽可能避免主缺页中断从硬盘读，这样随着次缺页中断的增多，文件缓存区也逐步增大，直到系统只有少量可用物理内存的时候  才开始释放一些不用的页。

监控工具



     秒一次 共次
  __                ___         

                   _  _                   
                                                       

                   _  _                   
                                                       

                   _  _                   
                                                       

                   _  _                   
                                                       
重要参数：

表示平均每次设备操作的等待时间以毫秒为单位。
表示平均每次设备操作的服务时间以毫秒为单位。
表示一秒中有百分之几的时间用于操作。

如果的值与很接近，表示几乎没有等待，磁盘性能很好，如果的值远高于的值，则表示队列等待太长，系统上运行的应用程序将变慢。
如果接近，表示磁盘产生的请求太多，系统已经满负荷的在工作，该磁盘可能存在瓶颈。

  选项  用于显示和相关的扩展数据

  __                ___         

            
                              

                                     
                                                        
查看哪个进程占：，效果和看一样。查看某个进程打开的文件：{}
四、 
对于
良好状态指标
接收、发送缓冲区不长时间有等待处理的网络包
监控工具

    

对于服务，查看所有监听的端口的网络情况
                                 
                                                     
                                                     
                                                     
                                                     
                                                     
                                                     
                                                     
                                                     
、为，或者不长时间有数值是比较正常的。
对于服务，查看丢包情况网卡收到了，但是应用层没有处理过来造成的丢包

   

      
         
       
      
   这一项数值增长了，则表明在丢包。
对于来自单卫的经验，
良好状态指标
对于而言，不会出现因为缓存不足而存在丢包的事，因为网络等其他原因，导致丢了包，协议层也会通过重传机制来保证丢的包到达对方。
所以，而言更多的专注重传率。
、监控工具
通过可以查看各层网络协议的收发包的情况
   |  
              
              
重传率 =   
至于这个值在多少范围内，算的，得看具体的业务了。
业务侧更关注的是响应时间。

相关推荐常用操作及命令今天，大数据已无所不在，并且正被越来越广泛的被应用到历史、政治、科学、经济、商业甚至渗透到我们生活的方方面面中，获取的渠道也越来越便利。通过本系列的前面几篇文章，我们已经了解了数据可视化的必要性，而目前市面上也已经具备了非常多成熟的绘制工具，如和魔镜等等。虽然这些工具正在变得越来越自动化，然而，随着大数据时代的来临，信息每天都在以爆炸式的速度增长，其复杂性也越来越高；其次，随着越来越多科学可视化的需求产生，地图、物理结构等技术将会被更加广泛的使用。所以，当人类的认知能力越发受到传统可视化形式的限制时，隐藏在大数据背后的价值就难以发挥出来，如果因为展示形式的限制导致数据的可读性和及时性降低，从而影响用户的理解和决策的快速实施，那么，数据可视化将失去其价值。
然而，所幸的是，技术的快速发展和不断变化的认知框架正在为人类打开新的视野，促使艺术与技术相结合而产生新型的数据可视化形式。
数据可视化的演变历史
一为什么数据可视化形式亟待改进
我们每天都在说大数据，那数据到底能“大”到怎样的程度？也许你已经听说过以下结论：世界上％的数据是在过去几年内产生的。事实上，过去三十年中，全世界的数据量大约每两年增加倍，有专家估计，到年的时候，数据的年度产出量会达到甚至更多，这已远远超出了著名的摩尔定律理论；所以，面临着这样的巨大挑战，大数据的时代的数据可视化给我们提出了以下要求：
以更细化的形式表达数据
首先，让我们来看一个相对简单的静态可视化图表：
图不安全流产率百分比估计  
再来是一个更复杂的可视化图表：
图到年间个国家的移动电话、固话和互联网的订购数量与容量  
图是一个数据量较少的静态可视化图表，我们可以通过根柱状图的对比快速得到信息，而显而易见的，图的数据量大大超出了图，不仅有一百多个国家的数据变化，还包含不同的年份对比。更庞杂的数据量要求设计者通过更加细化的方式来呈现数据，所以我们可以看到图以折线图为基础，结合了气泡的动态变化、语音说明，还包括让读者通过交互操作来选择展示哪些数据，才得以恰当和全面地展示这份数据，从而更完整的讲述一个故事。
以更全面的维度理解数据
“随着大数据技术成为我们生活的一部分，我们应该开始从一个比以前更大更去全面的角度来理解事物。”
这句话来自《大数据时代》，作者的原意是在大数据时代我们应该舍弃对数据精确性的要求，而去接受更全面但是也更混杂的数据，笔者认为它同样可以用来形容未来在数据可视化方面可以进步的方向。
众所周知，人类的视觉认知能力是有限的，类似下图这样的高密度可视化图形，虽然看似丰富和具有“艺术感”，可中间重叠连接的数据往往导致图形变得复杂和难以理解。
每个节点代表一个页面，每一根线代表页面之间的连接维基百科链接结构可视化
但是如果像下面这两个宇宙科普项目这样：你可以通过放大或缩小星系、调整视角、甚至像飞进了这些星球之间一样去观察它们，点击它们查看详细介绍等等……这样一个更”立体”的数据展示是否能更好的帮助你去理解这些信息呢？
通过交互式可视化展示探索宇宙中超过十万颗星球 
通过手势识别设备来探索开普勒计划目前已确认的近个候选系外行星视频地址
如今人们逐渐已不再满足于平面和静态的数据可视化视觉体验而是越发想要“更深入”去理解一份数据，传统的数据可视化图表已不再是唯一的表现形式现代媒介和技术的多样性使人们感知数据的方式也更加多元。
以更美的方式呈现数据
艺术和数据可视化之间一直有着很深的联系，随着数据的指数级增长和技术的日趋成熟，一方面，用户们对可视化的美学标准提出越来越高的要求；另一方面，艺术家和设计师们也可以采用越来越创造性的方式来表现数据，使可视化更加具有冲击力。 纵观历史，随着人们接受并习惯了一种新的发明后，接下来就是对其进行一步步的优化和美化，以配合时代的要求， 数据可视化也是如此，因为它正在变得司空见惯，良好的阅读体验和视觉表现将成为其与竞品所区分的特征之一。
 项目将 “里约”地球峰会期间的话题汇集成星球上的一颗颗大树视频地址
二大数据时代的数据可视化具有哪些特征
在这里，笔者大概将其整理归纳为以下三点，当然它们并非都是必备特征：

三典型应用场景
那么，这些运用新技术的数据可视化目前主要是在哪些场景和形式下使用呢？
大屏
首先，不得不提到的一定的是大屏了。什么是大屏？顾名思义，就是指通过整个超大尺寸的屏幕来展示关键数据内容。随着许多企业的数据积累和数据可视化的普及，大屏数据可视化需求正在逐步扩大，例如一些监控中心、指挥调度中心这样需要依据实时数据快速做出决策的场所，以及如企业展厅、展览中心之类以数据展示为主的展示场所，还有如电商平台在大促活动时对外公布实时销售数据来作为广告公关手段等等，而具体的展示形式又可能分为带触摸等交互式操作或只是作单向的信息展示等等。
双十一购物狂欢节采用实时数据大屏，带给观众更加准确、震撼和清晰的体验
触摸屏
作为实现交互式数据可视化的方式之一，触屏设备常常用作控制大屏展示内容的操作设备其中也包括手机和平板，也可以兼顾显示和操作一体来单独展示数据，大大增加了用户与数据之间的互动程度。
将触摸屏与可视化相结合的微软黑科技视频地址
网页
目前应用于数据可视化方面的网页技术可以说是琳琅满目，如、、、来自百度数据可视化团队等等，这些工具都能很好的实现各类图表样式，而作为的一个第三方库则相对更侧重于方向的展示。
年内世界小型武器和弹药的进出口贸易数据展示
视频
有数据显示，人们的平均注意力集中时间已从年的秒下降到年的秒，这并不奇怪，当我们在面对越来越多的信息来源时，会自然倾向于选择更快捷的方法来获取信息，而人类作为视觉动物天生就容易被移动的物体吸引，所以视频也是数据可视化的有效展示手段之一，并且视频受到展示平台的限制更少，可以应用的场景也更广。不过因为其不可交互的特性，视频展示更适合将数据与更真实、更艺术的视觉效果相结合，预先编排成一个个引人入胜的故事向用户娓娓道来。
地球交通路线发展史视频地址
四数据可视化的未来
可惜，仅有以上这些展示方式是不够的，人眼仅仅透过平面的屏幕来接收信息仍然存在着限制，、、、全息投影…这些当下最火热的技术已经被应用到游戏、房地产、教育等各行各业，可以预见的是数据可视化也能与这些技术擦出有趣的火花，比如带来更真实的感官体验和更接近现实的交互方式，使用户可以完全“沉浸”到数据之中。可以想象一下，当我们可以以ᵒ全方位的角度去观看、控制、触摸这些数据时，这种冲击力自然比面对一个个仅仅配着冷冰冰的数字的柱状图要强得多。而在不远的未来，触觉、嗅觉甚至味觉，都可能成为我们接受数据和信息的感知方式。
将新闻事件中抽象的死亡人数数据变成一具具尸体摆放在空间中，给用户更直观的冲击视频地址
结语
感谢技术的飞速发展带给了我们更多元的选择，使我们可以运用前所未有的创造性方式来展示数据， 但这并不意味着传统的数据可视化形式会逐渐消亡，毕竟这些新的展示技术和形式目前仍然面临着较高的制作成本，而传统的展示形式仍然是解决需要快速输出的可视化需求时的理想选择。数据可视化是一门同时结合了科学、设计和艺术的复杂学科，其核心意义始终在于清晰的叙述和艺术化的呈现，这些需要依靠数据分析师和设计师的精心策划而不是仅有炫酷的效果 ，最终达到帮助用户理解数据和做出决策的目标，才能发挥它巨大的价值和无限的潜力。
参考资料：

《大数据时代》   ö
       
           
             一、 的简单使用
、创建文件实例
编辑配置文件  
   
           固定后缀为，一定要注意空格
    
      
       
      
          _
            
注意：

参数指定了对哪些主机进行参作；

参数指定了使用什么用户登录远程主机操作；

指定了一个任务，其下面的参数同样是对任务的描述，在执行过程中会打印出来。


执行创建文件文件
    
      

      
     
     
     

     _ 
     
     
     

      
                    =    =    =    =   
                    =    =    =    =   
                    =    =    =    =
 现在来查看是否批量创建成功文件。
         
     |  | = 
         月    

     |  | = 
         月    

     |  | = 
         月    
给创建的批量导入内容，并查看导入的结果
    
    
      
       
      
          铁匠运维网博客
              
    
      

      
     
     
     

     铁匠运维网博客 
     
     
     

      
                    =    =    =    =   
                    =    =    =    =   
                    =    =    =    =   

        
     |  | = 
    

     |  | = 
    

     |  | = 
    
、创建用户实例
编辑配置文件
   _
    
      _
       
       
      _ 
      
          
      
           
           ={{  }}

参数对该实现的功能做一个概述，后面执行过程中，会打印 变量的值 ，可以省略；

_参数指定了在以下任务部分执行前，是否先执行模块获取主机相关信息，这在后面的会使用到获取的信息时用到；

参数指定了变量，这里指字一个变量，其值为 ，需要注意的是，变量值一定要用引号引住；

提定了调用模块，是模块里的一个参数，而增加的用户名字调用了上面变量的值。


执行配置文件
   _ 

 _ 

   
 
 
 

  
                =    =    =    =   
                =    =    =    =   
                =    =    =    =
查看远程机器的文件，是否创建出来了用户
         
     |  | = 
    

     |  | = 
    

     |  | = 
    
二、循环
实例：修改目录下的 文件属性
去新建实验文件
    

  
   
  
      创建实验文件
        {}

    

      

      
     
     
     

     创建实验文件 
     
           =    

     
     

      
                    =    =    =    =   
                    =    =    =    =   
                    =    =    =    =
编辑配置文件
    
    
      
       
      
             
           ={{  }} = = =
          _
             
             
执行配置文件
    
      

      
     
     
     

         
      = =
      = =
      = =
      = =
      = =
      = =

      
                    =    =    =    =   
                    =    =    =    =   
                    =    =    =    =
三、条件判断
条件判断一般用于针对不同版本的系统，比如对、 等系统进行不同的操作命令。
编辑配置文件
   
    
      
       
      _ 
      
           
            
           __ == 
执行配置文件
   
      

      
     
     
     

       
     
     
     
           =    


      
                    =    =    =    =   
                    =    =    =    =   
                    =    =    =    =
四、 
当我们执行  后，服务器发生变化之后我们要执行一些操作。比如我们修改了某个服务的配置文件，需要重启下服务。实例如下：
编辑配置文件
   
    
       
       
       
      
           
           = =
            
      
           
              
说明：只有  模块真正执行后，才会去调用下面的  相关的操作，追加内容。也就是说如果  和  内容是一样的，并不会去执行  里面的  相关命令。所以这种比较适合配置文件发生更改后，需要重启服务的操作。
执行配置文件
   
       

      
     
     
     

       
     
     
     

        
     
     
     

      
                    =    =    =    =   
                    =    =    =    =   
                    =    =    =    =
查看执行结果
                这里我直接用 显示的最后一行内容
 |  | = 


 |  | = 


 |  | = 

可查看到  文件成功，同时也执行了  的相关命令，追加了新的信息。

相关推荐
服务器环境部署服务器全功能环境部署作者：，腾讯适配测试负责人、专家兼容测试负责人商业转载请联系腾讯获得授权，非商业转载请注明出处。原文链接：

 导读
谷歌 开发者大会上发布了 的正式版， 其官方代号为奥利奥。网上关于新功能特性的介绍已铺天盖地，新功能特性会对程序应用带来哪些影响呢，我们从兼容性角度来看下这部分变化。


测试版本： 

一、安装启动测试
 中权限设置新增安装限制功能，即每个的「安装未知应用」功能将默认被限制，避免关联应用自动安装的问题，特别是针对一些流氓应用比较有效。
、测试目的
检查游戏、在系统环境下能否正常安装、启动、卸载
、测试用例
、测试结果
、测试结论
测试的个应用在允许安装权限情况下均可正常安装、启动、卸载，在系统环境下兼容性在这部分功能未出现问题。
在第三方应用市场下载程序低版本会出现安装失败、安装包错误等问题，更新版本可以解决。
二、 画中画模式
 中，谷歌更加强调多任务处理场景中的流畅性，引入了  画中画模式。这功能允许用户自定义窗口大小，可以让用户把视频窗口固定在屏幕角落，同时运行其他 达到多屏显示效果。
、测试目的
引入的画中画模式与是否兼容
、测试条件
设置应用和通知高级特殊应用权限中允许进入画中画模式，在指定应用中全屏播放视频时点击键进入画中画模式
、测试用例
、测试结果
、测试结论
测试的个不同类型的游戏、中，发现开启画中画模式播放视频，同时进入天天德州游戏，视频自动暂停播放，手动点击播放视频几秒后仍然会自动暂停播放；使用表现卡顿，且随机出现提示“没有响应”。另外，画中画模式播放视频，同时运行其他视频播放结束均会关闭，暂时无法确定是系统设定如此还是由于原因造成。
目前只有浏览器、 服务、支持画中画模式，其中全屏播放视频时点击键直接跳转到主屏界面，无法进入画中画模式，浏览器全屏播放视频也很多无法进入画中画模式，该功能兼容性还有待开发。

三、通知圆点功能
类似  的通知角标，但不会显示具体通知数量，只会在图标右上角显示一个圆点。 当出现通知圆点时，长按应用程序图标，就会以类似气泡的形式快速预览。而在通知中心中删除这些未读通知，应用图标上的标记点也会消失。
、测试目的
通知圆点能否正常显示
、测试条件
设置应用和通知通知允许使用通知圆点
、测试结果
例如，如图目前版本在有消息提示时仍未正确显示圆点提示
、测试结论
测试的款、游戏中出现未读通知时，图标上都没有通知圆点提示，也无法通过长按来直接读取提示信息。
四、后台进程限制
安卓系统越用越卡、电池寿命的问题一直是用户使用的痛点，谷歌表示一直在优化安卓的后台应用限制策略，以最大程度减小后台应用对电池的消耗和对资源的占用。  对隐式广播、后台服务和位置更新等进行了后台自动限制，以此来减少后台数据使用、增加手机电池寿命。
这里选取了几个常用软件，用工具抓取了后台运行时相关性能数据进行了对比，结果如下：
测试结论
从上面数据看来，系统比系统的后台运行程序限制并不明显，仅仅在数值上有微小的提升，普通用户在正常使用时没有明显感受。
五、其它内容未进行实践测试
其他新功能特性如 功能长按应用图标可弹出子菜单、智能文本选择、设置界面精简、通知支持自定义提醒的时间间隔、动态亮屏、标准的表情等功能与兼容相关性较小，暂未进行测试覆盖。
六、暂时结论
系统环境下，安装启动测试项兼容性较好；画中画模式中会出现视频自动暂停播放、其他同时运行的应用卡顿甚至提示无响应的兼容性问题；通知圆点功能暂时与目前线上应用不兼容；后台进程限制的体验效果，相比系统，运行速度没有明显的改进。
总体来看，选取的几个系统新功能特性测试出现的较多，一方面是自身版本存在问题，另一方面可能与目前线上应用未对新系统特性提供接口支持有关。目前除了、等几个系列设备可以更新外，还未大范围推广，所以影响面较小，开发和测试等人员需要提早注意更新以便自己相关产品在新系统版本上顺利运行。

 现在登录腾讯即可使用 系统真机。提供上千台真实手机，随时随地进行测试，保障应用手游品质。节省百万硬件费用，加速敏捷研发流程。
 同时腾讯兼容性测试团队积累了年的手游测试经验，旨在通过制定针对性的测试方案，精准选取目标机型，执行专业、完整的测试用例，来提前发现游戏版本的兼容性问题，针对性地做出修正和优化，来保障手游产品的质量。目前该团队已经支持所有腾讯在研和运营的手游项目。
欢迎进入： 体验安卓系统真机
欢迎进入： 使用专家兼容测试服务。兼容性测试团队期待与您交流！ ， ！导语：一名校招新人入职一个月的一些总结与感悟

模式
提到肯定避不开模式，即模型－视图－控制器，通过将业务逻辑、数据、界面显示分离的方法组织代码，将业务逻辑聚集到一个模块里面，在通过个性化界面与用户交互的同时，不需要重新编写业务逻辑。具体到里面，我个人的观点是请求通过对应的映射到指定的内，与定义的数据模型映射到数据库进行交互并完成业务逻辑的处理，最后将处理结果在里以的形式进行返回。
举个简单的例子：
在终端里面发出如下请求：

    { }
 在指定的目录下的文件夹里面，里对应有这样一行配置进行路由：

 __ =__
 需要提醒的是，如果该行代码不在最后，结尾的逗号一定别忘了
这样这个就会被映射里面的__这个接口：

_
 __
    
     
    
     
数据交互
上文没有涉及到与数据库的交互，这里单独做整理，这也是最近项目中涉及最多的一块内容。
比如现在要在数据库中新建一张表

  ``
    ``    _
    ``     
    ``      
    ``     
    ``     
       ``
     =   =
 还有一张运行时的表

  ``
    ``    _
    _     
    ``     
    `_`     
    ``     
       ``
     =   =
 对应到里面定义的数据模型，可以看到如下定义

 
         = _= _=任务名
      = __=，_=创建时间
      = _=超时时间
          = _= _= _= 
     
        _ = 
 
             = 
           = _=任务状态
    _ = _=构建结果
              = _= _= _= 
     
        _=
 有三点需要注意

里没有设置 的话，默认为每张表新建一个名叫的列，为主键列。如果你的表里面有一列叫，且不设置它为主键的话，是会产生冲突的。
里默认会为每张表的外键列设置一个格式为 表名全小写_ 的列，例如表中的_那一列。
默认会为每张表命名为数据库_表名，可以像上面代码里的那样通过设置_的形式来自定义表名。

在中需要在中配置的数据库，比如
 = {
     {
         
         _
         
         
         
         
    }
}
 如果在项目中需要用到多个数据库，可以这样进行操作，在上述代码下面进行添加

 = {
     {
         
         _
         
         
         
         
    }
     {
         
         __
         
         
         
         
    }
}
 注意跟对应的标签
然后需要在中进行数据库路由的配置，比如

_ = 
 这样在目录下的文件中需要定义配置上文提到的标签

 
           
     __  
         __ == 
                    
         

     __  
         __ == 
             
         
最后在对应的表里面通过设置  _ = 就访问非默认的数据库 

 
         = _= _=任务名
      = __=，_=创建时间
      = _=超时时间
          = _= _= _= 
     
        _=
        _ = 
 这样就可以实现对多个不同的数据库中的多张表进行同时访问了。
里面与数据库交互一些，比如

_ = = _
 对应的语句为

      =     
 具体的就不多赘述了，可以参考下手册。
总结与感悟
人生苦短，我用
提到肯定离不开这句话，做为一名校招新人，第一次接触框架，在这段时间的封闭开发中也体验到了所带来的便捷之处，上手起来确实很快，在短短的一个月时间内对于的印象也是很轻巧，整体的架构包括对的支持让用户使用起来也觉得比较方便。
一时爽，重构火葬场
这是同事说的一句话。因为整个封闭过程中需要对另外一个项目组的一个工程进行一部分重构，这期间涉及到的版本控制，文件依赖等各种问题确实也浪费了一部分时间去处理，包括最后的测试方面也暴露除了动态脚本语言的一些局限性，既然选择了就得接受，这是我的看法。
如有错误欢迎各位大大不吝指正，感谢！我在京东的整个职业生涯中教会了我很多的技能，最近有时间也乐意把学到的和大家分享。
分享的主题：专项测试冲突测试
什么是冲突测试冲突测试是一种叫法，可能不同的公司叫法不同。我们所谓的冲突测试是指，在运行某一程序的功能时被第三方功能或者软件给干扰的测试。该测试方法模拟的是一种基于软件状态场景的测试。从软件的运行状态来看，我们认为软件状态一般只有开始、挂起、结束，这三种状态。
冲突测试即为模拟干扰软件运行“开始”、“挂起”、“结束”状态的测试。
冲突测试的应用范围和一些应用场景冲突测试这种测试方法，常见于手机软件测试、移动通信类嵌入式软件测试等领域。但在一些桌面软件或者系统测试领域当中也可应用，只是应用的场景并不如移动通信类软件这么广泛。
冲突测试应该在整个测试中的地位？地位应该与边界值测试中的地位相同。在设计测试用例时，也应较多的考虑这类测试。根据以往采用这种测试方法进行测试的经验来看，此类测试往往会引起一些较严重的问题。
冲突测试目的：验证在模块操作过程中触发一些常见打断，客户端对于事件优先级的处理是否影响了功能，这一点很重要，往往我们在质量把控方面会忽视这一点。
测试方法：在被测操作过程中触发预先准备好的事件。确认被触发的事件是否可以正常出现，以及事件发生后之前的状态是否继续在执行，最后确认事件结束后状态的现状是否正常。
通过标准：系统事件可以正常触发，中的各状态表现正常。种情况的预期现象以各是否符合常规、合理为标准。例：如在搜索加载进度条过程中电话呼入，此时搜索过程被弹出电话呼入提示压盖，搜索转入后台操作，响铃可以正常提示等，无论是接听或挂机后，搜索要么还在加载进度，或者已经转入到结果界面，最终个进程互不中断。
冲突测试主要关注的点：
注：此类测试在手机等移动通信软件中的一个难点就是，找准测试时间点。因为在执行某个功能时，发生的速度非常快，而要打断这个状态就得算好时间。因此并不是每次事件触发后刚好赶上了短暂的某状态，在次事件触发情况下仍不出现问题认为可以接受。

相关推荐
【测试】怎么测试启动时间？
快速定位手游内存占用过高问题
移动开发一站式解决方案这是《使用腾讯云学习深度学习》系列文章的第三篇，主要是接着上一讲提到的如何自己构建深度神经网络框架中的功能模块，进一步详细介绍  中  工具包提供的几种深度神经网络模块。本系列文章主要介绍如何使用 腾讯云服务器 进行深度学习运算，前面主要介绍原理部分，后期则以实践为主。
往期内容：
使用腾讯云  学习深度学习系列之一：传统机器学习的回顾
使用腾讯云  学习深度学习系列之二： 简明原理
上一讲中，我们用最简单的代码，实现了最简单的深度学习框架，然后进一步的实现了     以及  这几个模块，并且用这几个模块搭建了一个最简单的两层深度学习网络。
当然，我们没有必要自己亲自关注这些底层的部分，接下来的内容，我们将基于现在最火的深度学习框架 ，这里以  版本为例，详细介绍一下更多的模块的原理，谈一谈怎么使用这些零件搭建深度学习网络。在 版本的  中，已经集成了以前的  模块，使得搭建基本的 模块更加简单、方便。
 我们可以简单的将深度神经网络的模块，分成以下的三个部分，即深度神经网络上游的基于生成器的 输入模块，深度神经网络本身，以及深度神经网络下游基于批量梯度下降算法的 凸优化模块：

批量输入模块

各种深度学习零件搭建的深度神经网络

凸优化模块


其中，搭建深度神经网络的零件又可以分成以下类别： 

各种深度学习零件搭建的深度神经网络
常用层






卷积层





池化层





正则化层



反卷积层中在卷积层部分






需要强调一下，这些层与之前一样，都 同时包括了正向传播、反向传播两条通路。我们这里只介绍比较好理解的正向传播过程，基于其导数的反向过程同样也是存在的，其代码已经包括在  的框架中对应的模块里，可以直接使用。
当然还有更多的零件，具体可以去 文档中参阅。
接下来的部分，我们将首先介绍这些深度神经网络的零件，然后再分别介绍上游的批量输入模块，以及下游的凸优化模块。
 深度神经网络的基本零件
 常用层：
 
 层，就是我们上一篇文章里提到的  层，即 = ，计算乘法以及加法。
 
 层在我们上一篇文章中，同样出现过，即 层以及层，他们都是  层的一种。当然  不止有这两种形式，比如有：

图片来源 激活函数与及参数
这其中  层可能是深度学习时代最重要的一种激发函数，在年首次被提出。由公式可见， 相比早期的  与 函数，  有两个重要的特点，其一是在较小处都是或者，但是较大值函数没有取值上限。其次是层在除不可导，是一个非线性的函数：

即 =
对其求导，其结果是：

 
 层，指的是在训练过程中，每次更新参数时将会随机断开一定百分比的输入神经元，这种方式可以用于防止过拟合。

图片来源         
 
 层，指的是将高维的张量 如二维的矩阵、三维的矩阵等变成一个一维张量向量。 层通常位于连接深度神经网络的 卷积层部分 以及 全连接层部分。
 卷积层
提到卷积层，就必须讲一下卷积神经网络。我们在第一讲的最后部分提高深度学习模型预测的准确性部分，提了一句 “使用更复杂的深度学习网络，在图片中挖出数以百万计的特征”。这种“更复杂的神经网络”，指的就是卷积神经网络。卷积神经网络相比之前基于  层建立的神经网络，有所区别之处在于，卷积神经网络可以使用更少的参数，对局部特征有更好的理解。
 
我们这里以 的卷积神经网络为例，来逐一介绍卷积神经网络中的重要函数。比如我们使用一个形状如下的卷积核


























扫描这样一个二维矩阵，比如一张图片：
















































其过程与结果会是这样：

图片来源
当然，这里很重要的一点，就是正如我们上一讲提到的，  函数的  两个参数都是变量，会在不断的训练中，不断学习更新。卷积神经网络中，卷积核其实也是一个变量。这里的


























可能只是初始值，也可能是某一次迭代时选用的值。随着模型的不断训练，将会不断的更新成其他值，结果也将会是一个不规则的形状。具体的更新方式，同上一讲提到的  等函数模块相同，卷积层也有反向传播函数，基于反向函数计算梯度，即可用来更新现有的卷积层的值，具体方法可参考的反向传导练习。举一个经过多次学习得到的卷积神经网络的卷积核为例：




第一层卷积层的个、大小为  的卷积核结果矩阵。









图片来源 年文章
清楚了其原理，卷积神经网络还需要再理解几个输入参数：
 _ =  = 

其中：

 指的是输出的卷积层的层数。如上面的动图，只输出了一个卷积层， = ，而实际运用过程中，一次会输出很多卷积层。

_ 指的是卷积层的大小，是一个 二维数组，分别代表卷积层有几行、几列。

 指的是卷积核在输入层扫描时，在  两个方向，每间隔多长扫执行一次扫描。

 这里指的是是否扫描边缘。如果是 ，则仅仅扫描已知的矩阵，即忽略边缘。而如果是 ，则将根据情况在边缘补上，并且扫描边缘，使得输出的大小等于 _  。


 
这里  就比较好理解了，就是特地选取输入图像的某一个固定的小部分。比如车载摄像头检测路面的马路线时，摄像头上半部分拍到的天空就可以被  函数直接切掉忽略不计。

图片来源自动驾驶课程
 
部分提到输入参数时，提到 参数如果是，扫描图像边缘时会补上，确保输出数量等于   。这里  的作用，就是在图像外层边缘补上几层。如下图，就是对原本  的图片进行 =  操作后的结果：

图片来源 博客
 池化层
 
可能大家在上一部分会意识到一点，就是通过与一个相同的、大小为的卷积核做卷积操作，每次移动步长为，则相邻的结果会非常接近，正是由于结果接近，有很多信息是冗余的。
因此， 就是一种减少模型冗余程度的方法。以      为例。图中如果是一个  的输入矩阵，则这个  的矩阵，会被分割成由两行、两列组成的  子矩阵，然后每个  子矩阵取一个最大值作为代表，由此得到一个两行、两列的结果：

图片来源 斯坦福课程
 
 与  类似，不同的是一个取最大值，一个是平均值。如果上图的  换成 ，结果会是：



















 
，其实指的是，之前举例  提到的  ，对子矩阵分别平均，变成了对整个 矩阵求平均值。
这个理念其实和池化层关系并不十分紧密，因为他扔掉的信息有点过多了，通常只会出现在卷积神经网络的最后一层，通常是作为早期深度神经网络  层   层结构的替代品

前面提到过  层通常位于连接深度神经网络的 卷积层部分 以及 全连接层部分，但是这个连接有一个大问题，就是如果是一个    的全连接层，一下就多出来了百万参数，而这些参数实际用处相比卷积层并不高。造成的结果就是，早期的深度神经网络占据内存的大小，反而要高于后期表现更好的神经网络：

图片来源   
更重要的是，全连接层由于参数偏多，更容易造成 过拟合——前文提到的  层就是为了避免过拟合的一种策略，进而由于过拟合，妨碍整个网络的泛化能力。于是就有了用更多的卷积层提取特征，然后不去  这些    大小卷积层，直接把这些    大小卷积层变成一个值，作为特征，连接分类标签。
 正则化层
除了之前提到的  策略，以及用 取代全连接层的策略，还有一种方法可以降低网络的过拟合，就是正则化，这里着重介绍下 。
 
 确实适合降低过拟合，但他提出的本意，是为了加速神经网络训练的收敛速度。比如我们进行最优值搜索时，我们不清楚最优值位于哪里，可能是上千、上万，也可能是个负数。这种不确定性，会造成搜索时间的浪费。
就是一种将需要进行最优值搜索数据，转换成标准正态分布，这样就可以加速优化：
输入：一批 数据 
期望输出： β，γ

具体如何实现正向传播和反向传播，可以看这里。
 反卷积层
最后再谈一谈和图像分割相关的反卷积层。
之前在  介绍了卷积层，在  介绍了池化层。相信读者大概有了一种感觉，就是卷积、池化其实都是在对一片区域计算平均值、最大值，进而忽略这部分信息。换言之，卷积池化，就是对输入图片打马赛克。
但是马赛克是否有用？我们知道老司机可以做到“图中有码，心中无码”，就是说，图片即便是打了马赛克、忽略了细节，我们仍然可以大概猜出图片的内容。这个过程，就有点反卷积的意思了。

利用反卷积层，可以基于 卷积层全连接层结构，构建新的、用于图像分割的神经网络 结构。这种结构不限制输入图片的大小，



卷积全连接层结构
全卷积层结构









图片来源：     
 
上图在最后阶段使用了  模块，这个同样在  的  模块可以找到。用法和  基本相反，比如：
= 

就相当于将输入图片的长宽各拉伸一倍，整个图片被放大了。
当然， 实际上未必在网络的最后才使用，我们后面文章提到的  网络结构，每一次进行卷积操作缩小图片大小，后期都会使用  函数增大图片。

图片来源       
 深度神经网络的上下游结构
介绍完深度神经网络的基本结构以后，读者可能已经意识到了， 部分提到的深度神经网络的参数大小动辄几十、上百，如何合理训练这些参数是个大问题。这就需要在这个网络的上下游，合理处理这个问题。
海量参数背后的意义是，深度神经网络可以获取海量的特征。第一讲中提到过，深度学习是脱胎于传统机器学习的，两者之间的区别，就是深度学习可以在图像处理中，自动进行特征工程，如我们第一讲所言：

想让计算机帮忙挖掘、标注这些更多的特征，这就离不开 更优化的模型 了。事实上，这几年深度学习领域的新进展，就是以这个想法为基础产生的。我们可以使用更复杂的深度学习网络，在图片中挖出数以百万计的特征。

这时候，问题也就来了。机器学习过程中，是需要一个输入文件的。这个输入文件的行、列，分别指代样本名称以及特征名称。如果是进行百万张图片的分类，每个图片都有数以百万计的特征，我们将拿到一个 百万样本  百万特征 的巨型矩阵。传统的机器学习方法拿到这个矩阵时，受限于计算机内存大小的限制，通常是无从下手的。也就是说，传统机器学习方法，除了在多数情况下不会自动产生这么多的特征以外，模型的训练也会是一个大问题。
深度学习算法为了实现对这一量级数据的计算，做了以下算法以及工程方面的创新：

将全部所有数据按照样本拆分成若干批次，每个批次大小通常在十几个到多个样本之间。详见下文 输入模块
将产生的批次逐一参与训练，更新参数。详见下文 凸优化模块
使用  等计算卡代替 ，加速并行计算速度。

这就有点《愚公移山》的意思了。我们可以把训练深度神经网络的训练任务，想象成是搬走一座大山。成语故事中，愚公的办法是既然没有办法直接把山搬走，那就子子孙孙，每人每天搬几筐土走，山就会越来越矮，总有一天可以搬完——这种任务分解方式就如同深度学习算法的分批训练方式。同时，随着科技进步，可能搬着搬着就用翻斗车甚至是高达来代替背筐，就相当于是用  等高并行计算卡代替了 。
于是，我们这里将主要提到的上游输入模块，以及下游凸优化模块，实际上就是在说如何使用愚公移山的策略，用 少量多次 的方法，去“搬”深度神经网络背后大规模计算量这座大山。
 输入模块
这一部分实际是在说，当我们有成千上万的图片，存在硬盘中时，如何实现一个函数，每调用一次，就会读取指定张数的图片以=为例，将其转化成矩阵，返回输出。
有  基础的人可能意识到了，这里可能是使用了  的 生成器 特性。其具体作用如廖雪峰博客所言：

创建一个包含万个元素的 ，不仅占用很大的存储空间，如果我们仅仅需要访问前面几个元素，那后面绝大多数元素占用的空间都白白浪费了。所以，如果  元素可以按照某种算法推算出来，那我们是否可以在循环的过程中不断推算出后续的元素呢？这样就不必创建完整的，从而节省大量的空间。在中，这种一边循环一边计算的机制，称为生成器：。

其关键的写法，是把传统函数的  换成 ：
  _=
    _ = 
     
        
            _ _
            _ = _

             = 
             = 
               _
                 = _
                _ =   _ 
                _ = _
                _
                _

                    
            _ = 
            _ = 
             _ _

然后调用时，使用


即可一次返回  张图像以及对应的标注信息。
当然， 同样提供了这一模块，，并且还是加强版，可以对图片进行 增强处理 如旋转、反转、白化、截取等。图片的增强处理在样本数量不多时增加样本量——因为如果图中是一只猫，旋转、反转、颜色调整之后，这张图片可能会不太相同，但它仍然是一只猫：

 = 
            _=
            _=
            __=
            __=
            _=
            __=
            __=
            _=
            _=

      
_

 凸优化模块
这一部分谈的是，如何使用基于批量梯度下降算法的凸优化模块，优化模型参数。
前面提到，深度学习的“梯度下降”计算，可以理解成搬走一座大山，而“批量梯度下降”，则是一群人拿着土筐，一点一点把山上的土给搬下山。那么这一点具体应该如何实现呢？其实在第二讲，我们就实现了一个随机批量梯度下降   ，这里再回顾一下：
 _ _=
       
         =   _  

训练神经网络的过程
   
     = 
       __
         输入模块，将全部所有数据按照样本拆分成若干批次
        _ _ = _ _ _=_
         各种深度学习零件搭建的深度神经网络
        __
         凸优化模块
        _ 

当然， 其实并不是一个很好的方法，有很多改进版本，可以用下面这张图概况：

 里，可以直接使用     以及  等模块。其实在优化过程中，直接使用  默认参数，基本就可以得到最优的结果：
   
 = 
=_
                =
                =

 实战项目—— 图像分类
最后我们用一个 中的官方示例，来结束本讲。
首先做一些前期准备：
 初始化
 ____  _
   
   
   
   
      
    
   _
     
   
   
   

 _  _
   
 = 
__=
_=





 定义变量
_ = 
_ = 
_ = 
_ _ =  
_ =    
_ =  
_ =  


_ _ _ _ = _
_ = _  
_  = _  

_ = _
_ = _


_ = _ _ 
_ = ___ _
_ = ___ _

上游部分， 基于生成器的批量生成输入模块：
 = 
            _=
            _=
            __=
            __=
            _=
            _=
            __=
            __=
            _=
            _=

_

核心部分，用各种零件搭建深度神经网络：
 = 
_ _ =_=_

_ _

_=_


_ _ =

_ _

_=_






_


构建的模型如下：

下游部分，使用凸优化模块：
 = =
=_
                   =
                   =

最后，开始训练模型，并且评估模型准确性：
训练模型
_ = _ =_ = __=
 = _=
__ _ _=_
                        __=_  _
                        =_ =
                        _=_ _ =_


 模型评分
 = _ _ =
 输出结果
  
                      


以上代码本人使用   执行，个  中，每个  用时  左右，总计用时在十五分钟以内，约  后，验证集的准确率数会逐步收敛在左右。
本篇是继上一篇“如何造轮子”的主题的一个延续，介绍了  中  工具包有哪些现成的轮子可以拿来直接用。
目前腾讯云  服务器还在内测阶段，暂时没有申请到内测资格的读者，也可以用较小的数据量、较低的_在普通云服务器上尝试一下，但是最终结果准确率肯定不能与的结果相比。使用普通的云服务器运行本讲的代码。并且在接下来的内容中，我们的数据处理运算量将越来越大，必须租用 云服务器 才可以快速算出结果。服务器的租用方式，以及  编程环境的搭建，我们将以腾讯云  为例，在接下来的内容中和大家详细介绍。作者简介：文赫，年加入腾讯，作为前端开发工程师参与过手游戏公会，游戏中心，企鹅电竞等项目，具有丰富的移动端开发和直播开发经验。

导语 企鹅电竞项目，直播和视频播放是其中的核心。面对着产品同学不断的询问：为什么的体验这么差？为什么不能和的播放体验保持一致？我们对着不明确的文档和不同浏览器的怪异表现欲哭无泪。 经过一系列的调研爬坑，斩荆披棘，我们一步步提升了体验，做到了和基本一致的体验。在摸索优化背后，我们也想把这些问题和解决方法总结下来，让其他同学做到直播的时候可以自豪的说，这就是我们的直播体验

 自动播放问题
通过属性视频的自动播放需要在标签上添加属性 如：
  
但是在很多浏览器里，如下并不支持这个属性，在下必须给设置
 =  = 才能让这个属性生效从而让用户一进入页面就开始视频的自动播放
通过直接调用方法在一些情况下我们想加入一些判断逻辑，如判断用户网络环境，在下自动播放，在环境下给出提示，这中情况下就适合直接选中并调用来播放视频
但是这种情况下也需要的支持，如在手下可以做到直接调用，在微信下因为不允许视频直接播放，则必须通过用户的真实操作来触发调用这就是各种微信的活动页面需要引导用户进行一下点击操作才开始的原因。
同时发现真实点击必须使用触发、、或  事件等标准的事件才能触发，使用封装过的事件并不能触发播放器的播放
 页面内联播放问题
在 和一些安卓的一些浏览器下播放视频的时候，不能在页面中播放视频，系统会自动接管视频
如果需要在页面内播放视频，需要在视频标签上加上 ，在以后，需要加上建议同时加上这两个属性，同时需要支持这种模式，手和微信都支持这种模式
在
 =       在内设置属性
 = 
 视频的高度问题
在安卓下，一些浏览器如浏览器和浏览器，系统会把视频的层级调到最高，所以如果想在页面上显示元素，都会被视频盖住，单纯的设置该的是无效的，如图所示

解决方案：在弹出会显示在视频上方的时候暂停视频播放将视频所在的的父元素的高度设为处理完弹出的事件后将视频所在的父元素高度还原
 视频的默认播放图标
在下会有一个默认的播放图标，如图所示

在都会默认显示，不能通过控制，但是可以通过样式将其隐藏
 {         
}
视频的控制栏
在播放的时候，如果在标签上设置了属性，则会在视频里显示控制栏
在
  

需要注意的是这个控制栏是系统自带的，无法通过控制其样式，建议不要使用这个属性而是自己通过自己制作一套控制条
视频的刷新
我们知道暴露了和方法来提供视频的播放和暂停，但是没有标准的刷新方法，如果我们想实现视频的刷新，则需要通过实现
  = 

  {
     
}
视频的全屏问题
全屏
暴露了一个方法，可以让每个都请求全屏，当然标签也可以使用。但是在测试中发现，一些安卓机不支持该属性，如小米手机，所以需要在调用的时候进行一下判断
  =   {
    
}  {
   
}
系统接管播放
我们上边说道调用的方法来进入视频的全屏，那么这个方法会使浏览器完全接管视频播放，如图所示

这种接管的后果是这时的我们是没有办法控制视频的播放，也没有办法在上面浮动我们的元素，如弹幕，礼物这些，会完全被视频盖在下面，所以我们的目标即是解决这种系统接管的问题
使用伪全屏样式全屏
样式全屏的核心是设置标签的宽高，使其撑满整个，看上去像全屏一样但是因为视频一般都是的宽高比，所以在竖屏情况下不能很好的做到铺满整个屏幕

而一般用户进入页面基本都是竖屏，所以我们就要考虑怎么让用户在竖屏点击全屏按钮时，能体验到像终端一样自动进入横屏全屏的体验，下面有两种方案
在用户点击全屏时候，通过属性旋转屏幕
通过的，我们可以把元素旋转显示通过 并设置的高度为当前的宽度，的宽度为当前的高度来实现旋转全屏。这种模式的显示没有太大问题，但因为是通过控制的页面显示，对于原生的空间不能很好的控制，如系统的键盘

在拉起键盘输入弹幕的时候，键盘不受控制还是竖屏显示了如果页面不涉及与原生组件的交互，那么这种方案是一种很可行且兼容性比较好的方案
用户在点击全屏时，通过 来控制旋转横屏
在手里，我们和终端的同学合作添加了控制横竖屏的接口在用户点击全屏的时候，先判断当前是否横屏

  是否横屏
 
  {       
      =  {        
          ==  ||  == 
    }  {         
           
    }
}
设置为横竖屏
 {         
        是竖屏，是横屏
 }
如果是竖屏则强制旋转进入横屏，同时监听页面的方法，页面横竖屏变化的时候会触发这个方法，在这个方法里再动态的调整的宽高来铺满整个屏幕

注：
之前我们发现插入了一段来劫持视频的全屏的事件

满足条件的标签全屏时都会被接管，另外调用方法时，也会接管播放器。
如果发现在内核下无法使用伪全屏而被浏览器接管，可以咨询下同事为你的域名开启白名单，不接管你域名下的视频播放
总结：
在经历过各种优化和调整后，我们可以在直播页做到看直播，看弹幕，发弹幕，发送礼物，表情，查看排名等各种功能，再配合上手里的隐藏的_=，可以实现全屏播放效果，做到了媲美原生播放的体验。
现在的的播放还有很多的表现和兼容性的问题，希望这份指南可以帮你在遇到同样的坑时能尽快爬出来，并优化你的播放体验，吸引到更多的用户  最近研究了一下里面字典的实现，作为高效的内存存储而被广泛使用，内部实现的结构以及多种高效的数据结构，其底层基本上就是靠字典来实现。而其字典数据结构是基于哈希表来实现的，其中一些特性的实现十分精妙。
数据结构
节点数据结构
因为是基于开链法的哈希表实现，所以需要维护了一个节点
   {
     
     {
         
        _ 
        _ 
         
    } 
      
} 
哈希表数据结构
其中是当前哈希表的大小，是当前使用的大小，会根据当前的大小来做相应的调整，调整的过程就是字典动态扩容的过程，具体过程下面会描述。＝－，是用来做掩码的，哈希算法算出的，通过操作来代替除留余数，这么做的原因是操作比％更快。
   {
     
      
      
      
} 
字典数据结构
是函数指针类型，封装了哈希函数，比较函数，释放内存函数等等。一个高效的哈希函数能保证哈希的结果尽量均匀分布，中的字符串哈希算法便是著名的开源算法，但是因为上层的有不同的数据结构，所以实现了不同的哈希函数。字典中维护两张哈希表，主要是用来做动态的，便是两张表动态的索引。是当前迭代器的个数，具体后面会详细介绍。
   {
     
     
     
             ==  
            
} 
字典定义整体的结构图如下：

特性介绍
的字典实现了很多特别的东西，花式造轮子的根本原因还是从时间与空间上做考量。
动态扩容缩容
的数据都是放在第一张哈希表中中的，所谓的动态扩容就是说那张哈希表快不够用的时候，目前是  的时候，使用来扩大哈希表的容量。这其中有两种方式，一种是提供了显示的扩容的接口，供外部调用，另外一种是在添加数据的时候调用_，以此来判断是否需要扩容。缩容就是当前哈希表使用率  低于某个值时，目前这个值是，利用缩小哈希表的容量。扩容和缩容的操作就是的过程。
渐进式
就是将第一张的数据迁移到的过程，实现了两种策略，一种是在定时器的每个里面，执行操作的时候，还有一种是在增加查找删除等字典操作的时候执行，这样的过程可以保证的时候不会阻塞服务器，对用户来说，也是无感知的。的过程中维护了一个索引，就是上面介绍的字典结构中的，使用这个索引遍历，将数据无缝迁移到。因为在中的任何时刻，一个节点只能存在其中一张哈希表中，所以每次操作都需要处理两张表。
迭代器
里面的字典实现了两种迭代器，一种是安全的迭代器，一种是普通的迭代器。所谓安全就是指在迭代的过程中可以执行添加查找等操作，非安全的迭代器就是只能执行迭代操作。其实本质上就是安全的迭代器会给设置里面的变量，这样字典的各种操作就不会执行操作，如果在迭代的过程中执行了，迭代索引就会错乱。
接口介绍
    
创建字典，目前中用到字典的地方有很多，包括全量的，超时的等等中的， 命令回调表，结构，结构，结构等等。
      
添加数据，前面说到会执行操作，并且如果字典底层正在，索引的计算会读取两张表来判断，并且数据只会添加到第二张表里面。
     
查找数据，和添加数据很类似，唯一的区别是查找数据的时候不会计算是否需要扩容。
     
删除数据，和添加数据的过程类似，但是在删除数据的过程中不做缩容操作，缩容是上层负责主动调用缩容接口和。
  
迭代字典，搭配或者操作，前面有说到安全迭代器和非安全迭代器的区别，非安全的迭代器在初次迭代的时候会计算一个哈希值，释放迭代器的时候这个哈希值是否被改变了。
总结
字典的实现有很多有趣的特性，包括动态扩容缩容，渐进式等，所有这些特性的出发点都是基于充分使用内存的角度去考虑。
是时下最流行的基于的开源计算机视觉库，它功能丰富，函数众多，从最基本的读写图片，到简单的图像处理比如降噪滤波、边缘检测、图像变换、特征提取等，再到更加高级的行人检测、人脸识别、文本识别等，尽皆包含。在提供的函数的基础上，我们可以很方便地开发自己的应用，实现自己的算法。总的来说，就是非常强大。具体有多强大？那得用了才知道。
很多要做人脸识别，要用到特征的人都问过的一个问题是，为什么配置好之后，却找不到人脸识别的头文件，找不到在哪？这是因为之后，把一些还在最新的，但不是很稳定的，还在测试阶段的东西放在了模块里面。而且官方默认不带模块。不幸的是，我们最想用的人脸识别和特征都在里面。如果需要用的话，那就需要自己编译了。在 上的配置和编译的方法可以参考我之前的博客。今天的内容仍然是用语言，最近用用着比较顺手。
的环境配置
显然，跟众多基于的库一样， 也是有接口的。下配置可以用下面两种方法：

官网下载并安装之后，在目录\\\\\之下有一个文件，把它拷贝到安装目录下的\\文件夹下面即可。需要注意的是版本要对应，比如这里就要对应位的。而且目前官方自带的只有版本的包。如果想要其他版本怎么办？

那就要说到一个神奇的网站了：      ，这里面包含了几乎所有的能用到的库的安装包，比如我们需要的，这里可以找到下面这么多版本，可以适应不同的需求，还有编译的版本的，简直是惊喜。



按照自己的环境下载相应的版本，然后还是用安装，命令如下：
  
请把星号换成对应的名字。
我这里用的是包含的位的包。
猫脸检测
喵星人真的是要统治世界了。不然为什么自带的检测器中除了人脸检测、行人检测这些意料之中就应该存在的检测器之外，还悄悄多出了猫脸检测器呢。
今天我们就来试一下这个猫脸检测到底 是什么样的？基于的猫脸检测十分简单。用的话只有区区行代码。其中行代码中发挥主要作用的只有一个函数：

此函数的作用是，在输入图像中检测不同尺寸的对象，返回包含对象的矩形框。它接收的参数：
——输入图像
——表示每轮检测图像齿轮减少的比例
——指明对象要至少被检测到几次才能判定对象确实存在
——检测对象的最小尺寸
——检测对象的最大尺寸
代码
按照惯例，注释齐全，无需多说。
  = 
 
 加载猫脸检测器
 = _
 = 
 读取图片并灰度化
 =   
 =  _
 猫脸检测
 = 
    
    = 
    =
    = 
    =__

 框出猫脸并加上文字说明
      
            
           _
 显示图片并保存
 

 = 

效果
运行脚本后效果如下：


举一反三
本文虽然只是在说猫脸检测，但是在下，人脸检测、行人检测、人眼检测等都是同样的道理，同样的流程。只需要把最开始相应的检测器换掉，然后按照实际情况调节的参数即可。比如以下是人脸检测的效果：作者：王少鸣 

 在发布了    ，把 开发技术扩展到了平台。  让开发者使用  和  编写应用，利用相同的核心代码就可以创建 基于， 和  平台的原生应用。本文将浅析 的架构及相关基础知识。环境搭建及调试相关知识参考官网文档即可，本文不再赘述。
一架构分析
层次架构：
层：层为逻辑入口，启动层的解析器，执行通过传递来的渲染指令，从而构建等。层依赖于众多优秀开源库，在图片处理使用的是，网络通信使用的是，当然还有众多工具类，如解析工具，知名开源库，小而全的底层工具类等，在层均封装为。层核心包是，封装了众多上层的，如，，等，下面会以的启用过程，完整分析层的架构。
层：层最主要是封装了，执行对的解析。基于，开发者可以尽情使用的新特性，如、箭头操作符等，而且  运行在中的，完全不存在浏览器兼容的情况。桥接了   通信的核心接口。主要是将来自目录的或本地加载到，再通过解析文件。
层：主要处理事件分发及 ，主要有以下几个部件：

：层通编写的 来构建或， 是在内存中的一种轻量级表达方式，可以通过不同的渲染引擎生成不同平台下的。的使用在  里极为重要 因为的存在让计算   更高效。
： 组件通过内部的  变量控制生命周期及事件回调。如方法用于定义组件初始状态，后续组件可通过  属性读取该状态。当事件触发或者主动调用方法更新数据导致状态变化， 方法就修改状态值，每次修改以后，自动调用  方法，重新渲染组件。
：使用，使用实现了 ，不依赖于，能编译成或者，最终达到跨平台的展示目的，但暂时不支持，暂时只能支持简单的布局和普通的动画。

与通信机制：
在层与层的分别存有相同一份模块配置表，与互相通信时，通过里的配置表将所调用模块方法转为{}的形式传递给处理层，处理层通过的模块配置表找到对应的方法执行，如果有，则回传给调用层。在了解 启动后，第三部分会详细讲这套机制。
二从应用启动到页面加载完成分析
        上图为   加载过程的解析，下面先概要描述上层核心类及原理，再梳理核心的启用步骤。  ：：主要是用来创建及管理的实例的上层接口，控制开发调试，生命周期与所在保持一致。
：为启动入口核心类，负责监听及分发事件并重新渲染元素，启动后，其将作为的 。
：顶级异步封装类，提供与互通的环境，通过将的 传送到引擎。
：层模块注册表，即暴露给的集合。
：层模块注册表，负责将所有注册到，通过动态代理调用到。
：定义核心框架模块，创建。
启动过程的解析：
在时会配置应用所需的模块与模块之后，通过的启动。
在创建同时会创建用于加载的，并传递给。
会创建模块注册表及模块注册表，并遍历实例化模块。
通过向 请求 ，并传递给，最后传递给，再通过通知完成渲染。
三与通信机制
与之间的调用，是以两边存在两边存在同一份模块配置表，最终均是将调用转化为{ ，，}，处理端在模块配置表里查找注册的模块与方法并调用。   ：通过注册表调用到实例，透过的，调用到中的，最后通过，调用，根据参数｛｝相应模块执行。详细流程如下图。   ：不主动传递数据调用。在需要调用调模块方法时，会把参数｛｝等数据存在中，等待的事件触发，再把中的｛｝返回给，再根据模块注册表找到相应模块处理。详细流程如下图。
 
四总结
将分解成组件，废弃了模板，统一视图逻辑标签，使构建的视图更容易扩展和维护， 更是其提高性能的亮点， 中的并不保证马上影响真实的，会等到事件循环结束，利用算法，通过当前新树与之前的树作比较，计算出最小的步骤更新真实的。 的推出更使得利用相同的核心代码就可以创建 ， 和  平台的原生应用，但目前 的基础库将近，落地项目仍需要精简，目前我们正在精简中。当然，对于版本也有考验，仅支持     以上的版本 ，当然，在系统不支持情况下，可以作为后备方案。我们后续会持续关注 的动态，向大家继续推送更多关于 的文章。底部有关于 所有类库的描述

文章来源公众号空间终端开发团队


相关推荐
   框架启动核心路径剖析
   项目实战总结
面向未来的跨界开发技术上微信小程序提供了一套在微信上运行小程序的解决方案，有比较完整的框架、组件以及 ，在这个平台上面的想象空间很大。
小相册是结合腾讯云对象存储服务  ，简称制作的一个微信小程序示例。在代码结构上包含如下两部分：

 小相册应用包代码，可直接在微信开发者工具中作为项目打开

 搭建的  服务端代码，作为服务器和通信，提供  接口示例用于拉取  图片资源、上传图片到 、删除  图片等。


小相册主要功能如下：

列出  服务器中的图片列表

点击左上角上传图片图标，可以调用相机拍照或从手机相册选择图片，并将选中的图片上传到  服务器中

轻按任意图片，可进入全屏图片预览模式，并可左右滑动切换预览图片

长按任意图片，可将其保存到本地，或从  中删除



部署和运行
拿到了本小程序源码的朋友可以尝试自己运行起来。
整体架构

 准备域名和证书
在微信小程序中，所有的网络请求受到严格限制，不满足条件的域名和协议无法请求，具体包括：

只允许和在  中配置好的域名进行通信，如果还没有域名，需要注册一个。

网络请求必须走  协议，所以你还需要为你的域名申请一个证书。


域名注册好之后，可以登录微信公众平台配置通信域名了。

 云主机和镜像部署
小相册的服务器运行代码和配置已经打包成腾讯云  镜像，大家可以直接使用。

腾讯云用户可以免费领取礼包，体验腾讯云小程序解决方案。



镜像已包含「剪刀石头布」和「小相册」两个小程序的服务器环境与代码，需要体验两个小程序的朋友无需重复部署

 配置 
镜像中已经部署了 ，需要在下修改配置中的域名、证书、私钥。

配置完成后，即可启动 。

 域名解析
我们还需要添加域名记录解析到我们的云服务器上，这样才可以使用域名进行  服务。
在腾讯云注册的域名，可以直接使用云解析控制台来添加主机记录，直接选择上面购买的 。

解析生效后，我们在浏览器使用域名就可以进行  访问。

 开通和配置 
小相册示例的图片资源是存储在  上的，要使用  服务，需要登录  管理控制台，然后在其中完成以下操作：

开通  服务分配得到唯一的 
使用密钥管理生成一对和用于调用  
在  列表中创建公有读私有写访问权限、加速的 存储图片的目标容器

 启动小相册示例  服务
在镜像中，小相册示例的  服务代码已部署在目录下：
进入该目录：
 
在该目录下有个名为的配置文件如下所示，按注释修改对应的  配置：
 = {
      监听的端口号
     
    __ 

     填写开通  时分配的  
     填写密钥 
     填写密钥 
     填写创建的公有读私有写的名称
}
小相册示例使用管理  进程，执行以下命令启动  服务：
  
 微信小程序服务器配置
进入微信公众平台管理后台设置服务器配置，配置类似如下设置：

注意：需要将设置为上面申请的域名，将  合法域名设置为在  管理控制台中自己创建的  的相应  加速访问地址，如下图所示：

 启动小相册 
在微信开发者工具将小相册应用包源码添加为项目，并把源文件中的通讯域名修改成上面申请的域名。

然后点击调试即可打开小相册开始体验。

这里有个问题。截止目前为止，微信小程序提供的上传和下载  无法在调试工具中正常工作，需要用手机微信扫码预览体验。
主要功能实现
上传图片
上传图片使用了微信小程序提供的获取需要上传的文件路径，然后调用上传文件接口发送   请求到自己指定的后台服务器。和传统表单文件上传一样，请求头也是。后台服务器收到请求后，使用  模块  解析  请求，将解析后的数据保存为指定目录下的临时文件。拿到临时文件的路径后，就可直接调用   提供的文件上传  进行图片存储，最后得到图片的存储路径及访问地址存储的图片路径也可以直接在  管理控制台看到。
获取图片列表
调用列举目录下文件目录 可以获取到在  服务端指定  和该  指定路径下存储的图片。
下载和保存图片
指定图片的访问地址，然后调用微信小程序提供的和接口可以直接将图片下载和保存本地。这里要注意图片访问地址的域名需要和服务器配置的  合法域名一致，否则无法下载。
删除图片
删除图片也十分简单，直接调用文件删除  就可以将存储在  服务端的图片删除。

相关推荐微信小程序云端解决方案微信小程序接《法律人工智能十大趋势上》
六、人工智能和机器人将成为法律系统的主要进入点
无论是律所和律师，还是法院，抑或当事人和终端消费者，基于人工智能和机器人技术的“智能交互界面” 将成为法律系统的主要进入点，法律机器人和人工智能是其中的核心。对于律师而言，未来的法律实践比如法律检索、案件管理、法律写作等将主要通过具有智能交互界面的法律机器人和人工智能系统来完成，这就好比医生现在主要借助各种复杂的医疗器械来完成医疗活动一样。对于法院而言，司法审判的数字化和在线化，意味着类案检索、裁判文书写作、证据分析和推理等也将在法律人工智能的辅助下进行，甚至为其所取代。对于终端用户而言，交互性的、基于互联网的问答系统可以以文本或者语音对话的形式同用户交流，并生成所需的法律信息，或者指导其完成基本的法律文件和格式。在此背景下，律师当前的角色将会发生变化，一些角色可能被机器取代，比如常规性、重复性任务；一些角色可能被机器增强，比如案件预测、法律写作；而对于新法新规，律师依然需要扮演核心角色。
七、律师市场评价将使法律行业更加透明，可能带来“马太效应”
法律市场作为一个双边市场，其评价体系在很大程度上是不透明的，不像电商平台以及外卖、生活服务等平台，具有较为完善的用户评价机制，确保了市场的透明度和消费者的知情权。但是由于法律市场在很大程度上并未平台化，很难搭建有效的评价机制。然而，人工智能、大数据等正在改变这一状况，对律师市场进行评价正变得可能，成为了法律科技的一大趋势。当前，律师推荐已经成为法律科技的核心领域之一，国内外都在持续涌现律师推荐和评价类的产品和服务。律师市场评价相当于将律师置于阳光之下，明星律师、普通律师、不合格律师等的区分将透明化，结果可能带来律师市场的“马太效应”，明星律师业务增多，收入增多，而普通律师、资历浅的律师将遭到相反的待遇。这呼吁律师转型，即以技术化的低成本模式提供法律服务。
八、法律人工智能职业将作为法律行业的新兴职业而不断涌现
法律机器人和法律人工智能并非凭空产生，需要技术人员和法律专家之间的通力合作。随着人工智能与法律不断融合，这一领域的研究、开发和应用将不断增强，法律人工智能职业将作为法律行业的新兴职业而不断涌现。当前，一些积极拥抱新技术的国际律所已经在加强法律能力建设，法律开发者、法律数据分析师、法律数据库管理者等正在加入律所、公司法务部门、法院、法律数据库公司等法律机构。法律科技公司更是需要既懂法律又懂技术的复合型人才。未来，技术与法律的结合将更为密切，对新型人才的需求也更为迫切。
九、法律教育与人工智能等前沿信息科学技术将日益密切结合起来
中国《新一代人工智能发展规划》已经看到了法学教育与人工智能的结合，提出打造“人工智能法学”复合专业培养新模式。这是极为高瞻远瞩的设想。笔者曾参与翻译“  ”一书，书中对美国“”四年本科三年法学院教育的法学教育模式提出严正批判，认为法学院根本不需要读三年，顶多需要两年，可能一年就够了。而中国传统的法学教育是高中毕业后直接读四年本科法学教育，这样的法学人才培养模式很难适应机器人和人工智能主导的未来法律实践。相比现在的律师，未来的律师将会从事大不一样的工作，所以需要不同的教育。因此，新规划提出的“人工智能法学”培养模式是有远见的。
其实，国外法学院早就开始探索革新法学教育，注重对法科学生的科技和数字素养的培养。比如，早在年，乔治城大学法学院即开始提供一个技术创新与法律实践的实践课程，形成特色的“  ”比赛项目，培养学生的法律开发能力。年，墨尔本大学法学院开始提供如何开发法律应用的课程。未来，法律教育与人工智能等前沿信息科学技术将日益密切结合起来，而能否较早较快实现这一设想，取决于法学教育的反应速度。其实，人工智能不仅仅对法学教育提出了挑战，要求跨学科融合的教育模式，而且对其他学科教育也提出了类似的挑战。
十、计算法律 ，以及算法裁判，或将成为法律的终极形态
英格兰和威尔士上诉法院大法官在在线法院的倡议中提出了算法裁判，即人工智能可以代替法官直接作出裁判。这并非不可能。其实，计算法律学历来就是人工智能与法律的核心研究方向之一，在思考“除了书面语言，法律可以有更精确、更形式化的表达吗？”这一问题，并探索用计算逻辑和代码来表达法律。笔者此前在知乎网站上看到一个设想：如果能用一列维向量描述各种事件，将「事件」导入「法律」，从而产生「判决」。将法律条文转化成代码，从而使得判决彻底脱离个人主观判断。并且可以在任何人的计算机上在线。将代码开源，放在类似的网站上，供全民监督。计算法律当前在计税等一些领域有应用，更多则是一种学术研究；但在未来的成熟的信息社会，更普遍的计算法律将可能出现，届时系统将会自动执行法律，不需要律师，甚至也不需要法官。因为那时的法律已经完全自动化了。
法律人应做好迎接未来的准备
人们说，预见未来的最好方式是创造未来。法律行业的未来需要法律人这一职业共同体共同创造。虽然之前有研究认为律师助理和法律助理被自动化的概率高达，引发了人们对法学毕业生就业的担忧。但笔者在网站的测试结果显示，仅有的律师会被人工智能和机器人替代。不管科学与否，都可以作为一种暂时的宽慰。
据笔者调查，律师的工作包括十三项：文件管理，案件管理，文件审阅，尽职调查，文件起草，法律写作，法律检索研究，法律分析和策略，事实调查，客户咨询服务，谈判，其他交流和互动，出庭及准备；律师需要及早思索这其中的哪些任务可以被自动化或者可以借助科技提高效率，而英国学者则提出了“分解”法律服务的思路，认为一项法律任务可以被分解成多个部分，核心部分可以由律师完成，其他部分则由效率更高的第三方完成。
而对于法律服务自动化的担忧，包括律师在内的法律人在判断其工作的价值以及在思考人工智能技术对其工作的影响时，至少需要考虑以下三个因素：第一，是否涉及数据分析和处理，在这一方面，人类几乎不可能和人工智能和机器人相匹敌，尽早使用并适应新技术才是明智的选择；第二，是否涉及互动交流，类似行政前台等法律客服工作被自动化的可能性非常大，一般的法律咨询也可以被自动化，但更高级别的互动交流如谈判、出庭等则很难在短期内被自动化；第三，是否处于辅助决策的地位，人工智能辅助决策已经被应用在了很多领域，在法律行业，人工智能辅助决策也正在发生并成为一个趋势，比如在案件结果预测上，人工智能可以比专业律师做得更好，诸如此类，尽早利用并适应新技术才是必然的选择。
最后，作为总结，经过三十多年的发展，在超强运算能力、大数据和持续改进的算法的影响下，人工智能对法律以及法律行业的影响正在加深、加快，未来年法律行业将可能迎来一场巨变。作为法律人工智能最直接的目标客户，法律人需要调整心态，积极拥抱新技术和新模式，并在这个过程中坚持对法律的理念和信仰，防止法律人工智能削弱、损害法律共同体所秉持的以及法律系统所坚持的观念和价值，让法律人工智能来促进司法正义，而非带来偏见和歧视，或者背道而驰、贬损正义。我们容器集群内核基于，支持对容器进行周期性的探测，根据探测结果来决定判断容器的健康状态，并执行额外的操作。当我们创建服务时，在容器参数页的高级设置选项里面，可以为容器设置健康检查。

健康检查类别


容器存活检查。该检查方式用于检测容器是否活着，类似于我们执行检查进程是否存在。如果容器的存活检查失败，集群会对该容器执行重启操作，检查成功则不执行任何操作。

容器就绪检查。该检查方式用于检测容器是否准备好开始处理用户请求，一些程序的启动时间可能很长，比如要加载磁盘数据或者依赖外部的某个模块启动完成时才提供服务，这时候程序进程在，但是并不能对外提供服务。这种场合下该检查方式就非常有用。如果容器的就绪检查失败，集群会屏蔽请求访问该容器，否则会放开对该容器的访问。


健康检查方式

端口探测
端口探测的原理是，对于提供通信服务的容器，集群周期性地对该容器建立连接，如果连接成功，则认为探测成功，否则认为探测失败。选择端口探测方式，必须指定容器监听的端口。比如我们有一个容器，它的服务端口是，我们对该容器配置了端口探测，指定探测端口为，那么集群会周期性地对该容器的端口发起连接，如果连接成功则认为检查成功，否则认为检查失败。
请求探测
请求探测针对的是提供或者服务的容器，集群周期性地对该容器发起 请求，如果 返回码的范围在，则认为探测成功，否则认为探测失败。使用请求探测必须指定容器监听的端口和的请求路径。举个例子，我们的容器提供了服务，服务端口为，我们的检查路径为，那么集群会周期性地对容器发起   请求。
执行命令检查
执行命令检查是一种强大的检查方式，该方式要求用户指定一个容器内的可执行命令，集群会周期性地在容器内执行该命令，如果命令的返回结果是则认为检查成功，否则认为检查失败。对于上面提到的端口探测和请求探测，都可以通过执行命令检查的方式来替代：

对于端口探测，我们可以写一个程序来对容器的端口进行，如果成功，脚本返回，否则返回。

对于请求探测，我们可以写一个脚本来对容器进行， ，并检查返回的，如果在的范围，脚本返回，否则返回。


注意： 必须把要执行的程序放在容器的镜像里面，否则会因找不到程序而执行失败。
注意 如果执行的命令是一个脚本，不能直接指定脚本作为执行命令，需要加上脚本的解释器。比如我们脚本是_，那么我们使用执行命令检查时，指定的程序应该是  _。究其原因，是因为集群在执行容器里的程序时，不在终端环境。
其它公共参数


启动延时，单位秒。该参数指定了容器启动后，多久开始探测。例如启动延时设置成，那么健康检查将在容器启动秒后开始。

间隔时间，单位秒。该参数指定了健康检查的频率。例如间隔时间设置成，那么集群会每隔检查一次。

响应超时，单位秒。该参数指定了健康探测的超时时间，对应到端口探测、请求探测、执行命令检查三种方式，分别表示连接超时时间、请求响应超时时间，以及执行命令的超时时间。

健康阈值，单位次数。该参数指定了健康检查连续成功多少次后，才判定容器是健康的。例如健康阈值设置成，只有满足连续三次探测都成功才认为容器是健康的。 注意 如果健康检查的类型为存活检查，那么健康阈值只能是，用户设置成其它值将被视为无效，因为只要探测成功一次，我们就能确定容器是存活的。

不健康阈值，单位次数。该参数指定了健康检查连续失败多少次后，才判断容器是不健康的。例如不健康阈值设置成，只有满足连续三次都探测失败了，才认为容器是不健康的。



相关推荐 容器编排系统介绍 腾讯云容器服务的滚动升级使用简介作者：

前言
 是微信官方的终端基础组件，是一个使用  编写的业务性无关，平台性无关的基础组件。目前已接入微信 、、、、 等客户端。现正在筹备开源中，它主要包括以下几个部分：
、：可以独立使用的公共库，包括 、线程、消息队列等；、：可以独立使用的日志模块；、：可以独立使用的网络诊断模块；、：可以独立使用的信令分发网路模块。
本文章是  系列的第一篇：高性能跨平台日志模块。
正文
对于移动开发者来说，最大的尴尬莫过于用户反馈程序出现问题，但因为不能重现且没有日志无法定位具体原因。这样看来客户端日志颇有点“养兵千日，用兵一时”的感觉，只有当出现问题且不容易重现时才能体现它的重要作用。为了保证关键时刻有日志可用，就需要保证程序整个生命周期内都要打日志，所以日志方案的选择至关重要。
常规方案

方案描述 对每一行日志加密写文件

例如  平台使用  实现日志模块，每有一句日志就加密写进文件。这样在使用过程中不仅存在大量的 ，更致命的是因为有大量的  需要写入，影响程序性能很容易导致程序卡顿。选择这种方案，在  版本只能选择把日志关掉。当有用户反馈时，就需要给用户重新编一个打开日志的安装包，用户重新安装重现后再通过日志来定位问题。不仅定位问题的效率低下，而且并不能保证每个需要定位的问题都能重现。这个方案可以说主要是为程序发布前服务的。
来看一下直接写文件为什么会导致程序卡顿 

当写文件的时候，并不是把数据直接写入了磁盘，而是先把数据写入到系统的缓存 中，系统一般会在下面几种情况把   写入到磁盘：

定时回写，相关变量在__和__中定义。

调用  的时候，发现   占用内存超过系统内存一定比例，相关变量在__ 后台运行不阻塞 和_阻塞 中定义。

内存不足。


数据从程序写入到磁盘的过程中，其实牵涉到两次数据拷贝：一次是用户空间内存拷贝到内核空间的缓存，一次是回写时内核空间的缓存到硬盘的拷贝。当发生回写时也涉及到了内核空间和用户空间频繁切换。
  回写的时机对应用层来说又是不可控的，所以性能瓶颈就出现了。
这个方案存在的最主要的问题：因为性能影响了程序的流畅性。对于一个  来说，流畅性尤为重要，因为流畅性直接影响用户体验，最基本的流畅性的保证是使用了日志不会导致卡顿，但是流畅性不仅包括了系统没有卡顿，还要尽量保证没有  峰值。所以一个优秀的日志模块必须保证流畅性：

不能影响程序的性能。最基本的保证是使用了日志不会导致程序卡顿

我觉得绝大部分人不会选择这一个方案。
进一步思考
在上个方案中，因为要写入大量的  导致程序卡顿，那是否可以先把日志缓存到内存中，当到一定大小时再加密写进文件，为了进一步减少需要加密和写入的数据，在加密之前可以先进行压缩。至于  下存在频繁  的问题，可以使用  来实现进行避免，而且通过  可以实现一个平台性无关的日志模块。

方案描述：把日志写入到作为  中间  的内存中，达到一定条件后压缩加密写进文件。

这个方案的整体的流程图： 

这个方案基本可以解决  版本因为流畅性不敢打日志的问题，并且对于流畅性解决了最主要的部分：由于写日志导致的程序卡顿的问题。但是因为压缩不是  ，所以仍然存在  峰值。但这个方案却存在一个致命的问题：丢日志。
理想中的情况：当程序  时，  捕捉模块捕捉到 ， 然后调用日志接口把内存中的日志刷到文件中。但是实际使用中会发现程序被系统杀死不会有事件通知，而且很多异常退出， 捕捉模块并不一定能捕捉到。而这两种情况恰恰是平时跟进的重点，因为没有  堆栈辅助定位问题，所以丢日志的问题这个时候显得尤为凸显。
在实际实践中， 可以使用共享内存做中间  防止丢日志，但其他平台并没有太好的办法，而且   以后，大部分手机不再有权限使用共享内存，即使在   之前，共享内存也不是一个公有接口，使用时只能通过系统调用的方式来使用。所以这个方案仍然存在不足：

如果损坏一部分数据虽然不会累及整个日志文件但会影响整个压缩块

个别情况下仍然会丢日志，而且集中压缩会导致  短时间飙高


通过这个方案，可以看出日志不仅要保证程序的流畅性，还要保证日志内容的完整性和容错性：

不能因为程序被系统杀掉，或者发生了 ，  捕捉模块没有捕捉到导致部分时间点没有日志， 要保证程序整个生命周期内都有日志。

不能因为部分数据损坏就影响了整个日志文件，应该最小化数据损坏对日志文件的影响。


 的日志模块
前面提到了使用内存做中间  做日志可能会丢日志，直接写文件虽然不会丢日志但又会影响性能。所以亟需一个既有直接写内存的性能，又有直接写文件的可靠性的方案，也就是  在用的方案。

 是使用逻辑内存对磁盘文件进行映射，中间只是进行映射没有任何拷贝操作，避免了写文件的数据拷贝。操作内存就相当于在操作文件，避免了内核空间和用户空间的频繁切换。 

为了验证  是否真的有直接写内存的效率，我们写了一个简单的测试用例：把 的数据分别写入 大小的内存和 ，以及磁盘文件次并统计耗时 

从上图看出几乎和直接写内存一样的性能，而且  既不会丢日志，回写时机对我们来说又基本可控。  的回写时机：

内存不足
进程 
调用  或者 
不设置 _ 情况下 仅限

如果可以通过引入  既能保证高性能又能保证高可靠性，那么还存在的其他问题呢？比如集中压缩导致  短时间飙高，这个问题从上个方案就一直存在。而且使用  后又引入了新的问题，可以看一下使用  之后的流程：

前面已经介绍了，当程序被系统杀掉会把逻辑内存中的数据写入到  文件中，这时候数据是明文的，很容易被窥探，可能会有人觉得那在写进  之前先加密不就行了，但是这里又需要考虑，是压缩后再加密还是加密后再压缩的问题，很明显先压缩再加密效率比较高，这个顺序不能改变。而且在写入  之前先进行压缩，也会减少所占用的  的大小，进而减少  所占用内存的大小。所以最终只能考虑：是否能在写进逻辑内存之前就把日志先进行压缩，再进行加密，最后再写入到逻辑内存中。问题明确了：就是怎么对单行日志进行压缩，也就是其他模块每写一行日志日志模块就必须进行压缩。
压缩
比较通用的压缩方案是先进行短语式压缩， 短语式压缩过程中有两个滑动窗口，历史滑动窗口和前向缓存窗口，在前向缓存窗口中通过和历史滑动窗口中的内容进行匹配从而进行编码。 

比如这句绕口令：吃葡萄不吐葡萄皮，不吃葡萄倒吐葡萄皮。中间是有两块重复的内容“吃葡萄”和“吐葡萄皮”这两块。第二个“吃葡萄”的长度是  和上个“吃葡萄”的距离是  ，所以可以用  的值对来表示，同样的道理“吐葡萄皮”可以替换为  

这些没压缩的字符通过  编码其实也是  的整数，所以通过短语式压缩得到的结果实质上是一堆整数。对整数的压缩最常见的就是  编码。通用的压缩方案也是这么做的，当然中间还掺杂了游程编码，  的转换。但其实这个不是关注的重点。我们只需要明白整个压缩过程中，短语式压缩也就是  编码完成最大的压缩部分也是最重要的部分就行了，其他模块的压缩其实是对这个压缩结果的进一步压缩，进一步压缩的方式主要使用  压缩，所以这里就需要基于数字出现的频率进行统计编码，也就是说如果滑动窗口大小没上限的前提下，越多的数据集中压缩，压缩的效果就越好。日志模块使用这个方案时压缩效果可以达到 。
既然  编码已经完成了大部分压缩，那么是否可以弱化  压缩部分，比如使用静态  表，自定义字典等。于是我们测试了四种方案： 

这里可以看出来后两种方案明显优于前两种，压缩率都可以达到 。第三种是把整个  生命周期作为一个压缩单位进行压缩，如果这个压缩单位中有数据损坏，那么后面的日志也都解压不出来。但其实在短语式压缩过程中，滑动窗口并不是无限大的，一般是  ，所以只需要把一定大小作为一个压缩单位就可以了。这也就是第四个方案， 这样的话即使压缩单位中有部分数据损坏，因为是流式压缩，并不影响这个单位中损坏数据之前的日志的解压，只会影响这个单位中这个损坏数据之后的日志。
对于使用流式压缩后，我们采用了三台安卓手机进行了耗时统计，和之前使用通用压缩的的日志方案进行了对比耗时为单行日志的平均耗时 

通过横向对比，可以看出虽然使用流式压缩的耗时是使用多条日志同时压缩的  倍左右，但是这个耗时本身就很小，是微秒级别的，几乎不会对性能造成影响。最关键的，多条日志同时压缩会导致  曲线短时间内极速升高，进而可能会导致程序卡顿，而流式压缩是把时间分散在整个生命周期内， 的曲线更平滑，相当于把压缩过程中使用的资源均分在整个  生命周期内。
 方案总结
该方案的简单描述：

使用流式方式对单行日志进行压缩，压缩加密后写进作为  中间 的  中

虽然使用流式压缩并没有达到最理想的压缩率，但和  一起使用能兼顾流畅性 完整性 容错性 的前提下，的压缩率也是能接受的。使用这个方案，除非  损坏或者磁盘没有可用空间，基本可以保证不会丢失任何一行日志。
在实现过程中，各个平台上也踩了不少坑，比如：

 锁屏后，因为文件保护属性的问题导致文件不可写，需要把文件属性改为 。

 使用  创建的  是稀疏文件，当设备上无可用存储时，使用  过程中可能会抛出  信号。通过对新建的  文件的内容全写来解决。

……


日志模块还存在一些其他策略：

每次启动的时候会清理日志，防止占用太多用户磁盘空间

为了防止  被拔掉导致写不了日志，支持设置缓存目录，当  插上时会把缓存目录里的日志写入到  上

……


在使用的接口方面支持多种匹配方式：

类型安全检测方式：  。例如：“ ” “” 
序号匹配的方式：  。例如：”  ” “” 
智能匹配的懒人模式：_  。例如：”_ _” “” 

总结
对于终端设备来说，打日志并不只是把日志信息写到文件里这么简单。除了前文提到的流畅性、完整性、容错性，还有一个最重要的是安全性。基于不怕被破解，但也不能任何人都能破解的原则，对日志的规范比加密算法的选择更为重要，所以本文并没有讨论这一点。
从前面的几个方案中可以看出，一个优秀的日志模块必须做到：

不能把用户的隐私信息打印到日志文件里，不能把日志明文打到日志文件里。

不能影响程序的性能。最基本的保证是使用了日志不会导致程序卡顿。

不能因为程序被系统杀掉，或者发生了 ， 捕捉模块没有捕捉到导致部分时间点没有日志， 要保证程序整个生命周期内都有日志。

不能因为部分数据损坏就影响了整个日志文件，应该最小化数据损坏对日志文件的影响。


上面这几点也即安全性、流畅性、完整性、容错性， 它们之间存在着矛盾关系：

如果直接写文件会卡顿，但如果使用内存做中间  又可能丢日志

如果不对日志内容进行压缩会导致  卡顿影响性能，但如果压缩，部分损坏可能会影响整个压缩块，而且为了增大压缩率集中压缩又可能导致  短时间飙高。


 的日志模块  就是在兼顾这四点的前提下做到：高性能高压缩率、不丢失任何一行日志、避免系统卡顿和  波峰。

本文来源于： 微信公众号接个性化资讯推荐 算法篇  上 
深度学习篇
日益红火的深度学习也在不断影响着资讯推荐，在这一节就简要下最近爆出来的几篇相关文章，大致可以分为两类：技术。此时深度学习主要用来学习的也就是通常意义上的的表示形式，每个可以表示为一个向量，向量之间的相似度可以用来改善推荐。这里深度学习的重点是用来学习合理的表示；使用深度学习直接对预测目标建模。此时深度学习的重点放在最终要解决的问题上。初看起来似乎第一种形式不如后者来得直接，但第一种形式在实际应用中通常能起到简化架构、快速解决问题的功效，还能作为一个基础特征来改进线上其他环节的效果。下面我们分别选择一两篇有代表性的文章来进行科普。
 的新闻推荐团队利用 的技术来学习新闻的表示。大家可能比较熟悉，它通过最小化变换前后信号的误差来求解，而则是对输入随机加入一些噪声，再对其进行变换输出，最终是通过最小化加噪声后的输出和原始不加噪声输入之间的差异来求解。应用中不少结果表明，这种方法比传统的学习到的效果更好。具体示意图如下。
 
但这种方法是经典的无监督学习套路，直观来看和应用场景中要求相似新闻的也要尽量相似没有直接的关联这里单单从优化目标来看，实际上由于语料的天然性质或者人们用语习惯，这个相似性的要求已经间接隐含在优化目标里了。而新闻有很多人们编辑好或者其他模型产生好的类别信息，假如、新闻都是体育类，是教育类的，通常意义上来讲Ａ和Ｂ相似度是比Ａ和Ｃ要高的。这是在训练深度学习时已知的先验知识，如果能把它加入到优化目标中，学习到的就能更好的表达相似度信息，于是有了下面的方法。
 
如图所示，通过在原始的优化目标中加入“同类新闻相似度大于不同类新闻相似度”这一项，我们就可以把先验知识作为约束加到模型中。 的人实验证明了如此得到的确实能更好的表示相似度信息。
微软研究院也提出过一种很有趣的得到表示的方法。作者利用用户的搜索日志，同一个下，搜索引擎往往返回篇，用户一般会点击相关的，不太相关的一般不会点，利用这个反馈信息也可以训练神经网络。具体示意图如下，这里的优化目标就是要求点击的一个_的预测得分_|要高于不点击的，论文基于这个信息构造除了损失函数，也就得到了最终机器学习可以优化的一个目标。
 
目前只介绍了如何得到的，实际推荐中要用到的一般是对一个的兴趣程度，只有在得到 后才能通过算和的相似度来度量这个兴趣程度。那么如何得到的呢？了解的同学可能能想到，既然我们已经得到了新闻的的表示，想办法把他们传到侧不就行了么？
确实如此，一种简单的做法是把用户近期点过的所有新闻的取个平均或者加权平均就可以得到的了。但这种模式还有优化的空间：用户点击是一个序列，每次点击不是独立的，如果把序列考虑进去就有可能得到更好的表示；点击行为和曝光是有联系的，点击率更能体现用户对某个或某类新闻的感兴趣程度。鉴于这两点，我们很容易想到通过深度学习里经典的解决序列学习的方法， 的人使用的就是一个经典的特例：。训练时将用户的曝光和点击行为作为一个序列，每次有点或不点这样的反馈，就很容易套用训练得到的，具体做法如下图所示。

微软还发表了《            》，文章提出了一种有趣的得到 的方法，这是一个典型的 的方法。现在很多公司都不仅仅只有一个产品，而是有多个产品线。比如微软可能就有搜索、新闻、、等产品，如果将用户在这些产品上的行为反馈统一在一起训练一个深度学习网络，就能很好的解决单个产品上用户冷启动、稀疏等问题。具体网络结构如下，总体的优化目标是保证在所有视图上和正向反馈的的相似度大于随机选取的无反馈或者负向反馈的相似度，并且越大越好。用数学公式形式化出来是 ，对应的神经网络结构如下图所示。

今日头条
作为国内当红的个性化推荐产品，今日头条技术经历了三个阶段：
    早期以非个性化推荐为主，重点解决热文推荐和新文推荐，这个阶段对于用户和新闻的刻画粒度也比较粗，并没有大规模运用推荐算法。
    中期以个性化推荐算法为主，主要基于协同过滤和内容推荐两种方式。协同过滤技术和前面介绍的大同小异，不再赘述。基于内容推荐的方式，则借助传统的、和对新闻有了更多的刻画，然后利用用户的正反馈如点击，阅读时长、分享、收藏、评论等和负反馈如不感兴趣等建立用户和新闻标签之间的联系，从而来进行统计建模。
    当前以大规模实时机器学习算法为主，用到的特征达千亿级别，能做到分钟级更新模型。 架构分为两层图来自头条架构师的分享：检索层，有多个检索分支，拉出用户感兴趣的新闻候选；打分层，基于用户特征、新闻特征、环境特征三大类特征使用实时学习进行建模打分。值得一提的是，实际排序时候并不完全按照模型打分排序，会有一些特定的业务逻辑综合在一起进行最终排序并吐给用户。
 
任何一种算法都有其局限性，业务要结合自己产品的特点，选择合适的算法解决特定的小问题，融合各种算法解决一个大问题。另外要设计合理的实验和放量机制，以在有限的影响内，最大程度地利用真实的用户行为来修正算法判定的结果。比如，可以先放的流量来试探用户对新闻的兴趣，并用模型进行建模；再用的流量来修正模型的效果，进行优胜劣汰；最后将真正置信的推荐结果推送到全量用户。
个性化资讯推荐的未来
个资讯消费是人的基本需求，个性化资讯推荐让我们能更好地消费资讯，享受生活的快乐。个性化资讯推荐还有很长的路要走，目前面世的产品仅仅迈出了第一步，看起来有模有样，实际上问题多多。例如被吐槽最多的一个问题：用户一天看了很多，但睡前闭目一想，记住的很少，对自己有用的更是凤毛麟角。这只是一个表象，背后其实暴露了很多现有推荐的问题。
要做好一个资讯推荐产品，不单单精准推荐技术需要演进，呈现形式、交互方式、产品形态、内容生态等等都需要去探索，最最重要的要想清楚以下几个本质问题：
    人为什么需要阅读？    人为什么会消费资讯？    用户为什么需要到你这阅读资讯？    好的阅读体验到底是什么，如何量化？    产品推荐的基因是什么？
加油吧，个性化资讯推荐！
参考文献：

桑赓陶，《 把握市场、产品和技术的动态匹配——韩国三星电子公司产品开发战略演变的基本原则及其对中国企业的启示》
         
       
  
         
       
        
          
              
____

 

如何看待头条的成功？
网上很多人都从各种角度有过分析，但大都是通过现象来解释现象，抓住本质的不多。个人比较喜欢用“市场、产品和技术”动态匹配理论来看这个问题：对于一个特定的企业来说，它在特定时点上所找到的、要去满足的市场是特定的；特定的市场要求企业用特定的产品去满足，而特定产品则是特定技术的某种物化。企业只有掌握相应的特定技术或者有能力在一定的时间内把这种特定技术开发出来并把它物化成特定产品，企业选择的特定市场才有可能得到满足。
用动态匹配理论来看头条，可以看到它的成功是如此之合理。随着资讯市场的成熟和发展，人们需要一个在碎片时间消费有趣资讯的产品，来解决用户的需求。这里的有趣因人而异，就需要用个性化的推荐技术去满足。如此看来，头条在合适的时机，用合适的技术做了合适的产品，造就了自己的成功。前言
又到了周末，坐在电脑面前，看着数码宝贝 皮卡丘  ⊙⊙ ，然后吃了一个柠檬   ，多么美好。
然后我就收到了一大堆群消息，微信消息，各个地方都在说电脑中毒了或者病毒通知，这里盗用一张群友的图片李郑
就像这样的
还有这样的通知
从通知里你看得到一些关于这个病毒的基本信息
下面是全球中招情况看着还是蛮壮观的
在中国东部已经泛滥，想想信息在国内的传播速度，应该再过不久就到我这里来了，所以提前做打算。
中毒是什么样子？诺，就是上面的和下面的样子
预防
如何预防它， 巧了， 国内各大网络安全组织都开始加班加点了，
微软已经对该病毒有了处理，若你使用的是的话只需要打开  即可。
若是其他系统的话，微软的良心还在。微软决定对已经停止支持的   和   发布特别版补丁 
所以大家也不用太怕这东西。
然而鄙人也给出一个预防的这是代码，你可以复制到你的记事本里，然后把文件拓展名改为运行即可
此代码小编实验过，完美免疫病毒，希望没有中毒的小伙伴们都运行一下，以防万一
    
 


__\\\ \\   \
=   

__\\\ \\   \
=   

__\\\ \\   \
=   

__\\\ \\   \
=   

__\\\ \\   \
=   

__\\\ \\   \
=   

__\\\ \\   \
=   
有这么东西保护，司机可以继续开车啦。
杀！杀！杀！
要是中招了怎么办？？？？
巧了，国内大神已经有了一个尝试性解决办法
关于高校比特币病毒 社工破解的可能性尝试：
打开自己的那个勒索软件界面，点击 复制黑客的比特币地址把粘贴到 区块链查询器在区块链查询器中找到黑客收款地址的交易记录，然后随意选择一个交易哈希值把 复制粘贴给 勒索软件界面按钮 等黑客看到后 你再点击勒索软件上的 再点击 解密文件即可。
这是实现这个方法的代码写的
    

      

  


 
 
 
 
 ==
    =

    =
=_
_=    
==
_=    _
请将在列出的比特币交易中选择一串，复制粘贴到勒索软件的 等待黑客验证后，点击 再点击即可恢复\        ，                \
   _
       
        
        =方法来自：


向作者致敬，这是作者的地址
原此处方法小编已经实践过，方法无效，小伙伴们不要试了。
另外国内已经有了一些解决该病毒的方法。详情见 勒索病毒用户处置指南
具体是说该病毒把原文件删掉了，然后通过文件恢复找到的文件，小编在此认为 这个方法太复杂，且无法找回，找回的文件文件名也无法恢复。在此小编正继续深入研究，希望可以早日给大家提供更好的解决方法。
如果这些方法没有怎么办？莫慌，还有最后一招终极解决办法重装系统，建议迫不得已再用自从百度推荐全站  以来，一直就想让博客跟上这个节奏。可惜，国内所有的免费都不支持。所以要开启势必要暴露网站真实，按照博客现在被攻击的节奏，估计一暴露就没有了安生的日子！
偶尔的心血来潮，百度了一把支持的，打开了腾讯云的一个：

  支持  吗？
 目前处在邀请测试阶段，暂时还不提供申请，还请谅解。我们正在完善此特性，一旦产品成熟，我们会第一时间公布，敬请期待。

呵呵，邀请测试是么？既然是自家的产品，那还是毛遂自荐吧！
于是找到了公司腾讯云的产品经理，说了我这个想法，于是有幸就用上了国内这个为数不多的特权。
虽然，走的是后门，但是测试责任还是得尽好才是，因此也和产品经理没少交流。博客全面化也遇到了非常多的问题，下面就让我来细细道来。

一、回源
腾讯云默认是回源，这样就有一个问题：因为我们要全站，不想有， 那么势必需要将的请求到上。这时腾讯云通过过来请求源站，那么请求到的就是了！这也是前些天博客时不时来一个的原因了。大部分请求对的支持不是很完善。。。

刚开始还无法自行设置回源模式，还好我用上不久，就发布了新版本，支持回源选择。妥妥的选择了回源。然后静态文件我没有做强制，因此静态文件我选择回源，略微优化一下负载。
二、微信公众号
如上设置之后，又发现了一个新问题，微信粉丝跟我反馈，公众号不能自动回复了！
检查了下，原来是因为公众号只支持模式的请求，因此微信公众号的请求得到的也是结果，导致自动回复失败！
看来全部跳到也是行不通的。测试了半天，最后用如下规则搞定：
{
    
   _ 
    
     {
        如果是请求就交给 ，从而支持微信公众号自动回复
          _ =   
        {
                 
              
        }
        如果是请求，则到站点
          _ =  
        {
                 
        }
        其他任何请求，都到站点，这是补刀
           
        }
        动态请求交给
          \|
        {
             _  =
             _  
             _ 
              
        }
}
三、被缓存
虽然对的缓存支持不好，但是不代表不能缓存！因此，腾讯云偶尔会缓存网站的结果，导致强制跳转失效！结果就是访问页面也不会自动跳转了。
而现在腾讯云还不支持在节点直接设置强制跳转，实在没办法，在网页的里面加入如下代码搞定这个问题：
 如果检测到是页面，则自动跳转到对应的页面 
 =
  =  { 
         = 
}

四各种跳转
之后，发现以前的文章外链自动跳转出问题了，把文章中的内链也当成了外链！而且评论中我自己的链接也变成了跳转。
看了下，原来是之前的函数并没有兼容，于是改了下，搞定。
文章外链跳转支持
___
 _{
    __=
    {
      {
            ==  _===  _\||||||  _|||||\\{
        =_=\\ =\=\ 
        }
    }
    }
     
}

评论者链接跳转支持
 __ =  {
        = ___ _ 
     = __ _ 
         ||  ==   {
     
    }  {
         _|\\\ {
              == =  =_ =
        }  {
              = =_ =
        }
    }    
}
五外部资源
众所周知，要全站，那么所有页面都不能存在非资源，否则浏览器就会拦截这些内容，并显示惊叹号！于是大把的问题迎面而来：
百度分享不支持
这个问题最终我用最苦逼的方法解决了，那就是将百度分享代码中的，已经会请求到的其他资源全部都下载到本地具体会请求到哪些资源，我都是在浏览器开发者模式中获取的，并修改其中的链接指向到本地，搞定了百度分享的大部分功能。
比如，分享到空间、微博，分享到微信显示二维码都搞定了，唯独那个“更多”选择恕我无能为力：

最后，我将修改好的文件上传到支持的七牛，所以有需要的人可以将百度的分享链接修改如下，即可使用：
___={{{}}{}}||=== 
说白了，就是将之前的百度分享代码中的修改为我提供的即可：
代码地址：
如此解决之后，浏览器就是绿色了，不会有黄色的惊叹号，不过如果你点击分享，依然会请求到非的百度分享，这时候会出现黄色惊叹号，恕我无能为力了，但不影响使用！
新浪微博关注按钮
好吧，这个问题我暂时没时间处理，直接屏蔽了这个功能，估计参考上面的方法可以解决。
六、整理总结
全站已有天，总体还是不错的！不过，腾讯云的功能目前还在邀请测试阶段，所以想尝鲜的小伙伴就只能耐心等待正式公测了。相信这个国内唯一支持的会大受欢迎的！
不知不觉已经写了这么长了！暂时就整理这么多，后续有新的问题再更新到这篇文章当中，敬请期待！

相关推荐 常见问题腾讯云实现全站  方案
是一套用于开发客户端界面、逻辑以及功能的开发组件。布局文件及逻辑文件可以运行时执行，主要用以解决客户端界面、逻辑快速更新以及快速开发的诉求。
的语法规则与原生类似，而写逻辑的部分除语言语法规则外，可以直接使用我们提供的 以及原生，因此熟悉客户端开发的开发者上手成本会非常小。
除了解决动态更新问题外，希望开发者能够以更快的速度开发产品功能需求，因此我们在语法和开发方式上做了一些改变，期望开发者能够实现：小功能极速开发、大功能极速上线。希望为开发者带来更小的安装包增量以及更加简单、易于维护和修改的组件库，的代码组件约组件 。
组件特性：
运行时加载，布局、逻辑可动态刷新无需编译，所见即所得，开发效率更高极小的安装包增量开发者低上手成本与开发体验相同
轻应用开发组件 正式开源
地址 
请给  一个 ！欢迎提出你的  和 前言
最近在进行性能优化设置。在修改配置文件之前需要备份原有的配置文件夹，这是网站架设的好习惯。以下的配置调优均是在 的环境下进行的。
 相关查看命令了解
查看当前安装模块多路处理器
   
查看进程数即各个模式下能够处理的并发请求数
    |   |  
得到的结果数字就是表示可以同时并发的进程数据，一个父进程，个子进程。默认是开启个子进程
查看的并发请求数及其连接状态
    |   { }  {     }
    

        ：无连接是活动的或正在进行
        ：服务器在等待进入呼叫
        _：一个连接请求已经到达，等待确认
        _：应用已经开始，打开一个连接
        ：正常数据传输状态
        _：应用说它已经完成
        _：另一边已同意释放
        _：等待所有分组死掉
        ：两边同时尝试关闭
        _：另一边已初始化一个释放
        _：等待所有分组死掉
查看请求服务的 按照连接数排序。
   | | { } |  { } | |  | 
查看详细链接情况
   
检测某一台服务器的端口是否开启状态
        
验证配置是否正确
   
模块启用
模块介绍： 各个模块功能 基本模块默认包含，必须明确禁用；扩展实验模块默认不包含，必须明确启用。
        模块名称    状态    简要描述
        _  基于媒体类型或请求方法，为执行脚本而提供
        _  提供从文件系统的不同部分到文档树的映射和重定向
        _  发送自己包含头内容的文件
        __  使用基本认证
        __  在未正确配置认证模块的情况下简单拒绝一切认证信息
        __  使用纯文本文件为认证提供支持
        __  在未正确配置授权支持模块的情况下简单拒绝一切授权请求
        __  使用纯文本文件为组提供授权支持
        __  供基于主机名、地址、请求特征的访问控制
        __  基于每个用户提供授权支持
        _  自动对目录中的内容生成列表，类似于或命令
        _  在非线程型上提供对脚本执行的支持
        _  在线程型上用一个外部守护进程执行脚本
        _  指定目录索引文件以及为目录提供尾斜杠重定向
        _  允许修改或清除传送到脚本和页面的环境变量
        _  根据上下文实际情况对输出过滤器进行动态配置
        _  处理服务器端图像映射
        _  实现服务端包含文档处理
        _  仅限于在平台上实现扩展
        __  允许记录日志和定制日志文件格式
        _  根据文件扩展名决定应答的行为处理器过滤器和内容类型语言字符集编码
        _  提供内容协商支持
        __  仅限于在平台上实现加密支持
        _  根据客户端请求头字段设置环境变量
        _  生成描述服务器状态的页面
        _  允许用户从自己的主目录中提供页面使用
        __  使用摘要认证更安全，但是只有最新的浏览器才支持
        __  基于实际认证支持者创建扩展的认证支持者，并为它起一个别名以便于引用
        __  提供匿名用户认证支持
        __  使用数据库为认证提供支持
        __  使用数据库为认证提供支持
        __  允许使用一个目录存储用户名和密码数据库来执行基本认证和授权
        __  使用数据库文件为组提供授权支持
        __  基于文件的所有者进行授权
        _  基于键的内容动态缓冲内存或磁盘
        __  允许使用 元文件，从而可以在发送文件时对头进行修改
        __  允许对页面进行字符集转换
        _  允许提供协议支持
        __  为_访问服务器上的文件系统提供支持
        __  为_锁定服务器上的文件提供支持
        _  管理数据库连接，为需要数据库功能的模块提供支持
        _  压缩发送给客户端的内容
        __  基于磁盘的缓冲管理器
        _  将所有操作转储到错误日志中
        _  一个很简单的协议演示模块
        _  一个很简单的模块演示模块
        _  允许通过配置文件控制的和头内容
        __  使用外部程序作为过滤器
        __  提供文件描述符缓存支持，从而提高性能
        _  允许通过配置文件控制任意的请求和应答头信息
        _  实现规定的查找
        _  生成配置情况的页面
        _  为其它模块提供连接池和结果缓冲服务
        __  实现对比日志，即在请求被处理之前和处理完成之后进行两次记录
        _  对每个请求的输入输出字节数以及头进行日志记录
        __  基于内存的缓冲管理器
        __  通过读取部分文件内容自动猜测文件的类型
        _  提供的代理网关功能支持
        __  _的扩展，提供  支持
        __  _的扩展，提供负载平衡支持
        __  _的扩展，提供对处理 方法的支持
        __  _的支持模块
        __  _的支持模块
        _  一个基于一定规则的实时重写请求的引擎
        _  允许运行时加载模块
        _  自动纠正中的拼写错误
        _  使用安全套接字层和传输层安全协议实现高强度加密传输
        _  使用与调用服务器的用户不同的用户身份来运行和程序
        __  为每个请求生成唯一的标识以便跟踪
        _  使用跟踪用户会发送很多，以记录用户的点击流
        _  提供基于版本的配置段支持
        __  提供大批量虚拟主机的动态配置支持
性能调优，模块启用关闭
    启用压缩
         _ _
    启用重写
         _ _  
    启用默认扩展，支持在这里进行修改主要配置
           
    提供文件描述符缓存支持，从而提高性能
         __ __
    启用基于键的内容动态缓冲内存或磁盘  
         _ _  
    启用基于磁盘的缓冲管理器
         __ __  
    基于内存的缓冲管理器
         __ __ 
    屏蔽所有不必要的模块
         __ __  
         __ __  
         __ __  
         __ __  
         __ __  
         __ __  
         __ __  
         __ __  
         __ __  
         __ __  
         __ __  
         __ __  
         __ __  
         __ __  
         __ __  
         __ __  
         __ __ 
    已经过时屏蔽
         _ _
    用于定义缺省文档、等
         _ _
    用于定义记录文件格式
         __ __
    定义文件类型的关联
         _ _
    减少左右的重复请求
         _ _  
    允许修改或清除传递到或页面的环境变量
         _ _
    根据客户端请求头字段设置环境变量，如果不需要则屏蔽掉
         _ _
    生成描述服务器状态的页面
         _ _
    别名
         _ _
    地址重写模块
         _ _
    _ 负载均衡调度模块
            _ _ 
    过滤模块，使用缓存必须启用过滤模块
         _ _ 
    关闭服务器版本信息
         _ _
    自动修正用户输入的错误 
         _ _
 扩展配置文件说明
            自动索引配置
                  配置
              的默认配置
                 _ _模块配置
            多语言配置支持
               在网站上提供手册
                  多路处理模块配置文件
   实现多语言的错误信息
                  配置
              配置用户目录
               虚拟主机配置
性能指标计算方法
提供下面这个公式，以供大家在平时或者日常需要进行的性能测试中作为一个参考。
计算平均的并发用户数： = 
是平均的并发用户数； 是   的数量； 是   的平均长度；指考察的时间段长度。  
并发用户数峰值：’ ≈ 根号
’指并发用户数的峰值，就是公式中得到的平均的并发用户数。该公式的得出是假设用户的  产生符合泊松分布而估算得到的。
自带的压力测试工具
 最常用的语法格式是这样的
        
     表示最多进行次测试。也就是下载文件次。
     客户端并发连接个数。
    启用 功能。默认不启用功能。
必须安装在客户端上，并且客户端机器配置性能要高些。
比如我们要对下载次进行测试，并发访问为个，启用 功能，则访问指令为
        
的压力测试工具
 是开发的基于的压力测试工具。 
多路处理器
目前版本已经 纳入正式版，不再是实验状态。安装时，已经自动将 一起安装进去，通过 可以查看到模块。由此可以看到， 已经成为默认的工作模式。
启用
  

配置 参数
   
       
                 

       版本叫 =     
                  

       
                

       
             

        =   
                 

       
             

        =     
            

    版本叫                
       
  

    、：初始数量的服务器进程开始，默认为个
    、：最小数量的工作线程保存备用，默认是个线程
    、：最大数量的工作线程保存备用，默认是线程
    、：固定数量的工作线程在每个服务器进程，默认是个
    、：最大数量的工作线程，默认是
    、：最大连接数的一个服务器进程服务，默认为，没有上限限制，但是为了避免内存异常，影响稳定性，需要设置一个数值进行限制在修改配置后需要停止再启动，  不能通过生效，而是先   然后再  才可以生效。
    、：是活动子进程数量的硬限制，它必须大于或等于除以的值。最大，默认是。只有在你需要将和设置成需要超过默认值个子进程的时候才需要使用这个指令。不要将该指令的值设置的比和需要的子进程数量高。使用这个指令时要特别当心。如果将设置成一个高出实际需要许多的值，将会有过多的共享内存被分配。如果将和设置成超过系统的处理能力，可能无法启动，或者系统将变得不稳定。  最大只能设置到。如果你需要设置其为更高，需要在前面添加其中不能少于的数值。该设置方法适用于 系列。
    、：是所有服务线程总数的硬限制，它必须大于或等于指令。使用这个指令时要特别当心。如果将设置成一个高出实际需要很多的值，将会有过多的共享内存被分配。如果将和设置成超过系统的处理能力，可能无法启动，或者系统将变得不稳定。该指令的值应当和可能达到的最大值保持一致。
计算的相关参数
：计算服务器进程的平均内存
    |   |  {   }

：计算正在通讯传输过程中的进程的平均内存，最好在一天之内不同的时间段内运行以下代码
    |   |  { } |  { =     }  {   }

通过上面两个指令计算出平均进程所使用的内存大小 ，再通过以下公式计算
 =               
      、   
      、   
      、  
      、 == 
      、            
  与 区别
可以支持比更高的并发数，主要安装在类上的工作模式。 是 的变种，但是具有比 更好的并发性能。在 模式下，是不被支持的，他会被切换到 下处理。 在版本时才被从实验状态转化成标准应用。
 缓存设置
涉及的缓存模块有_、__、__、__。如果要使用缓存必须启用这四个缓存模块。同时修改缓存设置后，必须重启，刷新缓存，否则用户访问页面不是最新页面。
_、__、__、__关系
 缓存分为硬盘缓存和内存缓存
 __ __ 都依赖于_
 __是结合_使用，可以用于指定几个频繁访问，但是变化不大的文件
配置硬盘缓存和内存缓存的缓存配置
 _  
   设置缓存过期时间，默认一小时  
      
   设置缓存最大失效时间，默认最大一天  
            __  
   启用缓存，并设定硬盘缓存目录路径  
       
   设定访问用户的缓存路径，需要进行授权配置，如设置为  
      
   缓存目录深度  
      
   缓存目录名称字符串长度  
      
   缓存文件最大值  
       
   缓存文件最小值   
       __  

   缓存路径  
       

   缓存对象最大个数  
      

   单个缓存对象最大大小  
      

   单个缓存对象最小大小   
      

   在缓冲区最多能够放置多少的将要被缓存对象的尺寸  
      

   清除缓存所使用的算法，默认是 ，还有一个是  
      

   缓存数据最多能使用的内存  
      
文件缓存的应用
、缓存文件：如果你的网站有几个文件的访问非常频繁而又不经常变动，则可以在  启动的时候就把它们的内容缓存到内存中当然要启用内存缓存系统，使用的是 __ 模块，有多个文件可以用空格格开，具体如下：
 __  
        
  

、缓存句柄：
 __  
     

压缩配置
通过_模块实现页面压缩，要想进行页面压缩必须启用以下两个模块
 _ _  
 _ _
页面压缩模块配置
 _  
设定压缩率，压缩率  是建议值，不能太高，消耗过多的内存，影响服务器性能  
   

    
    
    
    
    
    
    
    
    
  _  
    
    
    
    
    
    

插入过滤器  
   

排除不需要压缩的文件  
 _ \|||||    
 _ \||  ’  
 _ \    
 _ \    
 _ \    
 _ \    
 _ \    
 _ \    


在 中和服务器的一次连接只能发出一次请求，而参数支持 版本的一次连接，多次传输功能，这样就可以在一次连接中发出多个请求。从而避免对于同一个客户端需要打开不同的连接。很多请求通过同一个 连接来发送，可以节约网络和系统资源。
启用场景
    如果有较多的图片访问，则需要开启长链接
    如果内存较少，大量的动态页面请求，文件访问，则关闭长链接，节省内存，提高访问的稳定性
    如果内存充足，较好，服务器性能优越，则是否开启长链接对访问性能都不会产生影响
配置
    在的配置文件中，设置：
    、   默认为修改为
    、   设置为状态
    、 默认为如果值设置过高，由于每个进程都要保持一定时间对应该用户，而无法应付其他用户请求访问，从而导致服务器性能下降。
    、   如果设置为表示无限制，建议最好设置一个值  
    把设置的尽量大，可以在一次连接中进行更多的请求。但在我们的测试中还发现，把 设置成，则评测的客户端容易出现“  ”的错误，所以具体数值还要根据自己的情形来设置。
问题集锦
、加载
 __ __  
               `
、配置信息后面不能跟随注释，注释必须另起一行  
            
、关键字错误  应该是
  
               
、启用
 _ _  
               
、注释不能跟在配置参数后面，否则会导致配置解析失败
       
            

相关推荐
云服务器双向认证配置指南腾讯云下从迁移到过程作者：龙井
本文根据《龙门阵之门外汉》直播内容精简整理而成。
直播  分享链接  密码 

如果你是的门外汉，不管是真汉子还是女汉子，希望这篇文章可以帮助你理解，掌握的主要知识点和实践。
龙门阵是四川话里聊天、唠嗑的意思，一群人坐在一起，喝着茶，天南海北的聊天。龙门阵会持续跟大家聊更多的话题，请大家多多关注。今天我们来聊门外汉须知，对于外行人或者站在门口的同学，你们需要了解的知识尽在其中。

先来一段闲话，最近我发现软件开发和去餐厅吃饭非常像，只是餐厅需要交付的不是软件，而是一桌菜，包含了前菜、主菜、甜点等等。拿去年很火的一部剧《好先生》来举个栗子：

吃饭的人就是用户；
点菜的服务员就是业务人员，负责收集用户需求进行分析；
主厨就是架构师，负责设计；
其他厨师就是研发，负责实现设计和用户需求；
试菜员就是测试，负责验证菜品是否符合标准要求；
上菜的服务员就是运维，负责将菜交付给最终用户，往往菜做的不好，做的慢，挨骂的总是上菜的人，因为运维是交付的最后环节，里用户最近，前序环节的问题都会累积到运维侧爆发。

餐厅做的好的地方在于：一道菜一道菜的上，要是等上一小时，一次性给你端一桌菜上来，而且是连桌子一起端，大家想想你的感受是啥？

好了，闲话完毕，我们今天重点聊三个话题：

我们正在经历的时代；
是什么？如何理解？
门外汉须知；

时代

为什么这么说？乐神 张乐老师分享过很多次，我们所面临的大环境就是易变的、不确定的、复杂的、模糊的。用户的需求很多时候是模糊和不确定的，在交付到用户手上之前，我们的软件和服务都存在着较大的风险。

同时我们这个时代正在经历最激烈的技术革命，开发流程、应用架构、部署和打包的环境、应用基础设施都在发生巨大的变化。：运维大神 赵班长说这张图让他睡不着觉，你呢？

尤其是技术架构，随着业务的发展，为了满足业务的要求和组织的复杂性，技术架构也在复杂化，面对右侧的架构，传统的开发方式、架构、基础设施都捉襟见肘。

下边这张图是年年度状态报告高效运维和时代社区联合翻译中文版 中的数据：
报告中将组织分为：高效能组织、中等效能组织、低效能组织，如下数据就是高低效能组织之间的对比：

部署频率就是每天部署上线的次数，体现的是生产力，高效能组织高出倍；
交付时间是指从代码提交到部署上线的时间，越短说明工程交付能力越强，高效能组织少出倍；
变更失败率是指每次部署失败的比率，体现的是质量，高效能组织低出倍；
故障恢复时间是指故障后的修复时间，也就是常说的，生产环境的每一分每一秒的宕机都是直接经济损失，高效能组织要快倍；


是什么，如何理解？
说完背景，我们进入的主题，为什么会存在，的冲突来自哪儿？开发、测试团队和运维团队在思维、目标、、技能、工具各个方面都是不一样的。

因为冲突的存在，之父作为工程师倍感沮丧，他在寻求使用敏捷的方式解决运维的问题，机缘巧合之下，举办了第一届活动，并在上自发形成了运动，大家都在基于实践经验去解决开发与运维的协作问题。

在维基百科上概念是大家比较有共识的理解，很多人尝试诠释是什么？但是都不及这个概念精简。

我们一开始面对时就像盲人摸象一样，认为自动化就是、将看板运用到运维就是、需要开发去做运维、运维需要去做开发，这些理解都是片面或错误的。

我在学习的一开始认为，就是要解决最后一公里的交付问题，也就是从代码提交到发布上线的过程。

后来我从敏捷的思路去理解，可以说是敏捷的延伸，延伸到技术运营领域。每一次迭代都是开发、测试、运维协作完成，每个迭代都会有一次或多次发布上线。

后来，我参加高效运维社区的 认证培训，对的知识体系有了更体系化的了解。

精益管理和：是的基础理论支撑，包括持续改进、准时制、消除浪费、单件流等等。持续集成实践和的安灯拉绳机制很类似；敏捷管理：主要是敏捷开发的理论和实践；持续交付：是最重要的工程实践，自动化的核心内容；服务管理：主要是讲究轻量级


是集大成者，它并不制造概念，它是讲很多理念和实践进行整合，打通端到端的过程，目标就一个服务业务，更快更好的交付业务。

门外汉须知
基于对的理解，我整理出了能力模型，包括如下五方面，后续的核心概念和实践参照这个思路给大家分享

敏捷研发
谈敏捷就一定会提敏捷宣言，我在学习敏捷的时候，老师说敏捷宣言最重要的一句话就是：我们一直在实践中探寻更好的软件开发方法。就是在探寻过程中逐渐演化出来，适合这个时代的软件开发方法。

下图是几种常见的敏捷开发方法：、和看板的关系

是最流行的敏捷开发方法，如下图是台湾精益和敏捷大师 李智桦老师的一张图看尽，大家可以详细研究，的重点内容：三种角色、四种会议、三种产物。

极限编程讲究的是工程与技术实践，尤其是对反馈的要求很高，持续集成、结对编程、重构、测试驱动开发等实践都来自，这张图代表了不同时间的反馈周期。

看板是在微软推行的过程中研究出来的一套方法，原本目的是为了更好的推行。李智桦老师有一篇文章专门说明了和的关系，应该结合使用。

如下这张图也是李智桦老师针对看板的六条规则，大家可以参考，对而言，识别出团队的工作流至关重要。 认证培训里有一个《凤凰项目沙盘模拟实战》需要团队使用来改善交付节奏和控制产能。

持续交付
持续交付包括：配置管理、持续集成、自动化测试、代码质量、部署流水线等方面，大家可以参考图片和直播内容进行更详细的了解。后续龙门阵会更深入的为大家分享持续交付的内容。

持续集成的基础是配置管理，至少需要使用版本控制系统将代码和配置管理起来。然后使用类似这样的工具标准化代码目录结构和依赖管理，之后才能实现自动化构建，进一步才能做到持续集成

测试三角形是比较经典的分析自动化测试的成本和效果的图，由于自动化的单元测试成本太高，一般和写生产代码的成本比例是比，甚至更多，所以发展出了叫自动化测试的橄榄球模型，和测试少做，重点做接口级测试，目前这种做法也是大多数团队在实践的。

在配置管理、自动化构建、自动化测试的基础上，我们的持续集成才能使完成的，如下这是一个持续集成的测试，你可以问自己三个问题来判断你们的持续集成做的如何？

每个开发是否每天至少都向主干提交一次代码？
每次提交是否都触发自动化构建和测试？
如果构建和测试失败，是否可以在十分钟内修复？

根据我的经验，大部分团队都通过不了这三个问题的测试，但并不是说一定要这样，我在做的过程中有个原则：简单粗暴最有效！先解决问题，再完善。

持续交付的核心是要打造一条从代码提交的部署生产的流水线，就像车间里的流水线一样，更加高效和标准。

高效运维社区之前做过一个部署流水线的，大家可以看看基于开源工具，我们是如何实现端到端的持续交付的。

关于持续交付，乐神 张乐老师的《持续交付的体系化方法》更详细的梳理了持续交付的框架，推荐大家仔细研读，有机会也可以到或者大会听乐神的分享，面对面交流。

大家听了这么多概念，对、敏捷、持续集成、持续交付的关系一定有点懵懵懂懂，这张图可以帮助大家理解。

技术运营
关于运维，我并不专业，后续我们会在龙门阵专栏里持续要求运维的大神跟大家深度分享，我这里贴一张的图，供大家参考

之前请教过我认识的一位运维总监，中小型运维团队能力建设顺序是：规范与标准—监控—自动化部署—日志管理
组织文化
这是大神 博客里的一篇文章，深度介绍文化，这次不展开，后续龙门阵会跟大家详细解读，需要组织文化的改进才能最终落地，就是完全重新定义了自己的组织文化：自由与责任，他们的、产品创新、云原生应用、微服务都做的非常好。

根据我的经验，影响改变组织与文化的两大利器：实践与度量。
实践在落地和坚持可以让团队朝着我们希望的行为习惯改进。
度量更是可以改进团队的行为，度量要慎重，一旦开始考核，度量很容易变味道。体系化的度量框架也是非常重要的，据说乐神 张乐老师正在整理，希望能帮助到更多的组织实现转型。
可视化
可视化对团队了解现状，发现改进方向非常重要，可以分为：过程可视化、数据可视化。

实践分布地图
这张图比较复杂，让门外汉看会比较烧脑，仅供大家参考，在不同的能力领域，可以有很多的实践可以做，大家还可以去关注整理的工具分布图，有这么多实践和工具，落地不用愁。

时代是陪伴大家终生学习的技术社区，推荐大家一些书，可以帮助大家入门和掌握的很多内容，《持续交付》一定要看，一定要看，一定要看。

最后，欢迎大家关注我的个人微信，进行更深度的交流，时代社区的更多直播和线下活动、深度好文也会在公众号里进行发布。

文章来源：时代社区一、业务概述
、简介
 是一个开源的、基于分布式的、面向文档存储的非关系型数据库。是非关系型数据库当中功能最丰富、最像关系数据库的。由编写， 可以运行在、、、系统上，支持位和位应用，提供多种编程语言的驱动程序。旨在为应用提供可扩展的高性能数据存储解决方案。高性能、易部署、易使用，存储数据非常方便。最大的特点是支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。
、架构
托管平台提供的存储架构是三节点副本集的高可用架构，三个数据节点位于不同的物理服务器上，自动同步数据。节点提供服务一般情况，当节点出现故障，系统自动从两个中选举新的节点。特殊情况下，可开放一个节点提供读写分离的服务。
复制集由一组实例进程组成，包含一个节点和多个节点， 客户端的所有数据都写入，从同步写入的数据，以保持复制集内所有成员存储相同的数据集，提供数据的高可用。
下图是一个托管平台提供的复制集，包含个节点和个节点。

二、业务特性
、 高性能
【高并发读写】
 支持多线程，可充分利多核的优势，有效的提高其读写性能。在千万级数据中，简单读操作的的可达到万秒；简单写操作的可达到万秒。在亿级数据中，简单读操作的也能达到万秒。
 【超强的压缩性】
 托管平台提供的服务，采用版本持续升级，采用 存储引擎，对于简单结构数据可达到左右的压缩，对于较复杂结构的数据压缩率也在左右，极大了减小了存储空间，降低了使用成本。
、 高可用性
【容错性】
三副本架构拥有较高了容错能力，当节点出现故障，系统自动从两个中选举新的节点，业务完全无感知。与此同时利用另一个节点进行快恢复，可将替换节点恢复至最新状态。避免从冷备数据中恢复而导致的数据不一致问题。
【自动同步机制】
副本集数据同步主要包含个步骤： 全量同步和追同步源的，即增量同步，保证了数据的主从副本间的一致性，为故障转移和读写分离提供了基础保障。
【隔离机制】
有效的控制业务对机器资源的使用，使得就算是多个实例混跑，也不会造成相互影响的恶性循坏，每个业务都能独占分配的资源。
、 高可靠性
【完善的监控体系】
提供利用率、内存使用率、主从状态、连接数、磁盘空间等实例信息实时监控和历史趋势统计信息，并且通过可视化图标的形式展示，便于开发和运维随时了解实例动态、定位故障以及根据业务发展趋势预先提供技术保障。
【自动备份和快恢复】
采用每天全量冷备、实时备份、应急备份。有效防范因误操作等原因对业务数据造成不可逆的影响，提高容灾能力。
【专业的管理平台】
托管平台提供的服务，采用专业的管理控制台。从业务的申请接入，到业务的日常维护问题定位、实例重启、备份、数据恢复，以及业务的扩展，都提供专业的全面的、自助的、可控的管理平台。全面提升研发、运维效率。

业务申请地址：
=

、 可扩展性
【支持弹性扩容】
 可以按需扩容，扩容过程方便快捷，不涉及物理机的迁移等重操作，出色平行扩容能力，也提高了资源的利用率。
【升级过程对用户透明】
定期对的版本进行升级，使业务能第一时间享受到新特性带来的性能优化，同时升级过程对业务完全透明和无感，依赖较少，不影响业务的正常使用。
三、 应用场景
 存储服务具有其自身的特性和优势，在以下需求的业务场景中，使用该存储服务，能起到较好的效果：

海量数据的存储
高并发读写需求
异构数据混合存储
严格的读写分离需求

相关推荐：《  第一期 ：集群搭建 》《 第二期：压缩与索引 》导语
 成为新一届的版本帝后，需要预编译的模块常常更新不够及时，就会出现我这样上班时间搞环境 ，那么如何保持一机多版本继续使用低版本的  运行 ，而又不影响正常项目中使用最新版本的  呢？
首先，安装 ，这是一个  版本管理工具，让你的电脑同时运行多个  环境。
   | 
使用  的童鞋请按  文档安装。
接着安装一个老版本的  用来专门运行 ，我这里使用的是  版本
  
你可以接着安装最新版本的 
  
这样，你的电脑上就同时存在两个版本的  了，在安装  依赖，运行相关  命令前，使用  命令切换到指定版本
  
接着这个  里的  和  都是指定版本了，这里要注意， 命令只对当次  会话有效，新开  窗口，即恢复使用默认。
如果你使用 ，可以用  自带的  运行集成插件来指定  版本。作者：陈舜尧
导语： “这张图片在快捷发图栏背景是黑色的，为啥发到会话窗口里背景就变成白的了？” 通过一个单，对黑白背景问题跟进的过程中发现了手中很多奇怪的表现。一层层看代码，整理总结了手中图片的显示和发送逻辑，以及对透明通道图片的特殊处理。

一、黑背景？白背景？

这张图片在快捷发图栏背景是黑色的，发到里背景就变成白的了。拿到问题，分析有两种可能原因：展示的背景色不一致；选中的图片的透明通道在和快捷发图栏两个不同的场景下过滤规则不一致。
很容易就能发现两个场景处理图片的不同：快捷发图栏将图片获取为，再压缩成，这个过程直接忽略了透明通道，默认处理的结果就是一张黑色背景的。快捷发图栏所有图片的字节流持久化到同一个文件里，这样做的目的是下次从本地加载多张图片时，会共用同一个文件，提高加载效率；
中的缩略图也是由原图压缩成，在处理的代码中，我发现了人为加白色背景的逻辑，原来这都是产品的策略，可能考虑到中图片黑色背景视觉上不太美观，所以进行了特殊处理。然而快捷发图栏和中视觉上没做到统一，有道是 产品拍头一时爽，开发解火葬场

二、都是，怎么有黑又有白！
既然问题找到了，美滋滋的准备加个鸡腿，然而事情并没有那么简单！回归问题的时候我用了另外一张图片测试，咦，怎么这张图片在中背景是黑色的？
有两个怀疑方向：、压缩成的过程，丢失透明通道导致中这张图片为黑色背景；、有没有可能是在上绘制白色背景失败导致的该问题？

先从第一个方向分析，通过把输出为，再把白底、依次绘到上，期间旋转信息的处理、对长图的特殊处理、这里就不展开了。这里怀疑输出为时，透明通道丢失。
我们知道指的是一种色彩模式，里面代表，表示，表示，表示，其实所有的可见色都是右红绿蓝组成的，所以红绿蓝又称为三原色，每个原色都存储着所表示颜色的信息值，中的值有下面几种，_ 代表位位图 ，_ 代表位位图 ，_ 代表位位图 ，_ 代表位位图。有没有可能是输出为的过程中，有奇葩的策略调整的值导致通道遗失？于是一步步断点跟踪这块的代码，很遗憾没发现异常。
再看看第二个方向，我们下加白色背景的代码见上图，设置了。能设置绘图时不同图层的混合方式，下图展示了不同的混合方式。我们处理是将图片叠加到白色背景上，这里_看上去也没问题。。。

啪啪啪打脸，看来不是怀疑的两个方向出了问题。于是病急乱投医把锅甩给了图片。。。。。
“会不会是格式的问题，某个参数导致转化过程中背景不同？？？？”
在查阅资料、用工具分析对比了两张图片的结构，欣喜得发现问题跟格式并没有半毛钱关系。冷静下来，还是用老办法，一步一步跟代码！！！！

游戏图压缩后大于是的你没看错，压缩后图片反而大，压缩步骤取，再绘制，最后质量压缩成，所以是拿原始图片当作大图去生成缩略图，原始图片有透明通道，所以对应的缩略图能加上白色背景；骰子图片压缩后发现比原图小，所以用压缩图当作大图去生成缩略图。是质量压缩生成的，已经丢失透明通道，是一张黑色背景的图。即使在加上白色背景也被上层图层覆盖，我们看到的就是黑色骰子缩略图。
我之前分析的过程中忽略了压缩原始图片生成这一步。一叶障目，理清了思路，问题就显而易见了！
三、黑白分明，搞清楚所有情况下的表现
既然理清了流程，那就把所有情况下的表现分析下吧。我们看看勾选原图下的表现。

这里很好理解，骰子图勾选原图后，是把原始图片生成缩略图，原始图有透明通道，所以生成的缩略图也有白色背景。

如果是发送图片，客户端去接收消息下载图片呢？端发送图片不存在是否勾选原图的概念，也不存在压缩的概念耿直。客户端接收方会去下载端发送的图片和架平生成的缩略图。
四、黑白闪变是什么鬼！
这时我在回归过程中又发现了一起不寻常的现象。客户端发送游戏图后，接收端收到图片，在中的缩略图会有一个由黑变白的过程。呵呵，兵来将挡，来我解。又滚去熟悉了下接收端的逻辑。

发送的这张游戏图是由透明通道的，架平并没有为有透明通道的图片添加白色背景的策略，所以接收端下载的是一张黑色背景的架平缩略图。
这里要提到手的预下载策略。用户可能会去点开大图，如果点击时再去下载，转菊花的过程体验很差，所以手会综合网络情况、当前已用流量等维度去判断是否需要提前帮用户下载大图。图中图片消息命中了预下载策略，手帮用户提前下载好了大图。
这时候问了，大图明明是黑色背景，为什么中会闪变成白色？哈哈哈，这里又是手人性化的一点，由于下载好了大图，为了让用户在中可以直接可以看到比较清晰的缩略图，手不信任架平生成的缩略图，用已经下载的大图在本地生成了相对高清的缩略图。
而下载的大图是有透明通道的，根据前面已经提到的产品策略，我们会给本地生成的缩略图加上白色背景，所以出现了闪变

五、总结
全文告一段落，在跟进问题的过程中，又完整的走了一遍手的图片发送流程。
除了提高对业务的熟悉程度之外，不禁感慨，前辈们为图片发送展示流程做了数不清的优化项，前人栽树后人乘凉，由衷的钦佩！导语
笔者对各大厂商预估模型的优缺点进行对比，并结合自身的使用和理解，梳理出一条预估模型的发展脉络，希望帮助到有需要的同学。
  提纲
 背景
  海量高纬离散特征 广点通精排
  少量低纬连续特征   
  
  百度凤巢
  阿里妈妈
 _ 
  背景
众所周知，广告平台的最终目标是追求收益最大化，以  广告为例，平台收益既与  单价有关，又与预测  有关。在排序的时候， 可以认为是一个确定的值，所以这里的关键是预测用户的点击率 。

 指数项  是一个调节因子，用于平衡用户体验和收入。扶持力度用于调节各个广告渠道 
互联网公司根据各自业务的特点，研发出了各种各样的  预估模型及其变种，本文尝试在众多流派和分支中梳理出一条  预估模型的发展脉络。
   海量高纬离散特征 广点通精排
逻辑回归可以称之上是  预估模型的开山鼻祖，也是工业界使用最为广泛的  预估模型。 是广义线性模型，与传统线性模型相比， 使用了  变换将函数值映射到  区间，映射后的函数值就是  的预估值。
 利用了  函数，函数形式为：   
对于线性边界，边界形式如下：  
 函数在有个很漂亮的形，如下图所示：

构造  损失函数，用梯度下降法求最小值，得到参数向量θ：

 正则化
为了防止过拟合，通常会在损失函数后面增加惩罚项  正则或者  正则：

 正则化是指权值向量  中各个元素的绝对值之和，通常表示为||||；
 正则化是指权值向量  中各个元素的平方和然后再求平方根，通常表示为||||。

其中， 正则可以产生稀疏性，即让模型部分特征的系数为 。这样做有几个好处：首先可以让模型简单，防止过拟合；还能选择有效特征，提高性能。

如上图：最优解出现在损失函数的等值线和约束函数  相切的地方，即凸点，而菱形的凸点往往出现在坐标轴上系数  或  为 ，最终产生了稀疏性。
 正则通过构造一个所有参数都比较小的模型，防止过拟合。但  正则不具有稀疏性，原因如下图，约束函数  在二维平面下为一个圆，与等值线相切在坐标轴的可能性就小了很多。

 离散化
 处理离散特征可以得心应手，但处理连续特征的时候需要进行离散化。通常连续特征会包含：大量的反馈  特征、表示语义相似的值特征、年龄价格等属性特征。
以年龄为例，可以用业务知识分桶：用小学、初中、高中、大学、工作的平均年龄区间做分桶；也可以通过统计量分桶，使各个分桶内的数据均匀分布。
反馈  特征的离散化，一般通过统计量分桶，但在桶的边界往往会出现突变的问题，比如两个桶分别为 、，在边界左右的值  和  会带来完全不同的效果。这里给   埋下一个伏笔。
 特征组合
 由于是线性模型，不能自动进行非线性变换，需要大量的人工特征组合。以  类特征为例，用户  往往有上亿维，广告  往往有上百万维，特征组合会产生维度爆炸。
广告特征里往往有三类维度，分别是广告类特征、用户类特征、上下文类特征。这三类特征内部两两组合、三三组合，外部再两两组合、三三组合就产生了无限多种可能性。所以在  预估模型的早期，主要工作就是在做人工特征工程。人工特征工程不但极为繁琐，还需要大量的领域知识和试错。
 优缺点
优点：由于  模型简单，训练时便于并行化，在预测时只需要对特征进行线性加权，所以性能比较好，往往适合处理海量  类特征，用  类特征有一个很重要的好处，就是防止信息损失相对于范化的  特征，对于头部资源会有更细致的描述。
缺点： 的缺点也很明显，首先对连续特征的处理需要先进行离散化，如上文所说，人工分桶的方式会引入多种问题。另外  需要进行人工特征组合，这就需要开发者有非常丰富的领域经验，才能不走弯路。这样的模型迁移起来比较困难，换一个领域又需要重新进行大量的特征工程。
  少量低纬连续特征   
   是一种典型的基于回归树的  算法。学习 ，只需要理解两方面：

 梯度提升 ：每次建树是在之前建树损失函数的梯度下降方向上进行优化，因为梯度方向求导 是函数变化最陡的方向。不断优化之前的弱分类器，得到更强的分类器。每一棵树学的是之前所有树结论和的残差。

 回归树 ：注意，这里使用的是回归树而非决策树，通过最小化  损失函数找到最靠谱的分支，直到叶子节点上所有值唯一 残差为 ，或者达到预设条件树的深度。若叶子节点上的值不唯一，则以该节点上的平均值作为预测值。



核心问题 ：回归树怎么才能越来越好？
最直观的想法，如果前一轮有分错的样本，那边在后面新的分支只需提高这些分错样本的权重，让没学好的地方多学一学。这种方法在数学上可以用残差来很好的解决，比如上图中，第一轮训练后残差向量为   ，第二轮训练就是为了消除残差，即这些分错的样本，当残差为  或者达到停止条件才停止。
那么哪里体现了呢？其实回到第一棵树结束时想一想，无论此时的   是什么，是均方差还是均差，只要它以误差作为衡量标准，残差向量    都是它的全局最优方向，这就是 。
核心问题 ：如何将多个弱分类器组合成一个强分类器？
通过加大分类误差率较小的弱分类器的权重，通过多棵权重不同的树能者多劳进行打分，最终输出回归预测值。
 特征工程
由于  不善于处理大量  类离散特征后文会讲到，但是却善于处理连续的特征，一般的做法是用各种  反馈特征来做交叉，来范化的表达信息。在这种情况下，信息会大量存在于动态特征中，而少量存在于模型中对比 ，信息几乎都存在于模型中。下图是作者为搜索广告的  模型设计的特征，读者可供参考。

 优缺点
优点：我们可以把树的生成过程理解成自动进行多维度的特征组合的过程，从根结点到叶子节点上的整个路径多个特征值判断，才能最终决定一棵树的预测值。另外，对于连续型特征的处理， 可以拆分出一个临界阈值，比如大于  走左子树，小于等于 或者  值走右子树，这样很好的规避了人工离散化的问题。
缺点：对于海量的  类特征， 由于树的深度和棵树限制防止过拟合，不能有效的存储；另外海量特征在也会存在性能瓶颈，经笔者测试，当  的   特征大于  万维时，就必须做分布式的训练才能保证不爆内存。所以  通常配合少量的反馈  特征来表达，这样虽然具有一定的范化能力，但是同时会有信息损失，对于头部资源不能有效的表达。
   
 在  年发表文章介绍了通过  解决  的特征组合问题，其主要实现原理是：
训练时， 建树的过程相当于自动进行的特征组合和离散化，然后从根结点到叶子节点的这条路径就可以看成是不同特征进行的特征组合，用叶子节点可以唯一的表示这条路径，并作为一个离散特征传入  进行二次训练。
预测时，会先走  的每棵树，得到某个叶子节点对应的一个离散特征即一组特征组合，然后把该特征以  形式传入  进行线性加权预测。

 改进
 的方案在实际使用中，发现并不可行，因为广告系统往往存在上亿维的  类特征用户  亿维，广告  上百万维，而  由于树的深度和棵树的限制，无法存储这么多  类特征，导致信息的损失。有如下改进方案供读者参考：
方案一： 训练除  类特征以外的所有特征，其他  类特征在  阶段再加入。这样的好处很明显，既利用了  对连续特征的自动离散化和特征组合，同时  又有效利用了  类离散特征，防止信息损失。

方案二： 分别训练  类树和非  类树，并把组合特征传入  进行二次训练。对于  类树可以有效保留头部资源的信息不受损失；对于非  类树，长尾资源可以利用其范化信息反馈  等。但这样做有一个缺点是，介于头部资源和长尾资源中间的一部分资源，其有效信息即包含在范化信息反馈  中，又包含在  类特征中，而  的非  类树只存的下头部的资源信息，所以还是会有部分信息损失。

 优缺点
优点： 可以自动进行特征组合和离散化， 可以有效利用海量  类离散特征，保持信息的完整性。
缺点： 预测的时候需要等待  的输出，一方面 在线预测慢于单 ，另一方面  目前不支持在线算法，只能以离线方式进行更新。
   百度凤巢
随着深度学习的逐渐成熟，越来越多的人希望把深度学习引入  预估领域，然而由于广告系统包含海量  类离散特征，如果全用  表示，会产生维度爆炸， 不支持这么多维的特征。目前工业界方案是 ，即用  做 ， 做训练。
 的目标函数如下：

可以看到  的前半部分可以理解成是 ，后半部分可以理解成是特征交叉 阶  只支持  维特征交叉。
   模型往往具有多个隐层，通过 、 等激活函数做非线性变换，残差会反向传播，并通过随机梯度下降来更新权值向量，最终预测时通过  函数做归一化输出二分类用  做归一化；多分类用  做归一化


  的具体做法是：

对于离散特征，先找到其对应的  ，并用  做 ，把该   下的所有特征分别投影到这个低维空间中。以用户  为例，如果用  可能有数十亿维，但是如果我们用  编码，就可以把所有的  都映射到一个  维的向量连续空间里，这就大大缩小了  模型的输入。
而对于连续特征，由于其特征维度本来就不多，可以和  的输出一同输入到  模型里进行训练。
 优缺点
优点： 可以自动进行特征组合，并能把同一   下的海量离散特征投影到一个低纬的向量空间里，大大减少了  的输入。而  不但可以做非线性变换，还可以做特征提取。
缺点：由于  阶 只支持  维的特征交叉考虑性能的因素常用  阶 ，所以不能像  那样做到  维的特征组合。另外  模型出于调参复杂和性能不高的原因，并不适用于中小型业务。所以在工业界使用的不多。
  阿里妈妈
前一阵子阿里巴巴的广告部阿里妈妈公布了其    模型 ， 是  的一个改进， 它采用分而治之的思想，用分片线性的模式来拟合高维空间的非线性分类面。
简单来说， 就是聚类 ，先对样本空间进行分割，这里有一个超参数 ，用来代表分片的个数，当 = 时自动沦为普通的 ；当  越大，拟合能力越强；当然随着  增大，其所需要的训练样本数也不断增大，性能损耗也不断增加。阿里的实验表明，当 = 时，表现最好。

上图公式可以看到，左边聚类部分用  做分区函数并决定样本空间的划分，右预测部分用  做拟合函数，并决定空间内的预测。

上图可以看到，对于这种高纬空间的非线性分类面，用  的效果比  好。
 优缺点
优点： 通过先验知识对样本空间的划分可以有效提升  对非线性的拟合能力，比较适合于电商场景，如  类和服装类不需要分别训练各自不同的  模型，学生人群和上班族也不需要单独训练各自的 ，在一个  模型中可以搞定。模型的迁移能力比较强。
缺点： 中超参数 需要人工去调，另外还是有  共性的缺点，如需要人工特征组合和人工离散化分桶等。
 _ 
对于  静态特征这种模型，信息主要存储在模型中相比  动态特征，信息既存储在模型中又存储在动态特征里，所以为了让模型更加快速的适应线上数据的变化， 率先把在线算法  引入  预估模型 。
 算法其实并不复杂， 算法需要遍历所有样本才能进行一轮参数的迭代求解如随机梯度下降，而  算法可以每取一个训练样本，就对参数进行一次更新，大大提升了效率。但这样做也引入了一个问题，模型迭代不是沿着全局的梯度下降，而是沿着某个样本的梯度进行下降，这样即使用  正则也不一定能达到稀疏解。
 是在传统的在线算法如  和  的基础上做了优化，它采用和  一样的  正则，同时和  一样会限制每次更新的距离不能太远。所以它在稀疏性和精确度上要优于  和 。

另外  采用  ，意思是对于某个特征的完整性比较低的时候，会动态加大学习率，而对于特征完整性高的，会减小学习率，让特征权重慢慢学。学习率的计算公式如下，即步长等于历次梯度的平方和的开方的倒数：

 优缺点
优点： 可以在线训练，这样使  存储于模型中的信息可以得到快速的更新。另外  也具有不错的稀疏性和精确度，可以减少内存占用防止过拟合。最后 _ 还支持动态的学习率，可以对不同完整性的特征采用不同的步长进行梯度下降。
缺点： 同样具有  的缺点，需要人工特征工程和人工离散化分桶。
引用
              
               – 
                  
       –         
    
                     
            
                                 
               先说说背景

是一个全区全服的休闲类游戏平台和社区，主逻辑服务器部署在四大，核心全部在深圳。对跨的专线依赖度很高。

网平提供专线故障后切的备份机制，当也中断时在线会下降到

窄带、孤岛无法提供游戏服务。


再说说分析
专线断了进行容灾，无非是数据走外网。外网能抗住么？其实木有人能告诉你。
公网包量、流量测试
小时包量测试：
压力：大约每分钟包，每个包为
结果：在小时之内一共传输个包，
成功个包，失败个包。
失败率：，
小时之内失败一共只有次，为网络抖动。
小时流量测试：
压力：大约每分钟包，每个包大小为
结果：深圳入流量：，出流量 ，
收包数等于发包数，无丢包
网速测试
非高峰期月日点测试结果如下表：
高峰期月日测试结果如下表：
测试数据表明，
专线在闲时和忙时都很稳定。
外网在忙时值会有升高，跨运营商红色的值可高达 不夸运营商的情况值低于 跨专线的流量用于玩家登录服务器时获取数据，游戏交互过程不受此延时影响，因此对于游戏来说完全可以接受。
外网状况从包量、流量、网速三个方面都可以支撑跨地域服务器通信需求。
最后说说设计
正常状态下：à专线à专线中断了：àà外网àà
惨绝人寰的事情发生了。。。。
专线中断并且外网中断，处于孤岛状态。。孤岛模式： ààà
偏远地区时可以使用的节省带宽模式：
àà合并流水后发包给à外网àà
全貌图：
看看效果吧
在具备防专线中断容灾能力前，一旦出现专线中断故障，区域的在线人数会迅速下降。。。趋近于在线。。。。恐怖。。
月日的专线中断演习，系统进行内外网切换的决策的几十秒内有在线的轻微影响。切换完成后，在线完全无影响。
写在最后
的防专线中断系统的设计思路首先将其作为一个旁路系统，在状态时，尽量减少对系统核心架构的影响，没有带来任何额外的专线流量。 填充是由正常的专线数据在内完成。
其次，作为容灾系统需要有自动化运营能力。否则，真正专线故障时，手动切换带来的时间损耗会大大降低系统的效能。
最后，这种多地域、多部署的全区全服系统有其自身的特殊需求，在具备了足够大的用群体后才有防专线中断容灾的现实需求。在做系统设计的时候需要因地制宜为了产品、用户而去考虑系统设计，绝对不能为了容灾而容灾、为了设计而设计。共勉。

相关推荐浅谈全区全服架构的游戏后台如何有效避免故障，腾讯云专家谈联合运营经验导语  的出现，一方面对于整个手机行业的发展极具创新领头羊的作用，另一方面也对现有业务的页面适配带来了新的挑战。 对于手中的各业务来说，受 影响的页面挺多，应该采取什么快速有效的办法来应对呢？

目前的页面可以分为通栏页面和非通栏页面两种，每种页面都可能有底部操作栏，具体如下：
通栏页面
顶部通栏
某些业务的一级页面多数使用了顶部通栏的效果，由于 在状态栏增加了的高度，对于现在通栏规范的内容区域会有遮挡情况。
解决方案：对于通栏页面在页面顶部增加一层高度的黑色适配层，整个页面往下挪。
这种做法虽然不符合苹果要求的设计规范，但由于短时间内更新全部的成本太高，可以先这样简单处理，后续再优化的设计展现。

底部栏操作栏
有些页面使用了底部栏操作栏，由于 去掉了底部键，取而代之是高度的  ，对于目前的底部栏操作栏会造成一定的阻碍。
解决方案：在页面底部增加一层高度的适配层，将操作栏上移，颜色可以自定义。

非通栏页面
底部栏操作栏
原因同上，在底部有高度的  ，对于目前的底部栏操作栏会造成一定的阻碍操作。
解决方案：在页面底部增加一层高度的颜色块，将操作栏上移，颜色可以自定义。

关于安全区域
这里可能有人会有疑问，为什么非通栏下的页面内容是通到底部的，而按钮却是在安全区域上方呢？
这个问题涉及到安全区域， 和先前版本的不同之处在于， 比较重视安全区域了。这意味着，如果给页面元素设置   它会渲染在屏幕顶部的之下，也就是状态栏下面。如果给页面元素设置   它会渲染在屏幕底部的之上，也就是底部安全区域上面。
为了解决这个尴尬的情况，苹果公司给我们提供了一个设置的标签的解决方案。
  可以设置的选项就是 它有三个可选值：

         可视窗口完全包含网页内容
         网页内容完全覆盖可视窗口
    同的作用

通过给页面设置=，可以将页面的布局区域延伸到页面顶部和底部。

对于通栏页面，设置了的属性，发现会不生效，经过跟同事查看手源码后发现，终端对于通栏的情况设置了属性，去除了上下安全区域的边距，使得安全区域的上下边距失效了。
另外提一点，经过个版本的测试，发现在渲染页面的时候，底部按钮在位置表现上不一致，可能是一个还未解决的：

使用方案：
根据以上的设计方案，可以这样处理：

修改页面属性
在页面链接一个来给 访问的页面增加对应的适配层
在页面上给对应的结构加上适配的类名



          
  {
    增加头部适配层
     {
         
         
         
         {
             
             
             
             
             
             
             
             
        }
    }

    增加底部适配层
     {
         
         
         
         {
             
             
             
             
             
             
             
             
        }
    }

    导航操作栏上移
     {
         
    }
}
  
 = 

     =
     = == 
     = =
     = ==== 
     = = 
     = =  
     = = =
     = =
    游戏中心


 =  =
 =   
     =
         =  
         =游戏
    
      =
         =  
         =直播
    
     =
         =  
         =赛事
    
     =
         =  
         =电竞圈
    
     =



如上，这样做的问题是，要修改的页面非常多，而且给页面带来了额外的类名，对以后的样式移除也有一定的工作量。
既然使用的方式来解决这个问题不是很完美，是否可以通过终端的方式给增加适配层，从而解决这个问题呢？
使用终端方案：
经过跟终端同学的沟通，确定是可以通过终端的方式，针对 机型，在原生界面初始化的时候可选择是否要增加适配层，这样页面就不需要样式处理了。
具体是通过链接中增加参数来进行适配

参数名_        控制 适配行为
参数名_   控制顶部适配层颜色  
参数名_  控制底部适配层颜色  




_
作用




   
增加顶部适配层，只对透明导航栏风格有效


   
增加底部适配层


   
顶部适配层颜色在主资源加载完成后填充颜色，只对透明导航栏风格有效


   
底部适配层颜色在主资源加载完成后填充颜色



对于顶部通栏的页面，通过加参数来增加顶部黑色适配层。_=_=

对于有底部操作栏包括通栏和非通栏，通过加参数来增加底部适配层以及设置颜色。_=_=_= 
这里的=为和两个特性数字相加

这样，无需写一行代码，只需要给页面链接增加适配参数，就可以完美适配 了
以后的头部优化之后，也可以通过参数配置去掉目前的顶部黑色适配层
更多具体技术实现可以查看这里：
作者：

  是用来代替 ，用来生成缓存的效果的。以前吭哧吭哧的学  的时候，就发现  好难用。而且  特意告诉你， 有毒，请不要乱用，保不定后面不支持。今儿，我看了下兼容性，呵呵

人生苦短，及时享乐，前端真坑，不敢乱学。
前方高能，如果觉得生活没有趣味可以继续看下去，会让你的人生更没有趣味。如果觉得凑合能过，请   。
继续
  讲道理是由两部分构成，一部分是 ，还有一部分则是 。所以，  本身的执行，就完全不会阻碍当前  进程的执行，确保性能第一。那  到底是怎么工作的呢？

后台进程  就是一个  独立于当前网页进程。
网络代理  可以用来代理请求，缓存文件
灵活触发 需要的时候吊起，不需要的时候睡眠这个是个坑
异步控制  内部使用  来进行控制。

我们先来看看  比较坑的地方，它的 
 的生命周期
首先， 并不是你网页加载就与生俱来的。如果，你需要使用 ，你首先需要注册一个 ，让浏览器为你的网页分配一块内存空间来。并且，你能否注册成功，还需要看你缓存的资源量决定有可能失败，真的有可能。如果，你需要缓存的静态资源全部保存成功，那么恭喜您， 安装成功。如果，其中有一个资源下载失败并且无法缓存，那么这次吊起就是失败的。不过， 是由重试机制的，这点也不算特别坑。
当安装成功之后，此时  就进入了激活阶段。然后，你可以选择性的检查以前的文件是否过期等。
检查完之后， 就进入待机状态。此时， 有两种状态，一种是 ，一种是 。就是激活睡眠。激活是为了工作，睡眠则为了节省内存。这是一开始设计的初衷。如果， 已经 ，那么，你网页的资源都会被  控制，当然， 第一次加载除外。简单的流程图，可以参考一下 的

从入门到放弃
上面简单介绍了  的基本生命周期实际上，都是废话，讲点实在的，它的兼容性咋样？

基本上手机端是能用的。
基于 
现在，开发一个网站没用 ，估计都没好意思放出自己的域名太 。 不仅仅可以保证你网页的安全性，还可以让一些比较敏感的  完美的使用。值得一提的是， 是基于  的，所以，如果你的网站不是 ，那么基本上你也别想了 。这估计造成了一个困难，即，我调试  的时候咋办？解决办法也是有的，使用  或者  完成域名映射即可。
下面，我们仔细介绍下， 的基本使用。

 实际上是挂载到  下的对象。在使用之前，我们需要先检查一下是否可用：
    {
   
}
如果可用，我们就要使用  进行路由的注册缓存文件了。不过，这里有点争议。啥时候开始执行  的注册呢？上面说过， 就是一个网络代理，用来捕获你网页的所有  请求。那么，是不是可以这么写？
   {
     执行注册
     {

    } {

    } 
  }
这样理解逻辑上是没有任何问题的，关键在于，虽然  是  ，但浏览器的资源也是有限的，浏览器分配给你网页的内存就这么多，你再开个 这个很大的。。。，没有  才怪嘞，而且如果你网页在一开始加载的时候有动画展示的话，那么这种方式基本上就  了。另外，如果算上用户第一次加载，那么这个卡顿或者延时就很大了。当然， 在制定相关规范时，肯定考虑到这点，实际上  在你网页加载完成同样也能捕获已经发出的请求。所以，为了减少性能损耗，我们一般直接在  事件里面注册  即可。   针对这个加载，专门讨论了一下，有兴趣的可以参考一下。特别提醒，如果想要测试注册  可以使用隐身模式调试！！！那当我注册成功时，怎样查看我注册的  呢？这很简单，直接打开  就可以查看，在当前浏览器中，正在注册的 。另外，还有一个 ，用来查看当前浏览器中，所有注册好的 。使用  进行注册时，还有一个很重要的特性，即， 的作用域不同，监听的  请求也是不一样的。例如，我们将注册路由换成 
   {
     执行注册
     {

    } {

    }
  }
那么， 后面只会监听  路由下的所有  请求，而不会去监听其他，比如  等路径下的。

从这里开始，我们就正式进入  编程。记住，下面的部分是在另外一个  中的脚本，使用的是  的编程方法。如果，有同学还不理解  的话，可以先去学习一下，这样在后面的学习中才不会踩很深的坑。监听安装  的代码也很简单：
  {
     
}
当安装成功后，我们能使用  做什么呢？那就开始缓存文件了呗。简单的例子为：
  {
  
     {
       
        
        
        
        
      
    }
  
}
此时， 会检测你制定文件的缓存问题，如果，已经都缓存了，那么 ， 安装成功。如果查到文件没有缓存，则会发送请求去获取，并且会带上  的  ，来表示缓存的版本问题。当然，这只针对于第一次加载的情况。当所有的资源都已经下载成功，那么恭喜你可以进行下一步了。大家可以参考一下  。这里，我简单说一下上面的过程，首先  你可以理解为  ，它接受的实际参数只能是一个 ，因为 和  返回的都是 ，这里就是一个串行的异步加载，当所有加载都成功时，那么  就可以下一步。另外， 还有另外一个重要好处，它可以用来延长一个事件作用的时间，这里特别针对于我们  来说，比如我们使用  是用来打开指定的缓存，但开启的时候，并不是一下就能调用成功，也有可能有一定延迟，由于系统会随时睡眠 ，所以，为了防止执行中断，就需要使用  进行捕获。另外， 会监听所有的异步 ，如果其中一个  是  状态，那么该次  是失败的。这就导致，我们的  开启失败。
不稳定加载
不过，如果其中一个文件下载失败的话，那么这次你的  启动就告吹了，即，如果其中有一个  是使用  的话，那就代表着您这次启动是  的。那，有没有其他办法在保证一定稳定性的前提下，去加载比较大的文件呢？有的，那你别返回  就了。什么个意思呢？就这样：
  {
  
     {
     不稳定文件或大文件加载
      
        
      
       稳定文件或小文件加载
       
             
      
    }
  
}
这样，第一个  是不会被捕获的，当然，由于异步的存在，这毋庸置疑会有一些问题。比如，当大文件还在加载的时候， 断开，那么这次请求就是无效的。不过，你这样写本来就算是一个 ，这种情况在制定方案的时候，肯定也要考虑进去的。整个步骤，我们可以用下图表示 

缓存捕获
该阶段就是事关整个网页能否正常打开的一个阶段非常关键。在这一阶段，我们将学会，如何让  使用缓存，如何做向下兼容。先看一个简单的格式：
  {
  
    
       {
             
          {
           
        }
         
      }
    
  
}
首先看一下，第一个方法，用来包含响应主页面请求的代码。当接受到  请求时，会直接返回   结果。我们在  中，捕获页面所有的  请求。可以看到  ，这个就是  的  流。我们通过  捕获，然后返回  对象，用来进行响应的处理。大家看这段代码时，可能会有很多的疑惑，是的，一开始我看的时候也是，因为，根本没注释，有些  实际上是内核自带的。上面的就有：

 这是用来控制缓存专门分离出来的一个对象。可以参考 
 是现代浏览器用来代替  专门开发出的  请求。可以参考  通信

简单来说， 根据 ，在缓存空间中查找指定路径的缓存文件，如果匹配到，那么  是有内容的。如果没有的话，则再通过  进行捕获。整个流图如下：

，那现在有个问题，如果没有找到缓存，那么应该怎么做呢？

啥都不做，等下一次  自己根据路由去缓存。
没找到，我手动  然后添加进缓存。

那怎么手动添加呢？很简单，自己发送 ，然后使用  进行缓存即可。不过，这里又涉及到另外一个概念， 和  流。这是在  通信方式 很重要的两个概念。 不仅分装了 ，而且在通信方式上也做了进一步的优化，同  一样，使用流来进行重用。众所周知，一个流一般只能使用一次，可以理解为喝矿泉水，只能喝一次，不过，如果我知道了该水的配方，那么我就可以量产该水，这就是流的复制。下面代码也基本使用到这两个概念，基本代码为：
  {
  
    
       {
          {
           
        }

         因为  流已经在  中使用过一次，
         那么该流是不能再次使用的。我们只能得到它的副本，拿去使用。
          = 

          的通过信方式，得到  对象，然后发送请求
         
           {
             检查是否成功
             ||  ==  ||  ==  {
               
            }

             如果成功，该  一是要拿给浏览器渲染，而是要进行缓存。
             不过需要记住，由于  使用的是文件的响应流，一旦使用，
             那么返回的  就无法访问造成失败，所以，这里需要复制一份。
              = 

            _
               {
                 
              }

             
          }
        
      }
    
}
那么整个流图变为：

而里面最关键的地方就是  这是现在浏览器操作数据的一个新的标准。为了避免将数据一次性写入内存，我们这里引入了 ，相当于一点一点的吐。这个和  里面的  是一样的效果。你用上述哪个流图，这估计得取决于你自己的业务。

在  中的更新涉及到两块，一个是基本静态资源的更新，还有一个是  文件的更新。这里，我们先说一下比较坑的  的更新。
 的更新
 的更新不仅仅只是简单的更新，为了用户可靠性体验，里面还是有很多门道的。

首先更新  文件，这是最主要的。只有更新  文件之后，之后的流程才能触发。 的更新也很简单，直接改动  文件即可。浏览器会自动检查差异性就算只有  的差异也行，然后进行获取。
新的  文件开始下载，并且  事件被触发
此时，旧的  还在工作，新的  进入  状态。注意，此时并不存在替换
接着，当你现在已经打开的页面关闭时，那么旧的  则会被  掉。新的  就开始接管页面的缓存资源。
一旦新的  接管，则会触发  事件。

整个流程图为：

如果上述步骤成功后，原来的  就会被清除。但是，以前版本  缓存文件没有被删除。针对于这一情况，我们可以在新的  里面监听  事件，进行相关资源的删除操作。当然，这里主要使用到的  和  有很大的关系因为，现在所有缓存的资源都在  的控制下了。比如，我以前的  缓存的版本是 ，现在是 。那么我需要将  给删除掉，则代码为：
  {

    = 

  
   遍历  里所有缓存的  值
     {
       
         {
            {
           删除  版本缓存的文件
             
          }
        }
      
    }
  
}
另外，我那么你不经仅可以用来作为版本的更新，还可以作为缓存目录的替换。比如，我想直接将 的缓存文件，替换为  和 。则，我们一是需要先在  事件里面将  和  缓存套件给注册了，然后，在  里面将  缓存给删除，实际代码和上面其实是一样的：
  {

    = 

  
   遍历  里所有缓存的  值
     {
       
         {
            {
           删除  版本缓存的文件
             
          }
        }
      
    }
  
}
， 更新差不多就是这样一块内容。
文件更新
对于文件更新来说，整个机制就显得很简单了。可以说，你想要一个文件更新，只需要在  的  阶段使用  进行缓存即可。实际操作也很简单，一开始我们的  阶段的代码为：
  {
  
     {
       
        
        
        
        
      
    }
  
}
我们只需要在这里简单的写下一下  代码即可。
  {
    = 
   事先设置好需要进行更新的文件路径
    = 
    _
    _
    _
  


  
    _ {
        =  {
       使用  对象进行路由拼接
          =   
         =       =  
         创建  对象进行流量的获取
          =   { }
         手动发送请求，用来进行文件的更新
          {
            =  {
             解决请求失败时的情况
                   
                    
          }
           将成功后的  流，存放在  套件中，完成指定文件的更新。
            
        } {
                     
        }
      }

        {
         
      }
    } {
        
    }
  
}
当成功获取到缓存之后，  并不会直接进行替换，他会等到用户下一次刷新页面过后，使用新的缓存文件。

不过，这里请注意，我并没有说，我们更新缓存只能在  里更新，事实上，更新缓存可以在任何地方执行。它主要的目的是用来更新  里面缓存套件。我们提取一下代码：
 找到缓存套件并打开
_ {
         根据事先定义的路由开始发送请求
        =  {
         执行 
          {
           缓存请求到的资源
            
        } {
                     
        }
      }
     使用  进行全部捕获
        {
         
      }
    } {
        
    }
现在，我们已经拿到了核心代码，那有没有什么简便的办法，让我们少写一些配置项，直接对每一个文件进行文件更新教研。有的！！！还记得上面的  事件吗？我们简单回顾一下它的代码：
  {
  
    
       {
             
          {
           
        }
         
      }
    
  
}
实际上，我们可以将上面的核心代码做一些变化直接用上：
  {
  
     {
        {
          =  {
           
           
        }
          || 
      }
    }
  
}
这里比较难的地方在于，我们并没有去捕获  相关内容。也就是说，这一块是完全独立于我们的主体业务的。他的  只是用更新文件而已。我们可以使用一个流图进行表示：

，关于文件的缓存我们就介绍到这里。
用户更新
现在，为了更好的用户体验，我们可以做的更尊重用户一些。可以设置一个 ，告诉用户是否选择缓存指定文件。有同学可能会想到使用  ，来告诉  执行相关的缓存信息。不过事实上，还有更简单的办法来完成，即，直接使用  对象。 和   类似。都是直接挂载到  对象上的。所以，我们可以直接使用  这个全局变量来进行搜索。那么该环节就不需要直接通过 ，这个流程图可以画为：

代码可以参考：
  {
  

    = 
   创建  套件
     {
    =   {
       返回  对象
       
    } {
     缓存指定路由
      
    }
  }
}
这里我就不赘述了，简单来说就是更新一下缓存。
 相关
上面大致了解了一下关于  的基本流程，不过说到底， 只是一个容器，它的内涵只是一个驻留后台进程。我们想关心的是，在这进程里面，我们可以做些什么？最主要的应该有两个东西，缓存和推送。这里我们主要讲解一下缓存。不过在 中，我们一般只能缓存 上面在文件更新里面也讲了几个更新的方式。简单来说

简单的情形上面已经说了，我这里专门将一下比较复杂的内容。
网络缓存同时干
这种情形一般是用来装逼的，一方面检查请求，一方面有检查缓存，然后看两个谁快，就用谁，我这里直接上代码吧：
  {
      = {
     通过  的  特性来决定谁快
     =  = 
     这里调用外层的 
     = 
     如果其中有一方出现 ，则直接挂掉
      =  = 
       =  
  }
}

  {
  
    
      
      
    
  
}
总是更新
这里就和我们在后台配置的  ||  一样，询问更新的文件内容，然后执行更新
  {
  
     {
        {
         
         
      }
    }
  
}
先返回后更新
这应该是目前为止最佳的体验，返回的时候不会影响正在发送的请求，而接受到的新的请求后，最新的文件会替换旧的文件。这个就是前面写的代码
  {
  
     {
        {
          =  {
           
           
        }
          || 
      }
    }
  
}
接下来，我们来详细了解一下关于   相关的内容。加深印象：
 
 虽然是在  中定义的，但是我们也可以直接在  域下面直接使用它。它通过  流就是 来进行内容的缓存。每个域名可以有多个  ，具体我们可以在控制台中查看：

并且   是懒更新，实际上，就可以把它比喻为一个文件夹。如果你不自己亲自更新，系统是不会帮你做任何事情的。对于删除也是一样的道理，如果你不显示删除，它会一直存在的。不过，浏览器对于每个域名的   数量是有限制的，并且，会周期性的删掉一些缓存信息。最好的办法，是我们自己管理资源，官方给出的建议是 使用版本号进行资源管理。上面我也展示过，删除特定版本的缓存资源：
  {
    = 

  
     {
        {
          ===  {
           
        }
      }
    }
  
}
  操作相关方法
这里，我们就可以将   理解为一个持久性数据库，那么针对于数据库来说，简单的操作就是 。而   也提供了这几个接口，并且接口结果都是通过  对象返回的，成功返回对应结果，失败则返回 

  成功时，返回对应的响应流。当然，查找的时候使用的是正则匹配，表示是否含有某个具体字段。

是否忽略  的查找。即，我们查找的区域不包括 。比如 =，我们不会再搜索 = 这几个字符。
当设置为  时，会防止  验证  ，默认情况下，只有  和  能够通过。默认值为 。
当设置为  时，表示不对  响应头做验证。即，  只需要通过  做匹配即可，不需要对响应头  做验证。默认值为 。
 自己设置的缓存名字。一般用不到， 会自动忽略。





{} {
      
}

  成功时，返回一个数组，包含所有匹配到的响应流。 和上面的一样，这里就不多说了。

{} {
       {
      
    }
}

 这实际上就是一个语法糖。  。即，它会自动的向路由发起请求，然后缓存获取到的内容。

 {
   请求的资源被成功缓存
}

 等同于
  {
    {
        
  }
    
}
={
     成功缓存
}

这个就是上面  的  实现方式。接受一个  数组，然后发送请求，缓存上面所有的资源。

  {
  
     {
       
        
        
        
        
      
    }
  
}

  将请求的资源以  键值对的形式进行缓存。如果，之前已经存在对应的 即， 值，那么以前的值将会被新值覆盖。

  {
   成功缓存
}

  用来删除指定的 。如果你不删除，该资源会永远存在除非电脑自动清理。
  返回当前缓存资源的所有  值。

     {
       {
      
    }
  }
可以查看到上面的参数都共同的用到了  这就是  套件里面的请求流，具体，可以参考一下前面的代码。上面所有方法都是返回一个  对象，用来进行异步操作。
上面简单介绍了一下  ，但实际上， 的管理方式是两级管理。即，最外层是  ，下一层是  。
 
浏览器会给每个域名预留一个  只有一个。然后，剩下的缓存资源，全部都存在下面。我们可以理解为，这就是一个顶级缓存目录管理。而我们获取   的唯一途径，就是通过  进行获取。这里，我们就可以将  方法理解为 没有已经存在的   则新建，否则直接打开。它的相关操作方法也有很多：

{}：在所有的   中进行缓存匹配。返回值为 

 {
    ||  {
     {
       
    }
     
  }
}

 用来检查是否存在指定的  。返回  代表是否存在。

 {
  检测是否存在    为  的缓存内容
    {
     没存在
  }  {
    
  }
} {
   处理异常
}

 打开指定的  。并返回  。

  {
    
  }

 用来删除指定的  ，返回值为 

 {
   检测是否删除成功
}

 通过可以通过  的形式来删除多个  
 {
          ===  {
           
        }
      }

 以数组的形式，返回当前   保存的所有   。


  {
        {
          ===  {
           
        }
      }
    }
    
上面就是关于   的所有内容。
这里放一张自己写的总结图吧：


原文链接：


相关推荐页面性能优化的利器 — 开发性能优化核心定义介绍篇简介近日，勒索软件  感染事件爆发，全球范围个国家遭到大规模网络攻击，被攻击者电脑的文件被加密，被要求支付比特币以解密文件。腾讯云技术社区「腾云阁」第一时间为广大网友分享了多篇解读和处置稿件，为方便大家阅读汇总在本文中，后续将持续更新，加入最新内容。
 勒索病毒用户处置指南
勒索软件  感染事件影响范围极广，腾讯安全云鼎实验室发布本处理指南意在指导云上用户在遭受攻击前后进行相关处理，个人用户也可参考部分章节。 
 勒索病毒数据恢复指引
如果你不幸中招，可使用数据恢复软件通过恢复被删除的加密前的文件，能恢复部分文件，一定程度上挽回用户损失。应用户咨询和要求，本文以免费工具易我数据恢复工具为例提供加密数据恢复指南和步骤演示。
腾讯安全反病毒实验室解读“”勒索软件
本文由腾讯安全反病毒实验室分享，对  勒索软件进行了解读。该软件利用了  操作系统下名为  的漏洞。攻击者利用该漏洞，向用户机器的  端口发送精心设计的网络数据包文，实现远程代码执行。如果用户电脑开启防火墙，也会阻止电脑接收  端口的数据。
比特币勒索病毒肆虐，腾讯云安全专家给你支招
 月  日凌晨腾讯云安全团队为云上用户紧急排查，连夜进行了分析，并提出了修复建议。同时腾讯云安全专家还通过直播分享，与网友互动支招。本文中包含直播的回看视频，欢迎观看。
 蠕虫详细分析
 蠕虫具体是如何工作的？它会对哪些文件进行加密？本文作者进行了详细的介绍。

针对于腾讯云服务器，腾讯云安全团队提供了专业的网站后门木马检测等安全功能，集合专业的机器学习模型，定期检测网站，及早发现木马并通知到您，为您的云服务器安全保驾护航。前情提要
去年，谷歌的阿尔法狗战胜了韩国顶级围棋九段高手李世石，让“人工智能”一鸣惊人。国内外各种科技传媒、创业公司对人工智能的大势宣传，更是让广大吃瓜观众仿佛一觉醒来就坠入了科幻电影中的神奇场景。
实际上，任何技术发展都是一个循序渐进的过程。人工智能并没有那么神乎其神，也不是那么遥不可及，它其实早已经存在于我们周围，以增强智能的形式为我们生活中的某个环节提供便利和更加友好的体验。比如当我们在手机端绑定银行卡、认证个人资料时，用拍照代替手工录入，手机神奇滴识别了我们的证件类型和格式，并从中找到了它所想要的信息，这一点是否也是很智能的呢？这项看起来神奇又简单的功能背后的核心技术就是人工智能中的技术领域之一：。当然你们可能会说了：“等一下，你先告诉我是什么！”

 图：手机拍照证件识别
  ，光学字符识别是指利用电子设备例如扫描仪或数码相机采集目标字符，通过检测暗、亮的模式确定其形状，然后用字符识别方法将形状翻译成计算机文字的过程；简而言之，就是令机器学会“识字”。
早在世纪年代，就开始利用技术实现各类文档的数字化，早期的设备庞大而复杂，只能处理干净背景下的某种印刷字体。世纪年代，针对扫描图像印刷体文本的识别率已经达到以上，搭载了证件识别技术的各种文档扫描仪、名片扫描仪应运而生，一时风靡，可谓应用迎来的第一个高潮。
进入世纪，高精度拍照智能手机的诞生，催生了许多以手机拍照识别文字作进行信息录入及查询类应用。照片中的包含文字的场景复杂多变，已非传统扫描仪类应用所能比拟；而云计算及无线网络的发展，前端用摄像头进行捕捉，后端利用云计算对图片进行处理，两者结合，更让应用充满了想象空间。技术可谓历久而弥新，重新成为研究热点。
证件识别是技术的实践应用阵地之一。身份认证是互联网的大背景下，连接虚拟和现实的重要一环。作为服务于微信产品的模式识别团队，来自于微信支付、微信公众号审核等业务的迫切需求促使我们在证件识别领域持续钻研，不断创新。目前我们已经可以支持银行卡、身份证、机动车行驶证等多类证件自动识别，识别正确率在以上。本文将带领大家回顾一下证件识别技术进化的过程。
证件识别
证件识别是证件识别的奠基版本，主要服务与微信客户端的智能绑卡和身份认证。
这一版本采用带有提示框的扫描方式采集证件图像。图的操作界面想必大家都不会感到陌生：当用户选择绑卡并用手机对准证件时，客户端首先会调起一个对焦模块，采集一帧最清晰的图像用于检测证件区域。卡片检测模块则在提示框的四个边界附近搜索稳定的边缘，并将检测到的卡片边缘用高亮表示，对用户进行提示引导。

图：微信绑卡流程
当检测到符合条件的边缘后，就可以通过计算单应性矩阵，将带有透视形变的证件区域校正成标准证件区域样本。以利于后续的信息检测和识别。

图：证件检测与校正
的证件识别流程如图所示。其中卡片检测及校正环节如前所述已在客户端完成。传到服务器端的标准证件区域图像仍需要：版面分析、行切分、单字切分、单字识别、后处理验证等环节才能输出最终结果。其中涉及的技术分为基于经验制定的规则策略和基于统计学习的分类模型。前者广泛应用在预处理阶段卡片检测、版面分析、行切分、单字切分的边缘提取、二值化、连通域分析、投影分析等，以及后处理阶段的信息验证；后者包括基于方向梯度直方图特征和多类别分类器的单字识别引擎，用于单字识别阶段。

图：证件识别流程
版面分析需要判别证件类型以及正面背面、将倒置的证件转正、提取卡片中待识别的感兴趣区域  等。由于各种卡片的版式不同，这一环节往往需要定制大量精细调节的人工规则。
得到之后，需要进一步在区域内进行行切分和单字切分，得到单字区域输入给识别核心。这一步通常采用连通域分析或投影分析的方法，为了适应光照和背景等干扰，我们研发了基于模板的最优投影分割算法，可以得到较好的切分结果。

图：基于模板的最优投影分割算法进行单字切分的结果
单字识别是体现性能的核心技术。采用了基于统计学习的单字识别方法。从切分出的单字图像中提取文字的笔画、特征点、投影信息、点的区域分布等有效特征，经过融合，交给分类器。分类器将提取的待识别字符特征与识别特征库的比较，找到特征最相似的字，提取该文字的标准代码，即为识别结果。
单字识别的输出不免有误识，需要利用卡片号码校验规则、日期有效范围等先验知识对结果进行后处理，争取将正确的结果最终呈现给用户。
证件识别
版上线之后，反响不错，基本解决了产品的刚需。然而在应用过程中也暴露出一些问题：首先，版面分析的性能不稳定，主要是人工规则的叠加造成算法鲁棒性较差，的调节很容易陷入顾此失彼的困境。其次，单字识别的误识率较高，尤其是在光线不理想或是清晰度不高的情况下识别结果较差。针对这些问题，我们引入了深度学习方法，推出了证件识别。
基于回归定位的信息行检测
我们将版面分析和行切分两个依赖人工规则的预处理环节进行合并，以目标检测的思路判断图像中的卡片类型和放置方式，并直接提取卡片中的待识别信息行。这其中包含了两类任务：

检测卡片类型，将输入图像分为三种情况：卡片正面、卡片背面、非卡片；

检测信息位置和形变并校正。通用的目标检测算法只能定位目标的最小外接矩形框，不能直接判断形变类型和角度信息；我们通过回归估计得到信息行的顶点，从顶点的位置关系即可推理得到形变和角度信息，从而巧妙解决这一问题。
 上述两类任务虽然属于不同类型，但是依赖的底层图像特征却可以共享。这里借鉴了人脸关键点检测的思路，采用 ，基于一个网络同时输出两类任务结果：



图：基于的信息行检测 
基于的单字识别引擎
在我们之前的许多实践工作中已经证明：在样本充足的前提下，即使一个简单的的单字识别性能依然可以完胜传统的特征工程模型。如果对于某些信息栏仅包含汉字比如姓名或者英文数字比如证件号码或有效日期的情况，识别性能还可以通过限定识别字符集得到进一步的提升。证件中的字形、字体和排版较为规整，我们采用包含层卷积的简单模型作为单字识别引擎来兼顾速度和性能需求。经过单字识别引擎的升级，单字识别性能提高了约个百分点。
证件识别
技术的进步总是来源于产品无限追求。基于扫描模式的证件识别方案优化之后，产品又有了新的需求：扫描的接口不够通用，能不能基于拍照、甚至直接上传照片的方式来进行证件识别呢？
听起来不是一个很过分的要求，然而实际体验之后，发现：由于客户端不再具有检测校正的机会，传到服务器的待识别对象的画风就由变成了和。这就引入了三个难题：

证件在图像中占比、角度不固定，可能存在较大旋转和透视形变；

证件图像背景可能比较复杂；

同一张图中可能存在多个证件对象。


这时，直接回归定位证件信息的方法效果已经不能满足实用需求。为此，我们在版中对证件信息定位模块进行了进一步改进。










扫描模式的样本
拍照模式的样本
上传照片模式的样本



图：证件识别的各种应用模式
基于图像统计分析的证件检测模块
加入这一模块的主要目的是应对用户上传照片中存在多个证件的情况，如图。我们通过一系列的图像处理和投影分析操作，判别图像中证件个数，并得到单个证件的感兴趣区域   ，即保证每个中有且只有一个证件，而且证件的区域占比超过。这一环节的主要难点在于：

寻找关键切点，即对应证件之间的区分位置， 需要针对背景和光照变化较为鲁棒；

需要判别证件个数，避免误切。


在算法研发过程中，我们针对各种实际情况进行了测试和调节，以保证较好的性能。















图：证件检测模块的输出结果
基于深度学习的证件和信息定位模块
由于拍照模式下证件本身的形变可能较大，直接回归条目位置已经不能达到很好的效果。于是，我们在的信息行定位网络中加入卡片顶点检测的分支，得到证件的类型、位置和摆放角度。这些信息同时可以辅助信息行的检测和定位。由于这个模块的加入，已经可以完美支持证件的°旋转，较大角度的透视形变，以及复杂的拍摄背景等情况。图给出了一些实际场景中示例。














图：支持全角度旋转和较大透视形变的证件识别
形近字识别优化
的一个经典难题就是形近字的识别，这些看起来长得很像的字符经常让识别引擎“傻傻分不清楚”即使是强悍的深度神经网络也难免挂一漏万。在中，我们引入了一个提高类别区分度的损失函数： 。其原理大致如下：之前的分类损失函数，如 ，只关注了待识别的图像应该属于哪个类别，但是并没有关心一个同样重要的问题：同类别的样本特征是否足够聚集？
以分类界的 问题“手写数字识别”为例，把网络倒数第二层全连接层输出一个维的特征向量可视化，其分布如图。可见，每个类别内的特征分布呈狭长条状，类内差异较大。 就是给每个类别的数据定义一个，大家要向靠近，离得远的要受惩罚。从而把特征分布变成了图的样子。采用 ，我们的单字识别引擎性能提高了约。









：特征分布基于 
：特征分布基于 



图：  示意图
训练数据的准备
所有的深度学习网络都有一个共同点：成也数据，败也数据。充足的数据燃料才能使网络的性能得到飞升。然而证件属于身份敏感信息，搜集和标注都有较大的成本。当实际样本不能满足我们的训练需求时，我们就转向合成样本的途径：通过开发各种合成样本的工具，得到大批量的接近真实情况的合成样本；采用合成样本训练、实际样本微调和测试的形式，以较为经济高效的方式达到各类网络性能的实用化水平。图为我们为证件定位任务和单字识别任务准备的训练样本，这些合成样本已经广泛应用到了各类模型训练中。









证件定位网络训练样本
单字识别网络训练样本



图：利用合成工具产生的训练样本
应用前景展望
作为人类需求牵引科技发展走到今天，智慧的延伸决定了世界的无限潜能。证件识别作为连接互联网线上和线下的重要一环，在各种互联网应用入口中承担着重要的角色。微信一直以来以业务需求为驱动，以实际应用为产出，在证件识别领域深入钻研，广泛实践。目前我们可以自信地说，微信在证件识别这一技术领域处于业界领先地位，欢迎各位同行交流探讨。导语 针对花样直播唇音同步问题，设计了一套量化测试方案。通过字符识别以及音频频率的分析，简便快捷，低成本，高准确度的测量出唇音同步差。本文重点对该方案的设计原理进行了分享。

一种唇音同步差量化方案的介绍
  唇音同步原理
音视频采集的数据分别来自于麦克风与摄像头，假定摄像头与麦克风采集数据是实时的，并在采集到数据时给他们一个时间戳来标明数据所属的时间，而编码封装按照原音视频时间的相对关系，就能保证音频与视频在时间上的对应。如此封装好数据之后，播放端同样根据音视频的时间戳来播放对应的音视频，就能实现音视频同步的效果。
不同步的原因主要有以下几种：
  生成环节：如果数据块上打的时间戳本身就有问题，必然产生不同步；
  传输环节：音频流、视频流分开传输，到达解码播放端时刻不同步；
  解码环节：解码时，未对音视频时间戳进行对齐，或对齐的不好，导致播放不同步。
最后表现出来，就是声音和画面对不上，严重影响用户体验。
  用户如何感受到不同步
 用户已知什么画面主播口型对应什么音色；
 用户在看画面的同时，耳朵在听对应的声音；
 通过大脑对比声音和画面的时间差，感知是否同步，感知同步差大小。
  如何模拟用户进行量化测试
、 生成对应的视频文件，并且已知画面每一时刻对应的声音特性；
生成一个什么样的视频文件，能够最好的让画面和声音一一对应起来，是这个问题的关键。
这里采用的方案是：
   生成一个秒表视频，每个时刻，对应时间显示都是线性递增的；
   生成一个与视频等长的扫频文件，每个时刻，声音的频率都是线性递增的；
   将时间与频率对齐，如对应频率，对应频率，对应频率等等；
、 将用户播放的视频画面以及声音同步录制下来；
、 像大脑一样去同步分析画面和声音，对比他们和视频源的差别；
   对于视频，按固定周期，使用 取视频帧，查看画面秒表时间；
   对于音频，按固定周期，使用查看对应音频频率值；
   比较秒表时间与频率值的偏差，得到唇音同步时间差。
流程图如下：
    自动化实现简介
手动测试太麻烦，用就可以轻松自动化。如上图所示，各环节都有相关模块可以帮忙处理。
   ：截取对应时间的视频帧，分离出音频文件；
   ：数字识别，读取秒表对应时间；
   ：变换，分析音频频率值。
   ：给工具加个界面，成品如下。

    小结
当前方案为纯黑盒测试，可支持竞品测试。
但对于秒表数字清晰度有一定要求，如数字有拖尾模糊等情况，会影响识别准确度。
欢迎有兴趣的同学联系陈兴一起交流改进。导语应用场景从创建、上传直到部署的详细过程，并简单的介绍了腾讯云容器服务的使用方法。通过快速拉起一个定制服务，极大的简化了部署，加快了业务部署节奏，并降低了运维成本。 —— 人生苦短，快用。

一、实践背景
为了学习，我们先结合实际需求，设计这样一个场景：假设有一个个人网站，想使用反向代理方案，能够在国内外快速搭建多个类似于的节点，提供集群式的访问服务。
我想到的方案如下： 常规部署方案：    购买云主机环境初始化部署配置反向代理解析 部署方案：购买云主机 安装拉取自定义镜像并执行解析 腾讯云容器方案： 腾讯云容器服务创建服务解析
很明显，使用部署方案，整个过程会变得简单快捷，也更易自动化。当然，若不是对有特殊要求的话，腾讯云的容器服务当选为最佳方案。
下面简单记录下我从镜像的创建、上传到部署的实践过程。
实验环境：
 •腾讯云：     •阿里云：     •     • 镜像版本： 官方最新版 • 版本：  •其他略
二、制作镜像
、安装配置
 安装
   

 配置腾讯云镜像加速官方的龟速
 
新增如下参数：
==

重启服务：
  
、制作基础镜像
拉取 官方基础镜像  
查看当前镜像 
   
                                                                                         
                                                                          
运行并进入镜像：

    
此时，终端已经进入了镜像里面，现在我们可以根据自己的需求安装额外的组件，比如我这次需要用到任务计划服务、进程守护等，那么直接在这个终端开始操作：
      
     
     
    
：上面的提示符中的  就是本次启动的   在下面的步骤即将用到。完成必要组件安装之后，按下   退出系统，接着使用   命令创建新镜像，比如命名为 ，版本：

   
执行完成后，可以使用   查看刚创建的镜像：
   
                                                                                         
                                                              
到此，我们就创建了一个自定义的基础镜像：基础镜像类似一个虚拟机的快照，方便后续步骤都可以从这个基础上重新制作。
：这里展示的是进入里面通过手工部署的方式，其实我们还可以通过来完成上述所有操作，可以极大的减小镜像的体积。
、制作服务镜像
有了前面的基础镜像之后，我们可以在此基础之上添加应用程序或自定义配置，打包为服务镜像。以本文背景需求为例，为了方便后续维护，我采用纯静态编译方式，制作成绿色便携版本。
因此，我们先在宿主机上静态编译一个符合需求的仅展示关键步骤，依赖组件自行搞定：
 把所有依赖都静态编译进去
  = \
__ \
__ \
___ \
__ \
=  \
= \
__ \
= \
=__ \
=____
 安装
   
安装后得到  目录，接着我们按照实验需求修改各项配置，比如反向代理：

 {
     
    _ 
    _ 
       

       {
        _ 
        __   _
        _ 
        __  
    }
}
全部配置后，运行，确保可以正常工作。
、编写
①、创建一个目录，比如

  
 
②、创建 配置文件，注意必须非模式，所以此处会带上参数：

=


=  


=
③、继续创建其他所需文件，比如 ：
          
④、将前面的目录拷贝过来：
   
⑤、编写文件：
 
  
 
 将所需文件复制到镜像指定路径
  
  

 定义一些命令因为是分层的，这里建议将多个命令通过连接，写到一个里面来减少层数
 指定时区，解决时间和宿主机时间差异问题
      \
            \
            \
             \
              

 运行 ，这里注意只能用一次
 
附： 常用指令，可以按实际需求自行添加：
：指定基础
：用来指定镜像创建者信息
：从复制文件到的路径
：在容器里面执行命令
：设置启动时执行的操作，只能是一条，多条则只执行最后一条
：指定容器需要映射到宿主机器的端口，也可以再的时候指定
：用于设置环境变量
：指定挂载点，使容器中的一个目录具有持久化存储数据的功能
、构建镜像
命令为：  =  ，比如：
  = 
之后，再执行 就可以看到刚刚创建的镜像：
   
                                                                                         
                                                                         
                                                              
 接着，可以下测试镜像是否能正常运行，命令语法大致如下：

   宿主目录镜像目录   宿主端口镜像端口 镜像名称版本
若加上  参数，将会后台运行，这里我们想看下刚刚创建的镜像是否正常， 所以采用前台运行模式，命令如下：

       
执行过程：

             
                                         
           
           
       
       
       
                 
                 
可以看到，镜像能够正常运行，接着我们还可以继续测试下启动的是否能够正常提供服务，这里就不详细介绍了。
三、私有仓库
前文已经制作了一个带有反向代理服务的镜像，此时还只能在本地使用，若是要让其他服务器也能用到这个镜像，我们可以使用   创建一个私有仓库，步骤如下：
、拉取私有仓库

  
 此时，执行 应该可以看到个镜像：

   
                                                                                         
                                                                       
                                                                   
                                                                          
                                                                       
、拉起仓库

       
、推送镜像
第一步查看镜像列表时，拿到需要推送的镜像的，比如 
①、先打，语法如下：
    仓库地址命名空间镜像名称版本
②、然后，语法如下：
  仓库地址命名空间镜像名称
执行过程如下所示：
           
    
      
  
  
  
  
  
  
  ===                                                  
  ======                                               
完成后，执行 就可以看到刚刚提交的镜像了：
   
                                                                                         
                                                    
                                                                       
                                                                   
                                                                          
                                                                       
③、测试拉取：
现在可以在本机本机可以先删除在拉取或另找一台服务器进行 拉取测试。
比如，先在宿主机上删除这个镜像：
    
 
 
此时，  列表已经消失，再执行   就又回来了。
    
   
      
   
 
     
、离线方案
当私有仓库无法使用时比如存在网络限制，我们还可以将镜像保存为一个包，方便离线使用，使用也非常简单：
①、   方案
使用    查看当前正在运行的镜像列表，得到对应的  ，执行如下语句可以将运行中的镜像导出到指定包：

     
有了包之后，就可以使用  来导入：

  |    
②、   方案
使用   查看本地已有镜像列表，得到对应的 ，然后执行如下语句可以将本地已存在镜像保存到指定包：

      
后面则可以使用  来加载包镜像：

   
两种方案的区别： • 只能导出正在运行的镜像，而  可以直接导出本地镜像； • 导出的镜像文件一般会小于  保存的镜像本文实践数据：相差； • 导出导入是根据容器拿到的镜像，再导入时会丢失镜像所有的历史，所以无法进行回滚操作   ，而保存加载的镜像，没有丢失镜像的历史，可以回滚到之前的层。
四、容器服务
上述私有仓库其实已经可以满足整个实验背景需求，我们可以在购买其他云主机之后，就可以通过私有仓库外网地址快速拉起一个反向代理服务了。
但是，我们都知道国内的云主机都是小水管，而按流量收费的模式也比较昂贵。此时，本文的主角才姗姗来迟：腾讯云容器服务。
简单来说，腾讯云的容器服务，就是给我们提供了一个在云端的私有仓库，我们可以将制作好的镜像，推送到腾讯云私有镜像仓库，然后就可以在腾讯云或国内外其他云主机上快速拉起自定义的镜像服务了，非常非常方便！而且，最重要的是该服务目前免费。
下面简单分享一下腾讯云容器服务的使用方法。
、创建仓库
①、开通镜像服务
打开腾讯云容器服务：
按照页面提示填写相关信息并设置仓库密码：
②、接着在【我的创建】页面新建一个镜像仓库：

得到腾讯云私有仓库地址：
即：
③、重置密码
如果忘记密码的话，可以使用【重置密码】功能来设置新的密码： 
、上传镜像
①、仓库认证
 填写你登录腾讯云的账号，一般是号码

  = 
 ②、推送镜像
和前文推送镜像到本地私有仓库一样，先查看镜像，然后如下先打，然后推送：
   
  
 比如：

   
  
成功后，就可以在腾讯云容器页面查看到刚刚提交的镜像版本了：
 
、拉取镜像
最后，我们就可以在需要部署反代服务的云主机上进行拉取操作了。
比如，我在阿里云主机上拉取这个镜像：
①、安装：  
②、启动：   
③、登录腾讯云仓库

  = 
 ④、拉取镜像
  
    
   
      
   
  ===========================                          
  ================================                     
   
   
   
   
   
  
 ⑤、运行镜像
这里我们正式执行，所以加上  参数：

         
 整个过程不到分钟，真的非常方便！
五、小结
本文记录了一个实际的应用场景从创建、上传直到部署的详细过程，为我们提供了一个新的软件发布方式，只要将应用以及相关的依赖打包成镜像，并上传到镜像仓库之后，我们就可以快速拉起一个定制服务，毫无拖泥带水，从而极大的简化了部署。
本文还简单的介绍了腾讯云的容器服务，通过容器服务，我们可以上传自定制镜像，可以在腾讯云主机或其他国内网服务器上快速拉起应用服务，加快了业务部署节奏，并降低了运维成本。
嗯，当然最重要的还是我通过这个实践，熟悉了的基本知识和基础使用方法，从而实现了我的入门学习目标。爬虫中常用处理，对于类似百度这样的搜索引擎，则需要配合使用，步骤如下
获取链接信息
在浏览器中打开，使用抓取，如下图

双击中的捕获链接，获取整个连接信息
然后在后加入捕获的链接信息
即
__=__=__=__=__=======
同理也可以获取下一页链接
__=__=__=__=__=
=====
这里需要注意的是，下一页链接需要填入查询页
代码如下

          {
          =  
         {
              =  
            __
            
              =  
              =  
            
              = 
              = 
                 {
                 
            }

        }    {

            

        }
         
    }
使用的时候，调用即可，其中是查找页
处理
思路是把链接保存到中，然后通过解析这里需要的包是
保存需要下边两个工具类

 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

   {
     文件操作类 
         =  

    {  }

          
               {
          = 
          = \\
          = \\\\
           =  
           =  

        =========分割线===========  \ 
          = 
          {
               =   
                    
              = 
              = 
              =  {
                      
                         \ 
            }
        }

        =========分割线===========  \ 
          = 
          {
               =   
                    
              = 
              = 
              =  {
                     
                           \ 
            }
        }
    }


         =   

           {

          = 
               
                 
         {
             =  
                 {
                
                  =  
                  = 
                  =  {
                    
                    
                    
                }
                
            }
            合并成功 
        }    {
            
        }  {
             {
                  =  {
                    
                }
            }    {
            }
        }
    }

          {


          = 
          =  


          {
            
        } 
        
        去重结果保存在中  \
        词数统计成功，结果保存在    中
        
        

        
        
          =  
        是否统计词性出现次数是 否\
          = 
          ==  {
             

            词数统计成功，结果保存在    中
        }
    }


           
             {
          =  
          =     
          =      
          =  
          = 
          =  {
             =   
        }

          =    =        
                    
          =  {
             
               =      {
                  =     
                开始提取第      个文件……
                
            }
        }  {
            
        }
             {
            正在写入     \
               \
                    
        }
    }

         {
          =  
          = 
          = 
           =      {
             = 
              {
                }
            }
        }
    }


    {  }
          
                {
          = 
          = \\
           =  

          = 
          {
               =   
                    
              = 
              = 
              =  {
                    ==  {
                               \
                            
                }
            }

        }
    }

        
               {
          =  
          =  
          =  
          =  
          = 
          =  =  {
            
        }
         
    }


             {
          = 
          = 
          = 
            {
              = 
              = 
              {
                 
            }
        }
         
    }

         
              {
          = 
          = 
          = 
           =   
          = 
          = 
          {
             = 
              {
                 = 
                   
            }  {
                 
            }
        }
         

    }


          
             {
          =  
          = 
          =  
          = 
          {
              = 
              {
                
            }  {
                
            }
        }

             {
            

        }
         

    }


             {
          =  
          ||  {
              指定文件不存在！
        }

          = 
          =  {
             =   
        }

          =    =        
                    

          =  

          =  

          = 
          = 

           =      {

              =       

              =  

             = 
             =       

                  {
                
            }
            
             = 
            第      个子文件生成……

        }
        
    }


           {
          =  
          =  
          =  

        
          =   
                     
          = 


          =  =  {



              =  
            

        }
         
    }



           {

         {
              =  
              {
                
            }
              =   
              =  
            
            

        }    {
            
        }
    }


         {
          =  
          {


             
        }
          {
             =   
        }
          {

             
        }  {

             
        }
    }


         {

          {
             =   
        }
          =  

          ||  {
             
        }
          = 

          = 
           =      {

              {
                 = 
                 
                    
            } 
             {
                 = 
                 
                    
            }
        }
         
             

          {
             
        }  {
             
        }
    }

         {
          = 
          =  

            {
            
             = 
        }
         
    }

        {
        
        
        
        
    }
}

 

 
 
 
 
 
 
 
 
 

抓取保存到本地 

   {

             {

          = 
         {
             =  
        }    {
            
        }

          = 
         _ = 
         {
             _ = 
            _
            _  _
            _
                          
             _ = _

             _ = _ 
             _

        }    {
            
        }
    }

           {

         {
              =  
                       
            
            
        }    {
            
        }
    }

        _  
              {
          =   _
                
          =  
          = 
          =  =  {
            
        }
         
    }

}
主程序如下，由于网址限制短时间访问次数，写一个定时器，每隔爬取一次，代码如下

 

 
 
 
 
 
 
 
 
 
 
 
 
 

 
 
 
 

使用方法 

   {
        = 
        = 

           {

        

          =   {
              = 
              = 

            
               {

                 {
                      {
                          =    {
                            
                            
                        }  {
                            
                            
                        }
                    }

                }    {

                    
                }
            }
        }
          =  
          = 

          =     
        每隔        分钟爬取下一个词
                 \
          

    }


          {
          =  
         {
              =  
            __
            
              =  
              =  
            
              = 
              = 
                 {
                 
            }

        }    {

            

        }
         
    }



          
              {

           =  
           = 
           =   

           =     

           = 
                 __=
                 __=
                 __=
                 =
                 
                 ====
        
                正在爬取  词      首页数据⋯⋯  \

          
          =  
          =   
          = 
                =宋体


           = =
          

          {

             = 
            对不起，关键词    
                     未被索引，请使用模糊检索方式查询  \
        }  {
             = 
                 {
                  \ 
                  \ 
            }
            词      首页数据爬取成功  \
        }

           = __=__=__=__=__=
                 =
                 
                 ====

        
          =   {
            
               {

                 {

                    
                      =  {

                        正在爬取  词    
                                 第    页数据⋯⋯  \

                          =     
                                 

                          
                          =  
                          =   
                          = 
                                =宋体
                        词      第
                                   页据爬取成功  \
                             {
                              \ 
                              \ 
                        }
                    }      {
                         = 
                          =  {
                            词    
                                     标注语料已经抓取完成，结果保存在中
                                     \
                             
                                    
                        }
                        
                    }

                }    {

                    
                }

            }
        }
          =  
          = 
          =   
          

    }
}
运行结果
抓取的在和文件夹下，结果保存在中回首腾讯云存储十年的历程，腾讯云存储业务中心总监邹方明将其划分为四个阶段：萌芽时代、图片时代、视频时代和云时代。
腾讯云存储面临的第一个大挑战正是在图片时代兴起之初。当时，传统的三层储存架构模式在性能、及成本方面都明显难以招架海量的日志和图片上传。腾讯云存储适时推出了系统自动化运营方案，通过实时监测物理区域，在秒内就能做出反应，对校表储存量超过的存储磁盘进行扩容，极大地节省了传统扩容方式所耗费的时间与人力。
腾讯云存储业务中心总监邹方明
但在自动化扩容运营系统基本适应图片时代后，新的问题开始出现：当空间、动态以及、朋友圈相册每天上传量高达亿级别的时候，文件删除量也达到了，之前设计的磁盘条带化整理系统遭受挑战。为了便于磁盘的自动回收，腾讯云存储将磁盘分成同等大小的空间并进行分片分头的整理，留存出到的冗余利用率，解决了当时的问题。
当腾讯云存储的数据储存增长量在四年时间内从到，腾讯云存储接到的需求也不断增多。面对超大容量源文件存储设备消耗量大、维护成本高的问题，腾讯云存储通过文件压缩、转码、解码的方式，将一个文件一个索引转换为多级索引，每个级别索引仅代表一个小分片，把这些小分片累积起来以支持更大的存储，强力解决了这一问题。同时，腾讯云存储通过设计纠删码的方式，为文件留出—份纠删冗余并分别存在多台设备里，最终使文件存储大小压缩到—份，极大的减少了原先存储的设备量。
同时，这一纠删码技术也运用到信息安全保障中：在单地数据中心出现问题时，这一技术能保障另一共存数据中心能及时完整地进行数据的整合并恢复归档，在降低成本的同时，极大程度地保障数据的安全。本文作者： 

在几年前，天空一声巨响 闪亮登场 前端宝宝们如获至宝 已经表单提交神马的 真的太 心累了 有了之后 网页的性能可大幅提升，告别刷新，告别如水的流量 不过，长江后浪推前浪，一代更比一代强 由于被同域限制着 导致 多服务器配置，云服务资源的存储 没办法充分利用 所以业界想到另外一种方法 实际上和没有半点关系，唯一相同的就是都是异步执行，而且完美解决了 问题 科技就是第一生产力 发展  以前追求就是静态网页显示信息而已。 现在，正朝着前进。 以前的单向交流 已经不能满足 需求了。 怎么办呢？ 改呗 所以，紧接着 诞生了 至今为止 前端通信方式算是告一段落。 这里我们将围绕上述的几种通信方式进行简单的介绍 以下是几个技术的顺序






 进入主题吧

相信这个应该不用过多的讲解了吧 差不多就步

创建对象
监听请求
设置回调
设置参数
发送
获得数据执行回调

这里，我就直接上代码了
   =  {
      =  {
         
        {
             =  
        }{
             =  
        }
         
    }
     { 为目标地址
          = 
        
         = {
            ===||==={
                 =   将解析为对象
                
            }
        }
        
          写入参数
          将参数字符化
    }
}
调用执行
{
    {
        
    }
    {
        
        
    }
}
 这样差不多就完成了一个的简单模型。当然，我们也可以使用提供的函数 只是他里面做了更多的兼容性和功能性

 就是    我真的不知道这个名字的含义到时有什么卵用 一开始在使用时 就是使用的函数就可以了 但，这造成了一个很不好的 总是让我们以为 和 有什么关联似的 而，事实上，他们两个是完全不同的机制 原理大家已经很清楚了，就是完完全全的异步操作 但的原理是什么呢？
原理
 其实是和  标签 有很大的关系 最大的优势就是实现异步跨域的作用 他到底是怎么做到的呢？ 其实 就是利用的 属性，实现跨域的功能 

     

 
   {
        
}


 =
===
 上面的写法有点不符合前端风味 说明一下 其实其实就相当于一个回调函数而已 在里面的内容我们来瞧一瞧 使用 来指定回调函数名字 并且传入一些参数

 = 
 = 

这就是前端发送的全部 那应该怎么执行呢？或者说，返回的内容是什么呢？ 很简单 根据里面指定的函数名 在返回的里面使用 来执行 服务器端返回的内容
{
      
}
 然后浏览器收到后直接执行即可 这里，我们来模拟一下服务器端盖怎样执行一个的函数
  = 
     = 
     = 
  = {
      
}
  {
     =  
      
    `   {}     {}`
     {   }
          
}
  上面基本上就可以完成一个简单的函数执行。 当然  里面也有相关的 操作。 有兴趣的同学可以看一看
 我们可以模拟一下实在的请求上面是直接将写死在内部 这样造成的结果可能会阻塞页面的加载 所以，我们需要以另外一种方式进行，使用异步添加方法
  = {
     = 
     = `{}={}`
    
}
  = {
    `   {}`
}
=
 上面就是一个精简版的了。 另外，也推荐使用的和进行请求 先看一下
 = {
  
}
 这里，我们需要关注一下里面中=里的的内涵 使用自动生成数的方式 省去了我们给回调命名的困扰。 其实，最后会被一串字符代替，比如  这个就代表你的回到函数名 不过，还是推荐使用因为你一不小心就有可能忘掉最后的 使用发送
{
     =
     
     {
            
        }
    }
 这样，我们就可以利用很简单的发送了

和 都是 的操作 但是有时候 我们更需要服务器主动给我们发信息 比如，现在的应用，完全可以实现服务器发送 然后再处理 而，就是帮助我们向靠近  全称就是   中译 为 服务器推送
他的技术并不是很难，和不同，他依赖原生的，所以对于开发者来说更好理解。 比如在 只要我不执行并且一定时间持续发送信息的话那么该连接就会持续打开 其实通俗来说，就是一个长连接 所以以前我们通常使用长轮询来代替他但是这样有个缺点就是 可操控性弱 错误率高。 所以，正对于这点 觉得需要在客户端另外指定一个机制能够保证服务器推送 实现连接的操作简单 在这样背景下诞生了 但和具体的区别在什么地方呢 

数据类型不同  只能接受  类型  可以接受任意类型
结束机制不同 虽然使用长轮询也可以实现这样的效果 但是 服务器端必须在一定时间内执行才行 而 只需要执行 即可

简单
先看一个端 一个比较简单的
  =    指定路由发送
 =  {  监听信息的传输
      = 
         = 
}
 =  { 当连接发生时触发
    
}
 =  { 当连接正式建立时触发
    
}
 主要就是创建一个对象 里面的参数就是发送的路由 不过目前还不支持所以也被限制在同源策略下 在返回的里面包含了，需要处理的一切信息也是通过事件驱动的，如上面所述 这里通常有一下几类重要的事件 ||| ||| ||当连接打开时触发| ||当有数据发送时触发 在对象内包含了相关数据| ||当发生错误时触发|
上面几个方法比较重要的还是方法 主要用来进行信息的接受 回调中的 包含了返回的相关数据 包含的内容 ||| ||| ||服务器端传回的数据| ||服务器端的域名部分有| ||用来指定当前数据的序号主要用来断线重连时数据的有效性|
服务器返回数据格式
上文说过 是以格式进行传输的 但具体内容是怎样的呢
 

  
 

 
  
 

    
  
   
 上面就是一个简单的 每一段数据我们称之为事件 每一个事件经过空行分隔 前面是数据类型后面是数据 通常的类型有

空类型 表示注释在处理是会默认被删除比如   
 声明该事件类型比如
 最重要的一个类型 表示传输的数据。可以为格式或者格式 比如 { }
 其实就是 用来表明该次事件在整个流中的序号
 用来表明浏览器断开再次连接之前等待的事件不常用

其实上面最重要的两个字段就是 所以，我们一般获取的话就可以使用 和 上文说道 每一段内容是通过换行实现的 那服务器端应该怎么实现 写入的操作呢？ 同样 这里以 为例
      \
     \\
 通过使用\\进行两次换行操作即产生空行即可
使用自定义事件
服务器端不仅可以返回指定数据还可以返回指定事件不过默认情况下都是事件 但我们也可以指定事件 比如
 
  
 
 这里出发的就是 事件。 即 这就是触发自定义事件的方式 在 我们可以使用 来进行监听
  =  
 {
    
} 
服务端使用
由于使用的是协议，所以对于服务端基本上没什么太大的改变 唯一注意的就是 发送数据使用即可，断开的时候使用
  {
       
       
        允许跨域
    }
  =
  = {
   ==={
      
   }{
         \
         \\
    
   }
   
}

  这里有一个 大家可以打开控制台看一下 会发现，有一个连接一直处于状态 该连接就是一个。 
兼容性
目前，在市面上大受欢迎 不过总有一个， 离经叛道 居然连都不支持 偶尔去翻了一下，还在 结果底下的评论基本都是 有空可以去看看 逼逼程序员

 不同于其他的协议，他是独立于存在的另外一种通信协议。比如像这样的一个路径就是一个 通信 通常的实时通信并不会传输大量的内容 所以对于协议那种，进行连接时需要传递，和 来说 这种方式的通信协议，会造成一定的时延 通信协议就是在这样的背景下诞生了 他与 不同的是双向通信

     

我们来看一个简单的 
  =  
   =   {
      
  }
   =   {
          
      
  }
   =   {
       
  }
   =   {
      
  }
   
 可以说上面就是一个健全的 通信了 和一样，我们需要创建一个对象 里面的参数指定连接的路由 而且，他也是事件驱动的 常见的事件监听有 ||| ||| ||当连接建立时触发| ||当有信息到来时触发| ||当连接发生错误时触发| ||当连接断开时触发|
 发送数据
另外， 最大的特点就是可以双向通信。这里可以使用方法发送数据 不过只能发送和二进制 这里，我们通常 数据叫做 他是数据发送的最小单元包含数据的长度和数据内容 下面就是几种常用的发送方式
   
 { } 

    =  
   

    =  
   

    =  
  
 另外还可以使用指定传输的数据格式不过一般都用不上，就不说了 不过需要提醒的是 方法，一般在和的回调函数中调用
 接受数据
同理，和差不多 通过监听事件，来接受发送回来的数据 接受其实就是通过来获取 不过 需要和端商量好的类型
  =  { 
     { 
    
  }  {
     接受数据
  }
}
 那端应该怎样处理通信呢？ 虽然是另外一种协议，不过底层还是封装了通信 所以使用的模块，基本就可以满足，不过里面需要设置很多的头 这里推荐使用模块
 发送数据
简单的 
  = 
    =  {   }

通过的方式通信 和类似
   {
     {
      
  }

  
}
 可以参考 编写的
为什么会有子协议
由于 本身的协议对于数据格式来说，不是特别的清晰明了，可以传输等等其他格式 这样对于安全性和开发性能来说，友好度很低。所以，为了解决这个问题  出现了 在使用时和都需要配置一样的 例如
  =  
                        
 服务端需要将发送过去 在的过程中 会识别 如果端也有相同的子协议存在 那么连接成功 如果不存在则会触发 连接就被断开了
 协议内容
 是有   提议并创建的。 主要的内容就是 一张表 

相比来说 真的是简单 其实一句话就可以说完

    –   

具体内容是 

第一个比特 表明 该 是否信息的最后一个 因为信息可以分多个包传送 但最终客户端接收的是整个数据
操作码 表示传送的类型 比如|| 
 比特位表示该数据是否是从  = 
  用来表示 的长度
  用来加密有效值
 就是传输的数据

 能否跨域
首先，答案是。 但，网上有两部分内容

              

看到这里我也是醉了 事实上 是可以跨域的。 但是为了安全起见 我们通常利用 进行 域名保护
即，设置如下的相应头   这时 只有 能够进行跨域请求 其他的都会
那什么是呢
   
 是  跨域资源分享  是 规范中 一项很重要的 一开始 收到     的限制 奈何不得。 结果出来了 等 阿猫阿狗 这让很不安呀 但是 大手一挥 亲 我给你开个 结果 就出来了。  就是用来帮助 进行跨域的。 而且支持性也超级好 啊，亲 但是 是使用 发送的真丑的一逼 所以，这里安利一下 大神写的一个函数我把英文改为中文了
   {
    =  
      {

     检查是否含有属性
     只存在于对象中
      

  }     =  {

     检查是否是，并且使用的
     =  
     

  }  {

     否则基本上就不能跨域了
     = 

  }
   
}
 然后 就可以直接， 那其实就完成了 但是什么意思呢
中的
该属性就是用来表明，你的的时候，是否带上你的 默认情况下是不带的 如果你要发送给的话 就需要将设置为了  = 但是并不是随便就能接受并返回新的给你的。 在端还需要设置  这样才能返回新的给你 不过，这还有一个问题就是还是遵循 的。 所以 你无法使用去访问他 他的增删查改只能由 控制
 的 验证
的  应该算是中里面 巨坑的一个。 因为在使用 的时候， 有时候我命名只发送一次请求，但是结果出来了两个。 有时候又只有一个 这时候 我就想问，还有谁能不懵逼 这里，我们就需要区分一下  的作用到底是什么。   是为了 更好节省宽带而设计的 因为 要求的网络质量更高 而且 花费的时间也更多 万一 你发送一个 请求这个不常见吧 但是服务端又不支持 那么你这次的 请求是失败了， 浪费资源还不说，关键用户不能忍呀 所以 这里我们就需要区分，什么是简单请求 什么是比较复杂的请求 简单请求 简单请求的内容其实就两块 一块是 一块是

 



 




 这是的请求头
 但只有一下头才能算简单 



比如 我使用上面定义好的函数 来发送一个简单请求
   = 
  =  

 我们来看一下，只发送一次简单请求时，请求头和相应头各是什么剔除无关的
  
  
 
 
 
 
 
 
  =
 上面就是一个简单的 头的交互。 另外，说明一个该头是必不可少的 本来在中 一般可以通过来获取相关的相应头。 但是 在中一般可以获得如下几个简单的









如果你想暴露更多的头给用户的话就可以使用 来进行设置 多个值用分隔 那发送两次请求是什么情况呢 我们如果请求的数据是的话，就会发送两次请求
   = 
  =  


 第一次我们通常叫做  他其实并没有发送任何 过去 只是将本次需要发送的请求头发送过去 用来验证该次请求是否有效 上面的请求头就有
 
 
 
 
 
 
 
 
就是用来表明该次请求的方法 请求内没有任何附加的数据 如果该次  服务器可以处理，那么服务器就会正常返回 如下的几个头
  
=    
    
 
 
 
 
 说明一下里面的头

 指明服务器支持的方法
 表明该次  最长的生存周期
 是否支持你自定义的头 比如 

这里，主要要看一下 这和另外一个机制有很大的关系 因为 已经多发了一次请求， 如果每次发送格式的的话， 那我不是每次都需要验证一次吗？ 当然不是   有自己的一套机制 通过设置 来表示该次  的有效时间。 在该有效时间之内， 后面如果有其他复杂 的跨域请求的话，就不需要进行两次发送验证了 而且，第二次的请求头和相应头 还可以减少不少重复的 第二次继续验证
=  
  
 
 
  =

=   
   
 
 
 
  最后上一张  大神话的  的运作流程图= 
 
 看不清的话请新建一个标签页看，放大就能看见了
发展图谱
不多说了 上图 


原文链接简单介绍
 是一个笔记本，这个笔记本可以编写和执行代码，分析数据，嵌入内容，以及共享可重复性的工作。  以前成为 可以在一个简单的笔记本中轻松分享代码，数据，图标以及说明。发布格式也比较灵活：， ，，，，等等。代码单元是基于输入和输出格式。例如：

安装
有多种方式可以安装  

使用  安装。在终端中输入    
用户可以使用  安装。  和  可以下载  的桌面版。
 可以通过一个桌面应用在  环境中工作。
  提供对   的托管访问。
   提供基于的。
 为个人用户启动一个临时在线的。

主观观点： 下常用 ，但并不是说  和 用户就不需要了，个人觉得  都应该尝试一下，启动和管理库都很方便。

入门指南
安装  之后，在终端中输入    来启动。此时将在  打开浏览器到的，默认是 。 用户打开  可以在一个 中看到所有的，打开很方便。当编码和发布的时候，具有相同的优势。有所有的选项，移动代码，运行，更改 ，并且运行 的时候使用 
有用的命令

   支持 自动补全！可以键入 _ 来查看对象的属性。有关 ，运行 ，探索对象的提示，可以查看  。
 提供介绍和功能概述。
  运行后打开快速参考：
  将运行一个 将在空间内运行  将运行，并在下面插入一个 更多的快捷键请看 


语言
本教程的主要内容是讨论在   中执行 代码。也可以使用   来执行  语言的代码。
 管理
在安装 时，需要在中安装，或者运行感叹号前缀，例如：
  
如果已经编辑了代码，可能需要  。 自带重载机制。可以在执行新行之前重新加载所有更改的模块。
_ 
 
本教程使用到的一些：

 通过网址导入数据，创建数据框架，可以很简单的处理数据，进行分析和绘图。请参阅使用 的例子：。
 用于科学计算的，用于代数，随机数生成，与数据库集成和管理数据的工具。请参阅使用  的例子：。
 一个基于的数学、科学和工程库。
 用于制作交互式，达到出版品质图表的图形库。更多统计，科学，图表等，请参阅：


如果使用的是 在中可以发现，前三个库都已经默认帮你下载安装好了。然后把过滤条件改为，搜，安装即可。非常方便

 数据
可以使用  的 _ 函数来导入数据。下面的示例中，导入了一个    的，并使用将数据展示在一个中。  

 函数是在线的，需要先设置账号和，具体请参阅：
使用_ 来索引 ：

大多数的函数也适用于整个 。例如，调用  计算每列的标准差

内联绘图
可以使用 ’   ，通过调用  或者离线工作的时候使用  。在中绘制，可以将数据分析和绘图保存在一个位置。下面是一个可以交互的绘图。转到    页面，了解如何设置凭据。通过调用  自动生成内嵌  的交互式版本：

绘制多个轨道，并使用 语法，自定义颜色和标题，来对图标进行样式化。还可以进行控制，将  设置为    或者 。


现在中显示了交互式图标。将鼠标悬停在图标上来查看每一栏的值，单击并拖动来放大到特定部分，或单击图例以隐藏显示轨道。

绘制交互式地图
 现在集成了 。下面的例子，将绘制世界分级统计图。
   
   

 = _____

 =  
         = 
         = 
         =  
         = 
         =       \
                  
         = 
         = 
         = 
             =  
                 = 
                 = 
             
         = 
             = 
             = 
             = 
 
       

 = 
     =   
\
             =\
              
     = 
         = 
         = 
         = 
             = 
        
    


 =  = = 
  = = 

绘图
使用和，可以在中绘制交互式图。
   
 _  

   

 =     
 =   
  =  

 =            =     
 =        =     
 =        =     
 =                      =   

 =  =   =   = 
 = 

 = 
     =  
     = 
         = 
             =   
             =   
             = 
             =   
        
         = 
             =   
             =   
             = 
             =   
        
         = 
             =   
             =   
             = 
             =   
        
    


 =  =   = 
  = _

绘制动画
查看的   ，来了解如果在 中创建内联动画，比如：

 控件和 小部件
给内联图表添加   和 ：
   
   

 = 
         = 
         =  =   = 
         =  =   
         =   
         =           
 = 

 = 
   
     = 
         = 
         =    
    
     =       
    

 = 
     =  
     = {  }
     = { }
     = 


 =  = 
 =  =   = 

  =   

此外，  可以给添加 ， ， 搜索框等。更多信息请参阅   。为了让其他人能够访问你的工作，他们需要，或者你可以使用基于云的选项。

运行代码
是的内核，允许在笔记本中编写和执行代码。 检查 文档 以获取一些简单的安装说明。 安装后，通过调用    打开 ，并使用“新建”下拉列表选择一个笔记本。

完整实例地址：_
附加嵌入功能
可以嵌入其他功能，如视频。 例如，从：


可以通过将数学内容用包住，来将嵌入中，然后将该单元格作为  运行。 例如，下面的  是   = \  {      } ，左右应该是双符号，但这里打双，就出错无法保存文章了==但会呈现表达式。

或者可以在的输出中展示，请参阅：

导出和发布 
可以将导出为，，，，和文件。 也可以将 转换成幻灯片。 可以在上发布 。 只需访问 并选择右上角的   按钮。 选择  并上传 文件！ 上传的笔记本将存储在你的    中，并托管在一个唯一的链接，能快速和简单分享。下面是一些例子：

_
_
_
_

 
发布交互式图形的用户也可以使用 ’   工具来绘制和拖放界面。 这些  可以发布，嵌入和共享。

  
对于希望传播和生产应用程序的用户， 是，，，和     的集合，用于通过数据分析后端轻松创建数据可视化应用程序。

 
对于更多教程，请查看 ’  ：所有文档都是用  编写的，可以自行下载并运行，或者查看   作者：梁定安，腾讯织云负责人，目前就职于腾讯社交网络运营部，开放运维联盟委员，腾讯云布道师，复旦大学客座讲师。

背景
如今移动设备性能越来越好，移动浏览器对 以下简称的支持越来越完善。同时页面只需一次开发即可跨、双平台发布、快速迭代、无需审核。因此很多移动端产品都选择实现。但应用每次请求页面，都需要重新加载和渲染，先天性能、流程度没有原生好，卡慢现象出现更多。有时会收到到用户反馈和投诉：

用户：我的页面打开太慢了；
用户 登陆成功后列表显示不全，上面显示读取内容失败；
用户 经常提示动态读取失败，这样实在不方便，希望尽快改进。

面对用户的反馈，产品和开发也感到困惑：究竟有多慢？哪个步骤慢？是个别还是大范围受影响？失败的返回码是多少？是不是运营商劫持？能让用户配合用抓个包么？如何优化？优化的效果怎么衡量？
为了便捷的衡量页面的速度、质量，高效定位问题，给用户提供更优质的服务。我们建设了自己的前端监控——天网云。
天网云  是什么
天网云  以下简称  是天网监控体系中的一部分，专注于用户端 监控，主要分部分：
    测速系统
通过了解页面响应时间分布情况优化应用，从白屏时间、首屏时间、网页加载时间、资源加载时间和整页完成时间角度展示用户响应时间分布情况，通过浏览器类型、设备以及地理分布等多维度数据进行对比分析。提供端到端的可视化、快速定位缓慢原因及受影响的用户详情。
    返回码系统
在最接近用户的场景，监控前端页面请求的成功率和延时，从时间、平台、网络环境、地域等维度详细分析，快速定位请求失败和耗时长的具体环境，优化应用。
    诊断系统
诊断系统提供便捷的移动端用户环境信息搜集解决方案。下发一个 ，用户打开后唤起手机 ，授权收集上报后，获取用户的设备信息、网络信息、用户的出口  和 ，同时可自定义  拨测规则。数据上报至后台，系统自动分析，给出诊断报告。
下面，我先介绍测速与返回码系统是如何实现的， 诊断系统在下次做单独介绍。
 测速
    测速原理
我们一直在使用各种方式监控产品的页面性能。从控制台、  抓包，到使用  和  这种侵入式代码方式来检测  事件发生和结束的时间，再到使用第三方工具如某某助手等通过在不同的浏览器环境和地域进行测试来寻求优化建议等等，这些方式不仅麻烦，而且测量的指标比较单一。好在   性能工作小组与各浏览器厂商都已认识到性能对于  开发的重要性，为了解决当前性能测试的困难， 推出了一套性能  标准，各种浏览器对这套标准的支持也逐渐成熟。
 就是这套  提供的性能数据，它精确的告诉我们当访问一个网站页面时当前网页每个处理阶段的精确时间  ，具体属性值如下：
 
每个属性的详细说明，可以在这里了解
有了这些属性的耗时数据，我们可以通过简单计算获取常用的一些页面性能参数：

 查询耗时 ：  
 链接耗时 ：  
 请求耗时 ：  
解析  树耗时 ：   
白屏时间 ：  
 时间 ：  
 时间 ： – 

    数据上报
怎么获取这些属性数据呢？我们写一个段简单的  仅测试试试：
 
调用后得到的上报结果如下：
 
我们约定每个指标为一个测速点，按顺序用数字代替。然后，在前端页面里收集  以及业务自定义测速点耗时数据上报。
例如：=====
 后方便阅读：==========
，，是系统自动分配的 ， 其中 ， 用于标识域名；用于标示页面。
 的值 ，代表测速点， ，的值为测试点耗时。
    数据统计
 
数据统计是基于我们二次开发的哈勃  框架，进行实时  处理，分析计算页面测速点的耗费时间、用户分布。
    前端展示
常用的天趋势对比：

还可以有很多展现，比如慢用户画像：
 
计算测速点延时正太分布：
 
点击测速点，可以从时间、平台、运营商、、省份等维度帮助分析用户访问页面的速度以及用户分布。但是，这里还是看单个测速点。怎样更直观的了解页面性能损耗呢？我们想到常用的 浏览器的   里面的网络  图：

从  图中可以看出，单个请求，每一个步骤耗时情况。那个步骤耗时最多，也非常清晰。再来看优化后实现的效果，这是最近天的  图：
 
点击查看明细，下图的体验是不是更加友好？

应用实例
有用户反馈某页面响应慢，通过查看测速数据，定位到是  执行时间引起。优化后，执行时间下降显著：
 
 返回码
前端页面中上报每次请求的返回码包括  协议返回码和业务返回码和延时，后台给出各个纬度接口请求的成功率和耗时及用户分布数据。
数据采集
在页面中每次后端的  请求埋点，记录、上报请求的返回码以及耗时数据。例如：页面调用  _ 这个接口，耗时=返回码= 返回成功= 抽样率为=
====_====
数据统计
 
数据统计也是基于我们二次开发的哈勃框架，进行实时处理，最终根据地域、网络类型、设备等维度统计入库成结果表。 
    数据展现
提供多维度，灵活对比查询，方便定位问题。

应用实例
某条接口成功率在左右，主要的错误码为参数错误。根据该错误码定位到提交请求的时候参数检查存在问题，可能会提交空参数。修改发布后，成功率保持在以上。 
 
最后
 监控作为业务质量的重要一环，意义重大。问题定位，性能优化都需要基于上报的数据进行。这里总结了一下我们在前端监控的一些尝试，怎样让监控系统更高效的定位问题，是我们一直在思考解决的问题。欢迎各位有好的想法一起交流探讨。作者：陈帅团队：腾讯移动品质中心

一、思路简介
在腾讯内部或者业界，耗电性能测试已有非常多的成熟方案。既有高端深入、带着原理去测试的方案；也有直接读取系统文件、读取手机显示电量百分比的方案。如果你也玩《王者荣耀》，前者可以类比于王者高端局，后者则是青铜匹配局，各有各的乐趣。
读取系统文件或采用工具获取整体手机电流值的方法，受影响的因素多，数据波动大，可信度不高，同时从开发角度说，告诉他一个简单的电流值，对他们定位问题的帮助，也不够。

图一源码中计算耗电的逻辑
先简单看下源码，无需过于深入理解逻辑。在类中可以发现，某个的耗电量值，来源于方法，其中包含、、移动网络、、蓝牙、传感器、摄像头、闪光灯等细分耗电量。通过以上分析：
“这个版本，我们耗电量高。”
就可以变成：
“这个版本，我们占用时间片过高。”
“这个版本，我们单位时间收发网络流量过高。”
“……”
与此同时，、、移动网络耗电量等细分指标，则都可以成为测试人员关注的专项测试项。同时测试人员也可以根据自己业务团队重点关注的方向，设计对应的专项测试。
二、数据源
在中，使用 获取数据，其中第、位数据代表、。如下，这两个值代表进程从进程存活以来，在用户态运行的时间为： ，在内核态运行的时间 。
= 该任务在用户态运行的时间，单位为。
= 该任务在核心态运行的时间，单位为。
本方案，主要以这两个值为依托，输出耗电各场景下的耗电性能。
三、数据采集
首先设计一个基类，用于各类性能测试，包括本篇的耗电，以及内存性能、流畅度等其他专项。主要用于统一化测试执行逻辑_、_中的调用逻辑都为和。

图二性能测试基类
的收集方案，在_调用实例的方法时，创建定时器后开始执行__。同样，在__中同样适用定时器每隔收集一次中的、数据，同时计算这过程中，进程耗用的时间 =_ – _ 。同时每收集一次数据，使用___向文本中将本次计算果写入文件。

图三性能数据收集具体逻辑
四、数据使用
获得单一进程的数据后，使用如下表的平均值即可评估出一个特定自动化用例场景下，对应的每秒 、是否有优化或者达标。

图四平均值评估耗电
但如上，假设获得这个值，从标准上可以判定其不符合预期，那如何驱动开发去修改问题呢？
开发在得知这个结果之后，需要复现测试的场景，相当于重走了测试同学的执行路径。所以如果测试多走一步，开发就可以少走两步。借助  工具         ，我们可以获取到详细的数据。 界面可以 全选，复制到做排序。

图五分析线程占用
在黑盒性能自动化发现有进程有耗电异常之后，使用分析包，一般可以找出几个耗电大头线程。同时使用功能，又可以大致查看到该线程到底是运行在哪些方法上。
通过以上的分析，基本上可以为业务开发找到耗电元凶。其实如果没有前述的黑盒自动化框架，测试在黑盒测试中如果感觉到应用总是会导致手机发烫，也可以去用关注下各个线程的占用时间，找出元凶给开发修改。
搜索微信公众号：腾讯移动品质中心，获取更多测试干货！作为中一个重要语法特性，几乎所有稍微复杂一点的数据分析场景都离不开，如今 已经成为应用程序开发的主流，作为开发者，我们有必要了解在中是如何组织运行的。
总体流程介绍
在阐述实现之前，我们首先简单介绍的总体流程，一般地，我们有两种方式使用，一种是直接写语句，这个需要有元数据库支持，例如等，另一种是通过编写应用程序。如下图所示，语句被语法解析 成查询计划，或者我们通过提供的组织成查询计划，查询计划分为两大类：逻辑计划和物理计划，这个阶段通常叫做逻辑计划，经过语法分析、一系列查询优化后得到优化后的逻辑计划，最后被映射成物理计划，转换成执行。

更多关于的解析与执行请参考文章【的解析与执行】。对于语法解析、语法分析以及查询优化，本文不做详细阐述，本文重点介绍的物理执行过程。
基本要素
如下图所示，大致包括三个要素：方式、条件以及过滤条件。其中过滤条件也可以通过语句放在条件中。

支持所有类型的，包括：

 
  
  
  
  
  

下面分别阐述这几种的实现。
基本实现流程
总体上来说，的基本实现流程如下图所示，将参与的两张表抽象为流式遍历表和查找表，通常为大表，为小表，我们不用担心哪个表为，哪个表为，这个会根据语句自动帮我们完成。

在实际计算时，会基于来遍历，每次取出中的一条记录，根据条件计算，然后根据该去中查找所有满足条件==的记录，并将中每条记录分别与得到后的记录，最后根据过滤条件得到最终的记录。
从上述计算过程中不难发现，对于每条来自的记录，都要去中查找匹配的记录，所以一定要是查找性能较优的数据结构。提供了三种实现：  、 以及 。
  实现
要让两条记录能到一起，首先需要将具有相同的记录在同一个分区，所以通常来说，需要做一次，阶段根据条件确定每条记录的，基于该做 ，将可能到一起的记录分到同一个分区中，这样在 阶段就可以将两个表中具有相同的记录拉到同一个分区处理。前面我们也提到，对于一定要是查找性能较优的数据结构，通常我们能想到表，但是对于一张较大的表来说，不可能将所有记录全部放到表中，另外也可以对先排序，查找时按顺序查找，查找代价也是可以接受的，我们知道， 阶段天然就支持排序，这个是非常好实现的，下面是  示意图。

在 阶段，分别对和进行 ，在遍历时，对于每条记录，都采用顺序查找的方式从查找对应的记录，由于两个表都是排序的，每次处理完的一条记录后，对于的下一条记录，只需从中上一次查找结束的位置开始查找，所以说每次在中查找不必重头开始，整体上来说，查找性能还是较优的。
 实现
为了能具有相同的记录分到同一个分区，我们通常是做，那么如果是一个非常小的表，那么其实就没有必要大动干戈做了，直接将广播到每个计算节点，然后将放到表中，如下图所示。

从上图可以看到，不用做，可以直接在一个中完成，通常这种也称之为 。那么问题来了，什么时候会用 实现呢？这个不用我们担心， 自动帮我们完成，当的估计大小不超过参数设定的值默认，那么就会自动采用 ，否则采用  。
 实现
除了上面两种实现方式外，还提供了 实现方式，在 阶段不对记录排序，反正来自两格表的具有相同的记录会在同一个分区，只是在分区内不排序，将来自的记录放到表中，以便查找，如下图所示。

不难发现，要将来自的记录放到表中，那么每个分区来自的记录不能太大，否则就存不下，默认情况下 的实现是关闭状态，如果要使用 ，必须满足以下四个条件：

总体估计大小超过设定的值，即不满足 条件
开启尝试使用 的开关，=
每个分区的平均大小不超过设定的值，即 阶段每个分区来自的记录要能放到内存中
的大小是三倍以上

所以说，使用 的条件其实是很苛刻的，在大多数实际场景中，即使能使用 ，但是使用  也不会比 差很多，所以尽量使用
下面我们分别阐述不同方式的实现流程。
 
 是一定要找到左右表中满足条件的记录，我们在写语句或者使用时，可以不用关心哪个是左表，哪个是右表，在 查询优化阶段，会自动将大表设为左表，即，将小表设为右表，即。这样对小表的查找相对更优。其基本实现流程如下图所示，在查找阶段，如果右表不存在满足条件的记录，则跳过。

  
  是以左表为准，在右表中查找匹配的记录，如果查找失败，则返回一个所有字段都为的记录。我们在写语句或者使用时，一般让大表在左边，小表在右边。其基本实现流程如下图所示。

  
  是以右表为准，在左表中查找匹配的记录，如果查找失败，则返回一个所有字段都为的记录。所以说，右表是，左表是，我们在写语句或者使用时，一般让大表在右边，小表在左边。其基本实现流程如下图所示。

  
  相对来说要复杂一点，总体上来看既要做  ，又要做  ，但是又不能简单地先  ，再  ，最后得到最终结果，因为这样最终结果中就存在两份 的结果了。因为既然完成  又要完成  ，所以  仅采用  实现，左边和右表既要作为，又要作为，其基本实现流程如下图所示。

由于左表和右表已经排好序，首先分别顺序取出左表和右表中的一条记录，比较，如果相等，则和，并将和分别更新到左表和右表的下一条记录；如果，则说明右表中没有与左表对应的记录，那么与，紧接着，更新到左表的下一条记录；如果，则说明左表中没有与右表对应的记录，那么与，紧接着，更新到右表的下一条记录。如此循环遍历直到左表和右表的记录全部处理完。
  
  是以左表为准，在右表中查找匹配的记录，如果查找成功，则仅返回左边的记录，否则返回，其基本实现流程如下图所示。

  
  与  相反，是以左表为准，在右表中查找匹配的记录，如果查找成功，则返回，否则仅返回左边的记录，其基本实现流程如下图所示。

总结
是数据库查询中一个非常重要的语法特性，在数据库领域可以说是“得者的天下”，作为一种分布式数据仓库系统，给我们提供了全面的支持，并在内部实现上无声无息地做了很多优化，了解的实现将有助于我们更深刻的了解我们的应用程序的运行轨迹。作者： 本文首次发表在《程序员》杂志  年  月期。

前言
基于本地数据的全文搜索，在移动应用上扮演着重要的角色。与基于服务端提供的搜索服务不同，移动端受硬件条件限制，尤其在数据量相对较大的情况下，搜索性能问题表现得十分突出。本文以移动平台广泛采用的  为例，介绍了移动平台的基本原理，结合微信安卓客户端自身实践，重点讲述微信在上的一些性能优化经验。
  
  是为全文搜索开发的一个插件，它是内嵌在标准的分布版本当中，它具有如下的特点：
搜索速度快：使用倒排索引加速查找过程
稳定性好：目前在移动端的稳定性比较好， 就是的基础上搭建的
接入简单：和平台本身就支持，并且 的使用就和正常使用表一样。
兼容性好：受益于本身兼容性很好，  也有很好的兼容性。
目前发布了个版本，我简单说下三个主流的版本。
：基础版本，具有完整的特性，支持自定义分词器，库函数包括，。
：在的基础上，性能有较大优化，增加相关性函数计算。
：和有较大变动，储存格式上有较大改进，最明显就是的分段存储，能够支持更大的的存储；并且开放，支持自定义辅助函数。发布于年中。
存储架构
微信全文搜索在 年底上线，最初主要服务于联系人和聊天记录的业务搜索。在方案设计之初，为了让这个功能有很好的体验，同时考虑到未来接入业务的会不断增多，我们设计目标是：
 搜索速度快
微信全文搜索使用  ，通过倒排索引提高搜索速度。
 业务独立性
微信的核心业务是联系人和消息，而微信全文搜索无论是在建立索引、更新索引或者删除索引时，都需要处理大量数据，为了使得全文搜索不影响微信的核心业务，采用如下的存储架构：

独立、读写分离：微信全文搜索在整体架构上独立于主业务，搜索也是独立于主业务；当主业务数据发生更新时，主业务通过方式通知搜索对应的业务数据处理模块，业务数据处理模块会通过一个独立的数据库连接接访问主业务数据库，不和主业务存储层共享数据库连接。
减少数据库操作：在搜索模块中，会有专门处理业务数据的模块，对一些复杂的数据结构做一些特殊的处理。例如对于一个成员的群聊，如果把个群成员分次插入搜索当中，会造成过多的数据库操作。所以，微信会把所有的群成员拼接为单个字符串，插入搜索中。
热数据延迟更新： 针对更新频率非常高的热数据，采用延迟更新的策略。所有的索引数据分为正常数据和脏数据。当数据发生更新时，先把对应的数据标记为脏数据，然后有一个定时器，每隔分钟，把数据更新到索引中。
 可扩展性高
高可扩展性要求搜索表结构和业务解耦。 官网上的例子，都是以单索引表的方式，每一列对应业务的某一个属性，当对应业务发生变化，需要修改索引表的结构。为了解决业务变化而带来的表结构修改问题，微信把业务属性数字化，设计如下的表结构：

负责全文搜索的索引建立，它和逻辑无关，当搜索关键词时，只需要找到对应的即可。负责业务逻辑的过滤，通过和来过滤对应业务的数据，最后输出。
搜索优化
微信全文搜索于年月日版本上线，到年春节后的版本，总体用户量从亿增加到亿，重度用户数量也大幅度增长，微信本地搜索的数据量也大幅度增长，造成了搜索速度不断下降，用户投诉不断增加。我们统计过，从微信版本到版本，微信全文搜索各个任务的平均搜索时间增长超过倍，给微信全文搜索带来巨大挑战。
为了优化搜索时长，先看下搜索的流程图：

通过每个阶段的耗时，发现在取数据阶段，时间占比达到以上，并且搜索的结果集数据量越大，时间占比越高，最高可以达到。取数据阶段是一个循环的过程，所以优化一个循环需要从两方面着手，减少单次循环耗时和减少总体循环次数。
减少单次循环执行耗时
深入  源码，发现的库函数耗时占单次循环执行耗时以上，并且数据量越大耗时越长。
库函数：用于把词语偏移转为字节偏移，微信当中使用字节做结果排序和结果高亮。
函数输入：

：用户查找的关键词

命中：关键词所命中的文档。文档就是全文搜索中的基本单位，可以是一个网页，一篇文章或者是一条聊天记录

目标词语偏移：在搜索阶段，通过关键词查找搜索索引可以拿到目标词语偏移


函数输出：

目标字节偏移：表示关键词在命中中的字节偏移。

例如：
=我 命中=我和我弟弟去逛街 目标词语偏移=、
把命中经过分词器分词，可以得到下表：

最后计算可以得出目标字节偏移=、
下图是函数处理命中字节数和耗时的关系：

函数的处理过程中包括分词，所以第一步就优化分词器。
要优化分词器，分词规则是重中之重。微信的分词规则为英文和数字合并分词，非英文和数字单独分词。举个例子，如对于昵称“中国”，分词结果为“”、“”、“中”、“国”。这个分词规则的原因主要是在微信对全文搜索的结果排序需求主要是其他的属性排序，并非依据文档的相关性排序。即，全文搜索部分只需要找到存在关键词的文档，并不关心文档中存在几个关键词。而且用户的输入大部分情况都不能组成词语，存在方言，所以把整个词语全部拆开建立索引是符合需求的。
微信全文搜索最早开发于年底，是  的最高版本，但是自带的分词器不能很好的支持中文，只能使用分词器，当时分词器的接入比较简单，对中文支持较好，所以使用了分词器。

对于昵称“中国”输出分词器中，开始是编码，分词器会做一次转化为编码，接着查找词典，最后进行后处理得到分词结果。从输入输出中可以发现，转化编码和查找词典这两步其实是多余的，所以微信舍弃分词器，自定义了分词器。

分词直接处理的编码的内容，通过单个，判断当前字符的编码范围和编码长度，根据不同的情况做出不同的处理。

经过分词器优化后函数耗时在处理万的耗时降低为，但是这样的优化还不够，当处理超过个结果时，仍然会超过，所以有了下一步的优化。
在移动端由于屏幕的限制，往往在最后显示搜索结果时，只会高亮少量命中的关键词，而函数会计算命中中所有目标词语偏移，所以需要对函数进行改造。
最开始我尝试的方案是直接修改函数源码，发现对的封装比较难使用，函数的依赖也比较多，修改出来的代码很难维护，可读性也不好，所以需要寻找新的方法来优化。在一番研究以后，我发现支持自定义辅助函数，并且有比较好的的封装，所以最后使用自定义辅助函数重新实现函数的功能，并加入优化逻辑。
输入：=我 命中=我和我弟弟去逛街 目标词语偏移=、 目标返回个数=
分词器分步回调，当分词器第一次返回“我”，符合目标词语偏移的第一个，并且此时已经满足目标返回个数个，函数直接返回目标字节偏移=。

减少总体循环次数
减少取数据阶段的总体循环次数，比较容易想到的就是在层做数据的分页返回，分页返回就意味着需要在层排序，在层排序的决定因素就是排序因子。但是微信全文搜索面对的业务排序因子多并且复杂，无法直接使用中的 ，所以需要通过一个中间函数转化，把所有的排序因子通过一个可比较的数字体现，最后再使用 排序。
这里简单说下，比较复杂的排序因子如下：
时间分段排序：时间范围在半年内，排序因子取决于下一级排序因子，时间范围在半年外，取决于时间的远近。
函数结果排序：排序因子是一个函数计算的结果，不是一个直接的数据库，并且函数计算结果不可直接使用 ，例如字符串形式的数字。
通过以上的分析，减少总体循环次数的核心点就在于，把层的排序转移到层去做，优点如下：

减少

减少层到层的数据拷贝


所以这里关键的实现点在于中间转化函数的实现，微信的中间转化函数是通过的辅助函数实现的。

的实现原理就是通过把所有的排序因子转化到一个位的数值当中，高优先级的排序因子置高位，低优先级的排序因子置低位。最后的如下：

特殊优化——聊天记录搜索优化
微信全文搜索中有一个比较特殊的搜索任务，就是聊天记录。
如图所示：

图中的红色圈内的数字表示，此会话中，包含关键字“我”的聊天记录的个数，而会话的排序规则就是会话的活跃时间。微信聊天记录的搜索有一下两个特点：

有统计属性

数量非常多单关键词命中最高可达到万条


从搜索流程图中可以看出，微信最初采用的方案是在层统计个数和排序，此方法在大数据的情况下不可取。鉴于之前分析过减少循环次数可以通过分页返回，其核心点在于把排序从层转移到层，所以就有了优化方案一。
优化方案一： 
实现如下：

此方案通过 在层直接统计出命中聊天记录的个数，并按照最近的时间排序，但是也有明显的缺陷：

无法使用索引加速：当和同时使用是，中必须包含的字段才可以命中索引，原因是使用会生成中间子表。

全量计算：在层统计命中聊天记录个数是统计了所有会话，上图中只需要统计个会话，浪费了大量资源。


优化方案二：分步计算
鉴于方案一全量计算的问题，采用分步计算的方式。
第一步：找出最近活跃的个会话

得到会话，然后执行以下，可以分别得到三个会话的命中个数

但是这种方法也存在问题，需要执行多条。
优化方案三：
鉴于方案二需要多条的问题，可以通过自定义聚合函数实现一次性统计。执行步骤如下：
第一步：找出最近活跃的个会话

得到会话，然后执行以下

可以一次性得到三个会话的命中个数。

最后
经过优化后，微信全文搜索全体用户各个任务平均耗时都在以下，而重度用户各个任务的平均搜索耗时都在以下，平均时间优化的幅度达到倍以上。
后续还有很多值得优化的地方，例如，在计算高亮时，如果在的数据结构中，直接加入字节偏移，那么还可以节省一部分时间。
最后希望我的分享能够对大家有些价值，欢迎留言交流。 基础书写格式
 段落
在  中，连续的一行或多行就是一个段落。用空行来进行切段。
这是第一个段落
我跟上面是同一个段落

这是第二个段落

 大纲
正确地使用大纲，可以帮助  系统渲染目录，计算定位锚点，好处多多。
 中，使用  来定义大纲标题，有多少个 ，就表示是几级的大纲。比如：
 这是一级标题会生成标签

这里是段落内容

 这里是二级标题会生成标签

这里是段落内容



 这里是六级标题

这种书写方式非常直观自然。
 引用内容
引用部分的内容只需要在行首加上  就可以了。比如：
          

看起来是这样的：

         

 强调文本
您可以使用加粗和斜体来格式化文本内容。
加粗使用 这种语法
斜体使用 这种语法 或 _这种语法_
还可以混合使用：加粗文本中的_斜体_

 删除线
你可以使用  包裹一段文本让它拥有删除效果
这样来删除一段文本

 超链接和参考
 超链接
通过 文本 的形式来添加超链接。比如这个是一个腾讯云的超连接。
腾讯云  控制创意，如此简单
 参考
 文本参考
如果文档中同一个链接多次使用，可以使用参考的方式。使用中括号可以把一个文本变为引用，如 爱因斯坦，在文档的后续，需要指明参考文本和参考连接的对应关系：
爱因斯坦是一个伟大的科学家。

爱因斯坦 

渲染效果：

爱因斯坦是一个伟大的科学家。

 命名参考
如果不同文本要参考同一个链接，可以使用命名参考，其格式为参考文本参考名称。在文档的后续，需要附上参考名称和链接的对应关系。比如
微积分是高等数学中研究函数的微分、积分以及有关概念和应用的数学分支。

 
 
 

渲染出来是这样的：

微积分是高等数学中研究函数的微分、积分以及有关概念和应用的数学分支。

 列表
 无序列表
在行首添加  或  可以开启列表模式，比如
 第一，
 第二，
 第三，

 首先，
 其次，
 最后，

有序列表
在行首添加数字，就可以开启有序列表模式，比如：
 打开冰箱
 把大象放进去
 关上冰箱

 列表嵌套
在上一级列表的基础上加两个空格，即可嵌套列表
 打开冰箱
   用右手打开
   轻轻地打开
 把大象放进去
   不要吐槽
     大象太大
     冰箱太小
     例子很无聊
 关上冰箱

整体效果：


打开冰箱
用右手打开
轻轻地打开


把大象放进去
不要吐槽
大象太大
冰箱太小
例子很无聊




关上冰箱


 表格
表格使用了直观的定义方式，使用  和 | 分割行和列。
月份|收入|支出
||
   ||
   ||
  ||

看起来效果如下：



月份
收入
支出




















其中，航标题后的一行使用的横杆数量是不要求的，只是为了排版好看才人工对齐。比如你可以这样来定义上述表格。
月份|收入|之处
||
||
||
||

你还可以使用  指定列的对齐方式。
月份居中对齐|收入右对齐|支出左对齐
||
               |          |
               |          |
              |          |

看起来效果如下：



月份居中对齐
收入右对齐
支出左对齐




















 代码
 行内代码
在文本中使用 `  包裹的内容会被识别为代码，比如
现在你可以不用 `` 了，现代浏览器都把复制了 `` 属性的元素放在了全局变量里。

渲染出来是：

现在你可以不用  了，现代浏览器都把复制了  属性的元素放在了全局变量里。

 多行代码
使用 ```  来包裹多行的内容成为代码。
比如：
    ```
        = 
        = 
        =   
    ```
 代码高亮
在 ```  的后面，可以指定代码的类型，如：
   ```
      =  
    

渲染的效果如下：
  =  
前言
互联网中，对一个内容实体的建模，如新闻，商品，通常有两个方向：，，如该文章属于哪个类别、文章标题、关键字、作者、新闻字数等等信息，这些属于从内容上描述文章信息；，另一块是，即从用户与内容之间的各种不同行为来建模用户的关系。今天我们就来重点关注下基于用户行为的内容表示的一些有意思的东西。
协同过滤
协同过滤相信很多做推荐的人经常接触的一个算法，是一种经典的集体智慧的算法：在大量的人群行为数据中收集信息，得到大部分人群的统计结论来表示人群中某种趋势，或者我们称为共性的部分。
为帮助理解，这里简单举几个栗子：比如我等屌丝程序猿，大部分会是下面这种情况：

除了程序猿的装扮，程序猿的很多时候也有下面这个特点

特点人群，会更大几率对他相关或者有兴趣的内容产生行为，同理，转换下用户和内容的彼此身份，如果某个内容，被相似的人群产生行为是否能够书名这些内容有一些实体会引起这一类人群的兴趣，这就是的假设前提，和属于一个硬币的两面，应该综合考虑才能算是比较合理的某个内容实体的表征方式。

很显然一些公共的信息如一个出生湖北武汉，年纪岁的未婚女演员并不能表征她就是刘亦菲，但是如果加上她的信息，她参演过功夫之王、铜雀台、四大名铺等等那就八九不离十了。是的，的数据就是那么重要，而协同过滤就是使用的比较多的方法。
基于用户的协同过滤
一句话描述基于用户的协同过滤，就是找到和目标用户最相思的用户，然后把该用户产生过的物品，收集为候选列表，滤除掉已产生行为物品，并考虑用户相似度为权重，进行加权排序，大体如下：

对用户进行推荐，因为与用户行为相似度较大与，其相似度为，用户，其相似度为，其值为，所以最终对用户的推荐为商品。
基于的协同过滤
一句话描述基于的协同过滤就是计算的相似度，然后推荐用户已购买的商品相似度比较大的物品。

很明显商品与商品的和商品的相似度都比较高，滤除已产生行为商品，对用户推商品。
基于模型的协同过滤
基于模型的协同过滤的方法，大体是用模型来替代比较粗糙的相似度计算法方式，这里描述下比较经典的 方法， 前面基于用户和的方法在实际场景中会出现数据稀疏、计算复杂的问题， 是一个比较好的方法，采用了矩阵分解的思路，将原始的用户对的行为矩阵转换为两个矩阵用来表示用户、的隐向量表示，然后在隐向量空间来度量用户或者的相似度。

等号左边的矩阵记录不同用户对不同商品的行为分布，通常在实际系统中，矩阵很大，而且通常十分稀疏， 方法就是将这个矩阵分解为两个比较小的矩阵，分别为用户和的隐向量矩阵，然后利用这些隐向量矩阵计算用户对的偏好得分，或者计算与或者用户与用于之间的相似性，在不同场景下来进行各种需求的计算。
利用建模共现关系
前面提到了使用协同过滤来建模，得到_的方式，那么是否有其他的方法呢？ 回归到数据来源，用户对各种不同的行为如果组成一个有一个的序列，如果我能建模序列内，元素之间的相似度，是不是就能很好的表征这些元素。好吧，大家可能发现了，这不就是吗？每个序列不就是的语料语句吗？是的，就是这样， 其实说了前面许多，什么协同过滤， ，就是想引出这个，使用来建模数据，下面我将详细描述，我是怎么在实际数据中做这些尝试的。
原理
的原理，有很多文章都讲过了，这里就不详细描述了，想进一步了解的可以去一下， 这里一句话解释下：利用或收集窗口上下文信息，来建模词与词之间的共现关系。
尝试
用于阅读资讯相关内容，通常在一个有效时间内，如一个，所有文章会形成一个文章序列，通常文章与词的映射，何为？如黄忠垃圾？
这盘《王者荣耀》竟打了分钟，手机充三次电这篇文章可能就会提取到王者荣耀这个词，形成词的序列，收集到有效用户的所有行为，即可拿到所词的序列，这个序列中包含了用户在阅读比如词为王者荣耀后，更可能去阅读王者荣耀英雄的数据如李白、诸葛亮的文章内容，也就是说在一个序列内，其共现概率应该比较高，那么其向量化后的相似度也应该更大，这个是可能需要话很大力气才能建模的。，话不多说，我们用实际数据实验一下，说明一下，以下所有数据均来自于内部，无法共享，老铁们不要私信来求数据啦，给你们我就会被开除的。
数据收集
一个数据的收集理论上应该包括词序列，还有先后关系，才能比较合理的建模一个可用的模型，但是，数据收集难度问题。
我们这里使用的是用户每天在词上的行为序列，也没考虑词的先后，所以这里其实有一个风险，可能达不到我们预先想要的类似的结果，因为理论上是有一个 限制，然后窗口了上下文来和中间词做一个推断，其实质是一个分类问题正样本为中间词，负样本为窗口外词， 所以其实这里如果没有时间先后，还有窗口太大为天，本身在模型上是有风险的，但是，又稍微一想，其实语义的依赖关系本身就也有可能不在 内，随机性的顺序，丢失的信息应该不多，考虑了很多，和小伙伴也讨论，感觉问题不大，直接先上看看，最后的数据如下：

需要说明的是这里的数据做过基本的去脏处理，包括设置阈值，排除行为过少的用户，大概能拿到的数据。
模型训练  在上实现很容易，只需要几行就可以完成：

   
 
=     =
 = 
    __

 = = = = _=
_ = _
_
  
现在在实现的，效果不是很好，这里先占个坑，后面等搞好了再来填。
结果
这里我们对做一些展示：

 
   
   
 = 
_ = 
 = _
__ = { }
 _=_
 __   
       
        ___ = \
        _ = ___
        _ = ___
        ___ = _

 = 
    =
    _=
    =
    _=
    _=
    =

 ____  =
     __ =     
    =     
        
          = __ 
         
        
            
            = 
            = 
            = 
            =
            =

    

 = 
_ = _
 = 
 = __    
___ 

__ = __ __

 __  =
    _ = _____ =
    _ = __    _
     __ = __    _
       {}   {}   {}
        _   _

_知乎 
以下是一些例子， 感觉还是蛮有意思的：

如王者荣耀，相似度最高的是天美工作室， 然后就是很多相关的英雄以及一些主播信息，还有一些有意思的如宋喆、车晓、张静初、郑则仕，这类看起来相关性不大的实体，应该是因为看王者荣耀的小伙伴们更偏向于娱乐化的新闻，因此更优可能露出车晓、张静初、宋喆这些娱乐圈人物。
个的分布：

如何使用？
产生的向量表示，原则上可以用来表征词，由于数据来源于，可以加上的数据，然后放在诸如模型，在文章点击率预估，又或者模型的部分，提升模型准确性；还可以在一些相关文章推荐时，通过来露出其他相关的，推荐这些的文章；甚至可以和相同的用法，作为的一种初始化表示，在任务中这些参数。
所有代码都在，有兴趣想在一些数据上测试的可以重现下。导语
描述  压缩的使用场景和解决方案，包括压缩传输协议、压缩列解决方案和压缩表解决方案。
提到  压缩相关的内容，我们能想到的可能是如下几种和压缩相关的场景：
、客户端和服务器之间传输的数据量太大，需要进行压缩，节约带宽
、 某个列的数据量大，只针对某个列的数据压缩
、 某个或者某几个表数据太多，需要将表数据压缩存放，减少磁盘空间的占用
这几个问题在  侧都有很好的解决方案 ，针对第  个问题，可以使用  的压缩协议解决；针对第  个问题，可以采用  的压缩和解压函数完美解决；而针对最复杂的第  个问题，则可以在引擎层面进行解决，目前 、、、 等引擎都支持表的压缩。本篇文章要详细讨论的就是此类关于  压缩机制相关 的问题，下面是主要的内容：
一、 压缩协议介绍
、适用场景
 压缩协议适合的场景是  的服务器端和客户端之间传输的数据量很大，或者可用带宽不高的情况，典型的场景有如下两个：
、查询大量的数据，带宽不够比如导出数据的时候；
、复制的时候  量太大，启用 __ 参数进行日志压缩复制。
、压缩协议简介
压缩协议是  通信协议的一部分，要启用压缩协议进行数据传输，需要  服务器端和客户端都支持  算法。启动压缩协议会导致  负载略微上升。使用启用压缩协议使用 参数或者 = 参数启动客户端的压缩功能。如果启用了 或者 = 选项，那么在连接到服务器段的时候，会发送 _的服务器权能标志位，和服务器端协商通过后 次握手以后，就支持压缩协议了。由于采用压缩，数据包的格式会发生变化，具体的变化如下：
未压缩的数据包格式：

压缩后的数据包格式：

大家可能留意到压缩后的数据报格式有压缩和未压缩之分，这个是  为了较少  开销而做的一个优化。如果内容小于  个字节的时候，就不对内容进行压缩，而大于  字节的时候，才会启用压缩功能。具体的规则如下：
当第三个字段的值等于  的时候，表示当前包没有压缩，因此  的内容为 ，即请求类型和请求内容。
当第三个字段的值大于  的时候，表示当前包已采用  压缩，因此使用的时候需要对  进行解压，解压后内容为 ，即请求类型和请求内容。
、方案实践
在客户端连接的时候加上 或者= 参数。如果是对同步添加压缩协议支持的时候，则需要配置 __=。下面是采用压缩协议连接  服务端的范例：

      

      =       


如果需要在主从复制中启用压缩传输，则在从机开启 __= 参数就 。
、压缩效果
可以通过在  中使用 选项来观察压缩传输的效果，也可以通过主从复制中已用 __ 参数来观察压缩传输的效果，很容易看出效果，这里不再截图说明。
二、 列压缩解决方案
 针对列的压缩目前直接的方案并不支持，映象中腾讯的  可以直接针对列的压缩。这里主要介绍一个曲线救国的办法，那就是在业务层面使用  提供的压缩和解压函数来针对列进行压缩和解压操作。也就是要对某一列做压缩，就需要在写入的时候调用  函数对那个列的内容进行压缩，然后存放到对应的列。读取的时候，使用  函数对压缩的内容进行解压缩。
、适用场景
针对  中某个列或者某几个列数据量特别大，一般都是 、、 等数据类型。
、压缩函数简介
 的压缩函数  压缩一个字符串，然后返回一个二进制串。使用该函数需要  服务端支持压缩，否则会返回 ，压缩字段最好采用  或者  字段类型保存。使用  函数对压缩过的数据进行解压。注意，采用这种方式需要在业务侧做少量改造。压缩后的内容存储方式如下：
、空字符串就以空字符串存储
、非空字符串存储方式为前  个  保存未压缩的字符串，紧接着保存压缩的字符串
、方案实践
字段压缩方案涉及到的几个相关的函数如下：
压缩函数



解压缩函数



字符串长度函数



未解压字符串长度函数

_

实践步骤：
、创建一张测试表
      ```_` 

``     _  

``     内容列

  ``

  =   = =压缩测试表
、网表中插入压缩的数据
  ```_` 
、读取压缩的数据
   ```_`
、查询对应的长度和内容
 _     _    ```_`
、压缩效果

从上面截图可以看出压缩效果比较好，针对 、、、 等，如果里面重复的数据越多压缩效果就越好。
三、 表压缩方案解决方案
、适用场景
采用压缩表一般都用在由于数据量太大，磁盘空间不足，负载主要体现在  上，而服务器的  又有比较多的余量的场景。
、表压缩简介
、为什么需要压缩
目前很多表都支持压缩，比如 、、、 。由于使用  主要是不需要做什么改动，对线上完全透明，压缩方案也非常成熟，因此这里只对  做详细说明。对于  和  的压缩方案将在  的压缩方案二中撰文说明。
在  没有大量横行的时候，数据库几乎都是  负载型的，在  有大量余量的时候，磁盘  的瓶颈就已经凸显出来。而数据的大量存储，尤其是日志型数据和监控类型的数据，会导致磁盘空间快速增长。硬盘不够用也会在很多业务中凸显出来。一种比较好的方式就诞生了，那就是通过牺牲少量  资源，采用压缩来减少磁盘空间占用，以及优化  和带宽。尤其针对读多些少的业务。
 出来后，数据库的  负载有所降低，但是对于磁盘空间的问题还是没有很好的解决。因此压缩表使用还是非常的广泛。这也就是为什么那么多的引擎都支持压缩的原因。而  在   的时候就支持了压缩功能，只是压缩比比较低，通常在 左右。而  能达到 左右， 的压缩比能达到 左右。
注意：压缩比和你存储的数据组成有很大的关系，并不是所有的数据都能达到上面所说的压缩比。如果大部分都是字符串，并且重复的数据比较多，压缩比会很好。
、 的压缩介绍
使用  压缩的前提条件是，___ 这个参数要启用，__ 这个参数设置成 。
你可以使用 _= 来  或者  表来开启  的压缩功能，如果没有指定 __ 的大小，默认 __ 为 __ 大小的一半，也可以通过指定 __= 参数来开启  的压缩功能， 可以为 、、、、，单位是 。 的值越小，压缩比越高，消耗的  资源也越多。注意  或者  的页不支持压缩。启用压缩后，索引数据也同样会被压缩。
你也可以通过调整 __ 来设置压缩的级别，级别从 ，默认是 。级别越低，意味着压缩比越高，同时也意味着需要更多的  资源。
、压缩算法
 压缩借助的是著名的  库，采用  压缩算法，这种算法在减少数据大小和  利用方面很成熟高效。同时这种算法是无损的，因此原生的未压缩的数据总是能够从压缩文件中重构， 实现原理是查找重复数据的序列号然后进行压缩，所以数据模式决定了压缩效率，一般而言，用户的数据能够被压缩 以上。
、压缩表在 _ 中如何处理
在 _ 缓冲池中，压缩的数据通过 __ 的大小的页来保存，如果要提取压缩的数据或者要更新压缩数据对应的列，则会创建一个未压缩页来解压缩数据，然后在数据更新完成后，会将为压缩页的数据重新写入到压缩页中。内存不足的时候， 会讲对应的未压缩页踢出去。因此如果你启用了压缩功能，你的 _ 缓冲池中可能会存在压缩页和未压缩页，也可能只存在压缩页。不过可能仍然需要将你的 _ 缓冲池调大，以便能同时能保存压缩页和未压缩页。
 采用最少使用算法来确定将哪些页保留在内存中，哪些页剔除出去，因此热数据会更多地保留在内存中。当压缩表被访问的时候， 使用自适应的  算法来维持内存中压缩页和非压缩页的平衡。当系统  负载比较高的时候，这种算法倾向于讲未压缩的页剔除，一面腾出更多的空间来存放更多的压缩页。当系统  负载比较高的时候， 倾向于将压缩页和未压缩页都剔除出去，这个时候更多的内存用来保留热的数据，从而减少解压的操作。
、如何评估 __ 是否合适
为了更深入地了解压缩表对性能的影响，在   库中有对应的表可以用来评估内存的使用和压缩率等指标。_ 是收集的是某一类的 __ 压缩表的整体状况的信息，汇总的是所有 __ 压缩表的统计。而 ___ 表则是收集各个表和索引的压缩情况信息，这些信息对于在某个时间评估某个表的压缩效率或者诊断性能问题很有帮助。___ 表的收集会导致系统性能受到影响，必须 ____ 选项才会记录，生产环境最好不要开启。
我们可以通过观察 _ 表的压缩失败情况，如果失败比较多，则需要调大 __。一般建议 __ 设置为 。
、方案实践
、设置好 ___ 和 __ 参数
  ___=  __=
、创建对应的压缩表
  _      _=__=
如果是已经存在的表，则通过  来修改， 如下：
  _ _= __=
、压缩效果
压缩效果通过线上的一个监控的表修改为压缩后的文件大小来说明，压缩前后对比如下：

四、参考文献








作者 | 张祖优 腾讯高级工程师

对于的漏洞挖掘过程，其实就是一个使用不断测试和调整再测试的过程，这个过程我们把它叫做；同样是，有些人挖洞比较高效，有些人却不那么容易挖出漏洞，除了掌握的技术之外，比如编码的绕过处理等，还包含一些技巧性的东西，掌握一些技巧和规律，可以使得挖洞会更加从容。
应该是我挖过的最多漏洞的一种漏洞类型，累积下来，就国内、金山、新浪、网易等这些互联网公司的，应该至少也有超过个，这篇文章主要就是根据自己的一些经验与大家一起探讨编码绕过、处理等技术因素之外的 的一些技巧。

模糊测试是挖掘漏洞最常用的手段之一，不止是，应该可以说可以用于大部分类型的漏洞挖掘。通俗可以把这种方式理解为不断尝试的过程。

的流程


这是一个比较常规的漏扫中检测插件的一个流程图，其中比较关键的几个点在于：

检测输入点
潜在注入点检测
生成
攻击验证

检测输入点其实就是寻找数据入口，比如说数据，或者头部里的，再或者路径等等，这些都可以成为输入入口，转换为比较形象点的说法，比如看到一个搜索框，你可能会在搜索框里提交关键词进行搜索，那么这里可能就发生了一个或者请求，这里其实就是一个输入点。
其次是潜在注入点检测，潜在注入的检测是判断输入点是否可以成功把数据注入到页面内容，对于提交数据内容但是不输出到页面的输入点是没有必要进行的，因为即使可以提交攻击代码，也不会产生；在潜在注入点的检测通常使用的是一个随机字符串，比如随机位数字，再判断这位数字是否返回输出在页面，以此来进行判断。为什么不直接使用进行判断呢？因为里包含了攻击代码，通常很多应用都有防火墙或者过滤机制，中的关键词会被拦截导致提交失败或者不会返回输出在页面，但这种情况不代表不能，因为有可能只是不够好，没有绕过过滤或者其他安全机制，所以采用无害的随机数字字符就可以避免这种情况产生，先验证可注入，再调整去绕过过滤；而随机的目的在于不希望固定字符成为防御黑名单里的关键词。
再者就是生成和进行攻击验证的过程，的好坏决定了攻击是否可以成功；而对于不同情况的注入点，需要使用的也是不同的，比如，注入的位置在标签属性中还是标签事件中，使用的是不同的；
标签属性中：如 =注入位置，：  =
标签事件中： = =注入位置 ：
其实的生成就是一个不断和不断调整的过程，根据注入位置上下文代码的结构、内容以及应用过滤机制等不断调整和不断提交测试的过程，下图是一个的生成流程。

那么假如某次调整后成功，也就意味注入成功，并得出这个漏洞的。
其实为什么一开始就介绍下扫描器常规的检测方式呢？因为手工 其实也是这样一个过程，很多安全工具其实就是将手工的过程自动化。
接下来进入正题我们一起探讨一些的挖掘技巧。
不一样的昵称

这是一个微信网页版的存储型，注入点是微信昵称的位置右图，通过访问微信群成员列表可以触发导致弹框。

这是微信某个春节摇一摇活动的这里是生效了，通过微信访问活动页面，自动授权后获取微信昵称并自动显示在活动页面，当时微信昵称是：张祖优，由于生效，导致昵称显示变大。

这仍然是腾讯某个产品的活动页面，也是通过微信点击自动获取昵称然后在活动页面显示，这个截图的页面链接实际是：= =点击抽奖===相当于当时我的昵称是： =点击抽奖

这也是一个微信网页版存储型，注入点同样是在昵称，通过访问通讯录可以触发，触发的昵称大概是： = =。
看了几个漏洞，再给大家看看我之前的昵称和微信昵称：

其中右图的昵称是张祖优。
看了上面的例子，我想大家已经可以发现，前面的几个其实都是基本通过昵称的位置提交攻击代码导致了的产生，这其实就是一种被动挖掘的技巧。其实漏洞挖掘，特别是，有时候是靠主动挖掘，但更多的时候也可以通过被动的方式发现，特别是类似、微信这种一号多用的情况，可以想象你的微信昵称、昵称或者签名等，在不同的应用、网页中登录，你的昵称就会在不同的地方显示，这些昵称在微信、本身不会导致问题的产生，但到了其他页面呢？也许就会导致问题的产生。
当然，现在微信应不允许设置含有特殊字符的昵称了，而大家也可以看到，对尖括号进行了转义，不过在这之前，单单就微信昵称，通过这种方式，我起码发现了腾讯以及非腾讯的各种朋友圈中的活动的不下于二十个。
网址跳转中的规律

这是一个年提交的腾讯云登录跳转的。
前一段时间雷锋网有对我做了一个采访，这篇文章也发在上，不知道大家有没有看到其中有一个细节，讲的是我为了哄女朋友开心，然后挖洞收集公仔，当时其实我是在两天内挖洞十几个洞，并且都是。可能大家就会好奇为什么能一下子挖洞那么多的洞，还是不同厂商的，我现在能记得的有、、搜狐畅游等，其实是当时找到一个规律，上图中腾讯云的这个也属于这个规律，所以就专门提出来。
登录和注册是大部分网站的必备功能，而不知道大家有没有注意到一个细节，当你在未登录状态下访问一些需要需要登录态的页面，比如个人中心，他会自动跳转到登录或者注册页面要求你登录，然后这个时候的登录其实会带有一个跳转，这是为了方便你登录后直接跳转到你原来访问的页面，是一个比较好的用户体验的设计。
在使用这样的功能的时候，我直接手上尝试，直接把跳转的修改为我的博客链接，然后再登录，发现可以直接跳转到我的博客，于是我再尝试了，发现代码可以直接执行并弹了个框。这个功能的设计其实原来是进行站内的跳转，但是由于功能设计上的缺陷，没有对跳转的进行判断或者判断有问题，于是可以导致直接跳转到其他网站或者产生。当然，不止是登录，注册功能也存在同样问题。当时我去测试了很多网站，发现很多网站就存在这样的问题，于是我才可以做到连续去挖不同网站的漏洞来收集公仔，就是用了同样的一个问题。
=
=
而整体的测试流程大概是这样的：

号里的秘密

这是之前腾讯云官网的一个 

这是之前微信国外版官网的一处  

这是之前域下的一个 ，这里应该是实现一个页面访问来源统计的功能，将拼接到通过加载的方式发起请求以此向服务端发送访问来源，黑客可以构造地址为 = 的页面点击链接跳转到 ，就可以触发。

这是比较早提交的一个游戏的 ，这处的正好当时保存下，如下，读取然后写入到为的标签代码里，于是导致的产生。
 =
    =
     {
            
         = 
    }

这类都是 ， 不同于其他类型的，的产生是由于页面中的代码在页面渲染完成后通过读取等内容修改页面树而产生的。
其实不难可以发现，这类在大部分情况下也是有一些技巧可言的，比如大家可以发现网址中都存在 不是一定得存在，只是这种情况比较常见；那么是不是见到网址中存在就可以随便去修改后面的内容就一通呢？当然不是，还需要去判断页面的源码中的代码以及页面引用的文件的代码中是否存在对以下内容的使用，是否存在没有过滤或者过滤不全的情况下将以下的内容直接输入到树里。





被改变的内容

 一旦有存在以上的情况，那么往往存在 的概率就比较大，接下来就是看看能不能绕过相关的过滤和安全机制的处理。
这是之前挖的一个存在于以前 版本的网页预览功能的一个；通过在聊天窗口分享文章，然后点击链接会在右侧打开页面显示文章的内容，会导致的产生。

为什么在客户端里也会存在其实很多客户端，包括现在很多手机，很多功能都是通过内嵌网页进行实现的，于是也就为什么会存在等前端问题。这些网页可以通过设置代理的方式来发现。


这是一篇发表在博客园的文章，文章里包含一些的攻击代码，但是可以发现代码在博客园本身已经被进行了转义，没法产生。

而文章被在中预览的时候，可以发现，被转义的攻击代码又转义了回来因为这个功能需要只显示文本内容，而删除一些没必要的页面框架、内容的显示，所有对内容有做了一些转码等操作，导致的攻击代码的生效，并由此产生了其实这类叫做，突变型。

这是一篇发表在微信公众号的文章，文章中包含了一些盲打后面会进行介绍的攻击代码，然后可以看到，在微信公众号文章里代码被进行了转义，而无法生效产生。

是一个第三方网站，会主动采集微信公众号上的一些文章并生成访问链接和索引，可以看到同样的一篇文章在被传送门采集转载后，本来会被转义的代码直接生效了，于是就成为了存储型，我们通过盲打平台也可以看到其他用户访问这篇文章而被采集并发送到盲打平台的。

有的时候，被转义的内容也会成为生效的攻击代码，通过控制源头的方式也可以使得的攻击产生。
随手进行的盲打

这是我盲打平台项目的其中一页结果截图，这里的每一项都包含对应网址访问用户的，而则可以用来直接登录对应的地址；在图里包含了 、游戏客服、新浪邮箱等几个网站的后台的，不过可惜的是，由于这些平台进行了访问限制，所以外网无法访问，也无法登录。
抛开无法访问的问题，那么这些信息是怎么得来了呢？盲打。

常规的攻击是通过页面返回内容中攻击代码的生效与否来判断的攻击是否成功；而对于一些网页功能，比如反馈，我们可以发现，不管你提交什么内容，返回的内容都是感谢您的反馈类似的语句，并不会根据你提交的内容而在页面中显示不同的内容，对于这样的内容提交点，就无法通过页面反馈判断攻击代码是否注入成功，那么就可以通过盲打。
盲打一般通过盲打平台，在盲打平台建立项目，会生成项目攻击链接，实际上就是一个类似文件的访问链接，这个文件中其中至少包含一个功能，那就是向盲打平台发送请求传输数据回来，比如，这样的话，类似在反馈页面提交的攻击代码一旦生效，就等于代码被执行，那么就会向盲打平台返回数据，那就说明攻击成功了；假如一直没有返回数据，那就说明提交的攻击代码没有执行或者执行出问题，也就证明攻击失败。
盲打平台的项目：

对于我而言，看到类似下图这样一个内容提交的地方，我都会忍不住提交盲打代码
 =

而类似于这样的功能，如果存在，一般会在什么地方什么时候出发攻击代码呢？管理人员在后台审核这些内容的时候，所以说一般盲打如果成功，往往可以获得对应功能管理后台的地址以及管理员的，假如管理后台没有做访问的限制，就能用对应管理员的登录上去。

这就是上图手游客服中心盲打成功得到的后台地址和当前已失效并修复。
总结
在的世界里有很多的技巧和方式，学会从正常功能中发现攻击方式，在安全的世界里，除了技术，还需要猥琐的思维和技巧。
另外，其实大家不难发现，不管是昵称、网址跳转或者是文章提到的内容转义的变化也好，很多时候内容原有的地方并不会触发，而内容在其他地方使用后则就触发了，所以对于开发人员来说，不管是来自哪里的内容，都应该有自己的过滤机制，而不能完全的信任，其实总结一句话就是：任何的输入都是有害的！

相关推荐：成勒索新目标，数据服务基线安全问题迫在眉睫一篇文章带你看懂信息泄露事件作者：

前言
长久以来 都有损坏问题，从、等移动系统，到、 等桌面系统都会出现。由于微信所有消息都保存在，服务端不保留备份，一旦损坏将导致用户消息被清空，显然不能接受。
我们即将开源的移动数据库组件   ，致力于解决  损坏导致数据丢失的问题。
之前一篇文章《微信  数据库修复实践》介绍了微信对数据库修复以及降低损坏率的实践， 这次再深入介绍一下微信数据库修复的具体方案和发展历程。
我们的需求
具体来说，微信需要一套满足以下条件的恢复方案：

恢复成功率高。 由于牵涉到用户核心数据，“姑且一试”的方案是不够的，虽说  成功率不太现实，但  甚至  以上的成功率才是我们想要的。

支持加密。  端微信客户端使用的是加密  ，加密会改变信息 的排布，往往对密文一个字节的改动就能使解密后一大片数据变得面目全非。这对于数据恢复 不是什么好消息，我们的方案必须应对这种情况。

能处理超大的数据量。 经过统计分析，个别重度用户大小已经超过，恢复方案 必须在如此大的数据量下面保证不掉链子。

不影响体验。 统计发现只有万分之一不到的用户会发生损坏，如果恢复方案 需要事先准备比如备份，它必须对用户不可见，不能为了极个别牺牲全体用户的体验。


经过多年的不断改进，微信先后采用出三套不同的恢复方案，离上面的目标已经越来越近了。
官方的恢复方案
 一下 恢复，不难搜到使用命令恢复的方法。命令的作用是将 整个数据库的内容输出为很多  语句，只要对空  执行这些语句就能得到一个一样的 。
命令原理很简单：每个 都有一个_表，里面保存着全部 和的信息本身的信息，不包括里面的数据哦，遍历它就可以得到所有表的名称和   的语句，输出 语句，接着使用    通过表名遍历整个表，每读出一行就输出一个语句，遍历完后就把整个   出来了。 这样的操作，和普通查表是一样的，遇到损坏一样会返回_，我们忽略掉损坏错误， 继续遍历下个表，最终可以把所有没损坏的表以及损坏了的表的前半部分读取出来。将 出来的语句逐行执行，最终可以得到一个等效的新。由于直接跑在上层，所以天然 就支持加密，不需要额外处理。
图：输出样例
这个方案不需要任何准备，只有坏的用户要花好几分钟跑恢复，大部分用户是不感知的。 数据量大小，主要影响恢复需要的临时空间：先要保存 出来的的空间，这个 大概一倍大小，还要另外一倍 大小来新建 恢复。至于我们最关心的成功率呢？上线后，成功率约为。这个成功率的定义是至少恢复了一条记录，也就是说一大半用户 一条都恢复不成功！
研究一下就发现，恢复失败的用户，原因都是_表读不出来，特别是第一页损坏， 会导致后续所有内容无法读出，那就完全不能恢复了。恢复率这么低的尴尬状况维持了好久， 其他方案才渐渐露出水面。
备份恢复方案
损坏的数据无法修复，最直观的解决方案就是备份，于是备份恢复方案被提上日程了。备份恢复这个 方案思路简单， 也有不少备份机制可以使用，具体是：

拷贝： 不能再直白的方式。由于 本身是文件主   或 ， 直接把文件复制就能达到备份的目的。

： 上一个恢复方案用到的命令的本来目的。在完好的时候执行， 把 所有内容输出为 语句，达到备份目的，恢复的时候执行即可。

 ： 自身提供的一套备份机制，按  为单位复制到新 ， 支持热备份。


这么多的方案孰优孰劣？作为一个移动，我们关心的无非就是 备份大小、备份性能、 恢复性能 几个指标。微信作为一个重度使用者，备份大小和备份性能是主要关注点， 原本用户就可能有 大的 ，如果备份数据本身也有 大小，用户想必不会接受； 性能则主要影响体验和备份成功率，作为用户不感知的功能，占用太多系统资源造成卡顿 是不行的，备份耗时越久，被系统杀死等意外事件发生的概率也越高。
对以上方案做简单测试后，备份方案也就基本定下了。测试用的大小约 ， 数据条目数大约为 万条：
图：备选方案性能对比
可以看出，比较折中的选择是   压缩，备份大小具有明显优势，备份性能尚可， 恢复性能较差但由于需要恢复的场景较少，算是可以接受的短板。
微信在  方案上再加以优化，由于格式化语句输出耗时较长，因此使用了自定义 的二进制格式承载输出。第二耗时的压缩操作则放到别的线程同时进行，在双核以上的环境 基本可以做到无额外时间消耗。由于数据保密需要，二进制数据也做了加密处理。 采用自定义二进制格式还有一个好处是，恢复的时候不需要重复的编译语句，编译一次就可以 插入整个表的数据了，恢复性能也有一定提升。优化后的方案比原始的  压缩， 每秒备份行数提升了 ，每秒恢复行数也提升了 。
图： 性能优化效果
即使优化后的方案，对于特大备份也是耗时耗电，对于移动来说，可能未必有这样的机会 做这样重度的操作，或者频繁备份会导致卡顿，这也是需要开发者衡量的。比如微信会 选择在 充电并灭屏 时进行备份，若备份过程中退出以上状态，备份会中止，等待下次机会。
备份方案上线后，恢复成功率达到，但有部分重度用户损坏时，由于备份耗时太久， 始终没有成功，而对数据丢失更为敏感的也恰恰是这些用户，于是新方案应运而生。
解析恢复方案
备份方案的高消耗迫使我们从另外的方案考虑，于是我们再次把注意力放在之前的方案。  方案本质上是尝试从坏里读出信息，这个尝试一般来说会出现两种结果：

的基本格式仍然健在，但个别数据损坏，读到损坏的地方返回_错误， 但已读到的数据得以恢复。

基本格式丢失文件头或_损坏，获取有哪些表的时候就返回_， 根本没法恢复。


第一种可以算是预期行为，毕竟没有损坏的数据能 部分恢复。从之前的数据看， 不少用户遇到的是第二种情况，这种有没挽救的余地呢？
要回答这个问题，先得搞清楚_是什么。它是一个每个 都有的特殊的表， 无论是查看官方文档  ，还是执行语句    _，都可得知这个系统表保存以下信息： 表名、类型、 创建此表索引的语句，以及表的。_的表名、表结构都是固定的， 由文件格式定义， 固定为  。
图：_表
正常情况下， 引擎打开后首次使用，需要先遍历_，并将里面保存的语句再解析一遍， 保存在内存中供后续编译语句时使用。假如_损坏了无法解析，“恢复”这种走正常 流程的方法，自然会卡在第一步了。为了让_受损的也能打开，需要想办法绕过引擎的逻辑。 由于引擎初始化逻辑比较复杂，为了避免副作用，没有采用的方式复用其逻辑，而是决定仿造一个只可以 读取数据的最小化系统。
虽然仿造最小化系统可以跳过很多正确性校验，但_里保存的信息对恢复来说也是十分重要的， 特别是，因为它是表对应的结构的根节点所在地，没有了它我们甚至不知道从哪里开始解析对应的表。
_信息量比较小，而且只有改变了表结构的时候例如执行了 、 等语句才会改变，因此对它进行备份成本是非常低的，一般手机典型只需要几毫秒到数十毫秒即可完成，一致性也容易保证， 只需要执行了上述语句的时候重新备份一次即可。有了备份，我们的逻辑可以在读取自带的_失败的时候 使用备份的信息来代替。
初始化的问题除了文件头和_完整性外，还有加密。加密数据库，对应的恢复逻辑还需要加上 解密逻辑。按照的实现，加密 是按 进行包括头部的完整加密，所用的密钥是根据用户输入的原始密码和 创建 时随机生成的  运算后得出的。可以猜想得到，如果保存错了，将没有办法得出之前加密用的密钥， 导致所有都无法读出了。由于 是创建时随机生成，后续不再修改，将它纳入到备份的范围内即可。
到此，初始化必须的数据就保证了，可以仿造读取逻辑了。我们常规使用的读取的方法包括方式恢复， 都是通过执行语句实现的，这牵涉到系统最复杂的子系统——执行引擎。我们的恢复任务只需要遍历所有节点， 读出数据即可完成，不需要复杂的查询逻辑，因此最复杂的引擎可以省略。同时，因为我们的系统是只读的， 写入恢复数据到新  只要直接调用  接口即可，因而可以省略同样比较复杂的平衡、和同步等逻辑。 最后恢复用的最小系统只需要：

读取部分的接口，或者直接用的、的也可以

的解密逻辑

解析逻辑


即可实现。
图：最小化系统
   详细描述了文件格式， 参照之实现解析可读取  。加密  情况较为复杂，幸好 加密部分可以单独抽出，直接套用其解密逻辑。
实现了上面的逻辑，就能读出的数据进行恢复了，但还有一个小插曲。我们知道，使用查询一个表， 每一行的列数都是一致的，这是层面保证的。但是在的下面一层——层，没有这个保证。 的每一行或者说每个、每个可以有不同的列数，一般来说，插入一行时， 里面的列数和实际表的列数是一致的。但是当对一个表进行了   操作， 整个表都增加了一列，但已经存在的行实际上没有做改动，还是维持原来的列数。 当查询到 前的行，缺少的列会自动用默认值补全。恢复的时候，也需要做同样的判断和支持， 否则会出现缺列而无法插入到新的。
解析方案上线后，成功率约为。这个成功率计算方法为恢复成功的  数除以总  数。 由于是我们自己的系统，可以得知总  数，使用恢复  数比例的计算方法比人数更能反映真实情况。 解析好处是准备成本较低，不需要经常更新备份，对大部分表比较少的应用备份开销也小到几乎可以忽略， 成功恢复后能还原损坏时最新的数据，不受备份时限影响。 坏处是，和一样，如果损坏到表的中间部分，比如非叶子节点，将导致后续数据无法读出。
不同方案的组合
由于解析恢复原理和备份恢复不同，失败场景也有差别，可以两种手段混合使用覆盖更多损坏场景。 微信的数据库中，有部分数据是临时或者可从服务端拉取的，这部分数据可以选择不修复，有些数据是不可恢复或者 恢复成本高的，就需要修复了。
如果修复过程一路都是成功的，那无疑使用解析修复效果要好于备份恢复。备份恢复由于存在 时效性，总有部分最新的记录会丢掉，解析修复由于直接基于损坏来操作，不存在时效性问题。 假如损坏部分位于不需要修复的部分，解析修复有可能不发生任何错误而完成。
若修复过程遇到错误，则很可能是需要修复的损坏了，这会导致需要修复的表发生部分或全部缺失。 这个时候再使用备份修复，能挽救一些缺失的部分。
最早的修复，场景已经基本被解析修复覆盖了，若修复不成功，恢复也很有可能不会成功。 即便如此，假如上面的所有尝试都失败，最后还是会尝试恢复。
图： 恢复方案组合
上面说的三种修复方法，原理上只涉及到文件格式以及基本的文件系统，是跨平台的。 实际操作上，各个平台可以利用各自的特性做策略上的调整，比如  系统使用  在充电灭屏状态下备份。
我们的组件
   ，微信的移动数据库组件，包含上面几种修复方案， 以及加密、连接池并发、、性能优化等特性，将在近日开源，欢迎关注。

本文来源于： 微信公众号

相关推荐
微信移动端数据库组件系列：基础篇一微信移动端数据库组件系列：原理篇三微信移动端数据库组件系列：  特性篇四  的简介
 是一个开源的针对批量数据和流数据的处理引擎，已经发展为的顶级项目之一。 的核心是在数据流上提供了数据分发、通信、具备容错的分布式计算。同时， 在流处理引擎上构建了批处理引擎，原生支持了迭代计算、内存管理和程序优化。
的技术栈：

的主要：

 ， 对静态数据进行批处理操作，将静态数据抽象成分布式的数据集，用户可以方便地使用提供的各种操作符对分布式数据集进行处理，支持、和。

 ，对数据流进行流处理操作，将流式的数据抽象成分布式的数据流，用户可以方便地对分布式数据流进行各种操作，支持和。

 ，对结构化数据进行查询操作，将结构化数据抽象成关系表，并通过类的对关系表进行各种查询操作，支持和。


此外，还针对特定的应用领域提供了领域库，例如：

 ，的机器学习库，提供了机器学习 并实现了多种机器学习算法。

，的图计算库，提供了图计算的相关及多种图计算算法实现。


的部署方式：

本地模式
集群模式或集群
云集群部署

另外，也可以方便地和生态圈中其他项目集成，例如可以读取存储在或中的静态数据，以作为流式的数据源，直接重用或代码，或是通过申请集群资源等。
  的架构

当集群启动后，首先会启动一个和一个或多个的 。由提交任务给，再调度任务到各个去执行，然后将心跳和统计信息汇报给 。之间以流的形式进行数据的传输。上述三者均为独立的进程。

：提交的客户端，可以是运行在任何机器上与环境连通即可

：系统的协调者，负责任务的排定分配、快照协调、失败恢复控制等，有三种部署模式：单机、一主多备集群、集群

：负责具体数据分析任务的执行，主要有业务数据的计算、传输等，相对于的把内存交给管理，的还自己管理了部分内存

：运行中固定大小的资源子集，一个中有多少个意味着可以执行多少个


：执行组件，即业务计算的执行实体

 运行例子
使用的自带例子 ，这是一个从字符串数组读取句子计算每个单词出现次数的例子。
、启动
、运行  
、执行完之后查看统计结果 
、那么我们访问可以查看到此的执行计划


 ：收据数据源，当前是从字符串数数组里面读取
 ：把每一条句子分隔成一个个的单词，设置每个单词的出现次数为，并提交到下游
 ：对每个单词进行聚合统计，统计每个单词的出现次数
 ：输出统计结果

代码：
       {

           
           = 

             
           = 

               
        

           
         
          {
                    
             = 
        }  {
                   
                 
                 
             = 
        }

           =
                 
         
                    
                

          
          {
            
        }  {
                     
            
        }

          
         
    }
  兼容 
考虑到业界当前主流的流式处理引擎为 ，为了更好的与业界衔接，在流处理上对是做了兼容，通过复用代码的方式即可实现在运行环境的执行，这个也大大降低了使用者过渡到的难度；同理也可以运行我们数平的。
、先来对比一下  与 的异同：


与 相比， 少了一层节点管理器，直接由主控节点管理
在流处理这一块， 与 从运行实体到任务组件，基本上能一一对应

、由上可得，虽然两者运行实体的结构及代码有一定的差别，但归根到底两者运行的都是有向无环图，所以从的相关类转换成执行的相关类是可以作转换的。以下是粗略的转换过程：       
、举个例子：已有，需要提交到集群，那么只需下面几行代码
   = 构造的
  =  
 ， 
    
  把的转换成再提交前言
 是腾讯内部最大的离线处理平台，也是国内最大的  集群之一。在运营这么大集群的时候，运营面临各种各样的难题，在解决这些难题的过程中，团队提炼出来的一个运营理念，用两句话去描述。

用建模的思路去解决运营的难题运营的问题怎么解决？你必须用一些数据建模的办法，把这个难题解析清楚，然后我们再去考虑运营平台建设。
运营平台支撑模型运作不是为了建设运营平台而建设，而是它必须有一定的运营理念。下文写到这样的运营理念是怎么贯穿在迁移平台的建设里面的。

本文主题主要包含以下几个方面：、介绍一下腾讯大规模集群 ，以及为什么做迁移。、迁移模型是怎么样的。、迁移平台是怎么做的。
腾讯大规模集群
先介绍一下腾讯大规模集群，我们这里讲的集群是指 。 是腾讯分布式数据仓库，它是一个海量数据存储和计算平台。为什么说是大规模集群？记得刚开始接手  运营的时候，很多年前，当时我们有台的集群，觉得我们集群已经很大了，但是过了几年之后，我们要运营的集群已经达到台。现在看来台还算挺大的，但是又过了几年后，我们规模到了台，这是我们的现状。我们的现状可以用三个指标来描述：、单集群  台、支撑每天  扫描量、同时提供  存储能力所以我们说是“大”，用苹果一句话说，  ，我们预计到年底我们规模会达到万台。
运营这么大规模的集群，运营人员自然会面临很多挑战。比如像设备运维、版本上线变更、配置管理、还有快速扩容等等。这些问题，我们都有相应系统去支撑，本文说的是我们遇到的另外一个头痛的问题：集群不断膨胀，从台到台，前期可以通过扩容解决。到目前这个阶段，台之后，我们发现扩容已经搞不定了。为什么？因为现有机房的容量和网络架构只能支撑这么大的规模，这时候我们需要将  迁移到其他城市更大容量的机房，这也就是我们面临的另一个问题，跨城迁移。
上文说了  的迁移原因，现在回过头来看  的整体架构。 是腾讯大数据的处理平台的一部分，整个腾讯大数据处理平台包含了下面五层。我们从下往上看：、最底层是数据存储层，包括 、、、；、第二层是资源调度层；、第三层是计算引擎层，包括 、 和 ；、第四层是计算框架，包括 、、、、 等；、最上层是服务层，提供给外部数据分析能力和机器学习能力。
这是整个腾讯大数据平台，刚才说的  覆盖了其中离线数据处理的部分。我们整个迁移覆盖了 、盖娅、、、、 和 。
迁移模型是怎么样的
跨城数据迁移到底难在哪里？首先，运维工作量非常大。有上百的数据要腾挪，有几十万任务需要切换，还有近万台的设备需要搬迁，这个事情对于运维来说工作量非常大。其次，要保障业务无感知。迁移过程中系统要稳定可用，要保障数据不能丢失，不能把一份数据从一个地方搬迁到另外一个地方的时候，把数据弄丢了。最后，要保障任务的计算结果准确而且任务的运行时长不能有明显的波动。不管是运维工作量大还是业务无感知，这都还不是最致命的，对于跨城迁移来说，最致命的问题是：当数据和计算分散在两个城市的时候，数据穿越可能造成专线阻塞，从而影响使用专线的所有系统，导致影响扩大化。在介绍跨城迁移模型之前，我们先简单介绍两个方案，一个是双集群方案，一个是单集群方案。
方案一：双集群方案双集群方案比较好理解，左侧跟右侧是两个城市的集群，双集群方案就是两套完全独立的系统，让它们独立去跑。在说方案之前，我再深入介绍一下  里面的几个模块。我们只看左边就可以了。左边从下面最底层是 ， 负责资源调度。中间最左侧是数据采集 ，它负责把各个业务线数据收集到 。 的核心是计算引擎和存储引擎，存储引擎是放数据的地方，计算引擎提供  和  的计算能力。之上有查询引擎，最上面提供两个用户入口，任务统一调度和集成开发环境 。
举两个例子来说说各模块是怎么交互的。
案例一，数据是怎么进入  的？首先业务数据经过数据采集模块，落地到存储引擎的某个目录下；统一任务调度  配置的一个入库任务，与  交互，将目录的数据转换成  表的数据。
案例二，数据是怎么计算的？数据计算通过任务触发，任务是对数据的处理加工，比如统计日报的时候，计算任务对某个表做操作，把结果写回到另一个表中。迁移是把存储和计算整套  平台，从一个城市搬迁到另外一个城市，双集群方案思路就很简单，在另外一个城市把所有系统都搭起来，跑起来就好了。系统在两个城市之间是完全独立的，比如数据两份，计算两份，在这两个独立的系统之间不需要有任何的数据穿越除了在迁移本身的数据穿越。这个方案最大优点就是不需要数据穿越，业务可以做到完全无影响，但是它最大缺点是需要大量的冗余设备。
方案二：单集群方案下面讲一下单集群方案，它跟双集群差异点在哪里？最核心的差别在于：存储不会同时在两个地方，要么在左边，要么在右边。单集群方案有一个最大的优点就是不需要大量的设备，慢慢地把一部分设备，一部分业务，从左边迁移到右边。这里会面临一个问题，比如刚才说到的一个计算的场景，如果没有控制好的话，会出现计算在左侧，数据已经跑到右侧去了，因为数据只有一份。任务跑起来的时候，左侧的计算引擎就会大量拉取右侧的数据，会对专线造成很大的风险。
对比一下刚才那两个方案，我们可以总结一下思路：在一个大的系统里，如果优先考虑成本，建议采用单集群方案。单集群方案最大风险是跨城流量控制，跨城流量控制最重要的点是：数据在哪里，计算就去哪里，要不然就是穿越；如果访问的数据两边都有，哪边数据量大，计算就在哪边。
建立基于关系链的迁移模型前面我们分析了一下我们实现跨城迁移的问题和方案，接下来我们为了解决跨城的流量控制降低跨城迁移的流量，我们引入一个基于关系链的迁移模型。我们需要知道数据流是怎么样来的，比如上面的一个关系链中，入库任务对最顶层的  数据做一些加工处理，处理之后把结果保存到入库表；分析人员基于这个入库表做各种计算和统计分析，比如统计某些指标，做关联性分析，这里配置了四个任务，这四个任务运行后产生新的结果表，其中还有两个结果表由下层的任务做进一步的处理，这样就产生了数据和任务的关系链。引入关系链模型，它能帮助我们理清楚数据和任务的关系。我们用椭圆描述数据，矩形描述对数据的加工，他们的连线表明访问数据的方向，是读还是写。这个关系可以用来指导我们的数据迁移，可以做到数据在哪里，计算就在哪里。
关系链的生成接着的问题是在一个大的系统里关系链怎么生成？在任务调度里面有一个概念，叫做依赖，用来描述任务的父子关系，父任务运行完成后子任务才允许运行。原来我们没有做关系链的时候，这是纯粹的任务调度层的关系，虽然它有一定指导作用，但是不能直接应用在迁移里面，因为我们需要的是数据和任务的关系，而不仅是任务和任务的关系，我们需要从庞大的任务管理系统生成关系链，来指导数据迁移。
接下来介绍一个叫  的运营工具，它是用做什么的？它会把我们跑的任务信息采集回来，把它保存在  里面，这些信息用于定位  失败原因或性能分析。它有一个主控模块，每五分钟去所有的  采集每个  的配置和运行信息，比如说它的访问数据是什么，输出结果是什么。为了支持迁移，我们改了一些逻辑，让  记录数据路径和任务，同时区分标识是读的还是写的。把这个数据采集出来以后，我们就可以做关系链的分析。这里面采集到的路径会非常多，比如一个日报可能访问的是昨天某一个表的数据，比如访问量，就需要访问昨天的分区。采集出来的数据路径粒度非常细，它是包含日期的。但是我们关注点并不需要到分区，我们关注的是表本身。所以我们把涉及到日期相关的路径规约掉，转成与日期无关的路径，数据规约对关系链分析有好处，归完之后减少了很多的数据量。我们把最基础的信息采集到，它描述了一个任务，访问什么数据，产生什么数据。经过我们的逻辑采集完之后，我们得到的是最原子的数据访问关系，就是一个任务对存储的操作，读或者是写，我们会产生非常多这样的原子关系，这种关系累计的结果就是关系链。我们清洗出来一个最基础的关系，可以拼凑成一个大的关系链。
切分大关系链关系链里面特别注意的地方，是一定要覆盖全面。统计分析里不仅有日报，还有周报和月报，统计周期一定要覆盖较长的时间范围，这样才能把所有关系描述准确。从最基础的原子关系聚合成关系链，可以用并查集算法。聚合出来的关系链，有大有小。对于小的关系链，很简单就可以把它迁走；但是我们发现一个很头痛的问题，聚合除了产生很多小的关系链，同时也产生了少量非常大的关系链，一个大的关系链可能包括超过十万个结点。这时候我们发现回到原点，本来想把整个数据仓库从一个城市挪到另外一个城市，思路是将它打散生成多个关系链，最后也确实产生一些小的关系链，方便我们做迁移。但是遗留了一些大的关系链。如果看这个图我们自然而然想：既然这么大的关系链迁不动，就先迁上面部分，这里就是把大的关系链切开的想法。我们引入一些关键结点，这些关键点把大的关系链切分成多个小关系链。那么哪个关系链结点才是最合适的？这个也很难找，大家可以想理论上是存在的，比如从图中标红色部分一刀切过去就可以一分为二，但是在上十万结点规模的关系链里是很难做到这个事情的。
引入双写表把这个问题先留在后面，我们先做一个假设，已经找到合适的结点了，怎么实施关键结点的迁移，有两种思路：一种是单份数据方案，比如把这份数据迁到另外一个城市，就让它穿越，很容易实现，但是不好控制流量；另一种是双份数据方案，把关系链一分为二的时候，就把关键结点的数据变成两份。我们引入双写表的概念，双写表有两个 。双写表的数据有两份，在城市访问数据的时候，城市 的  会返到主的 ，城市则返回备的 ，计算可以访问离自己近的存储。这里，需要一个任务把城市的数据同步到城市中，这是一个同步任务，这个任务在数据在城市生成后总有个计算任务往里面写数据，把城市的数据同步到城市，保证两边的数据是一致的。在迁移过程中把一个表升级成双写表的过程业务是无感知的，我们有机制保证数据双份，就近访问。
数据一致性保证刚才说到双写表在城市和城市有两份数据，由同步任务负责同步，这时候我们会遇到一个问题，在城市和城市，它的下游任务会不会在同步任务没跑完之前就去访问这个数据？我们必须要保证数据的一致性，这通过增加对同步任务的依赖实现。比如任务产生数据表，下面三个任务会读取表数据，这个依赖关系是上面这个任务是父任务，只有这个父任务跑完之后，下面三个子任务才能跑起来。这个依赖逻辑保证了三个子任务总能正确访问表的数据。加入了同步任务之后，我们就保证了数据的一致性。比如这个图里，我们有两个任务从城市迁到城市，这时候我们要保持数据和计算的一致性，只需要保证城市访问表数据的任务依赖同步任务即可。
最小化切分和关系链融合回到一个大的关系链怎么拆分的问题，假设已经把它拆开了。拆开的时候产生了很多小的关系链，把小的关系链从一个城市迁移到另外一个城市的时候，为了减少数据穿量引入双写表的概念，双写表加上任务依赖，保证了所有拆分出来的关系链有一个比较非常好的特性，就是不管产生多少个关系链，每个关系链都是随时可以迁移的。还有一个问题：我们很难找到合适的关键点，对一个十万节点关系链，我们做了一些尝试，用遍历的方式查找所有可行的双写表，都不能把这么大的关系链拆开，我们发现不存在单个双写表可以拆开这么复杂的关系链。
大家可以想象一下，一个很复杂的图里面可能找不到一个结点能够将它切分成多个关系链。单个双写表做不到，则需要使用多个双写表，这时候找出合适双写表的算法就会非常复杂。后来我们做了一个变通，让所有符合双写表规则的表都变成双写表，这样可以实现对一个大关系链的最小化拆分。之后我们对最小化拆分后的小关系链又做了融合，把很小的关系链并成规模适中的关系链。
这里面整体的思路，类似于工厂流水线打包，我们把关系链聚合，再把它拆分融合，变成一个个大小适中的关系链，就像工厂打包的一个个箱子，迁移就是把这些箱从从城市运输到城市的过程。
计算的迁移我再补充一下计算的迁移，刚才上面架构里面，说计算需要从城市迁移城市，怎么切呢？我们对每个任务加上城市  的扩展参数，当这个任务需要从城市切到城市跑的时候，只需要改这个参数就好了。平台会记录城市 ，并在不同系统上传递，进行准确的路由，这样实现任务是方便迁移的。再总结一下迁移模型，我们面临运营上很头疼的事情，要做跨城迁移，我们解决的方案是基于关系链，把关系链打散，通过机制保证关系链的一致性，使得我们迁移能够跑起来。
相关推荐鹅厂上万节点大规模集群的跨城自动迁移下
注：本篇内容来自”腾讯技术工程官方号“，公众号：有没有设想过，生活中突然多了个孩子会是什么体验？少女辣妈？人生巅峰？多了个玩具

   ï，历劫回归的  编辑注：作者陈湘玲的英文名告诉大家，现实是：产检一大早排队、一大堆证件要办、十级阵痛的煎熬、奶妈无证上岗的各种疼与累…

如何更科学应对人生新阶段？这些日子我到底经历了什么？又跟算法有什么联系？请听我徐徐道来。
一．孕期

 证件办理 — 法则
 月～ 月期间，我前后奔跑拿下了这些证书：商品房买卖合同书、结婚证、准生证、户口本。为啥会如此奔波呢？
其实在确认怀孕后，一般程序都是准备办理准生证了，办理准生证本身就很麻烦，作为一个持有广州集体户口的人来说这事就更复杂。

要办理准生证，通过一系列的推理，当前我的目标就是要先买房。我给自己定的  是一个半月时不我待啊要  周建档了，也就是一个半月内我需要买到房子并且已经到房管局做好备案，那么我最迟一个月内就要挑中房子签好购房合同。白天还要上班，那么多的房子需要去看，挑战这么大，我要怎么办？

法则 — 专治选择困难症

法则：又名未婚妻问题，是指在  个候选中只能选一个，不能回头反悔的前提下，抛弃前 个在后 个候选中选取第一个比前  个候选好的。
推导原理详见：死理性派恋爱法：拒绝掉前面的人，适用于恋爱、购物等场景，屡试不爽。
那用在买房的需求上，就是可以这么操作：在第一阶段，我只看不买，就是根据自己的购买能力，了解一下市场上哪些房子我喜欢，哪些我不喜欢，记住在这个阶段内我看到过的最满意的那个房子。 等到过了 这个时间点之后 ，我就进入第二阶段，从这天开始，一旦遇到一个比第一阶段那个最好的房子好，或者类似的房子，就毫不犹豫地买下来。
根据这个法则，我们需要先定义好的概念，对我来说好的房子满足以下条件：
软条件：布局、房间数、朝向、方位
硬条件：业主可以尽快过户或直接看一手房
根据这个法则，我顺利地在  天后找到合适的房子，买了下来。于是证件问题就陆续解决了。
日常产检 — 作业调度算法
只要去过医院的人都知道，每次都是等、等、等。不同孕周的产检项如下图所示，整个怀孕过程产检次数不低于  次。

若每次都是等个大半天到一天才产检完，那么我用于产检的总时间就相当于  天了！不得了啊，一是作为孕妇很疲惫，二是影响上班和其他安排。于是在第三次产检第，我就开始思考：怎么样才能让自己的产检更快完成？

  作业调度算法  专治任务管理问题

产检的本质，就是作业调度，选  周为例子，要做的产检项那么多，也就是要执行的进程有这么多个的时候，如何使用调度算法来达到最优？     
我们先细化下每个产检项所需的时间和优先级，优先级按照是否必须预约或开单来定。



产检项
所需时间
优先级
备注




 超大排畸
约 

 超都是当次预约生效，错过这次就得重新预约


测体重


无需开单，随时可进行


测血压


无需开单，随时可进行


测宫高腹围


需要医生开单


多普勒胎心


需要医生开单



 注：每个项目都包含了该项目的排队时间。
根据长期探索， 根据所在的南医三院的情况， 了一个算法组合：拆分任务 定优先级 短作业优先算法，来达到产检最高效率。
拆分任务
首先把上述产检项，能细化步骤的进行拆分蓝色部分为拆分出来的步骤：



产检项
所需时间
优先级
备注




 超大排畸


 超都是当次预约生效，错过这次就得重新预约


拿  超报告单


报告单一般需要  出


问医生结果


包含排队时间，查看结果一般要等前面就诊的人先完成


测体重


无需开单，随时可进行


测血压


无需开单，随时可进行


测宫高腹围


需要医生开单


多普勒胎心


需要医生开单



调度算法选择
①　 先来先服务——适用于长作业
先来先服务    是最简单的调度算法，按先后顺序进行调度。
定义：按照作业提交或进程变为就绪状态的先后次序，分派 ；当前作业或进程占用 ，直到执行完或阻塞，才出让 非抢占方式。在作业或进程唤醒后如  完成，并不立即恢复执行，通常等到当前作业或进程出让 。

②　 短作业优先 — 适用于短作业
短作业优先   又称为短进程优先  ；这是对  算法的改进，其目标是减少平均周转时间。
定义：对预计执行时间短的作业进程优先分派处理机。通常后来的短作业不抢先正在执行的作业。
由于产检的长作业相对比较少一般  个，短作业比较多，所以我用  为主算法来执行产检流程。
拆分任务 定优先级 短作业优先算法组合
目前已完成了拆分任务，定优先级和了解了短作业优先算法，如何结合使用呢？
首先，按照优先级排列当前任务：

其次，到达的同个优先级的事项，把执行时间短的提前：

根据这个原则，把无效的等待时间都灵活安排起来，极大提高了我的产检效率，从原来的  天到最后的 ，都有赖于调度算法的改良使用。
生育知识学习 —  速读法
刚知道怀孕那会，特兴奋，一口气把畅销榜前十名的孕教育儿书给买了。但是真正开看的时候开始犯愁了。这么多书都写了这类内容，看一本的时间很长，很容易忘记，要怎么看书才合适？

 速读法 — 专治海量阅读问题

在这里介绍个  速读法。

于是我从中得到的读书笔记如下图所示，也方便我对同类内容做对比：

物资准备 — 复用经验数据库 关联规则挖掘法
随着分娩的临近，需要开始准备待产包和婴儿用品了。该怎么去罗列这些物资呢？

复用经验数据库 — 专治分类问题

复用经验数据库，简单来讲，就是询问他人的物资清单，先罗列出一批物资分类。

利用关联规则挖掘法 — 专治迷茫剁手党

什么是关联规则挖掘技术？
关联规则挖掘的根本目的是寻找商品销售记录中的相关性，从而更好地指导销售策略的制定。一个典型的规则是：购买了雀巢速溶咖啡的顾客都会购买雀巢咖啡伴侣。基于这个规则，在实体超市中，应当把这两种产品放到相近的地方，而在网上超市中，如果顾客购买了雀巢速溶咖啡却没有购买咖啡伴侣，则可以在关联商品栏目中添加相应的推荐。现在很多企业已经认识到详细的原始购买记录的重要性，并且建立了规范的数据仓库，这些都为关联规则挖掘技术的应用奠定了良好的基础。
在借鉴别人经验，罗列出初步的物资分类后，具体物资要买哪个型号，或者是否需要做物资补充，可以上熟悉的购物网站，利用当前的关联规则挖掘方案，来补全：

根据上述方法，我的物资准备清单就完成了！需要详细清单可以私聊找我拿。

二．分娩期

怀胎十月，总算快到了瓜熟蒂落的阶段。需要如何做准备才能心中有数呢？根据经验，这个阶段最重要的是做到这两点：风险评估。
风险评估 — 启发式风险模型

启发式风险模型 — 专治万一问题

启发式方法指人在解决问题时所采取的一种根据经验规则进行发现的方法。其特点是在解决问题时利用过去的经验选择已经行之有效的方法，而不是系统地、以确定的步骤去寻求答案。这个方法可以追溯到希腊的哲学家，是   在由他所写的著名的《如何解答它》一书中引进的。启发式的推理不仅仅是关注结果的和严谨的，而仅仅是临时的和不严谨的，它的目的是发现当前问题的解决方法。
启发式的方法常常出现在诸如自由问答、建议，或者向导中。
那跟分娩有啥联系呢？我们可以用万一来理解这种模型。
√ 确定性：万一我在上班时发动了？
√ 可靠性：万一发动时交通阻塞了？
√ 可用性：万一医院没床位？
√ 通用性：万一待产包不在身上？

基于启发式风险模型，我给自己准备了一个分娩代办事项 ：




事项




预产期前两周
确认住院必须的证件已放在包内



将入院必须带的物品放在包里



把放置包的位置告诉家人



准备好出院时需要的大人和宝宝的用品



确认到医院的最佳路线



有人陪同的情况下行动，一有动静马上到医院报到。
三．哺乳期

费尽九牛二虎之力，总算跨过鬼门关成功当了妈。本来以为可以好好踹口气，谁知新问接踵而至：
产后涨奶怎么办？
宝宝一直哭不睡啊怎么办？
坐月子是吃补还是不吃补？
坐月子能不能洗头？

于是这个时期，咱们的关键任务有两个修身齐家、新手上路。
修身齐家 — 控制变量对比法
这里的修身齐家，指的是养好身体坐好月子，并且保持稳定和谐的家庭关系。但是问题来了，娃不睡觉啊我要怎么修身齐家？
在这里，介绍一个控制变量对比法给大家。

控制变量对比法 — 专治找问题根因

控制变量对比法：对于多因素多变量的问题，常常采用控制因素变量的方法，把多因素的问题变成多个单因素的问题，而只改变其中的某一个因素，从而研究这个因素对事物影响，分别加以研究，最后再综合解决，这种方法叫控制变量法。它是科学探究中的重要思想方法，广泛地运用在各种科学探索和科学实验研究之中。
针对孩子不睡问题，我们选出可能的几个变量：吃饱程度、睡眠方式、环境舒适度。
要找出是哪个环节让他睡得不够好，我们采用一晚换一个变量，其余变量不变的方式。



序号
变量
结果





吃饱程度：喂得更久更饱
吐得厉害，毫无睡意，失败



睡眠方式：安抚奶嘴
几分钟就吐出来，失败



环境舒适度：洗屁股后才喂奶
醒的很少， 次变成  次，成功



经过控制变量法，我们知道是睡觉时环境舒适度不够引起的起床频繁，于是后续都在睡前把屁股洗干净、尿布换好，慢慢变成一晚只醒来一次的天使宝宝，测试通过。
新手上路 — 颠覆三观的  理论
世上有一个职业永远不用实习，在你不一定准备好的情况下就得上岗，那就是新手父母。
到底月子要怎么坐？该怎么抱孩子怎么给孩子洗澡？好焦虑。
这个时候，不妨试一下  理论。

 小时理论 — 快速上手一门技能

掌握一门技能需要多久呢？
答案是， 小时就够了。人的学习先后快慢， 小时性价比最高，足够使你上手一门技能。
 小时理论其实是你需要花  小时才能做到极致，做到行业顶尖，后来却被理解成需要花  小时去学习。而学习时间和学习效果有边际效用递减的关系。 通过实践，发现：你想学什么技能，只要你有规划，用心思的投入  小时左右去学，你会被自己的表现震惊的。

 小时让你快速上手新手父母要做的事，怎么进行？

抓住最重要的内容来学习：哺乳、坐月子饮食、抱孩子姿势、给娃洗澡的方法。

专业书籍只看要学的那部分内容；

排除干扰，精心学习：每天保证  小时认真学习和练习，累计  小时，足以掌握一门技能。


就这样，我慢慢从新手变成了可以一个人搞定娃的超人妈咪，还可以带娃之余顺便做家务看电视。
四．结语
上述就是我从怀孕到产检大概一年半时间里的所思所实践，未来学习的路还很漫长，我也非常享受当下的感觉。万事都有规律可循，我很享受工作所用的思路用于生活的方法挖掘。而且我也明白，方法不是人人适用，但是思路可以互相交流参考，于是记录下这篇不像孕期攻略的算法应用攻略，望君笑纳。作者：林泽水 

导语
是苹果在 上推出的新一代组件，用以替代中笨重难用、内存泄漏的 拥有滚动刷新率、和相同的引擎。简单的适配方法就不细说了，本文主要讲述适配过程中填过的坑以及善待解决的技术难题。
、白屏问题
自诩拥有更快的加载速度，更低的内存占用，但实际上是一个多进程组件， 以及 在其它进程中执行。初次适配的时候，我们也惊讶于打开后，进程内存消耗反而大幅下降，但是仔细观察会发现， 的内存占用会增加。
在一些用渲染的复杂页面，使用总体的内存占用      不见得比少很多。在上当内存占用太大的时候， 会；而在上当总体的内存占用比较大的时候， 会，从而出现白屏现象。在中加载下面的测试链接可以稳定重现白屏现象
这个时候会变为 简单的刷新操作已经失效，对于一些长驻的页面影响比较大。我们最后的解决方案是：
、借助
 以后新增了一个回调函数：
   _ 当总体内存占用过大，页面即将白屏的时候，系统会调用上面的回调函数，我们在该函数里执行  这个时候取值尚不为解决白屏问题。在一些高内存消耗的页面可能会频繁刷新当前页面，侧也要做相应的适配操作。
、检测是否为空
并不是所有页面白屏的时候都会调用上面的回调函数，比如，最近遇到在一个高内存消耗的页面上系统相机，拍照完毕后返回原来页面的时候出现白屏现象拍照过程消耗了大量内存，导致内存紧张， 被系统挂起，但上面的回调函数并没有被调用。在白屏的时候，另一种现象是会被置空 因此可以在的时候检测是否为空来页面。综合以上两种方法可以解决绝大多数的白屏问题。
、 问题
问题是目前的一大短板
、 存储
业界普遍认为拥有自己的私有存储，不会将存入到标准的容器中。实践发现实例其实也会将存储于中，但存储时机有延迟，在上，当页面跳转的时候，当前页面的会写入中，而上，执行或服务器注入的会很快同步到中，工程师曾建议通过 来触发同步到中实践发现不起作用，并可能会引发当前页面 丢失等问题。 问题在于发起的请求不会自动带上存储于容器中的。比如，中存储了一个 ====     ，通过发起请求，则请求头会自动带上=； 而通过发起请求 ，请求头不会自动带上=。
、
苹果开发者文档对的定义是：          通过让所有共享同一个实例，可以实现多个之间共享数据。不过 实例在杀进程重启后会被重置，导致中的、 数据丢失，目前也无法实现实例本地化保存。
、
空间的许多业务都依赖于作登录态校验，而上请求不会自动携带 目前的主要解决方案是：
、 前，在 中设置 解决首个请求带不上的问题；
   =   
   =    
 =  
 
、通过设置解决后续页面同域、请求的问题；
注意：无法跨域设置
  =   
   =     = =   
 
这种方案无法解决请求的问题，比如，第一个请求是 我们通过在 里带上解决该请求的问题，接着页面跳转到 这个时候 这个请求就可能因为没有携带而无法访问。当然，由于每一次页面跳转前都会调用回调函数：
      
可以在该回调函数里拦截请求，在 中带上并重新。不过这种方法依然解决不了页面跨域请求的问题，毕竟 只适合加载请求。
、 问题
在独立于进程之外的进程中执行网络请求，请求数据不经过主进程，因此，在上直接使用无法拦截请求。苹果开源的源码暴露了私有：
  通过注册 后将可以使用拦截请求：
  = ” 
  =  
   { 
            注册  把 和请求交给 处理 
              
              
}
但是这种方案目前存在两个严重缺陷：
、请求数据被清空
由于在独立进程里执行网络请求。一旦注册 后，网络请求将从 发送到 ，才能拦截网络请求。在的设计里使用进行进程之间的通信， 会将请求成一个然后通过发送给 。出于性能的原因，的时候和这两个字段被丢弃掉了参考苹果源码：
 及  _=。
因此，如果通过注册了  那么由发起的所有请求都会通过传给主进程处理，导致请求被清空；
、对支持不足
测试发现一旦打开开关：   选项设置为，同时通过注册了 ，发起的所有网络请求将被阻塞即便将      选项设置为；
可以注册 比如 因此希望使用离线功能又不使用方式的请求可以通过发起请求，比如， 然后在进程拦截这个请求并加载离线数据。该方案目前在空间动感影集上实践成功。不足：使用方式的请求该方案依然不适用，同时需要侧修改请求以及规则；
最近了解到浏览器团队已经解决了 导致请求丢失的问题，并封装在了中，也是强大！
、 问题
在上通过发起的请求数据会丢失：
同样是由于多进程间通信性能问题，导致字段被丢弃
 
  
  
 假如想通过 加载请求  可以通过以下步骤实现：

替换请求，生成新的请求  同时将的字段复制到的中
通过 加载新的请求
通过  注册 
使用拦截请求 替换请求 生成新的请求  ，将 的字段复制到的中，并通过加载，最后将加载结果返回

、 页面样式问题
在适配过程中，我们发现部分页面元素位置向下偏移或被拉伸变形，追踪后发现主要是页面高度值异常导致：
 空间页面有透明导航、透明导航下拉刷新、全屏等需求，因此之前整个是从开始布局，通过调整来适配特殊导航栏要求。而在上对的调整会反馈到的变化上，比如设置 = 那么的值会增加导致页面长度增加，页面元素位置向下偏移；解决方案是调整布局方式，避免调整。实际上，即便在上也不建议调整的值，这确实会带来一些奇怪的问题。如果某些特殊情况下非得调整不可的话，可以通过下面方式让页面恢复正常显示：
设置值后通过调整让页面恢复正常显示 
 参考：
  
 =     
 =      
 在接入直播的时候，我们发现在上会出现页面被拉伸变形的情况，最后发现是值不准确导致在上返回了一个非常大的值，而同学通过获取来设置页面高度，导致页面整体被拉伸。通过查阅相关资料，这个只在的几个系统版本上出现，苹果后来了这个。我们最后的解决方案是：延迟调用
{ = }
   
 = == = = = =
、 截屏问题
空间玩吧小游戏有截屏分享的功能，下通过  实现截屏的方式失效，需要通过以下方式实现截屏功能：
   
  { 
     
       
      =  
     
      
} 

然而这种方式依然解决不了页面的截屏问题，笔者已经翻遍苹果文档，研究过各种源码里的截屏私有，依然没有找到合适的解决方案，同时发现以及这两个全量切换到的浏览器也存在同样的问题：对页面的截屏结果不是空白就是纯黑图片。无奈之下，我们只能约定一个接口，让游戏开发商实现该接口，具体是通过 方法取得图片数据后返回格式的数据，客户端在需要截图的时候，调用这个接口获取 并转换成。
、 问题
放量后，外网新增了一些 其中一类主要堆栈如下：
 
      
     
   _____   
        
主要是调用函数引起的，从堆栈可以看出是回调函数
           没有执行导致的。在适配的时候，我们需要自己实现该回调函数，才能调起框，我们最初的实现是这样的：
         
{ 
      =     
      确认    {  } 
       {} 
}
如果退出的时候，刚好执行了 框可能弹不出来，最后没有被执行，导致；另一种情况是在一打开，就执行，这个时候由于所在进入或的动画尚未结束，框可能弹不出来，最后没有被执行，导致。我们最终的实现大致是这样的：
         
{ 
              { 
         
         
    } 
      =     
      确认    {  } 
          
           {} 
     
         
}
确保上面两种情况下都能被执行，消除了下弹框的，下弹框的原因与解决方式与类似。
另一个发生在退出前调用  执行代码的情况下。退出并被释放后导致变成野指针，而此时 还在执行代码，待 执行完毕后会执行，导致。这个只发生在系统上，参考  ，在及以后系统苹果已经修复了这个主要是对 做了 ； 对于系统，可以通过在里 防止被过早释放。我们最后用 了这个系统方法：
   
{ 
      _   
} 
 
             
  
       
{ 
      =  
          { 
          
          { 
              
        } 
    } 
}
、其它问题
、视频自动播放
需要通过设置是否允许自动播放，但一定要在初始化之前设置，在初始化之后设置无效。
、 问题
上调用   回退到上一个页面后不会触发函数、不会执行。
、结语
本文总结了那些年和导师一起填过的的坑。虽然坑比较多，但是相对在内存消耗、稳定性方面还是有很大的优势。尽管苹果对的开发进度过于缓慢，但相信才是未来。—   新特性