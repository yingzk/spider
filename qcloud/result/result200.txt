背景：
随着游戏娱乐等直播业务的增长，在移动端观看直播的需求也日益迫切。但是移动端原生的播放器对各种直播流的支持却不是很好。 原生的  不支持 、 直播流， 只支持标准的  流。本文介绍一种基于  框架下的跨平台播放器的实现，且兼顾硬解码的实现。
播放器原理：
直观的讲，我们播放一个媒体文件一般需要个基本模块，按层级顺序：文件读取模块、解复用模块、视频频解码模块、色彩空间转换模块  、音视频渲染模块。数据的流向如下图所示，其中  框架包含了文件读取、音视频解复用的模块。


文件读取模块的作用是为下级解复用模块以包的形式源源不断的提供数据流对于下一级的来说，本地文件和网络数据是一样的。在框架中，文件读取模块可分为层：

协议层： ，，，等这些具体的本地文件或网络协议
抽象层：结构来统一表示底层具体的本地文件或网络协议
接口层用：结构来扩展结构成内部有缓冲机制的广泛意义上的文件，并且仅仅由最上层用对模块外提供服务，实现读媒体文件功能。


解复用模块：的作用是识别文件类型，媒体类型，分离出音频、视频、字幕原始数据流，打上时戳信息后传给下级的视频频解码模块。可以简单的分为两层，底层是 ，， 等等这些具体媒体的解复用结构和相关的基础程序，上层是  结构和相关的程序。上下层之间由  相对应的  结构的 _ 字段关联  或  或  等等具体的文件格式。 和具体的音视频编码算法格式由  结构的  字段关联媒体格式， 相当于  的  ，解复用模块分离音视频裸数据通过  传递给下级音视频解码器。

视频频解码模块的作用就是解码数据包，并且把同步时钟信息传递下去。

色彩空间转换模块  颜色空间转换过滤器的作用是把视频解码器解码出来的数据转换成当前显示系统支持的颜色格式

音视频渲染模块的作用就是在适当的时间渲染相应的媒体，对视频媒体就是直接显示图像，对音频就是播放声音


跨平台实现
在播放器得个模块中文件读取模块、解复用模块和色彩空间转换模块  这三个模块都可以用  的框架进行实现，而  本身就是跨平台的。因此，实现跨平台的播放器的就需要抽象一层平台无关的音视频解码、渲染接口。、、 等平台只需要实现各自平台的渲染、硬件解码如果支持的话就可以构建一个标准的基于  的播放器了。
下图是基于的基本播放流程图：

图中红色部分是需要抽象的接口的，结构如下：

其中 __ 视频解码线程，默认有  的软解码实现，其他平台可以增加自己的硬解码实现。_ 为视频渲染抽象层，这里  可以是 的 ，或者是  的 。_ 是音频播放抽象层，可以直接操作声卡驱动， 里就支持 、 接口，当然也可以用 、   中的音频  实现。
这里顺便提下，随着 、 平台的普及， 版本的也逐步支持了 、 的硬件解码器，如  在很早之前就支持了 ，最新的  也已经支持了  的硬件解码库 。从下面重点介绍下视频硬解码以及音视频渲染模块在移动平台上的实现。

硬解码模块：
 的硬解码模块目前有  种实现方案：
_：
 是  之后版本的多媒体库， 早在  版本时就已经将_ 收录到自己的解码库中了，从  包括的头文件路径来看，是基于  版本的源码。因此编译  需要  的相关源码以及动态链接库。
 中的  目前只实现了  格式的解码，由于  机型、版本的碎片化相当严重，这种基于某个  版本编译出来的  也存在很严重的兼容性问题，我在  的机型上就遇到无法解码的问题。
：
 是  在 以后新提供的硬件编解码 ，其工作原理如图所示：

以解码为例，先从  获取 ，将待解码数据填充到 ，再将  交给，接下来就可以从  的  中拿到新鲜出炉的图像和声音信息了。下面的这段实例代码也许更能说明问题：
  = 
  …
   =    
 
   {
     = 
     =  {
       = …
          
     …
      …
   }
     = …
     =  {
       = 
       =    
          
             
     …
      …
   }    == ___ {
            
          
      =    
   }
 }
 
 
令人沮丧的是， 只提供了  层的 ，而我们的播放器是基于  架构的，核心的解码模块是不可能移到  层的。既然我们移不上去，就只能把  拉到  层了，通过  的方式将  相关的  在  层做了一套接口。嗯，现在我们可以来实现视频的硬件解码了：

_ 的实现如下图所示：

视频渲染模块：
在渲染之前，我们必须先指定一个渲染的画布，在上这个画布可以是，，或者是。
关于在层渲染图片的方法，我曾看过一篇文章，文中介绍了四种渲染方法：

  
   
  
  

如果是用  的  进行软解码，那么使用    将是最高效简单的方案，主要实现代码：
  = _ 

_ 
 _   ==  {
         
  _
}

_
示例代码中的  来自  层的 ， 指向  图像数据。
如果是使用了  进行解码，那么视频渲染将变得异常简单，只需在  配置时指定图像渲染的 ，然后再解码完每一帧图像的时候调用   ， 内部就会将图像渲染到指定的  上。
音频播放模块
 支持  套音频接口，分别是  和  ，这里以  为例介绍下音频的部分流程：
由于  只有  层的 ，我们也得像  一样在  层重做一套  的接口。

这里解码和播放是  个独立的线程， 负责从    中获取解码后的音频数据，如果解码后的音频采样率不是  所支持的，就需要用  进行重采样。

 硬解码模块
从  开始，开放了硬解码和硬编码 ，就是名为  的 ，支持  的硬件编解码，不过需要   及以上的版本才能使用。这套硬解码  是几个纯  函数，在任何  或者  代码里都可以使用。首先要把  添加到工程里，并且包含以下头文件。

解码主要需要以下四个函数：

                 创建解码
    解码一个
             解码完一个后的回调
          销毁解码

解码流程如图所示：

 视频渲染模块
视频的渲染采用   纹理贴图的形式。
 音频播放模块
采用  的  进行播放。数据流程和  平台是相同，不同的是， 平台把  数据喂给 ， 上把  数据喂给 。
总结
其实  自带的播放器实例  就是一个跨平台的播放器，得益于其依赖的多媒体库  实现了多平台的音视频渲染。但是  库过于庞大，并不适合整体移植到移动端。本文介绍的跨平台实现方案也是借鉴了  的内部实现，只是重新设计了渲染接口。



相关推荐
零基础读懂视频播放器控制原理——播放器源代码分析
【腾讯云的种玩法】  整合微视频上传管理能力，轻松打造视频后台导语：对于服务端来说，异步处理相比同步处理在性能上可能会有成倍的提高，本篇就对的异步处理进行一个简单的分析。描述客户端进行异步调用之后，的都进行了哪些的处理。

本文主要是项目在架构升级异步的时候，时不时出现死锁现象，因此想了解一下异步处理的时候线程执行逻辑是什么，最后看完了，发现和  无关。
本文介绍基于  协议的异步调用， 和  的也基本类似。异步调用是通过 _ 接口，调用时需要传递一个异步回调对象。通过定义  协议， 自带工具是可以自动生成相应的异步调用的接口实现。代码如下：
 _      
        {   
                 _
                _  
                  _
                __ _  _ 
        }
在该方法中，通过调用父类  的 __ 方法进入异步处理。在 __ 中初始化请求的消息体 ，设定请求类型为异步、设定异步回调的对象 在异步处理结束之后，调用该  的方法，初始化其他相应必要信息，然后调用 。无论是同步还是异步调用，最后都是会调用  方法。
在  方法中会根据同步、异步还是协程进行不同的处理。对于异步调用，还会根据是否开启协程来进行不同的处理，这里分析的是不开启协程的情况下的异步调用逻辑。在  方法中把请求都会添加到  的监听事件中，设置相应的 。代码如下：
_  这里的  就是包含了上一个方法中初始化的 
 _   
{  
        因为初次发起该请求，所以  位置肯定是不合法，进入  生成一个新的元素
        _
        {
                __ _ 
                _ == 
        }
        
        {
                 _ = __
                _=
                _ = _
                _ = 
                _
                _=
                __ _ 
        }
}
加入  监听事件之后，接下来的逻辑就出现了同步异步的区别：对于同步调用会有一个  一直等待直到调用返回；而对于异步调用则会在添加监听之后直接返回。无论是同步还是异步调用都是在  轮询，发现事件  调用方法处理。下面就是删除了不必要代码之后轮询执行逻辑，如下：   
 
{
         _
       = 
        _ = _

         _
        {
                考虑到检测超时等的情况 这里默认就  吧
                          = __
                           =       
                        {
                                 _  = _
                                _  = 
                                 ==    非指针 退出循环
                                 
                        }
                          
                        
        }
}
    _ 
{
                __ == 
                {
                          =
                           = 
                         _
                         {
                                        
                         }
                }
                
                {  
                            
                       =   
                          
                     {  
                                  
                        }
                }   
}
事件  之后的调用  方法。在  方法中会根据具体的事件类型执行不同的逻辑。根据上面  方法中添加事件代码，当发起异步调用的时候设定的  类型，进入 __ 分支。调用逻辑是通过  中调用 ，最后的逻辑执行是在  中。
在  中 ，首先检查当前队列大小，如果大于最大值，则调用  方法后直接返回；否则把数据交给网络传输_ 发送数据。无论是否发送成功，都会把请求加入_ 队列等待处理。此时你调用的接口刚把数据发送出去，然后  继续在后台监听。
   
{
         _ = _
        {
     = _
                
                 
        }
        生成   调用 而且 不是单向调用
        
        {
                 = _
        }
        _

        交给连接发送数据 发送数据成功
        _
                 __ = 
        {
                 == _
                {
                         
                         
                }

                  = _     
    
    {
         = _
        
    }
        }
        
        {
                  = _   
    
    {  
                                 = _
                    
    }
        }
         
}
 的  方法在上面已经有简单说明，定期检查监听的套接字，事件  之后，调用  方法处理事件，判断事件发生的类型。上面数据在_ 发送成功之后，调用的接口处理完成会发送回包，然后  监听事件  继续调用  方法，这次发现是数据进来的事件调用  接受数据。
   
{
        
        {
                  = 
                _  = __
                  _ _ _  ==  || 
                {
                        
                        
                        
                }
                
        }

         
          
        {
                  = 
                   =    
                {
                        
                }
        }
}
无论是同步还是异步请求，请求处理最后都是回到了  的方法 。对于同步则是会唤醒之前的 ，通知处理结束；对于异步则是把请求处理结果塞回异步处理线程中的队列，异步处理线程一直监听自己任务队列，发现有任务则取出消息体进行处理。
需要注意的是在向异步线程任务队列  任务的时候是平均分配的，没有考虑每个异步处理线程的负载，也不考虑是那个业务线程  进来的意思是同样一个业务线程接受到请求，可能一直是同一个异步处理线程处理，也可能多个异步线程同时处理来自同一个业务线程的请求。我们遇到的多线程数据共享的问题就是来自于这里，看完源码才想通。
   
{
         == _
        {
                 
                 
        }
         上报调用统计  
        
         == _
        {
                 ， 
                 
        }
         == _
        {
    
    {
        
        {
            如果是本线程的回调，直接本线程处理，比如获取 
              = 
            
        }
        
        {
            异步回调，放入回调处理线程中
            _
        }
    }
    
    {
        开启协程
    }
        }
        
}
通过阅读异步处理线程可以发现，处理逻辑是调用消息体里的回调对象的  方法，而该回调对象则是你最初进行异步调用的时候传递进去的。对于  则会根据你定义的异步对象的不同执行逻辑也不同。
 
{
         _
        {
                  
                异步请求回来的响应包处理
                _
                {
                        _ 
                        
                }

                 __
                {
                        从回调对象把线程私有数据传递到回调线程中
                           = 
                        
            {
                                _ _  _
            }
              = 
            
                }
        }
}
这样整个异步处理逻辑就结束了。
如果你业务需要调用另外一个服务的时候，那么使用异步会很明显提升性能的。主线程接受到请求之后执行一些业务必要逻辑处理就调用异步处理直接返回了，比较耗时网络  和之后的处理都放在了异步处理线程，主线程可以解放出来继续接受接下来的链接。作者：

 引子
作为安全的一部分，近年来安全事件层出不穷，而其中的攻击事件更加普遍，越来越成为移动互联网时代手机用户的一大痛点。请看以下一个安全事件。
君从广州到上海出差，在星巴克买了一杯咖啡，坐在门口连上某个热点的正在浏览一个网站，发现这个网站需要邮箱注册，注册后发现需要登录邮箱激活。于是君这打开了邮箱大师上的。
图 用户登录邮箱使用场景
输入了账号和密码，点击登录，登录成功没有问题。可是过一会，重新登录这个邮箱，发现登录不上去了。很明显，用户的账号和密码是他在喝咖啡的时候被盗取的并且被瞬间修改了。那密码究竟是怎么被盗取的呢？
其中一种可能的原因是用户连接的遭受攻击了。
如果我们产品要做一个功能，要求能够检测出这种攻击，在用户连接的时候能第一时间给予提示，让用户免遭损失。针对这样的安全方面的测试需求，我们应该如何测试呢？
 安全测试的难点
针对中的产品需求，要想测试好，有以下测试难点：
● 安全攻击原理认知缺乏：
对攻击的原理不清楚，对产品检测的逻辑也不清楚；
● 安全测试经验缺乏：
这类安全方面的功能点没有测试过，不好下手；
● 测试策略难以制定：
在理清攻击原理和测试目标的前提下，应该如何设计测试策略，能更高效地完成测试任务？
● 测试环境缺乏：
不知道怎么搭建测试环境？怎么评估搭建的测试环境是否满足测试需求
 难点突破
针对章节提到的测试难点，下面咱们来一一对症下药，各个击破。
　安全攻击原理认知缺乏——攻击原理剖析
先了解一下原理：某机器要向网关发送报文，会查询本地的缓存表对于系统就是，找到网关的地址对应的地址后，就会进行数据传输。如果未找到，则广播一个请求报文，网关识别到是自己的地址，于是向主机发回一个 。其中就包含有网关的地址，接收到网关的应答后，就会更新本地的缓存表。接着使用这个地址发送数据。
协议的原理存在一个可以被利用的漏洞：当没有发起 时，其他人也可向发送一个 。当收到一个 时，不会质疑，而是直接对本地的缓存表进行更新，将应答中的和地址存储在缓存表中。
因此，当局域网中的某台机器向发送一个自己伪造的 ，即地址为网关的，而地址是的，则当收到后就会更新本地的缓存表，这样本来要发给网关的内容就会发给了。同理，也可以用同样的方式对网关进行欺骗。在和网关之间作为中间人，而和完全不知道。
假设一个只有三台电脑组成的局域网，该局域网由交换机连接。其中一个电脑名叫，代表攻击方；一台电脑叫，代表源主机，即发送数据的电脑；令一台电脑名叫，代表目的主机，即接收数据的电脑这里的电脑其实也可以换成智能手机，所以如下图中用了电脑手机表示这个网络节点。这三台电脑的地址分别为，，。地址分别为_，_，_。其网络拓扑环境如图。
图： 欺骗网络拓补图
现在，电脑要给电脑发送数据了，在电脑内部，上层的和的数据包已经传送到了最底层的网络接口层，数据包即将要发送出去，但这时还不知道目的主机电脑的地址－。这时候，电脑要先查询自身的缓存表，查看里面是否有这台电脑的地址，如果有，那很好办，就将封装在数据包的外面。直接发送出去即可。如果没有，这时电脑要向全网络发送一个广播包，大声询问：我的是，硬件地址是－，我想知道地址为的主机的硬件地址是多少？
这时，全网络的电脑都收到该广播包了，包括电脑和电脑。电脑一看其要查询的地址不是自己的，就将该数据包丢弃不予理会。而电脑一看 地址是自己的，则回答电脑：―我的地址是，我的硬件地址是_。
需要注意的是，这条信息是单独回答的，即电脑单独向电脑发送的，并非刚才的广播。现在电脑已经知道目的电脑的地址了，它可以将要发送的数据包上贴上目的地址，发送出去了。同时它还会动态更新自身的缓存表，将_这一条记录添加进去，这样，等电脑下次再给电脑发送数据的时候，就不用大声询问发送广播包了。这就是正常情况下的数据包发送过程。
总结来说，这个通信过程分为以下四步。
主机   查询自己的缓存表，确认是否的记录存在；
主机  发一个请求的广播包，询问跟关联的地址是多少；
主机   发一个回复包，告知我的地址是，地址是；
主机   更新自己的缓存表，下次要发包给的时候直接发给。
  安全测试经验缺乏——攻击测试建模
针对如上攻击的原理，假如我们要测试一个能检测出以上攻击的功能，怎么办呢？首先，基于的模型，可以将攻击检测功能的三要素定义如下，说白了是要明确测试目标。
：
，准确：在有和无攻击时能准确检测出有和无攻击；
，通用： 不管有没有用户，都能满足。
：
——图 检测功能子模块——
矩阵
——表 检测功能矩阵——
  测试策略难以制定——攻击测试策略
通过对章节对测试目标的确定，借用领域的安全分析方法，我们可以画出攻击功能的软件失效故障树  如下：
故障定义：没有达到中的目标，我们用“检测功能失效”来统称。
图  检测功能故障树
由上图可见，每个条件判断都是一个逻辑或，我们认为检测失效、或者检测展示失效，或者日志上报失效都可以导致检测功能失效，所以对每个失效路径，我们可以快速得到核心用例路径如下：
表 由故障树导出核心用例
  测试环境缺乏——测试环境搭建
对于安全测试，和普通业务功能测试的最大的区别是安全测试对测试环境要求很高，所以往往测试环境的准备成为整个安全测试最难的也是最耗时的点。
那应该怎么准备测试环境呢？
 攻击环境准备
设备环境：
：一台装有无线网卡
手机：作为热点手机华为， 
手机被测手机：连接，用来查看缓存表，确认攻击成功， ，安装有腾讯手机管家。
手机：用户手机，通过连上热点，然后登陆邮箱操作三星， 

环境准备步骤：
： 上安装无线网卡驱动，确保网卡能用；
：上安装攻击软件，见附录；
：手机开设一个热点，如热点名为
 手机、和都连上该热点。
 网络拓补图
经过章节中后，可以通过查看的，如本次实例为。

可以通过 查看的，如：。

由此我们可以得到整个攻击环境的网络拓扑图如下：

图中，攻击确认手机也就是被测对象，由于我们的测试目标是腾讯手机管家的检测攻击的能力，所以这台手机要装上腾讯手机管家。
  攻击制造
 攻击前表检查
攻击前先检测手机表如下可以看到 列没有出现两个同样的地址，说明当前网络没有受到攻击。

 关闭防火墙
 嗅探器打开
打开启动嗅探器

 设备扫描
扫描局域网的所有设备

直到扫描结果如下可以看到设备和章节中的网络拓补图是对应的，这里因为安装在上，而不会显示本机的，因此在这里看不出来

 攻击链路添加
切换到底部的点击菜单栏号。

在弹出的页面如下，鼠标点击页面左侧一个节点，比如 会在页面右侧出现跟该节点的同一局域网的其他节点，比如另一台手机，和网关。

点击上图右侧的网关节点，即选择了到网关的链路，点击后会跳转到以下界面，说明这条攻击链路被添加了。

 启动攻击
点击以下图中的黄色图标即可。

 攻击成功确认
上的表现：

 密码盗取
接下来我们重现下章节的用户场景：
通过这台手机假如是一台用户手机的邮箱客户端，登录一个邮箱看看。

一点击登录，回到攻击的软件界面，可以看到密码和账号直接明文显示了。是不是很震撼？

 安全探秘
通过，我们都看到密码被捕获到了，但为什么会这样子呢。下面来解释下。
在的手机，通过连接， 进去打印缓存表如下：

结合章节讲到的攻击原理，看第二条记录：攻击的是，是，说明我要发包给攻击的话，可以正常找到攻击的，这个没有问题。
但是看第三条记录：——，这说明什么呢？我们都知道我们在局域网要想访问外网的话要通过网关，说明我要访问外网的话，先发包给网关，也就是，但是由于这个缓存表记录的网关的对应的是攻击的，所以导致我发给网关的包都会跑到攻击去了。这就是为什么说登录客户端会造成密码泄露的根源。也就是章节的安全事故的根源。
  测试确认
在经过的攻击确认后，我们在被测手机，打开腾讯手机管家，连接被攻击热点，确认以下几点：
确认检测出攻击，并确认产品上能展示正确：

确认攻击上报日志正确和管家其他日志上报查询方法一样，具体不表。
其他测试路径确认方法类似，此处从略。
 安全测试小结
作为一个测试人员，在接到一个安全测试的测试需求时，应该如何下手？
本文抛砖引玉，基本可以遵循以下的思路来：

把安全原理吃透；

对测试目标进行测试建模；

有效制定测试策略；

搭建一个比较靠谱的测试环境。
这样基本就能应对安全测试的一些入门问题了。至于深度安全测试，比如出现问题时候如何定位，产品数据有问题时如何和从测试人员的角度主导或者配合开发、产品童鞋跟进解决，诸如此类的问题本文先不讲，留到后续再讨论。

相关推荐【腾讯】测试分析？就这么简单！【腾讯】不会做分析？套路走起上一篇文章我们介绍了  的安装，但  有个缺点，那就是文档不太全，用起来可能是要看源代码才能理解某个方法的含义，所以今天我们就介绍一下 ，这个由谷歌爸爸出品的深度学习框架，文档比较全～以后的我们也都使用这个框架～
 概要
是谷歌爸爸出的一个开源机器学习框架，目前已被广泛应用，谷歌爸爸出品即使性能不是最强的其实性能也不错，但绝对是用起来最方便的，毕竟谷歌有 坐镇，这波稳。
 安装
官方有一个上的安装指南，点这里我们现在就照着这个安装指南操作一把，官方推荐在中安装，我们就在安装吧，大家也可以直接安装。前几天发布版了，我们就安装版吧～
先安装下和
  _  
  _  
安装下
     
接下来 建立一个全新的  环境。这里将环境建在 目录下 执行
   
  
然后 激活 
     如果使用 
     如果使用 
  终端提示符应该发生变化如果要退出虚拟环境可以执行
 
也可以直接在里执行下面的代码激活
 
在  内 安装 因为我用的是 所以执行
     
要是使用可以执行
    
当然也可以执行下面这个命令直接安装最新版
   
等命令执行完就安装好了
安装完成后可以在中执行以下代码
   
 =  
 = 

如果输出
 
就说明安装成功啦
运行脚本的时候会提示不支持 指令集的提示，这是因为我们是通过直接安装的编译好的版本导致的，如果想针对机器优化，可以直接从上的源代码编译安装。但这样会复杂些，而且我觉得其实提升不大，用都很慢。。。不如直接上性能提升快。
如果想安装版会复杂些，首先要有一块支持的卡，再安装驱动啥的，各位看官可以谷歌一下查询相关资料。如果不想搜索，也可以看本系列后续文章，以后也会介绍如何在下安装版。
 基本使用
在介绍样例之前，我们先介绍一下的一些基本概念
占位符
 = =

              
                           
          
占位符的数据类型占位符的纬度，例如代表的二维矩阵，可以代表任意维度，例如则代表任意行数，列的二维矩阵占位符的名字
变量在定义时要初始化，但可能有些变量我们一开始定义的时候并不一定知道该变量的值，只有当真正开始运行程序的时候才由外部输入，比如我们需要训练的数据，所以就用占位符来占个位置，告诉，等到真正运行的时候再通过输入数据赋值。例如
 =   
就是生成了一个的二维矩阵，矩阵中每个元素的类型都是也就是浮点型。
有时候定义需要训练的参数时候，会定义一个__大小的矩阵，其中_数输入数据的维度，_是输出数据的维度
变量
官方说明 有些长，我就不引用啦，这里介绍一个简单的用法，有一点变量在声明的时候要有一个初始值
 =   声明一个的矩阵，并将矩阵中的所有元素的值赋为，默认每个元素都是类型的数据
 =    声明一个的变量，并将初始值设为
我们一般还需要运行下__真正在的中初始化所有变量，后面的样例中也会有体现。
常量
官方说明 同样不引用啦，这里介绍一个简单的用法
 =    定义一个值为的浮点型常量
会话
所有的操作都必须在中运行，才能真正起作用，可以将当作运行的环境，运行完需要～
用关闭
 = 



使用语句关闭
   
    
简单使用
我们介绍下应该如何在中实现
   

 =    声明一个整型变量
 =    声明一个整型变量
 =    =   
 = __  初始化变量的操作
   
       在中初始化变量
      输出计算出的值
 样例
上有一个比较好的合集，有注释有源代码还蛮好的，但今天我们不讲上面的代码，我们讲如何用实现线性回归模型。
所谓线性回归模型就是 =     的形式的表达式拟合的模型。
我们如果想通过深度学习拟合一条直线  =    应该怎么做呢？咱不讲虚的先展示下代码！然后我们在逐步分析。
=
   

 = 
 = 
 = 
_ = 

 =     

 = __
 = 
_ = 

 = 
 = __


 = 
   
     = 
     =   
     = {   _  }
    _ _=
        ==  
            
           
           
            _=
先导入需要使用的库。
=
   
毕竟是基于的，那我们肯定要导入滴，导入之后取个别名，之后用起来方便些。
定义需要的变量，我们看看 =     中都有哪些变量。
 = 
 = 
 = 
_ = 
：我们训练时需要输入的真实数据 我们需要训练的，这里我们定义了一个维的变量其实吧，就是一个普普通通的数，直接用也行并将其初值赋为  我们需要训练的，定义一个维变量，并将其初值赋为_ ：我们训练时需要输入的对应的
定义线性模型
 =     
定义损失函数和优化方法
 = __
 = 
_ = 
 =  
损失函数 是用来评估我们预测的值和真实的值之间的差距是多少，损失函数有很多种写法，我们这里使用预测真实再取平均数来作为我们的损失函数用这个函数是有原因的，因为我们用的是梯度下降法进行学习损失函数的值越小越好，有些教程也叫 
 = 
优化函数代表我们要通过什么方式去优化我们需要学习的值，这个例子里指的是和，优化函数的种类有很多，大家到官网查阅，平时我们用的比较多的是和等，这里我们选用最常用也是最最基本的梯度下降，后面传入的值是学习效率。一般是一个小于的数。越小收敛越慢，但并不是越大收敛越快哈，取值太大甚至可能不收敛了。。。
我们简单介绍下什么是梯度下降，梯度顾名思义就是函数某一点的导数，也就是该点的变化率。梯度下降则顾名思义就是沿梯度下降的方向求解极小值。
详细解释大家可以自行谷歌一下～当然可以可以看这篇文章，当然由于性能的原因梯度下降有很多种变种，例如随机梯度下降   ，小批梯度下降   。本文样例采用的是，每次只输入一个数据。
_ = 
这个代表我们每次训练迭代的目的，本例我们的目的就是尽量减小的值，也就是让损失函数的值尽量变小
变量初始化
 = 
 = __

这个之前有所介绍了，我们需要在中真正运行下__才会真正初始化变量。
开始训练
 = 
   
     = 
     =   
     = {   _  }
    _ _=
        ==  
            
           
           
            _=
我们定义一个训练迭代次数次。
这里我们图方便，每次迭代都直接将作为，作为直接当成训练数据。
我们所有通过定义的值，在训练时我们都需要通过_来传入数据。
然后我们每隔次迭代，输出一次训练结果，看看效果如何～
  
 
 
 
  
 
 
 
  
 
 
 
  
 
 
 
  
 
 
 
  
 
 
 
  
 
 
 
  
 
 
 
  
 
 
 
  
 
 
 
可以看到在迭代了次之后效果就很好了，已经达到很接近了，也达到了也比较接近了，因为这里学习率选择的比较小，所以收敛的比较慢，各位也可以尝试调大学习率，看看收敛的速度有何变化。

相关推荐
深度学习入门实战一像一样算法生成梵高风格画像深度学习入门实战三图片分类中的逻辑回归用进行手写数字识别是一个支持反射的语言，从诞生的那一刻起就已经支持了反射。经典的反射代码可以这样写：

   {
           {
          =  
            
            
            
            

         =  
                     
            
            

            
                
    }
}
  {
        { }
        { }
}
    {
        { }
        { }
}
从上述代码可以看出，可以利用反射在运行时通过名字查找方法句柄，动态调用想要的方法。同时，上面的例子中也可以发现，通过反射调用是支持多态的。
一切完美。但是从开始，中又多了一个功能类似的成员，。先来看看又是怎么用的：
   {
           {
          =  
          =   
         
          
               
                
           
           
         =    
         =         
         =         
                

           
           
         =    

         =   
          
         =   

         =    
          =  
         =    
          =   =        
    }
}

  {
         { }
         { }
        { }
        { }
}
    {
         { }
        { }
        { }
}
反射调用也是支持多态的，并且和不同的是，的成员方法要线到某个，过程中已经做了类型检查；而成员方法左值是和函数参数一起传入的。注意到比多了一个方法，它与的区别是方法参数、返回值匹配非常严格，调用时如果有数值参数隐式转换如转子类转父类、装箱拆箱，会直接抛异常。
在源码层面运行表现层面来看，两者区别并不大，那为什么会在在新引入、这个特性呢？先从字节码看一看区别：
 
   
                    
   
                    
   
                    

 
  
                    
  
                    
  
                    
  
                    
  
                    
很容易发现，不管源码长什么样子，反射调用全部都是相同的签名；而则会根据源码形参类型生成不同的字节码符号表，相当于在文件中携带了更多信息。容易想到，生成这些特化字节码需要编译器支持，而则是根据注解  做代码生成。文档中描述如下：

                                                            

简单来说就是调用标记了的方法时，不管源码传什么参数都是可以编译通过的，编译器其实不按源码中描述的方法签名生成字节码，而是参考实际传入参数的形式类型或者称为变量类型更合适生成。
在的文档描述中还有一点值得关注：的访问性检查只在创建时检查一次，而则是每次调用都检查。

                                                    
                                 

也就是说，使用时更像平时写代码，只有成员是可以访问的，、的成员只能在类内部代码才能用工厂方法访问，外部是无法生成对象的但自己创建然后泄漏出去就不怪了。而则是全局都能访问，比如我们惯用的技巧就是使用反射获取  引用。
综上，更像是在语法规则内手写字节码：自己创建方法签名，自己决定调用方式，自己注意访问控制，最后还要自己决定类型隐式转换；而权限则大得多。虽然能力相对受限，不过性能确高了很多两者的实现对比解析待续…。导语
本文主要介绍了  的基本概念以及如何使用  统计代码量，同时介绍了   这款  界面使用工具。
一、简介
 是一种分布式版本控制系统    ，简称 ，客户端并不只提取最新版本的文件快照，而是把原始的代码仓库完整地镜像下来。这么一来，任何一处协同工作用的服务器发生故障，事后都可以用任何一个镜像出来的本地仓库恢复。因为每一次的提取操作，实际上都是一次对代码仓库的完整备份。
 主要有以下几个特点： 
 、直接记录快照，而非差异比较。
 和其他版本控制系统的主要差别在于， 只关心文件数据的整体是否发生变化，而大多数其他系统则只关心文件内容的具体差异。这类系统， 等每次记录有哪些文件作了更新，以及都更新了哪些行的什么内容。 并不保存这些前后变化的差异数据。实际上， 更像是把变化的文件作快照后，记录在一个微型的文件系统中。每次提交更新时，它会纵览一遍所有文件的指纹信息并对文件作一快照，然后保存一个指向这次快照的索引。为提高性能，若文件没有变化， 不会再次保存，而只对上次保存的快照作一链接。
、近乎所有操作都是本地执行。
在  中的绝大多数操作都只需要访问本地文件和资源，不用连网。例如，如果要浏览项目的历史更新摘要， 不用跑到外面的服务器上去取数据回来，而直接从本地数据库读取后展示给你看。所以任何时候都可以马上翻阅，无需等待。
、时刻保持数据完整性。
在保存到  之前，所有数据都要进行内容的校验和计算，并将此结果作为数据的唯一标识和索引。 使用  算法计算数据的校验和，通过对文件的内容或目录的结构计算出一个  哈希值，作为指纹字符串。该字串由  个十六进制字符 及 组成。
、多数操作仅添加数据。
常用的  操作大多仅仅是把数据添加到数据库。因为任何一种不可逆的操作，比如删除数据，都会使回退或重现历史版本变得困难重重。在别的  中，若还未提交更新，就有可能丢失或者混淆一些修改的内容，但在  里，一旦提交快照之后就完全不用担心丢失数据。
综上所述  更像是个小型的文件系统，但它同时还提供了许多以此为基础的超强工具。而不只是一个简单的版本控制系统工具。
二、 的工作流程
基本的  工作流程如下：
 在工作目录中修改某些文件。
 对修改后的文件进行快照，然后保存到暂存区域。
 提交更新，将保存在暂存区域的文件快照永久转储到  目录中。
更为简洁的说明如下图所示：

对于任何一个文件，在  内都只有三种状态：已提交，已修改和已暂存。已提交表示该文件已经被安全地保存在本地数据库中了；已修改表示修改了某个文件，但还没有提交保存；已暂存表示把已修改的文件放在下次提交时要保存的清单中。
由此我们看到  管理项目时，文件流转的三个工作区域： 的工作目录，暂存区域，以及本地仓库。每个项目都有一个  目录，它是  用来保存元数据和对象数据库的地方。该目录非常重要，每次克隆镜像仓库的时候，实际拷贝的就是这个目录里面的数据。
从项目中取出某个版本的所有文件和目录，用以开始后续工作的叫做工作目录。这些文件实际上都是从  目录中的压缩对象数据库中提取出来的，接下来就可以在工作目录中对这些文件进行编辑。
所谓的暂存区域只不过是个简单的文件，一般都放在  目录中。我们可以从文件所处的位置来判断状态：如果是  目录中保存着的特定版本文件，就属于已提交状态；如果作了修改并已放入暂存区域，就属于已暂存状态；如果自上次取出后，作了修改但还没有放到暂存区域，就是已修改状态。
三、 分支
在  中，分支是一个很重要的概念。 中的分支，其实本质上仅仅是个指向  对象的可变指针。 会使用  作为分支的默认名字。在若干次提交后，提交这有一个指向最后一次提交对象的  分支，它在每次提交的时候都会自动向前移动。 是通过创建一个新的分支指针来创建分支的。
 标识你在当前哪个分支的原理是，有一个名为  的特别指针指向你当前所在的分支。该指针与其他的版本控制系统比如 里的  概念大不相同。在  中，它是一个指向你正在工作中的本地分支的指针。运行创建分支的命令，仅仅是建立了一个新的分支，但不会自动切换到这个分支中去，下图中，新建一个  分支之后，仍然在  的分支。

如果需要切换分支，需要使用命令来进行分支的切换。切换上图中的  分支，这样  就指向了  分支，如下图所示：

每次提交分支之后， 随着分支一起向前移动，如下图所示：

由于  中的分支实际上仅是一个包含所指对象校验和 个字符长度  字串的文件，所以创建和销毁一个分支就变得非常廉价。说白了，新建一个分支就是向一个文件写入  个字节外加一个换行符那么简单，当然也就很快了。
这和大多数版本控制系统形成了鲜明对比，它们管理分支大多采取备份所有项目文件到特定目录的方式，所以根据项目文件数量和大小不同，可能花费的时间也会有相当大的差别，快则几秒，慢则数分钟。而  的实现与项目复杂度无关，它永远可以在几毫秒的时间内完成分支的创建和切换。
下面以一个简单的例子来做下说明：
 开发某个网站。
 为实现某个新的需求，创建一个分支。
 在这个分支上开展工作。
假设此时，需要紧急修补一个问题，那么可以按照下面的方式处理：
 返回到原先已经发布到生产服务器上的分支。
 为这次紧急修补建立一个新分支，并在其中修复问题。
 通过测试后，回到生产服务器所在的分支，将修补分支合并进来，然后再推送到生
产服务器上。
 切换到之前实现新需求的分支，继续工作。
 的分支主要有以下几种类型：
、长期分支
长期分支一般指的是最为稳定的分支，分支内的代码一般比较老旧。一般来说，在  分支中保留完全稳定的代码，即已经发布或即将发布的代码。与此同时，一般会有一个名为  或  的平行分支，专门用于后续的开发，或仅用于稳定性测试，当该分支一旦测试过后至稳定状态，便可以把它合并到  里。
也可以把该过过程类比为流水线经过测试的提交对象集合被遴选到更稳定的流水线，如下图所示：

、特性分支
一个特性分支是指一个短期的，用来实现单一特性或与其相关工作的分支。特性分支在任何规模的项目中都可以使用。
、远程分支
远程分支是对远程仓库中的分支的索引。它们是一些无法移动的本地分支；只有在  进行网络交互时才会更新。远程分支就像是书签，提醒着你上次连接远程仓库时上面各分支的位置。
一次  克隆会建立你自己的本地分支  和远程分支 ，它们都指向  分支的最后一次提交。你在本地  分支做了些改动，与此同时，其他人向远程代码库中推送了他们的更新，那么服务器上的  分支就会向前推进，而于此同时，你在本地的提交历史正朝向不同方向发展。不过只要你不和服务器通讯，你的  指针仍然保持原位不会移动。
此时可以运行命令来同步远程服务器上的数据到本地。该命令首先找到  是哪个服务器，从上面获取你尚未拥有的数据，更新你本地的数据库，然后把  的指针移到它最新的位置上。
四、 常用命令
这里大概介绍下  的常用命令：



命令
含义




 
克隆代码  


 
添加文件分支


 
提交文件分支   


 
显示已修改的文件分支


 
查看当前分支


 
切换分支


 
推送文件分支


 
移除文件


 
移动文件


 
查看  信息


 
从代码库中拉取最近的代码



五、 统计代码
这里来说明下如何通过   的命令来统计一段时间内的代码修改量，首先说明下  是如何进行代码数量统计的，注意是有一下的四点：
、增加空白行增加换行符后，增加的行数加 。
、删除换行符后，删除的行数加 。
、修改了某一行后，增加和删除的行数同时加 
、统计的代码指标只有增加的和删除的行数，没有修改的行数，与  不一样。
接着介绍如何通过命令来实现一段时间内代码量的修改：
、首先需要将要统计代码的通过   将代码从远程代码仓库拷贝至本地：

需要注意的是，如果建立的这个代码仓库的性质为  的话，则可以直接通过   路径的方式来进行代码的克隆。如果性质为  的话，如果使用   路径的方式则需要输入用户名以及密码来进行代码克隆的操作，如下图所示：

这种方式有一种不方便的地方，在每进行一次  命令的操作的时候就需要输入用户名以及密码。
还有一种方式是可以通过   用户名 密码 路径的方式来进行代码的克隆，例如项目的  路径为：项目名称 那么使用的   的具体方式为：  用户名密码项目名称 来进行代码仓库克隆到本地的操作，如下图所示：

需要注意的是：用户名和密码是写到 之后，用户名和密码之间使用冒号隔开，密码与后面的路径之间用符号间隔。
此处就有一个需要处理的问题就是，有时可能用户的密码中有包含这个符号，那么就需要将该字符进行转译的处理，此处的相当于这个字符串。
、跳转至完成克隆的本地代码文件夹中，进行拉取最新代码的处理。
当命令行中提示代码已经克隆到本地完成之后，需要使用  命令跳转至生成的本地代码文件夹中。

需要注意的是，默认登录进来的分支是  分支，即主分支。然后在执行   指令来拉取最新的代码：

如果有更新则会直接更新，如果没有则会提示用户目前的代码已经是最新的。此处代码克隆有一点需要说明的是：对于同一个项目，他的  代码路径一旦新建之后则不会改变，此后如果需要获取最新的代码，则只需要跳转至该项目的文件夹下，执行   命令即可拉取到最新的代码。
、使用   命令拉取一段时间的代码修改量
 统计  分支的代码修改量使用   命令拉取一段时间的代码修改量的具体命令为：
  = = =  |  {  =    =    =    }  {            }
其中  和  这两个参数是用户用来设置需要统计代码量的时间范围，表示统计的时间区间为 ，此处统计的时间量为开区间，不包括  和  的量，即统计的为  这一天的量。 参数表示对输出的值进行格式的设置， 为  系统中自带的一个强大的文本分析工具，通过后面指定的方式计算出代码的增加和删除的量，同时输出到命令行中。下图中直接得到修改的值：

 统计其他分支的代码修改量
由于进入项目之后，默认进入的是  的分支，有可能会有需要统计其他的分支的情况，此时需要先进行分支的切换，然后再进行统计。
首先执行   指令来查看当前有哪些分支，命令行中给出当前项目中全部的分支，其中绿色的表示你当前所在的分支。

需要切换至其他的分支，运行   分支名 的命令，进行分支的切换，再运行   进行验证，表明分支切换成功：

此时，则与统计  的步骤一致，先执行   命令，然后再运行   的令：

最后有一点需要重点说明的是：进行使用   进行代码量统计之前，一定要先执行   的命令，确保此时本地的代码是与远程代码仓库保持一致的，然后才能确保统计的结果是准确的。
六、 常用工具介绍
这里再来介绍一款好用的  工具， ，也称为小乌龟 。小乌龟  只支持  系统 有一个前辈小乌龟   和  都是非常优秀的开源的版本库客户端 分为  位版与  位版并且支持各种语言包括简体中文  _。
通过这个链接来下载安装包进行安装，此处对于安装的过程就不详细的进行说明了，这里说明安装完成之后的一些简单的操作界面。
、克隆代码到本地
在需要保存的文件夹中点击右键，选择   的命令，点击之后，在出现的窗口中的  中填写代码仓库的地址，然后直接点击 ，则克隆命令开始执行：

下图表示克隆完成：

同时指定的文件夹中出现拷贝的代码文件夹：

进入文件夹之后，点击右键，然后选择   之后，右侧的列表中给出  不同命令。

如果需要统计代码修改量，则需要先选择 ，下图表示已经更新成功：

然后再选择  ，如下图所示：

其中第  个地方表示当前代码的分支，第  处统计的时间段，第  处表明当前时间段的修改量，第  处是查看具体统计的结果，点击之后，计算之后出现最后的修改的结果：

如果需要切换分支，则直接点击第  处的 ，然后选择分支：

回到查看  界面，则分支进行了转换：

七、总结
本篇文章主要讲了下  的一些基本的概念以及如果使用   的命令来进行一段时间段的代码量统计，其中还可以统计不同作者修改的代码量，其中关于   统计的其他的功能在这里就不细说了。同时还简单地说明小乌龟  的使用方法。笔者对于这两者的研究还在继续中，请各位大牛们多多指教。作者：陈帅
团队：腾讯移动品质中心

一、数据源
占用内存的测试，要比的更为简单。 数据来源是 。当然，首先需要了解清楚里面这些数值的含义是什么，这里不详述。
程序内存主要是两部分：和。就是我们平常说的堆，我们创建的对象是在这里面分配的，而是直接在上分配的，对于内存的限制是 不能超过最大限制，否则。

图一 信息
二、数据采集
与耗电数据的采集一致，直接继承基类，然后使用定时器来每隔秒运行一次____，调用 来获取相关内存信息。如下图中，只收集了的数据，如果要具体分析和的内存信息，也可以将其数据单独过滤出来保存。在主路径的_中调用，保证在执行 自动化场景用例时，定时器一直在收集数据，直到_调用将定时器取消。

图二内存信息收集逻辑
三、数据使用
评估一个使用场景是否存在内存泄漏，如从首页进入一个二级页面，我们只需要将这个操作封装成自动化，重复执行遍，即可获得如下数据曲线。只要数据曲线不是如下图中的灰色平缓曲线，则可以证明该场景是有内存泄漏的。

图三内存泄漏示意图
同样，如果只提供上述的曲线给开发，定位问题也会比较麻烦，测试在内存泄漏的测试中，也可以多做一些。如果是内存泄漏，也可以使用   出一份文件别忘了先手工 。

图四内存
拿到文件后，可以导入 中查看，一般查看 占用最大的类，分析是否有内存泄漏，一个对象的，指的是该对象自身占用内存的大小。一个对象的   指的是当该对象被回收时，所释放掉的内存大小。由于该对象先前可能直接或间接持有对其他多个对象的引用，那么当它自己被回收时，被它所引用的其他对象有些也可能会被回收，所以这种情况下，该对象的 既包括他自身占用内存的大小，也包括所有被它直接或间接引用的某些对象占用内存的大小。

图五使用 查看内存泄漏
 的分析不够强大，也可以借助来分析内存泄漏：更多内容参考。
在链接内容中，可以关注下相关的内容，因为在中因为内存泄漏引起一般会跟图片有关，其他对象往往没有对象大，所以解决图片相关的内存泄漏是优先级非常高的。
篇幅有限，还有很多深入的内容无法一一铺陈，后续将继续深入学习内存泄漏测试的相关内容。
搜索微信公众号：腾讯移动品质中心，获取更多测试干货！事务作为并发访问数据库一种有效工具，如果使用不当，也会引起问题。是公司内使用的主流数据库，默认事务隔离级别是可重复读。本文尝试结合解释应用开发中并发访问数据库可能会遇到的可重复读引起的问题，希望能帮助大家在开发过程中有效避免类似问题，如果老版本应用中出现这类问题也可以快速定位。由于由于历史原因，目前蓝鲸体系内大多数稳定运营的工具系统用的是中该问题最为严重，本文先对环境中的一个应用案例进行分析，说明问题产生的具体原因，然后说明如何有效避免类似问题，最后介绍较新版本中事务实现原理开始已经很好避免本文案例中的大多数情况，并提供一个中由于对事务使用不当造成的异常案例。
先看下如下这段代码在中会有什么问题：
 
     = _= _=
     = 

 _
     = 
    ____= 
        
      = __= ={ }
     

    
 ___
      = __= ={ }
     
通过链接_请求得到的结果是错误 如果开启了，则可以看到如下错误信息：
  _
      

这个执行结果有点让人吃惊，本应该返回才对。
为了快速说明该问题产生的原因，这里将请求_过程中_和后台任务___所执行的语句分别打印出来：_响应请求过程执行的：
  
  `_``_` `_``_` `_``_`  `_`  `_``_` =    `_``_`    
  `_``` `_``` `_``_` `_``_` `_``` `_``` `_``_` `_``_` `_``_` `_``_` `_``_`  `_`  `_``` =  
  `__``` `__```  `__`  `__``` =  
   `__` `` ``   
  `__``` `__```  `__`  `__``` =  
  `__``` `__```  `__`  
后台任务___执行过程中执行的语句：
  
  `__``` `__```  `__`  `__``` = 
   `__` `` ``   

  `_``` `_``_` `_``` `_``` `_``_` `_``` `_``` `_```  `_`  `_``_` = 
   `_` `_` `` `` `_` `` `` ``    ==     

结合_响应过程执行的语句来看，就比较好理解上面的错误 了。响应开始的时候 开发框架进行了一次用户登录认证，设置了为这会直接开启一个事务，这时=的记录还不存在，由于默认的事务隔离级别是可重复读因此在_整个事务期间，都找不到=的记录，所以_执行到__会尝试插入一条记录=，但是在此之前后台任务已经向数据库中插入了这个，_执行__的时候就给直接报一致性错误。
弄明白了这个异常发生的原理之后，我们可能会吓出一身冷汗，如果写个循环一直去查询数据库中任务的状态到完成状态，岂不是死循环了。在中的确是这样，因为这个问题中的框架就被提交了，遵循的是 数据库 规范 需要将初试设置为关闭状态。到了之后已经覆盖了这个默认规范并且将设置为  因此新版本的出现上述问题的概率会大大降低。
我们可能会有些相对稳定运营的在生产环境，如果真的出现了类似的问题，可以尝试从几个方面修复：调整中间件，对登录认证完成之后进行一次操作。部分因为中间件过早开启事务的情形有用，比如本文的案例。发生类似错误时，显式进行一次操作。这种解决方式比较直观，但是如果错误本身就发生在事务中则会过早提交事务。如果只是需要把记录拿出来更新，可以考虑直接写更新记录。
为了说明中事务实现机制如何与不一样，将本文开始时使用案例放在中执行，调用的如下：
  
  
  ___ = 
  
  
  ___ = 
  `_``_` `_``_` `_``_`  `_`  `_``_` =   `_``_`   
  `_``` `_``` `_``_` `_``_` `_``` `_``_` `_``_` `_``` `_``_` `_``_` `_``_`  `_`  `_``` = 
  `__``` `__```  `__`  `__``` = 
从中执行的可以看出，的默认行为是运行在自动提交模式下。任何一个查询都立即被提交到数据库中，除非显示激活一个事务。最后，只是将这种可重复读引起问题的概率降低了很多，如果我们在事务中处理不当，也会引起类似问题，本文最开始的例子进行稍微调整，在中运行一样会报错。

 _
     = 
     = 
    ____= 
        
      = __= ={ }
     前言
与传统的浅层机器学习相比，深度学习具有优秀的自动提取抽象特征的能力，并且随着分布式计算平台的快速发展，大数据的处理能力得到极大的提升，使得近年来在工程界得到广泛的应用，包括图像识别，语音识别，自然语言处理等领域，并取得比传统机器学习更好的效果提升。另一方面，智能推荐系统，本质上是从一堆看似杂乱无章的原始流水数据中，抽象出用户的兴趣因子，挖掘出用户的偏好，因此把深度学习与推荐系统相结合成为近年来发展的一个新热点，事实上，，，，等公司早已经对如何把深度学习应用到推荐系统中有了很多深入研究，并在实际应用中取得了很好的效果提升 。

本文是深度学习在推荐系统实践应用系列文章的第一篇，详细介绍了如何把受限玻尔兹曼机   下面统一简称应用到我们当前线上的推荐系统中，包括的原理，在推荐系统的应用及其并行化实现的细节，后面两篇会详细介绍另外两个我们目前正在研究使用的深度神经网络，分别是递归神经网络     和卷积神经网络   ，详细介绍它们的原理，如何与智能推荐相结合以及线上的模型效果。
之所以把作为第一篇进行讲解，一方面是因为它的结构相对比较简单，是一个只有可视层和隐藏层两层结构的网络；另一方面，从严格意义上说，并不属于深层神经网络，它只是一个两层结构，并不“深”，但它同时也是构成其他深度神经网络的常用层次组件，因此，理解如何把应用到推荐系统上，将有助于理解后面几个更复杂的深度学习算法的应用。
一：受限玻尔兹曼机与推荐系统
 网络结构定义
我们首先给出的网络结构定义，是由可视层和隐藏层相互连接的一个完全二分图网络结构，如下图所示，每一个神经元是一个二值单元，也就是每一个神经元的取值只能等于或：

的网络结构具有这样的特点：可视层的每一个神经元与隐藏层的每一个神经元相互连接；可视层神经元之间，隐藏层神经元之间没有连线，这为我们后面的训练提供了一个很好的假设性条件：同一层的各神经元之间是相互独立的。对上面的网络结构，我们首先来定义下面的参数：
  ：分别表示可视层和隐藏层包含的神经元数目
 ：可视层的状态向量，表示可视层第个神经元的状态，只取或
 ：隐藏层的状态向量，表示隐藏层第个神经元的状态，只取或
 ：隐藏层的偏移向量参数，表示隐藏层第个神经元的偏移
  ：可视层的偏移向量参数，表示可视层第个神经元的偏移
  ：隐藏层与可视层之间的权重矩阵，表示可视层的第个神经元与隐藏层的第个神经元的连接权重
是一个基于能量的模型，我们需要定义其能量函数，并由该能量函数定义出相应的概率分布：下面我仅列出相应的公式，其推导过程可以查阅相关的资料，本文不做详细的描述
能量函数： 
 联合概率分布： ，其中 
 条件概率分布：
 ，其中表示可视层的第个神经元，表示隐藏层神经元的向量表示， ，其中 表示隐藏层的第个神经元，表示可视层神经元的向量表示，
   边缘分布：，其中
 与协同过滤
 上一小节我们对的结构定义进行了简要的阐述，那么怎么把该模型应用到推荐系统中呢？本质上是一个编码解码器，具体来说，通过，我们可以把原始输入数据从可视层映射到隐藏层，得到原始输入数据的隐因子 向量表示，这一过程也称为编码过程，然后利用得到的隐藏层向量重新映射回可视层，得到新的可视层数据，这个过程称为解码过程，我们的目标是让解码后的结果能和原始数据尽量接近，这样，在解码的过程中，我们不但能得到已评分物品的新的评分数据，还能对未评分的物品的得分进行预测，这些未评分物品的分数从高到低的排序形成推荐列表。
从上面的分析可以看出，我们将应用到推荐中去要解决下面的两个问题：

如何用可视层来表示用户的听歌流水数据？
等人提出的解决方法是对原始的进行扩展 ，以音乐推荐为例，可视层的每一个神经元分别表示每一首歌的得分，将可视层的每一个神经元扩展为个单元，分别表示对这首歌的评分是到分，如果对这首歌的得分是分，那么对应这个神经元的第个单元取值为，其余个单元取值为，如下图所示，图中对应的神经元表示用户没有听过该歌曲。




如何处理数据？

正如上一段我们提到，用户的原始输入数据只对部分极少数的歌曲有评分，对没有评分的歌曲对应的神经元，也就是上图中的神经元，在训练权重时我们并不考虑这部分数据，每一个用户的数据将构成一个独立的子模型，每一个用户的子模型只对其中关联到的权重值调整做出贡献，同理，每一个权重值的参数更新只由与该权重值相关联的用户数据来决定。
下面我们来看看修正的模型对数据编码和解码的过程：
 编码过程：利用原始数据，我们求取隐藏层的隐向量表示，这个过程是由条件概率公式求得：

下图是编码过程的动态图展示：

解码过程：与编码过程相反，利用上一步求得的隐藏层向量，我们反向求取可视层的概率值，但与提到的条件概率不同，用于推荐的模型是一个扩展的模型，可视层的每一个神经元不是唯一的一个单元，而是包含个单元，这样我们需要对条件概率进行调整，具体来说条件概率从函数变为函数，公式如下所示：

下图是解码过程的动态图展示：

二：模型最优化  对比散度 
通过第一部分的叙述，我们已经知道了的网络结构以及如何与推荐系统相结合，那么现在我们的问题就是如何训练模型，对于来说，就是要训练出三个权重参数：连接可视层与隐藏层的权重，可视层结点的偏移量，隐藏层结点的偏移量。
对于机器学习模型来说，我们首先要确定我们的目标训练函数是什么，对于模型，它本质上是一个编码解码的过程，因此我们很自然的想法是：期望经过编码和解码后的数据与原始的输入数据尽量接近，这也是最大似然参数估计的思想，即我们的最优化目标函数为：

其中上式的表示训练样本的大小，把第一节的边缘分布代入上式，分别对，和求偏导，我们得到：

上面三个梯度公式的等式右边都由两项构成，前一项称为正梯度，后一项称为负梯度，其中正梯度的求解很简单，它只依赖于当前的输入数据，但负梯度的计算我们需要考虑所有可能的可视层组合，假设可视层共有个神经元，那么共有种情况，若，那么就是有种组合，显然这个公式的时间复杂度是不能接受的，我们需要进一步的优化。   上面三个梯度公式的等式右边都由两项构成，前一项称为正梯度，后一项称为负梯度，其中正梯度的求解很简单，它只依赖于当前的输入数据，但负梯度的计算我们需要考虑所有可能的可视层组合，假设可视层共有个神经元，那么共有种情况，若，那么就是有种组合，显然这个公式的时间复杂度是不能接受的，我们需要进一步的优化。
训练的最大困难在于负梯度的计算，教授于年提出了对比散度的算法，它有效解决了训练速度的难题，也是当前的标准训练算法，对比散度的思想是通过一种合理的采样方法，以较少的采样样本来近似负梯度的所有组合空间，具体实现过程就是：我们从原始的输入数据出发，经过编码解码后得到新的可视层输入，这一个过程称为步采样，然后利用经过相同的过程，得到，重复这个过程次，最后得到，这个值就是最后负梯度的近似，这个过程被称为步采样过程，下图就是步采样过程的动态图展示：   训练的最大困难在于负梯度的计算，教授于年提出了对比散度的算法，它有效解决了训练速度的难题，也是当前的标准训练算法，对比散度的思想是通过一种合理的采样方法，以较少的采样样本来近似负梯度的所有组合空间，具体实现过程就是：我们从原始的输入数据出发，经过编码解码后得到新的可视层输入，这一个过程称为步采样，然后利用经过相同的过程，得到，重复这个过程次，最后得到，这个值就是最后负梯度的近似，这个过程被称为步采样过程，下图就是步采样过程的动态图展示：

在实现过程中，的取值一般在到之间，就能取得很好的效果，并且的值可随着迭代次数而动态改变 。
这样我们对上面的求导公式进行修改如下，其中表示第个用户的原始输入数据，表示第个用户经过步采用后的数据

三：对比散度的并行化实现
当前对的并行化训练已经有比较成熟的平台，如，，等，我们在实现的过程没有采用上面的平台架构，而是采用了集群来训练，对比散度训练过程本质上是一个梯度下降的最优化过程，下图是算法在的执行流程图：
根据前面的描述，每一个用户的数据构成一个子网络，集群首先是对数据和子模型进行切分，模型和数据在运行的过程中将被分配到不同的中执行，得到每一个子模型的正梯度以及步采样后的负梯度，然后子结果传送回端进行合并，一般来说为了防止全部数据返回造成端的网络通讯压力以及内存压力，我们可以采用树聚合的方式来优化，下图是树深度为和树深度为的效果图，注意不同线条的颜色代表数据在不同的单元中传输，从图中可以看出，深度越大计算的步骤会变长，但每一次传输到的数据会减少，可以防止端内存溢出的问题。
四：线上模型融合
经过前面三节的分析，我们已经对如何作用于推荐系统，模型的训练等都有了比较深入的了解，最后我们需要利用训练好的模型来生成推荐数据并与其他算法模型进行融合，对推荐结果数据的计算，是利用已经训练完的权重参数，对输入数据进行一次编解码的过程，解码后的新数据，不但能重新生成已经操作过的数据的得分，还能对未操作过的数据预测得分，也就是节的数据，这些数据的得分帮助我们对推荐数据进行排序。
要实现这个过程，我们有下面两种做法：一是直接离线批量生成所有用户的数据，但这种做法的计算量非常巨大；二是把训练好的权重单独保存，推荐数据的生成放到在线层实时计算，如下图所示：

在应用中，我们采用的是第二种方法，这种做法相比第一种方法的好处有两个：一是结果不依赖于离线任务，防止了离线任务的失败对线上数据的影响；二是线上实时计算的结果数据能够与现有的算法模型数据的融合更加灵活，包括后续数据处理的规则过滤，重排序等。
五：小结
本文详细分析了在推荐系统中的应用，从文中分析可以看出，对推荐系统的提升主要得益于它具有自动提取抽象特征的能力，这也是深度学习作用于推荐系统的基础。后面的文章中，将继续分析和如何在提取抽象特征的基础上，进一步提升推荐系统的性能。
参考文献
 
 
 
系列第二篇已经于月日在腾讯大数据官方公众号发表，有兴趣的读者可以关注腾讯大数据公众号留意后面的文章，谢谢。【引入】
说起“测试左移”相信对于大家来说已经不再陌生，左移的也手段非常多，无论是使用来做需求分析，还是使用来做测试建模，目的都是希望将隐藏的缺陷提早暴露。今天我们从“测试执行”的角度来谈左移，将测试的执行尽可能的左移，在执行阶段提早发现代码缺陷。
【现状和问题】
、手机管家研发模式和测试流程
手机管家现行研发模式为模式，即每个作为独立的功能模块研发团队，这种研发模式就要求测试人员先要测试内部功能增量测试，再来测试之间有交互的功能集成测试，但是很多功能是之间相互耦合相互交织的，在增量阶段是没有办法测试的。
、大版本的测试难点
小版本的迭代通常修改小功能，局部，测试这一部分内容可以在开发完毕进行，不必牵扯到其他，测试时间和风险可以很好评估。相对于小版本，产品的大版本通常会发生很大的变化，各个之间接口也会有增加和删除。由于每个开发测试进度不同，所以依赖其他的数据或接口的模块在自己的功能测试中是不可测的，例如内展示的数据源来自于询问其他，得到不同数据呈现不同；再如内逻辑依赖其他发出请求，收到不同请求，触发不同的业务表现。
为了解决上述因开发进度不一致而引起的间强依赖模块测试滞后问题，我们引入了测试左移方法。
【测试方案】
、测试框架

是一个插件，和管家业务插件无异，其中主要部分自动化测试框架，该框架继承了测试框架，在此基础上集成了管家测试通用的工具，结果报告，和用户接口等。
测试框架：包括基于实现测试基础框架，通用工具包括数据库，服务，日志存储等。
测试控制：通过用例的组合，结果报告的选择，达到定制化的测试流程的目的。
用户接口：界面用于本地测试，命令行界面用户自动化测试调用。
另一方面，很多时候需要非自动化的测试场景用于本地验证，成为一个天然的测试代码管理插件，避免测试代码和开发代码的混合存放，起到开发代码测试代码解耦的作用。
、测试思路
从数据的获取方式不同将之间通信分为两类：主动询问和被动接受。
主动询问：在特定场景需要其他模块的数据源时，主动询问该模块是否有数据可提供。得到数据后自身做出相应逻辑判断和更新。
测试办法：将业务插件请求其他插件改为请求插件，并给予对应的数据返回。
被动接受：收到其他模块发送的事件或消息，做出相应的逻辑处理和变化。如同之做测试的方法，模拟不同发送过来的数据，不同点在于旧版本的测试是为了解决环境构造复杂，没有真正把测试过程进行左移，执行阶段也是在联调后。方案如图：

、左移方案
旧测试流程：内开发完毕—联调—测试。
之前的接口测试执行是在联调之后，从各个业务层层出发。优点在于经过联调后的代码质量更高，缺点是测试执行较晚，且单纯从上测试功能很难保证接口的正确性。
“左移”后的测试流程：
、接口文档确定—编写接口测试代码；
、接口开发完毕—使用进行接口测试，关注接口逻辑，并接入；
、内功能开发完毕—使用进行测试和异常测试，关注功能逻辑；
、联调—测试之间接口相互影响与用户体验。
测试左移的流程一方面将测试的关注点从接口，功能，用户体验逐个级别关注到，另一方面将测试介入时间大大往前提，提早暴露缺陷，内开发完成即可开始测试执行，降低测试执行与开发进度的依赖。
【测试案例】
、手机管家主界面
业务介绍：手机管家新版的主界面的“四大金刚”，高级工具和管家推荐都是来源器其他的数据，当主界面接口开发完毕后，其他并没有同步开发完成。如何使用达到即刻测试达到测试左移，我们以“四大金刚”为例来说明。

业务逻辑：先来理清楚四大金刚业务逻辑：通过分析代码可以知道，四大金刚每一个入口都分别向不同的插件获取当前的状态，四个插件返回当前状态的，主界面再根据和插件来源查询配置文件，找到应该展示的文案更新当前，如下图右边部分：

可是，主界面开发完成了，其他四个插件并没有同时开发完成，按照以往的版本测试经验，我们需要等到所有接入业务开发完成后，从业务插件检查真实手机环境来测试主界面所以，一方面是测试时间滞后，另一方面模拟场景复杂多变。
测试方法：
采用上图左边的方法，我们将接入主界面的插件改为测试插件，从插件设置需要展示的状态，当主界面询问时即可返回预先设置的，达到测试主界面展示的目的。

测试收益：
将测试执行大大往前提，提现左移的价值；
需要展示的文案有种类，通过手动填写即可模拟，无需构造真实场景，省时省力；
提前发现展示错误。
最后，由于四大金刚接口两个简单，只有两个参数，我们认为覆盖了已知的种场景就能保证接口质量，所以没有做专门的接口测试。同样，主界面管家推荐测试方法类似，不再赘述。
、手机管家桌面浮窗
业务介绍：手机管家桌面浮窗被动接受管家各个插件发送的消息，并展示在小浮窗和大浮窗上，点击跳转到对应插件。

测试方法：
手机管家中定义了新的浮窗事件接口，按照左移思路，我们在接口文档确定后开始了测试代码编写，接口开发完成后接入测试。这种测试方法在之前文章有介绍过，但是这里要强调的重点有两个：
由于接口复杂，参数个，所以专门针对接口做了测试；

接口质量保证后，通过做了功能测试，且都在其他接入前完成。
测试收益：
在测试执行左移的前提下，发现 个，占桌面浮窗总个数的

同样，泰山权限引导模块采用同样的测试方法，在提测前发现个数个

、手机管家垃圾清理
业务介绍：
清理加速模块涉及到个插件，包括垃圾清理，空间管理等，当首页询问清理加速模块的展示时，空间管理会向各个插件获取手机状态，包括内存信息、手机空间信息、微信垃圾、日常垃圾、是否已清理和是否冻结等状态，之后根据优先级给出展示。首先在其他，没有测试的界面，其次是种手机异常情况模拟困难。
业务逻辑：
通过获取卡片信息接口的处理逻辑如下，空间管理插件收到首页发来的请求后，会依次向其他三个插件发送请求，当收到的状态满足展示条件时，便立刻向首页返回结果。
测试方法：
为了在联调前就发现内部逻辑问题，即将测试执行左移到没有开发完成前，我们使用来对内逻辑进行测试，也能够解决模拟场景麻烦的问题。使用这种的方法，我们通过直接修改其他插件的数据，为其构造合适的入参，比如构造为或者___存储容量提醒阈值为，则可以预期会向主页面返回的和，此时将返回结果和预期值比较则可以得到测试结果。
测试收益：
采用这种左移的方法后可以快速测试该用例中涉及的个插件间通信接口，在提测前快速判断提测质量，使测试执行更加敏捷；
可以解放大量手工测试资源，避免构造场景浪费的时间。
、手机管家提醒助手
业务介绍：
在手管版本中，提醒助手模块有个对外接口，涉及多数据交互。如何在间联调之前验证我们对外提供的接口是正确可用的？接口通信数据交互有哪些可以挖的测试点？沸点在这里分享实践的两个案例。
业务逻辑：
这里举推荐引导功能的例子，下图是简化后的业务实现逻辑，简单讲就是“各业务插件给提醒助手传数据，提醒助手存数据库，然后大浮窗来要数据的时候给它”。可见，这个功能涉及至少三个插件模块，按照传统的手工测试方法，需要三个联调通过才能测试，或者开发制造假数据但不方便覆盖所有场景。

测试方法：
在个联调前，为了尽早介入测试执行，在内该模块开发完成，我们把这个模块拆分成两个点来验证。
从各业务插件拿到的数据存储数据库是否正确。测试流程如下：

提醒助手本地数据库构造各种数据，验证传给大浮窗的数据加工结果是否正确。测试流程如下：

收益：
提醒助手模块用例条，在提测前发现有效个，且完全代替这部分逻辑的手工测试；
复现手工难以重现个并回归通过；
通过左移发现的在开发联调之前即可回归通过；
修复及回归测试时间缩短：开发直接在测试上定位并修改代码后回归验证，几分钟即可；
跨测试边界可较明显区分开。
【总结】
、测试左移的收益
测试执行左移：手机管家种对个模块主界面四大金刚、管家推荐、桌面浮窗、提醒助手、权限管理、管理，垃圾清理进行了测试左移试点，在提测前进行了接口测试，联调前进行功能模块测试，将联调提测后的工作了左移到提测前。
提前发现缺陷：个模块在提测前通过框架执行了条用例共提前发现 数个。
、接入每日监控
将左移测试用例加入到平台的自动化测试项目中，作为主线集成测质量报告输出，用于评价主线集成质量。另一方面每日构建包执行自动化测试，可以发现开发提交代码引起的，不必到提测才发现，甚至可以发现因测试遗漏而导致的线上缺陷。
想知道更多测试相关干货 请关注我们的微信公众号——腾讯移动品质中心：背景
笔者平常负责小组下午茶的组织部门的小福利，每次购买点心后，需要先垫付费用并记录下来，等到季度末的时候再汇总给接口人统一报销。两个季度下来，总感觉一些地方需要改进：

不能随手记录手机下单，不能及时把消费记录存入电脑的上

报销记录怕丢失硬盘坏过一次，翻了很多的历史才把记录找回

汇总统计不方便各组记录方式不一样，需要接口人逐个搜集，再一一汇总统计


作为一个搞自动化出生的技术控，面对这些问题简直不能忍，在合并完上个季度的报销费用后，我问自己：为什么不做个工具，既能解决问题，又能取悦自己呢？
需求分析
对于小工具而言，主要需求如下：

可以随手记录

可以自动备份

可以自动统计


自动备份和自动统计都比较容易，只要数据能录入到后台，这些都不是事儿；而要能随手记录，那就必须是移动端的应用毕竟手机大家基本都是随身带，下单也多是用手机，且安卓和苹果都支持。经过这么一分析，做个【微信公众号】就是一个合适的轻量级解决方案啦 _
当然，要作为部门记账报销用的工具，还得加一些小需求：

支持用户注册和鉴权 万一有其他人也关注了公众号，提几个数据上来，那就悲剧了

支持多用户报销 一个组可能有多人轮流组织，各自都要报销


系统设计
用户场景

按照角色进行划分如下：

用户：每个小组的下午茶接口人，购买下午茶后录入消费记录，等待报销

管理员：中心报销接口人，每季度汇总各小组消费统计数据，统一报销


系统交互


下午茶公众号：从用户场景看，用户与公众号的交互并不复杂，用基于文本交互的订阅号未认证来实现，性价比是最高的。当然，如果有条件通过微信认证，使用菜单和界面等高级能力，交互体验会更友好。

公众号服务：服务主要是处理微信公众平台转发来的消息，下文会详细介绍如何基于腾讯云来搭建公众号服务


基于腾讯云的公众号服务


服务器选型： 公众号的用户量并不大，业务场景也不复杂，所以最低配的云服务器核内存云硬盘带宽完全可以满足需求。

数据库缓存：腾讯云本身提供了非常完善的数据库云服务和云缓存，不过以本公众号的数据量和访问量来看，用专业的数据库云服务确实有点大材小用了，还增加成本。因此直接在上部署和，实际运行下来，发现性能完全没有问题。

服务：单从公众号的交互方式来说，选似乎有点‘重’，、、等轻框架更合适。不过，通过的后台管理功能可以对用户、费用、组织关系等信息进行快速的维护，能省掉不少的工作量，后续有新需求也方便扩展，因此框架选用。服务的搭建采用经典的的方式，稳定性和性能也都能得到保证。

数据安全性：报销记录非常敏感，每一笔都是实打实的经费，数据的安全性格外的重要，因此，增加一层数据的保护非常有必要。高可用、高稳定、强安全的云对象存储服务就是一个很好的选择，将数据每日备份到中，可以让数据的安全性得到大大的提高。


说明：使用数据库云服务来提升数据安全性是最直接有效的，考虑到尽量减少小工具的成本，这里选用了存储服务每月有存储、流量的免费额度，完全满足需要

服务可用性：作为一个面向部门多个小组的记账服务，可用性须得到保证，当服务出现异常时，必须要马上发现并修复。通过腾讯云提供的云监控服务，可以在服务出现故障后第一时间得到通知。

系统实现
完成了需求分析和系统设计，实现起来就是水到渠成了。
新建云服务器实例
在‘云产品’中选择‘云服务器’，进入云主机即可按提示创建云服务器


镜像这里选择的是‘  位’

硬盘建议选择‘云硬盘’，便于后续升级

一定要选择或以上的带宽，并分配公网，否则无法接收微信公众平台的消息

如果选择了额外的云硬盘，在登录后要先挂载才能使用


 
    这里有一系列交互式命令
 
  
 
        
软件安装

通过，大部分需要的软件都可以快速安装

  
  
  
  
  
  
  

和需要自己手动安装

如何在下安装和配置，网上的文章非常全，这里不再赘述本文采用

中的版本较低，可以自行下载需要的版本来安装文本采用


上传安装包到云服务器，推荐使用上传下载都可以，和都支持，界面友好，非常方便。
配置
网上的资料虽然不少，但实际配置起来难免踩坑，这里给出笔者的配置流程，供参考

、创建项目

本步骤主要是创建一个初始项目，用于调试，下午茶的逻辑实现放在后面完成
 此命令需要完成安装后才能使用
  _
 
项目的目录结构如下，其中
目录存放下午茶对应的工程
目录存放项目相关的配置文件
目录存放公共库
、、目录存放资源和模版文件
目录存放网站操作脚本

 _
        
        
         
         
         
        
        
        
        
         _
 调试模式启动，监听分配的公网 上的端口
   
访问 看到欢迎页面，说明此步骤成功
‘为示例，请替换为的公网

、配置

网上有很多例子是先配置，再配置，实际操作时很容易埋坑；这里直接给出完整的配置，一次搞定
 在目录下创建以下个文件，分别为和的配置文件
 
         
         _
        __
_：
_  _       _
_  _     _
_  _       _
_  _     _
_  _        _
_  _          _
_  _      _
_  _    _
_  _     
_                 __
_  _        _
_  _        _
_  _        _
_  _        _
：

 = 
 = 
 步骤中创建的_项目的绝对路径
 = _
 = _
 = _
 = 
 日志所在的目录一定要先创建好
 = 
 = 
__：
_  
 日志和所在的目录一定要先创建好
_  
        
 {
    _  
}
 {
         
  _  
  _    _  _ _   
     __ _ 
    __ ___
     日志目录要先创建好
  _     
       
    {
       对应中配置的文件路径
     
      
  }
   {
          
    _ 
         
    ___ 
       {
         _
    }
      {
         _
    }
      {
        _  
             __
    }
  }
}
 启动
 ：验证配置文件是否正确
   ___
 ：步骤显示后，启动
   ___
 后续修改配置并验证成功后，用此命令使新配置生效
  

在目录下创建文件如下：


 这里为上文中的全路径
__=_
     

            ||
         

   =  

        =`  |   |    |  `
         
             
        
                   
                 
        
                 __
                    
        
   =  
          
            
   =  
          
         __
            

            ||

这个脚本用于的启停，后续开发过程中，它的使用频率会非常高

修改相关代码后，需要重启使修改生效

启动


 启动
  
 重启
  
最后，访问 出现欢迎页面，说明配置成功
：如果到最后一步，没有出现欢迎页面，可以查看以下几个日志文件定位问题



公众号开发
下午茶消费如何记录和报销等逻辑下图灰色部分，不具备普遍参考性，就不详细介绍了，这里主要介绍微信公众号交互相关的内容。


、创建

在项目根目录创建名字为的


   

将生成的目录移动到_目录下：

  
 _
            ____
          
         
          
        

在__ 中添加

_ = 
    
    
    
    
    
    
    _
 添加新创建的
    


、修改路由配置

首先修改的顶层路由配置 __


 = 
     __
     
 将路径下请求路由到的定义文件中
      =


修改的路由配置 _

 = 
 将路径下的消息路由到 中函数处理
      =


、引入_库


微信公众平台相关的逻辑，主要有个方面的内容上图红框部分：
 公众号的维护与更新

 验证消息是否鉴权通过

 微信消息解析与封装
 通过微信公众平台的 开发文档 可以理解这些概念和协议，从而实现对应的处理逻辑。 不过从开发效率上看，如果引入开源的_库，可以将我们从这些非主干业务的开发工作中解放出来，节省大量的开发工作；而且开源库经过大量实际项目的运行，可靠性也非常高。
这里给大家推荐，文档清晰易懂，接口调用简单，按照示例能快速上手。以本项目为例：
定义用于存储获取的“”和“时间戳”的函数
 保存新的和过期时间，覆盖原来保存的
 ___ _
     直接使用的模型保存
    _ _

 获取当前保存的和过期时间之前通过___中保存的
 ___
    _ = ____
     _ __

得到类实例，后面的公众平台相关操作都通过此实例完成

 公众号的配置信息
 __和__为前一步定义的两个函数
 = = = =
                  _= __=
                  __=___
                  __=___
                  __=
 = =

验证微信消息

       ，解析个请求鉴权参数
     = 
     = 
     = 

     、通过提供的_接口验证消息是否鉴权通过
      _  
        _ 
         

     、如果是方法，说明是平台配置验证，返回参数的值即可；
        如果是，则说明微信公众平台转发的用户命令消息，进一步处理
      == 
         = 
          
         
      == 
         __
 解析微信转发的请求，提取发送用户、消息类型、消息内容
 、解析消息
    
        _
     
         _     
         

     、得到发送消息的用户、消息类型、消息内容
     =   用户
     =  
        消息类型
         =     消息文本
 将要回复的文本消息封装为微信公众号响应
 解析命令文本，判断格式是否正确
     = __
     
         = 您输入的格式有误
                 将返回的文本内容封装为响应文本
                 _方法返回的是一个文本
                 将此文本作为返回给微信公众平台即可
         _=
按照上面的方法，就可以很方便的完成与微信公众平台相关的逻辑处理了。

、下午茶逻辑处理
如何进行的开发，可以参考官方文档，非常全面，这也是选择框架的优点之一。

这里仅仅截取一段简单‘用户状态查询’逻辑，便于理解下文的公众号操作示例
     得到用户发送的文本已完成微信请求的解析
     = 
     根据请求中的用户查询用户信息
     = ___
     如果命令文本是‘’，说明是要查询用户状态
      == 
         得到用户的状态信息文本
         = __
                 将要返回给用户的文本结果封装为响应文本
         = _=
                 将响应文本作为响应的返回给公众平台
                 
到这里，我们已经完成了服务器环境的搭建和公众号后台服务的开发。接下来就可以配置公众号，让搭建的后台服务来处理用户发送的命令了。
微信公众号配置

登录微信公众平台，进入‘开发’‘基本配置’



填入在开发中配置的，确保对应的逻辑可以处理微信公众平台转发的消息

需要与实例化的时传入的参数相同

也是要与实例化时传入的参数相同

加密方式选择‘明文模式’，便于调试

点击“提交”，公众号后台服务将收到来自公众平台的请求。按照中的处理逻辑，如果校验成功并返回了，则公众号配置成功，后续用户在公众号中发送的消息，都会转发给我们的后台服务处理。

出现下图说明配置成功




在公众号中发送文本‘’，验证功能是否正确


：如果提交公众号的基础配置未成功 或 发送命令后未返回结果，请检查逻辑处理的日志来定位问题
使用云储存

、登录腾讯云，进入控制台



、创建一个，这里取名为‘’

要使用云存储，必选先创建

最终存储的文件，必须在某一个下

可以认为就是根目录，下面可以存放文件或者创建目录

的所属地域，最好与的机房所在地域一致，以获得最快的上传、下载速度



、参考文档进行安装


推荐方式
  __

、在云密钥中查询、、信息，调用的时候需要用到

、在代码中调用，完成文件的云存储上传


 导入
 _  
 _  
 通过、、，的地域
 创建一个实例
_ = _ __
                               __ _
 创建一个上传文件请求，参数为：名称、路径、文件路径
 注意参数的类型为，不是
__ = 
                _
 设置上传时如果存在同名同路径文件，是否允许覆盖
____
 通过完成上传，并得到上传响应对象
__ = ____
 判断响应对象的‘’值是否等于
 ：上传成功，非：失败
 __ = 
        {}__

、添加一个定时任务，每日调用脚本上传关键数据的备份文件到中

添加云监控

、进入云监控告警策略管理，添加‘告警策略’

、添加告警触发条件要监控的内容，如、内存、不可达、磁盘只读等等




、关联告警对象，这里勾选我们要监控的服务器

、设置告警接收组，这里选择接收告警邮件、短信的用户分组



这样，当服务器出现我们监控的问题时，就可以通过短信、邮件马上得到通知了。

公众号实现效果
到这里，基于云服务的公众号开发就完成了，使用时效果如下

添加一笔下午茶报销费用

查看小组未报销费用

查看中心未报销费用



回想几年前，有朋友开发一个小型的业务系统，却因服务器购买、托管、网络等问题耗费了大量时间和精力，等系统开发完成，已错过了最佳的上线时间，实在让人唏嘘。
如今，无论是服务器、网络、云存储还是，云服务的生态已经非常成熟，门槛低且成本小，我们何不放飞自己的梦想，在云中世界里尽情的飞翔呢！

相关推荐利用腾讯云服务器进行微校开放平台开发【腾讯云的种玩法】如何使用腾讯云服务器作为微信公众号的开发空间本文作者： 吴浩麟 原文出处：社区 未经同意，禁止转载

在开发微信公众号或小程序的时候，由于微信平台规则的限制，部分接口需要通过线上域名才能正常访问。但我们一般都会在本地开发，因为这能快速的看到源码修改后的运行结果。但当涉及到需要调用微信接口时，由于不和你在同一个局域网中的用户是无法访问你的本地开发机的，就必须把修改后的代码重新发布到线上域名所在的服务器才能去验证结果。每次修改都重新发布很繁琐也很浪费时间。
本文将教你如何通过  隧道把本地服务映射到外网，以方便调试，通常把这种方法叫内网穿透。
阅读完本文后，你能解决以下常见问题：开发微信公众号等应用时把本地服务映射到外网，加速调试流程；把你正在开发的本地服务分享给互联网上其它人访问体验；在任何地方通过互联网控制你家中在局域网里的电脑；

最终目的
把运行在本地开发机上的  服务映射到外网，让全世界都能通过外网  服务到你本地开发机上的  服务。例如你本地的  服务监听在 ，你有一台公网  为  的服务器，通过本文介绍的方法，可以让全世界的用户通过  访问到你本地开发机上的  服务。
总结成一句话就是：把内网端口映射到外网。
前提条件
为了把内网服务映射到外网，以下资源为必须的：

一台有外网  的服务器；
能在本地开发机上通过  登入到外网服务器。

要满足以上条件很简单：

对于条件：购买一台低配  服务器，推荐国外的 ；
对于条件：对于 、 开发机是内置了  客户端的，对于  可以安装 。

实现原理
要实现把内网端口映射到外网，最简单的方式就是通过  隧道。
 隧道就像一根管道，能把任何台机器连接在一起，把发送到其中一台机器的数据通过管道传输到另一台机器。假如已经通过  隧道把本地开发机和外网服务器连接在了一起，外网服务器端监听在 ，那么所有发给  的数据都会通过  隧道原封不动地传输给本地开发机的 ，如图所示：

也就是说，去访问  就像是访问本地开发机的 ，本地开发机上的  端口被映射到了外网服务器上的  端口。
如果你的外网服务器  配置了域名解析，例如  会通过  解析为 ，那么也可以通过  去访问本地开发机上的服务。 这样就做到了访问外网地址时其实是本地服务返回的结果。

通过  隧道传输数据时，数据会被加密，就算中间被劫持，黑客也无法得到数据的原内容。 所以  隧道还有一个功能就是保证数据传输的安全性。

实现步骤
把本地开机和外网服务器通过  隧道连接起来就和在本地开发机  登入远程登入到外网服务器一样简单。
先来回顾以下  远程登入命令，假如想在本地远程登入到 ，可以在本地开发机上执行以下命令：
 
而实现  隧道只需在本地开发机上执行：
   
可以看出实现  隧道的命令相对于  登入多出来  ，多出的这部分的含义是： 在远程机器上启动  端口监听着，再把远程机器上端口映射到本地的。 执行完以上命令后，就可以通过  去访问本地的  了。
通常把这种技术叫做  远程端口转发 。其实不限于只能把本地开发机上运行的服务映射到外网服务器上去，还可以把任何本地开发机可以访问的服务映射到外网服务器上去。例如在本地开发机上能访问 ，在本地开发机上执行：
   
就能通过  去访问  了。
保持运行
在执行完上面介绍的  隧道命令后，你会发现登入到了外网服务器上去了，如果你登出外网服务器，就会发现  无法访问了。导致这个问题的原因是你登出外网服务器时，在外网服务器上本次操作对应的  进程也跟着退出了，而这个退出的进程曾负责监听在  端口进行转发操作。
为了让  隧道一直保持在后台执行，有以下方法。
通过  自带的参数 还支持这些参数：

参数：表示只连接远程主机，不打开远程；
参数：表示不为这个连接分配；
参数：表示连接成功后，转入后台运行；

因此要让  隧道一直保持在后台执行，可以通过以下命令：
    
通过  隧道是不稳定的，在网络恶劣的情况下可能随时断开。如果断开就需要手动去本地开发机再次向外网服务器发起连接。  能让  隧道一直保持执行，他会启动一个  进程，并监控该进程的健康状况；当  进程崩溃或停止通信时， 将重启动  进程。使用 只需在本地开发机上安装  ，方法如下：

 系统：  ；
 系统：  ；安装成功后，在本地开发机上执行：    


就能完成和上面一样的效果，但本方法能保持  隧道一直运行。 可以看出这行命令和上面的区别在于把  换成了 ，并且少了  参数，原因是  默认会转入后台运行。
常见问题
如果你遇到通过以上方法成功启动  隧道后，还是无法访问 ，那么很有可能是外网服务器上的  没有配置对。为此你需要去外网服务器上修改 _ 文件如下：
 
这个选项的意思是， 隧道监听的服务的  是对外开放的 ，而不是只对本机的 。不开  的后果是不能通过  访问，只能在外网服务器上通过  服务到本地开发机的服务。
修改好配置文件后，你还需要重启  服务来加载新的配置，命令如下：
  
如果使用以上方法还是无法访问 ，请检查你外网服务器的防火墙配置，确保  端口是对外开放的。
其它代替方案
除了  隧道能实现内网穿透外，还有以下常用方法。
 是一个可用于内网穿透的高性能的反向代理应用，支持     协议。  有以下特性：

 比  隧道功能更多，配置项更多；
 也需要一台外网服务器，并且需要在外网服务器上安装 ，在本地开发机上安装 ；

 是一个商用的内网穿透工具，它有以下特点：

不需要有外网服务器，因为  会为你提供；
只需要在本地开发机安装  客户端，和注册  账户；
按照服务收费；

这些代替方案的缺点在于都需要再额外安装其它工具，没有  隧道来的直接。 想了解更多可以访问它们的主页。作者介绍：吴双桥 腾讯云数据库工程师

一 、背景介绍
近年来， 作为  的大数据   存储引擎受到人们的普遍关注。其架构的核心基于一种新的叫做分形树   的索引数据结构，该结构是缓存无关的，即使索引数据大小超过内存性能也不会下降，也即没有内存生命周期和碎片的问题。
特别引人注意的是， 拥有很高的压缩比官方称最大可达倍，可以在很大的数据上创建大量的索引，并保持性能不下降。同时， 支持  和 ，还有在线修改表结构  以及增加的复制性能等特性，使其在某些特定的应用领域如日志存储与分析有着独特的优势。
在  的应用场景中，通常是数据库插入操作的量远远大于读取的量，因而本次测试主要针对  的插入性能以及压缩比，以  作为参考基准。
二、测试环境搭建
测试使用的机器为高配机型，内存大于， 型号为     系列，数据盘使用的是  硬盘。
  版本使用的是 ，按照  网站上的安装方法使用插件的方式进行安装，见官网教程。使用命令查看：

|              |  |  |    |  |

|              |      |           |   |         | 
|                 |      |            |    |          | 
|              |      |            |    |          | 
|           |      |            |    |          | 
|              |      |            |    |          | 
|              |  |           |   |         | 
| _         |      |            |    |          | 
|             |      |            |    |          | 
|           |       |          |  |        | 
| _ |      |            |    |          | 

可以看到  引擎已经就绪，并被设置为了默认的存储引擎。
三、测试工具与变量
、测试工具选择
现在开源可用的  基准测试工具有很多，如，  ， ，  ， 和  等。综合工具的功能、易用性还有流行程度，最终选定操作简单但功能强大的  作为测试工具。在  版本中，已经开始支持脚本，使用修改起来非常灵活。另外，测试压缩比直接使用的  工具。
、测试变量
插入性能相关的变量
除去根据机器硬件特性配置的常规优化参数，对于存储引擎插入性能影响最大的是：是否将事务和同步刷新到硬盘。
需要特别说明的是，还有一个比较重要的指标，即是否开启了   功能，由于在测试环境  开启了   ，并能提高整体的性能，而  在测试机型上无法开启   功能，所以在这点上  有相对的优势。
 相关
对于  来说，控制这个功能的参数为_____和_。_____参数指定了在事务提交后的日志写入频率。具体来说：

当_____取值为  时，  会 每秒写入到日志文件并刷写到硬盘。但每次事务提交不会有任何影响，也就是   的刷写操作和事务提交操作没有关系。在这种情况下，性能最好，但如果  进程崩溃，通常会导致最后  的日志丢失。
当取值为  时，每次事务提交时，  会被写入到日志文件并刷写到硬盘。这也是默认值。这是最安全的配置，但由于每次事务都需要进行硬盘，所以也最慢。
当取值为  时，每次事务提交会写入日志文件，但并不会立即刷写到硬盘，日志文件会每秒刷写一次到硬盘。这时如果  进程崩溃，由于日志已经写入到系统缓存，所以并不会丢失数据；在操作系统崩溃的情况下，通常会导致最后  的日志丢失。在实际的生产系统中，_____会在和之间选择。一般来说，对数据一致性和完整性要求比较高的应用场景，会将其值设置为。

_参数指定了  的二进制日志同步到硬盘的频率。如果 开启，那么每个语句都写一次，否则每次事务写一次。

默认值为 ，不主动同步的写入，而依赖于操作系统本身不定期把文件内容到硬盘。
设置为  时，在每个语句或者事务后会同步一次，即使发生意外崩溃时也最多丢失一个事务的日志，因而速度较慢。

通常情况下，_____和_配合起来使用，本次性能测试覆盖了同步刷新日志和异步刷新日志两种策略。
 相关
中与类似的指标为__和___。与_____的含义类似，__指定当事务提交的时候，是否要刷新日志到硬盘上。

默认开启，值为。也就是每次事务提交时，  会被写入到日志文件并刷写到硬盘。
如果设置为 ，每次事务提交会写入日志文件，但并不会立即刷写到硬盘，日志文件会每隔一段时间刷写一次到硬盘。这个时间间隔由__指定。

___指定多久将日志文件刷新到硬盘，的 总大小为  且不可更改。默认为  秒，此时如果__设置为开启，那么这个值默认为  分钟。
__和___通常也是配合起来使用，本次性能测试覆盖了两种典型的组合策略。
压缩比相关的变量
大多数选择使用的场景，都非常重视它的存储压缩比，因而在实际应用场景中总会配套使用某种压缩算法。当前支持的压缩算法有，   ，当然还有不压缩。关于压缩算法的讨论，可以参考官方博客的一篇分析文章。
本次测试会结合真实的数据来从压缩比、耗时两个方面来检验上面几个不同的压缩算法。可以通过在配置文件中设置__来指定不同的压缩算法，它们的取值分别是：_ _ _和_。值得注意的是，算法是官方最新版本的默认算法，也是现今支持的云服务商的默认推荐算法。
压缩工具相关的变量
针对压测的参数有很多，这里选取的是与实际应用场景最为相关的两个参数：表数量以及线程数量。表数量对应的是数据库实际在同时写入的表的数量，线程数对应的到数据库上的连接。其他的参数，如表的大小，是否是事务等可能影响整体的插入性能，但影响并不显著，这里只选取最主要的两个参数进行分析。
、测试方法
本测试的采用的方式为经典的控制变量法。这里的变量有：采用的存储引擎类型，是否同步刷新日志，采用的压缩算法，以及另外两个与相关的参数：压测的线程数量和压测的表数量。其中，压缩算法的选择只是在四种算法中选择一种，所以并不与其他变量交叉测试。这样以存储引擎和同步刷新日志来划分测试，可以将整个测试数据分为四个大类：

  同步刷新日志；
  异步刷新日志；
  同步刷新日志；
  异步刷新日志。

在每个大类下，对压测线程数量和压测表数量进行交叉测试。压测表数量取值可能为     ，线程数的可能取值为         ，因而每个大类下进行   =  次压测，每次压测写入 条数据，对每次压测进行插入性能统计。
四、测试结果分析
、  同步刷新日志
将_____设置为，_设置为，也即是保证数据最安全：同步刷新到硬盘，并且针对每个事务同步一次。测试的情况见下表：



表数插入线程数





































































































用更直观的图表来展示：

可以看到：

在线程数比较少的时候不高于个，即总数目的一半，数据表的个数对整体的性能影响很小；当线程数较多时才显示出区别：相同线程数下，增加表数目可提升数据库整体吞吐量；
整体性能在线程时达到顶峰，也即达到的总数目，说明能充分利用硬件多的特性；
在线程数或者表数量很小的时候，增加线程数或者表数量可以线性地提升性能，在实际环境中值得注意；而在线程数量超过物理数量时，整体插入性能会下降。

、  异步刷新日志
将_____设置为，_设置为 ，日志文件会每秒刷写一次到硬盘，并且不主动同步的写入，而依赖于操作系统本身不定期把文件内容到硬盘。测试的情况见下表：



表数插入线程数





































































































用更直观的图表来展示：

可以看到与 的情况有所不同：

异步的情况，随着线程数的增加，插入性能提升较快，在个线程的时候已经接近峰值；
插入的峰值比同步情况的峰值低，这个与以往磁盘环境下的优化经验不匹配；通过查看盘的使用率很低，只有百分之几，因而硬盘条件下的的优化策略需要持续改进。

、  同步刷新日志
将__设置为，___设置为，也就是每次事务提交时，  会被写入到日志文件并刷写到硬盘。



表数插入线程数





































































































用图表来展示：

可以看到：

出乎意料的是，在线程数的时候插入达到峰值，也就是说并没有完全利用起多物理的优势。
对比线程数从的情况可以看到，在相同条件下比的性能还要高；而在线程数增多的时候，的插入在逐渐减小，而在线程数超过物理个数的时，插入才开始下降，说明还有很大的优化空间。

、  异步刷新日志



线程数插入表数





































































































用图表来展示：

对比之前的图标，可以看到：

与不同的是，是否开启的同步对的插入性能影响不大， 和 两者的图形形状几乎一样。
与同步的情况类似，在线程数的时候插入就达到峰值，有很大的优化空间。

、压缩算法选择
压缩算法测试使用的实际的运行数据做测试，原来用存储的日志数据为，用工具导出后为。测试表是典型的日志存储表，其结构如下：

|  |          |  |  |  |           |

|      |       |    |  |     | _ | 
|      |    |    |  |        |                | 
|      |   |    |     |         |                | 
|      |   |    |     |         |                | 
|      |   |    |     |         |                | 
|      |          |    |     |     |                | 
|      |  |    |     |         |                | 
|      |       |    |     |        |                | 
|      |       |    |     |        |                | 
|      |       |    |     |        |                | 
|      |       |    |     |        |                | 

依次将的__设置为不同的压缩算法，得到其导入后的实际存储空间以及导入时间，测试结果如下：



压缩算法项目
存储大小
导入时间

























从表中可以观察到：

几种压缩算法耗时差不多，相差很小；
不同的压缩算法的压缩比差异较大，压缩比较小，约为倍；压缩比最大的为倍；
作为官方选择的默认压缩算法，在压缩比和消耗上有较好的平衡，压缩比为倍。

结合在测试过程中持续观察的使用情况，算法在运行过程中使用率在左右，而算法使用率在之间摆动。因而，在实际生产环境中，如果没有特殊的考虑，建议使用压缩算法。
五、讨论与结论
本次测试以为参考，主要测试的写入性能以及存储压缩比。通过不同场景下的对比测试，可以得出几个观点：

现阶段插入性能有优势，性能大约高出左右；
虽然没有充分利用硬件的能力，但是已经表现出强大的足够高的性能，考虑到的成熟度，后面它还有较大的提升空间，可以持续关注其后续进展；
选择日志同步或者异步刷新对性能影响不大，建议默认选择同步日志保护数据；
在数据压缩存储上有绝对的优势，十几倍的压缩比对于冷备数据存储有着极大的吸引力。

值得一提的是，性能表现优异部分原因可归功于的成熟度，可灵活的配置许多参数以适应特定的应用场景，而暴露出的优化参数很少，不能根据硬件配置调整一些重要参数。综上，虽然在现阶段还没成熟，但已经表现出强大的性能以及突出的特性，应该作为某些特定应用场景的首选。

相关推荐  简单性能测试与分析 【腾讯】是如何做浏览器的性能测试的？ 【腾讯】移动性能测试平台解决方案全球化在整个互联网领域仍是大势所趋，而在红海时代来临的游戏行业，“游戏全球化”已成为近年来的热点。 
游戏全球化运营，对节点分布、网络稳定、网络加速、安全防护等云端基础能力提出了很高要求。腾讯云作为国内游戏行业领先的公有云，腾讯云的全球化布局一直走在快车道，更好地助力游戏厂商实现全球化运营。 
本期腾讯云沙龙北京站，与来宾聚焦探讨腾讯云在全球化方面的技术布局，并邀请到了游戏全球化先行者的代表分享实践与洞察。 
嘉宾简介：

张程   腾讯游戏语音资深产品经理
腾讯游戏研发部资深产品经理，在腾讯任职年，负责游戏语音的产品规划及发展。深耕游戏细分领域，以增强游戏互动社交体验为目的，致力于将游戏语音打造成为全球化、质量第一、可扩展性丰富的语音服务。
演讲概要：
当前手游产品越来越注重竞技与社交能力，语音交互技术也逐渐被应用于游戏中，用来优化玩家的游戏体验。腾讯游戏语音技术，目前广泛应用于腾讯自研手游如《王者荣耀》，《穿越火线手游》，《剑侠情缘》，《龙之谷》等近款游戏。本次将分享的实时语音、语音消息、语音识别三大游戏中常用的基本功能，还将分享基于语音的游戏内互动社交能力探索优化，和游戏语音的全球化之路。
视频回放：

关于：
系列沙龙由腾讯云主办，旨在为游戏开发者提供一个自由的交流分享平台。沙龙将围绕游戏行业趋势、研发技术、运维和推广等热点进行探讨。每期沙龙将邀请国内外游戏领域专家，分享游戏开发及运营过程中的思考和实践。    访问沙龙官网 ，了解最新沙龙资讯和更多干货回顾。作者 | 殷源编辑 | 迷鹿

殷源，专注移动客户端开发，微软 中国区特等奖获得者，现就职于腾讯。

越来越多地出现在我们客户端开发的视野中，从到，与客户端相结合的技术开始变得魅力无穷。本文主要讲解中的框架，正是它为提供了执行代码的能力。未来的技术日新月异，与正在碰撞出新的激情。
是的虚拟机，为的执行提供底层资源。
一、
在讨论之前，我们首先必须对有所了解。
 干啥的？

说的高大上一点：一门基于原型、函数先行的高级编程语言，通过解释执行，是动态类型的直译语言。是一门多范式的语言，它支持面向对象编程，命令式编程，以及函数式编程。

说的通俗一点：主要用于网页，为其提供动态交互的能力。可嵌入动态文本于页面，对浏览器事件作出响应，读写元素，控制等。

再通俗一点：抢月饼，。：请谨慎使用循环



 起源与历史

年底，欧洲核能研究组织科学家 ，在互联网的基础上，发明了万维网  ，从此可以在网上浏览网页文件。

年月， 发布了一款面向普通用户的新一代的浏览器 版，市场份额一举超过。

年，公司雇佣了程序员 开发这种嵌入网页的脚本语言。最初名字叫做，年月改为。

年月，公司与公司达成协议，后者允许将这种语言叫做。


 与

“”是公司的注册商标，用来特制网景现在的对于这门语言的实现。网景将这门语言作为标准提交给了——欧洲计算机制造协会。由于商标上的冲突，这门语言的标准版本改了一个丑陋的名字“”。同样由于商标的冲突，微软对这门语言的实现版本取了一个广为人知的名字“”。

作为的标准，一般认为后者是前者的实现。


 和

《雷锋和雷峰塔》
 和  是两门不同的编程语言一般认为，当时  之所以将  命名为 ，是因为  是当时最流行的编程语言，带有 “” 的名字有助于这门新生语言的传播。
二、 
 浏览器演进

演进完整图

___

分支

现在使用的主要两个浏览器和的开源项目。起源于的开源项目的分支，由苹果公司用于浏览器。其一条分支发展成为的内核，年在此基础上开发了新的内核。

 排版引擎
是、等浏览器的排版引擎，各部分架构图如下


  是 与进行交互的接口；

提供与底层驱动的交互， 如网络， 字体渲染， 影音文件解码， 渲染引擎等；

它实现了对文档的模型化，包括了  等的实现；

是专门处理脚本的引擎；


 引擎

引擎是专门处理脚本的虚拟机，一般会附带在网页浏览器之中。第一个引擎由布兰登·艾克在网景公司开发，用于 网页浏览器中。就是一个引擎。

下图是当前主要的还在开发中的引擎



 组成
主要由以下模块组成：

 词法分析器，将脚本源码分解成一系列的

 语法分析器，处理并生成相应的语法树

 低级解释器，执行生成的二进制代码

  基线   实施编译

 低延迟优化的

 高通量优化的


关于更多的实现细节，参考 
 
是一个实现的开源项目。使用提供的框架，你可以在或者基于的程序中执行代码，也可以向环境中插入一些自定义的对象。从 之后可以直接使用。
在中，我们可以看到这个

 _
 _

 
 

 ____  ___

 
 
 
 
 



  _ 
这里已经很清晰地列出了的主要几个类：












接下来我们会依次讲解这几个类的用法。
  ！
这段代码展示了如何在中执行一段代码，并且获取返回值并转换成数据打印
创建虚拟机
  =   

创建上下文
  =   

执行代码并获取返回值
  =  

转换成数据并打印
 =   



 = 
三、 
一个的实例就是一个完整独立的的执行环境，为的执行提供底层资源。
这个类主要用来做两件事情：

实现并发的执行

和桥接对象的内存管理


看下头文件里有什么：
___ _
   

 创建一个新的完全独立的虚拟机 


 对桥接对象进行内存管理 
  

 取消对桥接对象的内存管理 
  


每一个上下文对象都归属于一个虚拟机。每个虚拟机可以包含多个不同的上下文，并允许在这些不同的上下文之间传值对象。
然而，每个虚拟机都是完整且独立的，有其独立的堆空间和垃圾回收器  ，无法处理别的虚拟机堆中的对象，因此你不能把一个虚拟机中创建的值传给另一个虚拟机。

线程和的并发执行
 都是线程安全的。你可以在任意线程创建或者执行代码，然而，所有其他想要使用该虚拟机的线程都要等待。

如果想并发执行，需要使用多个不同的虚拟机来实现。

可以在子线程中执行代码。


通过下面这个来理解一下这个并发机制
  =   
  =   
  =    

_ {
      {
        
         
    }
}
_ {
      {
        
         _
    }
}
_ {
      {
        
         _
    }
}
 

和属于同一个虚拟机。
属于另一个虚拟机。
三个线程分别异步执行每秒次的 ，首先会休眠秒。
在上执行一个休眠秒的函数。
首先执行的应该是休眠秒的函数，在此期间，所处的虚拟机上的其他调用都会处于等待状态，因此和_在前秒都不会有执行。
而所处的虚拟机仍然可以正常执行_。
休眠秒结束后，和_才会开始执行不保证先后顺序。
实际运行输出的是：

_
_
_
_


_
四、 
一个对象代表一个执行环境。在代码中，使用去执行代码，访问中定义或者计算的值，并使可以访问的对象、方法、函数。

 执行代码

调用函数可以执行一段 的代码，并可向对象添加函数和对象定义

其返回值是代码中最后一个生成的值


 
___ _
   

 创建一个，同时会创建一个新的 


 在指定虚拟机上创建一个 

        

 执行一段代码，返回最后生成的一个值 
  

 执行一段代码，并将认作其源码仅作标记用 
         __ _

 获取当前执行的代码的 
  

 获取当前执行的 
   __ _

 获取当前执行的代码的 
  

           
  

 获取当前的全局对象。中的返回的便是对象
    

   
    
    

    

    __ _



 访问对象
一个对象对应了一个全局对象 。例如浏览器中中的，其全局对象就是对象。在其他环境中，全局对象也承担了类似的角色，用来区分不同的 的作用域。全局变量是全局对象的属性，可以通过对象或者下标的方式来访问。
一言不合上代码：
  =    = 

 =   
 =   
 =  




 = 
 = 
 = 
这里列出了三种访问对象的方法

通过的实例方法

通过的实例方法

通过下标方式


设置属性也是对应的。
 
 为提供下标访问元素的方式 
  

 首先将转为对象，然后使用这个值在 的全局对象中查找这个名字的属性并返回 
 

 首先将转为对象，然后用这个值在 的全局对象中设置这个属性。
可使用这个方法将中的对象或者方法桥接给调用 
  





 例如：以下代码在中创建了一个实现是 的 
 =  {
      =  
      =  
      =  
                       
}
  =  {  }
五、 
一个实例就是一个值的引用。使用类在和代码之间转换一些基本类型的数据比如数值和字符串。你也可以使用这个类去创建包装了自定义类的对象的对象，或者创建由方法或者实现的函数。
每个实例都来源于一个代表执行环境的对象，这个执行环境就包含了这个对应的值。每个对象都持有其对象的强引用，只要有任何一个与特定关联的被持有，这个就会一直存活。通过调用的实例方法返回的其他的对象都属于与最始的相同的。

每个都通过其间接关联了一个特定的代表执行资源基础的对象。你只能将一个对象传给由相同虚拟机管理的或者的实例方法。如果尝试把一个虚拟机的传给另一个虚拟机，将会触发一个异常。

 类型转换
提供了一系列的方法将与的数据类型进行相互转换：

 与对象
对象以及其包含的与中的对应名称的属性相互转换。所对应的值也会递归地进行拷贝和转换。
   = {  }

 给你看我的颜色
  = 
= = =   
  =  
= = =   

 给你点颜色看看
 = {  }
  


= = =
= = =
  
可见，中的对象可以直接转换成中的，传入也可以直接当作对象被使用。
 与数组
对象与中的相互转转。其子元素也会递归地进行拷贝和转换。
 “  = 

 你说哪个是真爱？
  = 
     
  =  
     

 我觉和不不错，给你再推荐个
 =  
   

  
  
   
 函数和 
中的转换成中的对象。参数以及返回类型使用相同的规则转换。
将一个代表的或者方法的 进行转换将会得到那个或方法。
其他的函数将会被转换为一个空的。因为函数也是一个对象。
 对象和对象
对于所有其他的对象类型，都会创建一个拥有原型链的对象，用来反映类型的继承关系。默认情况下，对象的属性和方法并不会导出给其对应的 对象。通过协议可选择性地导出属性和方法。
后面会详细讲解对象类型的转换。

相关推荐
接全面解析下篇导语：  想要制造出质量可靠的桥梁，就必须真正懂得力学原理。对于想要理解的软件工程师来说，也需要具备一定的硬件基础。
作者简介：谢宝友，在编程一线工作已经有年时间，其中接近年时间工作于操作系统。在中兴通讯操作系统产品部工作期间，他作为技术总工参与的电信级嵌入式实时操作系统，获得了行业最高奖中国工业大奖。
同时，他也是《深入理解并行编程》一书的译者。该书作者 是 中心领导者，  。《深入理解》系列文章整理了 的相关著作，希望能帮助读者更深刻的理解内核中非常难于理解的模块。
联系方式： ：  微信：

一、来自于霍金的难题
据说斯蒂芬·霍金曾经声称半导体制造商面临两个基本问题：有限的光速物质的原子本质
第一个难题，决定了在一个周期内，电信号无法在整个系统所有中广播。换句话说，某个指令对一个内存地址的写操作，不会在这条指令执行完毕后，马上被其他识别到操作结果。例如：对全局变量执行 = ，当 执行完相应的汇编代码后，其他核仍然看到赋值前的值。刚接触操作系统的读者，需要注意这一点。
第二个难题，导致我们至少需要一个原子来存储二进制位。没有办法在一个原子中存储一个字、一段内存、一个完整的寄存器内容最终的结果是，硬件工程师没有办法缩小芯片流片面积。当核心增加时，核间通信的负担会变得更加沉重。
当然，作为理论物理学家，霍金的这两个问题都是理论性的。半导体制造商很有可能已经逼近这两个限制。虽然如此，还是有一些研发报告关注于如何规避这两个基本限制。
其中一个绕开物质原子本质的办法是一种称为“绝缘体”的材料，这种材料允许较大的器件模拟超小型器件的电气属性。这种材料存在一些重大的生产困难，但是总算能将研究的前沿再推进一步。另一个比较奇异的解决方法是在单个电子上存储多个比特位，这是建立在单个电子可以同时存在于多个能级的现象之上。不过这种方法还有待观察，才能确定能否在产品级的半导体设备中稳定工作。
还有一种称为“量子点”的解决方法，使得可以制造体积小得多的半导体设备，不过该方法还处于研究阶段。
第一个限制不容易被绕过，虽然量子技术、甚至弦论，理论上允许通信速度超过光速。但是这仅仅是理论研究，实际工程中还未应用。
二、原子操作有多慢？
这里的原子操作，是特指内核中，类似于___这样的。简单的说，就是当某个原子操作完成时，确保所有核已经识别到对原子变量的修改，并且在原子操作期间，其他核不会同步对该变量进行修改。这必然要求相应的电信号在所有的之间广播。如下图：

对于普通变量操作非原子操作来说，电信号则不必在所有核之间传播并来回传递：

不能忘记一点：操作系统可以运行在超过个的大型系统中。在这些大型系统中，在所有之间广播传递电信号，需要花费“很长”的时间。
但是，很长究竟是多长？

在上表中，一次“  ”的周期是，够长了吧？而这个测试结果，是在比较新的、核的多核系统中进行的。在老一点的系统中，或者在更多核心的系统中，这个时间更长。
三、变量可以拥有多个值
这不是天方夜谭。
假设 向全局变量写入一个值，我们会很自然的认为：其他会立即识别到的值为。即使有所疑惑，我们可能也会退一步认为，在稍后某个时刻，其他“所有”都会“同时”识别到的值为。而不会出现一种奇怪的现象：在某个时刻， 识别到其值为，而 识别到其值为。不幸的是，是时候告别这种想法了。并行计算就是这么神奇和反直觉。如果不能理解这一点，就没办法真正理解。
要明白这一点，考虑下面的代码片段。它被几个并行的执行。第 行设置共享变量的值为当前的，第行调用函数对几个值进行初始化，该函数读取硬件时间计数，这个计数值由硬件给出，并且在所有之间共享。当然，这个硬件计数值主要是在架构上有效，笔者在架构上经常使用它。第行的循环，记录变量在当前上保持的时间长度。
  = 
  =  =  = 
   ==  {
    = 
    = 
       
     
 }
在退出循环前， 将保存一个时间戳，这是赋值的时间。 也保存一个时间戳，它是对共享变量保持最后赋予的值时刻的采样值，如果在进入循环前，共享变量已经变化，那么就等于。
这个数据是在一个  核系统上采集的。每一个核包含一对硬件线程。 、、和记录值，而  控制测试。时间戳计数器周期是，这对于我们观察缓存状态来说是足够了。

上图的结果，展示出每个识别到变量保持的时间。每一个水平条表示该观察到变量的时间，左边的黑色区域表示相应的第一次计数的时间。在最初期间 仅仅 拥有变量的值。在接下来的， 和看到不一致的变量值，但是随后都一致的认为其值是“”。 但是， 在整个内认为其值是“”，并且   在整个内认为其值是“”。
这真是一个匪夷所思的测试结果。同一个变量，竟然在不同的上面被看到不同的值！！！！
如果不理解硬件，就不会接受这个匪夷所思的测试结果。当然了，此时如果有一位大师站在你的面前，你也不能够跟随大师的节奏起舞。
四、为什么需要
请不要说：我还不知道是什么？
简单的说，是一种内存缓存一致性协议。
现代的速度比现代内存系统的速度快得多。 年的可以在每纳秒内执行十条指令。但是需要很多个十纳秒才能从物理内存中取出一个数据。它们的速度差异超过个数量级导致在现代中出现了数兆级别的缓存。这些缓存与是相关联的，如下图。典型的，缓存可以在几个时钟周期内被访问。借助于流水线的帮助，我们暂且可以认为，缓存能够抵消内存对性能的影响。

缓存和内存之间的数据流是固定长度的块，称为“缓存行”，其大小通常是的次方。范围从到字节不等。当一个特定的数据第一次被访问时，它在缓存中还不存在，这称为“ ”或者可被更准确的称为“  ”或者“ ”。“ ”意味着：在从物理内存中读取数据时，它必须等待或处于“”状态 数百个周期。但是，数据将被装载入缓存以后，后续的访问将在缓存中找到，因此可以全速运行。
经过一段时间后，的缓存将会被填满，后续的缓存缺失需要换出缓存中现有的数据，以便为最近的访问项腾出空间。这种“ ”被称为“”，因为它是由于缓存容量限制而造成的。但是，即使此时缓存还没有被填满，大量缓存也可能由于一个新数据而被换出。这是由于大量的缓存是通过硬件哈希表来实现的，这些哈希表有固定长度的哈希桶或者叫“”，设计者是这样称呼的，如下图。

这个缓存有个“”和“路”，共个“缓存行”，每个节点包含一个字节的“缓存行”，它是一个字节对齐的内存块。这个缓存行稍微显得大了一点，但是这使得十六进制的运行更简单。从硬件的角度来说，这是一个两路组相联缓存，类似于带个桶的软件哈希表，每个桶的哈希链最多有两个元素。大小 本例中是个缓存行 和相连性 本例中是 都被称为缓存的“”。由于缓存是硬件实现的，哈希函数非常简单：从内存地址中取出位哈希桶数量作为哈希键值。
在程序代码位于地址 ，并且程序依次访问地址时，图中的情况就可能发生。假设程序正准备访问地址，这个地址会哈希到 行，该行的两路都是空的，因此可以提供对应的字节缓存行。如果程序访问地址，将会哈希到第行，相应的字节缓存行可以放到第路。但是，如果程序访问地址，将会哈希到第行，必须有一个缓存行被替换出去，以腾出空间给新的行。如果随后访问被替换的行，会产生一次“ ”，这样的缓存缺失被称为“”。
更进一步说，我们仅仅考虑了读数据的情况。当写的时候会发生什么呢？由于在一个特定的写数据前，让所有都意识到数据被修改这一点是非常重要的。因此，它必须首先从其他缓存中移除，或者叫“”使无效。一旦“使无效”操作完成，可以安全的修改数据项。如果数据存在于该缓存中，但是是只读的，这个过程称为“ ”。一旦某个特定的使其他完成了“使无效”操作，该可以反复的重新写或者读数据。
最后，如果另外某个试图访问数据项，将会引起一次缓存缺失，此时，由于第一个为了写而使得缓存项无效，这被称为“ ”。因为这通常是由于几个使用缓存通信造成的例如，一个用于互斥算法的锁使用这个数据项在之间进行通信。
很明显，所有必须小心的维护数据的一致性视图。这些问题由“缓存一致性协议”来防止，常用的缓存一致性是。
五、的四种状态
 存在“”，“”，“”和“”四种状态，协议可以在一个指定的缓存行中应用这四种状态。因此，协议在每一个缓存行中维护一个两位的状态标记，这个标记附着在缓存行的物理地址和数据后面。
处于“”状态的缓存行是由于相应的最近进行了内存存储。并且相应的内存确保没有在其他的缓存中出现。因此，“”状态的缓存行可以被认为被所“拥有”。由于该缓存保存了“最新”的数据，因此缓存最终有责任将数据写回到内存，也应当为其他缓存提供数据，并且必须在缓存其他数据之前完成这些事情。
“”状态非常类似于“”状态，唯一的差别是该缓存行还没有被相应的修改，这也表示缓存行中的数据及内存中的数据都是最新的。但是，由于能够在任何时刻将数据存储到该行，而不考虑其他，因此，处于“”状态也可以认为被相应的所“拥有”。也就是说，由于物理内存中的值是最新的，该行可以直接丢弃而不用回写到内存，也不用通知其他。处于“”状态的缓存行可能已经被复制到至少一个其他的缓存中，这样在没有得到其他的许可时，不能向缓存行存储数据。与“”状态相同，此时内存中的值是最新的，因此可以不用向内存回写值而直接丢弃缓存中的值，也不用通知其他。处于“”状态的行是空的，换句话说，它没有保存任何有效数据。当新数据进入缓存时，它被放置到一个处于“”状态的缓存行。这个方法是比较好的，因为替换其他状态的缓存行将引起大量的缓存缺失。
由于所有必须维护缓存行中的数据一致性视图，因此缓存一致性协议提供消息以标识系统中缓存行的动作。
六、消息
协议需要在之间通信。如果在单一共享总线上，只需要如下消息就足够了：

读消息：“读”消息包含要读取的缓存行的物理地址。
读响应消息：“读响应”消息包含较早前的“读”消息的数据。这个“读响应”消息可能由物理内存或者其他的缓存提供。例如，如果一个缓存处于“”状态，那么，它的缓存必须提供“读响应”消息。
使无效消息：“使无效”消息包含要使无效的缓存行的物理地址。其他的缓存必须从它们的缓存中移除相应的数据并且响应此消息。
使无效应答：一个接收到“使无效”消息的必须在移除指定数据后响应一个“使无效应答”消息。
读使无效：“读使无效”消息包含缓存行要读取的物理地址。同时指示其他缓存移除数据。因此，它同时包含一个“读”消息和一个“使无效”消息。“读使无效”消息同时需要“读响应”消息以及“使无效应答”消息进行答应。
写回：“写回”消息包含要回写到物理内存的地址和数据。并且也许会“探测”其他的缓存。这个消息允许缓存在必要时换出处于“”状态的数据以腾出空间。

再次重申，所有这些消息均需要在之间传播电信号，都面临霍金提出的那两个难题。
七、状态转换


 ：缓存行被写回到物理内存，但是仍然将它保留在缓存中，并在以后修改它。这个转换需要一个“写回”消息。
 ：将数据写到缓存行，该缓存行目前处于排它访问。不需要发送或者接收任何消息。
 ：收到一个“读使无效”消息，相应的缓存行已经被修改。必须使无效本地副本，然后响应“读响应”和 “使无效应答”消息，同时发送数据给请求的，标示它的本地副本不再有效。
 ：进行一个原子读—修改—写操作，相应的数据没有在它的缓存中。它发送一个“读使无效”消息，通过“读响应”消息接收数据。一旦它接收到一个完整的“使无效应答”响应集合，就完成此转换。
 ：进行一个原子读—修改—写操作，相应的数据在缓存中是只读的。它必须发送一个“使无效”消息，并等待“使无效应答”响应集合以完成此转换。
 ：其他某些读取缓存行，其数据由本提供，本包含一个只读副本。数据只读的原因，可能是由于数据已经回写到内存中。这个转换开始于接收到一个“读”消息，最终本响应了一个“读响应” 消息。
 ：其他读取数据，并且数据是从本的缓存或者物理内存中提供的。无论哪种情况，本都会保留一个只读副本。这个事务开始于接收到一个“读”消息，最终本响应一个“读响应”消息。
 ：当前很快将要写入一些数据到缓存行，于是发送一个“使无效”消息。直到它接收到所有“使无效应答”消息后，才完成转换。可选的，所有其他通过“写回”消息将缓存行的数据换出可能是为其他缓存行腾出空间。这样，当前就是最后一个缓存该数据的。
 ：其他某些进行了一个原子读—修改—写操作，相应的缓存行仅仅被本持有。本将缓存行变成无效状态。这个转换开始于接收到“读使无效”消息，最终本响应一个“读响应”消息以及一个“使无效应答”消息。
 ：本保存一个数据到缓存行，但是数据还没有在它的缓存行中。因此发送一个“读使无效”消息。直到它接收到“读响应”消息以及所有“使无效应答”消息后，才完成事务。缓存行可能会很快转换到“修改”状态，这是在存储完成后由 完成的。
 ：本装载一个数据，但是数据还没有在缓存行中。发送一个“读”消息，当它接收到相应的“读响应”消息后完成转换。
 ：其他存储一个数据到缓存行，但是该缓存行处于只读状态因为其他也持有该缓存行。这个转换开始于接收到一个“使无效”消息，当前最终响应一个“使无效应答”消息。


文章来源于微信公众号  本文作者： 

 进制操作是一个比较底层的话题，因为平常做业务的时候根本用不到太多，或者说，根本用不到。
老铁，没毛病
那什么情况会用到呢？








上面只是列了部分内容。现在比较流行的就是音视频的处理，怎么说呢？
如果，有涉及直播的话，那么这应该就是一个非常！非常！非常！重要的一块内容。我这里就不废话了，先主要看一下里面的基础内容。
整体架构
首先，一开始我们是怎么接触到底层的  流呢？
记住：只有一个对象我们可以搞到  流  
这很似曾相识，例如在  使用中，我们可以通过  来直接获取  对象。 中，监听，返回来的 也是 。
  =  
 = 

   {
      = 
    ···
}
 但是， 并不能直接提供底层流的获取操作！！！ 
你可以通过  和  进行相关查看：

接下来，我们具体看一下  和  的具体细节吧。

首先声明这并不是一个具体的  对象，而是一整个底层  的概念集合。首先，我们了解一下底层的二进制：
二进制
在一般程序语言里面，最底层的数据大概就可以用  和  来表示： 
 根据底层的比特的数据还可以划分为两类：

 从左到右第一位开始，如果为  则表示为正，为  则表示为负。例如：
 从左到右第一位不作为符号的表示。例如：

而我们程序表达时，为了易读性和简便性常常会结合其他进制一起使用。

八进制
十进制
十六进制

特别提醒的是：

在  中 使用 字面上表示十六进制。每一位代表 。 使用 字面上表示八进制。每一位代表 。还有一种是直接使用 为开头，不过该种  较多，不推荐。 使用  字面上表示二进制。每一位代表 。

了解了二进制之后，接下来我们主要来了解一下  比特位运算的基本内容。
位运算
 中的位运算和其它语言中类似，有基本的  个。
与 
在相同位上，都为  时，结果才为 ：
  在  中二进制不能直接表示
   = 
 并且，该运算常常会和叫做屏蔽字结合起来使用。比如，在音视频的  中，第  位  表示该   里面是否存在 。那么为了检验，则需要提取第  位，这时候就需要用到我们的 。
  和  进行相与
  
或 |
在相同位上，有一个为  时，结果为 。
   
       =   
       =   
                   
     =    =   
非 
只和自己做运算，如果为 ，结果为 。如果为  结果为 。反正就是相反的意思了：
   
    =   
               
   =    =   
异或 
当两者中只有一个  那么结果才为 。
   
       =   
       =   
                   
     =    =   
左移 
基本格式为：  
将  向左移动  位数。空出来的补 
  
     
                  
        =   
带位右移 
什么叫带位呢
上面我们提到过 和 。那么这里针对的就是 的位移类型。
格式为：   
将  向右移动  位数。左边空出来的位置根据最左边的第一位决定，如果为  则补 ，反之。   = 
直接右移 
该方式和上面具体区别就是，该运算针对的是  的移动。不管你左边是啥，都给我补上 。
格式为：       = 

上面这些运算符主要是针对  的。不过有时候为了简便，可以省去前面多余的 。不过大家要清楚，这是针对  位的即可。

优先级
上面简单介绍了位操作符，但是他们的优先级是怎么样的呢？详情可以参考：
简单来说：按照下列顺序，优先级降低

      |

位运算具体运用
状态改变
后台在保存数据的时候，常常会遇到某一个字段有多种状态。例如，填表状态：填完，未填，少填，填错等。一般情况下直接用数字来进行代替就行，只要文档写清楚就没事。例如：

： 填完
： 未填
：少填
：填错

不过，我们还可以通过比特位来进行表示，每一位表示一个具体的状态。

： 填完
： 未填
：少填
：填错

这样我们只要找到每一位是否为  就可以知道里面有哪些状态存在。并且，还可以对状态进行组合，例如，填完并且填错，如果按照数字来说就没啥说明这样的情况。
那么基本的状态值有了，接下来就是怎么进行赋值和修改。
现在假设，某人的填写状态为 填完  填错。那么结果可以表示为：  =  | 
 后面如果涉及条件判断，例如：该人是否填错，则可以使用 来表示：
  是否填错
   
 或者，是否即填完又填错   |  
 后面涉及到状态改变的话，则需要用到|运算。假设，现在该人为填完，现在变为少填。那么状态改变应该为：
  取填完的反状态
  =   
 = 

 添加少填状态
 |= 
进制转换
在  中进制转换有两种方式： 和 。

 该可以将任意进制转换为  的进制。 默认为 。
 将指定  根据  的标识转换成为  进制。 默认为 。另外它主要用作于字符串的提取。
 字面上转换字符串为十进制。

 用于字符串过滤，例如：     
 里面的字符不仅只有数字，而且还包括字母。

不过需要注意的是， 是不认可，以  开头的八进制，但认可 。所以，在使用的时候需要额外注意。

上面说过， 是将其它进制转换为  进制，其第二个参数主要就是为了表示前面内容的进制，如果没写，引擎内部会进行相关识别，但不保证一定正确。所以，最好写上。     
 如果你只是想简单转换一下字符串，那么使用  无疑是最简单的。
     
     
     

 里面的坑就没有  这么多了。它也是进制转换非常好用的一个工具。因为是 字符串，所以，这里就只能针对字面量进制进行转换了。这四种进制的相关之间转换。

提醒：如果你是直接使用字面量转换的话，需要注意使用  进制转换时，隐式转换会失效。即， 会报错。

例如：
   
  
  
 如上面所述，他们转换后的结果一般没有进制前缀。这个时候，就需要手动加上相关的前缀即可。
例如： 进制转换
 {
       
}
 到这里，进制转换基本就讲完了。后面我们来看一下具体的 
整体架构
 不是一个可以用程序写出来的概念，它是许多  的总称。参考 。可以了解到，它的子类如下：











看上去很多，不过在  中，因为它天生都不是用来处理  类型的。所以，系列在  中应该算是主流。大概排个序：

      

他们之间的具体不同，参照：



数据类型
字节长度
含义
对应的语言类型






位带符号整数
 




位不带符号整数
 




位不带符号整数自动过滤溢出
 




位带符号整数





位不带符号整数
 




位带符号整数





位不带符号的整数
 




位浮点数





位浮点数




虽然口头上说  没有一个具体的实例，但是私下上面那几个  都是叫他爸爸。因为他定义了一些  的基本功能。首先是实例化：
 的实例化有  种：
   创建指定长度的 
   复制新的 
   不常用
       参数为 。
 上面  中最常用的应该为  和 。接着，我们了解一下，具体才创建的时候， 到底做了些什么。
当创建实例  的构造函数时，内部会同时创建一个  用来作为数据的存储。如果是通过  方式创建，那么  会直接使用该的内存地址。
接下来，我们就以  为主要参照，来看一下基本的处理和操作。
该例直接来源于 
    
  =  
 = 
  
  
__  

   
  =  
  

   
  =   
  =  
  

   
  =    创建 个字节长度的 
  =    
 它上面的方法大家直接参考  的上的就 。一句话总结就是，你可以想操作  一样，操作里面的内容。
根据  的描述，它本身的是从  和  编码来获取的。如果只是初始化，他里面的每一位都是 不过，为了容易测试，我们可以直接自己指定：
  =   

 或者

  =   
多字节图
假如一个  很长，假设有  位，算下来就是 。一开始我们的想法就是直接创建一个 就 。不过，根据上面的构造函数上看，其实，可以将一整个  拆成不同的  进行读取。
   的 

  =     中第一个字节内容

  =     中  的字节内容
字节概念
在字节中，还有几个相关的概念需要理解一下。一个是溢出，一个是字节序。同样，还是根据  来说明。
 每一个数组位，表示  位二进制，即范围为 。
溢出
   = 
      
 然后我们做一下加法：
 =   

 =   。因为    溢出 
 然后是字节序。
字节序
在 ，， 等高级语言中，字节序一般都是大字节序。而一些硬件则会以小字节序作为标准。 大字节序：假如  被  存储为  位。那么按照大字节序就是按顺序来，即   。 小字节序：和上面相反，即，。
当然如果只是在  上操作了的话，字节序可以使用  检测一下：
   {
      =  
           
       ===         
}
 关于  的内容差不多就是上面将的。接下来， 我们再来看另外一个重要的对象 。

 没有  这么复杂，衍生出这么多个 。它就是一个构造函数。同样，它的目的也是对底层的  进行读取。那么，为什么它会被创建出来呢？
是因为有 字节序 的存在。上面说过字节序有两种。通常， 和目前流行的电子设备都是大字节序，而如果是接收一些外部资源，就不能排除会接受一些小字节序的文件。为了解决这个问题，就出现了 。它的实例格式为：      
 同样，它的格式和  类似，也是用来作为  的读写对象。

 需要接入的底层 
 偏移量，单位为字节
 获取长度，单位为字节

它的具体操作不是直接通过获取，而是使用相关的方法来完成。而他针对字节序的操作，主要是针对 = 比特的流来区别，即， 是没有字节序 的概念的。
先以  位的作为例子：
   
 根据字节序，获得偏移字节后的两个字节。

 单位为 字节。
 字节序。默认为 。表示大字节序。  =  
  =  
  


 场景
如上面所述， 的场景有：








直接看代码吧：
  = 
  = 
  =  

 =   {
   = 
 ···
}

这里和  区分一下，作为一种兼容性比较好的选择。
   =  
 
 = 

 =   {
      = 
    ···
}




 = 
 = ···

  = _
  = 
  =    
  = 

  =  
 = 

   {
      = 
    ···
}
 上面这些都是可以和  进行交流的对象。那还有其他的吗？有的，总的一句话：

能提供的  的都可以进行底层交流。
原文链接：月日，在布拉格举行的 大会上，来自的主要维护者 向大会汇报了当前开源项目的进展，并按数统计年全球企业对的贡献。
其中，腾讯云向内核贡献了个，在全球企业贡献者中位居第，是唯一一家上榜的公有云厂商。这标志着腾讯云在虚拟化领域的研发实力已经进入全球一线厂商行列。

会上，腾讯云计算产品中心专家工程师肖光荣由于在虚拟机热迁移上的优异表现和贡献，被邀请在本次 发表主题演讲。
在热迁移过程中，虚拟机监视器需要跟踪虚拟机的内存写入并在迁移的下一个迭代将脏内存传输到目标宿主机。做内存写入跟踪必须要用写保护和脏页位图，内存写保护用于得知哪些内存有写入，脏页位图告知虚拟机监视器哪些页是脏页。这两块是影响虚拟机迁移性能的重要因素。
肖光荣就这两个重要因素重点介绍了腾讯云在虚拟机热迁移性能提升方面的最新进展以及当前腾讯云在提升写保护和脏页位图同步做的研发工作成果——快速写保护。
快速写保护有两个特点，无锁且算法复杂度为，这就意味着它的性能与虚拟机的内存大小和工作负载无关。脏页位图同步使用零拷贝的方法让虚拟机监视器和内核模块共享脏页位图内存来达到快速同步的目的。快速写保护对提升虚拟机迁移的速度和迁移的成功率有重要价值，这一重大改进将很快被合并到最新的版本中。
近年来，腾讯云一直秉承开放，共享的心态参与开源，凭借庞大的用户群和集群规模，腾讯云在虚拟化上做了深入的研究和丰富的实践，腾讯云自年月加入基金会以来，更加大了回馈社区的力度。在内核领域，腾讯云已经是贡献度最高的公有云厂商。
 是一年一度由开源项目组织的年度活动，主要为开发人员和用户提供一个讨论虚拟化技术的发展趋势及未来发展的挑战进行交流的高端技术论坛会议，是社区最为重要和权威的大会。关于的搭建在我的另一篇文章【腾讯云的种玩法】一个小白的自学建站史菜鸟建站入门的文末已经有了较为详细的解答，需要的朋友可以参考下。本文主要针对于的邮件设置，以下所有均在环境下进行。
发送邮件设置
开启插件
原来的邮件设置是有些鸡肋的，通过函数来发送，且不说能不能发送成功，就算发送成功了，一般也很难进入别人的收件箱，或者连垃圾箱都进不去，所以在这里介绍一个著名的插件：，我想多数人的都是使用这个插件。具体使用方法：、首先打开后台，点击左侧插件，点击安装插件，在右侧搜索插件，如图：、之后点击“现在安装”，然后启用，接着点击“设置”，填入相关信息，如图：、接着点击下面保存设置，然后可以发送一封测试邮件，试试是否可用，不可用接着往下看。
开启
有些人在配置插件时选择加密，却发现无法使用，配置为无加密就又可用了，这种情况通常是未开启，开启后就可解决问题，开启方法如下：、首先打开目录下的，找到=_看看前面有没有注释符，有则去掉并保存；若是没有这句话则加上这句话之后保存；、把目录下的、，以及目录下的_拷贝到\\目录下；、重启或者。注：开启方法请自行百度。
解决重设链接无效问题
很多朋友在重设密码时点击邮件中的链接会遇到会遇到重设链接无效的问题，仔细观察会看到链接最后有个，删掉就正常了，这是共有的，很久以前就有了，不知道为什么现在还存在，但既然存在，那就有解决的办法，具体如下：、编辑目录下的，搜索：_，约在行，将其所在行修改为： = __===  _ 如图：并保存，其实就是把前面的和后边的删掉；、打开目录下的，搜索__，约在行，修改为： =  __===  _   \\\\如图：并保存，其实还是去掉了那对尖括号。至此，已经可以发送邮件了，同时也支持了用户的自动注册。

相关推荐
【腾讯云的种玩法】一个小白的自学建站史菜鸟建站入门
腾讯云下从迁移到过程
服务器一秒钟丫鬟变格格 问题描述
机场拥有巨大的旅客吞吐量，与巨大的人员流动相对应的则是巨大的服务压力。安防、安检、突发事件应急、值机、行李追踪等机场服务都希望能够预测未来的旅客吞吐量，并据此提前调配人力物力，更好的为旅客服务。本次大赛以广州白云机场真实的客流数据为基础，每天数万离港旅客在机场留下百万级的数据记录。希望参赛队伍通过数据算法来构建客流量预测模型。

 数据概览
提供的数据：








连接   的人数表 ___


安检旅客过关人数表 ___


旅客进入－离开机场的行程表 __


航班排班表__ 比赛一段时间后才提供


机场登机口区域表 __ 比赛一段时间后才提供


机场接入点坐标表 ___ 复赛提供的



例如___ 表数据概览：



__
_
_

























提交表格案例：



_
__
































 初赛
初赛数据描述
初赛提供了至的数据
初赛问题描述
选手需要预测未来三小时月日到的时间窗口里，机场内每个 点每分钟内的平均设备连接数量
初赛解决方案
简要概括：均值加趋势
数据预处理：
提供的表格中时间数据都是精确到秒，而所提交的结果要求是每分钟的平均情况，所以我们首先需要将数据按照每十分钟的间隔汇总起来详细代码见
此处提供两种方案

以___表为例截取_的部分字符串，然后按照截取的_和__进行
 =   例如将 = 截取为 = 


将数据按照时间排序，然后抽出每十分钟的数据进行处理后整合，这个方式可能会比较麻烦，但是这个方式有他的优势，我们只需调整一个参数，便能让数据按照任意的时间间隔进行统计，便于以后复用函数


此处附加处理时间格式的一些函数
我们可以直接使用中的参数解析时间数据
 
 =_ _= 
 
 =     
 =_ _=  _=

当然也可以自己写函数处理
   
 
         
 
     
 
     = 
     = 
     
 = 
 
    

处理后可以得到如下数据命名为__











 




 




 




 




 




 




问题分析：
对于这个预测问题有以下关键两点：

机场每天的排班表基本稳定，用户在机场内的行走模式也基本稳定
时间序列具有一定程度的连续性，下午三点至六点的情况会一定程度延续此前几小时的情况

基于以上两点想法，就得到了两个基本模型：均值模型和时间序列模型
比赛初期只提供了前三个表格，所以开始就注重分析了这几个表格，例如从中可以提取出大概的位置信息和楼层信息，分组统计不同区域的是否有接近的模式，同时也可从安检和出发表格中寻找一定的关联等等。
但是经过分析发现，___及__的数据虽然和___的数据有一定的关联，但是其本身存在较大的随机因素，用随机预测随机存在太大的变数，不如只使用___中的数据进行更稳定的预测当然肯定也有队伍能很好得从___及__中提出很很棒的特征。后期提供的几个表格由于数据质量问题，经分析后发现贡献不是特别大，故也没有进一步利用。
因而之后要说的均值模型和时间序列模型都基于__表格的数据，并且是以为对象， 每一个分开预测。
数据探索：
接下来让我们对数据有一个大概的了解
 
    
        
    
    _ = ____ == 
     = _
     = _
     = _ =    =    = 
    _ = =
     =_   = _
     = _
     = 
     

以上函数能提取出特定的时间序列数据，及每分钟的平均连接数
 = 

 
     
     
     

     
      
     
 
绘图结果如下可以看出每天还是有一定的规律，但是有异常的日子












由于我们需要预测的是特定某几个小时的数据，所以需要如下函数提取部分的时间序列
 ___
    
     __
    
     

均值模型需要考虑之前每一天同一时间段的情况，所以有如下函数
 _
     = _ =  =   = 
     =  = 
     

 
    _=
     = 
       
         =   
        _ = ___
         _ ==   _
            __
        
            __
     _

使用以上函数便可以得到如下结果，其中的每一行是之前每天下午三点到下午点的数据
 = 


 
    
            =

_ = 
_
 
                
                       
                           
        
                      
                        
                          

但是之前这么多天必然有比较异常的日子，所以需要写如下函数将异常的日子过滤掉，此处的过滤策略是：
对每天特定时间段的数据求均值与标准差，然后将均值与标准差落在分位数以下和分位数以上的日子去除
 
           

 _
     =     _
    _ =   
    _ =   
     = __
    _ =     
     =     _
    _ =   
    _ =   
     = __
    _ =   
    _ = __
     _

例如对刚生成的_处理得到
_
          

为了更直观我们使用如下函数绘图
 _
    _




_
__









上图左侧为所有日子的时间序列，右图为去除异常日子之后的时间序列，可以看出已经将特别异常的几天去除了
均值模型：
每天的量值都存在一定的差异，直接将所有去除异常之后的日子取均值并不是特别好的策略，在此我们认为，机场下午点至点的人流总量应当与当天这个时刻之前的人流量存在一定的关系，所以我们取了上午点到下午点这一时间段的数据作为人流量值的参考。我们是有预测当天上午点到下午点的数据的，故可以依据此和之前去除异常后的多天该时间段的数据计算之前各天下午点到下午点数据的贡献度。

基于以上思想，并做了一点小修改写了如下两个模型，两个模型比较接近，但是在某些上其中一个会表现好很多，这使得我们之后利用误差分析挑选模型时多一个候选模型。
 
     

 

     = 
     = 
     = 

     = 
     = 
     = ___

      == 
         = =
    
         = 
         = =

         = 
         = 

     = _ =  =   = 
    _ =  = 

     _ 

 

     = 
     = 
     = 

     = 
     = 
     = ___

      == 
         = =
    
         = 
         = =

         = 
         =   

     = _ =  =   = 
    _ =  = 

     _

时间序列模型：
如果只用上文提及的均值模型，很可能在点那个时刻出现断点的情况，比如前一时刻是人，后分钟突然变成人，考虑到人们在机场移动具有连续性的特征，我们使用来对预测进行一定的修正，正所谓稳中求变，模型如下
 _ = 
    __ = 
    _ =   
    _ = 
    __ = ______
       
     _  
    _ = __
     = _==
      == 
         =         
        _
        __
        
     

试运行如下



_=








模型整合：
现在我们有了三个基本模型，单单使用一个模型去预测所有的效果必然不好，每个都有自己最适合的模型，所以我们通过对前一周每天下午点到点的数据进行预测，计算每个在每个模型上的平均误差，让每个挑选误差最小的那个模型进行预测。数据有缺失的情况，所有模型中包含了蛮多的异常处理部分。
代码如下
 
    _ = 
    _ = 
     = _____
     =___
     =___

     
             

    _ = 
    _ =        

     _
        _ = 
     _
        _ = 

            
        =____
        _ = 
    
        _ = 

     _
        _ = 

    _ = ___
     _


 
     
    _ = 
       _
         = 
         = 
           
            
                 = 
                 = _
            
                  
         = =
        _
         = 
         =====       =====  ===

     __    
         
         = _  
         =  
         
        

    _ = __
    ___
     _

 _

     = __    

      ==
         = 
      ==
         = 
      ==
                
             = _
             
                   
                 = 
        
              
             = 

     

为了看下混合模型的效果，可以使用如下代码
 _
    _ = 
    _ = 
     = _____
     =___
     =___
    =____
     = ____
    
    
    
    
    
    
     = 
    




 占优势例子
 占优势例子
_ 占优势例子










基于以上组件，便可以进行开心地预测了，结果保存为___
 _
    =
     = _

     = _

     
         = 
         = 
         = 
         =           
         

     =     
     = 
     = 
    _ = {}
    _ = _

       _
         = _
         =     
         = 
         = 
        __ = {}
        __ = __
        _ = ___
         = 
         

    _ = ___
    _ = ___   
    ____
     _


 复赛
 复赛数据描述
复赛提供了至的数据
复赛问题描述
选手需要预测未来两整天月日点到日的时间窗口里，机场内每个 点每分钟内的平均设备连接数量
复赛解决方案
简要概括：多层筛选加均值
基本思路：
复赛是对未来的两个整天进行预测，基本思路与初赛相似，但是做了如下修改

模型不再作为一天之内连续性的调整策略，而是用于预测未来两天整体量值的趋势
修改了数据的筛选机制

由于复赛是在天池数加平台进行，第一次接触对于平台并不是太熟悉，所以选择在其机器学习平台使用节点编写语句实现模型
解决方案：
首先在数据开发平台读取数据表
    __
      __  
   _____

然后在机器学习平台进行数据处理和模型搭建
读入初始数据预览如下

使用以下节点预处理数据每个节点是一条语句，将处理结果传入下一节点

使用了如下等语句这些语句应该可以再精简些，但是当初写好了就没再去修改了
__
 _  __|_  _ 
 ___
__
 _  __  _  {}
  _
__
 __  __ |     __ |   _  {}
__
 __    _  _    _    {}
 __
 __    _  _ _  _  {}
_
 _    _  {}
_
 _      {}   

得到如下结果

其中一个模型大概结构如下

节点确实有点多具体细节就不在此展开，此处简要提一下复赛中的筛选策略：
首先计算所有日子全部节点每天的平均连接量，从而得到一个时间序列。如下图所示

利用这个时间序列依据模型估计出之后两天的量值，依据这量值建立一个区间，筛选出均值落在这个区间内的所有日子，然后对这些天的数据按照初赛的思路再进一步做异常筛选，此外还要进一步加大最近几日的数据权重，依据这些想法建立模型。最后在某些步骤上做些小修改，共建立三个候选模型，依据初赛的思路进行误差分析整合模型进行预测。
误差分析的的结果大概如下，基于误差值可以挑选使用哪个模型


 总结
比赛初期其实提取了很多特征，然后使用一些机器学习算法去预测，但是效果却强差人意，随后结合实际问题思考，发现其实不一定要使用各种特征，而且很多随机因素对各个特征的影响真的蛮大的。仅使用一些简单的想法也能达到比较好的效果。
所以这次比赛后，想说的就是模型真的不是越复杂越好，也不一定要用各种现成的模型，结合实际问题背景去分析可能会比一直纠结各种特征以及模型参数获得更大的收益。
思路概览月日，腾讯云将在深圳会展中心举办「云未来」峰会。本次峰会由马化腾先生领衔，还有国际知名科学家、产业家、创新家同台分享，探讨人工智能与云计算的新趋势。
此外，腾讯云还专门组织了针对开发者的专场分享，邀请到了来自谷歌、英特尔和腾讯内部的多位产品、技术专家与腾讯云开发者进行现场互动。
腾讯云技术社区将向社区读者提供  张专场门票，免费赠送给一直以来关注腾讯云的开发者。
开发者专场嘉宾

除以上  位核心演讲嘉宾外，还会有诸多行业总监出席开发者专场，与你见面。
开发者专场议程
开发者专场，聚集众多技术专家 ，历时  分钟为你现场解读云时代，一起畅聊开发者的未来。以下为开发者专场议题方向：

云计算时代，开发者何去何从    
腾讯云社区发布    
异构计算前沿    
鹅厂解密：腾讯开源，在路上    
鹅厂解密：腾讯高效开发工具介绍    
云端安全：腾讯云应用案例    
云端架构：腾讯无服务器架构最佳实践    

开发者报名权益
您成功报名后，将享受以下主题专场权益：

云未来大会开发者专场现场席位
云未来大会全部  场主题专场参会
云未来大会配套服务权益

报名链接，先到先得
申请地址：报名时，请务必选择报名渠道为：腾讯云技术社区。作者    腾讯  团队

深度学习是机器学习中的一个重要的方向，深度学习其实就是神经网络学习，这里“深度”就是说神经网络中众多的层。
那么深度学习是用来干嘛的呢？简单说，那就是
分类
关于什么是机器学习的解释，上有一个买菜大妈都能看的懂的回答。翻译一下就是，吃遍南山区所有芒果的大妈，自己总结出个大颜色黄的比较好吃，所以买芒果的时候，直接挑选了这种。那什么是机器学习呢，就是你告诉机器每一个芒果的特征颜色，大小，软硬等，并且告诉机器其输出好不好吃，剩下的就等机器去学习出一套规则，这些芒果就是你的训练集。而当你再丢芒果进去的时候，已然熟悉基本法的机器就会直接告诉你这个芒果好不好吃，这种能自动对输入的东西进行分类的机器，就叫做分类器。

分类器的目标就是让正确分类的比例尽可能高。一般我们需要首先收集一些样本，人为标记上正确分类结果，然后用这些标记好的数据训练分类器，训练好的分类器就可以在新来的特征向量上工作了。
神经元
我们再来看看神经网络是怎么工作的。

最简单地把这两组特征向量分开的方法是什么呢？当然是在两组数据中间画一条竖直线，直线左边是，右边是，分类器就完成了。以后来了新的向量只要代入公式， =    ，凡是落在直线左边的都是，落在右边的都是。这是二维空间的分类，而当特征有很多种时，我们就要在维空间做分类，大家可以想象一下，就是用一个维超平面把维空间一分为二，两边分属不同的两类，，这种分类器就叫做神经元，是权值，是偏移。

这么一画是不是就很像人脑的神经元呀，我们就用这些神经元组成网络去学习训练集的数据，求出最优的权值和偏置以便最终正确地分类。 
神经网络

上图就是一个简单神经网络的架构，网络中最左边的一层被称作输入层，其中的神经元被称为输入神经元 。最右边的一层是输出层 ，包含的神经元被称为输出神经元 。网络中间的一层被称作隐层 ，在一些网络中往往有多个隐层。我们可以看到，输入向量连到许多神经元上，这些神经元的输出又连到一堆神经元上，这一过程可以重复很多次。数值向量在不同神经元之间传导。
但是，我们刚刚分析了神经元，神经元的变换是完全的线形的，如果神经网络的每层都只是做线性变换，多层输入叠加后也还是线性变换。因为线性模型的表达能力不够，所以需要激活函数来引入非线性因素。举个栗子，常用的激活函数函数，可以将实数压缩到之间。激活函数是神经网络强大的基础，好的激活函数根据任务来选择还可以加速训练。
接下来，确定了神经网络的连接方式、网络的层数、每层的节点数，建好网络模型之后，我们要开始学习这个神经网络的每个连接上的权值了。
训练网络
训练过程就是用训练数据的经过网络计算出，再和计算出，再计算出来更新的过程。就是训练集里预先加上的分类标记，就是你算出的结果与正确结果正确为，错误为的误差，或者叫损失。
那么其实就是通过梯度下降法尽可能缩小的过程。如下图所示，我们希望值可以降低到右侧深蓝色的最低点。
 
具体步骤如下：

正向传递：算当前网络的预测值                    是一种激活函数，、、是权重，是偏移量

计算：

计算梯度：从开始反向传播计算每个参数对应的梯度。这里用    来计算梯度，即每次更新所计算的梯度都是从一个样本计算出来的。

更新权重：这里用最简单的方法来更新，即所有参数都

预测新值：训练过所有样本后，打乱样本顺序再次训练若干次。训练完毕后，当再来新的数据，就可以利用训练的网络来预测了。这时的就是效果很好的预测值了。


 以上理论知识和公式来自斯坦福大学计算机视觉实验室推出的课程      
调戏 
接下来，摩拳擦掌想要试一试深度学习的朋友们可以试着调戏一下 。游乐场是一个通过网页浏览器就可以训练的简单神经网络，并实现了可视化训练过程的工具。下图就是游乐场默认设置的截图。

左边的每组数据，都是不同形态分布的一群点。每一个点，都与生俱来了个特征：和，表示点的位置。数据中的点有类：橙色和蓝色。我们这个神经网络的目标，就是通过训练，知道哪些位置的点是橙色、哪些位置的点是蓝色。如何确定网络结构呢？到底用不用隐层呢？还是一个隐层？两个隐层或更多？每个层的尺寸该多大？这些都可以在上调整，而且立刻就能看到直观的结果。快去试试吧
 安装
最后奉上大杀器，谷歌年开源的主流深度学习框架的官方安装指南 _， 上的安装会有一些小小的坑，遇到安装问题可以询问我哦。导语
最近做了个的项目，发现打包后的页面体积有点超出预期的大。为了减少请求量， 页面的和都是内联在里面的，查看生成的代码后发现，异步引入的模块中的 也被打在了页面上面。页面体积可是影响加载速度的关键，赶紧后解决了这个问题。这里记录下。
大部分使用过的朋友都知道，抽离需要使用到的插件，也不例外。官方给的的文档里面有这样的描述
 {
           
            {     处理中引入的
                   \
                   {
                       
                          {
                               
                          }
                      
                  }
              }
              {
                   \
                   
                   {{
                       {
                           
                           
                      }
                  }}
              }
          
        }
  这个不添加参数的话，不会抽离的
 {   }

这样打包后，我们把每个里面使用到的代码都单独打包出来了，这时候可以选择
使用生成带 链接的，也可以使用
把内联到里面减少请求数量，在移动端很有用
  然而会发现，异步引入的文件里面的，也会被抽离出来，打包内联到里面，
怎么解决这个问题呢。其实很简单，就是使用的参数，指定的作用文件夹，
对不想抽离的文件，使用和。就像这样
 {
           
           {
         \
         __ 
         {
         
        {
             
                }
        
        }
       }
       {
         \
         __ 
         
      }
             {
                   \
                   
                   {{
                       {
                           
                           
                      }
                  }}
              }
          
        }
  这个不添加参数的话，不会抽离的
 {   }

这里配置对目录下的代码，抽离出，对里面引用的代码，内联在里面。
这样异步加载的就不会被打包到首屏的里面了，页面体积减少，加载速度自然
就上去了。
下面附修改前后的对比。
修改前


修改后


很明显，修改后的体积变小了，然而值得注意的是，修改后的体积大于修改前，
这是因为在里面保存，需要更多的字符去表示，所以总体积变大了。把里面的
把里面的再抽离单独加载也是一个不错的注意。
不过怎么做效果好，还是要实际测试一下。接 《复旦教授徐英瑾：人工智能研究为何需要哲学参与 上》

三、从哲学的角度反思现在 自然语言处理与机器翻译
我们再看比较新的话题，从哲学的角度反思现在的自然语言处理与机器翻译，严格的说，自然语言处理是大概念，机器翻译是一个小概念。机器翻译是属于自然语言处理的，但有时候会把它分开来说。
现在机器翻译历史上有不同的路数，有基于神经元网络，基于统计的，基于符号的，基于中间语的，还有很多、很多路数。但是深度学习牛掰起来以后，大家都用深度学习来做，很大程度上，深度学习做机器翻译也将流行，也结合了一些大数据的方法。
“深度学习”技术，主要是作为一种“工程学技巧”进入我们的视野的。实际上，我们目前尚无法在科学层面上清楚地说明：“深度学习”技术为何能够提高相关程序之应用表现——遑论在哲学层面上为这种“进步”的“可持续性”提供辩护。
传统的神经元网络和深度学习相比，它的特点是中间处理层层数比较少，而现在的深度学习靠硬件的进步，可以把中间的处理层做成几十层上百层，这是以前不可想象的。做多以后，在很大程度上分析问题的层次感就多了，因为它层数越多就可以用不同的角度和层数分析问题，因此，很大程度上处理问题的手段就更加细腻了。的确体现出一种明显的工程学的进步。
很大的问题是，这种进步是否可持续？我自己站在哲学领域是持保留意见，我认为可以搞搞，但是认为这件事最后能做成像霍金所说的毁灭人类的超级人工智能是胡扯。我们可以借一些例子来讨论、讨论。
传统的人工神经元网络有输入层、中间层和输出层，通过数据的处理得到一个输出，通过反馈算法等等东西来弄，它的最重要的是要调整计算单元之间的权重，通过这种权重的调整，慢慢的让它的适应一类任务。传统的神经元网络最大的特点是，它能够执行的任务是比较单一的，也就是说它完成一个任务以后做了什么，就永远的恒定在这个表现的水准上做这个事。
如果你让他在大量帧数的画面里，在所有有刘德华的脸出现的图片里面做标记，他开始标记的水平比较差，但是他标记的至少比另外一台机器好，另外一台机器把关之琳的脸也标成刘德华，你的机器至少在正确的道路上，随着时间推移，通过训练慢慢能做了。然后刘德华演一部新电影，这电影刚刚上映，显然不是在训练样本里面，让他辨认里面是谁，分得很清楚，刘德华、吴彦祖、关之琳，分得很清楚，训练成功。
现在给它一个新任务，现在不是认人脸，是认一个完全不同的东西，练什么东西呢？假设是一部武打电影，里面也有刘德华参与，但是不要认刘德华，把所有打螳螂拳或者咏春拳的画面选出来，我没学过，如果你要做这件事，这个机器要重新来进行调整。
但是人类可以做一个推理，比如人类如果已经知道了甄子丹经常演叶问，而叶问是打咏春拳的，而人类已经学会了识别甄子丹，如果一部电影我给你一个任务，到底哪些画面是在打咏春拳？你不用看什么拳，你盯着叶师傅，盯着甄子丹就可以。
这里面有三段论推理，非常方便的从一个知识领域到另外一个知识领域。怎么识别甄子丹是一个领域，谁在打拳、谁在打叶问的咏春拳，这是另外一个知识领域。当中有一个桥，就是叶问老师是由甄子丹扮演的，而甄子丹扮演的叶问老师是打这个拳的，你有这个桥，两个知识就可以合二为一。
现在的问题也就是说，这对于符号来说很容易的事，对神经元网络是很难的。现在很多人说要把符号和神经元网络结合在一起，但是这个结合点怎么找？实际上困难很大。深度学习只是它的的升级版，它是非常高级的升级版。大家觉得打败李世石是非常了不起的事，实际上这是迟早发生的事，因为它只能局限在围棋这一个网络。同样一个深度学习系统同时做两件事，才算牛掰。
美国的生物统计学家 最近撰文指出，除非你具有海量的训练用数据，否则深度学习技术就会成为“屠龙之术”。有些人认为他的观点是不对的，但是我还是倾向于认为深度学习和神经元网络需要大量的训练样本，把某种模式重复性的呈现出来，让他抓到规律，整台系统才能慢慢调到很好的水平。请问前面的数据是不是在任何一种场合都能够获得呢？这显然不是那么容易的。
哲学家柏拉图会怎么评价目下的机器翻译？
伯拉图有一个东西叫《美诺篇》，主要是以对话形式来写他的哲学著作。《美诺篇》里面有一个重要的桥段，一个从未学过几何学的小奴隶在哲学家苏格拉底的指导下学会了几何证明。旁边的人反复问，你真的没有学过几何学吗？怎么证明那么好？小奴隶说，真没学过。旁边人证明，这小子字都不识，希腊文字母表都背不下来。
由此引发的问题是：小奴隶的“心智机器”，究竟是如何可能在“学习样本缺乏”的情况下获取有关于几何学证明的技能的呢？而后世的语言学家乔姆斯基则沿着柏拉图的思路，问出了一个类似的问题：岁的婴幼儿是如何在语料刺激相对贫乏的情况下，学会复杂的人类语法的？——换言之，按照柏拉图—乔姆斯基的看法，任何一种对于人类语言能力的建模方案，如果无法具备对于“刺激的贫乏性”   的容忍性的话，那么相关的建模成果就不能被说成是具备对于人类语言的理解能力的。
乔姆斯基的解释是人有先天语法结构的能力。人家问乔姆斯基，这个东西怎么来的？他说，这是进化当中的基因突变导致的。我最近美国开议事大会，碰到乔姆斯基，他一方面承认这肯定是进化基因突变的，但是另一方面又否认我们可能用经验手段去严格的研究语言进化的某个历史瞬间到底发生了什么，因为他认为我们缺乏追溯几十万年的语言基因突变的经验能力。
我并不完全赞成他的观点，但是有一点我赞成他，他正确的提出一个问题，这个问题就是机器学习主流没有办法解决的问题。小朋友是怎么做到这么小就可以掌握语法？
若按照按照乔姆斯基的标准或者伯拉图、苏格拉底的标准，，我们是否可以认为目前基于深度学习的机器翻译技术是能够理解人类语言的呢？答案是否定的。
实际上，已经有专家指出，目前的深度学习机制所需要的训练样本的数量应当是“谷歌级别”的——换言之，小样本的输入往往会导致参数复杂的系统产生“过度拟合”的问题。也就是说，系统一旦适应了初始的小规模训练样本中的某些特设性特征，就无法灵活地处理与训练数据不同的新数据。
一句话，凑数凑得太假了，以至于难以应对世界的真正的复杂性！
举个例子，一个人说她自己很适合谈恋爱，很适合和异性交往。她谈第一次恋爱，两个人如胶似漆，而且她的恋爱对象是非常奇葩的男人，非常宅，邋遢，很奇怪，别的男人对他也有意见，但是这个女人和他一拍即合。这就是过拟合。
你作为她的闺秘会担心一件事，她和这个男人分手以后，能不能适应正常的男人？按照统计学来看，第一次恋爱成功的概率是很低，如果你第一次就过拟合了，你以后怎么玩这个游戏？这很麻烦，这是恋爱中过拟合的问题，和谁都特别熟，黏住谁就是谁，分不开，他什么毛病也传给你，以至于你不能和第二个人谈恋爱。
另外一种是不拟合，就是和谁都不来电。按照机器训练来说就是怎么训练都训练不出来。一种太容易训练出来，太容易训练出来的问题是我现在用这组数据很容易把你训练出来，以后真实世界中真实数据和实验室不一样，你能不能应付？
就语言论语言，新数据与训练数据不同恐怕会是某种常态，因为能够根据既有的语法构造出无穷多的新表达式，本就是一切自然语言习得者所都具备的潜能。如果我愿意，我可以用大家听得懂的汉语跟大家描述各种各样的奇葩状态。这是语言的特点。也就是说既有的语法允许我们构造出无穷多的新表达式。
能够用既有的语法构造更多的新表达式，是任何一个语言习得者的能力，能够听懂别人用你的母语所表达的任何一种奇葩的表达式，也是一个合格语言习得者的能力，这个能力是何等的平常，但是对于机器来说是多么的稀奇。
换言之，无论基于深度学习技术的机器翻译系统已经通过多大的训练量完成了与既有数据的“拟合”，只要新输入的数据与旧数据之间的表面差距足够大，“过度拟合”的幽灵就都一直会在附近徘徊。
所以从过去当中永远没有办法必然的推出关于未来的知识或者关于未来我们不能有真正的知识，这是休谟哲学的相论点，他没有用什么拟合、不拟合的数据，因为他当时不知道深度学习。但是你会发现，过很多年，休谟的哲学问题没有解决。

从本人的哲学立场来看，未来人工智能需要做的事情：
 首先要在大的目标上指出通用人工智能是一个大的目的。
很多人给我说通用人工智能做不出来，我的书指出了，所有指出通用人工智能做不出来的论证是不成立的。第二个如果你相信某些人所说的，人工智能将对人类生产生活产生颠覆性的影响，而不是过去的自动化的零敲碎打的影响，只有通用人工智能才能对未来的生活进行颠覆性的影响。因为专用人工智能不可能真正取代人的工作，只有通用人工智能能做到。
比如家政服务员，让机器人做，你知道家务有多麻烦吗，家务有多难做吗？我始终觉得做家务比做哲学烧脑，我一直觉得做家务合格的机器人比做哲学还是要更慢一点，你十个人都喊着文本都是一个文本，十个人不同家庭的打扫情况就是不同。
这个人家里书很多，但他不希望你理得很整齐，另外一个人家里有很多书，但是希望你理得很整齐。这个小朋友岁，喜欢书。这个地方有小朋友岁，很不喜欢看书。这些问题都复杂，人都要被他弄崩溃，机器怎么搞得清楚？
 认知语言学的算法化。
 基于意义的普遍推理引擎，而不能把推理看成形式、逻辑的事情，而要认为这和意义有关。
 节俭性算法与该推理引擎的结合，我们的计算要从小数据出发，要体现节俭性，不能依赖大数据。
 结合认知心理学研究加入人工情绪等新要素。本文提要：广受欢迎的开源数据库 中，包括了众多新特性，其中包括对更好的支持、对格式和文档的处理，以及一直以来呼吁增加的象函数的功能等。

是众多网站技术栈中的标准配置，是广受欢迎的开源数据库，已经推出了的第一个候选发行版本。
 的新特性包括：

对 的开箱即用的完整支持
支持窗口函数和递归语法，这在以往是不可能或者很难才能编写这样的查询语句
对原生数据和文档存储功能的增强支持

 的发布，跳过了多个版本号从开始，由于修改和是用来保留做的集群版本，因此采用了的版本号。
 的预期发布日期
根据的策略“一个新的【一般】版本发布的周期是个月”， 并没有承诺 的发布日期。最近一次 的发布是年的月日，所以 的正式版本发行可能在年月。
 标准化之路
默认支持可以说是 最大的改变之一。 长期以来，一直存在着对的很多没能解决的问题。 所以，对 来说，一个长期的计划是尽可能多地修复那些持续的问题。
 不再将设为默认的编码，以防止新用户使用了这个有问题的遗留选项。现在推荐作为 的默认字符集设置，其目的是比现在不在推荐的字符设置更快，同时也支持更灵活的排序并区分大小写。
增强的不但支持非西方的字符集合也支持目前日益发展的表情。
 支持窗口函数
很多语言标准的实现如，译者注都支持窗口函数，它是能实现跨多行聚合计算的功能，并仍然允许从查询中访问到单独的行。在以前的版本中，不使用窗口函数是可以实现的，但是很麻烦而且速度慢。为了克服这个缺陷， 通过标准的关键字来实现窗口函数的功能，有点象其竞争对手的实现方法。
同样另一个功能是递归公用表表达式，它能让你针对子查询进行递归操作，而无需使用游标或其他有损性能的解决方法。
 更好支持文档型数据库和
 支持，这让 能使用原生和数据库竞争。  扩展了对的支持，并且性能更加好，增加了从查询中返回范围的功能就象语句” ”的功能，也增加了新的聚合函数能让在同一个查询语句中，能结合原生的结构化数据和的半结构化数据。
与相关的另一项改进包括的文档存储。 对文档存储的读取和写入在事务上是一致的，允许对数据进行更改的回滚操作。文档数据以开放的、用于地理空间数据的格式存储，并且能被索引，因此可以进行领接方式的搜索。
 的其他关键特性
其他 计划更新的特性包括：

在锁定行方面增加了更多选项，如 和两个选项。其中， 允许在操作中不锁定那些需要忽略的行；则在遇到行的锁定的时候马上抛出错误。

能根据可用内存的总量去伸缩扩展，以更好利用虚拟机的部署。

新增“隐藏索引”的特性，这样索引可以在查询优化器中变为不可见。索引在标记为不可用后，和表的数据更改同步，但是优化器不会使用它们。对于使用隐藏索引的建议，是当不决定某个索引是否需要保留的时候，可以使用。


哪里下载 
现在你可以下载 的的若干版本，和也可以下载源代码。可以在官网的下载页面中，访问其中的开发者候选版本去下载它们。原文地址：图像处理－像素化的原理及实现
博客地址：
马赛克算法首先需要确定马赛克单元的大小，即小方块的大小。马赛克图的每个马赛克单元都是纯色的块，其取值一般为原图中该块区域的颜色的均值这里的实现为了简化，取了原图中该区域左上角的像素。马赛克单元的大小决定了最后的马赛克图的样子，当值为时，就是原图。

上图中，最左边的图是原图，中间的图是马赛克图。当然你也可以对图像的某块区域打马赛克，如最右边的图，他只对头部打马赛克。算法实现如下：   {          普通图像－像素图，为像素图的大像素的宽度
                {                  }          普通图－像素图，、、、可指定打马赛克区域
                        {          =           =           = _           =            =             =      =  {               =      =  {                  =                                    =                      =                                    }        }             }}使用方法：  =    对全图打马赛克  =       对指定区域打马赛克开源项目是实现基本马赛克效果的开源项目，它能够异步对整个或者部分的区域打马赛克，处理完后会在的中回调，最小的版本为。使用方法如下：       设置区域     值越大，马赛克单元越小      {                      {            为马赛克图                     }    }    能够实现多样式的马赛克效果。使用方法如下：  =                   设置马赛克形状                 每个像素的密度如果该值和值一样，那么圆形之间相邻                 圆圈的大小                效果如下： 简介
传统的负载均衡是一种集群  技术，采用负载均衡技术和基于内容请求分发技术。 有三种工作模式  模式、 模式及  模式，三种模式分别都有各自的局限性。这样就催生了  概念。套用官网介绍：负载均衡    是对多台云服务器进行流量分发的服务。负载均衡可以通过流量分发扩展应用系统对外的服务能力，通过消除单点故障提升应用系统的可用性。
 基本概念
这里首先需要了解下腾讯云相关的一些概念，有助于后续了解  业务。
基本属性
  实例
腾讯云提供的一种网络负载均衡服务  ，可以结合    虚拟机为用户提供基于  协议类型的负载均衡服务。
后端服务器
接受负载均衡分发请求的一组云服务器实例，负载均衡服务将访问请求按照用户设定的规则权重转发到这一组后端  上进行应用处理。
虚拟地址
腾讯云负载均衡分配给每个负载均衡实例的虚拟地址。客户端可以通过  进行层负载分发。也可以按照进行层负载分发。
监听器
目前存在两种监听器。传统公网固定类型的监听器包括监听端口，后端服务器端口、负载均衡策略、健康检查阀值配置和轮训方式等，每个监听器对应后端的一个应用服务。新版的应用型监听器只有监听端口属性 还有证书信息。但是监听器下又可以创建域名和规则，规则中可以设置健康检查阀值、负载均衡策略、转发路径等信息。同时监听器维度存在几个概念需要了解下，主要如下：
：提供给客户端访问的端口
： 后端服务器需要启动的端口
轮询方式：目前只有权重轮询 _ 最小连接数三种轮询方式
会话保持：保证同一客户端多次请求在一定的时间内落地到后端同一台服务器上
： 是否支持后端服务器可以看到客户端的真实 ，否则  看到是    不支持获取客户端  
健康检查：针对  后端服务器端口存活状态进行检测，及时剔除异常端口的机器，保证服务稳定正常
证书
公网  支持  协议监听器，创建监听器过程中需要上传服务器和客户端证书。
负载均衡类型
内网与公网之分
内网  主要提供给同  下的子机之间进行负载均衡请求，  绑定的子机必须是  下的子机，客户端请求子机也必须是  下的子机。
公网  开发商可以将自己的服务搭建在  绑定的后端服务器上，然后提供给自己的用户使用进行访问。公网  对绑定后端子机有一个要求：子机必须要有流量。
基础网络与私有网络之分
基础网络包含  和实体网络子机，这里要求  绑定的后端服务器必须是基础网络子机。当基础网络与  互通之后，基础网络子机也可以访问私有网络的  服务。
私有网络即所有的  子机，这里同时要求  绑定的后端服务器必须是私有网络子机。
物理网络与  网络之分
　　物理网络：这种网络架构是腾讯云最早使用的框架，有非常大的局限性，如下描述： 受物理网络路由限制，子机不能跨机架迁移； 子机  固定，用户不可自定义； 用户的子机  无规律，不能划分网段，不方便管理。
 网络：为了解决实体网络的限制，应运而生出来了私有网络。 网络可以让虚拟机保持  、  不变进行跨机架迁移。用户自定义网络，选择  地址范围、管理子网、路由表和网关。支持   、  、专线接入，满足  网络与客户本地数据中心部署混合云需求。
综上所述，所以目前公网  同样也区分基础网络与私有网络类型。但是底层负载能力实现原理基本保持一致。
七层与四层之分
目前腾讯云内网  只支持层负载，不支持层负载。公网  同时支持层和层负载。下面介绍关于层与层的区别见下图。
　　层  主要是通过报文中的目的地址和端口，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。负载能力实现主要基于数据包的传输层信息    进行负载转发。
层  也成为“内容交换”，主要通过报文中真正有意义的应用层内容证书，，头部信息，会在负载均衡设备上进行证书校验，三次握手等操作，再加上负载均衡设备设置的服务器选择方式，决定最终的内服务器。负载能力实现主要基于应数据包应用层信息  等进行负载转发。
 业务架构
首先看下图，简单可以看到公网  的实现主要是由     实现。  集群承载腾讯流量入口，有着强大的负载均衡能力，当然也有其他重要能力例如： 漂移，容灾等。
 业务场景
传统场景
大多数用户使用传统的  主要具有三种使用场景：流量分发；横向扩展；业务分离。腾讯云目前提供两种类型的 ：经典型和应用型。
腾讯云目前提供的经典型  公网有日租基本可以满足大部分用户的使用场景，但是有一定的局限性。 主要局限性表现如下：

每个  分配一个 

分配一个域名带有腾讯云后缀的域名

 下可以创建多个监听器映射

子机绑定在  维度


这样就存在多个问题：域名含有腾讯云后缀，用户不可自定义；每个  对应一个域名，对  造成大量浪费；层访问只能细化到域名维度，不能在  维度进行细化。这样就应运而生了应用型 。

高级场景
针对比较高端的用户使用场景比较复杂，腾讯云推出应用型  可以在单个  上实现业务分离，真正基于应用层内容进行负载均衡。如下图所示。这种类型的  就完全弥补了传统的缺陷。主要优点整理如下：

每个  分配一个 

不会分配固有域名， 下可以创建多个监听器

每个监听器下可以创建多个域名

每个域名下可以创建多个规则

子机绑定在规则维度，并且可以绑定一台子机上的多个端口


这样做的好处比较多：真正发挥  七层转发的优势， 开始了解业务；有利于收敛，整个网站对外可以只使用一个公网；节省二级域名，减少解析次数，有效提高用户访问速度；自定义转发规则，会话保持和健康检查的颗粒度可以细致到转发组级别。

 实现
隧道技术区分
公网  流程中   中  集群上需要区分网络和物理网络。网络采用隧道封装技术实现和虚拟机之间进行通讯，物理网络采用隧道封装技术实现和虚拟机之间进行通讯。层和层负载均衡实现分别是在不同的集群上进行，当然实现技术也是不一致的。如果不清楚和隧道区别，请看下图。


根据小编本人理解， 技术主要应用场景在于该数据包的目的地址不是  里面封装的  信息，但是数据包到达目的端之后需要  的封装信息进行进一步操作 目前当数据包到达母机之后，母机根据  信息决定下一步路由； 隧道主要应用场景在于该数据包的目的地址就是即将要封装的  信息，可以理解为将新的  把原来的数据包进行再一次封装，这样数据包才能根据封装的目的进行路由。
层 
 网络
　　先对层  网络负载均衡整体的架构做简单介绍。用户在  控制台或者调用  操作之后，操作流最终会下发到  提供的  组件模块，该  模块主要负责提供接口比分配  ，创建监听器，创建域名和规则等供  调用， 上存在组件将接口请求中的相关规则下发到集群内每个  设备内核中， 上负载均衡转发功能主要由相关内核模块实现。
数据包入方向

当用户访问  的时候，首先数据流会到  中，根据下发规则找到  对应的  ，然后对数据包进行  和 ，将目的  和源  分别改为  和  。

 上存在  设备对数据包进行  封装，将  带入数据包，这样数据包就会将带有  头的数据包发送给子机所在的母机。

 母机上存在  设备对数据包进行解封装，根据  和  即可将请求发送给相应虚拟网桥下的对应子机。


数据包出方向

首先在经过虚拟网桥之后  设备需要对数据包进行  封装，此时的目的  为  ，源  为 。

数据包向  发送回到  上，在  上进行去掉  部分，进行  和  ，将源  和目的  转换为  和客户端  。

则数据包可以正常返回给客户端。这样既可完成一次负载均衡数据交互。



物理网络
整体流程上和  基本一样，只是在  和  之间通讯时通过  隧道的方式进行的， 的  集群中存在内核模块对数据包进行  隧道封装和解封装如下图。

七层 
层目前使用的底层架构是    的升级版，这里简单说一下  的强大之处。

多协议适配及卸载支持    ，对业务透明，减少业务协议适配压力

内容路由根据  ，  等字段深度匹配，精确、正则、前缀匹配

负载均衡策略加权轮询，_，最小连接数，一致性 


层针对  来讲主要是提供  和  服务，  有三大功能：身份认证防冒充；数据加密防窃听；数据一致性防篡改，防抵赖。目前  针对  性能做了很大提升，目前已经具有以下特点。

并行支持协议多

 计算性能强

 防攻击能力强

 访问速度快

统一的证书管理及证书远程加载服务


网络
其实和四层的区别主要是中间多了一层，如下图所示为  公网  数据流程图，这一层主要是做  反向代理和层负载功能的。本应该  和实体网络  之间是可以通过普通的  包进行数据交互的，但是  子机的话，存在私有网络和自定义 ， 就没法和  之间进行直接通讯了，目的  为  子机的话，数据包是没法路由的。为了解决上面的问题， 在上安装了内核模块，该内核用来模拟  封装  包，然后将  后的数据包和  子机进行交互就没有任何问题了。 为腾讯云业务层， 模块接收到请求之后将规则下发到 的配置文件中， 通过反向代理功能和  本身负载均衡功能会进行  维度的负载转发。


 提供的反向代理和负载均衡能力，这个是层负载均衡的核心功能。上面谈到 会下发业务侧的规则到 上，其实就是下发一个  的配置文件到 上，如下图所示。可以看到这个配置文件里面域名就是用户在控制台配置的域名，还有、信息、子机，权重等信息都存在这个配置文件中。


用户访问

模块中 _ 用来指定  或者域名，当用户访问这个域名的时候 _ 将请求匹配给  中  路径下 _ 这里  会根据不同的路径进行转发给相应的 _ ，实现了基于路径转发的能力

_ 接下来就交给相应的  模块处理了


 模块
 为  负载均衡的主要模块。它提供了一个简单的方法实现在轮训和客户端  之间的后端服务器负载均衡，并且可以对后端服务器进行健康检查。 并不处理请求，而是通过请求后端服务器得到用户的请求内容。在转发给后端时，默认是轮询，也可以是 _。
 健康检查
当  在检测到后端服务器故障后， 依然会把请求转向该服务器，当  发现  或者  后，会把改请求会分发到  的其它节点，直到获得正常数据后， 才会把数据返回给用户，上面配置文件中 _ 和 _ 字段就是和健康检查相关的。
物理网络
层物理网络负载均衡实现方式和  网络唯一的不同就是数据包封装技术不同，因为物理网络不需要进行封装，直接隧道即可实现和子机通讯如下图。其他就没有必要再详细说了，和  基本保持一致。

请求重定向
目前腾讯云应用型  支持请求重定向，域名端口  规则维度进行重定向。给用户直接的感受就是当你使用  在浏览器上进行访问时，请求会被自动重定向到  。这里底层的实现也是基于  的  操作进行处理。当用户设置了重定向操作之后，会在  下发如下配置

会话保持实现
 植入
在  插入模式下， 将负责插入  ，后端服务器无需作出任何修改。当客户进行第一次请求时，客户  请求不带  进入 ，  根据负载平衡算法策略选择后端一台服务器，并将请求发送至该服务器，后端服务器进行  回复不带  被发回  ，然后  插入  ，将  回复带  返回到客户端。当客户请求再次发生时，客户  请求带有上次  插入的  进入  ，然后  读出  里的会话保持数值，将  请求带有与上面同样的  发到指定的服务器，然后后端服务器进行请求回复，由于服务器并不写入  ，  回复将不带有  ，恢复流量再次经过进入  时， 再次写入更新后的会话保持  。
实践一下看看，可以看到第一次访问时返回给客户端的  值


 重写
表示负载均衡系统会根据用户自定义名称来分配和管理对客户端进行的植入操作，便于用户识别和区分自定义的名称，从而有选择的针对后端应用服务器上的不同应用设定会话保持规则，用户在进行配置时需要指定相应的名称。目前腾讯云不支持这种类型阿里云支持。
服务器如何分辨请求类型
由于  代理了  的  加解密，在后端  看来，所有层请求，都是  请求，客户不便于分辨是  ，还是  来源。 目前已全局生效，在   中植入  ：

    请求为  请求   

    请求为  请求


后端  可根据该信息判断来源。
服务器如何获取来访者真实 
　　针对  层  协议服务，负载均衡通过    获取来访者真实   ，该功能已经默认开启，无需配置，也不能修改。针对 层  协议服务可以直接获取，无需额外配置。
健康检查请求类型
目前默认是  方式进行请求，后续会改为默认使用  ，可选  的请求方式。修改后的健康检查使用协议 增加了  字段  字段可配置。  和  请求方式的区别如下： 
：只请求页面的首部。： 请求指定的页面信息，并返回实体主体。
其中，默认使用  方法请求的话，服务器返回的只是响应标题，可以有效降低后端开销，提高请求效率。但在某些业务场景下依然需要选取  方式请求，例如在较为苛刻的健康检查时，需要通过判断  中某些字段来获取版本号等，此时  请求返回的数据不足，需要通过  来实现。
 默认 
：浏览器接收到头部信息后，接受完  中定义的长度字节后开始解析页面，但如果服务端有部分数据延迟发送吗，则会出现浏览器白屏，造成比较糟糕的用户体验。中引入了   来解决上面这个问题，发送方将消息分割成若干个任意大小的数据块，每个数据块在发送时都会附上块的长度，最后用一个零长度的块作为消息结束的标志。这种方法允许发送方只缓冲消息的一个片段，避免缓冲整个消息带来的过载。该功能，主流的浏览器，以及  、  等  服务器是默认支持的，无需配置。
 同步
实现  集群后，肯定会首先考虑  同步问题，因为通过负载均衡后，同一个  访问同一个页面会被分配到不同的服务器上，如果  不同步的话，一个登录用户，一会是登录状态，一会又不是登录状态。腾讯云目前实现了集群内  连接定期同步。这样在别的服务器接管故障机器的包时，能够正确找到  ，保证提供正常服务。不同集群之间进行  同步，目前腾讯云尚不支持。
利用  同步  ： 是文件的形势存放在服务器端的， 是文件的形势存在客户端的，怎么实现同步呢？方法很简单，就是把用户访问页面产生的  放到  里面，就是以  为中转站。你访问  服务器 ，产生了  把它放到  里面了，你访问被分配到  服务器 ，这个时候， 服务器  先判断服务器有没有这个  ，如果没有，在去看看客户端的  里面有没有这个 ，如果也没有，说明  真的不存，如果  里面有，就把  里面的  同步到  服务器 ，这样就可以实现  的同步了。
集群容灾
集群容灾，简单来说就是一个集群中一台服务器倒掉不会影响整个集群的服务能力。 采用  动态路由协议来实现集群的容灾，若一台机器倒掉， 协议可以保证在 以内把机器从集群中剔除。 一个集群放在两个接入交换机下，并且保证跨机架的容灾，这样保证在即便有单边的交换机出故障或者单边机架掉电时，本集群的服务不受影响。
抗  攻击
腾讯云有非常厉害的大禹系统来保护业务，但是大禹系统的宙斯盾的检测时长是，那么在大禹系统生效之前，可能客户的  已经被压垮。为了解决这内的问题，我们开发了  的功能。目前腾讯云这边的具体实现是： 在接收到客户端的三步握手请求时，代理三步握手，在数据包到来之前，不会打扰到 ，一旦第一个包到来， 将其缓存，此时再和  进行三步握手，握手成功之后，将缓存的数据包发送给 ，之后的流程就透传数据包了。这样保证  攻击不会到达 ，而是由  来承担压力。本身承载能力比较强，又是集群模式，同时又具备资源隔离的能力，所以一般情况下，很难在以内把  机器压垮。 
结束语
本文主要讲述了腾讯云  的基本概念，业务架构以及公网  技术实现。关于内网  的技术实现请参考另一篇文章《腾讯云内网负载均衡技术实现》。接上文 《红包技术方案全解密 一 》
三、红包创新玩法挑战
春节红包大战，从企业红包演变到刷一刷红包、个性化红包和红包，玩法不断创新，用户体验更好，活跃度提升，参与人数也从亿增长到年春节的亿。

个性化红包

个性红包是在红包外观上的一次大胆尝试，借助该功能，用户可使用霸气的书法体将自己的姓氏／或其他文字提供自动简繁体转换镌刻在红包封皮上。此外，我们还提供了具有新年氛围的贺岁红包、与腾讯紧密结合的 、游戏形象、动漫形象等卡通红包，大大提高了红包的趣味性与观赏性。个性红包功能上线后，有超过的红包用户选择使用个性红包。在年春节期间共有万用户使用该功能，年除夕当晚突破千万的个性红包发送量。

个性红包在普通基础上，允许用户修改红包封皮，展示个性，应合场景，因此设计的要点是使用户操作顺畅，既保持发、抢红包的流畅体验，又能显示个性和有趣好玩。
个性化红包流程架构如下图所示：

从上图可以看出，简化后的红包的发放过程经历红包终端财付通红包后台手聊天交互窗口拆抢红包页面等过程，流程较长忽略了一些细节，实际流程更复杂，在这些步骤过程中如果每一步都走后台判断个性化红包状态，必然影响到红包的发放流畅性。
为了尽量不影响用户发红包体验，个性化红包在架构和运营上作了很多解藕和柔性设计。包括个性字体提前绘制，资源预加载，功能开关和容灾柔性处理等。
字体提前绘制
个性化红包支持所有简体与繁体汉字，并支持部分简体汉字转换成繁体汉字，为了改善使用“姓氏红包”用户的体验，我们把常用的个姓氏，使用预生成的方式，在用户手空闲的时候生成常用的姓氏图片保存到本地。其他的非常用姓氏，在展示的时候合成，合成一次保存在本地，下次在本地读取。
手终端在空闲时绘制好字体贴图，支持定时更新背景图和字体库，对非常用字，则启动个性化字体引擎生成对应的个性化贴图。
用户在发放或收到红包时，个性化背景和字体贴图已经生成好，不需要再生成，收发红包流畅体验无损。

资源预加载
个性化红包封素材提前制作好，上传到网络，手在空闲时提前从下载素材文件，并定时检查素材更新情况，及时更新。
功能开关
用户是否设置个性红包，选择的个性红包贴图样式，是否启用个性红包等信息，如果每次判断都从后台拉取，势必增加后台压力。用户对个性红包的设置信息，其实变化不大，并且访问红包商场实时设置的状态的结果在手终端是存在的。因此我们设计将这些用户状态在手登录时，从后台拉取一次后保存在手终端，在发红包的过程中将信息传递到下游服务中，通过红包商城设置的个性化红包标志，实时更新手本地配置。
这样的设计有几个好处

用户的个性化设置不再依赖于后台，发红包过程完全本地操作，没有任何延时，不影响红包的发放。

标志可以作为容灾开关，如果临时取消个性红包，或后台故障，可以临时屏蔽个性红包功能，恢复为默认红包样式，保障任何时刻红包功能正常可用。

标志可支持扩展，在红包后台可以根据扩展，支持付费红包样式付费购买、特权红包样式如超会专享等，支持红包商城扩展各种各样的个性化红包。

除了从后台拉取，当业务有调整导致变化，红包后台可以向手终端主动 状态，使得用户及时感知变化，进一步增强用户使用体验。


容灾柔性处理
相对于手平台功能，个性红包系统相对独立，运营和更新很快，系统各功能组件出现问题的几率可能较多，如果个性红包业务出现问题，而影响到正常红包发放或手功能的使用，会对口碑造成很大负面影响。我们在系统中设计了多处容灾和柔性处理措施，在个性红包业务异常时，能降级提供服务，最差时取消个性红包功能。
柔性措施一：用户登录时拉取个性红包失败时，采用默认红包样式。柔性措施二：红包后台向个性化红包后台拉取个性化设置鉴权详情是否付费、是否会员专享等时，如果拉取异常，采用默认红包样式。柔性措施三：个性化红包由用户输入姓氏，指定显示文字，可能遇到敏感字或需要临时下线，可以通过向手下发标志，临时取消个性红包功能，恢复到默认红包样式。

红包

红包是“天降红包”的简称，这个创新的玩法得到了用户的一致好评，参与用户亿次，共计领取红包和礼券亿个，获得了口碑和活跃的双丰收。

缓存设计
红包与以往的红包最大的不同在于多了一重地理位置关联，全国有上千万的地理位置信息，结合活动的任务奖品数据产生了海量的配置数据，而这些数据都需要快速实时读取。这是系统设计的一大挑战。
配置数据有以下特点：

数据量很大亿级，数据间有紧密的关联，我们采用数据库集群存储，并构建有可视化配置投放平台，实现自动容灾和备份的功能；

“一次配好，到处使用”，配置读量远高于写量，基本思想是设计开发一种缓存，放弃写性能，将读性能优化到极致。


上千兆的配置数据，如何供抽奖系统快速检索？考虑到业务使用场景、配置数据大小及性能，可以采用预先构建全量缓存并进行有序组织，由同步模块负责将构建好的配置数据同步到抽奖系统，供业务进程直接使用。为保证配置数据完整性，构建缓存采用双设计，只有构建或同步完成后才切换到最新配置。

地图打点与查点
基于的红包活动离不开地理位置相关的业务交互。在红包中，用户打开地图会定期向后台上报坐标，后台需要根据坐标获取周围可用的活动任务投放点，投放点事先都会进行安全筛查，去掉具有安全隐患的区域，避免给用户带来人身安全问题，本节主要介绍如何管理这些投放点。
地图格子
将整个二维平面根据坐标分成边长相等的正方形格子，根据用户的坐标用简单的数学运算即可获取相应的格子，时间复杂度。一个格子是一次查询的最小粒度。每次查询会返回以用户为中心周围共计个格子的任务点。

打点
红包是以任务维度投放的，每个任务关联一个集合，每个集合中包含几个到上百万不等的点，每个点都有一个经纬度信息。
打点即是事先建立格子到任务列表的映射。所有格子数据有序组织并存储在共享内存里，使用二分查找提升读性能。
查点流程
 客户端上报经纬度。
 根据经纬度计算中心格子。
 根据中心格子及半径配置，获取周围格子列表。
 在打点系统中获得此片区域全部和任务信息。
 检查任务状态后返回给客户端。
采集系统
采集系统主要负责汇总各行政区红包发放状态数据，主要提供以下功能：
实时返回区级行政区红包计数；
实时接受主逻辑的查询，返回奖品发放状态；
返回活动预告以及参数配置等辅助信息。
由于红包是按行政区进行投放的，每个行政区约投放个任务，每个任务又关联多种类型的红包，如果每次查询区级红包余量时，都实时计算和汇总红包状态数据，扩散带来的包量开销会比较大，为此，我们还是采用双缓存来解决该问题，一个进程负责将采集到的数据写到缓存，另一组进程提供查询服务。另外，还可以根据存储层的压力，适当地调整采集的频率，使得统计数据尽可能实时。

四、总结
自年起，历年除夕当天红包收发情况如下表所示，可以看出，参与人数和红包首发总个数都是节节升高。

红包业务复杂，海量访问，涉及业务多，流程长，项目的成功离不开相关兄弟部门的大力支持和能力合作，特别感谢即通产品部、财付通、即通平台部、市场部、商业广告中心、增值渠道部、社交用户体验设计部、集团市场与公关部、增值产品部、社交与效果广告部、网络质量部、即通综合部、架构平台部、社交平台部、网络运营部等个兄弟部门相关同事的付出和给力支持。作者介绍：黄日成，手游戏中心后台开发，腾讯高级工程师。从事服务后台开发年多，主要负责手游戏中心后台基础系统、复杂业务系统开发，主导过手游戏公会、企鹅电竞对战系统等项目的后台系统设计，有丰富的后台架构经验。

说到协议，相信大家都比较熟悉了，对于协议总能说个一二三来，但是协议又是一个非常复杂的协议，其中有不少细节点让人头疼点。本文就是来说说这些头疼点的，浅谈一些的疑难杂症。那么从哪说起呢？当然是从三次握手和四次挥手说起啦，可能大家都知道是三次交互完成连接的建立，四次交互来断开一个连接，那为什么是三次握手和四次挥手呢？反过来不行吗？
疑症  ： 的三次握手、四次挥手
下面两图大家再熟悉不过了，的三次握手和四次挥手见下面左边的”建立连接”、”数据传送”、”断开连接”时序图和右边的”协议状态机”

三次握手、四次挥手时序图

协议状态机
要弄清建立连接需要几次交互才行，我们需要弄清建立连接进行初始化的目标是什么。进行握手初始化一个连接的目标是：分配资源、初始化序列号通知对端我的初始序列号是多少，知道初始化连接的目标，那么要达成这个目标的过程就简单了，握手过程可以简化为下面的四次交互：

   端首先发送一个  包告诉  端我的初始序列号是  。    端收到  包后回复给  一个  确认包，告诉  说我收到了。   接着  端也需要告诉  端自己的初始序列号，于是  也发送一个  包告诉  我的初始序列号是。    收到后，回复  一个  确认包说我知道了。

整个过程次交互即可完成初始化，但是，细心的同学会发现两个问题：
 发送包是作为发起连接的包，还是作为响应发起者的包呢？怎么区分？比较容易引起混淆 
的确认包和接下来的包可以合成一个 包一起发送的，没必要分别单独发送，这样省了一次交互同时也解决了问题 这样建立一个连接，三次握手在进行最少次交互的情况下完成了两端的资源分配和初始化序列号的交换。
大部分情况下建立连接需要三次握手，也不一定都是三次，有可能出现四次握手来建立连接的。如下图，当两端同时发起来建立连接的时候，就出现了四次握手来建立连接对于有些的实现，可能不支持这种同时打开的情况。

在三次握手过程中，细心的同学可能会有以下疑问：
 初始化序列号、是可以是写死固定的吗，为什么不能呢？
 假如发送一个包给后就挂了或是不管了，这个时候这个连接处于什么状态呢？会超时吗？为什么呢？
进行断开连接的目标是：回收资源、终止数据传输。由于是全双工的，需要两端分别各自拆除自己通向对端的方向的通信信道。这样需要四次挥手来分别拆除通信信道，就比较清晰明了了。

 发送一个包来告诉  我已经没数据需要发给 了。 收到后回复一个  确认包说我知道了。然后  在自己也没数据发送给后， 也发送一个  包给  告诉  我也已经没数据发给 了。 收到后，就会回复一个  确认包说我知道了。

到此，四次挥手，这个连接就可以完全拆除了。在四次挥手的过程中，细心的同学可能会有以下疑问：
 和同时发起断开连接的包会怎么样呢，状态是怎么转移的
 左侧图中的四次挥手过程中，端的确认包能不能和接下来的包合并成一个包呢，这样四次挥手就变成三次挥手了。
 四次挥手过程中，首先断开连接的一端，在回复最后一个后，为什么要进行_呢超时设置是 ，定义了为分钟，设置成了，在_的时候又不能释放资源，白白让资源占用那么长时间，能不能省了_呢，为什么？
疑症     连接的初始化序列号能否固定
如果初始化序列号缩写为：  可以固定，我们来看看会出现什么问题。假设固定是，和建立好一条连接后，连续给发了个包，这个包不知怎么被链路上的路由器缓存了路由器会毫无先兆地缓存或者丢弃任何的数据包，这个时候碰巧挂掉了，然后用同样的端口号重新连上，又连续给发了几个包，假设这个时候的序列号变成了。接着，之前被路由器缓存的个数据包全部被路由到端了，给回复确认号，这个时候，整个都不好了，这是什么情况？我的序列号才到，你怎么给我的确认号是了，整个都乱了。
中，建议和一个假的时钟绑在一起，这个时钟会在每微秒对做加一操作，直到超过，又从开始，这需要小时才会产生的回绕问题，这几乎可以保证每个新连接的不会和旧的连接的产生冲突。这种递增方式的，很容易让攻击者猜测到连接的，现在的实现大多是在一个基准值的基础上进行随机的。
疑症   初始化连接的  超时问题
发送包给后挂了，回给的一直没收到的确认，这个时候这个连接既没建立起来，也不能算失败。这就需要一个超时时间让将这个连接断开，否则这个连接就会一直占用的连接队列中的一个位置，大量这样的连接就会将的连接队列耗尽，让正常的连接无法得到处理。
目前，下默认会进行次重发包，重试的间隔时间从开始，下次的重试间隔时间是前一次的双倍，次的重试时间间隔为    ，总共，第次发出后还要等都知道第次也超时了，所以，总共需要          = ，才会把断开这个连接。由于，超时需要秒，那么就给攻击者一个攻击服务器的机会，攻击者在短时间内发送大量的包给俗称   攻击，用于耗尽的队列。对于应对 过多的问题，提供了几个参数：_、__、___、___ 来调整应对。
疑症    的  两端同时断开连接
由上面的”协议状态机 “图可以看出，的端在收到对端的包前发出了包，那么该的状态就变成了_，在_状态下收到对端对自己包的包的话，那么状态就变成_，在_下收到对端的包，在确认已经收到了对端全部的数据包后，就响应一个给对端，然后自己进入_状态。
但是如果在_状态下首先收到对端的包的话，那么该在确认已经收到了对端全部的数据包后，就响应一个给对端，然后自己进入状态，在状态下收到自己的包的包的话，那么就进入  状态。于是，的两端同时发起包进行断开连接，那么两端可能出现完全一样的状态转移 _————_，也就会和最后同时进入_状态。
同时关闭连接的状态转移如下图所示：

疑症   四次挥手能不能变成三次挥手呢？
答案是可能的。
是全双工通信，在自己已经不会在有新的数据要发送给后，可以发送信号告知，这边已经终止到对端那边的数据传输。但是，这个时候对端可以继续往这边发送数据包。于是，两端数据传输的终止在时序上是独立并且可能会相隔比较长的时间，这个时候就必须最少需要 =  次挥手来完全终止这个连接。但是，如果在收到的包后，在也没数据需要发送给了，那么对的包和自己的包就可以合并成为一个包发送过去，这样四次挥手就可以变成三次了似乎协议栈就是这样实现的
 疑症    的头号疼症 _ 状态
要说明_的问题，需要解答以下几个问题

两端，哪一端会进入_呢？为什么

相信大家都知道，主动关闭连接的那一方会最后进入_。那么怎么界定主动关闭方呢？是否主动关闭是由包的先后决定的，就是在自己没收到对端的包之前自己发出了包，那么自己就是主动关闭连接的那一方。对于疑症 中描述的情况，那么两边都是主动关闭的一方，两边都会进入_。为什么是主动关闭的一方进行_呢，被动关闭的进入_可以不呢？我们来看看四次挥手可以简单分为下面三个过程

过程一主动关闭方发送；过程二被动关闭方收到主动关闭方的后发送该的，被动关闭方发送；过程三主动关闭方收到被动关闭方的后发送该的，被动关闭方等待自己的

问题就在过程三中，据协议规范，不对进行，如果主动关闭方不进入_，那么主动关闭方在发送完就走了的话，如果最后发送的在路由过程中丢掉了，最后没能到被动关闭方，这个时候被动关闭方没收到自己的就不能关闭连接，接着被动关闭方会超时重发包，但是这个时候已经没有对端会给该回，被动关闭方就无法正常关闭连接了，所以主动关闭方需要进入_以便能够重发丢掉的被动关闭方的。

_状态是用来解决或避免什么问题呢？

_主要是用来解决以下几个问题：

上面解释为什么主动关闭方需要进入_状态中提到的： 主动关闭方需要进入_以便能够重发丢掉的被动关闭方包的。如果主动关闭方不进入_，那么在主动关闭方对被动关闭方包的丢失了的时候，被动关闭方由于没收到自己的，会进行重传包，这个包到主动关闭方后，由于这个连接已经不存在于主动关闭方了，这个时候主动关闭方无法识别这个包，协议栈会认为对方疯了，都还没建立连接你给我来个包？，于是回复一个包给被动关闭方，被动关闭方就会收到一个错误我们见的比较多的：   ，这里顺便说下  ，在收到包的时候，还往这个连接写数据，就会收到  错误了，原本应该正常关闭的连接，给我来个错误，很难让人接受。
防止已经断开的连接中在链路中残留的包终止掉新的连接重用了连接的所有的元素源，目的，，源端口，目的端口，这个概率比较低，因为涉及到一个匹配问题，迟到的分段的序列号必须落在连接的一方的期望序列号范围之内，虽然概率低，但是确实可能发生，因为初始序列号都是随机产生的，并且这个序列号是位的，会回绕。
防止链路上已经关闭的连接的残余数据包         干扰正常的数据包，造成数据流的不正常。这个问题和类似。

 _会带来哪些问题呢？
_带来的问题注意是源于：一个连接进入_状态后需要等待一般是到分钟那么长的时间才能断开连接释放连接占用的资源，会造成以下问题

 作为服务器，短时间内关闭了大量的连接，就会造成服务器上出现大量的_连接，占据大量的，严重消耗着服务器的资源。
 作为客户端，短时间内大量的短连接，会大量消耗的机器的端口，毕竟端口只有个，端口被耗尽了，后续就无法在发起新的连接了。

  由于上面两个问题，作为客户端需要连本机的一个服务的时候，首选域套接字而不是 
 _很令人头疼，很多问题是由_造成的，但是_又不是多余的不能简单将_去掉，那么怎么来解决或缓解_问题呢？可以进行_的快速回收和重用来缓解_的问题。有没一些清掉_的技巧呢？
文章来自公众号：小时光茶社 

相关推荐 关闭连接为什么会能__前 言
经过周末两天的折腾，在大家的帮助下最终将用户  的性能峰值由最初的不到  的    提升至 ，心情也由最初的忐忑过渡到现在的平静，现在想来，整个的优化过程感觉还是比较好玩的，趁着现在还有些印象，就把整个排查  优化过程详细的记录下来，以备不时之需，也希望能给人一些启发来解决其它问题，同时，也让俺感谢一下在整个解决过程中给予很多帮助的同事，没有你们在背后的帮助， 端解决问题的时间要更久！
问题背景
上周团队聚餐的时候，老大说有一个用户使用  的时候遇到了问题，现有的  性能无法满足用户的性能需求。用户在对现有的  进行压力测试时发现    小于 ，继续加大压力的时候  上涨、  很低、  飙升、性能下降，最终导致网站处理并发能力的下降，无法达到预期的吞吐量。用户在对现有逻辑及吞吐量计算的基础上提出了性能指标，即  的单机性能    大于 ， 只有这样才能满足业务要求，否则  就是整个链路的瓶颈。由于用户的上线时间临近，上线压力比较大，老大说周末尽力搞定，如果搞不定，只能上最好的机器来解决性能问题，这样的话，成本就要上来了。当时正在吃饭，瞬间感觉压力山大，不能好好的吃肉了……，有木有……！
现场信息收集
第二天还没醒就收到老大的消息，然后怀着疑惑的心情火速上线，登录到机器上，开始了  性能的调优之旅……
首先，使用  监控工具查看了用户实例的性能状态，如下所示：
   
          |   |               |         |       |
  |        |            |   |           |
  |        |            |   |           |
  |         |            |   |           |
  |        |            |   |           |
  |        |            |   |           |
  |        |            |   |           |
  |         |            |   |           |
  |        |            |   |           |
  |        |            |   |            |
  |        |             |   |           |
从上面的性能信息可以发现命中率 ， 即用户基本是全内存操作，  较高， 有少量，   彪升，到底线程在做什么呢？怀着这样的疑问，然后执行了一下  {  }   以获取实例的内部线程信息，然后使用   将堆栈信息进行显示，发现了如下的信息：
 _________________________________________________
  __________________________________________________________________________
    
    
     ____________________________
根据上述的    文件相结合，可以看到如下堆栈：
    ____   
    ___   
    __   
    ___ _= _= _ = __  _
   = __  _
  _ == _=_= _=_=  _
    ___ _= __= _= = = = = =  _
  _ == == = == _=_=  _
    ____ == = ==  _
    __ == _=   _
   __ ==  _
根据上面收集的信息我们可以清楚的得出以下结论：

应用在执行语句的过程中，__ 中的锁冲突比较严重；
  层中的 _ 冲突比较重；
实例开启了 _ 功能；

经过了上面的分析，我们需要着重查看上述问题的相关变量，变量设置的情况会对性能造成直接的影响，执行结果如下：
     _ 

| _      |  |

| _ |     |

     

     

| _                           |   |

| ___            |       |
| ___           |       |
| ||
| ||
| ___              |       |

     
参数分析
这里我们先来介绍一下上述参数在  中的作用  含义：

___ 简介

___ 指的是  缓存  句柄的分区的个数，而每一个 _ 可以包含不超过 _____ 的__，详细可以参考官方的说明文档：___， 打开表的过程可以简单的概括为：
、根据线程的 _ 确定线程将要使用的 _，即 _  __、从该 _ 元素中查找相关系连的 __，如果存在转 ，如果不存在转 ；、从  中查找的__ 的 _ 中出取一个并返回，并调整 __ 中的 _  _ 元素；、如果  中不存在，则重新创建一个  并加入对应的 __ 的 _的列表；
从以上过程可以看出， 在打开表的过程中会首先从 _ 中进行查找有没有可以直接使用的表句柄，有则直接使用，没有则会创建并加入到对应的 _ 中对应的 __ 中，从刚才提取的现场信息来看，有大量的线程在查找 _ 的过程中阻塞着了，而 ___ 的个数为 ， 因此，此参数的设置需要调整，由于 ___ 的大小和 线程   并发 有关系，考虑当前的并发是左右，于是将该植设置为 ；
 中不同的线程虽然使用各自的  句柄，但是共享着同一个_，如果想从源码上了解   _ 以及 两者之间的相互，可以从变量 __， ___，__ 入手，阅读 __， _， __ 等相关代码，由于篇幅限制，在此不在详述。

  的前世今生

在  中有一个   乱序的问题，详情及复现方法可以参考这篇文章：   操作导致复制中断，_ 就是为了解决上述问题而在  中引入的。简单的说   是   层中的表锁，主要是为了控制  层    的并发而设计的， 但是  的设计中只有一把大锁，所以到中添加了参数 ___ 来控制分区的数量，进而实现大锁的拆分，虽然锁的拆分提高了并发的性能，但是仍然存在着不少的性能问题，所以在  中   的实现方式采用了   算法，彻底的解决了  层表锁的性能问题，而参数 ___ 也将会在之后的某个版本中被删除掉；
参考文档：___
由于实例中的表的数目比较多，而 ___ 的参数设置仅为，因此，为了将底锁的冲突的可能性，我们将此值设置为 ；

  作用  影响

通俗的说，  是  的内部诊断器，用于记录  在运行期间的各种信息，如表锁情况、 竟争情况、执行语句的情况等，和   类似的是拥用的信息都是内存信息，而不是存在磁盘上的，但和 _ 有以下不同点：

_ 中的信息都是从  的内存对象中读出来的，只有在需要的时候才会读取这些信息，如   _ 等，不需要额外的存储或者函数调用，而   则是通过一系列的回调函数来将这些信息额外的存储起来，使用的时候进行显示，因此   消耗更多的    资源；
_ 中的表是没有表定义文件的，表结构是在内存中写死的，而 _ 中的表是有表定义文件的；
实现方式不同，_ 只是对内存的   而 _ 则使用固定的接口来进行实现；
作用不同，_ 主要是轻量级的使用，即使在使用的时候也很少会有性能影响，_ 则是  的内部监控系统，可以很好的定位性能问题，但也很影响性能；

由以上的分析不难看出，在性能要求比较高的情况下，关闭 _ 是一个不错的选择，因此将 _ 关闭。另外关闭 _ 的一个原因则是因为它本身的稳定性，因为之前在使用 _ 的过程中遇到了不稳定的问题，当然，遇到一个问题我们就会修复一个，只是考虑到性能问题，我们暂时将其关闭。
_ 的详细使用说明可以参考：
_ 中文文档__ 官方文档
经过上面的分析和判断，我们对参数做了如下的调整：
___=
___=
_=
__=
勉强解决问题
调整了以上参数后，我们重启实例，然后要求客户做新一轮的压力测试，测试部分数据如下：
   
          |   |               |          |       |
     |        |                |   |            |
     |        |               |   |            |
    |        |             |   |            |
    |        |            |   |           |
    |        |            |   |            |
    |        |            |   |            |
    |        |            |   |            |
    |        |            |   |            |
    |        |            |   |            |
    |        |            |   |            |
从以上的测试数据来看，      已经满足要求，通过    { } 命令查看了一下系统负载，发现了一处比较吃  的地方 _，详情如下：
                  _ 
                    ___
                    ____    
                    ____  ___
                  ___
                    __
                    __
                    __
                    
              ____
        __
                    ___    __    
                    _
              __
使用      进行分析，发现调用比较多的地方是： __，于是断定  底层资源冲突比较严重，根据以往的经验执行如下命令：
    

| _          |  |

| ___ |  |
| ___ |     |

     
在  内部，当  线程获取  资源而得不到满足时，会最多进行 ___ 次尝试获取  资源，每次失败后会调用 ___ ___，导致 _ 占用了过多的 ， 其中 _ 的定义如下：

           
        
   
_

_
=====
                      
{
            
         = 
          =        {
                 = 
                __
        }
         __ {
                __ =  
        }

        
}
由于这两个值的设定取决于实例的负载以及资源的竟争情况，所以不断的尝试设置这两个参数的值，经过多次的尝试最终将这两个参数分别设置为：___ = ， ___ =  请注意这两个值不是推荐值！！！ 才将 _ 的占用资源降下来，最终降低了不必要的  消耗的同时   也稳定在了 ，具体资源占用详情如下：
                  ___
                  ___
                    __
                    __
                    __
                    _ 
                    ____  ___
                    
              ____
                    ____    
        __
优化到这个地步似乎达到了客户要求的性能，即  单机性能为     ，可是如果并发量在加大，我们的  能扛住更高的压力吗？
又起波澜
经过上面参数的调整， 已经不是性能的瓶颈，应用的吞吐量由之前的   ，但是离  的吞吐量还比较远，瓶颈出现在了应用端，为了增加吞吐量，客户又增加了几台客户端机器，连接数也由之前的  上升到 ，此时发现  虽然能够响应，但偶尔会出现   飙高的情况，具体运行状态如下，其中 __ = __  __  __：

|                | _ |  | __ | __ | __ | __ | __ | _ | _ |

|   |    |    |              |              |                 |             |           |               |                 |
|   |    |    |              |              |                 |             |           |               |                 |
|   |    |    |              |              |                 |             |           |              |                 |
|   |    |    |              |              |                 |             |           |               |                 |
|   |    |    |              |              |                 |             |           |              |                 |
|   |    |    |              |              |                 |             |           |               |                 |
|   |    |    |              |              |                 |             |           |               |                 |
|   |    |    |              |              |                 |             |           |              |                 |
|   |    |    |              |              |                 |             |           |              |                 |
|   |    |    |              |              |                 |             |           |              |                 |
|   |    |    |              |              |                 |             |           |              |                 |
|   |    |    |              |              |                 |             |           |              |                 |
|   |    |    |              |              |                 |             |           |              |                 |
|   |    |    |              |              |                 |             |           |              |                 |
|   |   |    |               |              |                 |             |           |              |                 |
|   |   |    |              |              |                 |             |           |              |                 |
|   |   |    |              |              |                 |             |           |               |                 |
|   |   |    |              |              |                 |             |           |              |                 |
|   |   |    |               |              |                 |             |           |              |                 |
|   |   |    |               |              |                 |             |           |              |                 |
接下文：《畅游数据库性能优化过程简析下》导语
近日，腾讯游戏安全中心捕获一款网吧内传播的恶意软件。原以为是常规的网吧盗号木马，但详细分析之后发现并非如此。经证实该恶意软件是目前发现的首款利用   漏洞传播，释放虚拟货币矿机挖矿的肉鸡集群。
 来源
 年  月  日左右，由腾讯网吧守护  和顺网联合团队在某网吧内发现异常的  进程，以及与之相关  进程，遂提取样本到安全中心进行人工核实。
 真身
拿到样本后从外观看与系统自带的进程无异，但查看属性发现  是一个压缩文件，于是开始产生警觉。

尝试使用  解压此文件后，发现了惊天大秘密—— 攻击工具包。从字面上我们可以看到永恒之蓝、永恒冠军字样的攻击配置文件。同时我们在解压之后的文件中也找到了与样本同名的两个可执行体，以及同名的  配置文件。

打开  查看一下，发现正式永恒之蓝的攻击配置文件。

打开  查看一下，发现了另一个  工具  的攻击配置文件。

于是猜测压缩包内的  是  攻击程序，压缩包内的  则是  后门。
尝试手工运行这两个可执行文件，发现的确是命令行工具，只是配置文件不正确，无法完成攻击。

 毒手
了解到样本的真身之后，我们开始认为这是一个和  一样的勒索病毒，但是仔细想一下发现样本并没有造成网吧电脑的大规模爆发，也没有业主有反馈，于是怀疑这并非是一起简单的勒索病毒事件。
深入分析后发现初始的 我们称之为母体并非简简单单的释放攻击包，其自身在释放攻击载荷之后，还会开启对局域网络  端口的疯狂扫描，一旦发现局域网内开放的  端口，就会将目标  地址及端口写入  的配置文件中，然后启动  进行第  步溢出攻击。第  步攻击的结果会记录在  中，攻击完成后，母体会检查攻击是否成功，若攻击成功，则继续修改  的配置文件，并启动 压缩包内的 ，并非母体在目标计算机安装后门，此称之为第  步攻击，结果会记录在  中。





这就完了吗？仅此而已吗？那这玩意儿到底是为了啥？这不科学，没有病毒仅仅是为了传播儿传播，但是此时我们的样本在实验室内已经不再继续工作了。于是我们在网吧中继续抓取到这东西的精彩后续：被安装了  后门的计算机中  进程被注入了一段 ，这和外网公布的  的行为一模一样，但样本中的这段  利用  进程在局域网被感染的其他计算机上下载了另一个神秘的可执行文件，而这个文件正是我们样本中一直没有提到的 与母体在同一目录下。


而这个  可不是 。那么它是啥？通过仔细的分析，我们发现它会做三件事情：
第一，先把自己添加到计划任务的一个不起眼的地方，让人感觉是一个合法的任务，从而达到自启动的目的。

第二，在局域网其他电脑上下载一个母体文件，以便于二次传播。
第三，释放一个  进程并以指定的参数执行这个进程。

继续跟踪这个  以及启动参数，发现了一个惊天大秘密，也就是整套传播机制的终极目的——挖矿。
从此程序的启动参数中我们看到了一个敏感的域名 一下发现这是一个国外各种数字货币的矿池，网站提供了各种数字货币的矿池地址，只要在网站注册账户，就可以利用矿机参与挖矿。而我们的样本中的矿机则是一款  上的开源矿机，挖矿的账户则是 这个账户，挖的正式一种不是很常见的数字货币——门罗币。



 横财
说道门罗币我们也要看一下这东西到底值多少钱，随便找了个交易平台看了一下，实时价格约人民币  元，价值虽然没有  那么高，但也不低，挖矿收益应该不少。

 总结
总体来看，恶意软件的释放、执行流程比较传统，但利用的攻击和漏洞相对比较新，在  漏洞被广泛利用到勒索软件的时候，作者却开启了另一扇淘金的大门。下面为大家图示总结一下此款恶意软件的传播和执行流程。

从  管家平台上看，此木马的传播量呈逐日上升阶段，还需要持续关注打击。在发文时，此款木马已经能够被腾讯电脑管家识别，并有效清除。




最后，提醒各位玩家及网吧业主应该及时更新操作系统补丁，避免被多次割韭菜，导致  伤疤未愈，僵尸矿机又来撒盐！作者简介： 薛伟， 腾讯专家工程师。

 引言
深度学习可以说是目前机器学习和人工智能领域最热的词汇了，已经热了数年，而且有望继续热下去。深度学习技术自横空出世以来，在多个应用领域刷新了历史记录，如语音识别、图像识别、自然语言处理等等，且其后劲甚足，不断有新的记录出现。近日，来自和的两个科学家团队又在体现高级人工智能的计算机围棋上以深度学习技术取得突破，大大提升了计算机棋手的棋力，取得了对一些人类棋手的胜利。的这一突破还登上了杂志的封面，并再次刷爆了笔者的朋友圈。
鉴于深度学习技术的辉煌战绩，以及目前来看深不可测的巨大潜力，各大和互联网公司纷纷投入资源开展研究与应用，以深度学习为方向的科研院所和创业企业也是层出不穷。鹅厂虽尚无深度学习研究院之类的独立部门，但是各不乏在深度学习研究和应用上颇有建树的团队，深度学习技术已经广泛应用于鹅厂各类产品，支持更好的语音识别、人脸识别、物体识别、商品识别、图片分类和检索、自然语言处理等等。本文将要分享的是笔者所在团队将深度学习技术应用于效果广告点击率预估的一些思考和实践经验。如笔者前文所言，本文是一个有点迟到的开篇，一些平台方面的工作在之前的文章中已有介绍，后面还会陆续补充一些细节内容。  
 从特征工程到端对端学习
需求来自于业务，方向来自于痛点。将深度学习技术应用于效果广告点击率预估并不是为了附庸风雅，而是因为有实际的需求和痛点。
时间回到三年前，当时现网点击率预估的主力算法模型是逻辑回归  。这是一个简单的广义线性模型   ，一般的机器学习和统计类教科书都有原理介绍，我们求极大似然估计，常用算法有并行随机梯度下降   ，和。模型和算法相对简单，但是特征工程 方面的工作量却是相当大的。
一种历史悠久并被广泛接受的观点认为，特征工程的本质是个表示问题。如果说机器学习算法是要从样本数据中学习出一个解模型的话，特征工程就是要寻找样本数据的最佳表示，使学到的模型更灵活、更简单、更准确。一般所说的特征工程大致包含了特征提取构造    和特征选择 两个部分。
特征提取构造是指自动特征提取手动特征构造地从原始数据出发构造新的特征的过程。自动特征提取方法包括从原始数据出发计算各种简单统计量、主成分分析  、无监督聚类 、图像中的线和边的检测等等，这些方法中有的还提供了对原始数据降维的功能。手动特征构造则是特征工程中更偏“艺术”的部分，通常要借助人的领域知识，以及对原始数据的深入观察和创造性思考。尽管在特征构造过程中可能会用到各种自动工具来辅助分析和可视化，在构造方法确定后，可能将其变成一个自动化的数据处理流程，但是特征构造过程的核心还是手动的。
特征选择是指从众多特征中挑选出少许有用特征的过程。和学习目标不相关的特征和冗余特征需要被剔除，如果计算资源不足或者对模型的复杂性有限制的话，还需要选择丢弃一些不重要的特征。特征选择方法大致可以分为三类：过滤器方法、包裹器方法和嵌入式方法。过滤器方法会为每个特征计算某种统计量如与目标变量的互信息 ，有时也称作信息增益，作为对这些特征的打分，然后按照打分对特征排序，过滤掉排名靠后的特征。包裹器方法会在由所有特征子集构成的空间中进行搜索，每次都用选中的特征子集训练一个模型，以该模型的精度作为对这个特征子集的打分。由于特征子集太多，所以这个搜索过程往往会使用启发式方法。嵌入式方法则是在训练模型的同时判断什么特征对模型精度的贡献大。一般是通过给模型引入正则化项，驱使学习算法产出复杂度相对较低的模型，从而达到上述目的。
效果广告点击率预估模型使用到了用户侧、广告侧和上下文侧的很多特征，持续的特征工程始终是模型效果提升的坚实基础。以用户兴趣类特征为例，依托账号打通的公司产品数据和广告数据，笔者所在的团队为各类精准推荐的场景打造了广告兴趣、兴趣、群兴趣、订阅兴趣、微信商业兴趣等等一系列的兴趣特征，并且还在持续丰富、改进和融合当中。用户兴趣类特征在点击率预估问题上的信息增益颇高，所以我们很早就将其加入模型，并带来了显著的效果提升，但是这个过程并不轻松，因为仅兴趣单独加入模型是不够的。当我们使用这样的广义线性模型时，除了引入用户侧、广告侧和上下文侧的众多基本特征之外，我们还需要引入交叉维度的特征。然而，特征交叉的空间是非常庞大的，即便是模型比较简单，也不可能无限制地做特征组合交叉并加入模型。兴趣类特征本就维度比较高，交叉后规模爆炸更快。此时的重担就压到了特征选择上，不是只挑选基本特征就好，还需要挑选交叉维度的特征。我们效仿实现了一套大规模特征选择工具 ，并在应用中引入一些领域知识来约简搜索空间。尽管如此，特征选择的开销，不论是人力资源还是计算资源，仍然是非常大的。
不仅如此，特征构造方面我们也面临着挑战。身处大数据时代，每天有大量的数据接入数平的数据平台并得到处理。笔者所在团队的同学每天都在想办法从数据中提取有价值的信息，进而构造有助于效果提升的特征。仍以用户兴趣类特征为例，目前用于构造这些特征的数据处理方法、工具和模型都是经过多年打磨的。每当有新的数据源接入，在打通用户账号后，负责兴趣特征构造的同学就会尝试从该数据源提取信息来丰富现有的兴趣，或者创建新的兴趣。如果新的数据源和已有数据源性质接近，现有的方法和工具可继续支持，仅需少许人工干预，例如参数调整。如果新的数据源和已有数据源异构性比较强，那么就需要设计新的特征构造方法。长远来看，我们需要有自动化程度更高的方法，用来从各类源数据出发构造特征。不仅如此，我们希望这种特征构造方法能够在一开始就和其最终服务的目标——效果广告点击率预估——对齐。这样做的好处是显而易见的，可以确保构造出来的特征不仅是与问题相关的，而且是精炼的。
特征选择开销大，特征构造成本高，这两个痛点是我们在实践中感受到并总结出来的。在效果广告业务开展的初期，这方面的痛感还不是非常强烈，或者说，尚未制约到效果的提升。但是随着业务的发展，对点击率预估模型的要求越来越高，特征工程的巨大工作量对效果提升的制约已经相当明显。从那时起，我们就开始思考和寻找各种技术手段来解决这个痛点，除了前面提到的自动化特征选择工具之外，我们还实现并生产应用了 等一批自动学习特征交互的模型。这些工作让我们对上述痛点有了更深入的认识，积累了经验，并最终促使我们转向深度学习寻找答案。
深度学习的算法模型众多，应用广泛，究其共性的话，表示学习 是一个核心的基本点。深度学习算法基于分布式表示 ，分布式表示假设我们所观察到的数据都是由因子之间的交互而生成的，而这些因子是按层来组织的。深度学习进一步假设这些由因子构成的层对应的是抽象或者组合的不同层级。对照前面我们的痛点，就不难理解我们为何会转向深度学习了。面对效果广告点击率预估这样一个有监督学习的问题，我们希望借助于深度学习来节约特征工程中的巨大投入当然，无法完全避免，更多地让点击率预估模型和各辅助模型自动完成特征构造和特征选择的工作这也被称作特征学习， ，并始终和点击率预估的目标保持一致。端对端学习   ，也称作端到端学习这个术语常被用来描述这个目标，这也是深度学习常被人推崇的能力。
笔者所在的团队在将深度学习技术应用于效果广告点击率预估之前，在深度学习平台、深度学习语音识别、深度学习图像识别等方面积累了一些研究和应用的经验。然而效果广告点击率预估的场景和上述场景有一些差别，目标和约束不尽相同，在追求端对端学习的过程中所做的取舍也有所不同，本文稍作阐述。
 技术方案和应用效果
图  功能模块示意图  
 架构
目前线上使用的深度学习点击率预估模型，其模型训练所用的架构同之前的模型差别不大。当事件点击曝光转化等等发生时，会实时地由上游生成最初的日志，然后经由接入数据处理平台，再用流式拓扑来给日志关联各种特征，形成训练数据，最后交给模型训练程序来训练点击率预估模型。模型会定期推送到实时推荐引擎，供运行时预估使用。
与点击率预估模型训练强调流式和实时不同，用于特征学习的深度学习模型的训练对延迟要求不高，目前还是离线批处理为主。例如，我们会定期爬取广告的落地页，从中获得广告的图片和文字描述，我们还会收集一些用户订阅和的内容，用户观看和点击广告的行为自然也在收集之列。在积累了足够多的数据后，我们会不定期启动训练深度学习模型来学习用户侧和广告侧的特征。此类模型的效果调优目前仍需要有人来操作，每次得到一个较好的模型后会持续使用一段时间，学习到的用户侧和广告侧特征会存入内存数据库供查询。
 模型和算法考量
前面提到，效果广告点击率预估的场景和语音识别、图像识别之类的场景对深度学习模型有不同的约束。其中一个很重要的约束就是运行时延迟的约束。
在效果广告的应用场景中，用于展示广告的广告位可以是客户端窗口中的某个位置、空间页面中的某个位置、微信公众号文章页中的某个位置、手机 中的某个位置，或者外部合作手机中的某个位置。广告需要在用户打开或者刷新这些窗口页面时立即得到呈现，以免破坏整个窗口页面的展现效果，影响用户体验，所以留给广告系统的响应时间不多。我们知道，一个广告系统的架构和请求处理流程还是比较复杂的，当收到广告请求时，先要检索出符合流量和定向要求的广告，然后粗筛筛掉大部分的候选广告，然后请求模块和模块分别估计点击率和转化率，然后再做精排并返回最后排名在前的几个广告。这个处理流程中各个环节之间可并行的余地不是很大，所以留给点击率预估的处理时间就更少了。按照目前的经验约定，当候选广告的个数在左右时，从请求服务到返回结果的平均延迟不应超过几十个毫秒，移动端广告位的延迟要求通常还要更高一些。
虽然点击率预估服务的接口很简单，传入用户、上下文和候选广告的信息，返回每个候选广告的点击率估值，但是背后仍然是一套比较复杂的系统，涉及到请求路由和负载均衡，分布式存储和缓存等等，并不仅仅是模型运算。所以实际用于模型运算的耗时还要再少一点。在这种情况下，用于运行时点击率预估的模型的规模和计算复杂度不能太大。
因此，我们把端对端学习的过程分成了两个阶段，用到的深度学习模型也相应划分成两类，前面其实已经提到了。一类是运行时用做点击率预估的模型，一类是辅助构造抽象特征的模型，这两类模型从设计到训练都对齐点击率预估的目标。前者的深度目前控制在隐层，每层的宽度也不是很大，不过还有进一步加深加宽的余地。这类模型的复杂度不高，但可以比较有效地解决前面提到的特征选择的痛点，无需手动尝试所有输入特征的组合，模型可以学到比较合理的组合方法，多个隐层可以捕捉到不同层次的特征交互。
后一类模型的规模和复杂度基本不受限制，因为其使用流程独立于运行时的点击率预估流程，延迟要求不高。例如，用于提取订单侧抽象特征的模型是在订单信息接入处理流程中被调用的，提取的特征向量会先入库，然后再用于点击率预估模型。这块我们还在不断地做实验，尝试用不同的数据源和网络结构来提取与点击行为潜在相关的用户侧和广告侧的特征。与此同时，我们对“传统”特征构造方法的改进和推广应用仍在继续，我们认为这两种方法仍将在未来一段时间内并存和相互补充，它们的产出都会交给前一类模型作为输入，并在那里完成交互和融合。
到目前为止，我们主要谈的是对深度学习模型端对端学习能力的运用。不过，换个角度来看，神经网络模型的强大拟合能力也是我们所看中的，特别是当特征变多了之后，我们更需要借助神经网络强大的非线性函数拟合能力。
有了模型，还需要有算法来训练模型，近年来这块的研究也比较热，但我们目前使用的仍然主要是随机梯度下降及其各种自适应变体，配合适当网络结构设计，对于我们手头的模型来说基本够用。
 系统考量
深度学习在学术界和工业界的火爆有目共睹，较为成熟的软件工具和平台也有不少，近期各大公司也纷纷开源了一些自用的机器学习平台，如开源的，微软开源的和，基于这些平台也可以开发深度学习的算法程序。笔者所在的团队前几年积累了一些使用和开发深度学习工具和平台的经验，当时主要还是针对语音识别和图像识别等应用场景。在综合考虑了其他目标应用场景的需求，包括点击率预估的需求后，我们基于开源社区的推出了 平台，如图所示。
我们为 平台设立的技术目标有这么几个。首先，满足多个领域常见的深度学习模型的训练需求，实验成本低且有充分的可扩展性，特别是要支持效果广告点击率预估相关的端对端学习需求，既支持相对规模较小的点击率预估模型，也支持大规模的特征挖掘模型，且可以根据需要扩展新的模型结构。其次，既能用于训练，也能用于运行时预测，一套代码搞定，且执行效率可以接受。第三，支持异构计算和并行加速，从而充分发挥服务器设备强大计算能力和高速网络通信能力。第四，依托  实现云化部署和管理。 基本达到了上述目标，目前已经用于效果广告点击率预估的生产环境。对此平台感兴趣的同学可以看一下此前笔者团队发表的文章。
 应用效果
基于深度学习的点击率预估模型从年年中开始应用于广点通现网，上半年在广点通广告位取得 的提升，下半年推广覆盖了其他移动内部站点、微信以及移动联盟，并在移动内部站点进一步带来 的提升，在微信广告位带来左右的提升。与此同时，特征工程的人力和计算资源消耗明显减少，新特征的实验周期明显缩短。
 展望
需求来自业务，方向来自痛点。于工作中体会到特征工程的一些痛点，促使我们转向深度学习。我们开发了平台，设计了模型，并在效果广告点击率预估应用中取得了较好的提升。深度学习技术的研究和应用方兴未艾，我们所涉猎的只是很小的一块。我们在实践中边总结边改进，还有很多的工作可以做，像模型结构设计、算法改进、系统性能调优，都需要继续投入。除此以外，深度学习和在线学习的融合也是我们重点关注的方向，我们在这方面的探索已经开始。
 后记
点击率预估模型的深度学习和在线学习融合方案已经在年年中的时候实现，并用于年中的线上放量，进一步提升了广点通效果广告的线上效果。目前使用的融合方案有两种，一种是快速增量更新模型，实现近似在线更新的效果，好处是部署和运维比较简单，另一种则是将在线贝叶斯学习的方法推广到模型，实现纯在线学习，其部署和运维略复杂一点。这两种方案的线上效果经在线对比实验确认是比较接近的，目前已经分别用于覆盖一些重要的流量。深度学习和在线学习的融合使得我们可以兼得二者的优点，也为进一步的点击率预估模型结构设计优化打下了坚实的基础。
融合实现后，点击率预估模型结构精调和从原始数据出发的特征构造将会是今后一段时间我们探索深度学习技术及其应用的重点。

参考文献
 效果广告点击率预估近期实践：在线学习
               
 腾讯用户画像—用户兴趣解读
 既相知，便相伴：揭开移动画像系列之总体介绍
 一种基于的特征选择方案
                    
                   
  
 解密最接近人脑的智能学习机器——深度学习及并行化实现概述
 深度神经网络的多数据并行框架及其在语音识别的应用
 深度卷积神经网络的多并行框架及其在图像识别的应用
 腾讯实时计算平台系列之一：初识
 广点通广告引擎设计与实现
 
      
    
  总结：腾讯演讲者的视角
  
 云化集群建设：引言  承深度学习之需，探高性能计算之路
 云化计算集群建设： 深度学习平台
 云化集群建设： 使用手册、疑难解答和最佳实践
 云化集群建设：  云平台


相关推荐
人人都可以做深度学习应用：入门篇上
效果广告点击率预估近期实践：在线学习接《在共享内存实现 上》
一些关键操作的设计：
遍历操作
数据库的遍历接口类似原生接口，用一个整数做游标，这个整数表示平衡树中的排行，即第个数据，每次遍历时：
根据游标找到对应的数据
遍历后继数据节点并返回指定量，以及新的游标
操作
同样利用平衡树的字段，根据数据库大小即根节点随机一个值，之后返回第个数据的即可
主动超时淘汰
类似在中的做法，每次随机选择一批设置了 的进行判断，做法有两种：
单独构建一个表，用平衡树存储到超时时间的映射，随机淘汰的时候对这个树做上面描述的操作即可，缺点是需要存两份
 作为每个的的元数据的一部分，的平衡树在实现的时候稍微特殊一点，每个节点增加一个 字段，存储此节点为根的子树中有多少被设置了超时时间，然后用类似选第个元素的算法，用的方式随机淘汰，缺点是的数据结构需要特殊设计实现每次操作都可能需要额外调整树节点的 域
渐进式命令执行的实现
需求
在执行读请求的时候，有时候我们得到比较大的数据，具体的场景可能是：有其他进程如内部运维进程直接和通讯，请求一个的，由于很大，处理耗时很久，而是单线程模型，所以来自客户的业务请求可能会被卡住共享内存版本的也是单线程模型
方便起见，我们以单的需求为例，考虑如何序列化返回并且在处理过程中不会造成卡顿的方法，总体来说有两个关键要求：
的执行应该是渐进式的，不能造成明显卡顿
出的结果必须是开始执行的那个时间点的快照，如果过程中这个被以任何方式修改，都不能影响快照结果
问题分析
如果不考虑上述需求，则问题就很简单，只需要原子性地处理请求即可，或者锁定这个，在中渐进式执行，在结束之前可以同时响应其他没有加锁的的写操作
而要同时实现上面两个需求，我们需要在过程中响应并操作正在被的，同时，由于被改变的部分可能还没有被到，因此需要实时地先保存一份原来快照的副本，类似通过来实现并发的机制，我们在这里实现手工的，即这段时间中被修改之前，实时将老的数据出一份，同时的粒度又要足够小，不能因为这个而导致修改操作卡顿太久；另一方面，会消耗额外内存，最好能尽量减少这个内存消耗的峰值
方案
整体思路和的的方式类似，只不过是利用了操作系统机制，我们用手工的做法：
收到请求时，对做一个快速遍历，记录下时可能遍历的实际数据的的地址列表类似过程中的页表复制，并将这个列表保存在私有内存中，和请求的对象绑定，相当于一个“待处理任务列表”，这个列表中的元素可以是一个指向的指针，也可以是一块实际的数据这样设计的作用见下
在过程中，渐进式地处理中的列表，对每个元素，访问其引用的数据，打包，每次处理一部分，直至结束；为了节省内存，如果实际场景允许的话，也可以做成特殊的协议，回复协议做成分段，做一段发送一段，无需全部后再发送
在渐进式过程中，如果这个有任何改动，则所有涉及到数据修改的包括上述的增删改、分裂、合并等等操作都在其修改之前将中的原数据拷贝至中对应位置，替换原来保存的指针，从而实现手工的
由于待处理列表是在私有内存，因此程序如果异常终止，资源会自动释放
如果同时出现多个进行，则各可以并行，每个绑定一个待处理列表即可，但需要一个全局的列表大小统计，用于统计列表中被的数据的空间，如果由于过多或的内存过大，则可立即令此任务失败，避免出现由于资源占用多导致的其他问题
举例说明：

如图，假设这棵平衡树在命令开始时，数据状态是上面黑色，之后在流程中遇到了若干写操作，流程和列表状态变化：
首先做各的地址快照，按顺序遍历所有节点，得到列表：

在任务中先了两个：和，剩余列表：

此时的 列表：，即和中的数据已经序列化到缓冲，下同
有写请求到来，插入了 ，由于被修改，且未被处理到，所以实时将老数据 到列表中，剩余列表：

此时，列表中和维持指针状态，而则保存了共享内存中对应的修改前的快照数据，三者加起来仍然是逻辑上的快照
在任务中继续了一个：，剩余列表：

此时的 列表：
又收到一个写请求，插入了数据，导致新增一个，这个操作对列表无影响
下一个写请求是删除 ，需要对做，但是由于已经做过了，所以不用做，对列表无影响
继续在中 的数据，此时使用之前拷出来的数据，剩余列表：

此时的 列表：
收到插入 的请求，影响了的数据，但是由于已经被过了，所以对列表没有影响
在中 的数据，列表清空，结束，结果为，发送给即可，可以看到，这个结果就是请求处理开始时，平衡树内部数据的精确快照，途中插入的写操作并没有影响到结果，并且我们只耗费了一个的额外空间列表中的元素如果是指针的话，耗费会很小
进一步优化：从上面过程中可以看到，如果我们按列表顺序进行，被的 在的时候，前面是还没有被，如果列表中各的数据可以不用保持有序，则我们可以优先那些被的，这样可以提前将其处理完毕释放
关键问题：上面是用平衡树做实例，链表的处理也是类似的，但如果是一个用链表形式保存的长字符串，则在时候可能需要将整个字符串拷贝出来，这一点可能还是有改进的空间
的实现
由于数据在共享内存中，不能用机制利用操作系统的机制，所以的实现还是通过类似上面渐进式的算法，只是稍微复杂一些：
先做这个平衡树的快照记录所有涉及的的指针
当中的被修改时，拦截所有对可能的写操作，并根据上面的算法进行手动
优先将脏数据落盘，提早释放空间
其实如果不纠结数据落盘的格式，还可以直接拷贝整个共享内存，因为这块内存就是下的一个文件，将文件按一定大小分页进行拷贝，也是程序手动控制，优先拷贝即将被写脏的页。如果想利用一下操作系统，还可以在的参数上做文章：大家好，我是来自华中科技大学计算机系的肖洋。第一次参加这种机器学习类的比赛，侥幸进了决赛，也来分享一下比赛心得体会。
一、问题与数据分析
这次比赛是预测广告转化率的问题，就是预测某个用户点击某广告之后发生转化的概率，这显然是一个二分类问题。首先简单对数据做一下统计，发现这里面正类负类比例严重失调，正类也就是发生转化的样本只占了总样本的。一上来我使用随机深林做了一下简单预测，发现预测的结果当中最大的概率也不超过，所以我感觉很不靠谱，另外在知乎上看到有人说这是一个 的问题，所以我就看了各种文章，使用里面的过采样、欠采样等方法，但是效果都不好，很明显我掉到坑里面了。总结一个经验吧，数据和实验结果才是王道，不要老凭自己的感觉去揣测。
二、特征选择
“特征决定上限，模型只能原来无限逼近这个上限”，这次比赛我确实深刻体会到了这个至理名言。特征工程是数据预测里面最重要的环节，没有之一。
首先是特征选择因为没有做过类似的比赛，所以一上来我就急急忙忙开始用随机深林的_做特征选择，这毫无疑问是费时而且错误的选择。其实有两种很简单的方法可以用来观察特征的重要性：第一种是通过方法，得到这个样本在各个取值下的均值，然后再求一次方差，就知道这个特征的重要性了；另一种是通=来观察一下在给特征取不同值的时候正负样本的比例，如果取不同值的时候比例相差很大，这个特征十有八九是一个强特征。
其次是各种特征的挖掘、组合等，这些隐藏的特征才是决定成绩的关键。特征挖掘方面，主要是各种统计变量，例如用户安装的个数、与各种特征对应的点击量、转化量、转化率等；特征组合方面，可以通过来简单统计一下组合特征下的情况，然后选择最重要的特征组合。听大佬说和是一个很重要的组合特征，可能我没有用好，导致了我和前面队伍的差距。
三、数据处理
数据处理方面我也没有花太多功夫，主要是对某些与转化率相关的特征做了一下贝叶斯平滑。为什么要做平滑，举个例子，对于特征，比如取值为的样本只出现了一次，没有发生转化，由于样本太少，我们并不能直接认为取值为的样本转化率为，毕竟样本太少，没有说服力。贝叶斯平滑的文章参考
四、模型选择
我使用过四种模型，随机深林、逻辑回归、和。其中随机深林效果最差，当然也有可能是我把这个模型用废了，逻辑回归其次，比稍微好一点，可能是因为考虑了特征的组合。另外提一句，在我的实验过程中调参对于结果的影响是微弱的，所以个人建议不要把太多的时间花在调参上面了。
最后希望自己能在决赛当中取得一个好成绩。服务稳定性到一定程度之后，都会开始经历一段精细化运营的过程，从成本意识角度来说也是成立的。作为前端出身的开发者们，产生共鸣的那就是如何能够直观且快速发现性能瓶颈，能够像调试前端的代码那样可视化，堆栈化，接下来我们就针对常见的性能分析方法来揭开的面纱。
一、使用情况可视化展示火焰图— 
充分利用劳动工具有助于帮助我们提升定位问题的效率， 自带的系统性能分析工具，为我们提供函数级与指令级的热点查找，常用于性能瓶颈的查找与热点代码定位。
如何正确完整的采集火焰图呢？
、用例构造
服务代码示例—编解码，如下片段：
 
 启动方式：
启动参数：__或—适用于
也可以使用____
标准方式： __ 
 启动方式：私有模板配置启动参数，如下：





    

        =






注：__或会对应生成一个文件，如图：

 脚本采集函数和热点代码
查看服务进程，采集时需要用到。命令：  – |  ‘’
 
采集脚本：          
参数说明如下：



采集频率
进程
调用记录
记录时长




 
 

 



进程对应的符号表权限设置：  。
踩过的坑！！！是为了消除下面这个问题的
              
      

挖出开源库里面的和



文件生成

单一颜色：   |  |   
多种颜色：  |  |  = –  ，如下图：

二、火焰图的理解与性能分析
 通过上面的步骤采集出两种不同颜色系的火焰图，如下图
 
 火焰图颜色对应关系，如下表：



颜色
类型




绿色
代码调用


蓝色
优化编译代码


黄色
代码


红色
系统调用



 火焰图形状对应关系



形状
含义




每一个平面方块
一个函数在栈中的位置也称一个栈帧


轴
栈的深度也叫栈的帧数


轴
表示总的样例，不过它们左右顺序没有特殊含义


每个平面方块的宽度
方块的宽度标示使用时间或者说相对父函数而言使用的比率，越宽代表占用的时间越长，或者使用很频繁



 序列化与反序列化火焰图分析
采用进行压力测试分析与性能开销
压测命令： –    
 从火焰图看到里面耗时主要消耗在序列化和反序列化

几个常见的栈帧类型说明：



栈帧
含义





指的是下回会被编译



指的是内置的运算方法



入口桩代码：作用是在的代码中，如果要调用的函数，则通过实现



内部命名空间，就是的，在的源代码可以找到对应的



 反序列化源码分析
概念普及——解析器常见原理：
 词法分析
 语法分析生成抽象语法树
 针对抽象语法树进行语义分析，构建你需要的内部数据结构或生成代码
通过局部查看火焰图分析源码

 ：入口桩代码，在的代码中，提供调用的函数如函数或者的函数
【编译】_

【解析器】

【词法分析】

【语法分析】

小结：通过火焰图我们能够清晰的看到函数的调用栈，并能够找到哪些函数是耗时较多的
序列化流程相似相似，感兴趣的同学可以看一下的和对应的文件
三、性能分析的另一种可视化图
 需要脚本
工程地址：
 基于文件转换成文件
     |   –  –  – 
 基于文件转换成文件
  –  – 
在物理机的尝试：

下载到磁盘，打开即可：

附录



作者：张三华

前言
随着微信客户端业务的增长，在数据库上遇到的性能瓶颈也逐渐凸显。在微信的卡顿监控系统上，数据库相关的卡顿不断上升。而在用户侧也逐渐能感知到这种卡顿，尤其是有大量群聊、联系人和消息收发的重度用户。
我们在对进行优化的过程中发现，靠单纯地修改的参数配置，已经不能彻底解决问题。因此从版本开始，我们合入了的源码，并开始进行源码层的优化。
本文将分享在源码上进行的多线程并发、性能优化等，并介绍优化相关的原理。
多线程并发优化
 背景
由于历史原因，旧版本的微信一直使用单句柄的方案，即所有线程共有一个 ，并用线程锁避免多线程问题。当多线程并发时，各线程的数据库操作同步顺序进行，这就导致后来的线程会被阻塞较长的时间。
 的多句柄方案及 方案
实际是支持多线程几乎无锁地并发操作。只需
、开启配置  _=、确保同一个句柄同一时间只有一个线程在操作

                         

倘若再开启的模式，多线程的并发性将得到进一步的提升。
此时写操作会先到文件末尾，而不是直接覆盖旧数据。而读操作开始时，会记下当前的文件状态，并且只访问在此之前的数据。这就确保了多线程读与读、读与写之间可以并发地进行。
然而，阻塞的情况并非不会发生。

当多线程写操作并发时，后来者还是必须在源码层等待之前的写操作完成后才能继续。

提供了 的方案，即发生阻塞时，会触发 ，此时可以让线程休眠一段时间后，重新尝试操作。重试一定次数依然失败后，则返回_错误码。

   方案的不足
 的方案虽然基本能解决问题，但对性能的压榨做的不够极致。在过程中，休眠时间的长短和重试次数，是决定性能和操作成功率的关键。
然而，它们的最优值，因不同操作不同场景而不同。若休眠时间太短或重试次数太多，会空耗的资源；若休眠时间过长，会造成等待的时间太长；若重试次数太少，则会降低操作的成功率。

我们通过 对不同的休眠时间进行了测试，得到了如下的结果：

可以看到，倘若休眠时间与重试成功率的关系，按照绿色的曲线进行分布，那么点的值也不失为该方案的一个次优解。然而事总不遂人愿，我们需要一个更好的方案。
 中的线程锁及进程锁
作为有着十几年发展历史、且被广泛认可的数据库，的任何方案选择都是有其原因的。在完全理解由来之前，切忌盲目自信、直接上手修改。因此，首先要了解是如何控制并发的。

是一个适配不同平台的数据库，不仅支持多线程并发，还支持多进程并发。它的核心逻辑可以分为两部分：

层。包括了接口层、编译器和虚拟机。通过接口传入语句，由编译器编译生成虚拟机的操作码。而虚拟机是基于生成的操作码，控制的行为。

层。由、、三部分组成，实现了数据库的存取数据的主要逻辑。


在架构最底端的层是对不同操作系统的系统调用的抽象层。它实现了一个  ，将层的接口在编译时映射到对应操作系统的系统调用。锁的实现也是在这里进行的。
通过两个锁来控制并发。第一个锁对应文件，通过种状态进行管理；第二个锁对应文件，通过修改一个的  的每一个进行管理。尽管锁的逻辑有一些复杂，但此处并不需关心。这两种锁最终都落在层的、和上具体实现。
它们在锁的实现比较类似。以操作在上的实现为例：
、通过__进行线程锁，防止其他线程介入。然后比较状态量，若当前状态不可跳转，则返回_
、通过进行文件锁，防止其他进程介入。若锁失败，则返回_
而选择 的方案的原因也正是在此－－－文件锁没有线程锁类似__的通知机制。当一个进程的数据库操作结束时，无法通过锁来第一时间通知到其他进程进行重试。因此只能退而求其次，通过多次休眠来进行尝试。
 新的方案
通过上面的各种分析、准备，终于可以动手开始修改了。
我们知道， 是单进程的，并没有多进程并发的需求，这和的设计初衷是不相同的。这就给我们的优化提供了理论上的基础。在这一特定场景下，我们可以舍弃兼容性，提高并发性。
新的方案修改为，当层进行操作时：
、通过__进行线程锁，防止其他线程介入。然后比较状态量，若当前状态不可跳转，则将当前期望跳转的状态，插入到一个的尾部。最后，线程通过__进入 休眠状态，等待其他线程的唤醒。
、忽略文件锁
当层的操作结束后：
、取出头部的状态量，并比较状态是否能够跳转。若能够跳转，则通过____唤醒对应的线程重试。

____是在库中新增的接口，与__类似，它能唤醒一个等待条件锁的线程。不同的是，____可以指定一个特定的线程进行唤醒。


新的方案可以在空闲时的第一时间，通知到其他正在等待的线程，最大程度地降低了空等待的时间，且准确无误。此外，由于的存在，当主线程被其他线程阻塞时，可以将主线程的操作“插队”到的头部。当其他线程发起唤醒通知时，主线程可以有更高的优先级，从而降低用户可感知的卡顿。
该方案上线后，卡顿检测系统检测到

等待线程锁的造成的卡顿下降超过

_的发生次数下降超过




 性能优化
保留文件大小
如上文多线程优化时提到，开启模式后，写入的数据会先到文件的末尾。待文件增长到一定长度后，会进行。这个长度默认为个页大小，在上约为。
同样的，在数据库关闭时，也会进行。不同的是，成功之后，会将文件长度删除或到。下次打开数据库，并写入数据时，文件需要重新增长。而对于文件系统来说，这就意味着需要消耗时间重新寻找合适的文件块。
显然的设计是针对容量较小的设备，尤其是在十几年前的那个年代，这样的设备并不在少数。而随着硬盘价格日益降低，对于像这样的设备，几的空间已经不再是需要斤斤计较的了。
因此我们可以修改为：

数据库关闭并成功时，不再或删除文件只修改的文件头的 。下次数据库打开时，会识别到文件不可用，重新从头开始写入。


保留文件大小后，每个数据库都会有这约的额外空间占用。如果数据库较多，这些空间还是不可忽略的。因此，微信中目前只对读写频繁且检测到卡顿的数据库开启，如聊天记录数据库。

优化
对性能的提升无需赘言，尤其是对于读操作。也在层封装了的接口，可以无缝地切换和普通的接口。只需配置 _=即可开启。

          
                             
                          

然而，你在上这样配置恐怕不会有任何效果。因为早期的版本的存在一些，在编译层就关闭了在上对的支持，并且后知后觉地在年月才重新打开。所以如果使用的版本较低，还需注释掉相关代码后，重新编译生成后，才可以享受上的性能。

开启后，性能将有所提升，但这还不够。因为它只会对文件进行了，而文件享受不到这个优化。
文件长度是可能变短的，而在多句柄下，对文件的操作是并行的。一旦某个句柄将文件缩短了，而没有一个通知机制让其他句柄更新的内容。此时其他句柄若使用操作已被缩短的内容，就会造成。而普通的接口，则只会返回错误，不会造成。因此，没有实现对文件的。
还记得我们上一个优化吗？没错，我们保留了文件的大小。因此它在这个场景下是不会缩短的，那么不能的条件就被打破了。实现上，只需在文件打开时，用将其映射到内存中，的层即会自动识别，将普通的接口切换到上。
其他优化
禁用文件锁
如我们在多线程优化时所说，对于 并没有多进程的需求。因此我们可以直接注释掉_中所有文件锁相关的操作。
也许你会很奇怪，虽然没有文件锁的需求，但这个操作耗时也很短，是否有必要特意优化呢？其实并不全然。耗时多少是比出来。
中有机制。被加载进内存的，使用完毕后不会立刻释放。而是在一定范围内通过的算法更新 。这就意味着，如果设置得当，大部分读操作都不会读取新的。然而因为文件锁的存在，本来这个只需在内存层面进行的读操作，不得不进行至少一次操作。而我们知道，操作是远远慢于内存操作的。
禁用内存统计锁
会对申请的内存进行统计，而这些统计的数据都是放到同一个全局变量里进行计算的。这就意味着统计前后，都是需要加线程锁，防止出现多线程问题的。

内存申请虽然不是非常耗时的操作，但却很频繁。多线程并发时，各线程很容易互相阻塞。
阻塞虽然也很短暂，但频繁地切换线程，却是个很影响性能的操作，尤其是单核设备。
因此，如果不需要内存统计的特性，可以通过___ 进行关闭。这个修改虽然不需要改动源码，但如果不查看源码，恐怕是比较难发现的。
优化上线后，卡顿监控系统监测到

写操作造成的卡顿下降超过

读操作造成的卡顿下降超过



结语
移动客户端数据库虽然不如后台数据库那么复杂，但也存在着不少可挖掘的技术点。本次尝试了仅对原有的方案进行优化，而市面上还有许多优秀的数据库，如、、等，它们采用了和不同的实现原理。后续我们将借鉴它们的优化经验，尝试更深入的优化。

本文来源于： 微信公众号作者：腾讯  交互设计师 梁睿思

在刚过去的考试月里，别人家的期末考试都在一本正经的考“老九门”，南京的一所高校期末考试居然考起了表情包！而面对这样的“无厘头”题目，学生们也是绞尽“墨汁”认真作答。无图无真相：
 
在现代互联网的社交中，斗图已然成为一种聊天方式，不发表情感觉都没法好好聊天！出题的这位老师在出考卷时，就是看到学生们正在群里斗图，才灵机一动想到了这道题目，以表情包作为考点，考查学生对“用户体验与心理”的认知。
一、用户：中的斗图习惯与诉求
在如今表情资源越来越多的情况下可下载商城表情、从网上搜索表情、收藏别人发的表情等，对于热衷斗图的用户来说，“量”已不再是用户在意的要素，而“质”才是关键，而越来越多的用户也开始自己表情。

发送一个引人瞩目、燃爆话题的表情，在群里引发大家激烈回应而得到的成就感，才是用户斗图的最大乐趣。一个大家都能随意下载的表情，和自己“精心”制作的好友搞笑表情，引发的效益必然不同，但往往能获得越高成就感的表情，获取制作难度也会越高。

二、机会与优势：中基于熟人社交的斗图
对于来说，聊天过程中大量产生的图片和表情，其实是很好的素材活水，基于这些素材进行二次加工，即能源源不断的产生属于自己的独一无二的表情。而在这些图片素材中，熟人的照片是最好的“生肉”，将小伙伴逗趣神态制作成斗图表情发出，在群里就能引发一片“哗然”。
其实在北京设计中心里，大家就十分热衷于相互制作“换脸”表情，即将平时偷拍的小伙伴的脸在别的斗图表情上，发到群里次次都会引发一连串的“乱战”，这也是触发我们做斗图功能的灵感来源之一。

制作这种“换脸”表情一般主要有几个步骤：抠出人脸、边缘羽化、色彩及曲线调节、与底图正片叠底等等，才能得到较好的效果，这对技术门槛要求较高，即使是设计师也至少需要几分钟的时间。
那么，能否让普通用户在 里，也能简单快速的创作好友的斗图表情呢？
三、功能设想：基于人脸识别的快速斗图生成
接入优图团队的人脸识别技术，我们就能快速将人脸识别并抠取出来，然后通过技术的方式自动将人脸进行效果处理和表情合成，即能让用户一键生成斗图！
请看视频：

感谢晓峰同学对的辛苦制作与倾情演出～
从以上视频中可以看到，制作斗图的方式主要有两种路径，这是为了针对两类用户的特性，而提供不同的方式和能力。

、从聊天场景切入，让功能快速触达
对于功能极其丰富的来说，一个新的功能要被用户接受和喜爱，除了切中用户痛点，让功能自然且恰当的触达用户也尤为重要。因此我们在设计中，考虑能在聊天中的斗图场景下，自动触发功能并为用户快速提供结果：
在聊天窗口中，当在最新的一屏消息内有两条及以上的图片消息我们认为此刻为潜在的斗图情景，则会触发对此图片的人脸识别判断。如果该图片有人脸，则右侧出现“来斗”按钮，点击后随机生成基于该脸来合成的表情。

为了降低操作过程中产生的转化折损，让用户更简单快速的斗图，交互方案选择了直接在图片旁边出现表情，点击表情即可发送。并且在旁边提供 “换一换”功能，点击即随机生成新的表情，让用户无需进入编辑界面也可快速更换表情。

、提供固定入口，让灵感随意挥洒
喜欢主动表情引发斗图战争的用户，可以通过聊天界面中号内、大图查看器里或发送图片时的固定入口，进入到编辑界面。

在编辑界面中，用户可以选择预设的身体及脸部素材，也可以自己添加相册照片、聊天图片、收藏表情来做背景，或者提取图片中的脸部来进行创作。通过对脸部的简单调整和文字的增修，即可创造自己独一无二的斗图表情。

另外，别说我没提醒你们：通过“来斗”功能提取的脸部，还可以保存下来，方便用户多次使用小伙伴的经典表情哟！ ´▽｀

四、脸部与背景的智能融合
因为与人脸进行合成的底图除了我们提供的预设素材，用户还可以自定义选择图片或已有收藏表情，所以底图的类型可谓五花八门，用户可能会想把一张脸贴到另一个人脸上，也可能会想贴在一个黑白的非真人表情上。为了不让用户去承担这种与不同底图融合的编辑成本，我们希望通过一种较为简单通用的方式，让脸部与不同的底图智能合成。
首先将图片里的脸部抠出后，先去色成黑白并制成透明，这样在与不同底图合成时，能一定程度解决不同肤色和光线的脸部融合的问题，同时也契合现在流行的斗图表情风格。对于不同的底图，技术会对图片色彩的平均饱和度进行计算，然后将脸部与底图做不同效果的融合。

用户用作表情的底图一般为两种情况：彩色的图片或表情  经典的黑白斗图表情多为黑色五官白色脸部。要想智能的将脸部和不同的底图做较好的融合或覆盖，就要针对这不同情况去做判断，做不同的融合方式。
但有很多看似是黑白斗图表情，其实都参杂了一些色彩，所以不能单纯的以“彩色”或“黑白”去区分这两种底图。经过大量图片表情的测试，我们取得了一个较为合理的阀值，当底图色彩的平均饱和度大于等于的，则认为底图为“彩色”的，将脸部下方对应的底图区域做高斯模糊效果以融合。如果平均饱和度小于，则认为底图为“黑白”的，将脸部区域下对应的底图区域做白色的遮盖。
为了让用户能更快速的完成编辑，我们对每个预设身体素材都会定义合适的脸部位置和大小，让脸部能自动合成到最合适的位置；对于自定义底图的情况，如果识别出底图上有人脸，也会自动将脸部大小和位置调整至与底图人脸重合。

上述的各种处理步骤和情况判定，都是为了尽量能让用户少一步操作，让界面上少一个按钮，让这种看似门槛较高的斗图玩法能够简单而流畅。
展望
由于时间和人力限制，现阶段只实现了我们设想中的基础功能和玩法，在后续的版本迭代中，我们希望不断完善技术和合成效果，并且给用户提供更多的玩法：

支持生成动图
支持多张人脸的编辑
支持效果滤镜、添加物件素材等
根据对人脸情绪的识别，匹配合适的文案和表情素材

最后喊一句：此功能已在  上线，欢迎同学们来玩来吐槽！郭林烁

在前端开发工作中，除了项目开发保质保量上线以外，项目的数据监控也应该配套起来，确保线上的正常运转。如上报  监控项目是否正常运转；测速上报反应项目质量；脚本错误监控作为监控中重要一环，当页面发生报错的时候，通过上报错误信息，能及时发现存在问题，修复优化、减少损失。
本文基于在手家校群前端脚本错误量优化的方案，致力于打造极致的脚本错误优化。
作为首篇，主要讲解基础的脚本错误监控和上报方式，以及常会遇到的   的产生原因和处理方法。
监控上报
脚本错误主要有两类：语法错误、运行时错误。监控的方式主要有两种：、。
监控方式
示例 · 
 {
         
} {
    运行时错误信息 ↙
    
}


通过给代码块进行  包装，当代码块出错时  将能捕获到错误信息，页面也将继续执行。
当发生语法错误或异步错误时，则无法正常捕捉。
示例 ·  语法报错

 {
             语法错误
} {
    语法错误信息 ↙
    
}

无法捕捉错误

示例 ·  异步错误
 {
     {
             异步错误
    }
} {
    异步错误信息 ↙
    
}

无法捕捉错误

语法错误无法在  中进行捕抓、而异步报错则可以通过为异步函数块再包装一层 ，增加标识信息来配合定位，可以用工具来进行处理，这里不展开。
示例 · 

   {}      错误信息
   {}      出错文件
   {}      行号
   {}      列号
   {}    错误详细信息
 
 =       {
     错误信息 ↙
    {
              
    }
}

     


 能捕捉到当前页面的语法错误或运行时报错，是十分强大的。那么 是否不再需要呢？其实并不是。
在使用过程中的体会： 主要用来捕获预料之外的错误，而  则可以用在预知情况下监控特定错误，两种形式结合使用更加高效。
上报方式
监控错误拿到了报错信息，接下来则是将捕抓的错误信息发送到信息收集平台上，发送的形式主要有两种：

通过发送数据
动态创建  标签的形式

示例 · 动态创建  标签进行上报
   {
      = 
      =   =  
}

监控上报整体流程
监控报错，并将捕捉到的错误信息上报给数据收集平台，如下图

错误信息分析 ·  
有了监控了后，就可以在收集平台上进行查看脚本错误量的日志统计。

发现占据榜首的错误信息 “ ” 具有非常高的比例，没有无具体的错误信息，无法定位问题，而这是怎么产生的呢？
产生   的原因
翻看在  的源码可以看到 “ ” 是浏览器在同源策略限制下所产生的。浏览器出于安全上的考虑，当页面引用的非同域的外部脚本中抛出了异常，此时本页面无权限获得这个异常详情， 将输出   的错误信息。

优化  
  来自同源策略的影响，那么解决的方案之一是进行资源的同源化，另外也可以利用跨源资源共享机制  。
方案一：同源化

将代码内联到文件中
将文件与文件放到同一域名下

以上两种方式能够简单直接地解决问题，但也可能带来其他影响，如内联资源不好利用文件缓存，同域无法充分利用优势等等。
方案二：跨源资源共享机制  
跨源资源共享   机制让应用服务器能支持跨站访问控制，从而能够安全地跨站数据传输。主要是通过给请求带上特定头信息，服务器实现了接口，就可以跨源通信，从而能够看到具体报错信息。
 为页面上标签添加属性。
 = 

增加  属性后，浏览器将自动在请求头中添加一个  字段，发起一个 跨来源资源共享 请求。  向服务端表明了请求来源，服务端将根据来源判断是否正常响应。

 响应头中增加  来支持跨域资源共享。

  表示通过该跨域请求，且该资源可以被任意站点跨站访问。而当该资源仅允许来自   的跨站请求，其它站点都不能跨站访问时，将可以返回：

 指定域名的  的响应头中需带上。
 字段的作用在于为缓存服务器提供缓存规则及缓存筛选的依据。当增加  响应头后，缓存服务器将会按照  字段的内容，缓存不同版本，在请求响应时根据请求头中的  决定是否能够使用缓存响应。

举例 · 不加  将存在错误命中缓存的问题

上图中，第一个请求 响应被浏览器缓存了，当第二个请求 发起，被错误命中了前一个请求的缓存，收到了  的响应时，将导致资源加载失败。所以当  不是返回为  时，需要加上  返回头来避免引缓存导致的权限问题。
 跨域脚本报错产生    通过以上方式进行处理后将能够捕获到具体的报错信息了。在  的实现中主要通过添加以下代码：
 {
     拿到请求头中的 
      =  
      {  不存在则忽略
        
    }

     设置  
     

     设置  
    
      
}

以上为本文所有内容，兄弟篇：   原文地址查看更多文章 前言：
的出现让我对机器学习产生了很大的兴趣，学习了  大神“史坦福大学公开课：机器学习课程”之后开始尝试自己处理相关问题，并在项目中进行实践一款横板动作游戏，最初采用的是  算法  算法的前身，在  中用  实现了  算法核心，神经网络和训练等模块，实际效果如下：

未经选练的
经过一段时间训练后
从视频中可以看出，训练后的  已经学习到一些找寻敌人和攻击的基本能力，但这个应用场景状态比较简单，只有一个小兵的位置。 要进行的操作也比较简单，方向移动和方向普攻。所以结果看上去还比较满意。
有了最初的实践，让我看到机器学习在复杂游戏中存在应用的可能，于是通过对  算法的进一步学习，并且在兄弟团队火影项目组的支持下，我开始在火影手游中进行了一些实践。
强化学习
机器学习有几个常见的解决问题的领域，包括回归和分类聚类，例如手写字体识别，语音识别，图像识别等，基本上都可以划分到一个回归或者分类问题上。但在游戏领域要面对的情况有些不同，在用机器学习解决回归或者分类问题时，无论在训练阶段还是预测阶段，样本都是离散的，他们之间不存在时间上的前后依赖关系。
训练时样本的顺序对实际训练结果没有太大影响，而预测阶段也完全不用考虑样本的前后关系，虽然神经网络中也有  算法引入样本的时间序列例如在处理语音识别问题时，但游戏领域要面对的是一个连续的交互问题。
人工智能领域常用  来表示一个具备行为能力的物体，强化学习要解决的问题就是  与环境  之间交互任务。
而无论什么样的任务，都包含了一系列的动作   状态  和收益 。
 置的是  在状态  下执行某个  后，对环境产生变化的一个评估。
强化学习的目的就是通过训练，让智能体  学习到一个策略  ，该策略反映的是状态  下选择  的一个对应关系，也就是什么状态执行什么动作。
能够在环境中获得最多的  的策略，称为最优策略，也就是强化学习的目标。
所以深度学习算法带给我们学习的方法，而强化学习带给学习的目标，也就是常见到的说法：
 =   
 算法
 就是结合了深度学习和强化学习的一种算法，最初是  在  年提出，它的核心利润包括马尔科夫决策链以及贝尔曼公式。网上介绍算法的文章很多，最初版本的算法可以概括如下：

 算法中有几个很核心的概念：

状态定义
在最初的实践中，采用连续帧游戏画面作为状态输入，采用  网络对输入的画面状态进行处理提取高维信息，最后再通过全连结网络层进行各个的值计算。
在我的实践中考虑到性能和学习效率的问题，并没有采用游戏画面直接作为输入，而是深入到游戏中，直接通过状态收集模块提取游戏主要特征预处理后作为算法的输入，当然考虑到公平的原因，提取的特征都是玩家可以直接从游戏中观察到的，例如：双方位置，血量，技能等。

预期收益
中使用两个网络和，其中用来计算当前状态每个的，用来计算下一个状态最大收益，和网络结构相同，并且定期的将覆盖。。
每次训练计算当前状态执行的带来的预期收益时，首先通过将下个状态产生的最大收益通过一定的收益衰减叠加到当前状态执行的产生的收益上，用来计算预期收益，这是一种很直观的方法，但也会带来一些潜在问题，在接下来的时间中会具体讲到改良方法。
所以本质上算法是通过迭代中每个的值的算法。

探索与贪婪
每次在选择一个进行执行的时候，通过一定的策略，选取一个，该可以有两种：一个随机，或者网络计算出来产生最大的。
如果选择的是随机，即尝试没有执行过的，体现了的探索能力
如果选择的是产生最大的，即表现得贪婪，尽力获得最大的。
而我们的选取策略就是在探索与贪婪中找到一个平衡，具体应用中可以在训练前期做更多的探索，随着训练次数的增加，逐渐的更加贪婪。

经验回放
通常我们从游戏收集到的和并不是直接进行训练，而是存放在一个经验池中。而每次训练从经验池中随机选取小批次经验进行训练，这样做可以避免观察到的数据前后依赖关系，同时也能避免受最近的操作影响过大，而“遗忘”以前发生的事情。


上面提到的是算法比较核心的几点，之后算法也出现很多改进。
实践

首先感谢火影客户端团队兽兽，和孙威的帮助，搞定了很多客户端的问题，才让这次实践有了应用基础，后续的深入实践和研究还需要很多客户端同学的支持。
目前在火影手游中，竞技场的采用行为树的方法实现，该水平较强，但行为模式比较单一，很容易玩家发觉是一个。
实践中希望采用算法训练，使水平能随着训练增加而提高，并且能够体现出丰富行为模式。
定义状态和预处理
如前文所述，我并没有直接使用图像画面作为状态输入这方面有待商榷，也请各位指正，主要是基于两方面的考虑：
 性能问题
图像识别需要多层的网络，将来在客户端直接使用时可能存在性能问题。
 学习效率问题
网络进行图像识别是为了提取游戏图像的高纬信息，在的实验中由于要应对各种游戏，所以采用图像作为状态的方式比较通用，而我们在具体实践中，可以考虑直接通过客户端收集游戏的主要特征作为状态输入。
有了最初横板动作游戏中的尝试，这次在实践中，我们将状态定义的较为复杂，主要包含个特征，例如：双方血量，位置，高度，技能，当前各动作执行阶段等。
收集到原始数据之后，还要进行预处理：
根据敌人和主角的相对位置，以主角为中心，划分的格子，然后将敌人和主角的状态填入对应的格子中，形成一个散列的状态数据，该状态中大部分数据为没有敌人和主角的格子
处理不同数据的表示范围，例如血量范围为，技能为，主要考量是不同特征对影响程度。
设计收益
我们的游戏中，收益组成比较复杂，包括：

对敌人伤害产生的收益

被敌人伤害产生的收益负值

躲避敌人攻击产生的收益

技能无法释放产生的收益负值


设计技能无法释放生成负收益的目的，是希望在模型在一个下产生一个不能执行的技能时，对当前下的进行惩罚，从而让模型学会技能释放的时机。
预测和执行动作
结合游戏实际情况，设计了包括空闲，方向移动，方向普攻，方向使用技能，方向使用技能，方向使用技能，使用替身技，一共个  。
整体训练流程
游戏客户端与训练进程进程之间通过  进行通信，每个时间片，客户端收集当前游戏状态 ，执行的  ，产生的收益  发送给训练进程。
训练进程将当前的  ，前一个状态  ，执行的  和  ，进行预处理后加入经验池中，等待后续训练过程处理。
同时根据当前状态，根据“探索和贪婪”策略计算得到一个  ，发回给客户端进行执行。
 算法改进

训练过程中发现  会倾向于总是使用某个固定的  ，引入对  的惩罚后效果也不明显，查阅相关资料后发现   ，在计算预期收益时，使用了下个状态可能产生的最大收益进行计算，存在过优化的情况，导致任何状态下计算出来都是某个  的收益最大，于是引入   和  两个改进算法，提升了训练效果。
 
在  算法中， 值的更新和动作的选择都通过在  网络上的  操作进行，这可能会产生过高估计一个  产生收益的问题， 算法的核心是将  的选择与收益衡量分离。通过在 上选择动作，然后用  衡量所有  产生的收益。
网上很多文章把  和  中引入的  概念混淆，实际上  是在  引入的基础上做的改进。
 
  的提出就是将  中  值的计算分为两部分：价值  和优势  。价值用来表示一个状态  的好坏程度，而优势表示一个状态下各个  的相对好坏程度。
由于在状态比较复杂的游戏中，执行哪个  对下一个状态影响不大，这时候只是计算某个  带来的潜在收益，就没有评估状态的价值作用大。
图中上部为模型，下部为网络模型
最终采用的网络模型如下：

其他
本次实践中除了上面提到的主要功能之外，还包含了经验池，，可降学习率，收益与动作回溯等具体细节，这里就不做详细描述。
训练效果
直观的看游戏中的表现
左侧蓝色圈的鸣人是算法训练过个小时后的，右侧红色圈的鸣人是游戏中行为树的视频中有的概率随机探索机制，所以偶尔看到一些怪异的操作，但从中还是可以看到机器学习训练出的有下面几个特点：

某些情况下使用出了连招对敌人造成了连续伤害视频中可以看到蓝色鸣人普攻螺旋丸大招的组合，已经显示出部分训练效果；

对敌人攻击不太躲避，但偶尔会释放替身技，说明我们对躲避攻击的设计有一定的效果，但可能收益值不够大；

容易空放技能，可能是放空技能没有惩罚导致。


客观的统计的平均收益和损失函数

平均收益
平均收益 稳步提高，但提高速度较慢，显示训练有成果，但训练效率不高，这主要是因为我们采用的是在线学习结合一定探索策略导致的后面会提到可以如何改进。

损失函数
损失函数在大的时间跨度上出现波动，慢慢趋于稳定，但并没有出现期待中的逐渐下降，说明我们的模型还有很大的优化空间。
改进
网络模型的改进
针对较高的情况，尝试不同的网络模型层数，神经元数量，经验池大小，大小，学习率，探索策略等，找到较佳的网络模型。
同时结合特性，通过优化计算的方法，
引入 机制
由于训练过程中，对于经验池中的记录采样采取随机采样的方式，导致取出的能产生较大的样本被采样进行训练的概率较低，我在后续改进中将会通过的方法，优先采样较大的样本进行训练
改进训练样本收集方法
在本次实践中，采用在线训练的方式，训练进程客户端进行通信，训练与使用过程结合在一起，而由于个格斗游戏，策略比较复杂，要在直接的战斗中学到好的策略例如合适的技能施放时机，连招策略，需要大量的时间让能够探索到成功的情况。毕竟单纯依靠简单的探索策略，在格斗类游戏中，找到一个好的战斗策略的机会很低。
接下来会我还会采用离线训练的方式，通过收集外网玩家真实战斗中的操作记录来训练，让能更快的学习到更好的操作策略。这就好比让一个打得好的老师傅教我们的如何进行战斗，通过这种方式能够快速的讲的水平提高到一个层次，然后再结合“探索和贪婪”策略，继续在较高的层次上进一步提高的水平。
学习资料
主讲斯坦福大学公开课 ：机器学习课程作者：

比较吸引我的地方在于其客户端服务端同构特性，服务端客户端可复用组件，本文来简单介绍下这一架构思想。

出于篇幅原因，本文不会介绍基础，所以，如果你还不清楚的生存周期等基本概念，建议先学习相关文档

客户端
先来回顾一下如何写一个组件。比如要做一个下面的表格：
可以这样写：先创建一个表格类。
  = 

  = 
  =   =   = 

 = {
       {
         {
                   {
                     
                         
                         
                         
                    
                }
            }
    }
}

假设已经有了我们要的表格的结构化数据。：
 三行数据，分别包括名字、年龄、性别
 = 
    {
         
         
         
    }
    {
         
         
         
    }
    {
         
         
         
    }


有了表格类和相应的数据之后，就可以调用并渲染这个表格了。
  = 
  = 

 类
  = 
 实例
  = 
 数据源
  = 

 方法把实例渲染到页面中 

    { }
    


我们把基础库、、、等打包成，引用到页面中：
 

    
        
    
    
    
     =


这样页面便可按数据结构渲染出一个表格来

这里  的具体打包工具可以是等，打包方法不在这里赘述

这个例子的关键点是使用来传递单向数据流。例如，通过遍历从``传来的数据```生成表格的每一行数据：


组件的每一次变更比如有新增数据，都会调用组件内部的方法，更改其结构。上面这个例子中，当给 新数据时，会自动为页面中的表格新增数据行。
服务端
上面的例子中创建的组件，出于性能、等因素考虑，我们会考虑在服务端直接生成结构，这样就可以在浏览器端直接渲染了。
这时候，我们的组件，就可以同时在客户端和服务端使用了。
只不过与浏览器端使用指定组件的渲染目标不同，在服务器中渲染，使用的是这个模块，它有两个生成字符串的方法




关于这两个方法的区别，我想放到后面再来解释，因为跟后面介绍的内容很有关系。
有了这两个方法，我们来创建一个在服务端环境运行的文件，使之可以直接在服务端生成表格的结构。

  = 

 与客户端略有不同
  = 

 与客户端略有不同
  = 

 类
  = 
 实例
  = 

 =   {
     
}

上面这段代码复用了同一个组件，生成浏览器可以直接渲染的结构，下面我们通过改改的官方 来做一个真实的页面。 
 
  = 

  = 

   {
   { }

    = 
    =  \\
              \
                \
                      \
                \
                 
                     
                \
              

  
} 

   

这时候运行 就能看到，不实用，达到了同样的表格效果，这里我使用了同一个，完成客户端及服务端的同构，一份代码，两处使用。
这里我们通过查看页面的源码，发现表格的中带了一些数据：
   都是些啥？这里同样先留点悬念，后面再解释。
服务端  客户端渲染
上面的这个例子，通过在服务端调用同一个组件，达到了同样的界面效果，但是有人可能会不开心了：貌似有点弱啊！
上面的例子有两个明显的问题：

 数据源是写死的，不符合大部分真实生产环境

服务端生成结构有时候并不完善，有时候不借助是不行的。比如当我们的表格需要轮询服务器的数据接口，实现表格数据与服务器同步的时候，怎么实现一个组件两端使用。


为了解决这个问题，我们的组件需要变得更复杂。
数据源
假设我们的表格数据每过一段时间要和服务端同步，在浏览器端，我们必须借助，官方给我们指明了这类需求的方向，通过这一生存周期方法来拉取数据。
 方法，我个人把它比喻成一个“善后”的方法，就是在把基本的结构挂载到中后，再通过它来做一些善后的事情，例如拉取数据更新等等。
于是我们改一下我们的``组件，去掉假数据，在```中调用我们封装好的抓取数据方法，每三秒去服务器抓取一次数据并更新到页面中。
：
  = 
  = 

  = 
  =   =   = 

  = 

 = {
       {
         {
                   {
                     
                         
                         
                         
                    
                }
            }
    }
       {
          {
              {
                {
                     
                }
            }
        } 
    }
}


这里假设我们已经封装了一个拉取数据的方法，例如 = 

到这一步，我们实现了客户端的每秒自动更新表格数据。那么上面这个组件是不是可以直接复用到服务端，实现数据拉取呢，不好意思，答案是“不”。
的奇葩之一，就是其组件有“生存周期”这一说法，在组件的生命的不同时期，例如异步数据更新，销毁等等过程，都会调用不同的生命周期方法。
然而服务端情况不同，对服务端来说，它要做的事情便是：去数据库拉取数据  根据数据生成  吐给客户端。这是一个固定的过程，拉取数据和生成过程是不可打乱顺序的，不存在先把内容吐给客户端，再拉取数据这样的异步过程。
所以，这样的“善后”方法，在服务器渲染组件的时候，就不适用了。
而且我还要告诉你，这个方法，在服务端确实永远都不会执行！
看到这里，你可能要想，这步坑爹吗！搞了半天，这个东西只能在客户端用，说好的同构呢！
别急，拉取数据，我们需要另外的方法。
中可以通过定义“静态方法”，学过面向对象编程的同学，自然懂方法的意思，没学过的，拉出去打三十大板。
我们再来改一下组件，把拉取数据的逻辑放到这里来。

  = 

  = 
  =   =   = 

  = 

 = {
     {
           {
              {
                 
            }
        }
    }
       {
         {
                   {
                     
                         
                         
                         
                    
                }
            }
    }
       {
          {

             组件内部调用方法时，使用
              {
                {
                     
                }
            }
        } 
    }
}


非常重要：组件能在客户端和服务端复用方法拉取数据的关键在于，必须在客户端和服务端有不同的实现！例如在客户端调用时，是发起请求，而在服务端调用时，有可能是通过协议从其他数据服务器获取数据、查询数据库等实现

由于服务端不会调用，需要改一下服务端渲染的文件，同样不再通过获取数据，而是调用的静态方法，获取数据后，再传递给服务端渲染方法，获取数据在实际生产环境中是个异步过程，所以我们的代码也需要是异步的：

  = 
  = 

 类
  = 
 实例
  = 

 =   {
      {
          = { }
         
    }
}

这时候，我们的组件已经实现了每秒更新一次数据，所以，我们既需要在服务端调用初始数据，还需要在客户端调用实时更新，所以需要在页面中引入我们打包后的。

  = 

  = 

   {
      ===  {
         { }

          {
              =  \\
                      \
                        \
                              \
                        \
                         
                             
                             =\
                        \
                      

            
        }
    }  {
         = 
        
    }

} 

   

成果
通过上面的改动，我们在服务端获取表格数据，生成供浏览器直接渲染；页面渲染后，组件每隔秒会通过获取新的表格数据，有数据更新的话，会直接更新到页面中。
的作用
还记得前面的问题么？
 和  有什么不同？服务端生成的是干嘛使的？
我们想一想，就算服务端没有初始化数据，仅仅依靠客户端的也完全可以实现渲染我们的表格，那服务端生成了数据，会不会在客户端执行的时候被重新渲染呢？我们服务端辛辛苦苦生成的东西，被客户端无情地覆盖了？
当然不会！在服务端渲染的时候，会为组件生成相应的校验和，这样客户端在处理同一个组件的时候，会复用服务端已生成的初始，增量更新，这就是的作用。
 和  的区别在这个时候就很好解释了，前者会为组件生成，而后者不会，后者仅仅生成结构数据。
所以，只有你不想在客户端服务端同时操作同一个组件的时候，方可使用。

原文链接：一、版本说明
原始版本： 
 目标版本： 
新增脚手架： 
脚手架版本： 
升级后主要依赖版本如下：

 {
     
     
     
     
     
     
     
     
     
     
     
     
}
 {
     
     
     
     
}
二、依赖更改
依赖导入更改：
 = 

 = 

 = 

 表单相关的

 = 
三、新增
官方说明
 模块能帮你把应用组织成多个内聚的功能块。
 模块是带有  装饰器函数的类。  接收一个元数据对象，该对象告诉  如何编译和运行模块代码。 它标记出该模块拥有的组件、指令和管道， 并把它们的一部分公开出去，以便外部组件使用它们。 它可以向应用的依赖注入器中添加服务提供商。
具体请参考官方文档。
管理公用组件

创建管理所有公用组件

 {}  
 {}  
 {}  
 引入公用组件
 {}  
 {}  
 {}  
 {}  

{
    
     
      
   
}
   {}

其他模块只需要引入

 {}  
 引入
 {}  
 该模块路由
 {}  
 该模块相关
 {}  

{
    
   
   
}
   {
}
四、路由相关
变更
拆分和新增了路由模块

：获取路由信息

路由事件实例，如表示导航事件变更完毕，等

反正改了挺多的，请自行查询官方文档…捂脸


新增路由模块
路由使用创建，示例如下：
 {}  
 { }  

 {}  
 {}  
 {}  

   =  
   这里主要供面包屑使用
  {     { 某个模块}
   
    {     { 列表}}
    {     { 详情}}
    {   }
  }

{
   
   
   
}
   {}
路由相关常用
 监听导航事件变更
  
 =    = {}
 获取路由信息
  
   =   获取根路由
   =   获取子路由
 遍历子路由，获取其等
     {
       获取
       获取
        获取或信息
}
若要写面包屑功能，可参考该文章   。
五、表单相关
依赖更改

 依赖中某些更改
  = 
 {}  
=  {}  
  = 
 {}  
=  {}  
原使用属性

更改表单属性  为 

 =  =  = 

同时在文件需引入和

 { }  

更改表单内属性为

 =  =  = 

若要在属性的内使用，需添加

={ }属性
 = = ={ } 
若要在属性的内使用=来进行验证，需更改验证为
原使用

更改表单内属性=为=
同时需要在该标签添加属性
 =  =  = = 
若不需要表单验证，则不需添加属性，而添加={ }
 =  =  = ={ } 
组件封装使用

使用时需加上以及两个属性
 =_  
=  =_ =_  
六、其他问题
 请求内容带时后台解析错误
原因：中封装的服务对参数编码方法，见_文件，导致后台获取图片地址失败。解决办法：使用覆盖编码

  覆盖原有的方法，见文件
 
    {
     {
     
  }
     {
     
  }
}
 组件迁移后，无法正确订阅事件
原因：中依赖注入，若在不同地方声明，则会创建不同的实例。
解决办法：在根组件声明注入服务，则整个使用同一个实例。
 升级版本失败
原因：版本升级后，对应版本修改了默认的属性，导致  会出现  。解决办法：回退版本，或者手动更改_里相关配置可查看       。
 运行   命令失败
原因：                      解决办法：  =  =   = =可查看       ’  ‘_’ 
：运行代码可通过：即时编译器动态引导、使用预编译器    两种方式。进行静态引导静态方案可以生成更小，启动更快的应用，默认优先使用。但此处因为有些动态计算环境的代码，故编译失败，此处手动关闭。
 升级到版本后，左侧导航的状态定位失效
原因：升级后，和的顺序调整仅根据个人观察，未经验证，导致组件状态未能在路由事件结束时完成更新。解决办法：目前在路由事件结束时，手动更新组件状态。
的内嵌样式失效。 =  模版里，在里使用= {{    }}的内嵌样式失效。
原因：中，需使用属性方式对样式进行设置。解决办法： 更改为={     }  更改为=    。
 在里，更改文件不能在浏览器中更新输出。
原因：里面默认启用” ”，将保存先存到临时文件。解决办法：关闭         ，参见  。
 无法从里获取的。
原因：中，使用的获取路由信息。
原代码：

 {  }  
  其余代码
     {
         = _
         = _ ||  = 查看、编辑、添加
          其余代码
    }
  其余代码
新代码：
 {  }  
  其余代码
     {
      _
         = {
           = 
           =  ||  = 查看、编辑、添加
           其余代码
        }
    }
  其余代码
 使用后无法自定义的 导致文件引入路径很长，如。
原因：内部封装了配置，若手动改动_不方便。解决办法：查看       ，该只针对性调整目录，具体可查看相关信息。
使用方式
 在目录下修改
{
   {
    
     添加路径相关
     
     {
       
    }
    
  }
  
}

 在根目录下修改
 主要用于编译器检测使用
{
   {
    
     添加路径相关
     
     {
       
    }
    
  }
  
}
升级版本后，组件迁移状态更新失效
原因：升级后，的顺序调整，导致组件状态未能在状态更新后完成更新。
解决办法：检测状态变更时，需手动再添加状态更新。
升级到版本后，等带动态等属性触发
原因：启用安全无害化处理，为防止等攻击，具体可参考官方文档安全。
解决办法：注入服务可以把一个值标记为可信任的，这里添加了一个叫的组件，位于。使用方式： = | 
迁移一些文件后，启动失败，出现     
原因：有些文件里面带有 ，若路径不对文件找不到则无法启动。
解决办法：调整文件路径，或者删除这些内容。导语
 开源了他们的  压缩算法和  存储引擎， 压缩算法志在取代当前普遍使用的的  压缩技术，而 是基于  引擎嵌入到 的一个分支，在  内部用作提升存储效率。那么，这个整合后的引擎性能如何呢，本周 团队第一时间进行了调研。
一、和的关系
是一个当前使用最广泛、且支持插件式存储引擎的开源数据库。我们常用的引擎有：、等；而是  将他们自己的修改后的引擎嵌入到中实现的。
基于引擎，不同于基于组织方式的引擎，是基于方式组织数据的，这种 的写入方式，很少出现随机的情况，是在内存之后才写入，写入放大较小；在压缩方面，之后实现了透明页压缩技术，压缩之后的页对齐会导致压缩效率降低，虽然也是页压缩，但不用页对齐存储的文件需要与操作系统对齐，但因 是，和的单页相比，这里的文件级别对齐对压缩效率的影响可忽略不计，除此之外，还在索引层面实现了点来减少存储开销：   技术索引中前缀相同的不重复存储和    技术压缩索引中额外表示的。
因此，整体上被描述为一个写入性能、存储效率均优于的新引擎。但具体性能如何，下面我们一探究竟。
二、性能测试部分
本文主要分个方面进行对比：写入性能；读取性能；压缩性能；
说明：因为内部使用的分支版本，外部公开资源较少，因此本次测试上有如下几方面的局限：
、最新的压缩算法，可以编译进中，但不能通过指定压缩算法使用，因此的压缩只能针对原生的压缩算法做测试。
、版本，同时支持传统表压缩技术和透明页压缩技术，但透明页压缩技术依赖于内核版本和文件系统的稀疏文件特性和打孔技术，当前测试机环境不能满足，因此的压缩只能针对透明表压缩技术进行测试。
一、写入性能对比
样本表配置：不开启压缩、开启压缩压缩级别为最严格的第级，刷盘参数设置为、不开启压缩、开启压缩压缩级别为默认设置
结果图示：横轴为测试的并发数，纵轴为往类样本表中写入的平响


开启表压缩后对写入性能损耗较大；并发时，与不开压缩相比，写入性能差别在倍因压缩和并发线程争抢综合因素
开启压缩前后对写入性能差别较小



并发对的读取影响大于
当并发低于时候，写入性能略优于
随着并发增大，写入性能损耗严重
较高并发下并发大于，写入性能远不及

二、读取性能对比：
样本配置：不开启压缩、开启压缩压缩级别为最严格的第级，刷盘参数设置为、不开启压缩、开启压缩压缩级别为默认设置
结果图示：横轴为测试的并发数，纵轴为往类样本表中查询的平响


开启表压缩后对读取性能影响也比较大；并发时，与不开压缩相比，写入性能差别在倍
开启表压缩，对读写性能损耗均比较大；且对写入性能的影响远大于读取性能
开启压缩前后对读取性能差别较小



并发对的读取影响大于
当并发低于时，的读取性能优于；
随着并发增大，读取性能也损耗严重
高并发下并发大于，读取性能也远不及

三、数据空间对比方面：
样本配置：开启压缩压缩级别为最严格的第级，刷盘参数设置为、开启压缩__设置为、开启压缩__设置为
结果图示：横轴为导入的数据量，纵轴为数据磁盘占有量单位为
说明：因为支持的透明页压缩算法依赖于 技术和稀疏文件技术，而当前系统内核过低，因此本次只针对和的表压缩性能做测试。


压缩效果较好，压缩前后磁盘占有量比例约：，即压缩后能减少的存储
默认压缩效果较差。几乎和不开启压缩时磁盘占用量相当怀疑是测试环境问题，这点待确认
在不开启压缩时，存储成本高于
随着单表数据量增大，在不开压缩时，的存储成本增长速率高于

三、测试总结：
通过第二部分的测试和分析，我们得出如下结论：

的表压缩技术，对读写的性能损耗都比较大
的表压缩技术，能降低约的磁盘存储
在高并发下的表现，并没有预期的那么强劲，尤其是在并发以后，写入和读取性能均下降明显
不开启压缩时候，存储成本高于

基于如上测试结论，我们建议：

的表压缩技术适用于对读写要求不高，但对磁盘利用率要求搞的场景
在不开启压缩时，若出现单表数据量大于，无论从存储上还是读写性能，均不如选择
的默认压缩效果，与预期差距很大，暂不做建议。

四、其他测试细节步骤：
、软硬件配置：




描述
详细参数




硬件
机型： 个核内存 万兆网卡



软件数据库
基于
=== = =  _= ==_==_= ___=___=___=____=___=__=___=___=   ___=____=_____=          _____=___=____= ___=__=___=____=____=___=___=___=_=___={____=_=__=}____=___=___=___=_= ___=__={_=}___={_=}  ___=____=___=___=___=


软件数据库

 =  =  =  _ =  =  =  __= = = __ = __ = __=__=__=_ = __ =  =  _ = __ = __ = __ = __ =  __ = __ =  ___=__ = __ = ______ = ___=____ = ___ = ___ = ___ = __ = ___=___=__= _= __= __=_= _=__=                                __ =  __ =  ___ =  _=_____________



、测试工具：
是阿里开源的一个数据库压测工具，支持定制化和表结构。
示例配置文件： _                         _   =   =    =    =    =    _   =   =    =    =    =  
使用方法：_ =  = 
参考文档
上篇文章简单的介绍了数据可视化的基础，将数据进行设计可视化后，可以让我们有一种全新的方式去认识数据，改变对数据的呈现和思考方式。那现在就让我们开始做一份数据的可视化图表，一步步的来看下我们如何获取数据，以及如何进行可视化的展示。在上章内容中，提到了关于【数据可视化迭代过程】的步骤，这也能看出整个过程包含的步骤，大致有：    确定主题  ．数据获得  图表选择表达 图表绘制。
当然了我们也可以看到可视化是要一个不断迭代的过程，步骤之间都需要多次的迭代修改的。
确定主题
这肯定是第一步了，在做数据可视化的时候，首先你要明了你要做什么，想要从数据获中取什么信息，有了目标才能明确的往下做。那我们这次还是来做关于空气质量的数据展示，了解历年来的实际情况和发展趋势。
数据获得
对于全国空气质量的数据，最权威的来源肯定是来自于中国环境监测总站 的数据提供。但是监测总站的提供的并不是很详细，还有很多第三方也提供类似的接口，比如 ，在说明上做的很详细，他们的数据每日更新。所以这次我们选择这个网站来获取数据源。我们可以看到提供的内容是相当多，包括、、、、、等等。我们只需要的数据，所以我们把其他不需要的数据都可以去除掉，同时把的数据转换为的数据格式，这里转换数据只是为了下一步处理方便，我这边是选用来做数据可视化处理的。如果你用，来做的话，可能会更方便点。
图表选择表达
对于很多人非设计师来说数据可能容易获取，但是像要把数据转换成合适的图表进行表达反而非常困难的。因为同样的数据，用不同的图表进行展示出来，得到的效果是完全不一样的。在平时我们可能用到最多的就是通过来做的图表，在的版本里面，提供了类共个图表，还提供了什么数据透视图，自定义图表等等，总之种类非常多。不过尽管图表种类繁多，但其基本类型只有以下几种：

曲线图：用来反映随时间变化的趋势；
柱形图：用来反映分类项目之间的比较，也可以用来反映时间趋势；
条形图：用来反映分类项目之间的比较；
散点图：用来反映相关性或分布关系；
饼图：用来反映构成，即部分占总体的比例；
地图：用来反映区域之间的分类比较；

那知道了基础图表的类型，如何去做图表的选择呢？国外专家 他将图表展示的关系分为 类：比较、分布、构成、联系。然后根据这个分类和数据的状况给出了对应的图表类型建议。当我们不确定使用什么类型的图表的时候，可以参考下这个图。

图表绘制
俗话说【不会撸码的交互不是好的数据可视化设计师】，虽然现在市面上有各式各样的可视化的方法和工具，但坦白来说【这些可视化工具都是大坑！！！】，要想做好可视化的表现，最好的方式还是需要掌握一门编程语言，只有这样你才能最合适的表达清楚出你想传达出来的数据信息。
这里给各位想跳入数据可视化这个大坑的设计师们编程大佬请无视，推荐一下这个创意编程语言。
是美国麻省理工学院媒体实验室旗下美学与运算小组创造出来的就是搞设计的人做出来的编程语言，非常容易上手，代码逻辑也很简单，几段代码就能做出十分出现效果的展示，下图就是的界面。
 
不过没有代码提示的功能的，用起来还是十分痛苦的，经常是因为一个单词写错了，而造成程序报错。不过后来我发现到 能支持的编译环境，而且能提供代码提示功能，简直是发现新大陆一样，从此用起来再也不费劲了。欢迎大家一起入坑一起学习。
确定用来实现后，我们继续来做的可视化展示。国家环保部将空气质量分为六个等级，分别用绿、黄、橙、红、紫、褐六个颜色来标注，对于着优、良、轻度污染、中度污染、重度污染和严重污染六个空气质量。我们要展示历年来的实际情况和发展趋势，就可以把每天的空气质量转换一个个不同颜色的小方格，通过颜色的区别来展示当天的情况。

先在纸上画一个简单的草图。已年为划分，下面用小方格展示该年内每天的空气质量是什么等级，把当天的数值转换对应的颜色值。

确定方式后，开始撸代码，代码很简单的，我大概编写了来行就完成了，代码逻辑很简单就是先导入数据，然后判断当前数据的值是多少，根据不同的值赋予小方块不同的颜色。

实现之后，看起来就是这样子的。日期时间轴是按照月到月排列的，通过上面的图示我们可以比较清楚的看到污染程度比较高的时间是集中在开头和结尾，就是月，月之间，也就是每年冬天就是污染程度高的时间。

我们继续把成都历史的数据可视化后来看下。我们发现年之前成都空气质量都还不错的，在年的时候，就没有小绿格了，可见年成都空气质量有多差劲，年、年后慢慢的开始有点好转。我们在把北京，上海和深圳的天气拔来看看。

第一列是成都年的空气质量，第二列是北京的，第三列是上海的，第四列是深圳的。可见深圳的空气质量完爆成都、北京和上海。几乎全是小绿格，真是宜居好地方。而帝都北京空气质量是这四个城市中最差的。其中年都是上述几个城市空气质量最差的一年，而也是这一年央视记者柴静从央视辞职出去开始拍摄雾霾的深度调查，在第二年年月号推出纪录片《穹顶之下》，引发了公众的一片哗然，全民开始关注雾霾，政府部门也开始着手治理雾霾，年、年开始有所好转。
小结
通过数据我们能看出起因，也能看到结果，这就是数据的力量。将数据可视化后，我们可以发现数据中更大的意义，最重要的还是实践做出来，这篇文章简单的讲解了下可视化的整个过程，我们如何寻找数据，以及做出有意义的可视化图表出来。希望更多的人兴趣，一起来做数据可视化。全球爆发的比特币勒索蠕虫病毒 事件还在持续发酵，就在昨天，无论是互联网安全界、国内众多高校、政府相关部门等各方都纷纷给出紧急应对措施。腾讯云也在昨天第一时间为云上用户提供了修复建议。
这款勒索软件究竟为什么会在全球大规模爆发？给我们敲响了什么警钟？国内信息安全专业媒体《嘶吼》对腾讯云鼎实验室负责人董志强进行了专访，一起来听听对此次事件的解读。

董志强腾讯安全云鼎实验室负责人。国内知名安全防护工具—“超级巡警”创始人，行业内公认的杀毒专家，因年初“熊猫烧香”事件成为全国焦点，曾负责百度海外安全产品。
月日爆发的“想哭”勒索软件事件，究其原因是之前泄露的一个 漏洞，微软随之便发布了补丁。但是微软补丁更新已经有一段时间，为什么现在会大规模的爆发？
：工具包被披露之后，大家纷纷想办法利用其中的工具，但是他们的工具利用起来有一定的门槛。另外，通过我们的分析，互联网上的补丁修复率并不高，最近还有很多简单的利用方式出来了，包括著名的黑客工具的插件。这就意味着利用已经比之前简单多了。从漏洞可靠性来看，之前的事件主要用漏洞，现在等脚本也出来了，所以黑客在利用这些工具就变得很简单了。
总结之前所有的黑客攻击事件，大部分都是发生在深夜或者周末。攻击者为什么会选择这个时间点发动攻击呢？
：从动机上看，这是扩大效果的需要，利用周末大家休息的空当发动攻击，与安全公司打时间差，这样效果会更好。
文件被勒索软件加密后，有什么有效的恢复手段吗？
：目前还没有有效的第三方修复工具可以完美还原被加密的文件。网上有一些宣称能解密的文章，本意是引导用户购买他们的数据恢复软件。数据恢复软件通过恢复被删除的加密前的文件能恢复部分文件起到一定效果。
对于这样的灾难，对用户和安全公司你有什么建议？
：这块各家都有解决方案。我简单说一下，对勒索软件来说，预防是目前最有效的手段。有一些老生常谈的东西依然有效。比如做好数据备份，及时更新系统补丁，开启防火墙做好端口过滤，安装腾讯电脑管家这样可靠的终端防护产品。不能把希望寄托在遭遇勒索后的解密上，勒索是黑客变现的手段，不要给他们批量扫描入侵的机会。
对于企业和云服务商，可通过腾讯云云镜等安全产品进行清理和普查。云镜基于腾讯安全积累的海量威胁情报数据，利用机器学习为用户提供黑客入侵检测和漏洞风险预警等安全防护服务。
除了打补丁，要做好安全组的策略落地，云服务商的镜像要第一时间更新，针对第三方服务商、生态伙伴提交的镜像也要全面检查安全性，确保有效升级。
安全行业应该加大透明度，加强信息交换和协同防御，比如这次勒索攻击，可以对攻击源进行联动封堵，增加黑客对抗难度 ，黑客换攻击源也是需要成本和时间，去更新他们的攻击脚本、木马设置等等。
每一次攻击事件，都是对各家安全产品，团队响应能力的一个考验和筛选，相信优秀的团队会脱颖而出。
另外呢，希望媒体能多给大家科普，多做一些勒索软件危害的宣传，提高大众安全意识。
：嘶吼被誉为计算机视觉领域三大顶级会议之一的另外两个为、近日揭晓收录论文名单，腾讯优图共有篇论文入选，居业界实验室前列，其中篇被选做口头报告，该类论文仅占总投稿数的。

本届  共收到篇论文投稿，其中篇被选为大会论文，录用比例。其中有篇口头报告和篇亮点报告。今年参会人数预计将超过人，可见其火爆程度。
作为计算机视觉领域最高级别的会议之一，其论文集代表了计算机视觉领域最新的发展方向和水平。此次腾讯优图入选的论文提出了诸多亮点：全球首个卸妆效果的算法；现今最准确的单张图像深度估计算法；完美解决多帧信息融合困难的多帧超分辨率视频结果；史无前例的手机双摄图像匹配和分割研究成果。这些论文呈现了有趣且可扩展应用的技术，让视觉成为了一个工业界和学术界的交叉热点。其中，腾讯优图的智能卸妆超分辨率、双摄融合、滤镜还原和智能图像缩放都是具有极大应用前景的技术。它们创造出新应用的同时也改进了现有算法，为后续的研究提供了更多的经验和指导。
下面我们将对腾讯优图篇入选论文进行解析，也邀请大家在的现场与我们进一步交流与讨论。
腾讯优图篇入选论文详解
论文：美化人像的盲复原
     


本文与香港中文大学合作完成。目前市面上有很多关于人脸美化的应用，如腾讯天天图等。由于这些应用的流行，网络上的人像很多与真人不符。本文提出一种图像盲复原的算法，用于将美化过的人像复原为真实的人像。为了简化问题，本文着重阐述如何解决全局美化操作的复原问题，例如肤色美白，去皱，磨皮等。由于这些操作是在图像的不同尺度上完成的，而我们又无法得到人脸美化应用中所使用的操作类型和参数，直接使用现有的模型并无法解决这个问题。我们提出了一种新的深度网络结构，成分回归网络，来对美化图像进行盲复原。即使在不知道美化系统具体参数的情况下，该网络结构亦能更好地将美化后的图像映射为原始图像。实验表明，该网络在不同尺度上均可以得到较高的还原度。
本文入选  口头报告，该类论文仅占总投稿数的。
 论文：细节还原深度视频超分辨率
   



本论文与香港中文大学、多伦多大学和合作完成。本论文关注解决视频超分辨率的问题，即利用视频中低分辨率的多帧信息，恢复出清晰而真实的高分辨率图像。传统的超分辨率算法处理速度慢，恢复效果严重依赖于繁琐的参数调整，因此难以实用。近期的基于深度学习的算法则由于运动估计不够准确，难以恢复足够丰富的真实细节。
本文作者从原理和实验上发现并指出：正确的运动估计对于图像细节恢复至关重要，并基于此设计了亚像素运动补偿网络层 。本文提出的适用于视频超分辨率的网络结构能够实现：单模型处理任意尺寸输入，任意倍率放大，任意多帧处理。同时，本文算法能够在取得丰富的真实细节情况下，达到很快的处理速度百倍于同等效果的传统方法。本文算法在效果、速度和实用性上均能超过现有其他算法。
本文入选  口头报告，该类论文仅占总投稿数的。
 论文：基于图的图像分割网络
       


本论文与香港中文大学、多伦多大学合作完成。本论文专注解决图像的语义分割问题。与比较常见的图像分割问题相比，这个问题又有了深度的信息。深度信息能够表征物体的几何形状，并且能够更精确的描述像素件的几何链接。因此如何利用深度信息做到更精确的图像分割成为这个问题最核心的模块。在此之前的方法都是先将深度图编码成图像，然后再把图当作另外一张图像并输入到神经网络里抽取特征。这种方法在本质上还是一个基于的解决思路，无法更好的融合点之间在真实空间的联系，并不能使得到的结果很好的利用深度信息。本文作者提出在把深度信息转化为点真实的三维坐标，然后建立基于点实际坐标的 图。并且利用基于图的神经网络，能够让图像特征可以根据图相互迭代更新每个点的特征。最后再利用分类网络对更新过的特征进行分类完成图像图像分割的问题。本文算法在效果上超过现在的基于卷积的方法，体现了该方法利用几何信息完成特征迭代更新的有效性。
本文入选  口头报告，该类论文仅占总投稿数的。
 论文：高质量的手机双摄图像匹配和分割估计
        


本文提出了一个高质量的手机双摄图像匹配以及分割的算法。同时解决了图像匹配和物体分割这两大计算机视觉里的难题。随着双摄逐渐成为手机的标配，怎样更好的匹配双摄图像一直以来都是学术界和工业界关心的问题。为了解决这一难题，作者提出了一种联合优化匹配和分割的框架，为了让优化高效，还提出了一种区域的匹配算法。作者建立了一个对双摄图像的数据集用于算法的评估和测试。
 论文：立体匹配的无监督机器学习
    


本论文与香港中文大学合作完成，主要提出了全新的立体匹配 的无监督学习 框架。深度神经网络在立体匹配问题中被广泛应用，与传统方法相比较下，精度和效率都有显著的提高。然而现有的方法大多基于有监督学习 ，另外少有的一些通过无监督学习得到的模型的精度也不甚理想。
在这篇论文中，作者提出了一种简单又高效的对立体匹配问题的无监督学习方法。通过左右一致性检测，此方法在每一次迭代中都会筛选出正确的匹配。这些正确的匹配会被用作下一次迭代的训练数据。经过数次迭代，此方法收敛到稳定状态。实验结果证明了此方法的精度远优于现有的无监督方法，且十分接近有监督方法。
 论文：基于零阶优化的图像滤镜还原
  


本论文与香港中文大学、多伦多大学和合作完成。在图像处理领域，研究者们设计了种类的繁多的滤镜用来消除噪声，去除纹理等。本文另辟蹊径，首次提出并探讨了滤镜问题的一个新方向：能否恢复经过图像滤镜处理之后的图片？
通过对图像滤镜过程的分析，本文作者发现传统平滑滤镜可以近似看做测度理论中的压缩映射。因此，在无需知道滤镜实现算法的情况下，用简单地零阶迭代算法便可以恢复滤镜前的效果。作者在常用的数十种滤镜上测试了算法，并均能取得很好的效果。本算法本身实现简单无需知道滤镜算法，无需计算梯度，效果显著，其揭示的现象和背后的原理有望引起后续研究者们对滤镜算法领域新的理解。
 论文：基于图模型神经网络的情景识别
     


本论文与香港中文大学和多伦多大学合作完成，作者提出了一种基于图模型的神经网络用于情景识别任务。在情景识别任务中，算法需要同时识别图中所展示的动作以及参与完成这个动作的各种角色，比如主语、宾语、目标、工具等等。为了显式地对不同角色间的关系建模，文中提出的图模型神经网络将表示不同角色的节点连接在了一起，并通过信息传递的方式使得网络可以输出一个结构化的结果。作者在实验中比较了不同的连接方式，比如线形结构，树形结构和全连接结构，发现在情景识别任务中全连接结构的效果最好。最后，文中还展示网络所学习到的对于不同动作的特有的连接结构。上图所示的结果图，比较了不同模型的检测结果。其中蓝底的表示参与动作的角色，绿底表示正确的预测结果，红底表示错误的预测结果。我们可以看到，使用全连接图模型能够纠正一些由其他模型产生的错误。
 论文：基于序列性组合深度网络的实例分割
      


本论文与香港中文大学，多伦多大学和合作完成。实例分割是比物体检测和语义分割更进一步的识别任务，旨在为图中每个实例都提供一个像素级别的掩膜，既保持了区分不同实例的能力，又保证了定位实例的精确性。该任务在自动驾驶，机器人等领域有广阔的应用前景。
在本论文中，作者提出了一种全新的方式，通过一组序列性的不同的深度网络逐步将一些低级的元素不断组合成更加复杂的结构，最终得到每个实例对应的掩膜。该方法同时解决了一些早期工作中自下而上的方法会把被隔断的物体错判为多个物体的问题。该方法在两个数据集上都取得了比早期工作更好的结果。

论文：基于弱监督和自监督的深度卷积神经网络图片缩放算法
        

本论文与韩国大学一起合作。随着数字显示设备的普及，随之而来的一个问题就是同一张图片在不同分辨率设备上显示效果的适应性问题。传统的线性缩放，或是简单裁剪等方法会带来诸如图片内容扭曲、内容丢失等负面效果。
作者提出了一种利用弱监督和自监督深度卷积神经网络来进行图片缩放的算法。该算法通过建立一个在输入图片与目标分辨率图片之间像素级别的映射，旨在对图片大小进行调整的同时，尽量保留图片中重要语义信息的比例结构，从而避免了内容扭曲、内容丢失等传统方法的缺陷，在最大程度上保持了图片显示效果的一致性。
 论文：分区域多人姿态识别算法
    


本论文与上海交通大学合作完成。自然场景下的多人姿态识别一直都是计算机视觉领域中较难攻克的课题之一。尽管目前人物检测的算法已经十分稳定，但微小的误差仍然很难避免。
针对在人物检测结果不准的情况下进行稳定的多人姿态识别这一问题，作者提出了一种全新的解决方案——分区域多人姿态识别算法。该算法综合利用了对称性空间迁移网络   和单人姿态估计算法，从而摆脱了多人姿态识别任务对人物检测准确性的依赖，并且进一步通过参数化的人物姿态表达对识别结果进行了优化。根据在公开数据集上的测试结果，该算法相较提出的算法提升了个百分点，尤其是对手肘、手腕、膝盖、脚踝等细小关键点的改善尤为明显。
 论文：学习判别判别数据拟合函数来做图像的去模糊
        


本论文与南京科学技术大学，大连理工大学和加州大学默塞德分校合作完成。本论文是关于一个用数据拟合函数来解决图像的去模糊问题。图像去模糊是一个经典的计算机视觉问题，需要合理定义数据拟合函数和图像先验知识。但是目前的大部分算法都是通过更好的定义图像先验来提高去模糊的效果，对数据拟合函数的研究比较少。本文提出了一种机器学习方法来学习模糊图像和清晰图像之间的关系，从而得到更好的数据拟合函数。该拟合函数能进一步帮助估计更加准确的模糊核。该算法在非常难的去模糊图像数据集中得到了最好结果。
 论文：利用已知物体和物质信息迁移的弱监督物体检测算法
        

本论文与爱丁堡大学合作完成。本论文关注弱监督的物体检测问题并利用已知物体可数和物质不可数信息迁移来提供帮助。弱监督物体检测的目标集合的中物体位置信息未知，而源集合中对应的物体和物质的信息包括位置、标记等则已知。源集合和目标集合中的物体类别有一定的相似性，比如外形相似或者拥有共同物质背景。为了迁移利用这种相似性，本文作者从源集合中获取三种信息：一个分割模型；源集合与目标集合物体类别之间相似度；源集合中物体与物质类别之间的共生性。作者紧接着利用分割模型对目标集合图片首先做图像分割，同时利用物体物质类别之间的相似度和共生性来修正分割结果。修正后结果被嵌入到多物体检测框架中联合训练并检测目标集合中的物体。本文算法效果在公开数据集上超过其他现有弱监督物体检测算法。同时本文特别选择了目标集和源集合差别很大的物体类别进行测试，显示本文迁移算法具有很强大的泛化能力。
带你一分钟了解
全称为    国际计算机视觉大会，由美国电气和电子工程师学会，     主办。作为世界顶级的学术会议，首届国际计算机视觉大会于年在伦敦揭幕，其后两年举办一届。今年将于月  日到  日在意大利威尼斯举办。
作为计算机视觉领域最高级别的会议之一，是中国计算机学会推荐的类会议。其论文集代表了计算机视觉领域最新的发展方向和水平。会议的论文收录率较低，影响力远超一般期刊，大致与中科院分区区和  的分区中靠前的学术期刊相当。是一种方便的网络通信编程模型，由于和编程语言的高度结合，大大减少了处理网络数据的复杂度，让代码可读性也有可观的提高。但是本身的构成却比较复杂，由于受到编程语言、网络模型、使用习惯的约束，有大量的妥协和取舍之处。本文就是通过分析几种流行的实现案例，提供大家在设计系统时的参考。
由于底层的网络开发一般和具体使用环境有关，而编程实现手段也非常多样化，但不影响使用者，因此本文基本涉及如何实现一个系统。
认识  远程调用
我们在各种操作系统、编程语言生态圈中，多少都会接触过“远程调用”的概念。一般来说，他们指的是用简单的一行代码，通过网络调用另外一个计算机上的某段程序。比如：

——  ：调用远程的方法。“方法”一般是附属于某个对象上的，所以通常指对在远程的计算机上的某个对象，进行其方法函数的调用。

——  ：远程过程调用。指的是对网络上另外一个计算机上的，某段特定的函数代码的调用。


远程调用本身是网络通信的一种概念，他的特点是把网络通信封装成一个类似函数的调用。网络通信在远程调用外，一般还有其他的几种概念：数据包处理、消息队列、流过滤、资源拉取等待。下面比较一下他们差异：



方案
编程方式
信息封装
传输模型
典型应用




远程调用
调用函数，输入参数，获得返回值。
使用编程语言的变量、类型、函数
发出请求，获得响应
 


数据包处理
调用，使用字节码数据，编解码，处理内容
把通信内容构造成二进制的协议包
发送接收
编程


消息队列
调用，使用“包”对象，处理其包含的内容
消息被封装成语言可用的对象或结构
对某队列，存入一个消息；取出一个消息



流过滤
读取一个流，或写出一个流，对流中的单元包即刻处理
单元长度很小的统一数据结构
连接；发送接收；处理
网络视频


资源拉取
输入一个资源，获得资源内容
请求或响应都包含：头部正文
请求后等待响应




针对远程调用的特点——调用函数。业界在各种语言下都开发过类似的方案，同时也有些方案是试图做到跨语言的。尽管远程调用在编程方式上，看起来似乎是最简单易用的，但是也有明显的缺点。所以了解清楚远程调用的优势和缺点，是决定是否要开发、或者使用远程调用这种模型的关键问题。
远程调用的优势有：

屏蔽了网络层。因此在传输协议和编码协议上，我们可以选择不同的方案。比如方案就是用的传输协议编码协议；而的方案往往使用协议。的甚至可以定制任何不同的传输协议和编码协议，你可以用  ，也可以用……。由于屏蔽了网络层，你可以根据实际需要来独立的优化网络部分，而无需涉及业务逻辑的处理代码，这对于需要在各种网络环境下运行的程序来说，非常有价值。

函数映射协议。你可以直接用编程语言来书写数据结构和函数定义，取代编写大量的编码协议格式和分包处理逻辑。对于那些业务逻辑非常复杂的系统，比如网络游戏，可以节省大量定义消息格式的时间。而且函数调用模型非常容易学习，不需要学习通信协议和流程，让经验较浅的程序员也能很容易的开始使用网络编程。


远程调用的缺点：

增加了性能消耗。由于把网络通信包装成“函数”，需要大量额外的处理。比如需要预生产代码，或者使用反射机制。这些都是额外消耗和内存的操作。而且为了表达复杂的数据类型，比如变长的类型，这些都要数据包中增加更多的描述性信息，则会占用更多的网络包长度。

不必要的复杂化。如果你仅仅是为了某些特定的业务需求，比如传送一个固定的文件，那么你应该用协议模型。如果为了做监控或者软件，用简单的消息编码收发会更快速高效。如果是为了做代理服务器，用流式的处理会很简单。另外，如果你要做数据广播，那么消息队列会很容易做到，而远程调用这几乎无法完成。


因此，远程调用最适合的场景是：业务需求多变，网络环境多变。
方案的核心问题
由于远程调用的使用接口是“函数”，所以要如何构建这个“函数”，就产生了三个方面需要决策的问题：
   如何表示“远程”的信息
所谓远程，就是指网络上另外一个位置，那么网络地址就是必须要输入的部分。在网络下，地址和端口号代表了运行中程序的一个入口。所以指定地址和端口是发起远程调用所必需的。
然而，一个程序可能会运行很多个功能，可以接收多个不同含义的远程调用。这样如何去让用户指定这些不同含义的远程调用入口，就成为了另外一个问题。当然最简单的是每个端口一种调用，但是一个最多支持个端口，而且别的网络功能也可能需要端口，所以这种方案可能会不够用，同时一个数字代表一个功能也不太好理解，必须要查表才能明白。
所以我们必须想别的方法。在面向对象的思想下，有些方案提出了：以不同的对象来归纳不同的功能组合，先指定对象，再指定方法。这个想法非常符合程序员的理解方式，就是这种方案的。一旦你确定了用对象这种模型来定义远程调用的地址，那么你就需要有一种指定远程对象的方法，为了指定对象，你必须要能把对象的一些信息，从被调用方服务器端传输给调用方客户端。
最简单的方案就是客户端输入一串字符串作为对象的“名字”，发给服务器端，查找注册了这个“名字”的对象，如果找到了，服务器端就会用某种技术“传输”这个对象给客户端，然后客户端就可以调用他的方法了。当然这种传输不可能是把整个服务器上的对象数据拷贝给客户端，而是用一些符号或者标志的方法，来代表这个服务器上的对象，然后发给客户端。
如果你不是使用面向对象的模型，那么远程的一个函数，也是必须要定位和传输的，因为你调用的函数必须先能找到，然后成为客户端侧的一个接口，才能调用。针对“远程对象”这里说的对象包括面向对象的对象或者仅仅是 函数如何表达才能在网络上定位；以及定位成功之后以什么形式供客户端调用，都是“远程调用”设计方案中第一个重要的问题。
  函数的接口形式应该如何表示
远程调用由于受到网络通信的约束，所以往往不能完全的支持编程语言的所有特性。比如语言函数中的指针类型参数，就无法通过网络传递出去。因此远程调用的函数定义，能用语言中的什么特性，不能用什么特性，是需要在设计方案是规定下来的。
这种规定如果太严格，会影响使用者的易用性；如果太宽泛，则可能导致远程调用的性能低下。如何去设计一种方式，把编程语言中的函数，描述成一个远程调用的函数，也是需要考虑的问题。很多方案采用了配置文件这种通用的方式，而另外一些方案可以直接在源代码中里面加特殊的注释。
一般来说，编译型语言如只能采用源代码根据配置文件生成的方案，虚拟机型语言如可以采用反射机制结合配置文件设置是在源代码中用特殊注释来代替配置文件的方案，如果是脚本语言就更简单，有时候连配置文件都不需要，因为脚本自己就可以充当。总之远程调用的接口要满足怎样的约束，也是一个需要仔细考虑的问题。
 用什么方法来实现网络通信
远程调用最重要的实现细节，就是关于网络通信。用何种通信方式来承载远程调用的问题，细化下来就是两个子问题：用什么样的服务程序提供网络功能？用什么样的通信协议？
远程调用系统可以自己直接对编程来实现通信，也可以委托一些其他软件，比如服务器、消息队列服务器等等……也可以使用不同的网络通信框架，如这些开源框架。通信协议则一般有两层：一个是传输协议，比如或者高层一点的，或者自己定义的传输协议；另外一个是编码协议，就是如何把一个编程语言中的对象，序列化和反序列化成为二进制字节流的方案，流行的方案有、  等等，很多开发语言也有自己的序列化方案，如都自带。以上这些技术细节，应该选择使用哪些，直接关系到远程调用系统的性能和环境兼容性。

以上三个问题，就是远程调用系统必须考虑的核心选型。根据每个方案所面对的约束不同，他们都会在这三个问题上做出取舍，从而适应其约束。但是现在并不存在一个“万能”或者“通用”的方案，其原因就是：在如此复杂的一个系统中，如果要照顾的特性越多，需要付出的成本易用性代价、性能开销也会越多。
下面，我们可以研究下业界现存的各种远程调用方案，看他们是如何在这三个方面做平衡和选择的。
业界方案举例
 
是一个“古老”的，雄心勃勃的方案，他试图在完成远程调用的同时，还完成跨语言的通信的任务，因此其复杂程度是最高的，但是它的设计思想，也被后来更多的其他方案所学习。在通信对象的定位上，它使用来定义一个远程对象，这是在互联网时代非常容易接受的。其对象的内容则限定在语言类型上，并且只能传递值，这也是非常容易理解的。为了能让不同语言的程序通信，所以就必须要在各种编程语言之外独立设计一种仅仅用于描述远程接口的语言，这就是所谓的：   接口描述语言。
用这个方法，你就可以先用一种超然于所有语言之外的语言来定义接口，然后使用工具自动生成各种编程语言的代码。这种方案对于编译型语言几乎是唯一选择。并没有对通信问题有任何约定，而是留给具体语言的实现者去处理，这也许是他没有广泛流行的原因之一。
实际上有一个非常著名的继承者，他就是公司的框架。也是使用一种编译生成多种语言的远程调用方案，并且用等多种语言完整的实现了通信承载，所以在开源框架中是特别有号召力的一个。的通信承载还有个特点，就是能组合使用各种不同的传输协议和编码协议，比如配合……这让它几乎可以选择任何的网络环境。
的模型类似下图，这里有的表示“桩代码”，就是客户端直接使用的函数形式程序；表示“骨架代码”，是需要程序员编写具体提供远程服务功能的模板代码，一般对模版做填空或者继承扩展即可。这个模型几乎是所有远程调用方案的标配。

  
 是虚拟机自带的一个远程调用方案。它也是可以使用来定位远程对象，使用自带的序列化编码协议传递参数值。在接口描述上，由于这是一个仅限于环境下的方案，所以直接用语言的类型作为定义语言。用户通过实现这个接口类型来提供远程服务，同时会根据这个接口文件自动生成客户端的调用代码供调用者使用。他的底层通信实现，还是用协议实现的。在这里，文件就是语言的，同时也是模板，供开发者来填写远程服务内容。而代码则由于的反射功能，由虚拟机直接包办了。
这个方案由于虚拟机的支持，使用起来非常简单，完全按照标志的编程方法就可以轻松解决问题，但是这也仅仅能在环境下运行，限制了其适用的范围。鱼与熊掌不可兼得，易用性和适用性往往是互相冲突的。这和追求最大范围的适用性有很大的差别，也导致了两者在易用性上的不同。
  
中对支持是比较早和比较完善的。首先它通过来查询对象，然后使用语言类型作为参数值的传递。由于的主要是语言的，所以对于功能来说，还是要用一种来描述接口，最后生成和文件来生产的和代码。而通信机制，由于是操作系统自带的，所以使用内核机制承载，这一点还是对使用者来说比较方便的。但是也限制了只能用于程序之间做调用。
   
 在互联网时代，程序需要通过互联网来互相调用。而互联网上最流行的协议是协议和服务，因此使用协议的 就顺理成章的成为跨系统调用的最流行方案。由于可以使用大多数互联网的基础设施，所以 的开发和实现几乎是毫无难度的。一般来说，它都会使用来定位远程对象，而参数则通过一系列预定义的类型主要是语言基础类型，以及对象序列化方式来传递。接口生成方面，你可以自己直接对做解析，也可以使用诸如或者这样的规范。在的方案中，则限定了只有四种操作函数，其他都是参数。

总结一下上面的这些方案，我们发现，针对远程调用的三个核心问题，一般业界有以下几个选择：

远程对象定位：使用；或者使用名字服务来查找

远程调用参数传递：使用的基本类型定义；或者使用某种预订的序列化反序列化方案

接口定义：使用某种特定格式的技术，直接按预先约定一种接口定义文件；或者使用某种描述协议来生成这些接口文件

通信承载：有使用特定之类的服务器，也有可以让用户自己开发定制的通信模型；还有使用或者消息队列这一类更加高级的传输协议


方案选型
在我们确定了远程调用系统方案几个可行选择后，自然就要明确一下各个方案的优缺点，这样才能选择真正合适需求的设计：
 对于远程对象的描述：使用是互联网通行的标准，比较方便用户理解，也容易添加日后需要扩展到内容，因为本身是一个由多个部分组合的字符串；而名字服务则老式一些，但是依然有他的好处，就是名字服务可以附带负载均衡、容灾扩容、自定义路由等一系列特性，对于需求复杂的定位比较容易实现。
 远程调用的接口描述：如果只限制于某个语言、操作系统、平台上，直接利用“隐喻”方式的接口描述，或者以“注解”类型注释手段来标注源代码，实现远程调用接口的定义，是最方便不过的。但是，如果需要兼容编译型语言，如，就一定要用某种来生成这些编译语言的源代码了。
通信承载：给用户自己定制通信模块，能提供最好的适用性，但是也让用户增加了使用的复杂程度。而消息队列这种承载方式，在系统的部署、运维、编程上都会比较简单，缺点就是对于性能、传输特性的定制空间就比较小。
分析完核心问题，我们还需要考虑一些适用性场景：
 面向对象还是面向过程：如果我们只是考虑做面向过程的远程调用，只需要定位到“函数”即可。而如果是面向对象的，则需要定位到“对象”。由于函数是无状态的，所以其定位过程可以简单到一个名字即可，而对象则需要动态的查找到其或句柄。
跨语言还是单一语言：单一语言的方案中，头文件或接口定义完全用一种语言处理即可，如果是跨语言的，就少不免要
 混合式通信承载还是使用服务器承载：混合式承载可能可以用到共享内存等底层技术，可以提供最优的性能，但是使用起来必然非常麻烦。使用服务器的话，则非常简单，因为服务的开源软件、库众多，而且客户端使用浏览器或者一些页面即可调试，缺点是其性能较低。
假设我们现在要为某种业务逻辑非常多变的领域，如企业业务应用领域，或游戏服务器端领域，去设计一个远程调用系统，我们可能应该如下选择：
 使用名字服务定位远程对象：由于企业服务是需要高可用性的，使用名字服务能在查询名字时识别和选择可用性服务对象。方案中的企业就是用名字服务的。
 使用来生成接口定义：由于企业服务或游戏服务，其开发语言可能不是统一的，又或者需要高性能的编程语言如，所以只能使用。
使用混合式通信承载：虽然企业服务看起来无需在很复杂的网络下运行，但是不同的企业的网络环境又可能是千差万别的，所以要做一个通用的系统，最好还是不怕麻烦提供混合式的通信承载，这样可以在等各种协议中选择。

相关推荐谈谈后台服务的和路由管理 经典游戏服务器端架构概述  浅析“远程对象调用”导语： 敢于对过去的脚本说不

前言
飞车作为一款竞速游戏，从年至今十年光阴，依然坚挺，能运维一款这样的产品，非常的荣幸，压力和动力都是有的，有压力才有动力。接手飞车运维以来，在扩缩容上耗费了比较多的精力，于是有了我们今天的主题，飞车扩容改造。
扩容之殇
飞车一年有次大的活动节点，春节，五一，暑假，国庆。活动的量级都是百万级别的，而由于成本和资源的限制，我们的机器不能长期保有在扩容期间的量级，因此，扩容缩容便成为了飞车运维工作中一项重要的工作。运维在活动前准备的时间相对比较长。通常分为以下几个阶段：
 资源申请。通常需要提前个月将预算提供给同事，经过评估确定能支持的虚拟机，机器以及物理机的量和交付的时间，一般情况下，需要预留两周的时间来扩容，一周用于扩容，一周用于观察；
周知周边同事支撑。由于活动量级很大，因此需要周边同事的支持。计算，推送邮件给架平，让架平同事分配足量的专用；其次是，通知网平，参照之前活动的流量数据，确保活动期间有足够的流量支撑；再次是通知安平，确保都在宙斯的防护之下；最后通知计平，能够有充足的资源保障充值的正常。得益于重大活动保障平台的建设，目前这部分工作，已经大大的简化；
 资源到位，扩容准备。扩容准备工作主要是需要将新来的机器加入到的管理，让新的机器的文件和现网都能保持一致；其次，申请，根据架平同事给的组，为新的申请端口；
扩容。机器准备就绪之后，就可以开始扩容了，飞车现目前扩容有一整套完善的标准云扩容模版，这就是我们今天要讨论的主题，请各位看官接着往下看。
现有扩容模版的缺陷
经过两次独立的扩容之后，发现了现有模版的缺陷。
首先，不支持多模块扩容；
其次，一次扩容的机器数量不能超过；
最后，是扩容脚本的学习成本比较高，新手上手比较慢，这也从一个侧面增加了扩容的风险。
想想，假设我们需要扩台机器，那我们得分至少次调用模版才能扩容完成，按照现有扩容一次保守估计分钟计算，这时间量是相当恐怖的，运维还要不要干活儿了，光在扩容上就把人耗死了。
从扩容脚本说起
飞车现有的扩容脚本是一代一代运维流传下来的，经过每一代运维哥哥的改造与优化，到现在已经是一个很稳定的版本了。今天我们只说扩容，对扩容做一次深入的剖析。众所周知，我们自研的业务，都是通过来管理进程的，因此扩容无非是准备好这三个文件，别出错，每个业务都有自己的一套扩缩容生态，现在飞车扩容要维护六个初始文件
后端维护文件 
前端文件
问题转换为维护这六个文件，一般情况下，后端是不需要动的，于是变成了维护这三个文件，先来梳理下现有的扩容脚本：
 核心脚本，这个脚本主要完成备份、输入参数转换、调用扩容脚本、生成信息、更新反外挂列表
 扩容脚本，这个脚本主要完成实例的计算以及更新前端文件
  调用接口，更新信息；
__ 主要用于反外挂列表的更新
他们之间的调用关系可以用下图来表示：

现有模版的输入参数是 大区号 模块名 列表。之前说过，一个是只能单模块扩容，而且不能多任务，因为这样会导致文件错乱；另外是机器数的限制，同模块得分多次才能完成调用。
改造开始
基于上述的问题，我们需要找到一些新的方法，避免这样重复的多次劳动。无论是脚本还是标准云的接口，都只能支持单模块的扩容，那我们的多模块扩容到底有什么实现思路呢？
首先，我们来解决标准云模版中批量修改主机名和批量移动主机模块的问题，在单模块扩容的时候，因为输入的模块和大区名只有一个，因此修改主机名和移动模块不会有问题，而多模块扩容的是呢？我们需要扩容的模块都是未知的，不能通过设定多个变量名来解决，这只是添油战术，指标不治本，另外，参数重载也不是行不通的。
通过标准云来操作这条路，我们是走不通了，我们就换一种思路。基于蓝鲸的接口，我开发了一个小型的，这个中封装了几个接口当然也可以通过心云开发接口
接口：修改主机名接口
接口：修改主机模块接口
 接口：刷新接口
以上三个接口，都支持多个模块，多个主机同时操作，而且返回特别的快，大大的节省时间。以后可以有更多的原子操作扩展，慢慢丰富，因为接口完全独立于业务，所以更加灵活，一定程度上实现了解耦。
有了这个的接口，接下来就可以专心的处理参数的初转换工作了，只要我的参数是按照的接口以及脚本要求的形式传入，总是能返回正确的结果。
接下来我们来解决参数处理的问题，现在就不通过标准云传参了，我们准备一个文件，这个文件的格式是：大区名|模块名|扩容，再写一个包裹脚本__，这该脚本的功能如下：
 _函数：转换输入参数为格式：
初始化参数
输入：
||
||
||
||
||
||
输出
｛
{


}
{


，
}
{
}
｝
  _函数：
移动到指定的模块 ___函数修改主机名为形式 ___函数刷新机器的  ___函数生成配置调用生成脚本      
至此，我们多模块扩容的核心功能就改造完成了。我们来回顾一下解决的思路
 简化输入，不重复调用模版 于是我们定义了包裹脚本，来转换输入以及完成脚本调用；
 绕过标准云的限制，定制符合业务需求的接口
改造之后，我们不过度的依赖于标准云，更灵活一些了，经过改造现在我们的扩容变成了这个样子：

增量扩缩容
以上就是在现有的基础脚本上就行了包裹转换，现在飞车的配置生成，是全量生成，前后两个版本的文件无法对比，运维每次扩容后要小心翼翼的去对比操作。这种扩容风险实际上还是比较大，因此增量更新脚本就应运而生了，增量更新脚本集成了扩容、缩容和变更的所有操作，运维只需要专心维护脚本即可。具体如图所示画：

增量更新的脚本的思路是：基础脚本负责备份回滚、检查变更、异常处理以及变更操作等小组的大神已经写好了这样一套稳定的基础脚本，业务侧只需要按照脚本要求，做好输入转换以及少量修改配置生成脚本即可。总结起来，新版本的脚本的特点如下
配置是增量的，这样可以差异；

完善的通知机制，让运维能在任何配置更改后看到配置差异；
完善的备份回滚机制。操作之前先备份，有错误能立刻回滚；
原子操作脚本，不支持拆分，有错误立马回滚；
完善的日志，任何的关键信息都有记录，出错时可以通过日志定位问题；
严格的，变更之后必须检验，以保证每次的变更都是正确的。
核心脚本的工作示例如


经过改造之后，我们的扩容，缩容，变更都可以通过这一套脚本来实现，扩缩容模版就可以变得更简单。
扩缩容生态建设
有了基础的脚本支撑，我们就依托于标准运维对之前的扩缩容“生态”工具进行改造，得益于的日趋成熟，飞车的镜像扩容模版也已经完成建设，镜像扩容省去了业务传包和一些初始化的工作，可以节约大部分的时间。
后期工作
改造后的脚本，已经在今年的国庆扩容中使用，但是仍然存在一些小问题，总结以下几点后期的方向：
 工具的不断测试。通过扩缩容不断的验证工具的正确性，确保工具的万无一失；
效果评估。尤其是引入之后的镜像扩容，相比于传统的扩容在时间成本上能有多大的提升；
 文档与版本建设。
致谢
至此我们的改造就基本上完成了。改造过程中遇到很多的问题，都逐一解决，感谢在这个过程中的提供的帮助。希望可以把飞车运维工作干得更好。热点事件
刘强东：下个月开始实现北京所高校采用机器人送货刘强东在今日的京东金融数据大会上发表演讲称，京东的配送机器人，在人大、清华等高校，最早的已经测试了将近一年时间，下个月开始将在短时间内实现北京市一百所高校全部采用机器人送货。刘强东还称，计划未来三年之内，重型无人机可以飞五百到一千公里，携带一吨到两吨的货物。从远期来看，希望京东重型无人机能够实现超过万吨载重货物的运输量。刘强东说，京东电商定位是作为一家用技术来为品牌商提供供应链服务的基础设施服务商。
图灵奖得主姚期智加盟旷视科技学术委员会任首席顾问旷视科技月日联合清华大学、清华交叉信息学院以“人工智能的本质创新”为题举办研讨会，同时宣布成立旷视科技学术委员会，并邀请中国科学院院士、首位图灵奖华人得主姚期智先生担任首席顾问，作为学术指导协助旷视科技加快推动产业实践。
爱沙尼亚智能身份证出现安全漏洞，导致全国半数身份证停用两天爱沙尼亚采用了智能身份证系统，智能身份证可以在网上银行或者网上投票等，作为身份认证来用。据外媒消息，最近相关专家发现，这款智能身份证上的芯片有漏洞，不法分子可以利用该漏洞盗取用户资料来伪造身份。受影响的身份证为年月至年月日之间发行的，合计约有人受影响，人数接近爱沙尼亚一半的人口。为了修补该安全漏洞，所有受影响的智能身份证都要完全停用两天，并且要在网上更新证书。懂玩手机网
特斯拉月日发布重卡 或将配备半自动驾驶系统特斯拉旗下纯电动重型卡车将于月日亮相。据了解，该车将采用纯电驱动，最大续航里程约为英里公里，未来或将配备半自动驾驶系统。腾讯汽车
苏宁第二家无人店落地上海 拟推广至北京等城市苏宁上海首家无人店“苏宁易购”，月日在苏宁易购五角场云店亮相。据悉，这是苏宁在全国范围内的第二家无人店，相比苏宁今年月份在南京开设的首家无人店，“苏宁易购”面积更大、品类更丰富，还实现了“刷脸”购物。苏宁易购副总裁、上海苏宁总经理范志军透露，今年双期间，他们会在北京、重庆、徐州三个城市再开家无人店。另外，苏宁在上海也在对近个商圈进行选址，未来会随着成本的降低，进行进一步复制。证券时报网
暴风发布无屏电视 售价元暴风发布全球首台人工智能无屏电视，售价元。暴风无屏电视采用超高主频的位旗舰芯片，高速大内存，高速大闪存，双频极速，蓝牙快速稳定，产品高配置更好地支持人工智能服务。相变材料搭配液冷散热技术、空气流场风道设计，保证长时间运行时的稳定和流畅；液压轴承、无级变速静音技术，让用户无噪音干扰观影。
寒武纪陈天石：预计未来年拿下中国人工智能芯片市场份额寒武纪陈天石在产品发布会上表示，公司预计未来年会有亿台设备使用寒武纪处理器，在中国人工智能芯片占有市场份额。发布会还公布了新一代寒武纪处理器。未来将推出寒武纪处理器，可应用于智能驾驶，性能比寒武纪相比强倍以上。据介绍寒武纪处理器是全球首款商用深度学习处理器，应用于华为麒麟芯片。近期寒武纪与中科曙光联合推出曙光处理器。
武汉投资亿元开发行业特种机器人武汉未来将生产自动驾驶汽车、水下作业机器人和排雷机器人等行业特种机器人。国内知名产业互联网提供商星河集团日前与武汉市签订战略合作协议，双方将共同投资亿元在武汉建设星河机器人产业园，推进工业机器人、服务机器人和特种机器人的开发应用。现场签约的星河集团董事长徐茂栋介绍，以机器人为代表的人工智能产业正迎来大发展时期，国际机构预测到年将产生高达亿美元的商业价值。
优步筹备第二代自动驾驶汽车 最快年底上市优步的第二代自动驾驶汽车正在试车轨道上进行开发测试，最早将于今年年底上路。优步的硬件工程师 表示，现款无人驾驶汽车需要一至两位车辆操作员。 一位优步员工坐在驾驶员座位上，当计算机系统告诉操作员需要关闭自行驾驶模式时，准备接管车辆。另一位员工坐在乘客座位上，监测地图，该地图会显示车辆传感器实时看到的内容，包括骑自行车的人、行人和其他车辆。乘客可以通过后座上的看到汽车“看到”的内容。
微软小娜 版更新发布微软小娜为用户带来 新版本更新，在该版本中微软主要是修复了并提升了性能。在上一个版本中，版重新设计了多种界面，可以在新“今日一览”中快速了解一天行程。微软小娜是微软全球首款智能专属个人助理。她可以帮助管理日程，设置闹钟、打电话、发信息、打开应用、搜索、导航、翻译，并回答任何问题。还能根据用户喜好，主动推送专属定制信息。之家
投资事件
公司枭龙科技获戈壁创投数千万元轮融资北京枭龙科技有限公司宣布，公司于年月底已经完成数千万轮融资，投资方为戈壁创投。此次投资的资金主要用于加大对光学等核心技术的研发投入，完成产业链上下游布局，加快研发 产品，以及行业解决方案研发。枭龙科技在年月成立，曾一年内完成三轮融资：获得种子轮融资、天使轮融资和立讯精密领投的轮融资。枭龙科技现有员工约人。年完成首款运动智能眼镜产品的研发、量产及上市。先后将运动智能眼镜、  双目智能眼镜、单兵头盔等多款产品研发完成并且量产上市。
主攻车内手势识别的「极鱼科技」完成轮融资极鱼科技国内以方案实现手势识别模块的创业公司宣布，已完成多万元的轮融资，投资方是上海雎才资本。极鱼科技房文新告诉氪，此轮融资将主要用于车内手势识别模块的研发和生产。此前，极鱼科技的手势识别模块主要面向领域，以及智能家居领域进行销售，客户多是下游端硬件厂商。极鱼科技将于年底开启千万美元的轮融资，主要是扩充生产线，将产能从每月台扩产到每月万台左右。氪
传商汤科技新一轮融资额或达亿美元，将成行业最大融资商汤科技计划在新一轮融资中筹集约亿美元，将创下人工智能行业最大规模融资。消息人士说，最新一轮融资将使商汤科技估值达到约亿美元。其中两位消息人士表示，融资已吸引到包括新加坡国有投资机构淡马锡控股在内的潜在投资者。新浪科技
工匠社获腾讯数千万人民币轮融资工匠社格斗竞技机器人研发厂商于近日完成数千万人民币  轮融资，投资方为腾讯控股。创始人兼 招俊健表示，轮融资将主要用于格斗机器人新系列的研发迭代并加大在品牌与市场的投入。招俊健告诉氪，团队的愿景是打造一款“铁甲钢拳”版的线下星际争霸。成立于年月的工匠社是一家消费级机器人研发商，团队为机器人设计了多元的操控系统，并在运动结构、算法与机器视觉方面做出了微创新。据招俊健介绍，工匠社目前已推出两款机器人系列：  系列和  系列，分别对应近战兵体系与远程兵体系。
超越智能新三板挂牌上市超越智能是一家自动化智能信息安全技术产品研发商，集设计、研发、生产、销售和服务等于一体，专注于自助银亭核心技术安防系统的研究开发，产品包括自助银亭、智能警银亭、智能清分机等，近日，超越智能新三板挂牌上市。
获得万美元轮融资，  领投是一个人力资源智能匹配平台，可以智能化分析员工的日常表现，工作技能，兴趣和专业知识背景，然后匹配到最合适的项目和工作任务之中，近日，获得万美元轮融资，  领投，参投方包括 ，  ，以及 。
获得万美元种子轮融资是一家无人驾驶电动拖拉机研发商，能够自动设计工作路线，无需人为操作即可完成农场作业，近日，获得万美元种子轮融资。
获得万美元种子轮融资是一家虚拟现实设备研发商，主要服务的是宗教朝圣者这一特殊用户群，研发的虚拟现实套件支持将头显设备和智能手机搭配在一起，利用虚拟现实和增强现实技术为用户提供身临其境的交互式宗教和精神体验，近日，获得万美元种子轮融资，投资方是一批来自 旗下的天使投资人。
主推虚拟情境外语学习课程， 获万美元种子轮融资 获得由 领投的万美元种子轮融资。至此， 累计融资万美元。 是美国的一个在线外语学习平台，目前主要为青少年提供中文和西班牙语课程。 主打交互式外语学习，这也是该平台最大的特点。其学习方式是为每个学生配备一位导师，通过视频直播进行一对一教学。 系列课程由视频和游戏组成，上课时，学生和他们的导师一起进入毁灭的玛雅或长城虚拟世界，共同完成一个任务或者说通关游戏。 为此开发了一个基于 的学习平台。写在前面

的渲染能力是由其他框架实现的，除了苹果的 、 或者其他自定义的、渲染引擎都可以与相结合。本文所介绍的技术都是基于。




关于物理模拟
虽然物理引擎都具有真实的物理变量，如质量、重力、摩擦力等，但当我们说道物理模拟，不是要真的去用真实世界的数值去模拟物理行为，事实上那样反而会失真。我们要做的是维护好各种变量的相对关系，制造一种真实的物理感官即可。

游戏中的物理引擎用来模拟世界中的物理特效，使物体具备的真实的动态行为。使用来管理这种物理模拟，让物体的碰撞、连接、掉落等具有真实感。
具有继承自的默认。任何添加到的物理对象，都会注册到中，维护其中的物理关系是重点。利用，我们主要做以下工作：

管理全局的物理变量。
利用其代理方法观察物理行为。
使用 方法，检测物理之间的物理关系。


想要一个参与到物理模拟中，只需要给赋值一个合适的值。所有拥有 的，会在 的 阶段，计算该的物理行为，在接下来的渲染阶段对做相应的变换。

一个合适的需要合理设置其与。


 可以被碰撞、力影响。适合场景中物理引擎可以完全接管的类型，如掉落的石块。
 不受碰撞、力影响，且不能移动。适合场景中地面、墙体等。
 不受碰撞、力影响，但移动的时候会影响其他。适合场景中的角色，毕竟我们不想角色的移动不想被太多力影响。


当 参与到物理模拟时，一个更贴合的形状能得到一个更令人满意的结果。但是对于一个比较复杂的几何体，简单的会显得过大，又会太复杂影响性能。这种情况可以使用若干个简单的形状拼装一个相似的形状，或者由设计给出一个合理的形状，总之形状的选择要平衡性能与真实感。
 
一个场景中会有许多，需要给他们设置，让我们只关注感兴趣的碰撞、接触。尤其要注意的是它们各自的默认值，不然很容易出现。
指定的类型，  默认为， 默认为。
指定能与该产生碰撞的 类型。默认是，即每位都置。
指定哪种类型的 与该发生接触几何体交叉后，通知给 。
这个属性在和以上默认值是，以下与相同。
记住重设 时，要恢复这些值
注意也有一个，用法与这个类似。但在 时，这两个容易搞混。这里吐槽以下苹果的命名。

当物理引擎检测碰撞时，使用的是来计算结果，除了性能，我碰到两个关于的问题：

如果是不可见的，那个虽然它有 ，在调试时也会显示，但不会参与物理模拟。
的物理引擎是不支持缩放变换的。如果一个做缩放变换后， 将仍是原来的尺寸。这种情况看我的回答，重点是当 之前如果没有指定形状，那么才会使用信息，使用也有一样的效果。

   
  =     
  
  =                                                       
                   ’  
物理模拟与其他动画的冲突
从的 可以看到，物理模拟实际上也是一种动画，只不过动画的参数由物理引擎控制。也遵循的传统，具有隐式、显式动画，同时有接口。由于物理引擎。
是将所有的计算结果应用到动画层上，即，这会让新加入的动画显得不正常。因为其他动画的初始值是从中读取的。对于这种问题，需要读出的值用于动画的初始值。
  
对于简单的碰撞，只要设置好 和  ，  等参数，其他的就由物理引擎接管了。碰撞的处理过程由个部分组成。
 
物理引擎会在渲染时检测物体之间的 是否发生重叠，这一过程我们可以通过中的方法观察。
 
与操作两个物体的之间的和，若返回非，则发生碰撞。
 
物理引擎会在渲染之前，计算物理碰撞的结果并应用到物体上。
 
当有两个物体相接触，若和相与不为零，那么会调用的方法。很显然这个结果的集合是小于碰撞结果的。通过这个方法，我们能够控制两个物体之间的碰撞，这在物理引擎接管的碰撞动画不理想时，是非常有用的。
当接触发生时，代理方法会传来对象，它包含了接触的对象、部位、法线与重叠距离。通过它可以修正错误的动画。例如我将一个石块从高处坠落，如果速度特别大，那么它会直接穿过底部的平面。因为在 的渲染时，两者相接触的那一帧在物理模拟时，石块已经大部分穿过了平面，这样在下一帧石块会直接穿过去，而不是回弹。可以看我的回答。
 
与中共有以下几种 ，用以观察世界中的物体关系，作用类似的  方法。
  

    
                                  
根据中的点，构造一条世界的射线，搜索或真实物体特征点或已检测出的平面。
 

    
                                   


    
                                                      
                                                       
第一个方法：根据等中的点，构造一条世界的射线，搜索与射线相交的几何体，为则忽视。
第二个方法：在目标的局部空间中，搜索与线段相交的子。
  

    
                                                      
                                                       
     
                                              
                                                
                                                     
第一个方法：在物理世界中，返回在两点之间的 所属的。第二个方法：在物理世界中，按变换滑动指定的形状，返回相交的 所属的。
 
 
     
                                                   
                                                   
     
                                                
第一个方法：检测物理世界中，两个是否发生接触，返回所有的接触点。
第二个方法：返回所有在物理世界中与指定发生的。
最后
物理引擎能够帮助我们模拟真实世界的效果，虽然高级的特效一般都是自己在渲染循环中实现的，但它大大减轻了我们计算成本。拥有良好的物理特效，能够让用户有真实的感受，希望本篇文章能够帮助大家。入司十年，受邀编写小文一篇，内心忐忑，唯恐写出的东西老套无用，认真思索一番，个人觉得积累的经验总结或是知识技能均在具体的项目中才能用上，唯有良好的工作、学习习惯才是整个职业生涯都可受用不尽的法宝。同时，相对而言，外化的各种行为或者表达习惯也是细枝末节，重要的是内在的思维意识习惯，这才是驱动个人成长的根本要素。
这十年的工作学习经历，个人觉得最重要的习惯就是一定要不断跳出自己的舒适区，摆脱惯性的控制。时刻对新变化、新问题、新技术等保持敏感，树立更高的目标倒逼自己，唯有这样才能战胜惯性，不断成长，持续提升自己的价值。就像下面这个图示意的，让自己随时保持在“学习区”，学习具有挑战性的东西，一段时间后，“学习区”会慢慢变为“舒适区”， “舒适区”越变越大， 而一部分的“恐慌区” 也会相应变成“学习区”。

接下来，按照“是什么、为什么、怎么做”来谈谈我对这个习惯的浅见。
 、是什么
个人感触较深的是，这个习惯在工作的不同阶段有不同的含义。
从毕业说起，在学校期间，学习的目标是掌握知识，兴趣是最好的老师，广度、深度和时间都是自由决定。工作以后，就要意识到学习的目标是完成项目，要以项目顺利开展为导向，如果是团队项目，进度上还需要注意和其他成员的配合，所以，这时的“保持敏感，战胜惯性”就是意识到需要完成学生到“工人”的转换，培养团队精神，和大家并肩战斗。
对于工作两三年的同学来说，独立模块的工作任务可以轻松胜任，在项目中与其他同学的沟通协调也可顺畅完成，这时，应该开始培养系统化思维，对于架构是否合理、系统关键瓶颈、整体运营成本等都要有深入的思考，在沟通协调中也要担任更加主动的角色，甚至在关键任务的攻克上起到带领作用。
以上阶段磨练三年左右，这时可以主导中型项目了，技术视野也覆盖到行业中的竞品，成为团队中的骨干，也会时常担任招聘面试官和新人导师的角色，这个时期就需要有意识的思考工作的价值，工作输出要对用户有价值，对业务发展、平台壮大、团队成长有价值，在项目的组织推动上如果涉及部门内外和团队上下也能很好兼顾。
打怪升级又三年，重要事项的决策领导会拉你讨论，时不时的也会有不认识的小伙伴找来，讨论与你专业特长相关的问题，这时就需要培养对于专业发展趋势的研判能力，做出决定后能够进行相关布局，说白了就是开拓新领域、打赢新战场的能力。
以上的时间线只是个人划定，所讨论的能力覆盖是否全面也未论证，只是想说明思维时刻保持敏感，战胜惯性，不断提升自己的专业力、组织力和影响力，才能实现个人成长的持续成长。

、为什么
在的位置上有几年时间，观察了不少毕业生，有一个感想，就是其实对于很多人来说，能力和起点都是差不多的，并没有本质的差别。真正决定两个人之间差距的，很多时候就是看你是否保持足够的敏感度，是否能战胜惯性，并且摆脱「想法太多，做得太少」的状态，努力练级。如果都做到了，那么在技术人生的这场局里，你的段位自然会快速提升，而能否快速提升的效果差距还是很大的：曾经阅读过几份薪酬报告，同一行业相同工作年限的人群，工作时间越久，薪酬变动范围越大。
、怎么做
要做到“敏感”，简单来讲就是要保持“心眼”张开，用心观察和思考周遭事情的变化，审时度势，至少做到“不要成为制约项目成功的瓶颈”，尤其是很多事情需要你拍板的时候，可能最大的瓶颈就是你。此外，在分析问题时，要跳出惯性的“自我视点”，摆脱“自我评价”的束缚，不受自己的思考方法、经验，以及常识的影响。并且能主动进阶，能做到站在比自己高两个职级的“老板”的角度来考虑问题，在更大的范围内审视你的价值。用这样的高标准、严要求来考核自己，相信一定可以战胜惰性，不断成长！导语
玩过  的童鞋应该知道，在  中配合 库可以很轻松地识别图片并在上面建立模型。然而，在  官网中，不仅可以识别图片，还可以识别几何体，特别是从  开始支持识别更不规则的物体。本文将详细介绍如何在  中用  做简单的物体识别。
文章将分为  识别过程和  开发过程两部分进行描述。
识别过程
  需要在官网上做的准备
在开始之前，需要在官网上注册自己的账号，才能新建，获得自己的后面需要用到和上传需要识别的图片或物体作为。
  选取需要识别的物体
对于物体的识别，需要符合以下几点标准：

不透明的刚性物体，并且物体没有可移动的部位
表面特征较有对比度，不支持柔软的或者可以变形的物体
不规则的图案或者形状越多识别会越好
不能太光滑导致有反光效果

例如一些玩具公仔、玩具车，都是比较好的识别对象

  打印识别图，物体需要放在右上角的网格中进行识别，打印如下所示的识别图时需要注意控制尺寸大小，让网格大小和物体的大小刚刚好是符合的，这样可以便于之后的识别过程更加精准后面将详细解释。

 下载扫描工具，物体的识别需要上传  文件到官网。至于文件的生成，需要到官网下载名为  的，然后安装到安卓手机上。下载地址： 
  接着就是打开，将物体放在网格中进行扫描。屏幕右上角的数越多，依附在物体上的点数越密集时，识别率越高。扫描时，必须注意在室内环境下，且没有集中的强光照射，其实就是避免不必要的物体反光和照射下产生的阴影导致识别不准确。将所有网格都填满时，识别就可以结束。这一步需要比较多的耐心。。。这里明显纸张的网格区域比小新的大小大很多，后面就会发现中展示的区域是整个网格大小，不止小新所包围的屏障的大小

识别完后，可以通过中的按钮，将摄像头对准物体看看是否成功扫描并且容易被识别到。识别成功会出现一个半透明长方体。

  最后一步，将软件生成的文件上传到官网我是通过从手机分享到上传到电脑的，然后下载。具体操作是在 中，添加，上传完成后这个时间会比较久，下载，每个数据包可支持多达个的。

 
开发过程
在中我们需要用到关于的对象分别是和，分别来自官方的 和上一部分的最后一步下载的关于识别物体的。导入后可在里面找到这两个的，拖进场景。另外记得要把默认的删除。因为我们只需用到。具体操作可看组内越升大神写的另一篇文章《有十块钱才玩得起的游戏》。
接下来介绍和的几个重要属性和参数：
 

       需要填写你在官网申请的上面提到的，否则不能运行。

     设置程序中是渲染质量优先还是帧速率优先，默认_在高性能设备下会优先渲染。 

    定义最多有多少个可以同时通过摄像头跟踪。但对于物体识别的跟踪，最大的支持数为

  定义摄像头下世界空间的原点，在摄像头移动时，坐标系为世界坐标系的其它的将会跟随这个原点移动。这里有四个选项：

_ 指定的为世界空间的原点。
_ 以摄像头第一个识别到的物体的坐标为世界空间的原点。
 世界坐标是以摄像头为准的，所以场景里的其它物体不会跟随识别移动。
_ 这个场景下经过测试，场景里的其它物体不会跟随识别移动。暂时还不知道和第三种模式的区别是啥。。。



    当 设置为_时，定义场景中指定的作为场景的世界空间的原点。将该拖进输入框即可。
    勾选可以使得在初始化时就自动加载需要识别的的数据包并激活，如果不想要在开始时就自动加载，则需要用到的了，传送门 
 
      指定加载数据集和需要识别的。
  包围被识别的的长方体 的尺寸。
     勾选的话显示包围被识别的的长方体 。
     默认不勾选时，程序会根据被识别的大小摄像头到的距离自动调整附在识别上的子物体的大小，与保持比例，如果勾选则会一直保持子物体的大小。
     当离开摄像头但是附在上的子物体还在时可以继续被跟踪到。看下图就明白了：     

       是的增强现实的一个重要功能，让识别所在的物理环境可以得以重构和增强，对于它的使用，官网有详细的介绍和例子，但不能与  同时被勾选。有兴趣的可以看看这个视频 点击观看 
当了解了以上参数的作用后，就可以结合自己的需求进行开发了，在开发过程中，可能有以下两点需要注意：
 为识别物体添加

为添加可以跟随它移动的对象其实很简单，只需为添加子物体，子物体的位置和大小也是以 的原点坐标为准的。例如下图要为小新公仔加两个球，两个球体在摄像头上会跟随小新移动。
但是这个球体离小新的距离太远了，如果想要在小新公仔的两个手掌上加上两个小球体作为动感光波，必须要把小球定位到小新的两个手掌周围，但是我们可以参考的只有 。
为了实现精准定位，首先要找到 。因为的场景下不会显示 ，所以我在下建立了一个跟 位置和大小相同的半透明的，在下显示情况如下图所示：

然后就会发现， 的大小其实是识别图右上角的网格大小所以前面才说要打印和识别物体大小差不多的识别图。
这个时候，就可以不断调整球体的位置和大小直到旋转的情况下都贴合小新的手掌， 的三个边缘线分别是\\轴，所以有了 的显示还是比较容易找的。然后记录球体的位置和大小

再切换到场景中，将记录下的位置和大小填入。之前以为会有更好的方法，找了好久没找到，后面发现官网介绍也是这样子做的。。。
这是最后在安卓手机摄像头下的展示效果，实在不知道会发光的动感光波在下要怎么实现，原谅我是建模渣渣，最后变成了小新的手掌出来了两颗会发光的小球体。

  还有一点，中的是没有默认自动对焦的，需要自己在中设置。在对应的脚本中加上以下这句可能要针对不同设备兼容，但是在三星 测试是没问题的：

__
参考文章地址：
【】
【】
【】首先，本人是一只喜欢瞎折腾的咸鱼，带有轻微的强迫症，同时也是。然而别人创建好的懒人整合服务端有时候并不是自己喜欢的东西，在强迫症和好动症的逼迫下自己瞎折腾出一套适合自己的服务端。
前提

服务端运行环境为，因此不限于操作系统平台，我在这里选用了 ，其他发行版更替相应专有命令即可
官方服务端可以在官网得到，但是存在可玩性不高并且游戏模式单一的缺陷，因此我选用了大众化的服务端十分感谢酱的贡献
由于个人服务器同时在线人数也不多，选用个内存的足够达到本人要求，因此所有环境基于的

开搞
至于基本内容这里就不赘述了，为了方便起见需要有权限以及方便远程连接的普通用户。
安装运行环境以及我比较喜欢直接安装，如果没有需求或者介意存储空间的童鞋可以考虑用于方便管理服务器，这里就一起安装好：
    
完成之后可以查看版本是否正确安装：
  
  _
     
       
添加运行服务的用户：
     
我习惯于使用，这里可以不指定，直接使用系统默认，参数创建用户主目录，不需要设置密码。
现在直接切换到用户，切换到主目录：
  
 
 

这时候最好创建一个工作目录，下载最新版本的：
 
 
 
下载完成之后运行，可以根据自己需求制定参数，若不指定就是最新版本：
    
经历时间取决于网络状态，一般几分钟到十几分钟左右。好了，现在可以去泡杯茶了。完工之后没有任何报错，可以看到在目录下有了这个文件：
  
         
准备开服
现在创建服务运行的根目录，我选在：
 
 
  
 
先手动执行一次：
    
参数 设置运行时最大和初始化内存，可以根据在线人数更改为或者更多，推荐值是。
这时出现提示：
                  
当然了，去看一下这个文件：
懒癌晚期当然没去看人家，直接改为=
好了，为了方便起见，开服当然需要一个脚本，我命名为：

  
 

    

   是在中如果捕获到就退出脚本。
万事俱备，只欠东风：
  

看到这里就表示我们的服务开好了：
第一次开启生成地图需要的时间比较长，后面再启动时就会很快。然而我们现在没有安装任何插件，还是很普通的一个裸服。在实用的时候，开服务必用用户先打开一个 再运行，这样可以保证随时随地很方便地管理控制台，避免了有时手滑不小心杀掉了进程。
在日常游戏中我们可能会使用很多插件，而当服务器环境搭建好之后安装兼容的插件是一件很容易的事情了，我这里列举一些我在使用的插件：
 本地认证管理

 系列，必备插件
  
  
  



 谁动了我的箱子

 谁动了我的地盘

 谁动了我的钱

 让砍树成为一件轻松的事

 喜欢么，来试试这个

  

配置
为了适合腐竹们不同的需求，的默认配置显然不能满足所有人，我们一点一点来配置。首先分析服务端根目录下的文件，这是 默认提供的配置文件，这里简要说明一下部分参数的含义：
  
=
 游戏模式，=生存，=创造，=极限
=
 游戏难度，默认为，为和平，不同难度会影响一些怪物的行为
=
 允许，如果不想玩家互掐的话可以关了
=
 最大玩家数量，限制同时可以在线的玩家数目，默认
=
 封包压缩阈值，超过这个大小的封包进行压缩，适当改小可以减少网络延迟，默认
=
 服务端监听哪个端口，默认，防止其他人陌生人扫描或者尝试登录可以改成其他值
=
 监听，默认全部，多网卡服务器可以指定一个
=
 游戏中视野距离，影响玩家在游戏中的可见距离，越大越占用服务器资源在中的配置会覆盖这里
=
 模式，防止盗版用户连接服务器
=
 地图种子，留空会随机生成一个，如果有好图可以指定
=  
 服务器，喜欢什么写什么

会有一套自己的配置文件，这里简要说明一下可以优化的项目，其他偏好设置一般默认即可：

默认值                 
实体追踪距离，可以认为是实体可见范围，对服务器性能影响不是特别大，如果有配置较低的客户端可以适当减小数值。

默认值：         
实体活跃范围，将会根据这个设置来确定实体是否被计算。一般指掉落物品，可以适当改小获得性能提升，另外如果过于小会导致难度大幅降低，在人数少的服务器上可以把和设置为和，保证难度。
：
默认值       
控制漏斗速度，如果有熊孩子制造了大量的漏斗传送，那么身为腐竹可以考虑修改这个参数。确定漏斗在传送物品的间隔；确定一次性传送多少个物品；参数可以认为是空漏斗扫描上层空间的间隔，如果设为，那么这个参数将会失效。例如，如果想将漏斗设置为一次传送个物品但是总效率不变的话，可以把设置为，设置为。

默认值：
随机光照更新，服务器会随机选取一些修正光照，之后也控制是否在初始重新计算光照，设置为可以大幅提升性能。

默认值：
实体碰撞阈值，设置更小的值可以减少过于密集的实体群造成服务器卡顿的现象，可以设置为。

默认值：
在中的配置会覆盖掉中的配置，服务器会根据这个值来加载区块，加载区块的数量和视距是二次方增长关系，因此可以设置为或者，人数很多的情况下可以设置为或者。如果视距过于小的话会导致在游戏中地图边缘消失、显示不正常的问题。

默认值：
每个封包传送多少个，我之前抓包测试，感觉在通信过程很多包都是报头占用了大小，适当提高数值可以减小网络压力，在按照流量计算的情况下会略微减缓流量消耗，可以设置为，如果设置过大可能会导致客户端崩溃。

单人在线时服务器的负载情况：
在的环境下，同时人同时在线没有熊孩子行为的正常游戏，利用率峰值一般会在左右这个锅不背，除掉一些系统基本服务和的服务插件占用，基本游戏性能完全满足。当然很多插件的配置也会多少影响到服务器的性能，但是只要插件不涉及密集实体群，高频电路等，主要的性能影响还是在基本配置之中。这样一个环境完美地解决了个人电脑运行服务器电费高、运营商对个人用户提供的上传带宽不足以及服务器管理复杂等诸多问题。
服务器地图备份
游戏服务器运行在上数据安全性当然很高，但是也避免不了有时手滑保不住数据，一旦地图数据没了，花了很多天辛辛苦苦盖好的大房子还要重来实在是一件很坑爹的事。毕竟从快照恢复也不见得能够适合所有场景，那么我们自己简单的做一个腐竹自用备份好了，当然这个备份和服务器运行环境处于同一块虚拟盘上面，有条件的话可以将备份文件保存在另外一块虚拟数据盘上面：


  目录
=
 设置需要备份的，如果有多个按需添加
=
=_
=__

 备份文件存放路径
_=
    _ 

   _
    _ 

      _
   


=` `

 按照日期打包地图文件
  _   

 删除天以前的旧备份
 _     {} \
完成之后可以把脚本添加到用户根据需要定期运行。因为服务器开的时间越久，熊孩子们扩展的地图面积越大，地图文件需要的存储空间也越大，所以一般每天执行一次也可以，必要的时候也可以手动执行一次备份。小白欢迎各路大神批评指正
流量监控统计
本人咸鱼，购买的是按照使用流量付费的我才不会说是因为上线人少时间不长所以固定带宽不划算，即使在云控制台可以监控网络流量，但是统计并不是很直观，所以需要直接统计服务所消耗的流量，原理是利用 的统计。
因为懒，没开什么别的服务，就没有配置任何防火墙规则：
 
  
  
  
现在开始配置流量统计：
        
        
指定这两条规则并没有添加任何参数，就是什么都不做，只是统计。
查看一下现在的统计情况：
  
       
                                           
                                                                     

       
                                           

       
                                           
                                                                     
可以看到现在都是，因为没有产生任何流量。
现在做个简单的测试，打开客户端连接到服务器，再来看一下：
  
       
                                           
                                                             

       
                                           

       
                                           
                                                            
可以明显的看到和增加了一些。
那么，为了方便直观，我们再来写个简单脚本统计流量：


=` `
     |  { } |\
 ` `    ` `

      
   
   

这里根据个人需求，我只是统计了出网流量，加了 参数，只统计链第一条规则       的流量，根据实际情况修改为相应的值。
收集到的流量记录大致如下：
  
  
  
  
  
  
  
  
  
  
  
因为根据个人需求，我这里是通过每小时分执行一次统计，并且在点的时候通过 清空流量统计，每天点按日期生成一个新的统计文件。这样就可以监控大致每天不同时段的流量情况，如果服务器上有其他公网玩家的腐竹使用流量计费的也可以通过这个方式了解到流量使用情况。
写在最后
是一部非常不错的创造性游戏，当然最有趣还是要和好友一起，无论在游戏世界还是服务器环境，大家分工合作共创美好生活什么的……毕竟个人能力有限，在配置环境以及脚本执行过程中难免疏漏，欢迎各位老司机批评指正。最后来一张合影吧
 生命不息，折腾不止 为了您和好友的方便，请综合选择离大家最近的节点土豪们请忽略 支持正版游戏，抵制不良软件

相关推荐
【腾讯云的种玩法】如何使用腾讯云构建自己的云桌面办公平台
免费体验腾讯云服务器，快速上云
【腾讯云的种玩法】个人网站如何开启？导语
本文将全面详细介绍如何搭建如图所示的集群。

图
环境
台装有 的主机，每台主机有个磁盘虚拟机磁盘要大于，具体虚拟机搭建可以查看虚拟机搭建  目前已经有了个的盘，再在每个节点添加一个的盘，假装是一个用作的，和一个的盘，假装是一个用作的。另外再添加台装有 的主机，用作 和本地源，详细信息如下：

集群配置如下：



主机

功能






、、




、 




 、




 、 本地源



环境清理
如果之前部署失败了，不必删除客户端，或者重新搭建虚拟机，只需要在每个节点上执行如下指令即可将环境清理至刚安装完客户端时的状态！强烈建议在旧集群上搭建之前清理干净环境，否则会发生各种异常情况。

本地源的搭建
这一节有以下个目的：

对于不能访问外网的集群，必须在内网搭建好源。
对于使用非最新小版本的，搭好本地源方便后续增加节点。
做实验的话，有了本地源，搭环境速度会快很多。

写本文时，的最新版本为，现在在节点搭建一个的本地源。
在节点安装和    
创建源目录，并下载所有文件，方法其实很简单，选择并下载你需要安装的版本，这里选择的是_，然后把所有的包含的包都下下来，除了那个，多太大了，可以不下。最后再加上的链接，这里你只需要复制粘贴就好了：
 
 
 __
 __
 __
 __
 __
 __
 __
 __
 __
 __
 __
 __
 __
 __
 __
 ___
 ___
 __
 __
 __
 __
 __
 __
 __
 __
 __
 __
 __
 __
 __
 __
 __
 
创建源并添加：

记得开启服务  
这样就在节点上搭建好了源，其他的节点只需要把拷贝过去就可以安装了了。暂时没找到别的简单的方法，我制作本地源的最初目的就是为了虚拟机里面安装能快一点。
源及的安装
需要在每个节点上执行以下指令

增加的源
   
安装客户端和：
 
     
关闭
 == 
 
   
  
配置
这里我把放在了节点上，其余三个节点都是 ，目的就是从根本上解决时间同步问题。暂时没有的
在节点上：修改注释掉默认的四个，添加三行配置如下：
修改文件如下：
        
 

重启服务，并查看端是否运行正常，正常的标准就是 指令的最下面一行是
   
    
     
   
                                
==============================================================================
                                       
至此， 端已经配置完毕，下面开始配置端。
在三个节点上修改，注释掉四行，添加一行指向

重启服务并观察是否正确连接到端，同样正确连接的标准是 的最下面一行以号开头
   
    
    
   
                                
==============================================================================
                                         
这个过程不会持续太久，实际生产最久内也会达到状态，下图给了一个未能正确连接的输出

可以观察到前面是没有的，一定要确定所有和端的都正确连接才能继续搭建   
参数配置方法
之所以写这一节，是因为网上查到的一些形如   _的方法重启之后是不会生效的，所以这里提供了一种重启之后仍然生效的方法，注意只是方法，并不代表实际生产值要配置成这里的值。当然在里面搭建不需要配置这些。

所有参数的配置方法，比如上面的_，这一类的参数配置方法都类似，就是把值写入到文件中即可： _ 参数配置方法如下
 _ =   
   参数配置方法如下
  =   

 即   文件句柄最大数，默认是，这里我们需要把这个值放大到        
        


修改磁盘的 ，这里我添加了一个内容如下=={}==  ==|=={}={__}=


解释下这里各个参数的意义， 这个值可以从指令获取，一般和的都是不一样的，上述指令对从的是 的磁盘设置了为以及__为。对于不同的磁盘，可以在内添加多条规则。
终于，终于，终于，把环境准备好了，这时候，我比较建议重启下主机。然后，简要介绍下这次搭建的的架构：

  用作个 的，以及 的。
  用作，三台机器共个构成
  用作，三台机器共个构成

磁盘分区
我们将的盘分出个的分区用作：

更新分区表，并查看分区是否正确：

将三台主机的盘都分好区，就可以开始部署了。如果报下面的错误，可以尝试重启主机，保证指令没有输出
  
          设备或资源忙                            
      设备或资源忙
部署
在部署节点安装，下文的部署节点统一指

在部署节点创建部署目录并开始部署：

从部署节点到各个其他节点。

如果之前没有到各个节点，则需要输入一下密码，过程如下：

此时，目录内容如下：

在文件中，添加几个配置项未添加_：

开始部署

查看集群状态：

开始部署， 盘对应关系如下



盘
盘
备注






 




 













我的一个小习惯，先部署，再部署，这样序号就会连续了。。。
  后面的参数格式为。
        
 后面的参数格式为需要注意的是，刚刚的这里需要写成，因为分了区。
现在，激活创建的：
这里会遇到一个，因为版本的要求需要是权限报错如下
                      
执行如下指令即可解决这个错误，当然这个步骤最好是放在磁盘分区一节：
 
不要忘了所有的盘都需要修改权限。
         
我在部署的时候出了个小问题，有一个没成功待所有部署完毕后，再重新部署问题即可解决，如果不出意外的话，集群状态应该如下：

不用等了，这里的 会一直卡着的，查看  就会理解____ = 的作用了。不像快速部署文章中会达到状态了，会在后续的章节中继续完善来解决这个问题。
同样的方法部署三个，指令如下：

执行完后，查看 ，应该可以看到个是的。
自定义
最后的工作就是把刚刚建的个组成下图所示的架构，这里的，等都是我们虚构出来的，和主机名没有任何关系，但是必须和刚刚部署的顺序一一对应！

首先创建对应的，指令规范为：

所以对应指令为：

再将对应的移到下，然后把移到对应的下面，注意添加时的是该的实际大小为 ，为，切勿随意填写！！！指令如下：

一不小心加错了怎么办？
查看当前的  ，是不是觉得棒棒哒！

最后有个孤零零的 ，丢那别管咯，留个纪念。
最后，修改即可：我习惯导出进行操作，十分方便不需要记什么指令。导出，并增加一条
   
    
  的意思是，导出的是二进制格式的。
 
翻到最下面，有个

复制粘贴再加个，并修改成下面的样子：

保存退出，编译刚刚的，并注入集群中：

查看 ：
  
     
      _
                   
         {===}
                
            
            
               
                   
                  
去除，增大的数即可：
    _ 
     _ 
这时候，稍等一下就会看到_的状态了，但是还没有体现出这种架构的优点，先查看下池的情况：
     
      _  _  _ _  _  _    _ 
这里主要关注_  ，池使用的是刚刚建的所以池的所有数据都是保存在上的：
    
         
关于的一些概念，可以参照大话那点事儿这篇文章。此时，将池是设置为，即由组成的结构，池的所有数据将会保存在这三个上：
      _ 
   _  
     
         
实际用法比如：
       
  
        
  

   

                        
                              

                                  
                                                   
                                             
                                              
      
      _  _  _ _  _  _    _ 
      _  _  _ _  _  _    _ 
      _  _  _ _  _  _    _ 
这一节的作用就是将同一台主机上的和分开使用，在一批次同样结构的主机上，构建出两种不同速度的，实际上，的自定义性，给提供了极大的可塑性。
总结的话
这篇文章除了没有涉及到具体的参数以及优化的参数外，基本上可以搭建一个适用于生产环境的集群，也算了了一桩心事，因为快速部署那篇还是写的很毛糙的，这篇花了不少心思把整个流程整理了下。  一、在此之前
在之前的文章中，我想大家已经对有了一个大体的了解，不过为了凑字数，我在这篇文章的开头再稍微回顾一下，如果我们需要使用来绘制图像需要走完以下这五步：
、从元素中获取 
、利用 语言，编写顶点着色器和片元着色器，并成对应的着色器程序
、准备好你想要绘制的图像的顶点数据，并写入缓冲区
、把着色器中的变量与载有顶点数据的缓冲区对应起来
、最后执行着色器程序，并在上绘制出图形

当然，并不是说所有的程序都必须按这样的逻辑进行，这里只是让大家对有一个基本的概念，而那些项目中使用到的真正的程序要比这复杂得多。
为了使得我们能集中精力去编写那些酷炫的程序，我把上面这些基本的步骤封装在几个工具类中，大家只要在页面里引入附件中的即可。在文件中，第一个提供给大家使用的是类，用于创建和管理着色器程序，具体使用如下：
 =__ = 

      =  

     载入顶点着色器
    __ _
     载入片元着色器
    __ _
    
    


第二个提供给大家使用的是类，用于创建和管理数据缓冲区，具体使用如下：
 =__ = 

     创建顶点数据缓冲区
      =   _

     向缓存区写入数据
     _
     是缓冲区中的数据和着色器中的_变量对应起来
    _  


除此以外，由于三维图形绘制还会涉及到大量的矩阵或向量运算，我们需要一些数学工具辅助我们的开发，这里给大家介绍一个库——。同样，大家只要在页面里引入附件中的即可。这里给大家演示一下的基本用法，详细的可以参考官网上的文档：
 =__ = 

     创建矩阵
      = 

     对矩阵进行转置
     
     对矩阵进行求反
     

     创建向量
      = 

     对向量进行规范化
     


有了这些工具，我们就可以开始讲解今天的主题了，使用绘制三维图形。
二、从到
在之前的例子中，我只是给大家演示了如何绘制一个二维的矩形，但真正强大的地方，在于它为我们提供了三维图像的绘制能力。当然这主要的得益于的计算速度，要知道，绘制三维图形，我们需要进行大量的逐顶点甚至是逐片元的矩阵运算，而且这些运算都必须在内完成，才能保证画面的流畅。如果是直接使用  绘制三维图像，所有这些运算，只能在中完成。而通过，这些耗时的运算就可以直接交给，通过中一些专用的硬件，使得运算的过程得到优化管线，并行。
说了那么多，那到底我们怎样才能绘制出一个三维图形呢？要绘制出三维图像，我们首先要知道三维图像和二维图像有那些区别。

从上面这幅图，我们可以比较直观的看到一个正方形到立方体的演变过程，主要经历了以下四步：
、给图像加入深度信息，也就是让这个正方形有了厚度，从一个“面”成为一个“体”
、换一个角度去观察我们的场景度俯瞰，这使得深度信息在视觉上得到了体现
、光有深度信息还不够，我们观察三维图像一般是带透视的，这样图像更有立体感
、最后我们需要在场景中加入灯光，灯光下的立方体更加真实
这样我们就有了一个大致的方向，为了绘制三维图形，我们需要一下四部分信息：
 =__ = 

     获取立方体的顶点数据，包含深度信息即轴坐标
      = 

     获取视图变换矩阵，用来模拟摄像机在不同角度的拍摄
      = 

     获取透视变换矩阵，用来模拟现实中近大远小的透视效果
      = 

     获取灯光数据，这里得到的是一个点光源，类似白炽灯
      = 


接下来，我就带着大家一步一步来完成各个方法的功能开发，首先是方法：
 =__ = 

      {
          = 
             = 
             = 

          =   
             =   
             =   

         顶点数据，三个坐标  组成一个顶点
         每个面有个点，总共是，个顶点坐标
          =  
                                  
                              
                            
                              
                              
                           
        

         法线方向，三个坐标  组成一条法线
         例如    代表指向轴正方向，长度为的法线
          =  
                                       
                                  
                                
                                  
                                  
                               
        

         顶点下标，中只能绘制三角形
         因此绘制一个面矩形，需要两个三角形
         
         ┌──────────┐
          |          |
          │          │
         └──────────┘
         
         其中    三个顶点构成第一个三角形
         而    三个顶点构成了第二个三角形
          =  
                         
                         
                      
                   
                   
                    
        

         {         }
    }


从方法中，我们获得了与立方体相关的顶点数据，其中包括了顶点坐标，顶点法线方向，还有顶点下标。其中大家可以注意到，顶点的坐标是包含了轴坐标，也就是包含了深度信息。有了这些信息，我们就可以进行下一步了，但在继续讲解前，我需要给大家普及一些基本的计算机图形学姿势——矩阵变换。
 以下内容涉及三角函数和线性代数，敬请家长注意
、旋转变换

从上图，已知坐标 ，求出绕 点旋转弧度后的坐标 

我们可以使用矩阵来表示：

、拉伸变换
已知坐标 ，求出绕 点向拉伸倍，向方向拉伸倍后的坐标 

同样，我们可以使用矩阵来表示：

、平移变换
已知坐标 ，求出向方向平移，向方向平移后的坐标 

似乎我们没有办法把它转换成矩阵表示？ ，只要我们引入齐次坐标即可：

通过以上的演示，我们得到了这样一个结论，所有的几何变换都可以转换成这种向量左乘矩阵的形式表示，而且多种变换作用于同一坐标点，只需依次与对应的矩阵左乘即可。
有了以上这些数学姿势，我们就可以继续我们的编码了。
我们先看方法，用于获取视图变换矩阵。绘图都是眼睛摄像机在轴上，向轴负方向即屏幕方向看去产生的视图：

我们并不能改变这个视线的方向。因此，为了能从别的角度来观察场景，我们只能对场景本身进行操作，例如我们要把眼睛从  点移动到  点，实质上可以通过，把整个场景向轴负方向移动来到达相同的效果。也就是说，我们可以通过对场景进行反向的几何变换来模拟眼睛的移动。但如果每一步都需要我们手动的进行反向操作，也未免太麻烦了，为此中提供了这样一个方法来辅助我们进行计算：
 =__ = 

      {
          = 

         眼睛的位置
          =   
         眼睛所看目标位置
          =   
         眼睛向上的方向
          =   

           

         
    }


利用方法，我们可以快速的得到眼睛从  点，望向  点的所需要的反向几何变换矩阵，我们把所得到的矩阵称为视图变换矩阵。
接下来我们看看方法，用于获取透视变换矩阵。绘图的空间，实际为一个的单位立方体，而我们眼睛所看到的真实的视觉空间，则是一个四方台：


我们要在中模拟这种透视，实际就是把这个四方台变换到的单位立方体上，只要是变换，我们都可以使用矩阵来表示，当然这其中的数学推导我就不说了，给我们提供了方法，来帮助我们计算出这个透视变换矩阵：
 =__ = 

      {
          = 

         视场角度，宽高比为，最近的平面为等于，最远的平面为等于
            

         
    }


最后，调用，来得到灯光信息。这里我们模拟的是一个点光源，与点光源相关的信息，只有两个，第一个是光源的颜色，另一个是光源的位置：
 =__ = 

      {
         点光源的颜色，白色，带点灰
          =   
         点光源的位置，坐标  
          =   

         {     }
    }


 三、世界
来到这里我们终于集齐颗龙珠，可以召唤出神龙了！！！！！

好吧，其实还不可以，我们只是拥有了用于绘制的数据，但怎么绘制我们还不知道神龙：怪我咯
我们之前说过，要教会绘图，我们需要着色器。着色器其实是提供给我们的可编程接口，用于对的管线进行编程，使得能完成我们所需的渲染需求。着色器程序写得好，你就等于成为了上帝，上帝说要有水，给你，上帝说要有风，拿去
我们不需要弄这么复杂，只要有钱，不，只要一个立方体就可以了：
顶点着色器
 =__

      _
      _
      _
      _
      _
      _
      _

      {
          =  _  _
          = _  _

        _ = 
        _ = 

        _ = _  
    }


片元着色器
 =__

      
      _
      _
      _
      _
      _

      {
          = _  _
          = _

          = _  _    

        _ =  
    }


 鉴于篇幅的关系，这次我就先不解析这两个着色器的意思，有兴趣的同学可以我。
有了着色器，我们就利用提供给我们的方法，生成着色器程序，把数据写于缓冲区，最终绘制我们想要的立方体：
 =__

     创建着色器程序
      =  

     绑定顶点着色器
    __ _
     绑定片元着色器
    __ _
    
    

     创建顶点坐标缓存区
      =   _
     写入顶点坐标数据
     _
    _  

     创建顶点法线缓冲区
      =   _
     写入顶点法线数据
     _
    _  

     创建顶点下标缓存区
      =   __
     写入顶点下标数据
     _
    

     写入透视变换矩阵
    _  
     写入视图变换矩阵
    _  
     写入法线变换矩阵
    _  
     写入立方体颜色
    _   
     写入灯光颜色
    _ 
     写入灯光位置
    _ 

     清除 和 中的数据
    __ | __
     绘制
      _ 


 大功告成！！！！

以上！作者：芦艺 

的日均视频播放量已经突破了亿，其中端的播放量在总播放量中的占比超过，相比年初，播放量的增长了超过倍。视频下载是整个视频播放的基础，如果下载侧出问题，则会造成整个视频播放的失败，这就对我们的视频下载提出了非常高的要求。
基于此，我们将视频下载总结为多快好省四个方面，以下载成功率、首次缓冲时长和缓冲概率为主要的技术指标对视频下载进行优化。具体参数的优化结果见下表，经过长时间的打磨，我们的视频下载模块的下载成功率已经达到了，视频的首次缓冲时长秒，二次缓冲概率低于，取得了良好的效果。下面我将从多快好省这四个方面，对我们主要的优化工作进行论述。
表 下载相关技术指标优化前后对比



技术指标
下载成功率
首次缓冲时长
缓冲概率




优化前





优化后


％



 多
在亿这个量级下，除了保证下载的成功率和下载速度这些主要参数之外，对于整个下载流程的监控、处理异常情况显得格外重要。为了提升视频的下载成功率、稳定性，监控整个下载流程，提升用户体验，我们采用本地代理的方式进行视频下载。
在手机上播放在线视频，最简单的方式就是实例化一个 将视频的通过设置给播放器，之后调用和遍可以开始播放视频。这种方式非常简单，但其中最大的问题就是整个过程中的数据流完全由控制，我们无法控制下载和播放的过程，也就导致我们没有办法提高成功率，优化用户体验。因此，侧的视频下载一般采用本地代理的方案实现。本地代理的方案即是指在播放视频的时候，将视频的转换为本地开头，在播放器通过本地请求视频数据时，本地代理截获这次请求，在经过本地的处理逻辑后，向服务器或者本地缓存请求数据。本地代理在获得视频数据之后，将数据转发给播放器，具体的流程如下图所示：

图：本地代理数据流
相比起直接由播放器请求数据，本地代理的优势是数据流由本地代理控制，我们可以在本地代理中加入缓存、预加载、防盗链等业务逻辑，这可以极大的提升视频下载的成功率，减少视频的缓冲时间，从而提升用户体验。
传统的本地代理方案确实解决了播放器直连带来的问题，但同样也会产生一些问题，视频下载和播放的业务逻辑复杂，过多的逻辑和下载本身耦合，给开发的过程带来极大的不便，并且这样也不容易接入第三方的下载器和对下载过程进行监控。因此，在经历了两个版本的迭代之后，我们将整个下载过程进行重构。这次重构使得下载各模块的职责明确，便于开发、维护以及接入第三方的下载，也为我们后续的优化打下基础，重构之后的方案会在之后单独成文介绍。
 快
国外的研究表明，的用户在秒没有加载完网页时就会放弃。在视频播放上，加快视频的加载速度，减少播放过程中的卡顿，对提高用户观看视频的体验有极大的帮助。经过我们长期的优化，现在视频播放的接近秒开，缓冲概率下降到不到，这极大的提升了用户体验，也从侧面提升了我们的视频播放量。
在这数据提升的背后，我们主要做了几个方面的工作：
：防盗链预拉取
盗链播放在国内非常普遍，而盗链会使平台资源流失，增加带宽成本，不利于平台的长期发展，国内大部分视频服务提供商都在一定程度上做了防盗链。防盗链的主要过程是后台下发的视频，在正式播放之前，需要通过中的部分参数，加上一些本地参数，向后台拉取真正播放的 这些真正播放的都带有时效性，这种方式可以从一定程度上避免盗链行为。但通过防盗链接口拉取真实的播放需要时间，这也在一定程度上延长了用户感知的视频加载时间。针对这种情况，我们对防盗链的模块进行了改造，引入预拉取机制，将防盗链的拉取与播放解耦，对用户的播放行为进行预判，在用户播放视频的过程中提前拉取并缓存之后视频的 从而减少了因为拉取防盗链造成的视频缓冲时间。

图 防盗链预拉取
：数据预加载：
从的源码可以发现 需要下载秒的数据才会开始播放视频，按照现在的外网平局下载速度计算，该过程的耗时在接近秒，因此对于数据进行预加载是减少视频首次缓冲非常重要的方法。但视频数据的预加载不能跟当前播放的视频抢下载带宽，因此我们选择以当前播放视频的播放进度和数据缓存量为维度，当两者同时达到一个阀值时开始下载下一个视频的数据。在实践的过程中，我们还发现，因为一些编码格式的原因，在播放视频之前可能会请求一部分尾部数据，因此，视频预加载还会加载一部分尾部数据，最大限度的保证预加载的效果。
：缓存改造
加载本地视频的效率远高于在线下载，因此，缓存的命中率会直接影响到视频缓冲的速度。最初的缓存方案是针对单个视频按照顺序缓存，这样实现简单，但存在的问题就是无法对于播放空洞非顺序播放场景，例如拖动、续播等进行缓存，这降低了视频的缓存率和缓存命中率，增加了带宽成本和视频的缓冲时长。之后我们针对缓存模块进行了改造，将顺序缓存改为分片缓存，即将单个视频的缓存按照一定大小进行分片，在遇到数据空洞或者缓存数据量达我们设置的单片缓存上限时，开启下一个分片缓存，确保可以缓存所有的下载数据。这样改造之后极大的提升了缓存命中率，降低了首次缓冲时间和二次缓冲的概率。

图 缓存改造
：性能优化
梳理下载和播放过程中整体的流程，通过工具排查流程中长耗时的点和优化过程中的逻辑，减少不必要的耗时和操作，并将部分耗时逻辑移入子线程；优化时序，将例如图片加载、缓存等重逻辑执行的时机后移，以及对视频播放关联度不高的逻辑使用懒加载。这样可以降低对于视频播放，特别是视频缓冲过程中，和的占用，使得系统能够调度更多的资源在解封装、解码、渲染等与播放、下载直接相关的操作上，进而减少这部分的耗时。
 好
下载的成功率是保证视频观看体验的基础，目前的视频下载成功率已经提升至，跟主要命令字的成功率相当。国内的移动网络环境错综复杂，不仅要处理断网、慢速、抖动等网络本身的题，还要处理跨网、运营商劫持等国情问题。下载成功率的提升过程非常艰难，我们在其中主要做了以下的工作：
： 直出与竞速
通过直出减少了劫持的可能性；对于下层代理的视频下载下发多组，通过竞速计算本地最佳，使用最佳进行直出下载；上层代理对于下层代理的整个下载过程进行监控，在监测到下载速度缓慢或者异常情况时连接失败、数据读取超时等立即切换下载，减少用户的视频加载时间。通过直出、竞速和切换，提高了下载的连接、数据读取成功率，减少了因劫持导致下载失败的概率，同时提高了下载速度。
：对于链接失效进行处理
上文章节中提到视频播放的链接均是经过防盗链处理，带有播放效期的链接，这就使得，在实际播放的场景中，很可能出现用户希望播放某视频时，跟随后台下发的视频链接已经过期失效的情况，如果不进行处理，则会极大降低下载的成功率。针对这种情况，我们根据视频的不同来源，对于每种情况进行异化处理，通过向后台重新拉取链接或者本地计算，解决了因连接中的失效导致视频无法播放的问题。
：下载命令字拉取接入私有通道
很早就开始采用维纳斯   私有通道方案进行网络数据传输，相比使用最多的方案，通过长连接、直出、接入点优化、数据压缩等方法，提高了网络连接的成功率和稳定性。为了提高主要命令字的拉取成功率，我们对原有用拉取命令字的方式进行改造，使用通道包裹原来的数据包，在后台通过通道收到原有的请求后再将请求分发至对应的后台，具体的流程如下图所示。这样通过低成本的改造不需要修改原有协议，后台直接透传基本没有开发工作量，借由提升了整个通道的传输质量，进而也提高了视频的下载成功率。

图：下载命令字拉取接入私有通道
：下载速率动态调节
在移动网络下，发生网络抖动和网络切换经常发生，但网络不稳定，对下载来说是非常致命的。为了应对网络抖动和网络切换，下层代理会监听当前的网络变化，监控当前的下载速度。下层代理在下载数据时，为了减少对于别的业务影响，不会占用全部的带宽，但当发生频繁的网络切换时，下载代理会主动突破速度的限制，尽可能快的在网络情况良好时下载数据，给之后的播放留下足够的数据，保证整体播放的流畅性。
 省
互联网的视频服务提供商在国内盈利极其困难，除了近几年视频市场竞争越来越激烈，版权费居高不下之外，国内高昂的带宽成本也是重要原因。因此，如何在保证视频质量的前提下，尽可能减少下载流量，减少下载而产生的带宽成本，对于我们来说也是非常重要的工作。在这部分，我们主要的工作如下：
 流量控制
为了保证用户观看的流畅性，减少视频缓冲，视频数据下载的可播放量与当前观看的时间点之前会保持一定的，在整个播放过程中，通过动态调节下载速度，这个的大小基本保持不变，并且的大小可以动态调节。在流量高峰的时间段，我们会通过后台进行流量控制，减少，也就减少了高峰时段整体的下载量。带宽的计费标准一般按照高峰流量计费，减少了高峰时段的流量，也就降低了带宽成本。具体流控如下图，高峰时段视频缓冲秒，非高峰时段缓冲秒，，两个参数均可由后台控制。

图：流量控制
 编码
是新一代视频编码标准，相比原有使用编码的视频，具有更高的压缩比，在画质近似的前提下，编码的视频文件体积只有的一半甚至更少，因此，播放编码的视频能极大减少带宽消耗。但现阶段主要存在的问题是终端编码耗时过长，后台编码过于消耗资源，以及在手机上，软解码支持硬解码的机型较少，并且硬解码的兼容性问题相比软解更多带来的耗电、发热以及兼容性问题。目前，通过自解码播放器，在经过大量的兼容性测试之后，已经在超过款主流手机上实现了视频的软解播放。空间视频和编码的下载带宽对比以及之后的预期情况如下图所示，可以明显看出，通过编码极大的降低了我们的视频下载带宽成本。

图：空间视频和编码下载带宽比较
另外在中论述对于视频缓存的分片改造，同时提升了下载数据缓存的使用率和命中率，也了减少了我们的视频下载带宽。
 总结
经过长时间的优化，视频业务，包括下载成功率、播放成功率、缓冲概率、首次缓冲时长等在内的主要技术指标，均得到了大幅度的提升，达到了我们的预期，也为视频点播和直播业务的持续发力铺平了道路。但技术优化是一个长期的过程，目前的视频播放已经开始启用自解码播放器，逐步替换原生的，之后我们还会通过播放器多实例，编解码，参数调节等方式进一步提升视频下载成功率，压缩视频缓冲时间，减少缓冲概率。也欢迎各位多使用体验我们在各个场景中的视频播放，如果对体验或者技术优化的建议和意见，欢迎交流。
 视频点播技术优化小分队：   
同时感谢腾讯视频的长期支持。作者：杨升军

腾讯云助手：微信查询服务器性能、重启机器、给快到期机器续费
一关注腾讯云微信公众号：腾讯云助手
腾讯云助手二维码
二使用腾讯云助手
账号
绑定账号：使用腾讯云上登记的账号绑定消息设置：全选，接收微信告警
管理
健康度机器列表：里边查看机器性能，重启系统
服务
续费管理：给快到期的机器续费，机器快到期会有提醒

相关推荐
腾云阁「腾讯云的种玩法」征文活动测试前
最近在做一场流量性能测试，期望得到的结果，既不是应用关键场景需要使用的流量总量，也不是应用跑起来后的平均带宽值。而是一个叫带宽峰值的玩意儿，它代表一段时间内，这个应用内最高会收发多少数据。有什么特别的呢？
流量测试一般的测试方法：定义关键场景，关键场景前流量值– 场景后流量值= 流量总量。流量总量时长 = 平均带宽。
测试手段：

流量卡。主要是记录流量起始点流量卡的流量值，和结束点流量卡的流量值。

工具或工具。都是每秒都在采样带宽值。

。需要被测应用是包。


在接到需求后，认真分析了上面的测试方法和测试手段，发现只有或基本能够满足，因为带宽峰值的含义就是一段时间内，带宽值曲线上的最高点。
开始撞墙
一开始我是很信赖的，毕竟是我大腾讯同事出品。直到测试开始，它给了我类似以下两组数据一是负数，二是带宽一点点增加。

输出的带宽测试报告
现有的工具无法满足需求，只能自己动手，丰衣足食了。首先理清楚我们可以从哪些地方拿到实时的流量数据：

从系统文件_中，可以很方便的拿出每个的流量数据，如下图，从开始，第列是，第五列是接收数据的数，第七列是发送数据的数。


文件中的流量数据

这个类中提供了一大堆方法用于获取流量数据的方法。其中主要包括：

      和 
     和
       和 
第一次撞墙
需要准确获取一个应用的实时带宽，从字面意义上看，似乎选择以上第点中的方法，或者第点中的更加合适，一个文件读取，一个系统接口获取，都是直接取出了对应的流量数据。于是根据，我迅速的码出了如下代码：
   = 
   = 
     {
      = _
      = 
        {
 =  
             =  
              = 
              = 
               =  = {
                
                 ==   
                  = \\
                   == {
                     =   
                }
            }
        }  {
            _
        } {
 {
  =  {

                }
  =  {

                }
            }  {
                _
            }
        }
 
}
然后悲催的发现，虽然通过命令：
   _
能够看到一行行漂亮的数据，在应用程序中却始终都只能读取到行。这个地方暂时没找到为什么，大概怀疑点是权限的问题。
当然我们可以写个运行在端的脚本程序，然后连接着被测手机，出该文件然后再分析，然而带宽峰值的测试，依赖于大样本量，连着跑，这个就局限了，只能我一个人测试，想找其他人帮忙太麻烦。
第二次撞墙
第一种方法不行，马上换。中的 和 这两个接口是否可行呢？看了的源码，关于流量的测试，它还真是用这两个接口实现的。
     {
    _   
      = 
      = 
             
          
     = 
     = 
      ==  ||  ==  {
 
    } 
           
}
好代码，然后冒出一个问号，为什么要特意标记一个呢？瞄一眼源码，从注释和代码中可以看出，以下这个接口是没有的；及以上，这个接口只能用来拿应用本身的数据；要拿其他人的？详情请看。

             
          
           
          
  
   { ___}  
   { }      
  
    { _}   
           
  { }         
         
  { }
 
   
   
 
     {
          
               
       = 
      == _ ||  ==  {
  __
    }  {
 
    }
}
看来这是版本碎片化带来的坑，瞬间体会到了开发同学做兼容适配的痛苦。
最终方案
由于项目急需用了，最终决定不再纠结于用哪个。直接使用以下两种方法来做，只是在测试前先杀掉其他应用，如果有手机管家的话，开启管家的禁止联网功能，保证只有被测应用在联网：

和

 和 


具体代码实现：
第一个比较简单直接调用即可。第二个因为 是隐藏方法，所以需要通过反射拿到该方法进行。
 {
 {
          = 
         =  
         =  
        
        
    }    {
        
    }
}

    {
  = 
     {
         = 
    }  {
        
    }
 
}

    {
  = 
     {
         = 
    }  {
        
    }
 
}
计算逻辑：
    {

       {
          = 
        通知界面刷新
        

          = 
          = 
          =   上次发
          =   上次收
          = 
          = 
          = 
          {
            
            获取所有网卡的流量
              = 
              = 
            获取网卡上的流量
             = 
             = 
             = 
            
              ==  {
                 = 
                 = 
                 = 
                  首次只收集数据
            }
      {   }
             = 
              =   
              =   
            每次都刷新并保存该文件，能够保证即使不停止，也会有数据
            
              =    
              =  
            
                    
            

             = 
             = 
        }
通知界面刷新
        
    }
}
将代码输出为一个应用，实时收集流量数据，写到文件中。将这个测试发给大家。测试步骤：

将被测应用外其他应用关闭；

开启被测应用，进入关键场景；

打开测试，开始收集带宽数据；

关键场景结束时，打开测试，点击结束；

将结果 出来发给测试；

分析取带宽峰值平均值。


这个方法虽然没有直接获取被测的流量，但是简单快捷，各个版本上的兼容性高，能够快速收集到较多的样本。当然也可以再结合来做兼容适配。
参考文献


 文章来源于：腾讯移动品质中心 本文由刘裕忠和张文波两位作者联合创作。

导语
在这个飞速发展的时代，我们有幸的见证了互联网的萌芽到爆发，移动互联网的兴起到鼎盛，目睹了诺基亚雅虎的兴衰，也见证了腾讯阿里走到全球市值十强；随着谷歌的横空出世，又让我们快速的切换到一个新的时代，而在这个时代，图像识别技术作为其基础能力之一，也在快速发展中，今天来聊聊图像识别的服务运行框架。
一、图像识别的业务应用
在聊框架之前，先简单说一下背景知识，图像识别作为人工智能领域中最基础的能力之一，是每个互联网巨头及公司的兵家必争之地，小到广告图片过滤大到国家安全宇宙探索都有着非常广阔的应用场景，例如在广告图片过滤、纸质文档电子化、聊天网页图片鉴黄、银行证券自助开户、人脸门禁安防等业务中都有了比较普及的应用，在这些业务中图像识别技术扮演着非常重要的角色，用好了图像识别，一方面能大大提高工作效率，另一方面能提供更好的用户体验。例如在广告图片过滤的业务中，从人工处理到自动处理，在效率和准确率都有显著的提升。
二、图片识别的算法类型
不同的应用场景会有不同的识别类型，而不同的识别类型自然会有不同的算法，按我们现有的业务大概做了梳理，分为如下几类，当然这只是其中一部分，就不班门弄斧了，毕竟这个范围太广了。
文字识别技术

自然场景图像文字识别
文档图像文字识别技术
身份证识别
银行卡识别
名片识别

图像内容理解

人脸检测与分析
明星脸识别
物体检测
图像特征识别

其它分类…
在这些不同的算法中，又有不同的构成方式，如采用传统的文字识别，是单阶段处理的，即一个算法即可完成识别处理；而在采用深度学习算法后，识别的过程大部分拆分为两个阶段：文字检测，获取图像中文字的所在位置，文字识别，分析所在位置的文字内容，即多阶段算法；还有更多阶段的算法类型，如分为图像拆分、检测、识别、结果合并等阶段。
三、如何提供图像识别的服务？
图像识别从算法研究、模型训练到规模化的提供服务，卷入的资源及处理的流程都是非常多的，但在开发阶段主要分为如下两个阶段：

算法研究模型训练： 主要由算法研究人员进行算法研究及模型训练，这里涉及到研究及算法实现，对各种图片集的模型训练等，这个也是图像识别最核心也最关键的工作，在这个阶段的输出通常是用编写的算法及训练好的模型文件。

框架开发算法集成： 主要由后台开发人员进行服务框架的开发及算法的集成运行，即把算法研究人员研究好的算法及模型文件集成到服务框架中，提供稳定的图像识别服务。


我们都知道在运算密集型的程序中优势比较大，所以在算法的实现上大部分都采用了，而在服务框架的编写上，实现方式就比较多样化了，有用也有的或者其它语言实现的， 这方面我们综合对比了和的性能及稳定性，两者其实相差无几，而因为其生态的强大，在编写效率上有很大的优势，能快速开发完成，且有更好的移植性，所以在服务框架的实现上，我们采用了，通过调用来实现。简单调用流程如下：
  框架  算法
四、我们的解决方案
一个系统的成型并不是孤立存在的，如果要规模化的提供稳定服务，必须是完备的一个系统，这里简单描述一下我们的整体实现方案，系统架构上主要分为三层：接入层、系统层、算法层，再加上存储系统、告警监控系统、日志系统等构成一套完整的解决方案。


接入层： 主要做一些输入输出的适配，如协议适配、参数适配、结果适配等。
系统层： 图像识别服务运行的系统框架，加载运行算法，提供稳定的识别服务，即图像识别服务框架，本篇文章的重点，会在第五点进行比较大篇幅的介绍
算法层： 主要由算法人员研究实现 各种识别类型的算法及模型文件
存储系统： 图片及结果存储
监控告警： 监控服务的运行状态，在异常时进行告警
日志系统： 请求日志的存储，为问题的跟踪排查提供依据

五、轻量级图像识别服务框架
整体架构
在打造一个框架之前，先来理一下图像识别服务的核心需求：

高性能： 识别请求需要快速返回
高可靠： 持续稳定的提供服务，局部异常不影响整体服务
动态扩容： 在流量增大时，能动态扩容，来应对持续增长的业务请求
多算法支持： 兼容多种算法，无论是单阶段还是多阶段，都一一兼容

针对上述的要求，我们借鉴了业界及公司内的架构方案，打造了轻量级图像识别服务框架，架构图如下：


： 接收接入层的请求，进行请求拆分、请求调度、结果合并等
： 实际执行算法的进程载体，主要包含算法模型的加载、更新，进行算法的执行
： 典型的分布式一致性服务软件，这里主要用于存储心跳信息、算法映射关系、算法执行计划、算法静态动态快照信息等
： 监听心跳并实时更新动态快照，触发更新路由规则及动态连接池

框架运行态
为了更好的说明这个框架，需要对运行态进行解剥，这里先分解一下这个框架的配置信息，主要分为静态和动态两种，静态配置由运维进行配置，动态信息由运行时决定。


算法映射关系： 即什么业务的什么识别类型调用哪个识别算法的哪个版本，正常情况是识别类型就决定了某个算法，但为了更灵活的业务支撑模式，我们细化了实现，即不同的业务相同的识别也可以适配不同的算法版本；

算法执行计划： 这个算法有哪些执行步骤，比如上面说到的场景图像文字识别，包含个步骤：文字检测、文字识别，那么此处算法的执行计划就有个步骤；

静态快照： 通常在分布式框架中，是没有静态快照的，这个主要是因为框架支撑的算法及版本都比较多，太过灵活的话会导致运维对整个集群的管理不好把控，所以加入了静态快照这个配置，从而对整个集群做到心中有数。静态快照主要用于配置执行步骤所在的服务器及端口，即各个算法执行步骤的部署情况，如文字检测算法部署在的端口，文字识别算法部署在的端口；

动态快照： 是静态快照的运行时，即根据的存活状态更新后的快照信息，如果某个服务器的挂了，动态快照就要剔除掉这个服务地址，如果恢复之后则把这个服务地址重新添加到动态快照；

请求过程说明：          

解析参数，根据业务类型、识别类型获取识别算法
获取识别类型的步骤进行算法调用，会根据执行计划的步骤调用的算法
在调用完最后一个步骤后进行结果汇总并返回



算法与框架的解耦
一个好的算法运行框架，应该尽可能减少对算法的干扰，而自身又要也少受算法的影响，这样就能为算法研究和系统开发提供一种高效的合作方式，为此我们对算法和框架做了解耦，框架的部署不依赖于算法，算法的开发也不依赖于框架，只需要把算法在生成时做一层简单的适配即可。如下是框架与算法的关系：

框架部署好之后，会启动的扫描线程，只需把算法及模型文件放入到指定目录，框架就会进行加载完成的上线。
多版本算法的兼容
业务形态的各式各样，也决定了框架应该有更灵活的支撑模式，如不同的业务对同一识别类型有不同的侧重点，那么算法的版本也会有差别，框架对此做了一些调整，如下图所示，各个业务的银行卡算法是采用了不同的版本。

容灾及集群热更新
一个好的系统，应该是稳定可靠的，容灾是必须的，在这方面，我们借助了这个典型的分布式一致性软件，实现了快速恢复的容错机制：


： 在启动的时候与建立临时节点维持心跳信息
： 监听在的心跳信息，如果断连或重连，立刻感知到并修改动态快照
： 监听上的动态快照信息，动态快照一发生变更立刻修改路由规则及路由连接池

通过这几个角色的配合，在节点出现异常的情况下，在迅速就完成了切换，保证了系统的稳定。这种机制也支持了集群的热更新，在需要对某个进行更新时，先对进行下线，感知后不向此发请求，完成更新启动后，再跟其重新建立连接并发送请求。
全链路追踪
虽然说框架具备了高可靠，但是很多情况下还是无法避免算法内部的 ，在这种情况下，恢复服务是第一的，这里我们做了进程的监听，如果发现进程 会立刻拉起；但在恢复服务之后，问题的复现及分析又是一个难点，在这里，我们做了一个全链路的跟踪，在框架的参数构造中增加了这个参数，能从接入、系统、算法、存储跟踪到这个请求，快速拿到错误图片进行沙箱环境的复现及分析。
为什么说轻量级？
在上述过程中，基本上把系统的实现方式描述了一遍，可能很多人会有疑问，为什么说这个框架是轻量级的，归纳了几点，认为这个框架还算是比较轻量的。

逻辑轻量：专注于路由管理、请求转发，结果合并，专注于算法调用，没有任何多余的逻辑
参数轻量：参数中只有图片内容、识别类型、业务类型、，没有多余的参数
系统侵入少：算法框架互相独立 ，一个框架兼容多种算法，但互不侵入
系统依赖少：除了依赖于，没有其它第三方依赖

六、框架的一些思考
此次采集混合语言编程来实现图像识别服务的提供，还是我们在框架上的第一次探索，虽然当前满足了稳定的服务提供，但是框架的提升还有很多路要走，这个会结合着业务的推广而不断提升。同时也为我们的框架设计提供了新的思路，利用好编程语言的优势在业务支撑上能事半功倍。
再者为了支持深度学习版本的算法，我们也开发了版本，方便于后续快速部署到集群，同时提供了单机版及版为一些业务的快速接入提供更多的可选方式。罗马并非一日建成，我们会持续优化架构，力争提供一个稳定高效的图像识别服务，为更多的业务提供优质的服务。作者：陈昱全 

想写一篇关于 的想法来源于追查一个魅族手机图片滑动卡顿问题，由于不断的导致的丢帧卡顿的问题让我们想了很多方案去解决，所以就打算详细的看看内存分配和的原理，为什么会不断的  和 有什么区别，能不能想办法扩大堆内存减少的频次等等。
 内存回收机制
 回收算法

标记回收算法   从 集合开始，将内存整个遍历一次，保留所有可以被 直接或间接引用到的对象，而剩下的对象都当作垃圾对待并回收，这个算法需要中断进程内其它组件的执行并且可能产生内存碎片。
复制算法 将现有的内存空间分为两快，每次只使用其中一块，在垃圾回收时将正在使用的内存中的存活对象复制到未被使用的内存块中，之后，清除正在使用的内存块中的所有对象，交换两个内存的角色，完成垃圾回收。
标记压缩算法 先需要从根节点开始对所有可达对象做一次标记，但之后，它并不简单地清理未标记的对象，而是将所有的存活对象压缩到内存的一端。之后，清理边界外所有的空间。这种方法既避免了碎片的产生，又不需要两块相同的内存空间，因此，其性价比比较高。
分代将所有的新建对象都放入称为年轻代的内存区域，年轻代的特点是对象会很快回收，因此，在年轻代就选择效率较高的复制算法。当一个对象经过几次回收后依然存活，对象就会被放入称为老生代的内存空间。对于新生代适用于复制算法，而对于老年代则采取标记压缩算法。

 复制和标记压缩算法的区别
乍一看这两个算法似乎并没有多大的区别，都是标记了然后挪到另外的内存地址进行回收，那为什么不同的分代要使用不同的回收算法呢？
其实者最大的区别在于前者是用空间换时间后者则是用时间换空间。
前者的在工作的时候是不没有独立的“”与“”阶段的，而是合在一起做一个动作，就叫或，或者就叫。也就是说，每发现一个这次收集中尚未访问过的活对象就直接到新地方，同时设置 ，这样的工作方式就需要多一份空间。
后者在工作的时候则需要分别的与阶段，阶段用来发现并标记所有活的对象，然后阶段才移动对象来达到的目的。如果方式是 ，则在之后就可以按顺序一个个对象“滑动”到空间的某一侧。因为已经先遍历了整个空间里的对象图，知道所有的活对象了，所以移动的时候就可以在同一个空间内而不需要多一份空间。
所以新生代的回收会更快一点，老年代的回收则会需要更长时间，同时压缩阶段是会暂停应用的，所以给我们应该尽量避免对象出现在老年代。
 虚拟机
 堆
堆实际上是由一个堆和一个堆组成的，其中，堆用来管理进程在启动过程中预加载和创建的各种对象，而堆是在进程第一个子进程之前创建的。以后启动的所有应用程序进程是被进程出来的，并都持有一个自己的虚拟机。在创建应用程序的过程中，虚拟机采用策略复制进程的地址空间。
策略：一开始的时候未复制进程的地址空间的时候，应用程序进程和进程共享了同一个用来分配对象的堆。当进程或者应用程序进程对该堆进行写操作时，内核就会执行真正的拷贝操作，使得进程和应用程序进程分别拥有自己的一份拷贝，这就是所谓的。因为是十分耗时的，所以必须尽量避免或者尽量少的。
为了实现这个目的，当创建第一个应用程序进程时，会将已经使用了的那部分堆内存划分为一部分，还没有使用的堆内存划分为另外一部分。前者就称为堆，后者就称为堆。这样只需把堆中的内容复制给应用程序进程就可以了。以后无论是进程，还是应用程序进程，当它们需要分配对象的时候，都在堆上进行。这样就可以使得堆尽可能少地被执行写操作，因而就可以减少执行写时拷贝的操作。在堆里面分配的对象其实主要就是进程在启动过程中预加载的类、资源和对象了。这意味着这些预加载的类、资源和对象可以在进程和应用程序进程中做到长期共享。这样既能减少拷贝操作，还能减少对内存的需求。
 和有关的一些指标
记得我们之前在优化魅族某手机的卡顿问题时，发现他很容易触发__，这个类别后续会说到，是分配对象内存不足时导致的。可是我们又设置了很大的堆为什么还会内存不够呢，这里需要了解以下几个概念：分别是堆的起始大小 、最大值 和增长上限值 。在启动虚拟机的时候，我们可以分别通过、和三个选项来指定上述三个值，以上三个值分别表示表示：

  虚拟机启动的时候，会先分配一块初始的堆内存给虚拟机使用。
  是系统给每一个程序的最大堆上限超过这个上限，程序就会。
  不受控情况下的最大堆内存大小，起始就是我们在用属性的时候，可以从系统获取的最大堆大小。

同时除了上面的这个三个指标外，还有几个指标也是值得我们关注的，那就是堆最小空闲值 、堆最大空闲值 和堆目标利用率 。假设在某一次之后，存活对象占用内存的大小为，那么这时候堆的理想大小应该为  。但是  必须大于等于  并且小于等于  ，每次后垃圾回收器都会尽量让堆的利用率往目标利用率靠拢。所以当我们尝试手动去生成一些几百的对象，试图去扩大可用堆大小的时候，反而会导致频繁的，因为这些对象的分配会导致，而后会让堆内存回到合适的比例，而我们使用的局部变量很快会被回收理论上存活对象还是那么多，我们的堆大小也会缩减回来无法达到扩充的目的。 与此同时这也是产生 的一个因素，后文我们会详细讲到。
 的类型

__ 表示是在堆上分配对象时内存不足触发的。
_ 当我们应用程序的堆内存达到一定量，或者可以理解为快要满的时候，系统会自动触发操作来释放内存。
_ 表示是应用程序调用、接口或者收到信号时触发的。
__ 表示是在准备抛异常之前进行的最后努力而触发的。

实际上，__、_和__三种类型的都是在分配对象的过程触发的。而并发和非并发的区别主要在于前者在过程中，有条件地挂起和唤醒非线程，而后者在执行的过程中，一直都是挂起非线程的。并行通过有条件地挂起和唤醒非线程，就可以使得应用程序获得更好的响应性。但是同时并行需要多执行一次标记根集对象以及递归标记那些在过程被访问了的对象的操作，所以也需要花费更多的资源。后文在的并发和非并发中我们也会着重说明下这两者的区别。
 对象的分配和触发时机

调用函数在堆上分配指定大小的内存。如果分配成功，那么就将分配得到的地址直接返回给调用者了。函数在不改变堆当前大小的前提下进行内存分配，这是属于轻量级的内存分配动作。
如果上一步内存分配失败，这时候就需要执行一次了。不过如果线程已经在运行中，即的值等于，那么就直接调用函数等到执行完成就是了。否则的话，就需要调用函数来执行一次了，参数表示不要回收软引用对象引用的对象。
执行完毕后，再次调用函数尝试轻量级的内存分配操作。如果分配成功，那么就将分配得到的地址直接返回给调用者了。
如果上一步内存分配失败，这时候就得考虑先将堆的当前大小设置为虚拟机启动时指定的堆最大值，再进行内存分配了。这是通过调用函数来实现的。
如果调用函数分配内存成功，则直接将分配得到的地址直接返回给调用者了。
如果上一步内存分配还是失败，这时候就得出狠招了。再次调用函数来执行。参数表示要回收软引用对象引用的对象。
执行完毕，再次调用函数进行内存分配。这是最后一次努力了，成功与事都到此为止。示例图如下：

通过这个流程可以看到，在对象的分配中会导致，第一次分配对象失败我们会触发但是不回收的引用，如果再次分配还是失败我们就会将的内存也给回收，前者触发的是__类型的，后者是__类型的。而当内存分配成功后，我们会判断当前的内存占用是否是达到了_的阀值，如果达到了那么又会触发_。 那么这个阀值又是如何来的呢，上面我们说到的一个目标利用率，后我们会记录一个目标值，这个值理论上需要再上述的范围之内，如果不在我们会选取边界值做为目标值。虚拟机会记录这个目标值，当做当前允许总的可以分配到的内存。同时根据目标值减去固定值 当做触发_事件的阈值。
 回收算法和内存碎片
主流的大部分采取的都是标注与清理  回收算法，也有实现了拷贝的，这一点和是不一样的，具体使用什么算法是在编译期决定的，无法在运行的时候动态更换。如果在编译虚拟机的命令中指明了__选项，则编译源码 – 此是中拷贝算法的实现，否则编译 – 其实现了标注与清理算法。由于  算法的缺点，容易导致内存碎片，所以在这个算法下，当我们有大量不连续小内存的时候，再分配一个较大对象时，还是会非常容易导致，比如我们在该手机上图片，具体情况如下：所以对于虚拟机的手机来说，我们首先要尽量避免掉频繁生成很多临时小变量比如说： 等函数中对象，另一个又要尽量去避免产生很多长生命周期的大对象。
 内存回收机制
 堆
运行时内部使用的堆的主要组成包括 、 、 和  四个， 用来存在一些预加载的类，  和 与虚拟机垃圾收集机制中的堆和堆的作用是一样的，  就是一些离散地址的集合，用来分配一些大对象从而提高了的管理效率和整体性能，类似如下图：在下文的 中，我们也能看到在的 中包含了的信息，方便我们查看大内存的情况。
 的类型
 当要分配内存的时候发现内存不够的情况下引起的，这种情况下的会  当内存达到一定的阀值的时候会去出发，这个时候是一个后台，不会引起 ，显示调用的时候进行的，如果打开了这个选项的情况下，在的时候会进行其他更多。
 对象的分配和触发时机
由于下内存分配和下基本没有任何区别，我直接贴图带过了。
 并发和非并发
在上不像仅有一种回收算法，在不同的情况下会选择不同的回收算法，比如内存不够的时候会采用非并发，而在后发现内存达到一定阀值的时候又会触发并发。同时在前后台的情况下策略也不尽相同，后面我们会一一给大家说明。

非并发步骤 调用子类实现的成员函数执行初始化阶段。
步骤 挂起所有的运行时线程。
 步骤 调用子类实现的成员函数执行标记阶段。
 步骤 调用子类实现的成员函数执行回收阶段。
 步骤 恢复第步挂起的运行时线程。
 步骤 调用子类实现的成员函数执行结束阶段。

并发步骤 调用子类实现的成员函数执行初始化阶段。步骤 获取用于访问堆的锁。步骤 调用子类实现的成员函数执行并行标记阶段。
步骤 释放用于访问堆的锁。
步骤 挂起所有的运行时线程。
   步骤 调用子类实现的成员函数处理在并行标记阶段被修改的对象。   步骤 恢复第步挂起的运行时线程。   步骤 重复第到第步，直到所有在并行阶段被修改的对象都处理完成。   步骤 获取用于访问堆的锁。   步骤 调用子类实现的成员函数执行回收阶段。   步骤 释放用于访问堆的锁。步骤 调用子类实现的成员函数执行结束阶段。
所以不论是并发还是非并发，都会引起 的情况出现，并发的情况下单次 的时间会更短，基本区别和类似。 并发和并发的差异
首先可以通过如下张图来对比下。 ： 

的并发和的并发有什么区别呢，初看好像者差不多，虽然没有一直挂起线程，但是也会有暂停线程去执行标记对象的流程。通过阅读相关文档可以了解到并发对于来说主要有三个优势点：

标记自身在对象分配时会将新分配的对象压入到类的成员变量描述的 中去，从而可以一定程度上缩减对象遍历范围。
预读取对于标记 的内存时，会预读取接下来要遍历的对象，同时再取出来该对象后又会将该对象引用的其他对象压入栈中，直至遍历完毕。
减少时间在阶段是不会其他线程的，这个阶段会有脏数据，比如发现不会使用的但是这个时候又被其他线程使用的数据，在阶段也会处理一些脏数据而不是留在最后的时候再去处理，这样也会减少后面阶段对于脏数据的处理的时间。

 前后台
  前台指的就是应用程序在前台运行时，而后台就是应用程序在后台运行时。因此， 就是应用程序在前台运行时执行的，而就是应用程序在后台运行时执行的。应用程序在前台运行时，响应性是最重要的，因此也要求执行的是高效的。相反，应用程序在后台运行时，响应性不是最重要的，这时候就适合用来解决堆的内存碎片问题。因此， 适合作为 ，而 适合作为 。由于有的能力存在，碎片化在上可以很好的被避免，这个也是一个很好的能力。
 大法好
总的来看，在上做的比好太多了，不光是的效率，减少时间，而且还在内存分配上对大内存的有单独的分配区域，同时还能有算法在后台做内存整理，减少内存碎片。对于开发者来说下我们基本可以避免很多类似导致的卡顿问题了。另外根据谷歌自己的数据来看，相对内存分配的效率提高了倍，的效率提高了倍。
  
当我们想要根据日志来追查一些可能造成的卡顿时，我们需要了解日志的组成，不同信息代表了什么含义。
  日志
 的日志格式基本如下：______ 就是我们上文提到的，是_还是_，了解到不同的原因方便我们做不同的处理。_ 表示系统通过这次操作释放了多少内存。_ 中会显示当前内存的空闲比例以及使用情况活动对象所占内存  当前程序总内存。_ 表示这次操作导致应用程序暂停的时间。关于这个暂停的时间，在之前操作是不能并发进行的，也就是系统正在进行，那么应用程序就只能阻塞住等待结束。而自之后，操作改成了并发的方式进行，就是说的过程中不会影响到应用程序的正常运行，但是在操作的开始和结束的时候会短暂阻塞一段时间，所以还有后续的一个_。_ 表示本次所花费的总时间和上面的_也就是 是不一样的，卡顿时间主要看上面的_。
  日志
_______基本情况和没有什么差别，的更多了，还多了一个__
__：  ，大对象占用的空间，这部分内存并不是分配在堆上的，但仍属于应用程序内存空间，主要用来管理  等占内存大的对象，避免因分配大内存导致堆频繁 。写在最后：图片来源自网络，特别鸣谢罗升阳。 

文章来源于公众号：空间终端开发团队


相关推荐
关于图片资源瘦身的奇思妙想
动态库压缩壳的实现导语：年月日，用户组大会在北京召开，腾讯网络媒体事业群数据库工程师周奇作为演讲嘉宾，分享了在腾讯网媒产品的使用场景，以下为演讲内容稿。
演讲嘉宾：腾讯网络媒体事业群 数据库工程师 周奇演讲主题：在腾讯网媒产品中的应用导语 ： “才刚写完用例，怎么开发大哥又改了了？” “维护这些破用例的时间，都够我手工测三遍了，真的有意义么？” “这破手机，能不能别老是系统弹框……”

一 、引子
自动化，在移动互联网时代的今天，一直都是在各大测试社区最为火爆的一个。甚至在测试同行面前一提起自动化，大家就会自然而然的问：“恩，你们是用的什么框架？？还是？”
其实在笔者看来，自动化是一个较低的测试项即  ，中文意思是投资回报率。但自动化相比接口自动化、白盒测试等，它更贴近手工业务测试行为。对于刚起步测试左移、效率提升的团队来说，是最迅速的切入点，也是广大黑盒，提升自身技术能力的起跑线。
笔者接触自动化一年多，兼顾业务测试的同时断断续续地投入，曾经无数次的想放弃：
 “才刚写完用例，怎么开发大哥又改了了？”
 “维护这些破用例的时间，都够我手工测三遍了，真的有意义么？”
 “测试框架自己有，我改用例也没用啊……”
“我调试的时候这个用例还是通的，放到里面跑就不通，到底怎么回事嘛！”
“怎么这么不稳定啊，老是断！！！”
 “怎么跑着跑着就了，到底是被测应用有问题，还是测试代码有问题啊？”
 “明明界面上有这个元素，怎么就是查不到呢？”
“这破手机，能不能别老是系统弹框……”
“这手机真是渣， 截个图，居然要三分钟才返回！”
“这些控件都没有，没有，层级还三天两头改，要我怎么查……”
 “查了这么多论坛，怎么就没有人遇到过类似的问题呢？”
……
这些问题让笔者一度怀疑，自动化这个，是不是根本没用，只是为了涨薪，或者为了摆脱重复无聊的手工业务测试，而出来自我欺骗的。
二、 问题分类及目标明确
笔者将以上所有的问题简单分成三类：设计类，环境类，细节类。一个好的设计模式，能够避免一部分问题；一套好的环境，可以让我们从乏味的维护工作中解脱；精益求精的细节，让测试用例更加可靠稳定。

图一 自动化常见问题
填掉这三类坑，基本上就获得了一套低成本高产出、少量维护、稳定可靠的自动化用例集。
三、 设计类问题分析与解决
“才刚写完用例，怎么开发大哥又改了了？”
“测试框架自己有，我改用例也没用啊……”
这类问题，我们需要从根上治。自动化开发，也应该是严谨的开发工作，它也需要设计模式，也是磨刀不误砍柴工。这里的设计，主要包括选工具、框架分层等。很多前辈都分析过自动化各类工具的优缺点，对工具选用笔者不再赘述。主要依托来介绍下笔者认为比较巧妙的用例框架设计。
 优化测试代码框架
无论你选择、、还是，刚入门时，看到的应该大致都是这样的。

图二和逻辑样例
问题在哪里？这些过于简单，都只教了我们自动化三元素：怎么查找元素、怎么操作元素、怎么校验结果。如果我们按照大多数分享帖或 来写作自己的。最后这种没有任何设计模式的框架，肯定会面临重构。拿上面的来说：

假如_这个开发改了，而你的用例集中，有个步骤用例到了这个，一个个去改，是不是要疯？

不厌其烦的重复写这一长串，你不烦？


笔者是如何做的？分层设计和模式。这两个方法，基本解决了笔者遇到的图一中所有的设计类问题。

图三 框架设计建议
按照图三进行分层设计后，得到如图四的测试代码包。

图四 分层后的用例框架
模式发源于社区，它的目的是减少重复代码，当开发修改时，测试只需在有限的位置修改代码。如果大家想深入了解，请参照如下


我们来看一下，现在手管首页包中的代码和页面。

图五 手管首页层部分代码
回忆一下上面的提供的，再对比引入分层设计和模式前后的代码，点击图五中的一键加速：

图六 引入前后代码对比
带来的好处，当然不仅仅是业务用例代码更清爽。

通过将查找和操作封装到基础层中，这部分代码就具体业务无关了，即使拿到其他产品中也可以复用；

通过层的分离，所有的与业务相关的，等都被限定在了包中，哪怕开发改了，修改包特定的页面中对应的元素就好了。

对包进行合理的业务拆分，比如将手管分成 主页，软件管理页，管理页等，在开发改了某个具体业务的界面后，测试能够迅速知道测试代码需要改哪里。


 兼容资源混淆的测试代码
除了整个框架的设计，有时候一些小问题也可以经过巧妙设计。比如资源混淆的问题。

图七 资源混淆
如图七，在手机管家的发布包中，用 下来发现，一键优化的，其是，但其实开发时，定义的显然不会用这种没有任何字面意义的代号，它在混淆之前叫_。
纯黑盒的自动化，也许你会摒弃_，直接写，但这样显然不够科学，既带来了严重的代码可读性问题，同时一旦版本迭代，混淆变了，也许就变成了。或者你会让开发给你测试的包，不要混淆，但如果想用自动化测试已发布的呢？
=解决该问题，也得从说起。回到图五中_的定义，这个静态变量并未在中初始化，只有一个的注解。其实，在框架层驱动测试开始前，框架会先调用如下图八所示的来初始化所有的页面。

如果被测应用未混淆资源，该方法只是将中的值赋值给。

如果被测应用已混淆资源，该方法则会从未贴出全部代码，实际是解析一个开发提供的混淆表，以原始为，混淆为的中读出对应的对应关系，将混淆后的赋值给。



图八 层动态初始化
四、环境类问题分析与解决
“怎么这么不稳定啊，老是断！！！”
 “明明界面上有这个元素，怎么就是查不到呢？”
“这破手机，能不能别老是系统弹框……”
 “这手机真是渣， 截个图，居然要三分钟才返回！”……
引子中提到的这些问题，根据经验，多半你的环境执行环境还不够稳定。
 相关问题
已知的不稳定原因如：电压不稳，各类手机助手的干扰，系统版本与版本不匹配、等等。如果我们迎难而上，去重写，投入将无限扩大。所以建议主要的解决方案，还是尽量规避。
     选用可靠硬件规避电压不稳定，上的项目组有过成熟的经验，选用性能更优的分接器，电压和可靠性会有更稳定的表现。附上链接，  一节中有不同硬件详细的性能对比， 
     屏蔽各类手机助手的干扰。助手、豌豆荚等，基本都在上做了二次开发，它们会与原生间有兼容性问题。建议直接使用系统作为运行环境以屏蔽这类干扰。
      降低用例在执行过程中对环境的依赖。这类自动化工具，每一个测试步骤都需要端的 和测试手机端的交互消息。测试过程中只要连接不稳定，都会导致整个测试套的失败。所以笔者认为，使用更原生的会是更好的选择；同时，测试过程中的日志、截图等，也尽量在测试手机上做持久化。
 弹框问题的解决
权限弹框，是手管自动化中的一个大坑。如下图，是测试手管过程中，在华为手机上遇到的部分权限弹框。这些弹框，并不会用例每次执行都弹出，不同厂商的弹出框也不一致。显然点击弹框的逻辑，写在逻辑中，只会导致自动化变得更复杂更不稳定。

图九 各类权限弹框
的，能够完全实现点击弹框和用例逻辑的解耦。当前笔者的实现逻辑是，监听弹框上的某个控件，当该控件出现时，执行来点击掉其中的取消或确定按钮。这样，用例就只需关注业务逻辑，而任何时候的弹框，都由来自动点击。如下图中，关注条件，是操作。

图十查找型
将所有的分不同的手机厂商进行注册后，再调用，然后再执行用例。该方法可以在中或者的中调用。当然，如果某个用例不想某个具体的弹框被点击掉，也可以调用反注册。

图十一 注册监听器
并不能解决所有的弹框问题。例如，在开启的场景中，由于的和上的弹框点击是同步的意思是调用了之后，如果界面上不点允许，该方法是不会返回的，使用上面的方式并不会点击权限申请的允许。这时，就需要用到线程方式来解决如下图十二，调用前，先启动一个线程等待弹框弹出。

图十二 多线程方式点掉弹框
五、细节类问题分析与解决
“我调试的时候这个用例还是通的，放到里面跑就不通，到底怎么回事嘛！”
出现上述问题，多半是因为我们的用例细节不够严谨。这类问题，往往决定着我们自动化用例集，是不是能从的通过率，提升到。
 顺序逻辑的用例
自动化相比手工，它只会关注告诉它的验证点，所以选择逻辑在用例中应该是禁用的。如下图十三中右侧的，如果用例执行到中，也许流程中存在，反之亦然。此时考虑拆分用例，左侧才是理想的用例逻辑。

图十三用例逻辑
另外，写作时，一定要牢记，只有我们告知程序要，它才会去。查找，操作，断言，自动化三要素缺一不可。
 解耦的用例
在中，会提供注解，似乎在鼓励写作用例时，使用用例间依赖。但笔者认为，用例间的依赖，会带来不必要的维护成本。只有高度解耦的用例逻辑，才能够更加健壮的支撑用例执行顺序调整、用例增删、出现异常场景后，用例失败不会导致用例也失败。
 优化等待
有时候会遇到以下场景，虽然原生的自动化工具提供了等待元素可见的方法，但使用起来，还是无法真正等到元素可见。针对这个问题，如下图的方法是一个不错的方案，它相对于来说，更节省时间。

图十四反复等待方法
 不用绝对坐标点击
绝对坐标点击，在不同尺寸屏幕上无法兼容。
第一方案应该是，推动开发对需要用到的控件添加或。但根据经验还是会有一些场景需要用到坐标点击：
， 考虑投入产出比，为所有控件添加的成本过高；
， 动态布局添加的都一样；
， 存在非布局的界面代码中直接布局。
这时，笔者依然不建议这样的坐标点击。有以下两种值得一试的方案。
     找到相邻控件坐标，计算当前控件的绝对坐标。如下图十四，中点击右上角警告小三角，会得到有一些元素黄色控件，是可能无法找到的。而使用相对坐标就是说，我们可以获取它相邻控件的坐标，然后减去或加上一个比较小的值，再点击计算后的坐标即可。

图十五 相对坐标
     使用屏幕尺寸计算相对位置。在测试开始，将屏幕尺寸存下来，使用百分比的方式计算得到需要点击的位置。如下，点击【宽度，高度】的位置。

六、总结
自动化测试是一门学起来很简单，用起来很麻烦的测试技术。
想要入门，两周就可以了解清楚或这类工具。自动化，无非就是查找元素、操作元素或设备、验证结果。这三个步骤循环多次，就是一个用例。
但要用好，并产出能效，需要走的路其实很长。由于篇幅限制和知识有限，这里不可能把所有的问题一一列出。对于所有这些问题，无非两个思路：一是绕过，二是解决。

选一个尽量简化，尽量底层的工具或从根上绕过一些工具会存在的问题；

采用良好的设计模式，让自己的框架更稳定，生命周期更长，维护成本更低；

明知道会耗费很多时间精力，收效却很小的环境问题，尽量绕过；

优化用例逻辑和细节，使之稳定可靠，更能说服别人相信自动化的测试结论。


最后，祝愿大家在自动化的道路上越走越顺！

文章来源于：腾讯移动品质中心 最近开始负责财付通的数据库的相关维护工作，其中有几套系统使用的  引擎，为了以后能更好地对这套系统进行维护，对  做了一些功课，将  引擎的功能、使用场景、部署、实战测试等做个简单的总结，希望不了解  引擎的同学看到这篇文章能对  引擎有个更深入的了解。
先来说两个我们  经常遇到的场景：
场景 ：有两个分布在不同实例上的多张不同的表，想要通过某个字段关联，做一个统计，或者想将分布在不同实例的表，合并到一个实例中来做一些查询。
场景 ：由于数据库容量的瓶颈或者是由于数据库访问性能的瓶颈，将一某一个大库、大表或者访问量非常大的表进行拆分，然后分布到不同的实例中。
这两种场景覆盖了我们  经常接触的垂直拆分和水平拆分，在这种场景下往往面临着如下几个窘境：
、这些表的访问和存取需要额外的路由规则，复杂度很高
、需要做数据汇总或者统计的时候，非常麻烦

我们想到的解决办法可能有如下几种：
、使用数据库中间件 
这个似乎是大公司的专用的，由于存在各种各样的限制，小公司往往使用起来非常不方便，对于里面存在的各种坑也没办法很好的进行规避。
、使用  分区表
无法解决磁盘空间瓶颈以及服务器性能瓶颈。
、使用    
支持数据库的高可用以及能实现读请求的扩展，但是对于写请求无法实现性能上的突破。
、使用  的多源复制
仅仅适合将多个实例的数据聚合到一起，用来做数据统计，但还是存在磁盘空间的瓶颈。
、使用 
可以实现将数据聚合，对于水平分割的场景并不适用，并且性能方面也存在比较大的问题。
、  和 
  是   的一种，对于这种需求是个比较好的解决方案，不过使用于生产环境的案例比较少。还有一个  分布式引擎方案，非常适合前面我们讨论的两个场景，下来将会做深入的介绍，该引擎目前已经集成到了  中，目前最新的版本是  。腾讯互娱  团队基于  基础上进行开发，提高了性能和稳定性以及修复了大量的 ，形成了非常靠谱的 ，目前已经在腾讯游戏、支付等领域广泛使用。
本文就是基于  的分布式数据库解决方案，下面就来详细介绍：

一、 引擎简介
、 引擎是什么
 引擎是一个内置的支持数据分片特性的存储引擎，支持分区和  事务，该引擎可以在服务器上建立和远程服务器表之间的链接，操作起来就像操作本地的表一样。并且后端可以是任何的存储引擎。 引擎根据表的设置的规则以及  表的规则自动进行智能路由，实现对后端数据库不通的表或者数据分片的访问和修改。因此该引擎对业务是完全透明的。目前  引擎已经集成到了  中，安装使用非常方面，目前最新的版本是  。更多信息可以访问：   ，具体的版本历史如下图所示：

、 架构图

、 的优势
、对业务完全透明，业务不需要做任何的修改
对于分库分表的逻辑业务不需要关心，只需要通过  作为代理入口，访问数据对应在后端哪台  上  自动帮你处理。
、方便横向扩展，能解决单台  得性能和存储瓶颈问题
、对后端的存储引擎没有限制
、间接实现垂直拆分和水平拆分功能
通过  和后端的数据库连接，可以是独立的表，也可以是基于分区表，分区表支持哈希、范围、列表等算法。
、完全兼容  协议
由于  特殊的插件式存储引擎架构， 层负责  解析、 优化、数据库对象视图、存储过程等管理；存储引擎层负责数据存储、索引支持、事务、 等，两者之间通过约定好的  接口进行交互。 解析、优化与执行交给  层处理，几乎支持执行任意类型  访问。
、 的劣势
、 的表本身不支持查询缓存和全文索引，不过可以将全文索引添加在后端数据库中；
、如果采用物理备份， 无法备份后端的数据，因为数据本身是存放在后端。可以对后端的  一一做物理备份
、 本身是单点，需要自己做容灾机器，比如通过  的方式
、多了一层网络，性能上会有一些损耗，尤其是跨分区、跨表查询性能会差一些
、 介绍
腾讯互娱  团队在   的基础上进行深入优化和定制开发，形成了 ，极大地提高了  性能、稳定性和兼容性，在性能上比  至少提升 ，目前  已经发展到了   版本， 经过了腾讯游戏海量访问以及高数据安全性的考验，整体解决方案已经非常成熟，目前财付通也有部分服务器使用了互娱的 ，腾讯互娱  团队修复的部分优化点如下：

二、 的使用场景解析
、垂直分表的场景和解析
、垂直分表场景图

、垂直分表场景解析
从上图可以看出， 后面接  台  ，可以将不通功能的表分布到后端不通的   中，比如 _ 的表专门存放在  中，_ 表存放在了  中，_ 表存放在了  中，_ 表存放在了  中。在图中的红色部分，当我们执行红色部分的  的时候， 会通过 _ 表的映射关系以及  的  映射关系，将查询 _ 表的请求都转发到  上， 查询完成后再将结果发给  服务器， 再转发给客户端。
、采用水平分表的场景
、水平分表场景图

、水平分表场景解析
 支持多种水平分表的模式，目前支持  分表、范围分表、列表分表，我这里用  来说明水平分表的工作原理。从上图中可以看出  对 _ 表针对  进行了分区，将  的记录存储在了 ， 的记录存储在了 ， 的记录存储在了 ， 的记录存储在了 。当用户访问 _ 的某条或者多条记录的时候， 会根据分区的情况，对相关的记录落在某台或者多台   上，再进行转发。比如    _  = 这个 ， 在收到这个请求后，会跟进分区情况选择对应的   进行转发。这里会将该请求转发到  中。 处理完成后，再将结果返回给  ， 再将结果转发给发起请求的客户端。
三、 引擎实战
一、 的安装部署
从   版本开始， 引擎就集成到了  中，集成后安装就非常的简单，安装步骤如下：
、安装  到   以及后端多台   上；
安装方法非常简单，这里不在赘述，具体可以参考：安装和更新
、安装  引擎到   上后端的   不需要安装  引擎

    _

或者登录  后执行

 _

备注：_ 在  目录下面
这个命令所做的事情如下：
创建  相关的系统表

___
___
_
_
___
__

创建  相关的表结构
加载  引擎
、检查  引擎是否安装成功

如果出现上图所示的结果就说明已经支持了  引擎了
二、 的使用实战
备注：本实践环境基于  环境全部验证通过
、 实战拓扑图
在实战部分，我使用了  台  ，部署图如下：

、实战前准备
、创建   访问后端   的权限后面配置中需要用到

    __   __

、创建  后端   的配置
可以通过执行如下  的形式直接创建

             __  __  
             __  __  

也可以通过直接给  表中直接插入相关的记录，不过后面执行   才能生效

  _ ____
  _ ____

创建完成后可以直接查询  表，确认是否添加成功，如下截图所示：

、创建基础测试表
在后端两台   上创建基础测试表在  和  上执行

  _ 
 
 
 
  
 
 =  =     

、 引擎实战
、建立垂直表远程表进行测试

  _ 
 
 
 
  
 
 =  = = 

创建之后，执行对应增删改查，看看是否对应的操作都发生在了  对应的   上？
测试完成后，删除掉  服务器上的 _ 表，你会发现  掉  上的表，不会导致后端   上的表被删除。
、建立  分区表

  _ 
 
 
 
  
 
 =  = =   _
   
    =  
   =   

创建之后，执行对应增删改查，看看是否对应的操作都发生在了  和  对应的   上？
测试完成后，删除掉  服务器上的 _ 表，你会发现  掉  上的表，不会导致后端   上的表被删除。
、建立  分区表

  _ 
 
 
 
  
 
 =  = =   _
    
        =  
       =   

创建之后，执行对应增删改查，看看是否对应的操作都发生在了  和  对应的   上？
测试完成后，删除掉  服务器上的 _ 表，你会发现  掉  上的表，不会导致后端   上的表被删除。
、建立  分区表测试

  _ 
 
 
 
  
 
 =  = =   _
    
       =  
      =   

创建之后，执行对应增删改查，看看是否对应的操作都发生在了  和  对应的   上？
测试完成后，删除掉  服务器上的 _ 表，你会发现  掉  上的表，不会导致后端   上的表被删除。
四、性能测试
性能测试可以采用  来测试，和  单台以及后端挂多台  的场景进行对比，确认  引擎的性能和优势，由于手头没有合适的设备这部分等以后有时间再进行测试， 的官网已经有对应的测试方法和结果，有兴趣的可以去 查阅。
五、参考资料
为了撰写本文，翻阅了不少资料，感谢前辈们的贡献，罗列如下：




高斯模糊实现方案探究
现在越来越多的在背景图中使用高斯模糊效果，如天气，效果做得很炫。 我们个性资料卡的标签模版也需要使用高斯模糊，这里就用一个来谈谈它的不同实现方式及各自的优缺点。
 
谈到高斯模糊，第一个想到的就是。是由引入，用来在上编写高性能代码的一种语言使用标准。 引用官方文档的描述：

                                

为了在中使用，我们需要直接贴官方文档，比直译更通俗易懂：

        
               

学习文档：
上面两点总结成一句话为：我们需要一组 文件中编写，及一组用于控制相关的 文件自动生成为类。 由于 的编写需要一定的学习成本，从__开始，内置了一些 用于常用的操作，其中就包括了 。
下面，通过实操来讲解一下来实现高斯模糊，最终实现效果将文字背景进行模糊处理：

布局：
 = =
 =
_=_
_=_ 

     
        = 
        _=_ 
        _=_ 
        = 
        = 

     
        =
        =_ 
        _=_
        _=_
        = 
        =
        _=_
        =
        = 

     
        = 
        _=_ 
        _=_ 
        = 
        =
        _= 

核心代码：
   {
      {

        
           {
            
            
              = 
              
             
        }
    }
}

___
      {
      = 
      = 

      =   _
      =  
     
       

      = 

      =  
      =  
    
    
    
    
      
    

           
}
当开始加载背景图时，取出它的，进行处理， 的主要逻辑在函数中。对于在中使用，官方文档中也有详细描述，对应到我们的代码，步骤为：

初始化一个 
至少创建一个对象用于存储需要处理的数据
创建 的实例，本例中是内置的对象
设置实例的相关属性，包括 等
开始操作，对应
将后的结果拷贝回中。

此时，我们便得到了一个经过高斯模糊的。
从上图可以看到，模糊处理花费了测试机为小米，由于假设每一帧的处理时间不能超过屏幕刷新频率，因此，若在主线程里执行操作，可能会造成卡顿现象。最好的方式是将其放入中执行。
此外，在引入，而一些内置的 在__中引入，为了在低版本手机中使用这些特性，我们不得不引入_兼容包，对于手安装包增量的硬性指标，貌似只能放弃__以下的用户？
有点不甘心，想想别的解决方案吧。
 
由于高斯模糊归根结底是像素点的操作，也许在层可以直接操作像素点来进行模糊化处理。一下，果不其然，一个名为的开源项目提供了名为的方法在层直接进行高斯模糊处理。
项目地址请猛戳： 
，现在来改造我们的程序
      {
      = 
      = 

      =   _
      =  
     
       
     =   
      
           
}
这里，仅仅是把相关的操作换成了提供的。效果图如下： 

效果还不错，与的实现差不多，但花费的时间却整整多了倍多，这完全是无法接受的。好吧，只能继续探究。
 
对于程序员来说永远是最大的宝藏。这篇提问帖终于提供了新的解决思路：

                                                  

它所表述的原理为先通过缩小图片，使其丢失一些像素点，接着进行模糊化处理，然后再放大到原来尺寸。由于图片缩小后再进行模糊处理，需要处理的像素点和半径都变小，从而使得模糊处理速度加快。 了解原理，继续改善程序：
      {
      = 
      = 
      = 

      =   _
      =  
     
         
      =  
    __
       
     =   
      
           
}
最新的代码所创建的为原图的大小，接着，同样使用来进行模糊化处理，最后再为设置背景，此时，背景图会自动放大到初始大小。注意，由于这里进行了缩放，的取值也要比之前小得多这里将原始取值除以得到近似值。下面是效果图：

惊呆了有木有！！效果一样，处理速度却快得惊人。它相对于方案来说，节省了拷贝到中，处理完后再拷贝回来的时间开销。
 
由于是将整个拷贝到一个临时的中进行像素点操作，因此，它不适合处理一些过大的背景图很容导致有木有。对于开发者来说，方案和方案的选择，需要你根据具体业务来衡量！作者：腾讯云高级工程师董晓杰

本文通过 搭建了一个简单的环境，使用的是 官方镜像，镜像版本， 镜像版本。主要介绍了环境的搭建及使用，更详细的企业级服务器的搭建可参考开源的。
亲自动手实验一下会理解更深刻，动手吧！
使用腾讯云容器服务无须自建，快速使用安全可靠的镜像仓库

是什么？
是的镜像存储服务， 上的镜像见官方镜像，更多详细信息请参见源码。
搭建

在服务器上执行如下命令安装，这里选择腾讯云    位镜像来创建服务器

   | 

安装

 是一个定义及运行多个容器的工具。使用 只需要在一个配置文件中定义多个容器，然后使用一条命令将多个容器启动， 会通过解析容器间的依赖关系，按先后顺序启动所定义的容器。详见 
      
  

启动服务，此例中包含和两个容器，涉及的配置文件请参见附录，部署好后，直接执行如下命令即可创建服务。
   

停止服务
  

重启服务
  

下线服务
  


上传镜像

因为上面搭建的服务是的，所以启动参数需要配置 选项，修改文件
 _= 

重启
   

拉取上传镜像    默认为
          


下载镜像
  
删除镜像
  
获取镜像仓库列表
  _
{}
未上传镜像前的输出如下：
  _
{}
获取镜像列表
    
{}
获取镜像信息
        
{
    
    
    {
       
       
       
   }
    
      {
          
          
          
      }
   
}
其中   即为执行 时看到的 。
表示了镜像的层次关系，可以通过中的来拉取，见下面获取镜像
获取镜像
 在上面获取镜像的信息中可以看到其只有一个，以此为例来看如何获取镜像。从拉取的结果可以看到获取的与文件是一致的。执行 实际上就是首先获取到镜像的信息后，再拉取的。
       
    
        
   
      
删除镜像 
 首先通过   参数获取到镜像的  ， 及以后的版本必须在中指定 ，否则默认返回的是的，其与的不同，使用不指定上述头信息返回的删除时会返回。
         

  
 
      
 
 
 
 
 
 

{
    
    
    {
       
       
       
   }
    
      {
          
          
          
      }
   
}
 根据上一步返回的删除，返回表示删除成功
       

       
    
       
   
  
  
  
 
   
     
  
       
   =
  
  
  
 
       
 确认结果
    
{}
删除镜像 
在上一步中，只是删除了镜像的信息，解引用的还在占用磁盘空间，执行如下命令可以查看可以删除的
   __    
 要删除，释放磁盘空间，需要执行下面的命令。需要特别注意的是在执行下面的命令时必须是只读模式只读模式可在配置文件中设置，否则可能会导致数据不一致。
   __   
附录
目录结构

| 
|   | 
|   |   ` 
|   ` 
|       ` 
` 

_ 

 {
  _ 
   
  _ 
}

 {
  _ 

                 
  __ 


    {
     
  }


   {
     

               
    ___ 

      {
       
    }

      {
      _ 
      __  _
      __  _
      __  ____

                             
      __  

      _ 
      __ 

    }

  }
}

 

   
  
     

    
         
    
         
    
        
             
        
             
    
         

     
     

 

  
     
     
    
       
       
    
       ==
    
       
  
     
     
    
       
    
       
       
    _
       图片平台上承接了巨量的图片每天需要针对几十亿的图像进行处理，由于格式是存储系统中存储最多图像格式，而格式编解码以及处理中都是大量的数据计算，较于具有更强大的数据并行计算的能力。于是研究利用来加速处理图像编解码以及图像处理 为此很有必要先了解的的编解码过程。
文章参考了大量外部资料，引用了相关的图片以及数据，所涉及到的内容或者原理都有相应的链接跳转以供查询。
的颜色模式
采用的颜色模式，通常叫着，其中代表亮度，代表色度和饱和度。而我们通常熟悉的计算机系统采用颜色模式。从颜色模式向模式转换采用以下公式：
 =      
 =     
 =      
为何采用格式编码呢？是因为亮度变换的敏感度要比对色彩变换的敏感度高出很多。因此采用颜色模式能够将图像不太重要的信息进行抽离出来。采用不同的采样比例来达到减少存储数据的目的。
经过上述颜色空间转换后，我们就能得到、、三个分量上的三张表。
采样
采样为例，若在一个的图像中。采样即为：
  =   =
  =   =
  =   =
若的转换为后图像编码表示为
     
     
那么经过采样后
      
     
数据存放为
     
那么原图共占用个字节，经过采样后仅需要个字节。这里通过采样初步减少了图像大小。
分块
数据采样完成后就需要进行下一步操作，进行空间域向频率域转换变换。在空间域里处理图像有困难，就转到频率域来进行处理。为了进行变换需要对图像码流进行分块。从码流中分别提取、、三个分量构成三张表。
 进行变换时需要的为单元。而最小编码单元是水平方向和垂直方向上采样最大值与的乘积。那么采样的大小为。
图像边缘在不满时需要进行补齐，采用不同的补齐方式将会产生不同的影响。如采用全黑色进行补齐将产生振铃效应在边缘较为锐利的文字型图像中较为容易发现。通常采用重复边缘上的数据来进行填充。其次是图像在进行变换时高频分量的丢失或者精度损失也造成振铃效应。
振铃效应图像对比



振铃效应影响的图片
处理的图像









变换

关于变换的数学过程在此不表，有兴趣可以参见这篇文章算法解密二，其蕴含的哲学思想很有意义 “世上任何复杂的事物，都可以分解为简单的事物的组合” 要对傅里叶变换进行更加深入的理解可以参考傅里叶分析之掐死教程完整版。

这里有两张傅里叶变换的经典图像


鉴于图像在的范围内相对的连续性，变换能够将能量集中于低频部分，而高频部分信息肉眼不敏感，这样就使得后续对变换后的矩阵进行量化减少高频信息成为可能。
变换的强大威力示例：

经过变换后得到的矩阵，其中位置称为直流分量，其他个元素称为交流分量。
量化
数据量化是针对变换后得到的系数矩阵进行精度处理使用系数矩阵中的每一项分别于对应的量化矩阵位置处的值相除所得到的新矩阵为量化后的结果。分别针对亮度、色度和饱和度提供两张不同的量化表。因为人眼对亮度相对于色度更加敏感，所以亮度量化表精度较色度量化表更加精细。



亮度量化表
色度量化表









而通常我们在进行质量调整时就是在量化表乘一个系数得到新的量化表。量化过程对于原图来说是一个有损的过程。这也就是实际图像质量无法超越原始图像的原因。
经过量化后的数据进一步缩小了数值范围，在右下角高频部分由于量化表系数较大很多图像在此部分形成了较多的。而左上角低频部分保留了较多的肉眼敏感的数据。
一个变化后数据量化的示例

针对量化后的数据需要从二维矩阵降维到一维的数组，方便进行数据编码。而由于矩阵呈现右下角数据更小更集中的趋势，在降维时采用了扫描算法。这样右下角的数据在一维空间中连续存放，有利于产生更多的。对减少编码后图像大小提高压缩率有很好的帮助。
扫描过程

上面数据经过扫描后行程这样的序列

数据编码
经过扫描后的数据进行横向排布后得到这样的序列

数据分为两部分，第一个数值为直流分量，对直流分量采用编码，因为该值通常较大，而相邻的图像数据之间的差值变化不大。
针对系数序列进行游程编码。是因为经过扫描后产生许多连续的，编码能够大幅减少数据的空间占位。
再使用标准的表对和编码后的数据进行编码得到二进制序列。而使用表编码时，针对直流分量和交流分量分别采用不同的表。对各个通道的编码也将采用不同的编码表。
欲了解上述数据如何进行编码，再进行编码可参考这篇文章算法解密四该文章详细的描述了游程编码过程以及从游程编码的结果进行编码得到相应的存储二进制数据流。
数据编码完成后把用到的表，表以及其他一些数据信息，按规定格式写入到数据的头部。和编码后的数据合并起来就产生了一个文件。头部写入的表。写入的是码字数量和编码内容，在解码时需要根据各个长度的码字数量结合编码内容来建立树对数据进行解码。
并行性考量
上述过程中变换过程，数据量化过程以及后续的数据编码过程都是以为单位，这些过程应该都能够进行并行化处理。来获取一定的处理加速。
后续将分析图像缩放以及解码过程，考虑通过并行化以获取加速的可能。从命令行下搭建一个  博客。用于开始进入云服务器的第一步。
 下载 
 是一个开源的博客程序，使用  语言编写。目前的第三方的插件很多。
 
 _
 安装软件包
安装一些博客需要使用到的软件，例如  服务的，、、。不过新版本的  已经将  从 源中移除，这里使用同源的数据库 。也是从  的开源出来的版本。
       
  
   
 配置数据库
登录数据库实例中，创建一个数据库。等会博客的文章、数据都存放在该数据库中。
___  

    
      
 配置  服务
配置  的一些配置。这样就可以让访问 ，就可以访问到博客。 

 {
    _   替换成自己服务器的地址
     

      {
                  
        _   
    }

      \ {
        _  =

        ___ \

         _
        _ 
        _ _ ___
        _ 
    }
}
重启 
  
 安装 
 
 _
然后打开浏览器访问  网页 
进入到欢迎界面
输入数据库、账号、密码。
提示没有权限。
人工将文本复制，写到  文件下。
重新回到网页上，继续下一步就可以了。
 管理 
设置博客的管理员帐号、密码等信息。


登录博客管理后台  
发表文章。查看博客。

博客首页年，好莱坞巨星安吉丽娜·朱莉突然发表声明：“医生建议我提早十年进行预防性手术——乳腺切除，我的母亲就是岁时被确诊为癌症，而我现在已经岁了。”医学界认为，朱莉的理性选择，让世界得以继续保有她的美。这个理性选择指的是，朱莉通过基因测序，检查出了基因缺陷，此缺陷意味着她有和的几率罹患乳腺癌和卵巢癌，于是，她接受预防性乳腺切除。

基因测序，让安吉丽娜·朱莉将罹癌风险降到了最低点。是不是很神奇，来来来，小编带你来看看它的适用人群吧！ 
再给你推条惊人的数字信息！根据相关数据显示，在年，我国新增肿瘤患者人数约为万人，因癌症死亡人数约万人。别紧张，再给你来条数据！从过去十几年到现在，人类基因组的测序成本从万美元减少到现在只要美元了。基因检测已经变得普罗大众。很快，基因检测就变得和体检一样平常了！

因为我们就是这么幸运的处在这个高效的互联网时代。有如水电一般的云计算、海量大数据和超级人工智能，计算算法在不断优化，基因测序幸运的搭上了顺风车，技术变得更加成熟和高效。举个栗子！
诺禾致源三代测序序列分析流程从传统迁移上云后，效率提升！！碳云智能多组学基因数据分析，云计算平台可以为其快速按需提供大量计算资源，上万核的计算能力完全不在话下！
是不是很震撼，让你更震撼的是，这惊人数据的背后竟然是腾讯超算云在搞事儿！来，先上张。
字有点多对吧，没事，那换个图片！
如果你还看不明白的话，让小编给你来解释一下吧！
这么来说，基因测序公司对接腾讯云后，借助腾讯云全球多地数据中心以及线的网络，可轻松将级乃至级数据上传至云端，并安全高效的将基因数据分发给用户。腾讯超算云针对基因测序企业提供高性能高稳定性的云服务解决方案，可提供多元的计算资源满足不同客户的业务需求，不仅降低基因测序企业的硬件投入成本、节省开发成本和人工成本，更使得基因测序越来越标准化规模化。从此基因测序公司就如坐上了一艘火箭，完全不用担心底层资源，专注于自身的基因测序业务和创新，嗖嗖往前飞就好。都看到这里了，我相信你对超算云是非常感兴趣了喽。来，给你上点儿干货，真的很干哦！
作为云上的腾讯超算云，对基因测序的影响是普惠大众的。这可不是随便说的哦！
深圳碳云智能科技有限公司是目前中国领先的专业百万健康数据收集平台。基因测序对计算资源要求多样，短时间需要扩展上万核计算，同时需要、等异构资源的灵活配置，而传统的集群无法满足上述要求，并且基因数据需要大容量安全可靠的归档存储，但传统存储价格偏高，建设周期长，无法满足业务增长需求。碳云智能通过腾讯超算云，实现了在分钟级别创建动辄上千核、数百  的  集群。计算集群的稳定性和实时性得到极大提升，减少了人工投入，进而极大程度地节约了成本。同时利用腾讯云丰富的异构资源，还实现了图像识别等新兴业务。
相信在未来，有超算云助阵的基因测序，会帮助到更多人及早发现疾病，甚至挽救生命。未来可能只需要十分钟，医生就能及时发现患者携带遗传性心律失常的基因，根据基因检测的结果，为患者制定针对性的健康生活方案，减少患者心脏病发导致猝死，避免成为“新闻头条猝死主角”的风险。
女神安吉丽娜·朱莉，如果知道超算云和基因测序这么美妙的融合，可以普惠大众，本着她热爱公益的心，相信她也肯定愿意来给这个以云为源动力，连接智能未来，带来智慧生活的腾讯云而打。作者：，腾讯游戏漏洞测试高级工程师

一、项目背景
外挂的危害
随着智能手机的全面普及和市场泛娱乐化，移动游戏行业发展迅猛，无论是市场收入还是用户规模，手游在游戏市场上已经占据了半壁江山。如此火热的市场吸引了大量外挂、辅助工作室等非法盈利团队，严重影响了游戏的收益、平衡，缩短游戏的生命周期，外挂对手游形成了这些危害：

图：手游外挂的八大危害 
为了避免这些损害，腾讯游戏内部的测试流程已经将“手游安全测试”设立为必经环节，腾讯大部分手游上线前都会进行手游安全测试，《王者荣耀》、《穿越火线：枪战王者》，《梦幻诛仙》等六星级游戏更是每一个版本都主动寻求手游漏洞扫描。《龙之谷手游》同样也是如此。
《龙之谷手游》的加入
《龙之谷》在端游时代遭受过游戏外挂“洗礼”，从简单的游戏内存修改、变速齿轮到后面越演越烈倍攻击挂、无敌挂、穿墙挂，曾经一度被玩家称作“外挂谷”。《龙之谷手游》依然延续端游类的玩法与类型，原汁原味还原端游经典，在手游版本发布前，游戏测试和运营团队将游戏安全性作为一个重要专项来持续开展。
为了吸取端游的历史教训，避免手游上线后再次出现游戏外挂，《龙之谷手游》测试团队选择与腾讯合作，使用手游安全测试专家模式，对游戏的客户端、服务器、以及通信协议方面的安全质量进行全面检测和把控。在顺利上线后，腾讯团队整理了《龙之谷手游》安全测试过程中的一些思路和实践内容，对外分享。
二、技术难点
手游的使用场景与传统有着巨大的差异，不同的游戏玩法， 技术实现都不一样，因此手游安全测试团队需要对每一个游戏，都从零开始研究游戏内部实现架构。
经过分析，《龙之谷手游》使用 组件来实现协议数据通信，而腾讯手游安全测试团队具备等主流协议结构的自动接入和解析技术，无需利用文件自动提取游戏协议结构代码，自动分析游戏通信协议明文点，完成通信协议工具接入。《龙之谷手游》属于重度类型，带有实时玩法，包含多种类型副本、小游戏玩法、公会、家园、天梯赛、英雄战场、世界等多个功能系统，如何在短时间内完成全量内容的漏洞检测是当时面临的最大挑战。手游安全测试团队一方面使用函数风险智能分析系统、盗刷漏洞扫描和拒绝服务攻击扫描对游戏进行一轮漏洞自动化检测，另一方面根据各功能风险性和优先级对游戏的战斗系统、交易所和战力成长系统进行深度分析和漏洞挖掘。

图：函数风险智能分析流程
三、实现方案
测试目标
根据手游安全测试团队对腾讯游戏多年的测试经验，手游安全漏洞主要会出现在客户端、游戏逻辑和服务器三个层面，为了整体全面的发现手游外挂情况，测试团队将手游外挂的风险项细化情况如下：

测试前的分析
前文提到不同手游玩法都会使用不同的技术实现，因此在《龙之谷手游》安全测试之初，团队对游戏进行了一个详细的分析与拆解。
游戏实现——拆分游戏玩法中风险节点
分析过程中，测试团队发现《龙之谷手游》的 “战斗系统”和“交易系统”是手游漏洞产生的高危模块，下文也将从这两块出发，拆分其中的风险节点。
战斗系统——单机模式与多人联机模式结合

《龙之谷手游》核心玩法包括和战斗系统以及各种模式的副本单机模式：主线副本属于单机模式，战斗过程完全在客户端侧实现，测试中可重点通过内存修改和函数修改来挖掘漏洞；

多人联机模式：巢穴副本、天梯赛、保卫队长等属于多人联机模式，战斗过程的实现由客户端和服务器相互配合来完成。根据实现，优先采用协议测试工具进行漏洞挖掘，在验证部分风险项时仍然要使用客户端的内存、函数、变速测试工具。


交易系统——游戏道具流通的核心枢纽
游戏允许玩家通过交易所进行物品交易流通，安全漏洞的影响面将会被交易系统进一步放大，也是需要优先进行外挂检测和漏洞挖掘的内容。
对于手游玩法的具体拆分，可见下图的安全风险分析示例部分：

图：《龙之谷手游》风险分析片段
安全风险项下钻分析示例部分：

图：《龙之谷手游》安全风险项下钻分析
除上述外挂风险以外，服务器端程序的健壮性也需要通过拒绝服务攻击扫描进行宕机风险的检测。
根据对于《龙之谷手游》的拆分，测试团队基本确认游戏核心玩法在于多人联机的或模式以及其丰富的交易系统，因此团队也将测试的策略调整为“协议测试为主，函数及内存修改测试为辅“。
游戏引擎——针对引擎与实现寻找突破口
游戏使用引擎开发，该类型游戏游戏源代码一般会使用、、中的一种或多种。经过分析《龙之谷》客户端部分代码逻辑是使用脚本语言，不过出于安全性考虑，研发团队已经将游戏安装包中客户端逻辑代码文件进行了加密，所以在逆向分析前要进行该文件的解密操作获取明文。获取明文源码的办法比较多：
、逆向解密函数，利用游戏解密函数解密；
、在游戏运行过程中将从内存中出来；
、 函数______和___ 也可以获取明文源码。

游戏某版本测试后发现安全问题
游戏风险分析完成后，漏洞挖掘的工作其实就完成了一大半，之后利用安全测试工具对风险进行逐一验证即可。在游戏中发现以下几种类型的漏洞，均属于致命级漏洞：
类型一：外挂类漏洞
   模式加速移动
   主线副本存在无敌秒杀、全屏攻击等大量安全漏洞
“天梯加速”漏洞视频：
无敌全屏秒杀”漏洞视频：
类型二：盗刷类漏洞
   拍卖可任意复制物品，无限盗刷龙币
   驱逐家园中的妖精可无限盗刷奖励
“拍卖所复制物品”漏洞视频：
类型三：宕机类漏洞
   图鉴分解请求中，构造异常图鉴引发服务器宕机
   图鉴分解请求中，构造异常图鉴数量引发服务器宕机
   公会、竞技场、图鉴商店的购买请求中，构造异常的物品数量引发服务器宕机
   纹章洗练请求中，构造异常的洗练次数引发服务器宕机
解决方法
外挂类漏洞

变速漏洞实现方式有多种，相应也有多种修复方案。可监控系统时间相关函数是否被篡改来检测通用变速器类的修改器；针对修改游戏内部保存角色移动速度变量的内存，也可以通过内存加密、设置影子变量和服务器坐标校验等方式来解决。

对单机副本外挂类漏洞的处理，可从副本结算请求的内容上做文章。如加入副本挑战序列号来防止结算重发；加入、或一些冗余信息来防止结算请求被篡改；加入战斗过程数据采样甚至隐形通过服务器安全策略校验，来防止无敌秒杀全屏攻击等类型外挂。


盗刷类漏洞

服务器处理购买、结算等物品发放请求时，需要加强对请求中各项信息合法性校验，另外运营侧可以接入运营经分系统，对各种道具和金钱的产出进行实时监控与告警。

宕机类漏洞

因程序健壮性导致的服务器宕机漏洞被检测出之后，修复起来比较简单，针对性做好异常值处理就能够修复。

四、最终效果
在项目测试阶段，手游安全测试团队累积为《龙之谷手游》挖掘出了个致命级漏洞，个高危级漏洞，个中危级漏洞，将潜伏在游戏中的龙币盗刷、外挂、服务器宕机等各类致命级、高危级漏洞提前揭露出来，提前制定修复方案进行修复，并评估和验收结果与风险。手游安全漏洞的测试为《龙之谷手游》项目组避免了经济损失，为游戏正式开启不删档，为用户提供安全、公平、健康的游戏环境提供了坚实支撑和保障。
关于腾讯手游安全测试团队

腾讯手游安全测试团队从年初开始对手游安全领域进行探索和技术积累，旨在通过提前发现游戏版本的安全漏洞，预警风险，打造出业界领先的手游安全测试技术方案，在工具上已经支持所有腾讯在研和运营的手游项目。团队通过使用与正式服同样的游戏客户端和服务器，模拟外挂工作室制作外挂的过程，依靠自身的技术积累来提高专业程度，持续保持漏洞的发现率。
目前提供了专家测试服务，希望通过提前发现游戏版本的安全漏洞，预警风险，帮助提高腾讯游戏的品牌和口碑。
服务目前已经登陆腾讯云，欢迎前来使用 
手游安全测试接入流程：
常见问题：

亲爱的读者，为了能够提供更好的网站内容，希望您填写我们的问卷，我们会随机抽取读者回馈币以示感谢！问卷入口：
商业转载请联系腾讯获得授权，非商业转载请注明出处。 
原文链接：阻击外挂——《龙之谷手游》安全测试的那点事采访  孟岩

导读
周志华教授是蜚声国内外的机器学习专家，也是本届中国人工智能大会的主席之一。他的《机器学习》年月出版之后，迅速成为这个领域的一本权威教材，在一年半的时间里重印十几次，发行逾万册，并被冠以“西瓜书”的昵称，成为这一轮  热潮的一个重要注脚。周志华教授潜心学术，为人低调，极少接受采访。这次中国人工智能大会上，由会议安排，他破例接受了我们的专访，就很多重要问题坦率的谈了自己的看法。我们特将内容整理成文，以飨读者。
大反转难免会有，盲目追捧深度学习有危险
科技大本营：感谢周教授接受采访。先谈谈当下最火的深度学习。河南大学的张重生教授在他的《深度学习》一书里摘录了你的一段话，是这么说的：

有点幽默，但很朴实，深度学习现在差不多就是民工活，调来调去，刷来刷去。文章发得飞快，貌似热闹，但有多少是能积淀下来的实质真进展，又有多少是换个数据就不靠谱了的蒙事撞大运？既缺乏清澈干净的内在美感，又不致力于去伪存真、正本清源，只图热闹好看，迟早把  变成废纸堆。

看来，对今天深度学习火爆的局面，您有您的不以为然。能否详细的解释一下您的观点？
周志华：不要误会，深度学习技术本身确实非常有用，能解决很多难题。有问题的是我看到国内的一种态势，什么东西一热起来，大家一拥而上，把所有其他东西全部都忽略了，好像机器学习乃至人工智能里面只有深度学习，这是很大的问题。
深度学习中间还有很多困难而又重要的问题值得深入研究，但这些真正值得研究的问题，就我看到的情况而言，好像做的人非常少。大多数人在干什么呢？拿它做做应用，调调参数，性能刷几个点，然后发几篇文章。这样虽然容易发表文章，但恐怕很难产生有影响的成果。工业界倒是没什么，不管用什么技术，产品性能提升了就好，但是学术界这样就不太正常了，都去做深度学习的应用，不去研究深度学习机器学习里面更本质的问题，我担心很多年轻人的聪明才智被耽误了。
另一方面，如果所有的人都只看到深度学习，忽略了其他研究内容，这是相当危险的。例如我们回顾一下，年左右的时候，有多少人意识到神经网络技术很有用了？很少。但其实这方面早在年左右的时候就已经突破了。那么当时为什么意识不到呢？因为大家都在追热门，而神经网络当时是冷门。这样的事情会不会重演？也许年之后很重要的技术，今天已经有苗头了，如果我们全都扑向深度学习，根本不去关心其他的东西，那会不会把未来丢掉了？
科技大本营：现在很多人都想学习深度学习，沾沾仙气。一般来说学习深度学习，总还是要具备一个比较完整的机器学习基础。但现在很多人不学机器学习基础课，一上来就搞深度学习，好像也能学得会，您赞成这种速成法吗？
周志华：这要看学习的目的是什么。
如果仅仅是为了使用现有的深度学习工具去做应用、解决已经清楚定义好的任务，那么可以去学速成法。只不过，这样的工作很容易被其他人替代。如果学习的目的是为了深入理解，为了在深度学习的研究里面有自己的创新，或者为了自如地解决那些没人给你清楚定义好的任务，那么恐怕还是要从打好基础开始。这就像武侠小说里的“正宗功夫”要慢慢打基础，“邪门功夫”上手快、短期内更“厉害”，但是到了后来，邪门功夫到了一定程度就会上不去了。
科技大本营：也就是说您认为深度学习是对传统方法的一次反转，而未来还会有别的方法来反转深度学习。您觉得这个可能性有多大？
周志华：“反转”这个词未必合适，但是必然会有更强的技术出现。
科技大本营：会是什么？概率图模型还有戏吗？
周志华：我们没法准确的“预知未来”。我想我们应该去关注一些重要的问题，这些问题在什么时候能得到解决，就可能带来新的突破。这涉及到很多其他方面的因素甚至机遇，没法能够事先规划出来下一个东西爆发点在哪。所以我觉得我们千万不要把眼光局限在一个地方。至于概率图模型，它有它的短板，也有它擅长的问题。
科技大本营：我知道您偏爱集成学习方法。现在的随机森林算法、 算法，效果很好，非常流行。不过我们都知道机器学习有所谓的“   ”，也就是说对于一般的问题，任意两种机器学习算法的期望性能都相同，没有哪一种方法是有绝对优势的。可是现实情况是，在  和其他的机器学习大赛当中，深度学习和  基本上一统天下。这种情况为什么会出现？
周志华：机器学习技术解决现实问题的时候，通常要“度身定做”，根据问题的特性去对方法做改造、甚至设计出专门的新方法，才能有更好的效果。但是能这样做的人不多，需要很资深的专家。之类的比赛里面，普通级别的玩家比较多，这时候比较热门流行的技术就比较容易被关注、被尝试，并且深度学习和都有现成的工具，很容易就被拿来用。不过我们应该意识到，在某个比赛上获得优胜的方法，未必是在这个任务上最优秀的技术。因为比赛的名次和很多东西有关，例如两种不同的方法，使用的人经验不同、花的功夫不同、使用的资源不同，最后的名次是因为方法本身的差别导致的，还是其他因素导致的，很难说。
科技大本营：您前一段时间发表了一篇文章，提出了   算法，引起广泛的关注。它是怎么出来的？现在进行到什么阶段了？
周志华：这个工作是希望能打开一个新的方向。今天在很多涉及到图像、声音的任务中，深度学习表现很出色。我们可以从两方面来看。一方面，现在当大家说到深度学习的时候，基本上就是在谈深度神经网络，甚至很多人认为深度学习只能通过神经网络来做。那么，深度学习是不是只能通过神经网络做？用别的结构行不行？这在理论上是很重要的一个问题。因为神经网络基本部件是可微分的，这直接导致了后续误差逆传播等技术选择，而现实世界当中并不是所有的规律都是平滑可微分的，非要用可微分的部件来建模，一定是最佳路径吗？而且机器学习中有很多类型的部件，其中相当一部分是不可微分的，基于这些部件能不能进行深度学习？这些问题我们希望探索一下，可能会产生新的启发。
另一方面，从应用的角度看，虽然今天深度神经网络在很多任务上性能很好，但仍然有很多任务，像随机森林这样的技术表现出色，甚至比深度学习效果还好。那么，如果能做出深度森林来，会不会在这些任务上有更好的结果呢？从某种意义上说，相当于是把深度学习的适用范围推广到更多的任务上去，这是它在应用上的价值。
就这个工作来说，我们更关心的是这条路能不能走，毕竟这是一条新的道路。如果能走，性能改进和效率提升是后面的事，有很大的空间。至于能走多远，现在我们也不清楚。就像来年前，卷积神经网络刚出来的时候，没人预料到它后来掀起了深度学习的热潮。
科技大本营：所以   不是小打小闹，是您战略性的研究方向，是不是这样？
周志华：这个工作确实考虑了很长时间。它主要是关于我关心的两个问题，第一个是基于不可微分的部件怎么做成深度模型，第二是对于集成方法和基于树的结构，我们有没有办法通过引入深度学习的思想把它的性能做的更好。这两个在机器学习中应该算是比较重要和基本的问题。
西瓜书是希望帮助读者了解机器学习的全貌
科技大本营：我们谈您的书，现在大家昵称为西瓜书，我买的时候发行了万册，现在有万册了吧。
周志华：、万左右。

科技大本营：那我估计是世界上发行量最大的一本机器学习专著了。这本书您说得很清楚，是一本教材。但是据我所知，还有很大一部分在职工程师甚至技术管理者也在读。我听到两个截然不同的评价。我有一个做计算机视觉的朋友，公司在国内还挺有名气，他喜欢直接从学校里面招人，招大三或者研二的优秀学生，拉过来培训、实习。培训的时候要讲机器学习大基础课，指定用您的书做教材，效果特别好。他们也跟一些国外的名著做了比较，发现就是西瓜书最好用。这是很好的正面的评价。另外一个评价，我有另一个朋友做移动互联网，他让他非常有经验的工程师买您的书学机器学习，结果这些工程师都叫苦，说看不懂。您怎么评价这两个截然不同的反馈？
周志华：这本书主要是希望在较少的篇幅内，以相对轻松的方式帮助读者对机器学习有一个全面的了解。
它最主要的用途，一是为初学者了解机器学习领域整体的轮廓，知道机器学习里大概有哪些东西，以便以后根据自己的需求和兴趣进一步深入学习，另一个是在读者阅读了许多材料之后，对知识体系做一个梳理。其实在机器学习里面，关于某个具体分支话题的书籍或阅读材料很多，但是以全面的、没有学派偏见的方式来介绍机器学习全貌，这样的读物不多，这本书算是这个方向的一个努力。
另外，由于着眼点是帮助读者建立机器学习大局观，这本书更多的是关于机器学习中的一些“思想”和“道理”，而不是一个算法速查手册，为了确保每章篇幅不要太长，不重要的细节会比较简略。
所以如同我在前言、后记里面一直强调的，这是一本教科书，老师可以根据学生的情况来决定如何发挥。如果自学的话，建议读者先不要纠缠在细节上，而是利用本书建立了整体框架之后，根据阅读材料的指引去做进一步了解，然后再回到本书做一个重新梳理。
如果是希望很短的时间内上手，学习使用现有的机器学习算法、工具去做应用，去解决已经清楚定义好的任务，那么这本书可能不是最合适的，直接面向速成应用的书可能更合适一些。另外，如果只希望知道一些算法是怎么工作的，不关心它为什么是这样，那么这本书可能也不是最合适的，一些算法速查手册类型的书更合适。
科技大本营：现在类似 这样的工具，已经做到了流水线化，把十几种模型串在一起，跑一晚上，早上起来，哪一个模型最好、哪一组参数匹配效果最佳，就都知道了。您那本书都不用看，看一下线上的手册就可以上工了，而且其实现在企业还愿意为这样的人付高薪。您觉得这样的人有什么问题吗？
周志华：没什么问题，取向不同而已。拿修大楼来打一个比方，建筑工人只要能照着现成的图纸把砖砌好就可以了，建筑工地需求量很大的时候，能砌好砖也许就能拿不错的工资。但有朝一日，你想自己设计大楼，就必须懂得一些思想。现在机器学习方面的人员需求量非常大，远远供不应求，所以一些相对低端的事情也可以拿到高薪，但我相信这方面的人员缺口很容易补上，多了之后，企业很自然会需要有更深入理解的人、专家级别的人，而这类人才的缺口补起来就很困难了。
科技大本营：那如果我本身是个工程师，有工作，但是也想深入研究一下机器学习，不满足于就是用用工具，还是希望能够在这个领域达到一个比较高的水平，做一个有思想的人，有深入理解的人，我该怎么办？
周志华：可以先看一些操作型的材料，会用工具，能应付本职日常工作。然后有时间的话，阅读一些着眼于介绍某几种常用具体算法的书。如果还希望进一步理解算法背后的思想和道理以便融会贯通，那就再进一步阅读全面介绍机器学习的书籍，我的书在这方面可以作为一个基础读物。这样的学习过程对希望全面建构机器学习知识体系的读者不是最佳，但是对工程人员，考虑到平时能拿出来的完整时间不多，数理基础可能也相对生疏了，也许这样的过程比较可行。
科技大本营：您会出视频教程吗？
周志华：教学需要因材施教。在课堂上我能看到学生有什么样的反应，我才知道下面应该怎么讲。每样材料都可以有多种阐述方式，要根据学生的反应来调整。视频上没法做到。
计算机科学的使命是用计算机去认识和改造世界
科技大本营：您在西瓜书的序言里面写过，当年在图书馆里面翻到一本机器学习的书就决定投身机器学习这个行业里面了。您为什么当时看了这样一本机器学习的书就确定这是您的重要方向呢？我相信您不止看了一本书，有很多的方向摆在您面前，您怎么那么有先见之明就挑了这么个未来大热门？
周志华：那是一本文集，《机器学习：一种人工智能途径》，今天一般认为它是关于机器学习的第一本专门文献。里面有很多先驱写的文章。其实这样的“老读物”很值得读，里面的一些思想即便在今天也很有指导意义。
确实看过很多其他的书，在人工智能里面很多分支领域的材料都读过一些。我很赞同图灵奖得主的一句话，他说“计算机科学并不仅是关于计算机，就像天文学并不仅是关于望远镜”。天文学的研究早期是关注如何建造更好的望远镜，但是到了后来，主要是在关注如何“用”望远镜开展研究。计算机科学的研究一开始当然也是关注如何“造”计算机，让计算机更好地运转，但是未来当然是要关注如何“用”计算机去认识和改造世界。这里面最重要的无疑是用计算机来对数据进行分析，因为这是计算的主要目的，而这恰好是机器学习的主要用处。
科技大本营：您当时就看得这么清楚了？这很不容易呀，九十年代的计算机科学也是琳琅满目，您怎么那么笃定？那个时候在国内搞机器学习是很孤独的，一般人很难支持，也需要很大的毅力，你怎么就那么笃信一定会起来。
周志华：坚持自己的判断，做自己认为重要的事吧。为何选用服务器进行测试
 协议因其易用性和普适性得到了大规模的普及，我们说协议是互联网的基石一点也不为过，当前提供服务的性能要求越来越高，如何提高  服务器的性能变得非常重要。近年来网卡性能快速发展，给高性能服务提供了硬件支持，但是 内核却越来越成为高性能网络服务器的瓶颈。
 的传输层协议为  ，作为面向连接的协议能够提供可靠传输，但是在性能有非常大的短板，尤其在短连接网络业务服务中，受限于表锁竞争等因素，系统内核大并发创建  连接的性能非常低。实际服务开发中我们一般会尽量使用长连接来优化网络性能，但是在部分面向终端用户的业务中很难完全使用长连接，而且即便是长连接，其性能在某些应用上依然无法让人满意。
为了提高网络服务器性能，业界提出了好几个   方案，比如 、、_等，这些方法的入门槛较高，而且主要是提供二层的收发包能力，没有提供完整的协议栈能力。  提供了一个低门槛、高性能、完整协议栈能力的网络服务器解决方案， 使用   开发套件提高网络收发包性能，移植  协议栈至用户态，提供了  和 微线程的编程接口，并集成了  等实用应用程序，适用大部分的  网络服务器场景并尽量降低业务接入  的接入门槛， 网络服务器无需改动业务代码或替换系统的网络即可快速接入，并获得更高的性能。
名词解释
：是一个全用户态的高性能的网络接入开发包，基于、协议栈、微线程接口等，适用于各种需要网络接入的业务，用户只需要关注业务逻辑，简单的接入即可实现高性能的网络服务器。
：  ，每秒钟新建断开连接数，本文主要指服务器每秒钟可以建立的  连接数。
：  ，每秒钟事务数，在本文中指从客户端发起并完成一个完整的  请求，过程包括建立  连接，发起  请求， 服务器接收并回复  大小为字节的数据总数据包大小为，客户端接收完成相应数据，断开连接。
测试表现
本节介绍  在适用于不同业务场景状态下的测试及结果表现，所有测试数据由  直接返回内存中缓存的数据，实际业务性能还受业务逻辑的影响，具体测试环境如下：
网卡       
      
内存：
操作系统    
内核版本：
数据包大小：  字节   字节或   字节仅达到线速的测试使用该大小，包越大整体带宽表现会越好。
短连接
腾讯云的  服务是一个典型的短连接服务，受限于系统内核  的性能瓶颈，在万兆网卡上原系统性能只有万 。在接入  之后，性能可以达到百万 ， 使用了多进程的架构，每个进程有单独的协议栈，无资源共享和竞争，虽然单进程协议栈提升并不明显约，但是整体系统性能有了质的提升。下图为  上进行短连接的   测试数据。

混合连接
腾讯云的  业务是主要使用长连接的业务，长连接能大幅提升用户的访问速度，但是在实际用户访问统计中，平均一个  连接只会处理个  请求，系统内核的  性能瓶颈依然会极大影响  的整体性能，而且即便单个连接处理更多的请求，其性能差距依然十分巨大。下图为使用  与系统内核进行的对比测试结果，分别为每个连接处理个和个  请求。
每个连接处理个请求每个连接处理个请求
长连接
当数据传输不涉及到终端用户时，就比较容易在服务器间使用长连接提提升性能，且随着处理的数据包越来越大时，系统内核  性能瓶颈的影响将会逐渐减小，如长连接大包的业务场景下使用系统内核依然能达到  网卡的线速。
但是  此时依然有其实用价值，因为  除了多进程对共享资源的优化外，全用户态的协议栈同时也对锁竞争、内存拷贝、中断处理、上下文切换等进行了优化，能够消耗更少的资源达到相同的性能表现。 下图为长连接场景下小文件典型场景如通信服务器之间的数据传输与较大文件典型场景如  业务中边缘节点和中间源间的数据传输时  与系统内核的对比测试。
长连接小文件表示未将网卡队列中断到不同长连接较大文件
交流
 欢迎业务使用、 或者加入开发、 顺便一下我们的项目，有任何问题可以提或直接联系我们。官方网站，官网资源持续完善中，如果您的项目使用了 ，也希望通知我们，让我们加入到应用列表中。微信公众号：搜索公众号  关注，会不定期发布的技术细节、使用技巧和应用场景等文章，同时欢迎投稿。 提供了  来记录来源  的地理位置信息，但  所依赖的  库是收费项目，免费的模块只能区分国家信息，不大适合在线上使用。而  另外也提供了  指令，一直以为  库比较庞大， 加载的时候开销会增加，以前特意试了下，其实情况还很不错。
 指令介绍



语法
   




默认值



上下文




 指令主要是可以根据指定变量的值映射出一个新变量。 如果不指定变量，默认为_，从   开始，可以根据任意变量映射新变量。



指令
用法解释





删除指定的网络，从   开始支持



默认值。 如果使用 ，可以用“”或代替 ，如果  没有指定，则默认值为空字符串。



包含一个定义地址和值的文件，可以包含多个。



定义可信地址 。 如果请求来自可信地址， 将使用其“”头来获得地址。 相对于普通地址，可信地址是顺序检测的。从   和  开始支持 。


_
开启递归查找地址 。 如果关闭递归查找，在客户端地址与某个可信地址匹配时， 将使用“”中的最后一个地址来代替原始客户端地址。如果开启递归查找，在客户端地址与某个可信地址匹配时， 将使用“”中最后一个与所有可信地址都不匹配的地址来代替原始客户端地址。



使用以地址段的形式定义地址，这个参数必须放在首位。为了加速装载地址库，地址应按升序定义。



 库收敛
没有进行收敛的  库行数很多，有的文件还特别大，加载起来比较慢，所以进行  库的收敛以减少库文件的大小，还是很有必要的。
 库来自于  和视频的修改版本，为了减少存储，特意将国家和省份的中文转换为英文，部分运营商的中文就没有简化了，可按  的标准简化为数字代码。

 是英文   的缩写，意思是全局负载均衡。

 的拼音版本见附件 __。
 网段收敛的工具来自于以前写的一个单线程的程序，处理上千万行的文本时，内存不够用了，如果要处理的文本过大，得手工分割下，多次收敛后再合并。因为没法贴附件，如果需要可以在评论区留言。
利用该工具，针对国家、省份和运营商三个维度进行了收敛，收敛后三个文件不到 。如果有必要，也可以针对城市再进行收敛。
另外，港澳台既在国家地区里，另外又在中国的省份文件里。
中国运营商映射文件
收敛后的文件扩展名为，方便  进  的配置文件。按运营商收敛后， 段共  行。
 _ {
        
               
              
             
               
              
               
        
}
国家地区映射文件
 的  库引入了很多干扰项，譬如组播地址、内网地址、保留地址都对应了地理位置，为了保证纯粹性，下载了  年  月  日的  库文件，提取了国家和地区信息。
去掉了部分内网和多播网段，按国家收敛后有  行。
  _ {
        
               
               
               
              
             
             
            
           
               
               
        
}
中国省份映射文件
国内按省份收敛后有  行。
 _ {
        
               
              
             
               
               
              
               
               
               
               
        
}
应用场景
网上说的用  来做负载均衡来调度，不大靠谱，不适合腾讯网之类的大网站，不过比较适合各地都有站点的地方站、论坛、城市、房产、旅游等网站，可以根据访客地理位置将请求  到特定站点。
另外，最常规的应用，就是将_、_、_ 三个变量加到日志格式定义里，这样，在日志里就可看到每次请求的地理位置，以供后续的统计分析。
使用方法
将这三个  文件放置在  安装目录的  子目录下，然后用下述指令包含进去，前面说的三个变量就可以用了。
  
效果
下面简单列出了  月  日  点前每个省的访问次数分布图，后续也可很容易分析出跨省跨网访问趋势来。
性能消耗
找了  台  年的 ，活动连接不到  万，出入包量各在  万左右，在  里加载了这  个文件，性能消耗基本可以忽略不计。
启动时间
加载起来很快，大大出乎我的意料， 加载的是  的  库，有段时间文件非常大，加载起来都是以分钟计的，所以以前对  库的加载一直有阴影，看来加载个  的文件，基本无影响。
    

    
    
     
性能
加载的时候负载有上升 ，稍后又恢复， 基本看不出变化。月日晚，腾讯云技术社区举行第一期线上技术公开课直播，共有近  人关注，实时最高  多人同时在线观看。
许多网友在本期公开课的活动页面下留下了自己对本次活动的评价以及建议。在准备后续公开课直播时，我们会积极考虑各位网友的建议。
另外，凡是符合活动期间获赠代金券条件的网友，我们已经在昨天中午点前通过后台向大家下发了相应金额的代金券，请大家前往代金券管理页面查看。
为了方便大家回顾直播内容，我们已经剪辑好了相关视频，包括：

嘉宾分享：腾讯云架构演变及经验

当前浏览器不能支持视频播放，请采用或以上浏览器

助教演示：搭建高可用站点

当前浏览器不能支持视频播放，请采用或以上浏览器
以上视频可在腾讯云课堂查看。
欢迎大家关注腾讯云技术社区 —— 腾云阁，了解最新技术公开课直播安排。做过面向公网  的运维人员经常会遇见恶意扫描、拉取、注入等图谋不轨的行为，对于直接对外的  服务器，我们可以直接通过  、 的  指令或是程序来  掉这些恶意请求。
而对于套了一层  或代理的网站，这些方法可能就失效了。尤其是个人网站，可能就一台，然后套一个免费的  就行走在互联网了。并不是每个  都能精准的拦截各种恶意请求的，更闹心的是很多  还不支持用户在  上添加  规则，比如腾讯云 。
因此，就有了本文的折腾分享。
一、真假难辨
如何禁止访问，我们先了解下常见的种网站访问模式：

用户直接访问对外服务的普通网站：浏览器  解析  数据处理  数据吐到浏览器渲染展示。

用户访问使用了的网站：浏览器  解析  节点  数据处理  数据吐到浏览器渲染展示。

用户通过代理上网访问了我们的网站：浏览器  代理上网  解析  上述种模式均可能。


对于第一种模式，我要禁止这个用户的访问很简单，可以直接通过  或者 的指令来禁止均可：
：     用户   的指令： 语    法       |  |  |  默认值     — 配置段        _顺   序：从上往下 ：  { 用户或段}
但对于后面种模式就无能为力了，因为  和  都只能针对直连，而后面种模式中，服务器直连是节点或者代理服务器，此时使用  或  就只能把 节点 或代理给封了，可能误杀一大片正常用户了，而真正的罪魁祸首轻轻松松换一个代理又能继续请求了。
那我们可以通过什么途径去解决以上问题呢？
二、火眼金睛
如果长期关注张戈博客的朋友，应该还记得之前转载过一篇分享  在  加速之后，获取用户真实  做并发访问限制的方法。说明  还是可以实实在在的拿到用户真实  地址的，那么事情就好办了。
要拿到用户真实 ，只要在  的  模块内加入如下配置：
获取用户真实，并赋值给变量
 ___   {
              _
        \  
}
那么，就是用户真实了，其实就是匹配了 ___ 的第一个值，具体原理前文也简单分享过：
其实，当一个  或者透明代理服务器把用户的请求转到后面服务器的时候，这个  服务器会在  的头中加入一个记录 ： 用户 代理服务器。如果中间经历了不止一个代理服务器，这个记录会是这样 ：用户 代理服务器 代理服务器 代理服务器 …可以看到经过好多层代理之后， 用户的真实 在第一个位置， 后面会跟一串中间代理服务器的地址，从这里取到用户真实的地址，针对这个  地址做限制就可以了。
而且代码中还配合使用了 _，因此 还能兼容上文中第种直接访问模式，不像 ___ 在直接访问模式中将会是空值！
所以， 还能配置到  日志格式中，替代传统的 _ 使用，推荐！
三、隔山打牛
既然已经拿到了真实，却不能使用  和  指令，是否无力感油然而生？
哈哈，在强大的  面前只要想得到，你就做得到！通过对  这个变量的判断，就能实现隔山打牛的目的，而且规则简单易懂：
如果真实为 、，那么返回
   | {
        如果你的安装了模块，还能如下输出语言，狠狠的发泄你的不满但不兼容返回试试吧！
        _  
                
         
        
}
把这个保存为 _ ，上传到  的  文件夹，然后在要生效的网站  模块中引入这个配置文件，并  重载  即可生效：
禁止某些用户访问
 _
如果再想添加其他要禁止的，只需要编辑这个文件，插入要禁止的，使用分隔符 | 隔开即可，记得每次修改都需要  重载 才能生效。
四、奇淫巧计
为了更方便的添加和删除这些黑名单，昨晚熬夜写了一个小脚本，一键添加和删除，懒人有福了！


                  
       

   ©                  


_=
_=_

_=      \ 
_=    \ 
_=    \     

_ {   {_}{_} }
_{   {_}{_}  }

_
{
 

                  
       

   ©                  


  


 |         
 |                
 |      _  
 |                
 |        


}

_
{
    _     \
    _    \
     
}

_
{
     {|  {==  =  \} _ 
}

_
{
      _ || _ _     
      _ || _ _      
    _=_ |    |  
     _
}

_
{
  _  \
_ _  
 _
 \   {
    _  
             
     
    
}

  _  \
_ _    \
 _  \
 

_ _    \
 

}

_
{
    _ 
         
          \| _  \
        _  \
        _    _  || \
        _    _ 
    
        _      
        
    
}

_
{
    _ 
         
          \|\||\ _  \
        _  \
        _    _  || \
        _    _ 
    
        _      
        
    
}

  
    | 
        _
        
        
    | 
        _
        
        
    | 
        _
    


   
      
        | 
            _ 
            
        | 
            _ 
            
         
            _
             
    
    

_
使用方法：

根据实际情况修改第、行  二进制文件及其配置文件路径

然后将此脚本保存为 _ 上传到服务器任意目录，比如放到 

给脚本赋予可执行权限：  _ 即可使用

使用参数：

 _ 

 |   显示帮助信息
 |   添加一个黑名单， 例如 _  
 |   初始化创建一个禁止的配置文件，需要自行 到需要的网站模块
 |   删除一个黑名单，例如 _  
 |   显示当前已拉黑清单



初次使用，先执行_ 创建一下  相关配置文件：_，默认内容如下：
    {
    _  
             
     
    
}
 是为了占位，规避为空的情况，实际使用中也请注意，必须要有一个占位，否则可能导致误杀哦！
生成这个文件之后，编辑网站对应的配置文件，比如 ，在  {}模块内部插入  _  注意有英文分号即可。
比如：

    {
            
        _ 
              
          

         _  新增此行
        其他略 
最后，使用   重载即可。
后面需要添加黑名单或删除黑名单都可以使用 _ 脚本来操作了！

最后，顺便说明一下，本文分享的方法仅作为使用网站遇到恶意的一种手工拉黑方案。而自动化限制的方案可以参考博客之前的分享：《在加速之后，获取用户真实做并发访问限制的方法》
好了，本文分享到此，希望对你有所帮助。
相关推荐：腾讯存储与免费体验双向认证配置指南虽然使用缓存思想似乎是一个很简单的事情，但是缓存机制却有一个核心的难点，就是——缓存清理。我们所说的缓存，都是保存一些数据，但是这些数据往往是会变化的，我们要针对这些变化，清理掉保存的“脏”数据，却可能不是那么容易。
首先我们来看看最简单的缓存数据——静态数据。这种数据往往在程序的运行时是不会变化的，比如服务器内存中缓存的文件数据，就是这种。事实上，所有的不是由外部用户上传的数据，都属于这种“运行时静态数据”。一般来说，我们对这种数据，可以采用两种建立缓存的方法：一是程序一启动，就一股脑把所有的静态数据从文件或者数据库读入内存；二就是程序启动的时候并不加载静态数据，而是等有用户访问相关数据的时候，才去加载，这也就是所谓 的做法。第一种方法编程比较简单，程序的内存启动后就稳定了，不太容易出现内存漏洞如果加载的缓存太多，程序在启动后立刻会因内存不足而退出，比较容易发现问题；第二种方法程序启动很快，但要对缓存占用的空间有所限制或者规划，否则如果要缓存的数据太多，可能会耗尽内存，导致在线服务中断。
一般来说，静态数据是不会“脏”的，因为没有用户会去写缓存中的数据。但是在实际工作中，我们的在线服务往往会需要“立刻”变更一些缓存数据。比如在门户网站上发布了一条新闻，我们会希望立刻让所有访问的用户都看到。按最简单的做法，我们一般只要重启一下服务器进程，内存中的缓存就会消失了。对于静态缓存的变化频率非常低的业务，这样是可以的，但是如果是新闻网站，就不能每隔几分钟就重启一下服务器进程，这样会影响大量在线用户的访问。常见的解决这类问题有两种处理策略：
第一种是使用控制命令。简单来说，就是在服务器进程上，开通一个实时的命令端口，我们可以通过网络数据包如包，或者系统信号如 进程号之类的手段，发送一个命令消息给服务器进程，让进程开始清理缓存。这种清理可能执行的是最简单的“全部清理”，也有的可以细致一点的，让命令消息中带有“想清理的数据”这样的信息，比如我们发送给服务器的清理消息网络包中会带一个字符串，表示要清理哪一个文件的缓存。这种做法的好处是清理的操作很精准，可以明确的控制清理的时间和数据。但是缺点就是比较繁琐，手工去编写发送这种命令很烦人，所以一般我们会把清理缓存命令的工作，编写到上传静态数据的工具当中，比如结合到网站的内容发布系统中，一旦编辑提交了一篇新的新闻，发布系统的程序就自动的发送一个清理消息给服务器。
第二种是使用字段判断逻辑。也就是服务器进程，会在每次读取缓存前，根据一些特征数据，快速的判断内存中的缓存和源数据内容，是否有不一致是否脏的地方，如果有不一致的地方，就自动清理这条数据的缓存。这种做法会消耗一部分，但是就不需要人工去处理清理缓存的事情，自动化程度很高。现在我们的浏览器和服务器之间，就有用这种机制：检查文件；或者检查文件最后更新时间。具体的做法，就是每次浏览器发起对服务器的请求时，除了发送给服务器外，还会发送一个缓存了此对应的文件内容的校验串、或者是此文件在服务器上的“最后更新时间”这个校验串和“最后更新时间”是第一次获的文件时一并从服务器获得的；服务器收到之后，就会把校验串或者最后更新时间，和磁盘上的目标文件进行对比，如果是一致的，说明这个文件没有被修改过缓存不是“脏”的，可以直接使用缓存。否则就会读取目标文件返回新的内容给浏览器。这种做法对于服务器性能是有一定消耗的，所以如果往往我们还会搭配其他的缓存清理机制来用，比如我们会在设置一个“超时检查”的机制：就是对于所有的缓存清理检查，我们都简单的看看缓存存在的时间是否“超时”了，如果超过了，才进行下一步的检查，这样就不用每次请求都去算或者看最后更新时间了。但是这样就存在“超时”时间内缓存变脏的可能性。

服务器静态缓存例子
上面说了运行时静态的缓存清理，现在说说运行时变化的缓存数据。在服务器程序运行期间，如果用户和服务器之间的交互，导致了缓存的数据产生了变化，就是所谓“运行时变化缓存”。比如我们玩网络游戏，登录之后的角色数据就会从数据库里读出来，进入服务器的缓存可能是堆内存或者、共享内存，在我们不断进行游戏操作的时候，对应的角色数据就会产生修改的操作，这种缓存数据就是“运行时变化的缓存”。这种运行时变化的数据，有读和写两个方面的清理问题：由于缓存的数据会变化，如果另外一个进程从数据库读你的角色数据，就会发现和当前游戏里的数据不一致；如果服务器进程突然结束了，你在游戏里升级，或者捡道具的数据可能会从内存缓存中消失，导致你白忙活了半天，这就是没有回写缓存写操作的清理导致的问题。这种情况在电子商务领域也很常见，最典型的就是火车票网上购买的系统，火车票数据缓存在内存必须有合适的清理机制，否则让两个买了同一张票就麻烦了，但如果不缓存，大量用户同时抢票，服务器也应对不过来。因此在运行时变化的数据缓存，应该有一些特别的缓存清理策略。
在实际运行业务中，运行变化的数据往往是根据使用用户的增多而增多的，因此首先要考虑的问题，就是缓存空间不够的可能性。我们不太可能把全部数据都放到缓存的空间里，也不可能清理缓存的时候就全部数据一起清理，所以我们一般要对数据进行分割，这种分割的策略常见的有两种：一种是按重要级来分割，一种是按使用部分分割。
先举例说说“按重要级分割”，在网络游戏中，同样是角色的数据，有些数据的变化可能会每次修改都立刻回写到数据库清理写缓存，其他一些数据的变化会延迟一段时间，甚至有些数据直到角色退出游戏才回写，如玩家的等级变化升级了，武器装备的获得和消耗，这些玩家非常看重的数据，基本上会立刻回写，这些就是所谓最重要的缓存数据。而玩家的经验值变化、当前、的变化，就会延迟一段时间才写，因为就算丢失了缓存，玩家也不会太过关注。最后有些比如玩家在房间地区里的坐标，对话聊天的记录，可能会退出时回写，甚至不回写。这个例子说的是“写缓存”的清理，下面说说“读缓存”的按重要级分割清理。

假如我们写一个网店系统，里面容纳了很多产品，这些产品有一些会被用户频繁检索到，比较热销，而另外一些商品则没那么热销。热销的商品的余额、销量、评价都会比较频繁的变化，而滞销的商品则变化很少。所以我们在设计的时候，就应该按照不同商品的访问频繁程度，来决定缓存哪些商品的数据。我们在设计缓存的结构时，就应该构建一个可以统计缓存读写次数的指标，如果有些数据的读写频率过低，或者空闲没有人读、写缓存时间超长，缓存应该主动清理掉这些数据，以便其他新的数据能进入缓存。这种策略也叫做“冷热交换”策略。实现“冷热交换”的策略时，关键是要定义一个合理的冷热统计算法。一些固定的指标和算法，往往并不能很好的应对不同硬件、不同网络情况下的变化，所以现在人们普遍会用一些动态的算法，如就采用了种，他们是：
根据过期时间，清理最长时间没用过的
根据过期时间，清理即将过期的
根据过期时间，任意清理一个
无论是否过期，随机清理
无论是否过期，根据原则清理：所谓，就是  ，最近最久未使用过。这个原则的思想是：如果一个数据在最近一段时间没有被访问到，那么在将来他被访问的可能性也很小。是在操作系统中很常见的一种原则，比如内存的页面置换算法也包括等，对于的实现，还是非常有技巧的，但是本文就不详细去说明如何实现，留待大家上网搜索“”关键字学习。

数据缓存的清理策略其实远不止上面所说的这些，要用好缓存这个武器，就要仔细研究需要缓存的数据特征，他们的读写分布，数据之中的差别。然后最大化的利用业务领域的知识，来设计最合理的缓存清理策略。这个世界上不存在万能的优化缓存清理策略，只存在针对业务领域最优化的策略，这需要我们程序员深入理解业务领域，去发现数据背后的规律。

相关推荐上一篇  高性能服务器架构思路：缓冲策略  一  下一篇 高性能服务器架构思路：分布式系统概念  三 关于作者：蓝邦珏，腾讯前端工程师，年加入腾讯增值产品部，期间主要负责过手阅读、手动漫项目的业务开发。业余喜欢折腾前端新技术和写文章。 

作为前端，我们常常会和  有着频繁的接触。比如使用  对项目进行构建的时候，我们会使用  接口将匹配到的文件转为 流的形式，再通过  接口对其进行链式加工处理；
或者比如我们通过  模块创建一个  服务：
  = 
   = {  }
此处的  和  也属于  的消费接口前者为  ，后者为  。
事实上像上述的 ，或者  等接口都属于  的实例，因此较少存在情况，是需要我们手动引入  模块的，例如：
 
  = 
  = 
  = 
  = 
  = 
_ = ={    
     == {
                   
         
    }
    
}

如果不太能读懂上述代码，或者对  的概念感到模糊，那么可以放轻松，因为本文会进一步地对  进行剖析，并且谈谈直接使用它可能会存在的一些问题这也是为何  要使用  的原因。
另外本文的示例均可在我的  仓库 获取到，读者可以自行下载和调试。
一 的作用
在介绍 流之前，我们先来看一个例子 —— 模拟服务器把本地某个文件内容吐给客户端：



  =   = 
  =    {
    __      {
        
    }
}

这段代码虽然可以正常执行，但存在一个显著的问题 —— 对于每一个客户端的请求， 接口都会把整个文件都缓存到内存中去，然后才开始把数据吐给用户。那么当文件体积很大、请求也较多且特别当请求来自慢速用户的时候，服务器需要消耗很大的内存，导致性能低下。
然而这个问题，则正是  发挥所长的地方。如前文提及的， 是流对象，那我们正好可以将其利用起来：
  =    {    

      = __  
    
}

在上方代码段里， 创建了  的可读流 。这里需要事先了解的是，流可以简单地分为“可读的”、“可写的”，或者“读写均可”三种类型，且所有的流都属于  的实例。
回到代码，对于创建的可读流，我们通过  接口来监听其  和  事件，并把  的可读流拆分成一小块一小块的数据，像流水一样源源不断地吐给客户端，而不再需要等待整个文件都加载到内存后才发送数据。
其中  可以视为流的“管道通道”方法，任何类型的流都会有这个  方法去成对处理流的输入与输出。
为了方便理解，我们把上述两种方式不使用流使用流处理为如下的情景：
⑴ 不使用流：

⑵ 使用流：

由此可以得知，使用流的形式，可以大大提升响应时间，又能有效减轻服务器内存的压力。
二 的分类
在上文我们曾提及到， 可以按读写权限来简单地分做三类，不过这里我们再细化下，可以把  归为如下五个类别：
⑴  ⑵  ⑶  ⑷  ⑸  
其中   和   都属于即可读又可写的流，而最后一个   是对  古早版本上的  的一个统称。我们将照例对其进行逐一介绍。
  
即可读流，通过  接口可以将其数据传递给一个 、 或者 流：
常见的   包括：
客户端上的  服务端上的       子进程的  和 例如在前面  的代码段中，我们就使用了  接口来创建了一个   ：
  =    {    

      = __  
    
}

这里有个有趣的地方 —— 虽然   称为可读流，但在将其传入一个消耗对象之前，它都是可写的：
  = 

  =  
 
  \
  \



执行结果：

在这段代码中，我们通过  的形式往可读流里注入数据，并以  来结束可读流。
不过这种写法有个弊端 —— 从使用  将数据注入  流中开始，直到另一个东西来消耗数据之前，这些数据都会存在缓存中。
这里有个内置接口 _  可以用来处理这个问题，它是从系统底层开始读取数据流时才会不断调用自身，从而减少缓存冗余。
我们可以回过头来看  的例子：
 
  = 
  = 
  = 
  = 
  = 
_ = ={    
         == {
                       
              
        }
    
}

我们是在 _ 方法中才使用  往可读流里注入数据供下游消耗也会流经缓存，从而提升流处理的性能。
这里也有个小问题 —— 上一句话所提到的“供下游消耗”，这个下游通常又会以怎样的形式来消耗可读流的呢？
首先，可以使用我们熟悉的  方法将可读流推送给一个消耗对象、 或者 流：
  = 
  = 

  = 
  = 
  = 

其次，也可以通过监听可读流的“”事件别忘了文章前面提到的“所有的流都属于  的实例”来实现消耗处理 —— 在首次监听其  事件后， 便会持续不断地调用 _，通过触发  事件将数据输出。当数据全部被消耗时，则触发  事件。
示例：
  = 

    {
     {
                
         = 
    }
    _ {
          =         
          {             迭代结束，顺便结束可读流
            
        }
         = {             将数据添加到流中
              \
        } 
    }
}

  =  {
      = 
         =     {
         = 
         
    }
}

  =   监听``事件，一次获取一个数据  =  可读流消耗完毕
  =   
执行结果为：

这里需要留意的是，在使用  往可读流里注入数据的代码段，我们使用了  将其包裹起来，这是为了让系统能有足够时间优先处理接收流结束信号的事务。当然你也可以改写为：
    {             直接 
         
    }
      \
  
可写流接口是对写入数据的目标的抽象：



常见的   包括：

客户端的  
服务端的  
  
 
 
 
子进程的 
 和 

可写流有两个重要的方法：

   —— 往可写流里写入数据；
   —— 停止写入数据，结束可写流。在调用  后，再调用  方法会产生错误。上方两方法的  参数表示编码字符串为时才可以用。

 方法的  回调参数会在  被消费后从缓存中移除后被触发； 方法的  回调参数则在  结束时触发。
另外，如同通过 _ 方法可以处理可读流，我们可以通过 _   方法在系统底层处理流写入的逻辑中，对数据进行处理。
其中参数  代表写进来的数据； 代表编码的字符串； 则是一个回调函数，调用它可以告知消费者进行下一轮的数据流写入。
示例：
  = 
  = 

_ =    = {     输出打印    
         写入完成时，调用``方法通知流传入下一个数据    
    
} 所有数据均已写入底层

  =  将一个数据写入流中  \
  \
  \ 再无数据写入流时，需要调用``方法
执行如下：

  
 是双工的意思，因此很容易猜到  流就是既能读又能写的一类流，它继承了  和  的接口。
常见的   有：

 
 
 

示例：
  = 
  = 

_ =   {    
      =      
       
    
}

_ =     {
       \ 
    
}

  =   

  


执行结果：

  
  是在继承了   的基础上再进行了扩展，它可以把写入的数据和输出的数据，通过 _ 接口关联起来。
常见的   有：

 
 

示例：
  = 
    {
      {
         || {}        
         =  || 
    }     接口写入的数据，处理后直接从  事件的回调中可取得    _   {        
          =    
            \
        
    }
}

  =  
  = 

   
  

执行结果：

其中的 _ 是   的内置方法，所有   都需要使用该接口来接收输入和处理输出，且该方法只能由子类来调用。
_ 接口格式如下：

_  

第一个参数表示被转换的数据块，除非构造方法  参数可选传入了 “  ”，否则其类型均为 ；
第二个参数用于设置编码，但只有当  为  格式即构造方法传入 “  ”参数的时候才可配置，否则默认为“”；
第三个参数  用于在  被处理后调用，通知系统进入下一轮 _ 调用。该回调方法接收两个可选参数 ——  ，其中的  参数可以将  写入缓存中供更后面的消费者去消费：
_ =   {    
    
    
}等价于

_ =   {
     
}
另外   还有一个 _ 内置方法，它会在没有更多可消耗的数据时、在“”事件之前被触发，而且会清空缓存数据并结束 。
该内置方法同样只允许由子类来调用，而且执行后，不能再调用  方法。
关于   的更多细节还可以参考这篇文章，推荐阅读。
  
在较早版本的  里， 的实现相较简陋，例如上文提及的“”接口均是从   开始才有，因此我们往往需要对其进行多次封装扩展才能更好地用来开发。
而   便是对这种古旧模式的  接口的统称。
需要留意的是，只要往任意一个  注册一个“”事件监听器，它就会自动切换到“”模式，并按照旧的  去执行。
 流可以当作一个带有  接口的事件发射器 ，当它要为消耗者提供数据时会发射“”事件，当要结束生产数据时，则发射“”事件。
另外只有当设置  为  时， 接口才会将当前流视作可读流：

  = 

  =  
 =  告诉  这是个可读流
  = 
  =   {    
      =  {
        
        
    }      
} 


另外，   还有  和  两个接口可用于暂停恢复流的读取：

 {      
    {
     
    
  }
}
  
对于可读流来说， 时， 的类型只能是  或，且消耗时  事件输出的数据类型都为 ；
对于可写流来说， 时， 的类型也只能是  或 ，_ 调用时所传进来的  类型都为 。
示例：
_ =    = {     输出打印
       
      转为
    
}

  

执行结果：

不过，为了增强数据类型的灵活性，无论是可读流或是可写流，只需要往其构造函数里传入配置参数“{   }”，便可往流里传入获取任意类型除外的数据：
  = {   }

_ =    = {     输出打印
     
    
    
}

  
 {    } 
  
执行结果：

  的兼容问题
在前文我们介绍了  ，它属于陈旧版本的  上的  接口，可以把它称为 。而从   开始， 新增了系列实用的新接口，可以做更多除了  之外的事情，我们把其归类为 事实上，在  开始，有些许新的变动，从该版本开始的  也可称为 。
那么这里存在一个问题 —— 那些使用了  的项目特别是  包，想升级使用环境的  版本到 ，会否导致兼容问题呢？
还好  虽然改头换面，但本质上是设计为向后兼容的。
打个比方，如果你同时推送了一条  流和一条旧格式的、基于事件发射器的流， 将降级为旧模式 来向后兼容。
但是，如果我们的开发环境使用的是  且因为某些原因不能升级，但又想使用  的怎么办呢？或者比如  上的某些开源的工具包，想要拥抱  的便利，又想保持对使用   的用户进行兼容处理，这样又得怎么处理？
针对上述问题，早在   释放之前， 就把  中操作  的核心接口独立拷贝了一份出来，开源到了  上并持续更新，它就是 。
通过使用 ，我们就可以在那些核心里没有  的低版本  中，直接使用 ：

  =  || 

 现在有  和  两个主要版本，前者跟进  的迭代，后者跟进  的迭代，用户可以根据需求使用对应版本的包。
 
 虽然提供了一个  的兼容方案，但我们也希望能对  复杂的进行精简。
而  便基于  对  接口进行了封装，并提供了更简单和灵活的方法。
 会为你生成  貌似旧版本是  来处理任意你想使用的流 —— 如前文介绍，相比其它流， 流处理起数据会更加灵活方便。
来看下  的示例：
  = 
  = 

        {        
           =                 
              == 
                 =   把  替换为 
        
        
    }
    
     = {
        
    }
使用  接口操作   下的流：
  = 
  = 
  = 

  = 


          是 {   }  的简易封装
        {          = {
             
             
             
        }        

        
    }
       {
        
    }
       {
        
    }
对比原生的  ， 简洁了不少，加上有  依赖加持，也很好理解为何像  及其插件都会使用  来操作和处理  了。
以上是本文对  的一个介绍，但事实上  还有许多未露面的 ，感兴趣的同学可以直接阅读官方 文档做进一步了解。
共勉

⑴     
⑵   
⑶    基础篇  
⑷          前言
欢迎加入腾讯云技术社区话题讨论！本期腾讯云技术社区特别邀请到了「腾讯魔方工作室群」技术总监   ，与大家交流讨论。
 的技术经验非常丰富，绝对的技术大拿。本话题下的评论均有机会得到  的回复。另外，我们还提供了精彩的礼品，奖励优秀的话题互动者。具体细节如下：
一、话题主持人


叶劲峰 
现任腾讯互动娱乐事业群魔方工作室群技术总监、专家工程师
腾讯开源联盟会长，《游戏引擎架构》译者
自小喜爱编程，获取了香港大学认知科学学士、香港中文大学系统工程及工程管理哲学硕士，及后于香港理工大学从事游戏引擎及相关技术研究。曾开发游戏《  》、《     》和《王子传奇》。 在腾讯研发的游戏引擎技术曾应用于《天涯明月刀》、《斗战神》等项目。

二、话题讨论
本期话题：这些年的编程经历中，有没有曾经遇到以为一个很简单的问题，最后却坑了你很多时间才解决？

 在你的编程经历中有没有曾经遇到以为一个很简单的问题，最后折腾很久
 超过一周，一个月甚至更久
  期间一度怀疑人生，怀疑智商是否适合写程序，心情非常低落。       最后解决了  
有可能是之前的代码或者环境犯了很低级的错误？
有可能是自己梦中灵机一动，正好完美解决了？

在本文评论区说出你的经历，与 「 腾讯魔方工作室群」技术总监   分享交流 
  将从中评选优秀回帖者，并为其颁发奖品
另外，向那些因为一个小问题而奋战良久的软件工程师程序猿致敬！
三、活动奖品


 黑轴机械键盘     

腾讯云充电宝     

 腾讯云元代金券  


四、活动规则

登录并在本帖下回复你对这个话题的看法，请勿水贴。

评论的第楼、第楼、第楼会获得腾讯云元代金券张。

 黑轴机械键盘、腾讯云充电宝 两项奖品， 会在相应的话题回复下如【恭喜您已获得了“奖品名”】，即可获得对应奖品

活动时间：年月日 — 年月日腾讯公司一直以来产品就深受我的喜爱，自以来，到微信支付再到，所以这次选择腾讯云服务器作为我的研究对象，一来是亲切感，二来是相信腾讯的技术实力。
作为一个程序猿，一直以来都是在于时间做赛跑，很多时间花费在软件启动的等待上面，这对于我来说是一种浪费。我个人以为，如果只是做一个简单的片段，或者测试某一段代码，就得去开启某些占用内存的，并且花费数秒甚至分钟去等待软件启动这很不明智，所以我打算打造一个个人常用工具集，当然这对于我来说是有用的，而对于其它人来说，同样也是有用的。
工具：代码演示工具
逛过的人都知道，上面有一个可以测试代码的工具，非常好用，而且轻巧，而且好用而且轻巧，重要的事我一般说遍。那么我为什么还要再造轮子？原因很简单，一个是想知道它的运行原理，之前没认真研究过，所以我想知道它是怎么运作的，这也是我的求知欲作祟，二来是因为的服务器这一年来明显的感觉不行了，以前代码提交以后可以立即响应，而现在代码提交了等待的时间可以跟我打开有的拼了，这里所以还是要赞一下腾讯云服务器，响应速度快。还有第三个原因，他们现在全都是谷歌以及百度的广告在旁边
然后就是环境搭建演示了
我的后端使用的的技术，前端使用的技术，环境部署见百度，传送门。
这个工具由于基本不与后端做数据交互，所以就别问我后端是怎么写的了，因为说了也没用，我们就看前端吧
演示地址

此工具使用的是技术，利用 创建而成，由于的安全性考虑，只可以本地使用这个插件，所以各位看客可以下载到本地使用，直接右键查看源代码即可。代码解析：
 = == =  
响应式页面
    
  =

上面这一段是响应式页面设置的，使得这个页面可以在手机或者上面也可以正常浏览这里是核心部分，我将在代码中注释出关键点

 {
      =   这里创建 对象，此对象只适用于模式
     _= 这里获取浏览器地址栏地址

    _=_    暂存数据
    _=_ 取值
    _=__ 操作字符串
     =_ 去掉协议头

    {
         
          =  
        {
            文件创建成功
        }
    }{
          =  
        {
            文件创建成功
        }
    }    
     =
    =
    
    文件写入成功
    
        自动刷新会丢失代码
     =
    字符数
    =
}

前面的代码没有上面亮点，值得一提的是这一段代码：
_=_    暂存数据
_=_ 取值
_=__ 操作字符串
 =_ 去掉协议头
这里是讲地址栏的地址进行一次字符串的截取操作，然后拼接生成的那个页面，组成新的地址，以便于在中使用。
_=_    暂存数据
_=_ 取值
这里是在那个隐藏的那里做一个数据的暂存然后取值，由于的可以操作文档独特性，有时候这一招十分管用。
{
         
          =  
        {
            文件创建成功
        }
    }{
          =  
        {
            文件创建成功
        }
    }
这里的代码则是对文件做一个判断，是否已经存在文件了，如果不存在，则创建，如果已存在，删除旧文件然后创建新文件
 =
=

文件写入成功
这里则是讲那个文本区域里面的值写入到创建的文件中，里面我没有查到有流的说法，这估计也是安全性考虑吧。
这里创建的文件将会在当中被引用，所以在右侧即可看到那个新生成的文件，不过由于刷新的问题不好处理，所以我只得让其手动刷新，当然此工具还提供了一个小工具，那就是字符数个数的读取，比如您有一大片文档需要统计字数事实上这样的事情时常发生，您可以直接粘贴到文本域里面，它将会自动给你统计出来。也算是在的工具上面重写并拓展了其功能吧。
部分也就是利用的的媒体查询，来匹配移动设备，这不是我所想讲的，如有兴趣，可以直接向我提问，或者百度吧。
结论
此工具也是我上班时候闲暇时间写的，本是为了方便自己，以及一个同事的，所以当时并没有考虑到将其置于服务器上，由于忽略了组建不可以跨域的问题，所以各位看客没办法在服务器段执行代码，如果有时间，我会考虑使用代码重写这个小工具，以便于服务器端也可以方便使用，这个工具当然优点也是有的，比如在断网的情况下呢？如果您刚好下载了这个工具，您就可以方便的在手机或者或者上面做代码测试了，您多半不会在手机安装的不是么？

相关推荐
【腾讯云的种玩法】激发云力量打造我的云端工具集
【腾讯云的种玩法】利用腾讯云搭建个人博客
最佳上云实践机分析大部分，可以发现在中图片应用较多的主要包括和两种资源类型。对于颜色很多尺寸大的图片一般用，主要适用场景是用于做背景展示，这类图片除了调整压缩参数做有损压缩外，无损压缩可优化的空间则一般不会太大。相对而言，图片的应用场景更多，一方面是由于其拥有透明值，另一方面也因为其可以方便缩放九宫格。这部分资源一般在中占用了比较大的体积，很多时候可以通过有损压缩减少颜色表来减少体积，但容易被像素眼的设计师挑战；另一种方案是无损压缩，常规方法包括转换为索引图片、改变编码方式、提升压缩级别等，相较而言体积小了但效果一样，本文也将就这一方面结合源码对其在的实践和问题进行阐述。
一选择压缩工具
首先是选择压缩工具的问题在这之前先看下系统是如何做的。的在编译阶段其实是会对图片进行压缩的，用的则是和，这个可以用的源码佐证：

用对图片进行预处理
用对预处理后的图片进行压缩生成新图片

可以看到对图片的压缩等级使用了最高等级，期间系统也会做颜色表转换，这样可以减少很大一部分图片的体积，但系统的压缩方案是不是完美无缺呢目前常用的无损压缩大概有、、、、，参考了很多文章，得出的结果是仍然是王者，毕竟是神童据说  的作者都尊敬他，做游戏的肯定都知道 写的。另外由于可以很好的支持命令行，方便放到编译脚本中自动化，所以暂时选它好了。
二实践案例
压缩工具选好了，第二步便是实验了。拿手为例，直接对手中的所有压一遍，的速度确实一般，对千张图片全部处理一遍大概需要分钟，不过这个过程只需要在本地做一遍，所以可以忍受，但处理完的结果不理想，因为没什么效果，减小量为十几 仔细分析得知这里面犯浑作怪的竟然是，由于先调再调会导致压缩效果覆盖。那么可不可以关闭呢？ 查看的参数，关于压缩相关的只有下面这两个参数：
其中便是预处理资源了，但是没有关闭的参数。。。。有点技穷了对不对。只能去源码中找灵感了，看的源码：
把它隐藏了，没有打印出来给用户打开这个参数，在手中资源打包脚本处分别加入参数，便可以把系统压缩给屏蔽掉了，样式如下： 
   至于为什么设置了这个参数就可以屏蔽呢，其实源码调用过程如下：
第步  
 第步 
第步 
终结： 
可是实验还没有结束，因为这样屏蔽掉会出现奇葩的景象，得到的手画面效果如下：为什么呢？仔细分析发现九宫格图片被压出问题了，在处理图片时会判断是不是九宫格图片，如果是则做特殊预处理：_其实主要的是九宫格信息弄出来，写入到字段，并最终写入的中： 
到这里又回到第一步为什么我说是神童了，因为可以选择进行压缩，所以解决方案便是：对于九宫格图片，我们单独拎出来，先用的 进行预处理得到字段，再用在压缩时调用参数保护一下块，这样便得到了正确的九宫格图片，安装包的效果图也就正常了。
三总结
上面大概就是无损压缩在中应用的基本思路和遇到的问题，归纳为一句话便是：替换掉系统的压缩算法。如果你不嫌麻烦和喜欢折腾的话可以在你的使用一下，效果还是非常显著的。不改变安装包内图片像素内容，轻轻松松减少几百体积，何乐而不为呢？

相关推荐
万象优图
重复相同图片或近相同图片去除接口热点事件
商汤牵手华为发布“超高密人脸识别”解决方案商汤科技和华为在第十六届中国国际社会公共安全博览会期间联合发布了超高密人脸识别一体化方案。基于加速和商汤算法的加持，服务器单机即可实现路高清视频流人脸识别的实时处理。本次发布的超高密人脸识别一体机，采用华为平台硬件技术，结合商汤科技在算法上针对加速的深度优化，能够高性能地执行人脸检测、跟踪、关键点定位、特征提取等任务。在单上即可实现路高清视频流的人脸实时处理，单机最多支持路高清视频流的实时人脸识别分析，满足中小型场景智能视频监控的视频人脸分析、布控、抓拍库检索、图片存储等需求。氪
夏普发布全球首款人工智能服务电视 能订外卖订电影票夏普与富士康共同发布电视战略之后，月日，夏普发布全球首款人工智能服务电视，继续布局基于电视作为家庭物联网枢纽的智能家居环境的生态系统。与市场上普通的人工智能电视相比，夏普人工智能服务电视能通过全程语音交互，以电视大屏为载体，用体验度更好的“视觉、按键交互语音交互”交互方式，解决用户吃穿住行的头部需求，实现诸如订外卖、订电影票等实用的生活服务。中国家电网
谷歌无人车放弃自动辅助驾驶功能：会让驾车者分神谷歌母公司旗下自动驾驶部门已决定停止开发自动辅助驾驶功能，因为实验显示，对这一功能的依赖会造成驾车者分散注意力，在发生紧急情况时根本来不及作出反应人工干预驾驶。该公司在实验过程中发现，测试用户过于依赖这一功能，会在时速高达英里的情况下坐在方向盘后面打盹、化妆、玩手机等。新浪财经
美团云深度学习平台将对开发者免费开放美团云人工智能峰会“赋能共生共赢”月日在京召开。美团云总经理李爽在会上展示了以“打造最开放的人工智能平台”为愿景的美团云生态合作图谱，并且正式宣布美团云深度学习平台将对开发者免费开放。此次峰会上，美团云宣布新增两款高性能云主机——基于最新®  ™的云主机以及云主机，进一步夯实计算能力，为用户提供更多选择。还将在国内首推基于的高性能深度学习平台，提供模型训练、推理等功能，增加深度学习平台的可用性和易用性，进一步帮助开发者及企业用户摆脱底层资源及组织运维方面的大量投入，加速产品商业化进程。
海康威视推新型无人机：具备双目智能感知功能海康威视行业级无人机在月月日于深圳会展中心举行的第十六届中国国际社会公共安全产品博览会上首次公开亮相。首次公开展出的海康威视四旋翼无人机是一款将高强防护性凝练于小巧机身的新品。其采用轻量化结构设计，一体成型，轻巧便携，防护等级达。它还具备双目智能感知功能，飞行时遇障碍物可自动悬停，而且当信号差时，凭借超声光流，可精准定位。同时亮相的还有新款海康威视六旋翼无人机，采用上翻式仓盖设计，操作更便捷；总控按键，一键控制电流通断，安全性能更强；通过轻便的结构设计和优异的动力性能进一步提升续航时长。快科技中科曙光研制出首款搭载寒武纪芯片的人工智能服务器中科曙光近日成功研制出首款搭载寒武纪芯片的人工智能服务器，命名为“”。主要是面向深度学习的在线推理业务环境。可以在空间中部署个人工智能前端推理模块，能够为推理提供强大的计算支持。新华社
华中地区首个量子通信城域网启动运营武汉市量子保密通信城域网运营服务日正式启动，这是华中地区首个量子通信城域网。该项目以政务网的量子通信应用为切入点，可实现政务网的办公透明、廉洁、高效管理，并确保政务数据的无条件安全，成为中国政务网标杆。根据业内估计，国内量子通信市场规模在年内达到百亿级，到年将达到千亿级。新华社
谷歌新入华计划与搜索、安卓无关，人工智能是中心谷歌再次入华的中心将是人工智能，而非搜索引擎或安卓软件。谷歌将积极推广——能降低开发人工智能系统难度，在中国这个全球最大的互联网市场建立商业合作关系。谷歌瞄准了中国学术机构和科技巨头。谷歌母公司还将扩大在中国的团队，寻求与中国公司在人工智能领域合作。谷歌在中国推广人工智能技术不一定能获得丰厚利润。目前，谷歌人工智能技术创收渠道是其云计算业务，这一业务尚未进入中国市场。另外，谷歌在中国市场还将面临来自百度等公司的竞争。彭博
迅雷下一阶段将 区块链迅雷旗下全球首个共享计算企业网心科技月日在京召开发布会，宣布最新一代共享经济智能硬件——玩客云的全新布局。发布会现场，迅雷、网心科技陈磊表示，迅雷下一阶段将  区块链，凭借亿迅雷用户、天然的分发平台、海量的共享计算资源等优势，用年全球领先的下载技术积累与技术创新的力量，致力于让中国区块链技术领先世界年。迅雷将积极推进版权，首先与花园达成合作，共同探索共享计算区块链版权分发、内容分发及高清视频内容传输等。玩客云和京东达成战略合作，成为京东年战略单品，下一阶段双方将将在双方良好既往合作基础上，继签联合探索“爆品”销售新模式。
丰田准备进一步测试无人驾驶汽车：建立危险驾驶场景丰田研究院周一宣布，它已经与加州康科德 签署协议。有一个占地英亩的试验场，丰田可以在实验场内测试两级自动驾驶系统，试验场专门用来测试联网汽车和自动驾驶汽车。试验场有许多设施可以测试无人驾驶汽车，比如桥梁、隧道、交叉路口，还有多种多样的地形。它的总目标是打造一个实验场，将多种环境考虑进去，如果在公共道路上测试可能会威胁公众。现在丰田在 做研究会更安全一些。新浪科技
投资事件
智能门锁企业云丁科技获近亿元轮融资云丁科技智能门锁企业在推出“鹿客”品牌、完成小米众筹之外，也于今年月获得了由百度风投领投，小米、顺为资本、双湖资本等机构跟投的近亿元轮融资，成为国内首家获得轮融资的智能门锁企业。本轮融资将主要用于巩固端市场业务，开拓端市场业务，加强研发体系，优化供应链及渠道，加大市场投入。
鼎晖投资和商汤科技联手融资约亿美元 建立投资基金鼎晖投资和商汤科技正在融资约亿元人民币约合亿美元，准备投资于技术。一名消息人士透露，鼎晖投资公司和商汤科技将作为普通合伙人，联合管理这笔基金。商汤科技可提供诸如面部识别、视频分析和自动驾驶等科技应用。目前还不清楚融资计划何时完成，或者谁将成为潜在投资者。新浪科技
视觉感知终端和自动驾驶机器人研发商踏歌智行完成轮数千万融资，辰韬资本领投踏歌智行是视觉感知终端和自动驾驶机器人研发商，基于、机器学习等技术，目前提供、、自动驾驶机器人等产品。
金融科技公司上海哈杜科技获君联资本数百万美元轮投资上海哈杜科技是一家专注于东南亚消费金融的金融科技公司，致力于在新一代金融科技移动信贷领域的探索，试图通过数据的机器学习和智能化风控模型实现全自动在线放款的金融技术，为传统银行和金融机构没法覆盖的群体提供更好的金融服务和产品体验。产品包括小额现金贷和消费分期类产品，以及和当地金融机构合作的其他分期类产品。
教育的学业采集与学情追踪反馈系统极课完成亿人民币轮融资，投资方为丹华资本、创投极课是基于图像识别和自然语言处理等技术研发的教育智能系统教育场景下的人工智能。作为一家教育智能科技公司，极课在完成学校日常教学、考试的数据采集和分析基础上，以教育智能系统的方式帮助老师做到以数据驱动教学，从而调整教学节奏和方向，提高老师和学生的时间效率。
金融科技公司“潘帕斯”获数千万元天使融资，戈壁创投和银杏谷资本投资潘帕斯是一家以大数据、人工智能服务为主的新金融技术服务公司，公司面向企业和机构提供基于全球资产配置的财富管理产品和金融大数据解决方案，旗下产品涵盖财富管理、资产配置、投资组合、风险管控等。
福特 收购激光雷达初创公司 福特的 正在加大它在激光雷达领域的努力，日前，这家公司收购了一家叫做 的激光雷达初创公司。     指出，的激光雷达激光将能帮助他们加大在城市环境下的自动驾驶所需的视觉范围和分辨率。
用机器人让孩子在手机上学编程， 获万美元轮融资 宣布完成万美元轮融资。这家创企设计了一些非常酷的小型机器人，能让孩子们在手机上进行编程，以帮助他们打下计算机科学的基础。本轮融资的投资方包括腾讯、软银韩国、  、 、  、  以及公司的一些现有投资人。该公司的编程机器人已经被美国万座小学所采用，同时它还在尝试让机器人教孩子学习科学、技术、工程和数学方面的概念。公司会利用这笔新融资将其现有的产品推广到全球其它地方，同时会进行新产品开发。
医生 获得万美元轮融资 是一款医生应用，支持和平台，该应用将人工智能与实际医生的专业知识结合在一起，帮助人们了解和管理他们的健康，据悉， 获得万美元轮融资，由 领投， 、 以及个人投资者  跟投。
人力资源科技创企 获得万美元轮融资 是一家人力资源科技创企，  公司利用人工智能、数据科学、数据分析、以及机器学习技术，开发了人才获取和劳动力管理的技术解决方案。该公司推出的解决方案可以自动开启招聘任务，自动寻找与匹配候选人，自动识别和判断，自动跟踪，自动评估和分析等，极大地提升了企业招聘效率，据悉， 获得万美元轮融资，投资方为 和。

本文来源于 腾讯  加速器 微信公众号网址 导语
本文整理自笔者在“腾讯大讲堂”的演讲。

作者介绍：杨平安，来自广州的微信事业群，在腾讯已经工作五年。

主要分享内容：

为何公司卓越研发金奖花落；
隐匿在业务后的大数据统计特征；
架构迭代的现实与实现


在作这份的时候，我对自己这五年的时光进行了一下简单的回顾，发现可以分成两个主题。
这两个主题就在我的职业生涯中不断交织，爱恨情仇，发展到了今天。
第一个主题呢，是我搞海量存储，详细来说就是不少业务的存储基本上是在我手上从无到有到今天的。
给大家列了一个海量存储架构的演进，大家可以看到这儿分别是支持单机十亿键值、支持冷热数据分离、支持分布式缓存、支持协议。支持两字背后都是对它的架构进行的脱胎换骨的改造，还有数据的挪腾，并不简单。
再来说第二个主题，我将它称为：海量存储搞我。
微信这个产品是年发布的。
这五六年里不少业务也进行了数次的迭代，以朋友圈举例，朋友圈广告、春节的红包照片等，期间用户的访问量也跟腾讯股票的线图一样，翻了数倍。
这些需求，对用户而言叫作玩法。
但我们这些后台存储呢，就只能称为死法。花样百出，被现实各种吊打。

这个是我们第一年的时候，数据存储的一个存储引擎的模型。
在第一年的时候，我们并没有专门为核心业务的数据定制一套专门的存储。而是使用了通用的存储模型，叫作存储，即日志型的存储。
所有的写都是在文件的最新位置追加写。可见它的写是很轻量的。
内存中会有个索引，指向了数据在磁盘中的位置。
每次读数据，都是先在内存中找到它的索引，然后再按照索引位置直接去磁盘上读。

这个模型的优点是显而易见的，它真的是非常轻量。
在不考虑有数据缓存的情况下，任何的一次读，都只会产生一次随机读盘。非常。
然而它的缺点也是致命的，它受限于内存。每台机型的机器，内存，只能存储约亿的键值。
但后面的情况是，许多业务的存储单机量需要达到数十亿。如果我们继续使用这种类型的话，就是对磁盘空间的极度浪费。

于是第二年，我们就设计出了支持单机数十亿键值的存储系统。
我们将它称为了系统，就是将刚才说到的内存中的键值索引放到了磁盘上存储，存储的方式呢，也是模型。
每次写数据，都是先追加写数据文件的最新位置，然后再更新索引，将索引写到了文件的最新位置。需要写两次。
如果是读呢，就要先读目录中键值的索引，然后再根据索引去读磁盘上对应的数据。
那么在这种架构下，每次的读都会产生两次随机读盘。这个效率跟索引全内存的存储比起来，肯定是差了一截的。
但是它解决了键值爆涨的问题。

然而等到第三年的时候，当前的这套系统又不顶用了。
因为我们当时按照某核心业务数据量的增长速度，进行了一个预估， 
大约等到年底的时候，该业务的数据量就会增加到，这大约就需要数千台机型的机器来支撑。
我们应该可以通过分析核心业务的业务模型，找到一条适合它自己的存储架构。



论我们如何设计冷、热数据集群的内部实现细节，有个问题是独立的，是必须首先要解决的。
即冷、热数据集群的架构关系。
在设计这套系统的时候，我们对业界的各类方案进行了充分的调研。
发现针对我们这种“冷数据不太冷，瓶颈，海量量”的场景表现的都较为乏力。
我就举一些反面教材，来说明下为什么这种架构不适合我们的应用场景。
以这类架构举例，集群存储冷数据的索引及数据，它和组成的热数据集群呢，是分别独立的两个模块。
每次读数据，都会先访问热数据集群，如果热数据集群不能命中， 则再访问冷数据集群。
热数据集群为了防空呢，就增加一个 组件，来降低冷数据集群的无效访问量。
这个架构最大的毛病是在机器上，它的键值索引无论是全内存，还是落盘，都对机器消耗非常多。

这是另外一个方案。这个方案变聪明了一点，它将冷数据集群中的键值索引给上提到了热数据集群中。
这样的好处就是降低了冷数据集群的负担。每次业务端都通过热数据集群来获取冷数据的索引，再直接读取冷数据集群中的文件位置。一次随机读即完成。
这个架构的问题在于扩容！
如果当前的机器数已经不能满足服务，我们最常见的策略就是增加服务器数目，这时候就涉及到了旧数据的迁移。
在这种方案下，无论是扩容迁移，还是冷数据下沉，都是以单为粒度进行的操作。
我们前面提到过，我们有万亿级别的键值，这种量级的数据流动，操作周期就太久了，将业务放在了一个不稳定的状态。

不以单为粒度进行操作以文件为基本单位来转存冷数据，同样的以文件为基本单位来记录冷数据的键值索引。
在静态的服务器集群中，这个方案是足够好的。
但当发生扩容的时候呢？
那么这套系统就彻底失败了。

为了批量的操作数据，我们提出了最小不变块的这么一个概念。

这张图就展示了如何实现最小不变块的。
方法就是通过两阶段哈希。
我们首先将用户进行一轮哈希，散落到数目有限的桶内。
每个桶就是一定数量的集合，然后再将这些桶进行第二轮哈希，路由到不同的实体机器上。
通过这种方法，将用户与机器路由隔离开来。处于中层的每个哈希桶就是一个最小不变块。

确定完最小不变块的算法后，我们就可以从整体上来规划系统的设计了。
这张图显示的呢，是我们数据一个大体的分层。
最热的数据，访问量占比以上，我们当然希望它是常驻内存的。
次热的数据，在中就可以支撑访问需求。而最冷的那部分数据，按最小不变块聚合在冷数据集群中，集群呢，也按最小不变块为基本单位，持有冷数据的索引，这样就不担心因扩容而重新组织的问题。

在整体上，由内存到再到盘，数据在时间维度上由热到冷。由这一点，我们联想到了算法。
这个算法呢，它是一个多组件算法。在本质上和树是一样的，都是一种索引建立的技术。不同的是，它将内存和磁盘划分开来，在算法中称为组件和组件。
所有的索引的变更，其实就是写数据，都在组件中提交。
只有当组件达到阀值后，才会延迟的提交到组件，并且是通过多路归并排序的方式。
如此一来，就将树中的随机级转换成了内存操作和顺序。
前面提到了，我们这种业务所有的键值都是带有毫秒级时间戳的，这样在组件中通过多路归并排序，就已经达到了数据的时间维度有序。
在我们的应用场景中，组件就是内存，存储最热的那部分数据，当内存容量满了之后，最热的数据变成次热数据，就会被迁移到组件，即硬盘中，与中原有的数据进行归并。当容量也达到阀值之后，就会将最冷的那部分数据迁移到组件，即冷数据集群的盘中。
前面的也说到了，我们的问题是如何将现在的数据按照时间维度来进行分开，以方便的剥离冷数据；算法就为我们指明了方向。

我们基于算法改造了热数据集群。这是它整体的一个架构图。
其实说白了，这就是一张的架构图。
我们也深入调研了的源码，如果直接使用实现存储，会存在一些严重的问题，例如单点文件损坏则全库难以恢复的问题，而且它内置了很多读写时候触发文件，数据文件索引懒加载会引发不可控的读盘等策略，会引发服务的抖动，在实际场景下不太适用，同时大量的动态内存分配会对机器的内存使用带来一定的不可控的因素，我们也需要结合业务特性进行细化，包括在处理冷、热数据，对如何调和、磁盘、磁盘占用等。所以我们采用的方式是重用里面的一些成熟数据结构组件，例如，等等，按我们的需求和策略去构建一套引擎出来。

基于这样一种架构图，我们实现了数据在整体范围上的有序，前面也提到过存储用的为位的，其中包括毫秒级时间，因此数据有序，即是时间有序。首先要做的是数据按块进行压缩，在改造之前，冷热数据混杂，是没办法实现按块压缩的，只能以单用户数据为基本单位进行压缩，只可以达到左右的压缩率。而通过按数据块进行压缩，则将压缩率提高到了左右。这点上，就相当于节省了的存储成本。同时，我们利用访问特征又对冷、热数据的存储进行了各自的定制，如冷数据访问量低，就可以采用比较大的数据块进行存储，它的索引粒度就大一些；热数据访问量大，数据块就小一点，降低读盘量，并且不进行压缩，减少的计算，同时为了精确防空，增加了 ，只有的误判。通过这些手段就有效的平衡了使用、性能、读盘量三者之间的关系。还有一些其它的优化，比如索引启动加载、命中率的记录级缓存等，这里就不需要单条的列出来说明了。

这页列了冷数据集群的一些设计要点。我想着重说明下冷数据集群的容灾模型。通过这张图，也可以看到，集群一组有三台机器，分别存储相同数据的三份副本，它们分布在不同的园区，可以实现园区级容灾。为了保证数据的一致性，我们采用了三节点串行写入的模型。之所以可以这么做，是因为冷数据集群的写入任务是离线式的，我们可以控制它的写入时机及并发数。在扩容的时候，我们就可以停掉写入，直接进行数据的复制，等复制完成之后，再提交路由表。

在进行冷数据存储的时候，面临一个很重要的问题：即在单盘数据完全丢失的情况下，如何恢复。作软是种方案，然而会使用一半的空间，而则需要扫描和计算数十的数据量。
因此最终我们采用了方案，决定从其它机器中恢复。
这就有必要将三副本作到盘级别的一致。
因此，我们在设计的时候，也通过预计算数据路由的方式，实现了盘级别的负载均衡。

这页图说明的是三机串行写入的一个过程，它分为两个阶段，其一是占位阶段，这阶段确保在三机中相同的位置预分配相同长度的空间。
然后在写入阶段，将数据依次的写入到各机。每个数据块大小为定长，其中包括校验码和用户数据。

这张图说明的是冷数据下沉的一个流程。它包括五个过程，、、、、。
整个过程对服务而言，因为是两阶段提交，都是无损的，对客户端也是透明的。

转眼就来到了第四年。
在第三年，通过冷数据集群的搭建，我们成功的解决了磁盘容量瓶颈的问题。
第四年，我们主要面临两个挑战，一个是春节活动。
我们预估用户的流量会瞬时涨五倍左右。
因此我们对业界方案又进行了调研。增加一个临时存储服务器，也是业界曾出现过的案例。显而易见的是，在节日期间的访问增量，都是由春节期间的新增的活跃数据所带来的。因此为这些活跃数据搭建一个临时的存储服务器。客户端根据访问所带的时间范围来决定转发到哪个集群。这种方案算是一种变相的扩容，优点是它不涉及旧数据的迁移。同时为了均衡临时存储服务器与原存储集群的压力，可以按比例的来分配活跃数据的流量。但是它的缺点也非常致命，这种方案要求数据的路由是限死的，不可能在面临洪峰的时候快速扩容。因此我们决定抛弃这个想法。

缓存层可以按比例来分摊存储层的流量，但与临时存储服务器不同的是，它支持快速扩容，也可以动态调整流量比例。但如果我们要采取搭建缓存这个方案，就不得不思考如下的问题：第一个是如何保证数据的一致性，通常的作法有保证严格更新，对存储层数据的更新，都确保缓存也相应的修改成功。但这种情况在面临机器离线的环境时就变得复杂了，因此我们需要一套简单而又行之有效的分布式缓存协议，来确保不读到过期的数据。另外一个需要思考的问题是缓存层的机器应该如何分布，使我们能更好的容灾，尽量确保不因机器的离线，而导致缓存的失效，引发模块的抖动。

存储访问具有读多写少的特征，读写比例达到了：，因此我们完全可以使用读更新的策略，即写时不更新缓存。需要在读的时候确保缓存层的数据是最新的就可以了。我们通过版本号来完成了这个请求。在存储层和缓存层都为每份数据维持了一套版本号。每次读缓存层的数据，都需要用缓存层的版本去存储层验证，是否与存储层的版本号相等，若相等，则说明缓存数据为新，直接返回，否则存储层就要把最新数据返回给缓存层。如此一来，在一次请求过程中，就同时的完成了数据有效性的辨别，以及过期情况下的缓存更新。那么这个协议能够成功应用，就必须依赖于存储层获取数据版本号是个轻量级操作，并且可以达到高。

我们通过缓存层的轻重分离，达到了这个目标。改造前，存储层已经有单机级别的 ，其中包含数据缓存和版本号缓存，命中率也达到了，算是比较高的。然而我们在运营的过程中，发现了这样一个现象，因为数据的平均大小是，版本号只有定长字节，这两类大小差异很多，但访问频度一致的数据混在同一个缓存的时候，就会出现大数据清洗挤压小数据的情况。我们称之为黑暗森林法则。因为版本号只需要很少的内存就应该可以达到很高的命中率，却会不断的被大数据把内存抢走，增加整体的流动性。因此，我们开发出了一个极其紧凑，包含千万级链的定长数据缓存。实现也非常简单，它就是一个二维数组和一个头部。一维用来作为哈希桶，另外一维当作链。 每次读写都通过数组内数据的挪动，来更新。

这样一个实现确保了内存的高效使用，仅用的内存空间，就缓存了约亿的，达到了的命中率。我们也调研过其它的方案，比如说多阶哈希缓存，它的内存使用率也仅能达到。存储层通过这样的一个改造，获取版本号由每秒，增加到每秒万。提升了约多。

由于存储层的单机已经实现较高的命中率，即使缓存层提供更多的内存，命中率也提高有限。首先在逻辑层到缓存层批量请求中的具有用户维度的相关性，它们可能属于同一个用户。但由于存储层以的哈希值来路由，所以这些都被打散掉，分散到了不同的机器上。为了最大效率的合并请求，我们必须保证路由到相同存储机器的数据，也必须路由到相同的缓存层机器。因此就必须让缓存层的机器与存储层在组数上对齐。实践的过程中，我们是缓存层组，而存储层组，比例为：。这样缓存层每合并个请求，再去访问存储层，平均下来，每个存储层机器批量数目为。

这页说明的是合并所使用到的批量化技术的一个具体实现。我们在请求合并的时候，限制合并历史数据的访问，来实现快慢分离，通过这样一个工作，我们将存储层的请求从降到了。

。到了第五年，协议席卷了整个微信后台的存储。
然而地位更重要的热数据集群，依然采用的是协议，而只有两份数据副本。
后面出于更高数据安全性的要求，我们必须把热数据集群中的数据也提升到三份副本。
面临的问题依然是成本压力。如果两份变三份，那需要的存储空间也要提供一半，就需要额外增加台的。
可不可以不要这些成本，就实现更高的数据安全性呢？
具有冷热分明的业务特征，一天内数据的更新占了总更新的，一个月内的数据的更新占了。这就意味着数据冷却很快。这就给我们提供了一个思路：按照时间点来切换存储。

因为我们之前搭建的冷数据集群是按照三个副本来存储历史数据的。通过切换存储，我们可以确保新增数据的高可用性。剩下未切换的就是当前的存量数据，它的增量很少，三个月整个模块也只增加左右。因此，我们可以利用冷数据下沉的任务，慢慢的来消化这部分的存量数据。

好，再来说下切换新存储。它是我们整体工程化的一个环节。在过去的一年，我们深度的思考了基于算法的一致性协议，针对当前现网数据的复杂性，设计出全新的分布式架构，逐渐的替换当前的 。目前已经上线到用户账户存储、消息存储、朋友圈时间线存储等核心模块。这个过程中沉淀出成熟的非租约 \组件和组件，它们分别服务于不同的数据类型和应用场景。


 但是采用逻辑端双写就涉及到前端的修改及上线过程。因为\的上线周期都很长，我们不想将太多的时间浪费到发现问题－修复问题－上线这样的循环中。因此，我们将上述两种方案结合起来。 同时在上线的过程中，  存储层兼容新旧模式，每次大改造都支持回退。    目前我们已经在上海及香港上线了此项改造，实现全程无故障切换。前言
使用文件进行进程间通信应该是最先学会的一种方式。任何编程语言中，文件都是很重要的知识，所以使用文件进行进程间通信就成了很自然被学会的一种手段。考虑到系统对文件本身存在缓存机制，使用文件进行的效率在某些多读少写的情况下并不低下。但是大家似乎经常忘记的机制可以包括“文件”这一选项。
我们首先引入文件进行，试图先使用文件进行通信引入一个竞争条件的概念，然后使用文件锁解决这个问题，从而先从文件的角度来管中窥豹的看一下后续相关机制的总体要解决的问题。阅读本文可以帮你解决以下问题：

什么是竞争条件？。
和有什么区别？
函数和与有什么区别？
如何使用命令查看文件锁？

竞争条件
我们的第一个例子是多个进程写文件的例子，虽然还没做到通信，但是这比较方便的说明一个通信时经常出现的情况：竞争条件。假设我们要并发个进程，这些进程约定好一个文件，这个文件初始值内容写，每一个进程都要打开这个文件读出当前的数字，加一之后将结果写回去。在理想状态下，这个文件最后写的数字应该是，因为有个进程打开、读数、加、写回，自然是有多少个进程最后文件中的数字结果就应该是多少。但是实际上并非如此，可以看一下这个例子：
   
 
 
 
 
 
 
 
 

  
  
  

 _  
{
     这个函数是每个子进程要做的事情
    每个子进程都会按照这个步骤进行操作：
     打开路径的文件
     读出文件中的当前数字
     将字符串转成整数
     整数自增加
     将证书转成字符串
     调整文件当前的偏移量到文件头
     将字符串写会文件
    当多个进程同时执行这个过程的时候，就会出现：竞争条件，
    多个进程可能同时从文件独到同一个数字，并且分别对同一个数字加并写回，
    导致多次写回的结果并不是我们最终想要的累积结果。 
     
      
     
     =  _
        {
        
        
    }
        
     =   
        {
        
        
    }
     = \
     = 
    
      
      _
     =   
        
    
    
}

 
{
    _ 
     

     = {
         = 
            {
            
            
        }

          ==  {
            _
        }
    }

     = {
        
    }
}
这个程序做后执行的效果如下：
   
         
     
   
    
  
     
   
    
  
     
   
    
 
我们执行了三次这个程序，每次结果都不太一样，第一次是，第二次是，第三次是，全都没有得到预期结果，这就是竞争条件引入的问题。仔细分析这个进程我们可以发现这个竞争条件是如何发生的：
最开始文件内容是，假设此时同时打开了个进程，那么他们分别读文件的时候，这个过程是可能并发的，于是每个进程读到的数组可能都是，因为他们都在别的进程没写入之前就开始读了文件。于是三个进程都是给加，然后写了个回到文件。其他进程以此类推，每次个进程的执行顺序可能不一样，于是结果是每次得到的值都可能不太一样，但是一定都少于产生的实际进程个数。于是我们把这种多个执行过程如进程或线程中访问同一个共享资源，而这些共享资源又有无法被多个执行过程存取的的程序片段，叫做临界区代码。
那么该如何解决这个的问题呢？对于这个例子来说，可以用文件锁的方式解决这个问题。就是说，对临界区代码进行加锁，来解决竞争条件的问题。哪段是临界区代码？在这个例子中，两端 之间的部分就是临界区代码。一个正确的例子是：

     =  _
      ==  {
        
        
    }

     =   
        {
        
        
    }
     = \
     = 
    
      
      _
     =   
     =  _
      ==  {
        
        
    }

我们将临界区部分代码前后都使用了的互斥锁，防止了临界区的。这个例子虽然并没有真正达到让多个进程通过文件进行通信，解决某种协同工作问题的目的，但是足以表现出进程间通信机制的一些问题了。当涉及到数据在多个进程间进行共享的时候，仅仅只实现数据通信或共享机制本身是不够的，还需要实现相关的同步或异步机制来控制多个进程，达到保护临界区或其他让进程可以处理同步或异步事件的能力。我们可以认为文件锁是可以实现这样一种多进程的协调同步能力的机制，而除了文件锁以外，还有其他机制可以达到相同或者不同的功能，我们会在下文中继续详细解释。
再次，我们并不对这个方法本身进行功能性讲解。这种功能性讲解大家可以很轻易的在网上或者通过别的书籍得到相关内容。本文更加偏重的是环境提供了多少种文件锁以及他们的区别是什么？
和
从底层的实现来说，的文件锁主要有两种：和。需要额外对说明的是，它只是系统调用的一个封装。从使用角度讲，或实现了更细粒度文件锁，即：记录锁。我们可以使用或对文件的部分字节上锁，而只能对整个文件加锁。这两种文件锁是从历史上不同的标准中起源的，来自而来自，所以或实现的锁在类型上又叫做锁。
除了这个区别外，系统调用还可以支持强制锁 。强制锁的概念是传统为了强制应用程序遵守锁规则而引入的一个概念，与之对应的概念就是建议锁 。我们日常使用的基本都是建议锁，它并不强制生效。这里的不强制生效的意思是，如果某一个进程对一个文件持有一把锁之后，其他进程仍然可以直接对文件进行各种操作的，比如、、。只有当多个进程在操作文件前都去检查和对相关锁进行锁操作的时候，文件锁的规则才会生效。这就是一般建议锁的行为。而强制性锁试图实现一套内核级的锁操作。当有进程对某个文件上锁之后，其他进程即使不在操作文件之前检查锁，也会在、或等文件操作时发生错误。内核将对有锁的文件在任何情况下的锁规则都生效，这就是强制锁的行为。由此可以理解，如果内核想要支持强制锁，将需要在内核实现、、等系统调用内部进行支持。
从应用的角度来说，内核虽然号称具备了强制锁的能力，但其对强制性锁的实现是不可靠的，建议大家还是不要在下使用强制锁。事实上，在我目前手头正在使用的环境上，一个系统在  分区的时候报错  ，而另一个系统虽然可以以强制锁方式上分区，但是功能实现却不完整，主要表现在只有在加锁后产生的子进程中才会报错，如果直接是没问题的，而且其他进程无论还是、都没问题   。鉴于此，我们就不在此介绍如何在环境中打开所谓的强制锁支持了。我们只需知道，在环境下的应用程序，和在是锁类型方面没有本质差别，他们都是建议锁，而非强制锁。
和另外一个差别是它们实现锁的方式不同。这在应用的时候表现在的语义是针对文件的锁，而是针对文件描述符的锁。我们用一个例子来观察这个区别：
   
 
 
 
 
 
 
 
 

  

 
{
     
    _ 

     =  _|_|_ 
        {
        
        
    }

      _   {
        
        
    }
     \ 

     = 
        {
        
        
    }

      ==  {

         =  _|_|_ 
            {
                
                
        }

          _   {
            
            
        }
         \ 
        
    }
    
    
    
}
上面代码是一个的例子，其作用也很简单：

打开文件。
使用对其加互斥锁。
打印“：！”表示加锁成功。
打开一个子进程，在子进程中使用对同一个文件加互斥锁。
子进程打印“：！”表示加锁成功。如果没加锁成功子进程会推出，不显示相关内容。
父进程回收子进程并推出。

这个程序直接编译执行的结果是：
   
 
 
父子进程都加锁成功了。这个结果似乎并不符合我们对文件加锁的本意。按照我们对互斥锁的理解，子进程对父进程已经加锁过的文件应该加锁失败才对。我们可以稍微修改一下上面程序让它达到预期效果，将子进程代码段中的注释取消掉重新编译即可：


         =  _|_|_ 
            {
                
                
        }


将这段代码上下的 删除重新编译。之后执行的效果如下：
   
         
   
 
此时子进程的时候会阻塞，让进程的执行一直停在这。这才是我们使用文件锁之后预期该有的效果。而相同的程序使用却不会这样。这个原因在于和的语义是不同的。使用或的锁，在实现上关联到文件结构体，这样的实现导致锁不会在之后被子进程继承。而在实现上关联到的是文件描述符，这就意味着如果我们在进程中复制了一个文件描述符，那么使用对这个描述符加的锁也会在新复制出的描述符中继续引用。在进程的时候，新产生的子进程的描述符也是从父进程继承复制来的。在子进程刚开始执行的时候，父子进程的描述符关系实际上跟在一个进程中使用复制文件描述符的状态一样参见《环境高级编程》节的文件共享部分。这就可能造成上述例子的情况，通过产生的多个进程，因为子进程的文件描述符是复制的父进程的文件描述符，所以导致父子进程同时持有对同一个文件的互斥锁，导致第一个例子中的子进程仍然可以加锁成功。这个文件共享的现象在子进程使用重新打开文件之后就不再存在了，所以重新对同一文件之后，子进程再使用进行加锁的时候会阻塞。另外要注意：除非文件描述符被标记了标记，锁和锁都可以穿越，在当前进程变成另一个执行镜像之后仍然保留。
上面的例子中只演示了所产生的文件共享对互斥锁的影响，同样原因也会导致或所产生的文件描述符对在一个进程内产生相同的影响。造成的锁问题一般只有在多线程情况下才会产生影响，所以应该避免在多线程场景下使用对文件加锁，而则没有这个问题。
为了对比的行为，我们在此列出使用的相同例子，来演示一下它们的不同：
   
 
 
 
 
 
 
 
 

  

 
{
     
    _ 

     =  _|_|_ 
        {
        
        
    }

      _    {
        
        
    }
     \ 

     = 
        {
        
        
    }

      ==  {

         =  _|_|_ 
            {
            
            
        }

          _    {
            
            
        }
         \ 
        
    }
    
        
    
}
编译执行的结果是：
   在子进程不用重新打开文件的情况下，进程执行仍然被阻塞在子进程加锁的操作上。关于对文件实现记录锁的详细内容，大家可以参考《环境高级编程》中关于记录锁的章节。
标准库文件锁
语言的标准库中还提供了一套文件锁，它们的原型如下：
 

  
  
  
从实现角度来说，库中实现的文件锁与或有本质区别。作为一种标准库，其实现的锁必然要考虑跨平台的特性，所以其结构都是在用户态的结构体中实现的，而非内核中的数据结构来实现。这直接导致的结果就是，标准的锁在多进程环境中使用是有问题的。进程在的时候会复制一整套父进程的地址空间，这将导致子进程中的结构与父进程完全一致。就是说，父进程如果加锁了，子进程也将持有这把锁，父进程没加锁，子进程由于地址空间跟父进程是独立的，所以也无法通过结构体检查别的进程的用户态空间是否家了标准库提供的文件锁。这种限制导致这套文件锁只能处理一个进程中的多个线程之间共享的 的进行文件操作。就是说，多个线程必须同时操作一个用打开的 变量，如果内部自己使用重新打开文件，那么返回的 地址不同，也起不到线程的互斥作用。
我们分别将两种使用线程的状态的例子分别列出来，第一种是线程之间共享同一个 的情况，这种情况互斥是没问题的：
   __
 
 
 
 
 
 
 
 
 

  
  
  
  

 _ 
{
     
      
     

    

       _ ==  {
        
    }
     =    

     = 
    
      
       _ ==  {
        
    }
     =    

    

     
}

 
{
    _ 
     

     =  
      ==  {
        
        
    }

     = {
         _  _  =  {
            _
            
        }
    }

     = {
         _  =  {
            _
            
        }
    }

    

    
}
另一种情况是每个线程都重新打开一个描述符，此时线程是不能互斥的：
   __
 
 
 
 
 
 
 
 
 

  
  
  

 _ 
{
     
      
     
     

     =  
      ==  {
        
        
    }

    

       _ ==  {
        
    }
     =    

     = 
    
      
       _ ==  {
        
    }
     =    

    

    
     
}

 
{
    _ 
     


     = {
         _  _  =  {
            _
            
        }
    }

     = {
         _  =  {
            _
            
        }
    }


    
}
以上程序大家可以自行编译执行看看效果。
文件锁相关命令
系统为我们提供了命令，可以方便我们在命令行和脚本中使用文件锁。需要注意的是，命令是使用系统调用实现的，所以在使用这个命令的时候请注意进程关系对文件锁的影响。命令的使用方法和在脚本编程中的使用可以参见我的另一篇文章《编程之常用技巧》中的并发编程和这部分内容，在此不在赘述。
我们还可以使用命令来查看当前系统中的文件锁使用情况。一个常见的现实如下：
   
                                  
                                      
                                       
                                    
                                        
                                        
这其中，主要表示锁类型，就是上文我们描述的和。和实现的锁事类型。表示是否事强制锁，表示不是。如果是记录锁的话，和表示锁住文件的记录位置，表示目前锁住的是整个文件。主要用来表示锁的权限，实际上这也说明了锁的共享属性。在系统底层，互斥锁表示为，而共享锁表示为，如果这段出现则表示有其他进程正在等待这个锁。其余参数可以参考 。
最后
本文通过文件盒文件锁的例子，引出了竞争条件这样在进程间通信中需要解决的问题。并深入探讨了系统编程中常用的文件锁的实现和应用特点。希望大家对进程间通信和文件锁的使用有更深入的理解。
大家好，我是！
如果你喜欢本文，欢迎在微博上搜索“”关注我，地址是：
大家也可以在微信上搜索：系统技术 关注我的公众号。
我的所有文章都会沉淀在我的个人博客上，地址是：。
欢迎使用以上各种方式一起探讨学习，共同进步。译者注：微服务和容器很好地结合了，但是它们的结合让日志记录也变成了一个难题。作者在本文描述了一些因素，在设置监控的时候是需要考虑的。以下为译文
在过去的几年中，容器已经成为领域的一个重要话题，尤其是在领域。简单地说，当从一个环境迁移到另一个环境时，容器提供了一种简单且可扩展的方法可以运行软件。
容器是通过在一个包中提供完整的运行环境实现的，其中就包括了应用程序，所有的依赖项，库，其它二进制文件以及运行时所需的配置文件。
与容器紧密结合的是微服务，它代表了开发应用程序的一种更灵活的方式。微服务体系结构将应用程序构建为一组松耦合的服务，这些服务通过处理离散业务功能的连接起来。微服务主要为应用程序开发提供了一种“分而治之”的方法，而不是一个大型的单一代码库。
在容器的基础架构领域是处于世界领先地位的，它是一个部署容器级软件应用的平台。容器的真正价值在于它们允许团队动态地启动一个完整的运行环境。可以说是让企业采用微服务的最具影响力的平台。
类似于虚拟机通过向来自一个服务器的终端用户提供一个操作系统的多个实例来简化软件开发和测试，容器在应用程序和主机操作系统之间添加了一个额外的抽象层。最大的不同是，容器不需要管理程序，只运行操作系统的一个实例总的来说，这等同于内存更少，运行时间更快。
与开发任何应用程序一样，日志记录是过程的中心部分，在出现问题时尤其有用。但是，在集装箱化应用程序的世界里，与传统应用程序相比，它是不同的。日志实际上意味着不仅记录应用程序和应用程序主机操作系统，以及服务。在处理多码应用程序时，有许多日志记录技术和方法可以记住。我们将在下面详细介绍前五种最佳实践。
基于应用程序的日志记录
在基于应用程序的方法中，容器内的应用程序使用日志框架来处理日志记录过程。例如，某个应用程序可能会使用 来对日志文件格式化，然后发送到远程服务器，并完全绕过环境和操作系统。
虽然基于应用程序的日志记录使开发人员对日志事件有了最大的控制权，但是这种方法也会在应用程序过程中产生大量的消耗。这种方法对于那些工作在传统应用程序环境中的人来说可能是有用的，因为它允许开发人员继续使用应用程序的日志框架例如 而不需要向主机添加日志功能。
 实际上意味着不仅需要记录应用程序和主机操作系统，还包括了服务。
使用数据卷
容器本质上是临时的，这意味着如果容器关闭了，那么容器内的任何文件最终都会丢失。相反，容器必须将日志事件转发到集中式日志记录服务比如，或者将日志事件存储在数据卷中。数据卷的定义为“容器内的一个标记目录，该目录用来保存持久或共享的数据”。
使用数据卷来记录事件的好处是，由于它们链接到主机上的一个目录，所以日志数据仍然存在，并且可以与其它容器共享。这种方法的优点是它减少了在容器失败或关闭时丢失数据的可能性。在这里可以找到关于在中设置数据卷的说明。
日志驱动
在中进行日志记录的第三种方法是使用平台的日志驱动程序将日志事件转发给在主机上运行的实例。日志驱动程序直接从容器的和输出里面读取日志事件这就消除了从日志文件中读取和写入的需要，最终也会稍微改善性能。
然而，使用日志驱动程序也有一些缺点
它不允许进行日志解析，只允许进行日志转发。
日志命令只与日志驱动程序文件一起工作。
当服务器不可访问时，容器就会终止。
这里可以找到为配置默认日志驱动程序的说明。
容器专用日志
这种方法的主要优点是允许在环境中完全地管理日志事件。由于专用的日志容器可以从其他容器收集日志事件，聚合它们，然后将事件存储或转发到第三方服务，这种方法消除了对主机的依赖。
专用日志容器的其它优点是
自动收集、监视和分析日志事件。
在没有配置的情况下自动缩放日志事件。
通过多个日志事件、和 数据流来检索日志。
方法
已经成为管理微服务架构的流行方法。的想法来自于类似摩托车的是如何附着在摩托车上的。引用一个消息源，“作为第二个过程在你的服务旁边运行，并通过类似于上的  这样一个同类接口提供了’平台基础设施’的特性。”
从日志记录的角度来看，方法的优点是每个容器都与它自己的日志容器有关应用程序容器保存日志事件和日志容器标记，然后像那样将它们转发到日志管理系统。

在这里查看图片灵感 方法对于大型部署来说尤其有用，因为这些部署需要有更专门的日志信息和自定义标记。不过，建立非常复杂，而且难度也很大。原文：    作者： 翻译：一、基本语法

资料地址：
新增特性：
   ： 变化
   ： 新增类型，可以与进行互换，以字母作为前缀
   ： 新增进行格式化处理
   ： 里面删除了 ， 新增  
二、数据分析
 基本理论
资料地址：

数据处理的最基本前期工作：
： 类别型数据
明确取值类别
明确每类取值的分布
： 数值型数据
了解极值与分位情况
了解正态性，均值，方差情况
了解变量相关性
： 通用处理
缺失值情况
重复性情况
—— ——————     
常见的任务分类：
： 分类问题
： 回归问题
： 聚类问题
： 时序分析问题
 基本工具

： 
： 和
的工具：   
机器学习
量化分析与回测：
： 图像处理
： 自然语言处理
 
资料地址：
数据结构： 
 
： 
  

 
资料地址：
 ： 包括样本切割，特征提取，
 _： 包括特征选择，交叉验证等
  ： 包括 等
 ： 分类器、回归、聚类


 
资料地址：




 
资料地址：

 
资料地址：

三、金融数据分析基础
 业务背景
客户类型，业务类型，建模类型

 金融数据分析建模基础
的常用方法
极值、缺失值的处理方法
标准化与归一化的处理
变量的编码方式
变量分箱的常用方式
值的计算与经验判断
的计算， 编码
交叉验证的策略与评价
各类模型的优缺点， 各类模型对输入的质量敏感性程度
各类模型的调参经验总结

四、数据分析实例
 ： 做玻璃分类——、、
示例代码：_
第一步：用读取文件， 用方法查看
第二步：查看直观特征：
    查看有几行几列
   获取每一列的表头名称，可以将过滤掉，只留下
   可以预览读取的数据行
   可以查看的数据类型
第三步：查看简单的统计特征：
   可以查看   
   比如：通过可以查看各个的取值范围是否大概一致，如果相差太大，要做归一化处理
   _可以用来查看样本里面标签的取值与对应个数情况
   比如：如果某个取值的数目特别多，表名样本非常不平衡，需要做 等相关处理，或者将样本分割一下
第四步：查看可视化的统计特征：
   的计算与描述——每个单变量与的分布情况——
   查看哪些变量需要做归一化处理——
   查看两两变量之间的关系——
第五步： 分割数据集： 和 可以直接用_里面的__
第六步：使用分类器做分类算法， 看各个取值下的准确率，从而决定_
第七步：使用模型 ，查看的准确率
提升模型准确率：
非平衡样本的数据处理
特征的归一化处理
其他分类器的尝试
尝试获取更多的数据
 ： 逻辑回归做  借贷数据分析
资料地址：
第一步：文件目录相关操作  
 某个文件或目录是否存在
拼接目录地址
第二步：文件压缩与解压相关操作：  
   
 
第三步： 里面取到某个列的数据， 做类型转换：
    = _
   =
   =_  
   将日期换成月份：将变更为
   _=  _
第四步：观察数据
直观情况：_、_、_
类型分布：___
按时间统计： 新增一列作为   这个列
__=___
___=__
____=
____=____ _    ____=_____    _____=_____
查看多变量间的分类统计情况：
___=___
____=____
___=__
____=____
第五步：处理 变量，改成这样的
_=__  
_=__
__=_
__=__
____=__
第六步：原始特征选择
第七步：缺失值处理
第八步：开始学习
  ： 、   
  ： 处理不平衡数据： 
  ： 分割   
  ： 选择模型，  
  ： 交叉验证调整最优化的超参数： __
  迭代策略的选择： 
 交叉验证评估的度量： 类型 _
 ： 股票量化示例
资料地址：
股票收益率   的计算
使用提供的接口，获取上证指数的价格数据
使用提供的接口，获取某只股票的价格数据
股票价格服从分布， 所以对价格数据，需要求 的序列
 _ = 
两个序列处理缺失值： 方案， 
_加入截距数据
 _
调用  两个 序列
  _
查看的情况：
 _
预测某只指数的涨跌
使用读取某只指数股票的日线数据
生成对应的时滞序列： 
   _{}   = _  
每天的涨跌：
   _ = __  
   _{}   = \_{}  _  
   _ = _
分割  
 = __ 
  = __   
_ =   
_ =   _
_ =  = _
_ =   _
_ =  = _
选择不同的模型，交叉验证获取优化的超参数，在 上， 在 上， 评估模型的优劣
 ： 银行客户流失预警模型
资料地址：
使用读取个数据源文件
  ：   =‘’
区分数据类型：
  

     

  

     
 
： ， 看的偏度，分布
： ， 看所有的分布比对哪些需要做归一化、标准化
： ， 看两两之间的关联情况
：  各个取值与的分布情况——合并多张图、轴
： 查看是否需要做截断，截断前和截断后与的关系
 变量预处理：
： 时间变量的处理，作为或者作为基于某一天之间的天数
统一处理两个时间的格式，转变为变量，两者相减之后取属性
 = 

 = 

 =     

 =     

 =       
： 类别变量的编码，
最常用的做法， 用变量在这个变量的某一类中的比率来代替这一类的取值。
如： =’女’——用等于‘女’的坏样本比率来替代
=’男’——用等于‘男’的坏样本比率来替代
第二种做法，添加哑变量，适合于取值较少的情况
如： =’’
=’’
用， 这两个变量来替换掉这个变量
第三种做法，用变量的某一类在样本中的出现次数来代替。
如： =’’出现次，‘’‘’用表示
 =’’出现次，‘’用表示
：  的处理
判断是不是有存在 ——从原始数据中取出非数据，比对
       

 =  == 

  == 

       {}
数值型变量的 ，通常超过均值上下个标准差就算
： 去掉使用循环的思维： 
      

       

   

    = 

 =         
变量衍生
   ： 之间相除得到某个
   ： 的均值，最大值，最小值
   ： 的求和
模型选择与训练：
   ： __
   ： 选择模型：
 
神经网络
   ： 参数调整：
默认参数，  
   ： 查看    
 ： 互联网金融银行 申请评分卡模型
资料地址：
使用读取个文件
查看个文件里面的，是否存在有的有值，有的没值， 取个里面都有的数据出来做 
_ _ _ =   
__ = _  _|_  _|_  _|_  _
能够去掉里面的重复数据
特征衍生：
： 一些原始变量，衍生不同 下面的 等变量
： 变量：
如果缺失率超过， 则去掉这个变量
如果不超过，作为一种特殊取值留着
： 变量：
如果缺失率超过， 则去掉这个变量
如果不超过，则考虑用填充的方式进行填充， ， 
特征分箱：
： 变量：
如果分类的取值个数个，则用每种分类里面的 代替每个分类
如果分类的取值个数=个，则看最大的那个， 如果这个的超过， 则去掉这个变量。 如果这个的坏样本占比为， 则将这个与最小的那个合并， 再重新  
： 变量：
使用卡方分箱方法，  个
查看每个里面的 ，如果 不单调，则降低的个数重新分
查看 的占比，如果超过， 则删掉这个变量
变量选择：
   ： 计算每个剩下来的变量的值， 值
   ： 取= 的所有变量
   ： 生成变量对， 计算变量对之间的相关系数，如果相关系数大于某个阈值取， 则变量对里面选值高的那个变量入模
   ： 查看每个变量的值，  =    的去掉
   ： 循环检查入模变量是否显著，如果不显著取为不显著，就去掉之后再跑一遍
   ： 直到所有变量都是显著的为止
跑基础的逻辑回归模型， 将 序列化存下来
    =  
    =__
   
   
跑正则化的逻辑回归模型，  和  采用不同的惩罚系数
   ： 用交叉验证的方式  ：
   __ = =_ = = _={_ }
   ___ = ____
   ： 序列化应用的逻辑回归模型
可以通过随机森林的方式确定变量的重要性， 根据随机森林的结果如： 取  的变量入模等来跑逻辑回归模型作者 | 京露编辑 | 吕力

吕力，腾讯助理工程师，毕业于华中科技大学计算机科学与技术专业，目前在腾讯社交网络事业群运营部担任运营开发工程师，致力于自由地写好程序，为人类进步添砖加瓦。

前言
逻辑层业务机器上如果有数据落地处理，可能会考虑的一个因素就是磁盘读写性能是否能满足要求，于是有必要进行测量。本文将介绍一些具体的测试操作。
获取
  查看，单位是，得到的是大小。


命令测算读写
写
命令从写，设置的块大小，命令写了的数据，性能是，对应
结论：写磁盘，在块大小为的情况下，每秒最大，写性能最高

读
读的文件，设置=，耗时，读性能为，也即
结论：读磁盘，在块大小为的情况下，每秒最大，读性能最高

测读
是一个专门用来获取磁盘参数的命令，可以看到 是，与命令差不多，也不知道用的多大的块大小，图中的 读的是内存。

相关推荐
性能测试报告容器健康检查详解蔡述雄，现腾讯用户体验设计部空间高级工程师。智图图片优化系统首席工程师，曾参与《众妙之门》书籍的翻译工作。目前专注前端图片优化与新技术的探研。

年，乃至接下来整个年，如果你要问前端技术框架什么最火，那无疑就是前端三巨头：、、。没错，什么，，等都逐渐脱离了热点。面试的时候不吹上一点新技术，好像自己就不是搞前端的似的。当然，希望大家都是抱着好学的心来开始一门学艺的，不管怎样，求求你，请接着看下去吧
本系列文将会通过很多一目了然的例子和一个实战项目——组件库，来帮助大家学习，一步一步来，毕竟这篇文章还有接下来的【升学篇】和【结业篇】呢。
什么是
不管你想不想了解，你只需要大概知道，就是和一样是一个前端框架，它的中心思想就是数据驱动，像远古时代的老前辈是结构驱动，什么意思呢，以前我们写代码时常用我把值改变了，这种写法先要获得结构，然后再修改数据更新结构，而的做法直接就是=我改变了，然后就会同步到某个结构上，视图管理抽象为数据管理，而不是管理结构了。不懂没关系，慢慢来。
还有一点必须要知道的是，是国人写的，技术文档也妥妥的是中文，想到这我就有学习的动力。
搭建环境
工欲善其事必先利其器，我们的学习计划从学会搭建所需要的环境开始，和的环境不用说是必须的，现在前端流程化很热门，基本上新的技术都会在这套流程的基础上做开发，我们只需要站在巨人的上装就可以了。我假设你的机子上已经有了最新的和了，那我们就只需要执行以下命令：
    
构建完了之后，随便进入一个我们事先准备好的目录，比如目录，然后在目录中做初始化操作：
    
参数是指这个项目将会在开发和完成阶段帮你自动打包代码，比如将文件统一合成一个文件，将文件统一合并压缩等。要是不知道的话，建议先了解下为好，当然不了解也不影响我们接着往下走。
的过程中会问你给项目定义一些描述，版本之类的信息，可以不管，一直输入确定跳过，完成之后出现以下界面，红框部分会提示你接下来要做的操作，按照它的提示继续敲代码就对了。

 
 
  
  是安装项目所需要的依赖，简单理解就是安装一些必要的插件，需要等一段时间；
   是开始执行我们的项目了，一旦执行这个命令之后，等一小会，浏览器应该会自动帮你打开一个为的链接，这个链接就是我们本地开发的项目主页了，如果没有，说明出错了。请移步到评论区回复吧。。。
：开发完成后执行  会编译我们的源代码生成最终的发布代码，在目录下

看看都给我们生成一些什么文件，这其中我们需要关注的是以下文件

保存一些依赖信息，保存一些项目初始化配置，里面保存一些的初始化配置，是我们的首页，除了这些，最关键的代码都在目录中，在很多服务器语言中都是预设为首页，像，等；打开目录中的，会看到这样的代码

说明我们的入口文件在目录中的，接下来我们就分析下这些初始化代码先；
跟着代码走
的核心架构，按照官方解释和个人理解，主要在于组件和路由两大模块，只要理解了这两大模块的思想内容，剩下使用就只是分分钟的事情了。所以在我的系列文中，会围绕组件和路由教大家开发一个前端组件库，这个过程也是我个人学习的练手项目，个人觉得一步步做下来之后，对的理解就可以算是出师了，胜过读遍书籍文档，那是后话了，先让我们看看最基本的生成的默认代码吧！
         `` 
           
   
   
   

 = 

   
 {
   
  
   
   {  }
}
先是第一句 
   
这句很好理解，就像你要引入一样，就是，然后就是；然后又引入了文件，也就是目录中和同级的文件；在中引入文件可以直接用，文件后缀名可以是，这是自己的文件类型，之前说的会将和文件打包，同样的道理，在中配置插件后项目默认配置，就可以将类型的文件整合打包，这和中差不多的道理。
说回这个文件，这是一个视图或者说组件和页面，想象一下我们的中什么也没有，只有一个视图，这个视图相当于一个容器，然后我们往这个容器中放各种各样的积木其他组件或者其他页面，中的内容我们后面说；
   
这句代码引入一段路由配置，同样的后边说很快就说到的不用急
接下来的  实例化，其实就相当于平时我们写时候常用的啦，然后声明：，意思是将所有视图放在值为这个元素中，表明引入的文件，即上述的文件，这个文件的内容将以这样的标签写进去中，总的来说，这段代码意思就是将放到中，然后以来指代我们的。
   
   引入这个组件
   引入路由配置

 = 

   
 {
   最后效果将会替换页面中为的元素
  使用路由
   告知页面这个组件用这样的标签来包裹着并且使用它
   {  }告知当前页面想使用这个组件
}
单页面组件
好了，现在打开我们的文件，在中，官网叫它做组件，单页面的意思是结构，样式，逻辑代码都写在同一个文件中，当我们引入这个文件后，就相当于引入对应的结构、样式和代码，这不就是我们做前端组件化最想看到的吗，从前的、也有这样的文件思想。

   =
     =
    
  



  {
   
}



 {
      
   
   
   
   
   
}

端之所以能识别文件，是因为前面说的在编译时将文件中的，，都抽出来合成新的单独的文件。
单页面组件会在后面的实战中完整体现，这里先不做过多描述；
看到我们文件内分为三大部分，分别是，很好理解结构，脚本，样式；就像一样暴露一些接口，可以看到我们的标签中除了一张图片之外就只有一行代码：


   =
     =
    
  

回看我们的浏览器页面中，图片是有了，可下面的文本和链接的代码写在哪里了呢？这里就要开始涉及路由了。

路由
这里补充下路由的大致概念：传统的路由是由服务器端根据一定的规则匹配来返回给前端不同的页面代码，如以下地址
 和 
注意这里只有和，这些不带的地址其实是服务器端经过一层封装指定到某些文件上去。同样的道理，前端也可以根据带锚点的方式实现简单路由不需要刷新页面

其中就是我们的锚点路由，注意开始我们在浏览器中打开的地址：
，
路由让我们可以访问诸如 或者 这些页面的时候不带刷新，直接展示。现在回到我们刚才打开的文件中看这行代码

这句代码在页面中放入一个路由视图容器，当我们访问的时候会将的内容放进去，访问的时候会将的内容放进去

如此看来，无论我们打开 还是页面中的图片都是公用部分，变得只是路由器里面的内容，那么路由器的内容谁来控制呢？
前面说的中有一句引入路由器的代码。
   
现在就让我们打开目录下的文件。
   
   
   
   
   



   {
   
    {
       
       
       
}
    {
       
       
       
}
    {
       
       
       
}
  
}
前面先引入了路由插件，然后显式声明要用路由  。注意到，等都是页面也可以是组件，接着注册路由器，然后开始配置路由。
路由的配置应该一目了然，给不同的分配不同的页面或组件，页面和组件其实是一样的概念，参数不重要只是用来做识别用的。看到这里就可以明白，前面说的红色框的内容，其实就是里面的内容，打开目录下的就能明白了。

到这里就可以完成路由的配置，我个人习惯喜欢把页面放在目录下，组件放在目录下，可能有人会问如果要访问的话要如何配置呢，很简单只要给路由加多一个子路由配置，如下：
{
       
       
       
       
        {
           
           
        }
        {
           
           
        }
      
    }
访问的时候会访问页面，里面放个路由器就可以了，然后访问的时候会往路由容器中放置的内容，访问的时候会往路由容器中放置的内容


    公用部分
    

小结
贯穿我们刚才学习的过程，从初始化到页面展示，的页面架构流程大概是这样的

总结下前面讲的内容先：

搭建环境
代码逻辑
单页面组件简单带过
路由
子路由

以上的流程就是我们刚开始接触时候的简单介绍，在之前就说过学习能掌握组件和路由的基本概念之后，对于我们后续了解他的工作机制有着很大的帮助，本篇章我们只是简单介绍了单页面组件，在下一篇文章中，我们将通过一个实战的项目，来充分了解组件化在构建中的重要性。
时间不早了，我也该回去睡觉了，消化一下，我们下一篇文章见
文末附上所有相关代码和官方文档地址


相关推荐
第二篇：《包学会之浅入浅出：升学篇》
第三篇：《包学会之浅入浅出：结业篇》作者：陆瑶瑶

一、概述
就是一个基于测试模型的用例生成工具。它主要应用于 模型。可以用来它可以直接读取 图形模型、模型、生成测试用例。
二、背景知识
要了解首先要了解是什么。
中文名称为基于模型的测试 基于模型的测试属于软件测试领域的一种测试方法。步骤如下：首先由被测系统，    的一些通常是功能方面描述，构建出被测系统的模型。再根据模型或模型中的一部分部分生成测试用例。进而进行软件测试。
 模型
模型的目的就是用来为构造测试用例而进行的被测系统描述。
在构造模型的这个阶段就可以已经发现许多问题。
模型的关键：
高度抽象
模型还包括被测系统的预期输出。
两个主要方面：
设计模型
测试模型
中模型通常有下列几种：
前置后置条件模型　       
基于转换的模型　    
随机模型：   
数据流模型　
模型验证：
语法
行为
举例：
一个测试模型可以由箭头和节点组成如下图所示。
一个箭头，代表了一次测试动作；
一个节点，代表一次测试验证。
 测试需求选择
  
目的：
指导测试用例生成器  如何生成用例。
测试需求选择包含方面：

模型中的目标结束条件

覆盖准则路径生成准则


状态覆盖
转换覆盖

行走算法

随机行走
覆盖引导
 测试用例生成
 
按模型及测试需求选择来生成测试用例。就是完成这部分工作的一个开源的工具。
 测试具体化
 
从测试套件到可执行级别，可以自己实现插件完成这部分功能。将测试用例转化成可执行脚本。
 执行测试
  
执行测试，并比较预期结果。
三、能做什么
就是一个基于测试模型的用例生成工具，完成上图中 的工作。给出一个测试模型及测试需求选择，能生成相应测试路径。由这个测试路径，可以用来执行你的测试脚本。它主要应用于 模型。可以用来它可以直接读取 图形模型、模型、生成测试用例。
四、通过建模
模型的目的是表达被测系统的预期行为。为此，我们使用有向图，其中顶点或节点表示一些期望的状态，并且边弧，箭头，过渡表示为了实现期望的状态需要做的任何动作。
例如，让我们来看一个需要验证的网站，然后才能访问网站内容。使用有向图设计测试可能如下所示：

  顶点
顶点表示我们想要检查的预期状态。在任何实现代码测试中，你可以通过断言或者数据校验改结果。
一个顶点称为节点，通常表示为一个框。
不在乎顶点的颜色或形状。
 边
表示从一个顶点到另一个顶点的方法。这是为了达到下一个状态需要做的任何动作。它可以选择一些菜单选项，单击按钮等测试动作。
只接受单向有向边箭头。不关心边有什么颜色或宽度。
 建模规则
顶点
顶点不是必需的。
如果使用，则必须有个且只有个顶点名称为：
从顶点出发只能有个边。
顶点不会包括在任何生成的测试路径中，它只表示一个开始位。
顶点或边的名字
名称是第一个单词，位于标签中边或顶点的第一行。
标签
标签是点或边上的所有文字描述。
守卫仅用于
守卫是一种只与边相关的机制。他们的角色与语句相同，并且使边有资格或者没有资格被访问。
守卫是一个用方括号括起来的条件表达式只有一个。
 == 
上面意味着如果属性等于，则边是可访问的。
操作仅用于
动作是仅与边相关联的机制。这是我们要在模型中执行的代码。它放在正斜杠之后。可以有多个，每个语句必须以分号结尾。
= =
是动作代码，它的执行结果将作为数据传递给守卫。
示例：

此示例说明和如何工作。
让我们从顶点开始：
_==
边缘的名称是_，后跟一个正斜杠，表示从该点开始直到行尾的文本是代码。该操作初始化个属性：和。
当我们走过上边缘时，我们到达_顶点。这个顶点有个边沿，都有。由于和在这一点上被初始化为，因此只有一个边可以用于步行：边_具有顶点_作为目的地。
假如，我们已经遍历边_和_，并再次到达顶点_，现在选择将选择具有顶点_作为目标的另一条边_。
这说明了如果我们需要这样做，我们如何能够通过图表来指导和控制模型执行路径。
模型中的关键字
在模型中使用关键词以增加功能和可用性。
  这在顶点中用于表示开始顶点。每个模型只有一个起始顶点。
  包含此关键字的顶点或边将在生成路径时排除。如果它是一个边，它将简单地从图中删除。如果它是一个顶点，顶点将被删除与其内外边缘。
  此关键字仅用于顶点。这意味着可以跳出当前模型，到任何其他模型到具有相同名称的顶点。 语法是： ：_
  只有一个顶点可以有这个关键字。在模型中使用数据时，需要初始化数据。这就是这个关键字。允许在更多的顶点中使用而不只是一个。 语法是： ： =   = 
  只有一个顶点可以有这个关键字。调用以根据需求标记。 语法是：：
多模型
可以在一个会话中使用几个模型。这意味着在生成路径时，可以选择跳出一个模型到另一个模型。当将不同的功能分为多个模型时，这是非常方便的。
控制模型之间跳转的机制是关键字。让我们看一个例子。考虑这个模型：

多模型运行举例：
       _ _  _  _  _  _  _  _ –
所有模型都加载到中，第一个模型模型是路径生成开始的地方。
当路径生成到达模型中的顶点_时，它必须考虑关键字： 这将告诉使用相同的名称搜索所有其他模型的同一个关键字：在我们的例子中，只有一个，它在模型中。现在决定是跳出模型，进入模型中的顶点_，还是留在模型中。这个决定是基于随机的。
此外，如果路径生成在模型中执行，并且它到达顶点_，则可以跳出模型，回到模型中的顶点_。
多模型特性
多模型之间的数据不通用。如上述模型，虽然模型与模型用相同变量，但在不同模型间跳转时。中的，与中的是不同变量。
多模型一起启动时，所有模型一起进行初始化。
多模型之间跳转，相当与自动在状态之间。建立条虚拟边，将根据算法选择是否前往状态。
 多模型之间跳转，以：标识的名称做作为查找对象，它要求为一个非空字符串。
五、路径生成器和结束条件
路径生成器连同停止条件将决定当通过模型生成路径时使用什么策略，以及何时停止生成该路径。路径发生器可以彼此连接。可以使用逻辑或，，||，使用多个停止条件。
 路径生成器
生成器是决定如何遍历模型的算法。不同的生成器将生成不同的测试序列，并且它们将以不同的方式遍历模型。多个发生器可以串联。
    
以完全随机的方式浏览模型。也称为“醉汉走路”或“随机步行”。该算法通过随机从顶点选择出边，并且在下一个顶点时重复此过程。
_    
尝试运行通过模型的最短路径，但以快速的方式。这是算法的工作原理：

选择一个尚未被随机访问的边。

使用算法选择到该边缘的最短路径

走该路径，并将所有执行的边标记为已访问。

当在步骤中达到选定的边缘时，从头开始，重复步骤 。

该算法对于非常大的模型工作良好，并且生成合理的短序列。缺点是当与结合使用时。该算法可以选择被守卫的路径。


_           
将生成到特定顶点或边的最短路径。
__ ==   
将计算并生成通过模型的最短路径。每个边缘的成本设置为 不建议使用此算法，因为对于较大的模型，并且使用模型中的数据，将需要相当长的时间来计算。
 结束条件
结束条件
_         
边覆盖率达到某个值时，模型遍历结束。停止标准是一个百分比数字。当在执行期间达到所穿过的边的百分比时，停止测试。如果一个边被遍历超过一次，当计算百分比覆盖率时，它仍然计为
_         
顶点覆盖率达到某个值时，模型遍历结束。停止标准是一个百分比数字。当在执行期间达到所遍历的顶点的百分比时，停止测试。如果顶点遍历超过一次，当计算百分比覆盖率时，它仍然计为。
_         
需求覆盖率达到某个值时，模型遍历结束。停止标准是一个百分比数字。当在执行期间达到所需求的百分比时，测试停止。如果需求遍历超过一次，在计算百分比覆盖率时仍会计为。
__      
高于依赖阈值的边都被覆盖时，模型遍历结束。每个边可以设置一个依赖值之间的百分比数字。停止标准是一个百分比数字。当在执行期间，所有高于或等于依赖值边被遍历完全时，停止测试。如果一个边被遍历超过一次，当计算百分比覆盖率时，它仍然计为。
_        
停止标准是指定的顶点。当在执行期间到达顶点时，测试停止。
_        
停止标准是指定的边。当在执行期间到达这条边时，测试停止。
_          
停止标准是表示允许测试发生器执行的秒数的时间。 请注意，时间与整个测试的执行进行比较。例如，这意味着，如果你有：
  个模型
 个模型中存在共享状态
 两者都具有设置为秒的时间停止条件
 两种型号将在秒后停止执行。即使一个模型没有访问过
   
条件是一个数字，表示由生成器生成的边顶点对的总数。例如，如果数字是，测试序列将是个动作包括对边和顶点。

这种特殊的停止条件永远不会停止。
 举例举例：
六、工作方式
 提供种工作方式
作为第三方库，可被测试程序直接调用。
作为可执行程序，以模式，加载，直接运行。
作为可执行程序，以模式，作为，提供服务。
 作为第三方库
作为第三方库，被测试程序调用
测试程序调用时，可以直接继承类。该类成员函数，可以配置在、中调用。在类初始化时中，以将所有类成员函数转化成了函数调用，存在的引擎中。函数名完全一致。作用是使原本的引擎可以调用代码。
以一个工程创建的测试举例。
新建一个目录，存放测试程序。
  _
 _
创建文件  复制以下代码到文件中。

同时，创建 复制以下代码。文件描述了测试程序用到的第三方包。可以看到，被包含在其中。如果本地没有该包，会自动从网上下载。

执行测试程序
运行 。执行测试程序。先下载了所需的包后，开始测试。
测试程序做了什么
首先，我们扩展类，它是 需要的执行上下文的接口。然后将传递给的构造函数。创建了一个的执行器。
以一个测试用例为例：

它的执行过程可以解释如下：
创建节点
创建图形或模型。
向模型中添加边。
这个边命名为：
向这条边添加守卫。 是条件表达式，这个将执行类成员函数得到返回值。如果返回值为，则边可以被访问以执行，否则不执行。
设置这条边的起点。这里设置的起点为顶点。
将顶点命名为：。
创建一个新的顶点，并将其设置为这条边的目标顶点。
刚建立的顶点命名为：。
为这条边添加一个操作。该操作是在遍历到边时执行的代码，调用函数。

构建模型使其不可变，并将其提供给。

创建一个路径生成器，并指定停止条件，并将其提供给。
将顶点设置为模型执行的起点。
创建一个的执行器，把传递给
只要路径生成器的停止条件未满足，将返回。
执行模型的下一步。
 以模式，加载
作为可执行程序，以模式，加载，直接运行。
见命令行，
 以模式，作为
作为可执行程序，以模式，作为，提供服务
见命令行，
七、命令行
  
  
全局选项会影响所有命令。一些选项，如版本，直接退出程序。
–             
–   
–     
 
    离线意味着生成测试序列一次，以后可以自动运行。或者，只是生成序列以证明具有路径生成器的模型与停止条件一起工作。
   _     _
– 返回数据格式为，默认
– 模型文件，一个  文件，后面跟着路径生成器及结束条件。这个选项可以出现多次。
– 加上这个选项将打印出模型中未访问到的元素，默认 
– 打印更多细节，默认
 
在线测试意味着基于模型的测试工具直接连接被测系统并进行动态测试。 将作为默认或 服务器启动。
– 返回数据格式为，默认
– 模型文件，一个  文件，后面跟着路径生成器及结束条件。这个选项可以出现多次。这个选线在模式 下有效、在模式 下无效。
– 作为 的端口号，默认
– 选则作为的启动模式  默认 或者 
默认。当  模式被选择了  选项无效。
– 选择元素作为开始元素第一个模型中。默认顶点。
– 加上这个选项将打印出模型中未访问到的元素，默认 
– 打印更多细节，默认
八、或服务的区别
运行作为或服务有什么区别？
 
同步，这使得客户端易于实现。
只能服务个客户端。
该服务当时只处理一个会话。模型可以使用加载调用上传，也可以在服务启动时的命令行中加载。
命令行举例：
启动    在默认端口   设置为 
       
启动 在端口 不进行
       
启动  在默认端口   设置为 服务启动是加载模型
          _
  
异步，这使得客户端实现有点复杂。可以同时为多个客户端服务该服务将处理多个连接。每个连接都将有一个唯一的会话。必须使用  调用来上传模型。它不会在命令行上加载任何模型
命令行举例：
启动   在默认端口    设置为 
     
启动   在端口 不进行
       
九、  接口
 
消息命令用于加载模型并启动服务。模型必须对模型使用格式。

加载和启动模型的请求示例。模型在标签内


如果请求成功 “” 为 “”

 
消息命令用于询问是否有任何元素在模型中执行。如果满足当前模型的所有停止条件，则对属性的响应将返回。



如果请求成功 “” 为 “”

 
消息命令用于从路径生成中获取下一个元素。 将给定路径生成器，计算下一个元素应该是什么，并在模型的执行中向前进一步。 在响应中返回元素名称。


如果请求成功 “” 为 “”

 
消息命令用于询问当前模型的当前各个变量的数据值



如果请求成功 “” 为 “”

 
每当发生时， 将发送消息给。此消息中的信息表示了模型遍历的进度。


十、 接口
 
调用以格式上载模型，并使用新测试重置。
 
    

请求成功，返回

 
如果有更多的元素要获取，将调用查询服务。如果是，则尚未达到停止条件的满足。
 


如果请求成功，“”将是“”。如果有更多的元素要获得，将是。

 
用于从路径生成中获取下一个元素。 将给定路径生成器，计算下一个元素应该是什么，并在模型的执行中向前一步。 在响应中返回元素名称。
 


如果请求成功，“”为“””  返回元素名

 
用于询问当前模型的当前各个变量的数据值。
 


如果请求成功，“”为“””   中返回各个变量的当前值。

 
用来设置当前模型中变量值
 


如果请求成功，“”为“”

  
模型重置为其初始状态。
 


如果请求成功，“”为“”

 
会终止测试会话的路径继续生成
 
    


 
调用将获取会话的当前统计信息
 


如果请求成功，“”为“”

十一、源码及构建
 编译前准备工作
·      
·  
· 
 获取源码

下载源码

通过获取源码


  
   包
 
    
可能遇到编译不过的情况。处理方法：

先一下，再重新编译。

 
    –
或
 
    

中为每个工程写了大量的单元测试。如果单元测试不过，也会造成编译不过去。这时，可以先注释掉某些。目录在每个工程对应目录下。

正确编译后，显示：
完成后，包目录

   工程结构


   

工具核心


路径选择算法具体实现所在位置。

路径遍历结束条件

执行到命令，获取是，将触发两个事件：_ _。
用户捕获事件，进行处理。

根据调用算法生成路径。

执行器。执行引擎、模型执行上下文环境、模型存储，都在这里。
：
模型类

文件解释器，用户解析文件

转换。用于解析各种格式模型输入。、、 、。以及将已有模型转换成各种格式模型输出、、 、。

提供的的  功能。及测试输出功能。

为作为提供支持。

 模式

 模式

相关推荐【腾讯】移动自动化测试框架对比微信读书排版引擎自动化测试方案在使用腾讯云  对象存储的过程中，我们经常有想要把整个  打包下载的需求，但是  并没有提供整个  打包下载的能力。这时，我们可以利用腾讯云的  无服务器云函数，完成   的打包，并重新保存压缩后的文件到  中，然后通过  提供的文件访问链接下载文件。
但是在使用  云函数进行   打包的过程中，偶尔会碰到这样的问题：我期望将某个   内的文件全部下载下来然后打包压缩，把压缩文件再上传到  中进行备份；但是在这个过程中，  内的文件可能数量多体积大，而  云函数的运行环境，实际只有  的  目录是可以读写的。这样算上下载的文件，和生成的  包，可能仅支持一定体积的文件处理，满足不了所需。怎么办？
在这种情况下，可能有的同学会想到使用内存，将内存转变为文件系统，即内存文件系统，或者直接读取文件并放置在内存中，或者在内存中生成文件。这种方法能解决一部分问题，但同时也带来了些其他问题：

 云函数的内存配置也是有上限的，目前上限是 。
 云函数的收费方式是按配置内存运行时间。如果使用配置大内存的方法，实际是在为可能偶尔碰到的极端情况支付不必要的费用，不符合我们使用  云函数就是要精简费用的目的。

我们在这里尝试了一种流式文件处理的方式，通过单个文件压缩后数据立即提交  写的方法，一次处理一个文件，使得被压缩文件无需在  的缓存空间内堆积，压缩文件也无需放在缓存或内存中，而是直接写入 。在这里，我们实际利用了两种特性： 文件的数据结构特性和  的分片上传特性。
 文件的数据结构
在官方文档中给出的  文件格式如下：
     

       
      
      
     
    
    
       
      
      
       
        
     
         
          
        
可以看到，实际的  文件格式基本是文件头文件数据数据描述符{此处可重复次}核心目录目录结束标识组成的，压缩文件的文件数据和压缩数据是在文件头部，相关的目录结构，文件信息存储在文件尾部。这样的结构，为我们后续  分片上传写入带来了方便，可以先写入压缩数据内容，再写入最终文件信息。
 分片上传
 分片上传按照如下操作即可进行：

初始化分片上传：通过初始化动作，获取到此次上传的唯一标识。此需要保存在本地并在后续上传分片时使用。
上传分片：通过初始化时获取到的，配合文件分片的顺序编号，依次上传文件分片，获取到每个分片的； 会通过  和分片顺序编号，拼接文件。
结束上传：通过初始化时获取到的，结合分片的顺序编号和，通知  分片上传已经完成，可以进行拼接。

在上传过程中，还随时可以查询已上传分片，或结束取消分片上传。
文件压缩处理流程设计
利用  文件数据结构中文件压缩数据在前目录和额外标识在后的特性，和  支持分片上传的特性，我们可以利用流式文件处理方式来依次处理文件，并且做到处理完成一个文件压缩就上传处理后的压缩数据分片。这种处理流程可以简化为如下说明：

初始化  文件数据结构，并将数据结构保存在内存中。
初始化  分片上传文件，保存好分片上传 。
下载要放入压缩包的文件至本地，使用  算法，生成压缩文件的数据内容并保存在内存中，并根据目录格式，更新数据格式中的目录标识。
将压缩后的文件数据使用  上传分片，上传至  中。
清理删除下载至本地的需压缩文件。
根据需要，重复  步骤，增加压缩包内的文件。
在压缩文件处理完成后，使用分片上传，将内存中的  文件数据结构最后的目录结构部分上传至 。
通知  结束上传，完成最终  文件的自动拼接。

在这个处理流程中，一次只处理一个文件，对本地缓存和内存使用都只这一个文件的占用，相比下载全部文件再处理，大大减小了本地缓存占用和内存占用，这种情况下，使用少量缓存和内存就可以完成  中大量文件的压缩打包处理。
使用进行  文件压缩处理实现
流式压缩文件库 
我们这里使用  开发语言来实现  文件压缩处理。我们这里使用了   和  模块。其中  模块是实现和包压缩的流式处理库，能够通过  输入欲压缩文件，通过  输出压缩后的文件流。的简单用法如下：
  
  = 
  = 

        
  = __  
  =  {
     {   }     
}

      


     
  = __  
 {   }

   
 {   }

               
                 

 将会在每次  文件的时候，将文件的压缩数据输出到  指定的输出流上。因此，我们在这里可以通过实现我们自身的 ，获取到  的写请求，并把写入内容转移到  模块的分片上传能力上。在这里，我们实现的  为：
  = 
  = 

 = 

 

  {
     
      
     = {}
   = 
   = 
   
}

 

_ =     {
  
  
}
通过集成  中的  ，我们可以将写操作转移到我们所需的  上去， 可以对接  的分片上传功能。 
 分片上传
 分片上传功能的实现如下，我们将其封装为  模块：
  = 

  = 
  {
      =  
    
    
     
}

 大于上传
  =     

  {
     = 
     = 
     = 
     = 
     = 
     =  
}

 =   {
     _ = 
        {
        _ = 
        
    }
}
 =   {
     _ = 
      = {
         
         
         
         
    } 
        {
          {
            
        }  {
            _  
        }
    }
}


 =   {
     = 
      =  {
          
        
         = 
         =  
    }  {
         =  
    }
}

 =     {
     = 
    {     }
      ==  {
        
    }
}

 =   {
      = {
           
    }
      = {
         
         
    } 
        {
          {
            
        }  {
            
        }
    }
}

 =   {
     = 
     
}

 = 
对于  本身已经提供的 ，我们在其基础上封装了相关查询，分片上传初始化，分片上传等功能如下：
  = 

  =  {
     
     
     
}
  =   = {
      = 
      = 
      = 
      = {
        
        
        
    }
        {
          {
              = `   {}   {}`
            
        }  {
             
        }
    }
}

  =   = {
        {
          {
            
        }
           
    }
}

  =   = {
        {
          {
            
        }
           
    }
}

  =   = {
        {
          {
            
        }
           
    }
}

  =   = {
        {
          {
            
        }
           
    }
}


 = {
    
    
    
    
    
}
在具体使用时，需要将文件中  相关登录信息的，，等替换为自身可用的真实内容。
功能入口实现函数
我们在最终入口函数  中使用各个组件来完成最终的目录检索，文件压缩打包上传。在这里，我们利用函数入参来确定要访问的  名称和所属地域，期望压缩的文件夹和最终压缩后文件名。云函数入口函数仍然为 _。
  
  = 
  = 

  = 

  = 

  = 

  =  

  =     = {
      = {
         
         
    }
      = {   } 

        {
          {
            
        }  {
              = 
              {
                  {
                    
                }
            }
              
        }
    }
}

  =     = {

      = {
         
         
    }
      =  {  } 

      = {   }

      =  {
         {   }     
    }
       {
        
    }

       {
        
    }

       {
        
    }

    

      {
            {
              = 
              = 
                 {
                 = {
                      = {   } 
                       = {
                          {
                            
                            
                        }
                          = 
                          
                         {   }
                          
                        
                          ==  {
                               
                            
                        }
                    }
                }
            }
        }
    }
}

_ =    = {
      = 
      = 
      = 
      = 
       
       
}
测试及输出
最终我们将如上的代码文件及相关依赖库打包为代码包，创建函数并上传代码包。同时我们准备好一个  命名为 ， 在其中创建  文件夹，并在文件夹中传入若干文件。通过函数页面的测试功能，我们使用如下模版测试函数：
{




}
函数输出日志为：

    _
    _
    _
    _
    _
     
  
可以看到函数执行成功，并从   根目录看到新增加的  文件。
项目源代码及改进方向
目前项目所有源代码已经放置在  上，路径为 。可以通过下载或   项目，获取到项目源代码，根据自身帐号信息，修改  文件内的帐号 、、这些认证信息，然后将根目录下所有文件打包至  压缩包后，通过  创建函数并通过  文件上传代码来完成函数创建，根据上面所属的“测试及输出”步骤来测试函数的可用性。
函数在此提供的仍然只是个代码，更多的是为大家带来一种新的思路及使用腾讯云  无服务器云函数和  对象存储。基于此思路，本身后续还有很多可以改进的方法，或根据业务进行变化的思路：

文件的处理目前还是下载一个处理一个，其实我们可以使用多线程和队列来加速处理过程，使用若干线程持续下载文件，使用队列对已经下载完成待处理的文件进行排队，然后使用一个压缩线程从队列中读取已下载的文件后进行压缩上传处理。这种方式可以进一步加快大量文件的处理速度，只是需要小心处理好缓存空间被使用占满后的等待和文件处理完成后的删除释放空间。
目前  从入参接受的是单个地域、、目录和输出文件，我们完全可以改造为从多个地域或拉取文件，也可以传递指定的文件列表而不是仅一个目录，同时函数执行触发可以使用  触发或  消息队列触发，能够形成更加通用的压缩处理函数。

后续对于此  如果有更多疑问，想法，或改进需求，欢迎大家提交   或 。项目地址：近日，在数据中心联盟组织的第五批大数据产品评测中， 腾讯云大数据平台取得了两项第一名，特别在性能上有非常亮眼的表现，其他各项成绩也名列前茅。本月日，中国通信标准化协会常务副秘书长、数据中心联盟理事长代晓慧在“大数据发展促进委员会年年会暨成果发布会”上，为包括腾讯云在内的通过测试的企业颁发了证书。

在本次数促会年会上，数据会办公室主任姜春宇对第五批大数据产品评测结果进行了通报，详细的解读了评测的方法和结果。大数据产品能力评测由数据中心联盟组织，并委托中国信息通信研究院实施测试，是国内起步最早、覆盖最广、技术水平最高、影响最大的大数据评测体系，圈定了国内大数据产品厂商第一梯队，为政府和行业用户选购大数据产品提供权威参考，可以方便政府和企业选购大数据产品。
大会中，腾讯云大数据资深架构师于涛进行了主题演讲，对腾讯云大数据与的硬件与技术实力、产品布局、未来发展等做了全面的介绍，同数据中心联盟的各成员进行了深入的交流。

腾讯云的大数据产品能力源自、空间、微信等海量业务的积淀。
截至年底，腾讯、空间、微信等全面产品线及亿万级数据资产背后，有着万亿条数据接入、亿次数据分发、的存储、的离线计算、万亿的实时计算、万次任务调度等亿万级的数据处理经验和能力，这些都是腾讯云大数据产品的坚固基石。
而从年第一个内部大数据集群上线以来，腾讯云大数据产品经过了多次迭代，进行多项腾讯社区组件的优化和自研组件的配置。用户可以按需部署大数据处理服务，实现数据处理需求，例如报表展示、报表分析、数据呈现、数据挖掘、数据分析等全面的大数据应用。
纵横数智，助画方略。腾讯云数智方略包含大数据平台、智能推荐、数字营销、数据可视化等产品，为企业及开发者提供完整的大数据解决方案，开源易用、多环境部署、安全合规、丰富的运维实践经验助力大数据解决方案在各行各业的开发与应用。
更多详情移步官网：导读
有个表做了分区，每天一个分区。
该表上有个查询，经常只查询表中某一天数据，但每次都几乎要扫描整个分区的所有数据，有什么办法进行优化吗？
待优化场景
有一个大表，每天产生的数据量约万，所以就采用表分区方案，每天一个分区。
下面是该表的：
  `` 
  ``    _
  ``   
  ``   
  ``   
  ``   
  ``   
  ``     _   _
  ``   
  ``     
  ``     ，
    ````
    `` ``````
   `_` ````
 = _=  =
     ``
       = 
        = 
        = 

该表上经常发生下面的慢查询：
   ``  `` =   ``    `` = 
优化之路
优化思路
想要优化一个，一般来说就是先看执行计划，观察是否尽可能用到索引，同时要关注预计扫描的行数，以及是否产生了临时表  或者 是否需要进行排序 ，想办法消除这些情况。
更进一步的优化策略则可能需要调整程序代码逻辑，甚至技术架构或者业务需求，这个动作比较大，一般非核心系统上的核心问题，不会这么大动干戈，绝大多数情况，还是需要靠尽可能发挥聪明才智来解决。
性能瓶颈定位
现在，我们来看下这个的执行计划：

      ``  
  `` =   ``    `` = \
   
            
  _ 
         
    
          
_ _
           
      _ 
           
          
          
这个执行计划看起来还好，有索引可用，也没临时表，也没。不过，我们也注意到，预计要扫描的行数还是挺多的  ，而且要扫描整个分区的所有数据，难怪效率不高，总是 。
优化思考
我们注意到这个总是要查询某一天的数据，这个表已经做了按天分区，那是不是可以忽略  子句中的 时间条件呢？
还有，既然去掉了  条件，反观表，剩下的条件貌似就没有合适的索引了吧？
所以，我们尝试新建一个索引：
        
然后，把改造成下面这样，再看下执行计划：
      ``   
  ``    `` = \
   
            
  _ 
         
    
          
_ _
           
      _ 
           
          
          
这优化效果，杠杠滴。

事实上，如果不强制指定分区的话，也是可以达到优化效果的：

      ``  
  `` =   ``    `` = \
   
            
  _ 
         
    
          
_ _
           
      _ 
           
          
          
后记
绝大多数的通过添加索引、适当调整代码例如调整驱动表顺序等简单手法来完成。
多说几句，遇到优化性能瓶颈问题想要在技术群里请教时，麻烦先提供几个必要的信息：

表
表常规统计信息，可执行     ‘’ 查看
表索引分布信息，可执行     查看
有问题的及相应的执行计划 没有这些信息的话，就别去麻烦别人了吧。有编程基础的同学可以借助此图分钟入门最基本语法，不喜勿喷，喜欢可以收藏
看不清楚可以右键保存图片查看数据库、操作系统和编译器并称为三大系统，可以说是整个计算机软件的基石。其中数据库更靠近应用层，是很多业务的支撑。这一领域经过了几十年的发展，不断的有新的进展。
很多人用过数据库，但是很少有人实现过一个数据库，特别是实现一个分布式数据库。了解数据库的实现原理和细节，一方面可以提高个人技术，对构建其他系统有帮助，另一方面也有利于用好数据库。
研究一门技术最好的方法是研究其中一个开源项目，数据库也不例外。单机数据库领域有很多很好的开源项目，其中  和  是其中知名度最高的两个，不少同学都看过这两个项目的代码。但是分布式数据库方面，好的开源项目并不多。  目前获得了广泛的关注，特别是一些技术爱好者，希望能够参与这个项目。由于分布式数据库自身的复杂性，很多人并不能很好的理解整个项目，所以我们希望能通过一系列文章，自顶向上，由浅入深，讲述  的一些技术原理，包括用户可见的技术以及大量隐藏在  界面后用户不可见的技术点。
本文为本系列文章第一篇。
保存数据

数据库最根本的功能是能把数据存下来，所以我们从这里开始。
保存数据的方法很多，最简单的方法是直接在内存中建一个数据结构，保存用户发来的数据。比如用一个数组，每当收到一条数据就向数组中追加一条记录。这个方案十分简单，能满足最基本，并且性能肯定会很好，但是除此之外却是漏洞百出，其中最大的问题是数据完全在内存中，一旦停机或者是服务重启，数据就会永久丢失。
为了解决数据丢失问题，我们可以把数据放在非易失存储介质比如硬盘中。改进的方案是在磁盘上创建一个文件，收到一条数据，就在文件中  一行。，我们现在有了一个能持久化存储数据的方案。但是还不够好，假设这块磁盘出现了坏道呢？我们可以做      ，提供单机冗余存储。如果整台机器都挂了呢？比如出现了火灾， 也保不住这些数据。我们还可以将存储改用网络存储，或者是通过硬件或者软件进行存储复制。到这里似乎我们已经解决了数据安全问题，可以松一口气了。，做复制过程中是否能保证副本之间的一致性？也就是在保证数据不丢的前提下，还要保证数据不错。保证数据不丢不错只是一项最基本的要求，还有更多令人头疼的问题等待解决：

能否支持跨数据中心的容灾？
写入速度是否够快？
数据保存下来后，是否方便读取？
保存的数据如何修改？如何支持并发的修改？
如何原子地修改多条记录？

这些问题每一项都非常难，但是要做一个优秀的数据存储系统，必须要解决上述的每一个难题。为了解决数据存储问题，我们开发了  这个项目。接下来向大家介绍一下  的一些设计思想和基本概念。

作为保存数据的系统，首先要决定的是数据的存储模型，也就是数据以什么样的形式保存下来。 的选择是  模型，并且提供有序遍历方法。简单来讲，可以将  看做一个巨大的 ，其中  和  都是原始的  数组，在这个  中， 按照  数组总的原始二进制比特位比较顺序排列。
大家这里需要对  记住两点：

这是一个巨大的 ，也就是存储的是  ；
这个  中的   按照  的二进制顺序有序，也就是我们可以  到某一个  的位置，然后不断的调用  方法以递增的顺序获取比这个  大的 。

讲了这么多，有人可能会问了，这里讲的存储模型和  中表是什么关系？在这里有一件重要的事情要说四遍：
这里的存储模型和  中的  无关！这里的存储模型和  中的  无关！这里的存储模型和  中的  无关！这里的存储模型和  中的  无关！
现在让我们忘记  中的任何概念，专注于讨论如何实现  这样一个高性能高可靠性的巨大的分布式的 。

任何持久化的存储引擎，数据终归要保存在磁盘上， 也不例外。但是  没有选择直接向磁盘上写数据，而是把数据保存在  中，具体的数据落地由  负责。这个选择的原因是开发一个单机存储引擎工作量很大，特别是要做一个高性能的单机引擎，需要做各种细致的优化，而  是一个非常优秀的开源的单机存储引擎，可以满足我们对单机引擎的各种要求，而且还有  的团队在做持续的优化，这样我们只投入很少的精力，就能享受到一个十分强大且在不断进步的单机引擎。当然，我们也为  贡献了一些代码，希望这个项目能越做越好。这里可以简单的认为  是一个单机的  。

好了，万里长征第一步已经迈出去了，我们已经为数据找到一个高效可靠的本地存储方案。俗话说，万事开头难，然后中间难，最后结尾难。接下来我们面临一件更难的事情：如何保证单机失效的情况下，数据不丢失，不出错？简单来说，我们需要想办法把数据复制到多台机器上，这样一台机器挂了，我们还有其他的机器上的副本；复杂来说，我们还需要这个复制方案是可靠、高效并且能处理副本失效的情况。听上去比较难，但是好在我们有  协议。 是一个一致性算法，它和  等价，但是更加易于理解。这里是  的论文，感兴趣的可以看一下。本文只会对  做一个简要的介绍，细节问题可以参考论文。另外提一点， 论文只是一个基本方案，严格按照论文实现，性能会很差，我们对  协议的实现做了大量的优化，具体的优化细节可参考我司首席架构师唐刘同学的这篇文章。
 是一个一致性协议，提供几个重要的功能：

 选举
成员变更
日志复制

 利用  来做数据复制，每个数据变更都会落地为一条  日志，通过  的日志复制功能，将数据安全可靠地同步到  的多数节点中。

到这里我们总结一下，通过单机的 ，我们可以将数据快速地存储在磁盘上；通过 ，我们可以将数据复制到多台机器上，以防单机失效。数据的写入是通过  这一层的接口写入，而不是直接写 。通过实现 ，我们拥有了一个分布式的 ，现在再也不用担心某台机器挂掉了。

讲到这里，我们可以提到一个非常重要的概念：。这个概念是理解后续一系列机制的基础，请仔细阅读这一节。
前面提到，我们将  看做一个巨大的有序的  ，那么为了实现存储的水平扩展，我们需要将数据分散在多台机器上。这里提到的数据分散在多台机器上和  的数据复制不是一个概念，在这一节我们先忘记 ，假设所有的数据都只有一个副本，这样更容易理解。
对于一个  系统，将数据分散在多台机器上有两种比较典型的方案：一种是按照  做 ，根据  值选择对应的存储节点；另一种是分 ，某一段连续的  都保存在一个存储节点上。 选择了第二种方式，将整个  空间分成很多段，每一段是一系列连续的 ，我们将每一段叫做一个 ，并且我们会尽量保持每个  中保存的数据不超过一定的大小这个大小可以配置，目前默认是 。每一个  都可以用  到  这样一个左闭右开区间来描述。

注意，这里的  还是和  中的表没什么关系！ 请各位继续忘记 ，只谈 。
将数据划分成  后，我们将会做两件重要的事情：

以  为单位，将数据分散在集群中所有的节点上，并且尽量保证每个节点上服务的  数量差不多
以  为单位做  的复制和成员管理

这两点非常重要，我们一点一点来说。
先看第一点，数据按照  切分成很多 ，每个  的数据只会保存在一个节点上面。我们的系统会有一个组件来负责将  尽可能均匀的散布在集群中所有的节点上，这样一方面实现了存储容量的水平扩展增加新的节点后，会自动将其他节点上的  调度过来，另一方面也实现了负载均衡不会出现某个节点有很多数据，其他节点上没什么数据的情况。同时为了保证上层客户端能够访问所需要的数据，我们的系统中也会有一个组件记录  在节点上面的分布情况，也就是通过任意一个  就能查询到这个  在哪个  中，以及这个  目前在哪个节点上。至于是哪个组件负责这两项工作，会在后续介绍。
对于第二点， 是以  为单位做数据的复制，也就是一个  的数据会保存多个副本，我们将每一个副本叫做一个 。 之间是通过  来保持数据的一致终于提到了 ，一个  的多个  会保存在不同的节点上，构成一个  。其中一个  会作为这个  的 ，其他的  作为 。所有的读和写都是通过  进行，再由  复制给 。
大家理解了  之后，应该可以理解下面这张图：

我们以  为单位做数据的分散和复制，就有了一个分布式的具备一定容灾能力的  系统，不用再担心数据存不下，或者是磁盘故障丢失数据的问题。这已经很 ，但是还不够完美，我们需要更多的功能。

很多数据库都会实现多版本控制， 也不例外。设想这样的场景，两个  同时去修改一个  的 ，如果没有 ，就需要对数据上锁，在分布式场景下，可能会带来性能以及死锁问题。
 的  实现是通过在  后面添加  来实现，简单来说，没有  之前，可以把  看做这样的：
  
  
……
  
有了  之后， 的  排列是这样的：
  
  
  
……
  
  
  
  
……
  
  
……
注意，对于同一个  的多个版本，我们把版本号较大的放在前面，版本号小的放在后面回忆一下  一节我们介绍过的  是有序的排列，这样当用户通过一个    来获取  的时候，可以将  和  构造出  的 ，也就是 。然后可以直接 ，定位到第一个大于等于这个  的位置。
这里有一篇更详细的文档，可以进一步阅读。
事务
 的事务采用的是  模型，并且做了大量的优化。事务的细节这里不详述，大家可以参考论文以及我们的其他文章。这里只提一点， 的事务采用乐观锁，事务的执行过程中，不会检测写冲突，只有在提交过程中，才会做冲突检测，冲突的双方中比较早完成提交的会写入成功，另一方会尝试重新执行整个事务。当业务的写入冲突不严重的情况下，这种模型性能会很好，比如随机更新表中某一行的数据，并且表很大。但是如果业务的写入冲突严重，性能就会很差，举一个极端的例子，就是计数器，多个客户端同时修改少量行，导致冲突严重的，造成大量的无效重试。
其他
到这里，我们已经了解了  的基本概念和一些细节，理解了这个分布式带事务的  引擎的分层结构以及如何实现多副本容错。下一篇文章，将会介绍如何在  的存储模型之上，构建  层。

作者简介：申砾，  ，前网易有道词典服务器端核心开发，前奇虎  新闻推荐系统  地图基础数据与检索系统  。

 源码地址：导语
针对每一个微服务所拥有的数据库发生变更时所产生的事件要如何做出相对应的动作 以维护其所拥有的数据库或数据仓储中的数据的时效性 这确实不是件容易的事 本文提供了四种架构方案。
前言
架構师在设计从多个微服務取数据 而生成报表的架构设计方案时 往往面临著需在边界上下文   数据的时效性 性能 可靠性与开发的复杂度间作取舍。
本文
从多个微服务取数据 而生成报表的设计方案 主要是参考      。
            
直接至各微服务所拥有的数据库中获取数据 并写至负责生成报表的服务所拥有的数据库或数据仓储中。此设计方案主要的问题是 破坏了原微服务的边界上下文   使得原微服务无法独立自主的修改自身所拥有的数据表结构 原微服务若有任何数据表结构上的修改 将会影响到生成报表的服务所拥有的数据库或数据仓储。

图一     
           
负责生成报表的服务 经由各微服务所提供的   取得所需的数据 并写至自身所拥有的数据库或数据仓储。此设计方案 藉由   维持了各微服务的边界上下文   但 却存在著其他的问题

性能上的问题 当负责生成报表的服务需同时向许多个 上百个 微服务获取数据时 则就表示将会有上百个远程调用会发生。所以 有可能负责生成报表的服务的某一个数据请求 已经达到了   但有的微服务所提供的数据 还尚未送至负责生成报表的服务。

数据量的问题 当负责生成报表的服务向微服务获取大量的数据时 例如 整个月的股票买卖。则大量的数据将造成大量流量 所以 也有可能对负责生成报表的服务的某一个数据请求 造成  。



 图二   
            
在夜间执行批处理至各微服务所拥有的数据库中获取数据 并写至负责生成报表的服务所拥有的数据库或数据仓储中。
此设计方案因为同样是属于    所以 也存在著破坏了原微服务的边界上下文   的问题 使得原微服务无法独立自主的修改自身所拥有的数据表结构。原微服务若有任何数据表结构上的修改 将会影响到生成报表的服务所拥有的数据库或数据仓储。
当然 此设计方案的另一个问题便是 数据的时效性 生成报表的服务所拥有的数据库或数据仓储 将无法获得实时的各微服务所拥有的数据库中的数据。

 图三    
            
当各微服务所拥有的数据库发生变更时 便会产生一个事件。此事件便会使得生成报表的服务去处理此事件 至发生数据库变更的微服务获取所变更的数据 并写入其所拥有的数据库或数据仓储中。
此设计方案不仅维持了各微服务的边界上下文   更使得生成报表的服务所拥有的数据库或数据仓储 获得实时的各微服务所拥有的数据库中的数据 拥有数据的时效性。

图四     
结论
比较这四种设计方案在边界上下文   、数据的时效性上的优、劣



　　 　　　
边界上下文
数据的时效性




  
劣
优


  
优
劣


  
劣
劣


  
优
优



当然 天下没有白吃的午餐    虽然维持了边界上下文   并提供了数据的时效性。但 却增加了产品架构的复杂度。使得微服务与生成报表的服务间产生某种程度上的耦合。也就是说 生成报表的服务必需知道 针对每一个微服务所拥有的数据库发生变更时所产生的事件要如何做出相对应的动作 以维护其所拥有的数据库或数据仓储中的数据的时效性 这确实不是件容易的事。作者：傅俊彬
团队：移动品质中心

一、背景
传统测试启动速度的方法是录屏分帧，即手工录制启动过程，然后通过分帧软件将启动过程的每一帧抽取出来，选取启动帧与结束帧，从而计算出差值作为启动速度。显然，这个方法有如下缺点：
、效率低下。
这种简单暴力的操作显然需要耗费人力与大量时间进行测试、数据收集以及分析。
、数据不准确。
由于一轮测试需要耗费大量时间，所以测试的次数有限，样本量较少，一次异常的数据就有可能会影响最终的结论。既然是简单粗暴重复的劳动，我们是不是可以考虑使用自动化来实现呢？答案是肯定的，我们采用了另一个更为高效准确的方法——读取系统日志获取启动耗时。
下面就来分享一下“懒人的智慧”。
二、日志信息
通过这个，我们可以获取一个的启动耗时。
下面是冷启动清除数据后启动的信息：

下面是热启动点击返回键后启动的信息：

可以看到冷启动有两条耗时的日志，这是因为首次安装启动存在闪屏，所以冷启动过程划分成了【点击图标进入闪屏】以及【闪屏结束后点击按钮进入应用首页】两个阶段。
通过可知：
冷启动耗时为：   = ；
热启动耗时为：
这里需要说明一下，在某些情况下会出现以下类型的：

其中前者是 ，后者是 ，关于二者的区别可以参考代码：

这里有三个关键变量，它们各自的定义如下：
：该函数调用时的时间点。
：一连串启动中最后一个的启动时间点。
：一连串启动中第一个的启动时间点。
通常情况下，点击图标只会启动一个，此时与指向同一个时间点，即=；但有些应用在启动的时候会启动一个无界面的做逻辑处理，然后再启动一个有界面的，此时指向有界面的启动时间，指向无界面的启动时间，。
如图所示：

小结
通过这个可以获取启动耗时。对于单个的启动，我们可直接使用作为启动耗时；对于多个的启动，我们则使用作为启动耗时。
三、数据采集
为了实现自动化测试，编写了一个实现性能自动化测试的框架，通过和驱动用例执行、实现数据收集。关于框架的详细介绍可以参考系列文章《场景化性能测试方向与框架篇》。
框架大体可分为两个部分：用例执行与数据收集处理，依次执行：
_、_、、_ 、_。
关于启动速度的用例执行比较简单，在此不赘述，每轮测试包括了冷启动与热启动，主要在内执行以下步骤：
清除数据启动应用滑动闪屏进入首页返回桌面再次启动应用。

而数据的收集，会在_方法内开启一个线程收集数据，通过命令：
    
我们可以只收集这个的日志，但是这个日志除了我们需要获取的耗时信息，还有其他一些启动相关的日志，在这里我们还需对日志做进一步的筛选过滤，具体规则如下：
不含的日志行丢弃；
不含指定包名的日志行丢弃；
不含指定名的日志行丢弃。

获取了有用的日志行之后，我们还需要对日志行提取出启动耗时的数据，即从     提取出 ，这里我们可以通过正则表达式来获取，具体代码如下：

四、数据分析
有了自动化脚本，我们就可以对历史版本的启动速度做一个对比，并将测试数据以折线图的形式直观地展示出来，从而更直接地反映不同版本启动速度的差异。

得出测试数据后，若测试结论不理想，我们可以通过  的 来观察不同线程及不同方法的执行耗时。

对于上半部分的图表，我们主要关注不同线程占用的耗时，颜色横条越长越多，表示该线程占用耗时越大。
对于下半部分的表格，我们主要关注对应线程下不同方法的占用耗时，主要关注以下三个字段：
 ：该方法平均占用  的时间；
 ：该方法平均执行时间，包括切换、阻塞的时间；
：该方法调用、递归次数。
以上三个字段数值越大，表示方法占用耗时越大。
为了方便开发定位，我们还可以将生成的文件提供给开发，具体的目录可以将鼠标放到名称上，对应的目录就会显示出来。

至此，启动速度数据的收集以及分析已经介绍完毕，水平有限，无法一一详尽，阅读过程中有任何的疑问或修正都欢迎随时提出，一同讨论。
搜索微信公众号：腾讯移动品质中心，获取更多测试干货！接《漫谈  技术上》
 视觉系统关键问题
结合上述介绍的系统，我们从以下几个方面分析视觉系统需要考虑的关键问题。
图像信息使用视觉方法根据使用图像信息的不同可分为直接法，间接法。
直接法，常见于稠密或半稠密的中，指的是采用图像上每个像素的信息亮度值来估计相机位姿；间接法，常用于稀疏的中，只使用显著的图像部位即特征用于位姿估计的计算。
直接法最基本的原理是亮度一致性约束，由于摄像机可以直接测量光的亮度，那么它的优化目标函数是光度误差如下图，优化变量可以是两幅图像之间的位姿关系，也可以是特征的位置。


根据直接法使用的像素的不同，可以分为稠密直接法和半稠密直接法。在上述介绍的系统中，为稠密直接法，它使用了所有的像素；和为半稠密直接法，它使用了梯度明显的像素；也为半稠密直接法，它使用了特征点周围邻域的像素。直接方法较多的使用了图像上像素的信息，在纹理较差的部分比间接法更鲁棒。但当场景中的光照变化后，直接法容易失效，亮度一致性约束要求两幅图像之间的光度误差尽可能地小。
间接法使用图像中的特征点或者线进行匹配，然后根据匹配关系求解如下图，它的优化目标函数是特征的重投影误差，优化的变量一般为相对位姿。间接法选取的特征一般要求比较显著，对视角和光照变化具有不变性，对模糊和噪声有一定的弹性，这需要在计算速度和特征质量上取得平衡。计算机视觉领域研究了很多不同的特征提取和特征描述，它们对旋转、尺度不变，和计算速度的性能都不一样。选择合适的特征依赖于平台的计算能力，视觉算法运行的环境，还有图像的帧率。可选的角点提取器如角点   、角点   ，角点   等，特征描述包括但不限于，，，，，和像素级别局部区块特征等。


使用间接法的系统一般都是稀疏的，因为它们只使用了图像的很少一部分像素的信息。在上述介绍的系统中，、、都属于间接法的系统。
数据关联
数据关联就是在不同图像之间建立对应关系，也就是把在多个视角看到的同样的图像部分关联起来，这样才能为后续恢复三维结构做好基础。
特征对应主要有三类：，和。
的对应通常用于系统初始化的时机，这时没有地图，也没有两幅图像之间的相机变换，只能使用的数据关联。为了减少计算时间，避免错误数据关联的可能性，可以用第一幅图像的特征位置定义一个搜索窗口在第幅图像中进行搜索，并采用特征描述之间的相似度进行度量。对于像素描述子的局部区块，通常使用模板匹配中差值的平方和，或者为了增加对于光照变化的鲁棒性，使用零均值像素灰度差平方和 ，或者零均值归一化交叉相关；对于高层特征描述子，比如，和，可能会采用范数向量中各个元素绝对值之和，就是绝对值相加，又称曼哈顿距离，范数就是欧几里德距离或汉明距离，为了加速匹配的搜索过程，可以采用树或词袋。
的特征对应常用于系统的运行阶段，前一相机位姿估计和场景结构已知，需要估计特征和这些路标在图像中投影的对应关系，有了这个对应关系，就可以通过的方法来求解当前图像和上一帧之间的相对位姿，通常计算时为了排除外点的干扰会结合的方法进行。
的数据对应主要用来估计和校正回环的累积误差，计算能使回环对齐的相似变换。在或双目系统中，还可以利用两帧之间的结构信息进行三维配准来计算相对位姿，实现三维结构的对齐。
初始化
单目的系统需要进行初始化，因为单帧图像数据并不能获取深度信息，也不能生成初始的地图。而和双目的系统由于单帧图像数据即可获取深度信息，所以不需要进行初始化操作。单目的初始化，只知道两幅图像之间的关联数据，初始相机位姿和场景结构都是未知的。
早期的，系统初始化利用一个已知尺寸的平面矩形实现，将相机摆放在该矩形前已知距离的地方，利用平面矩形的四个角点计算初始位姿。
后来的系统，包括、、，都采用如下的流程进行初始化。

使用单应矩阵初始化，此时场景应该由平面组成。要求用户手工选择前两个关键帧，而且用户在第一个和第二个关键帧之间，需要与场景平行地执行一个缓慢平滑且相对明显的平移运动。从第个关键帧提取特征点，在后来的每一帧图像中，采用数据关联方法追踪，直到用户插入第个关键帧。 特征匹配采用，由于没有考虑图像形变，匹配过程对运动模糊和由于相机旋转比较敏感，因此在初始化过程中对用户的运动状态要求比较严格。为了使匹配错误最小化，特征需要在两帧之间对称搜索，如果两个方向的匹配不一致，特征就会被丢弃。第个关键帧成功加入之后，则采用的方法来计算两个关键帧之间的单应矩阵，随后利用文献的方法对进行分解来恢复相机相对位姿。初始化非常脆弱，需要技巧去运行，尤其是对于没有经验的用户。另外，当初始化场景不是二维平面，或用户运动状态不恰当的时候，系统退化，容易崩溃。
也使用单应矩阵进行初始化，但不需要用户输入，系统启动时获取第一个关键帧并提取特征，然后用图像间的算法跟踪特征，为了避免用户二次输入，实时检测第一个关键帧和当前图像间的特征点平移量的中值，当这个值达到一定的阈值，算法认为已经获得了足够的视差，开始估计单应矩阵，然后分解单应矩阵并校验相机位姿，得到正确的位姿估计，并三角化对应的内点形成地图点。在第二个图像作为关键帧加入地图管理线程之前，利用捆集调整优化这两个图像帧以及其关联的地图点。与一样，的初始化同样要求平面场景。
的初始化不需要使用两视图几何，它从第个视角随机初始化场景的深度，然后通过随后的图像不断对场景深度进行修正。图像中梯度明显的像素点的深度被初始化为随机的分布，并赋值为较大的方差后放入系统。第一个初始化的关键帧和后面的图像配准后，跟踪直接开始。图像不断输入，初始特征点的深度测量用滤波方法优化，直到收敛。这种方法不存在两视图几何的退化问题；但在深度收敛之前需要处理大量图像，需要一个中间跟踪过程，生成的地图也不可靠。
在中，为了解决上述问题，作者建议并行计算基本矩阵和单应矩阵用方法，并评估两种方法的对称传输误差来选择合适的模型。完成之后，就会进行适当的分解，恢复出相机的位姿，并三角化生成初始地图点，最后通过捆集调整优化地图。如果选择的模型导致跟踪质量差，或者图像上的特征匹配较少，初始化就会迅速被系统丢弃，重新进行初始化，这保证了初始化的可靠性。
位姿估计
因为数据关联计算量巨大，对于每个新图像的位姿，如果能够有个位姿先验，那么对于缩小数据关联的范围就会非常有益。所以，建立这么一个先验是大部分系统位姿估计的第一个任务。， ，都在平滑的相机运动状态下采用恒定速度运动模型作为当前图像位姿的先验。但是，在相机运动方向上突然改变时，这样的模型就容易失效。和都假设在随后的图像上这种情况下都是用高帧率相机相机位姿没有明显改变，因此它们给当前图像位姿和前一个跟踪到的图像分配相同的先验信息。
下图是位姿估计的流程，前一幅图像的位姿用于指导数据关联流程，它可以帮助从当前地图中提取可见的子图，从而减少盲目投影整个地图的计算开销；另外，它还可以为当前图像位姿提供先验，这样特征匹配只在很小的区域内进行搜索，而不是搜索整个图像；最后，它还可以作为优化相机位姿的迭代初值。
 
下图演示了间接法的相机位姿是如何估计的，是用运动模型估计的新图像位姿，是真实的相机位姿。利用，将上一帧可见的地图点重投影到新图像上，在投影点周围一个搜索窗口内进行数据关联，系统使用欧式变换参数变换最小化重投影误差。为了获得对外点错误匹配的特征的鲁棒性，目标函数最小化会利用核函数处理掉重投影误差比较大的特征。

地图构建
不同的系统采用的地图表示形式不同，对于直接法的系统，由于恢复所有像素或者像素块的三维信息，它们生成地图为稠密或者半稠密的地图；而对于间接法的系统，它们仅恢复特征点的三维信息，生成的地图为稀疏的地图。无论是稠密、半稠密还是稀疏的地图，都可以看做三维的点云，虽然点云可以存储地图点的位置、特征和法线等，但是它们却不能反映相机位姿之间的关联，所以在系统中引入了位姿图 ，如、。为了构建位姿图，系统会从图像帧中挑选一些帧作为关键帧，这些关键帧即为真实场景在不同位姿处的快照。关键帧包含了位姿信息和与地图点云的观测关系，这些关键帧构成了位姿图顶点，它们之间的连接构成了位姿图的边，两个关键帧之间共视的地图点的个数就是这条边的权值。
下图是地图构建的一般流程。可以看到地图构建需要处理两个方面的工作：新的地图元素的加入和已有地图数据的维护。

新地图元素的加入主要是三维地图点和关键帧。现代的系统一般都会选取适当的关键帧，以达到场景的精简表示如、、通过明显的位姿变化原则添加新关键帧，通过明显的场景视图变化原则添加新关键帧；在新地图点生成方面，和通过优化关键帧位姿，根据匹配点三角化生成新的地图点，而和通过图像帧与关键帧的匹配不断更新深度滤波器，最后利用收敛的特征点的深度来描述新地图点。
已有地图数据的维护主要采用优化的方法对关键帧和地图点位姿进行优化，减少累积误差，并对冗余或错误的关键帧和地图点进行筛除，维护地图数据的有效性和正确性。由于地图数据维护多采用局部和全局的方法，计算较为耗时，、和均单独开辟线程进行处理。
重定位
重定位解决系统在遭遇突然的剧烈运动或者无特征区域等情况时，跟踪丢失后重新找回的问题。如果不能有效的重定位，系统前面建立的地图就不能再利用，系统就会失败。
在检测到跟踪失败后，会将后续每一帧的缩略图  与所有关键帧的进行比较，如果与其灰度的差异小于一定的阈值，那么通过方法估计其相对旋转，然后将地图点投影到当前帧寻找匹配，如果匹配足够，则计算精确位姿，重定位成功。这种方法需要丢失时的位姿与已有关键帧的位姿比较相近才可以成功，在有大的平移时会失败。
简单将图像帧与丢失前最后一次有效位姿附近最近的关键帧进行匹配，如果匹配成功则重定位成功。这种重定位策略对于光照变化和大的平移都很敏感，很容易失败。
随机从位姿图中选择一个具有两个以上相邻关键帧的关键帧，并试图将当前帧与它进行匹配，如果外点内点比率较大，那么丢弃该关键帧，重新随机选择；否则接着测试所有与它相邻的关键帧，如果相邻的关键帧中内点外点比率较大的关键帧数多于外点内点比率较大的关键帧数，或者存在多于五个的内点外点比率较大的关键帧，那么选择内点外点比率最大的关键帧进行跟踪，重定位成功。
的重定位会调用它的位置识别模块，该模块基于进行，它计算当前图像的向量，与地图中所有关键帧的向量比较，找出所有匹配得分高于最好低分的关键帧作为候选。对这些候选进行匹配和 计算，如果内点满足阈值条件，就认为重定位成功。
回环检测
回环检测对于消除系统长时间运行的漂移有非常重要的作用，如果能够识别到过的地方，那么回环的两端就可以对齐，全局的尺度一致性就能够保证。
的做法是每当加入一个新关键帧时，通过    中的  搜索与空间最近的个关键帧的匹配，一旦检测到闭环，则对位姿图进行优化，计算相似变换对齐回环两端，并将回环误差分散到到各个关键帧中。
回环检测使用重定位时同样的基于的地点识别模块，它可以为新加入的关键帧从已有关键帧数据库中高效快速的提取回环候选。为了确信回环和排除干扰，它引入连续一致性约束。确信回环之后，同样计算一个相似变换对齐回环两端。然后对关键帧和地图点进行调整，融合重复的地图点，并且执行一个基于位姿图的全局优化。
 的实现难点
在《  》中，有一句话说的好：“并不是一种算法，而是一个概念”。         
是多个学科多个算法的不同策略组合，它融合了图像处理，几何学，图理论，优化和概率估计等学科的知识，需要扎实的矩阵、微积分、数值计算知识，跟使用的传感器和硬件平台也有关系，研究者需要具备一定的硬件知识，了解所使用的传感器的硬件特性。所以，根据不同的应用场景，研究者和工程师必须处理从传感器模型构建到系统集成的各种实践问题。
从上面章节的分析可以看出，的各个环节用到的技术是偏传统的。与当前大热的深度学习“黑箱模型”不同，的各个环节基本都是白箱，能够解释得非常清楚。但却并不是上述各种算法的简单叠加，而是一个系统工程，里面有很多。
比如需要平衡实时性和准确性，一般是多线程并发执行，资源的分配、读写的协调、地图数据的管理、优化和准确性、关键参数和变量的不确定性以及高速高精度度的姿态跟踪等，都是需要解决的问题。
还需要考虑硬件的适配，的数据来源于传感器，有时是多个传感器融合，传感器的质量对的效果影响很大。例如，如果使用的相机图像噪点非常多，那么就会对姿态跟踪产生不好的影响，因为特征点提取会很不一致；再比如在系统中，如果相机和的时间戳不一致至少毫秒级，也会影响算法精度甚至算法失败。多个传感器的分别校准和互相校准，乃至整个系统众多参数的调整，都是非常耗费时间的工程问题。
由于产品和硬件高度差异化，而相关技术的整合和优化又很复杂，导致算法和软件高度碎片化，所以市场上目前还没有一套通用普适的解决方案，在短时间内也不会有。
 的未来
未来的发展趋势有两大类：一是朝轻量级、小型化方向发展，让能够在嵌入式或手机等小型设备上良好运行，然后考虑以它为底层功能的应用，比如手机端的和无人机等。在这些应用中，我们不希望占用所有计算资源，所以对的小型化和轻量化有非常强烈的需求。另一方面则是利用高性能计算设备，实现精密的三维重建、场景理解等功能。在这些应用中，我们的目的是完美地重建场景，而对于计算资源和设备的便携性则没有多大限制，由于可以利用，这个方向和深度学习也有结合点。
多传感器融合
实际的机器人和硬件设备，通常都不会只携带一种传感器，往往是多种传感器的融合。比如机器人除了视觉传感器，还通常具有激光雷达、里程计、等，手机除了摄像头，也带有、磁力计等传感器。融合多种传感器的信息对于提高系统的精度和鲁棒性有着重要的意义。比如目前手机上的的研究，它将视觉信息和信息融合，实现了两种传感器的优势互补，为的小型化与低成本化提供了非常有效解决方案，取得了良好的效果如苹果。
语义
的另一个方向就是和深度学习技术结合。到目前为止，的方案都处于特征点或者像素的层级。关于这些特征点或像素到底来自于什么东西，我们一无所知。这使得计算机视觉中的与我们人类的做法不怎么相似，至少我们自己从来看不到特征点，也不会去根据特征点判断自身的运动方向。我们看到的是一个个物体，通过左右眼判断它们的远近，然后基于它们在图像当中的运动推测相机的移动。和语义的结合点主要有两个方面：
语义帮助。如果有了物体识别的语义信息，就能得到一个带有标签的地图，物体信息可为回环检测、优化带来更多的条件。
帮助语义。物体识别和分割都需要大量的训练数据。要让分类器识别各个角度的物体，需要从不同视角采集该物体的数据，然后进行人工标定，非常辛苦。而中，由于我们可以估计相机的运动，可以自动地计算物体在图像中的位置，节省人工标定的成本。如果有自动生成的带高质量标注的样本数据，能够很大程度上加速分类器的训练过程。
此外，未来的技术将会越来越注重算法和硬件的深度结合，专用处理器如 和一体化功能模组如模组也是未来的发展方向，这将会大大降低现有硬件平台的计算能力瓶颈和算法调试门槛，带给用户更流畅的体验。
技术发展永无止境，的未来也才刚刚开始，让我们拭目以待！
参考文献：
                               
                        
                   
                 
                   
                  
                 
                         
                         
                     
                     
                        
   ö         
                     
                    
            
                   
   á         
                         

                     
                        
ú     ó                
_
             
                
                  
                    
                  
                   
高翔《视觉十四讲》从理论到实践工作模式简介
工作会启动两个通道：控制通道和数据通道。
控制通道一般由客户端发起，数据连接分两种：主动和被动。
模式：在客户端需要接收数据时，_大于的随机端口命令_  发送命令，这个命令包含了客户端是用什么端口来接收数据大于的随机端口，在传送数据时，_将通过自己的  端口和中包含的端口建立新的连接来传送数据。
模式：传送数据时，_命令_ 发送命令时，_自动打开一个之间的随机端口并且通知_在这个端口上传送数据，然后客户端向指定的端口发出请求连接，建立一条数据链路进行数据传输。
安装软件包
            查看是否已经安装
    安装
            列出安装文件如下
            的日志文件 
                    认证文件 
              启动脚本 
                          的配置文件存放的目录 
                禁止使用的用户列表文件 
_                禁止或允许使用的用户列表文件 
              主配置文件 
__  操作的一些变量和设置 
                    的主程序
安全设置
为了安全应该禁止匿名用户的登录：将配置文件的_参数设为屏蔽匿名用户上传，创建，删除的功能
   
_= 
__=      上传 
___=    创建 
___=    删除 
      重启服务器
为加强安全设置：限制系统用户锁定在家目录：
   
__= 
__=_  把需要限制的用户加入_即可
限制其他系统用户不能登录：
    是禁止使用用户列表。
    此时不能登录  这样用户将不能使用
使用的配置文件_来控制只有那些用户可以登录：
_ 用于存放哪些用户才能登录系统： 
  
在_= 的后面添加 
_= 
_=_
搭建支持加密传输的
首先检查软件是否支持
  | 
 =     ==说明此版本支持
              生成证书

    设置主配置文件参数
_=                                      是否启用 默认为
__=                                 是否允许匿名用户使用默认为
___=                       非匿名用户传输数据时是否加密默认为
___=                     非匿名用户登陆时是否加密默认为
_=                                          是否激活 加密默认
_=                                         是否激活加密默认
_=                                         是否激活加密默认
__=          证书的位置

相关推荐
【腾讯云的种玩法】一分钟加固你的腾讯云主机
如何在  下连接  服务？
免费云服务器立即领用作者简介：陈志兴，腾讯增值产品部高级工程师，主要负责手个性化业务、手 等项目。喜欢阅读优秀的开源项目，听听音乐，偶尔也会打打竞技类游戏。
本文根据作者在全球移动技术大会的上分享的整理，特别感谢卢景伦腾讯增值产品部高级工程师将精华汇总成文，方便大家阅读学习。


说在前面
年月日，增值产品部团队研发的轻量级高性能框架通过了公司最终审核，作为腾讯开源组件的一份子分享给大家。从当初立项优化页面加载速度，到不断摸索、优化，再到整理代码、文档，最终在上开源，并且在小时内获取数超过。我们非常高兴看到我们的成果收到这么多的关注，趁此机会，正好回顾一下的成长历程，也希望能够让大家更了解。
项目背景
相信大家再熟悉不过了，它具有快速迭代发布的天然优势，但也存在中一些让人诟病的问题，比如加载速度慢，体验差等。在此之前，手上很多页面首屏打开速度居高不下，甚至有些耗时达到以上，这意味着用户打开页面必须经过秒之后才能进行交互操作，体验相当差，很多用户忍受不了这个漫长的时间直接流失掉了。
为了提升用户体验和业务用户留存率，我们很多业务一开始通过开发，等页面模型验证符合预期后，再将页面转化成原生界面。我们很快意识到这不是一种健康的可持续的开发模式，一方面存在重复人力浪费，另外一方面原生商城除了速度快一点，要运营活动改版都很难。
所以后来团队改了切入方向，安排人力专心研究如何加快页面打开速度，经过了一系列的摸爬滚打和优化探索，最终我们研发出了框架，让页面首屏达到秒开，给用户一个更好的体验。下面就和大家分享框架的发展历程。
业务形态
任何一个技术框架都是结合具体的业务形态来进行发展优化的，技术是为了更好地服务业务，业务也会驱动技术的发展。因此在此首先介绍一下业务形态，我们是来自手增值产品部门的团队，负责手机上很多深受年轻人喜欢的个性化增值服务，比如气泡、挂件、主题等等。手上大部分的业务还是基于开发的，大家对手的业务形态可能有简单的了解。比如游戏分发中心、会员特权中心、个性化装扮商城等。这部分商城的特点比较明显，页面的很多数据都是动态的，是由我们的产品经理在后台配置的。

这些都是很常见页面，我们通常将等静态资源放到上，然后页面加载后，再通过去拉取最新的数据，进行拼接展示， 这样子可以利用到的多地部署和就近接入等优势，同时提高了服务器的并发能力。这种传统模式的加载流程如下所示：


用户点击后，经过终端一系列初始化流程，比如进程启动、初始化、创建等等；

完成初始化后，开始去上面请求加载页面；

页面发起请求对应的数据或者通过获取数据，数据回来后再对进行操作更新。


可以看出上述流程存在着几个问题： 


从外网统计数据来看，用户的终端耗时在以上，这意味着在这多的时间里，网络完全是空闲在等待的，非常浪费； 
页面的资源和数据完全依赖于网络，特别是用户在弱网络场景下，页面会出现很长时间的白屏，体验非常差； 
因为页面的数据依赖于动态拉取，加载完页面后，往往是看到一些模块先转菊花，再展示，体验也是不好的。同时这里涉及到较多数据更新，经常要更新，性能上也有不少开销。所以针对以上几个问题，我们对应做了很多优化和探索，这些优化帮助我们形成的最初构想。

的前世
基于传统模式的加载流程存在的种种问题，我们做了以下优化：
终端优化
针对终端耗时以上的情况，我们对手 框架进行了重构： 

启动流程彻底拆分，设计为一个状态机按序按需执行 

相关拆分模块化设计，尽可能懒加载，异步化 

内核在手中的独立进程中提前预加载 

创建对象复用池


关于第点，我们想分享一些平台上的细节，由于系统的生态原因，导致用户的系统版本和系统内核处于极其分裂状态，所以我们公司在手和微信统一使用内核。相对系统来说，首次启动内核时，创建比较耗时，因此我们尽量想复用，但是却是与 绑定。销毁复用的时候，需要释放的，否则会内存泄露。针对这种情况，有没有一种两全其美的办法呢？
计算机有一句经典的名言：“计算机领域任何一个问题都可以通过引入中间层来解决”。于是我们通过包装的方式，实现了一个的壳，真正的实现体包装在里面，逻辑调用真正调用到对应的实现体的函数。 经过实验发现，系统本身提供了这么一个，作为的一个中间层。
我们会将 包在里面，的时候，会将的设置为的，从而释放 。 类似如下：

静态直出

“直出”这个概念对前端同学来说，并不陌生。为了优化首屏体验，大部分主流的页面都会在服务器端拉取首屏数据后通过进行渲染，然后生成一个包含了首屏数据的文件，这样子展示首屏的时候，就可以解决内容转菊花的问题了。 当然这种页面“直出”的方式也会带来一个问题，服务器需要拉取首屏数据，意味着服务端处理耗时增加。 不过因为现在都会发布到上，直接从上面获取，这块耗时没有对用户造成影响。 手里面有一套自动化的构建系统，当产品经理修改数据发布后，可以一键启动构建任务，系统就会自动同步最新的代码和数据，然后生成新的含首屏，并发布到上面去。
离线预推

页面发布到上面去后，那么需要发起网络请求去拉取。当用户在弱网络或者网速比较差的环境下，这个加载时间会很长。于是我们通过离线预推的方式，把页面的资源提前拉取到本地，当用户加载资源的时候，相当于从本地加载，即使没有网络，也能展示首屏页面。这个也就是大家熟悉的离线包。 手使用生成离线包 同时离线包服务器将新的离线包跟业务对应的历史离线包进行做二进制差分，生成增量包，进一步降低下载离线包时的带宽成本，下载所消耗的流量从一个完整的离线包降低为一个增量包。
经过一系列优化后，在平台上，点击到页面首屏展示的耗时从平均多降低为，优化 以上。

所以针对以上几个问题，我们对应做了很多优化和探索，这些优化帮助我们形成的最初构想。
的诞生
虽然通过静态直出和离线预推等方式优化后，速度已经达到，但还存在很大的优化空间，当我们准备持续深入优化时，我们的业务形态发生了新的变化。
之前我们页面内容的数据主要是由产品经理要配置的，用户看到的内容基本都是一样的。而现在页面为了更好地为用户推荐喜欢的内容，我们后台引入机器学习和随机算法来做智能个性化推荐。比如左边新用户推荐的是新货精选，而右边活跃用户展示的是潮品推荐。另外还有部分的内容是随机算法推荐的。这意味着不同用户看到的内容是不同的，同一个用户不同时间看到的内容也有可能不同。

所以为了满足业务的需求，我们只能实时拉取用户数据并在服务端渲染后返回给客户端，也就是动态直出的方案。
但是动态直出方案存在几个比较明显的问题： 

服务端实时拉取数据渲染导致白屏时间长，因为服务器要先实时拉取个人数据，然后进行渲染直出，这个耗时不可控； 
首屏无法使用离线预推等缓存策略，因为每个用户看到的内容不一样，我们无法通过静态直出的方式那样把全部发布到；

虽然动态直出方案下，页面首屏无法通过离线预推等方式进行加载优化，但前面优化积累的经验给我们提供了思路：要优化白屏问题，核心还是得从提升资源加载速度方向入手。所以我们重点在资源加载方面进行了深度优化。
并行加载
首先在加载流程方面，我们发现这里访问依然是串行的， 要等终端初始化完成之后，才发起请求。虽然终端耗时优化了不少，但是从外网的统计数据来看，终端初始化还是存在几百毫秒的耗时，而这段时间内网络是在空等的。

因此性能上不够极致，我们优化代码，这两个操作并行处理，流程改为：

并行处理后速度有所改善，但我们发现在某些场景下，终端初始化比较快，但数据没有完成返回，这意味着内核在空等，而内核是支持边加载边渲染的，我们在并行的同时，能否也利用内核的这个特性呢？
于是我们加入了一个中间层来桥接内核和数据，内部称为流式拦截：


启动子线程请求页面主资源，子线程中不断讲网络数据读取到内存中，也就是网络流和内存流之间的转换；
当初始化完成的时候，提供一个中间层来连接和数据流；
当读取数据的时候，中间层会先把内存的数据读取返回后，再继续读取网络的数据。

通过这种桥接流的方式，整个内核无需等待，继续做到边加载边解析。这种并行的方式让首屏的速度优化以上，进一步提升了页面加载速度。
动态缓存
通过并行加载，我们极大地提升了请求的速度，但是在弱网络场景下白屏时间还是非常长，用户体验非常糟糕。于是我们在思考，是否能够将用户的已经加载的页面内容缓存下来，等用户下此点击页面的时候，我们先加载展示页面缓存，第一时间让用户看到内容，然后同时去请求新的页面数据，等新的页面数据拉取下来之后，我们再重新加载一遍即可。

保存页面内容这个工作很简单，因为现在我们资源读取都是通过中间层来管理的，只需要将整个读取的内容缓存下来即可。 于是我们就按动态缓存这种方案去实现了，但很快就发现了问题。用户打开页面之后，先是看到历史页面，等用户准备去操作的时候，突然页面白闪一下，重新加载了一遍，这种体验非常差，特别在一些低端机器上，这个白闪的过程太明显，非常影响体验，这是用户和产品经理都不能接受的。于是我们在思考，能否只做局部的刷新，仅刷新变化的元素呢？
通过分析，我们发现同一个用户的页面，大部分数据都是不变的，经常变化的只有少量数据，于是我们提出了模板和数据块的概念：页面中经常变化的数据我们称为数据块，除了数据块之外的数据称为模板。
页面分离
我们将整个页面通过标签进行划分，包裹在标签中的内容为，标签外的内容为模版。

首先我们对内容进行了扩展，通过代码注释的方式，增加了“”来标注一个数据块的开始与结束。 而模板就是将数据块抠掉之后的，然后通过{}来表示这个是一个数据块占位。 数据就是格式，直接。 当然，为了完美地兼容，我们对协议头部进行了扩展，比如增加来标注是否支持增量更新、来标注模板的是多少等。，有了上面这个规则或者公式后，我们就可以实现增量更新了。
请求规范约定
为了支持区分客户端是否支持增量更新等能力，对头部字段进行了扩展：

字段说明：

模式介绍
根据本地是否有缓存以及本地缓存数据跟服务器数据的差异情况分为以下四种模式。

模式介绍·首次加载
我们会在请求头部带上支持为和版本号等标识着首次加载的信息。当请求返回后，会在延迟几秒后避免激烈竞争将页面抽离成模板和数据并保存到本地。此时终端缓存目录下，该页面将对应三个缓存文件、、，其中是该页面的唯一标识即。
对于页面非首次加载场景，优先加载本地缓存， 同时我们会在请求头部带上当前缓存和模板的，后台进行模板对比之后，分为完全缓存、数据更新和模板更新几种情况。
模式介绍·非首次加载之完全缓存
本地有缓存，且缓存内容跟服务器内容完全一样。
模式介绍·非首次加载之增量数据

如果模板发现没有变化，那么会在响应头部返回=，同时响应包体返回的数据不再是完整的，而是一段数据，及全部的数据块。我们现在需要跟本地数据进行差分，找出真正的增量数据，如上图中，后台返回了个数据，实际上仅有一个数据是有变化的，那么我们仅需要将这个变化的数据提交到页面即可。一般场景下，这个差异的数据比全部数据要小很多。如果页面拆分数据得更细，那么页面的变动就更小，这个取决于前端同学对数据块的细化程度。
获得变化数据块_后，客户端只需要通知页面页面设置的回调接口进行界面元素更新即可。这里的通信方式也可以自由定义可以使用标准的通信方式，也可以使用伪协议的方式，只要页面跟终端协商一致就可以。

对于数据更新这种场景，终端还会将新的数据和模板拼接成为新的页面，保持缓存最新。当终端初始化比较慢的时候，去加载缓存的时候，这个页面可能已经是最新的了，连数据刷新都不需要。
模式介绍·非首次加载之模板更新
与数据更新模式不一样，由于业务需求，页面的模板会发生更改。当终端在获取到新的模板和数据后，本地在子线程中进行合并，生成一个新的缓存，然后回调通知终端，刷新来加载新的缓存。
我们来看一下最终的流程图，跟动态缓存对比，有不少细节优化：

我们从第步开始，首先会去读取缓存。会抛个消息通知读取缓存，如果已经准备好，则直接加载缓存，如果没有，则缓存先放在内存里面。同时也会带上模板等信息到后台拉取新的内容，后台经过之后，会返回新的数据。拿到新的数据后，首先会跟本地数据进行，如果发现已经加载缓存，则直接提交增量数据给页面。否则继续拼接最新的页面，替换掉内存里面的缓存，同时保存到本地。这个时候如果，则直接进行第步最新的内容即可。
数据统计

这个是我们外网的统计数据。在数据更新模式下，首屏的耗时在左右，相比普通的动态直出，优化了以上。模板更新这个会比首次高，是因为加载了两次页面，不过从模式占比上来看，我们大部分页面都是数据更新。针对模板更新这种耗时比较高的情况，前面优化积累的经验给我们提供了思路，核心还是从提前获取资源方向入手，因此我们优先考虑如何预加载模板更新。
预加载
实际上整个在没有的情况下，也是可以独立完成所有逻辑的，当用户点击页面的时候，我们在将和绑定起来即可。于是我们支持了两种预加载的模式，一种是通过后台的方式，来提前获取数据。还有一种就是，页面可以调用来预加载用户可能操作的下一个页面。通过这两种方式，我们可以把需要的增量更新数据提前拉取回来 。

效果对比

  没有使用

  使用
展望未来
开源只是故事的开始，我们仍会持续对  做改进，包括更易用的接口、更好的性能、更高的可靠性，同时快速响应解决开源后的和。这些改进最终也会原封不动地在手内使用，这一切都是为了更快的加载速度。 
  ，                  
点击链接直接访问源码：
如果觉得本文写得不错，想打赏作者，就在上给一个吧！自  年初， 和  语言就出现了明显的下颓趋势，与去年相比，这两种语言的市场占有率均下滑了 有余。根据  的数据显示，原本的  和  语言使用者纷纷转向了其它编程语言，而且大家并没有特定的偏好，改用哪种编程语言的都有。
目前，随着各行各业的软件使用率越来越高，很明显  语言和  语言已经无法满足使用者的需求了。什么编程语言都有一大堆簇拥者，这一点很容易证明。
 的时候，市场占有率仅有 的编程语言都能排入前  名，而如今这个数字只够让它排到第  名。
编程语言排行榜  榜单

下面是第  位的编程语言，排名如下：

【说明】
 编程语言社区排行榜是编程语言流行趋势的一个指标，每月更新。这份排行榜排名基于互联网上有经验的程序员、课程和第三方厂商的数量。排名使用著名的搜索引擎诸如 、、、、 以及  等进行计算。请注意这个排行榜只是反映某个编程语言的热门程度，并不能说明一门编程语言好不好，或者一门语言所编写的代码数量多少。
这个排行榜可以用来考查你的编程技能是否与时俱进，也可以在开发新系统时作为一个语言选择依据。客户案例
案例一：某大型综合金融机构

这是一个大型的综合金融机构，总部就在深圳，也是中国最大的。
他们之前需要逐台去登录服务器：没有办法集中查看日志没有办法对海量日志进行挖掘和用户行为分析    没有办法做多维度的查询，比如时间段、关键词、字段值而且没有办法进行日志的业务逻辑分析和告警。
使用日志易产品后：建起日志云，在内部建立了一个私有云来处理日志，已经接入了一百多个应用，每天新增的日志量是。做了日志云之后的好处是省去了登录服务器的操作，能够快速地查看，降低登录服务器的人为误操作的概率。对金融系统来说，这些生产线上的服务器是非常关键的。如果每个运维工程师都登录到生产线上的服务器去查看日志，一不小心，一个误操作，可能就影响了生产线上的应用，导致一次事故。上线日志易产品后，就禁止运维工程师登录服务器去看日志，所有看日志就在它内部的日志易云上来看，解决了需要日志统一管理的痛点。而且可以进行多维度的查询，提高定位异常原因的效率，可以对日志数据进行数据挖掘、用户行为分析，可以对系统的健康指数每天出报表。
现在很多用户用日志易，主要的一个功能是每天出报表给老板看，因为之前是用，是第二天出报表，用了日志易之后是当天点钟的时候就可以出报表，让老板下班前看到当天的情况。而且可以事先告警，只要一出错，就马上告警，而不是事后去追查这个问题。
案例二：中移动某省分公司
用来分析营业厅业务办理的的日志，这里就用了搜索处理语言，营业厅里面一笔交易是经过多个子系统的，每一个子系统都会产生日志。用了之后，就把一笔交易的每一笔子系统产生的日志给串起来，串起来之后还原成一笔交易，分析一笔交易的延时情况、响应情况。
图  示意图
图 中的就是在搜索框里写的，这还是比较短的，它搜索的字段就是“”，通过管道符把前面搜索的结果传给后面的事务命令。因为不同子系统的日志都传给命令了，这个命令执行的操作是找，因为每一笔操作都是有一个独立的，根据这个把这一笔交易在不同子系统上产生的日志都串起来。串起来之后排一个顺序，是以查询作为起点，传入参数，事务命令的参数有，还有，一笔事务是从查询开始的，以提交作为结束。但是如果一直不提交也会超时，超时的时间是分钟，如果分钟都不提交，就认为这笔事务超时了，这样就不会无限地等下去。通过这样一个事务的命令，把这个交易给串起来。
图  业务日志数据串联
图就是串起来之后的结果，这是我们的界面，这就是在搜索框里刚才写的搜索处理语言的程序，出来的结果就把这些交易全都串起来，一笔缴费业务，营业员所有操作都一目了然。它还得监控这些营业员，看这些营业员各自的效率怎么样。每个步骤所需要执行的时间都排好，包括网络处理时间、服务器处理时间，都排好序。这就是我们在中国移动山东省分公司做的一个案例。
案例三：国家电网

日志易产品主要用在安全信息事件管理，因为终端信息安全是日志的调查、分析、取证，它要到各省分公升去做审计，快速排查日志里的问题。月日，腾讯云在「云未来」峰会上推出了战略新品——智能云，宣布将腾讯积累近年的能力向政府、企业和开发者开放，其中首批开放计算机视觉、智能语音识别、自然语言处理的三大核心能力。腾讯云技术社区将陆续推出系列文章，介绍普通开发者如何快速接入并使用这三大  能力。
本文将为大家讲解如何上手智能云提供的智能语音识别服务。
功能简介
语音合成服务提供文本转语音服务，支持多种音色选择、语速选择。
目前提供 方式，用户可以通过上传需要合成的中文文本，系统会立即进行合成，云端合成成功后，返回合成结果语音。
语音合成实现了机器向人的语音交互，适用场景包括：广播播报，有声小说，智能车载等等，让应用开口说话，便捷人机交互。
 
语音合成的   请求结构如下：



参数名称
必选
类型
描述





是

 协议版本



是

 请求地址


 
是
数据集合
 请求头部


 
是

 请求方法，请求方法为 


 
是

 请求正文



其中， 的结构为 ：

=
__=
_=
=
=
=
=
=
=
=
 中各字段含义如下各字段的值需要进行  编码：



字段
必选
类型
描述





是

腾讯云应用  值



否

腾讯云项目 ，不填为默认项目，即，总长度不超过字节


__
是

子服务类型。：短文本实时合成。目前只支持短文本实时合成


_
是

合成语音格式，目前支持格式



是

音量，默认为，取值范围为



是

发音人，目前仅支持，女声



是

语速，默认值为，取值范围为到，表示加速到原来的倍，为相对于正常语速放慢倍



是

官网云密钥中获得的



是

当前时间戳，是一个符合   时间戳规范的数值，单位为秒



是

 且    小于天



是

随机正整数。用户需自行生成，最长位



  的结构如下：



参数名称
必选
类型
描述





是

语音识别服务域名，固定为 



是

用户的有效签名，用于鉴权。对应签名鉴权中得到的签名字符串



是





是

请求长度，此处为 总的字节数。文本数据，编码，长度限制为字节以内



请求示例
下列示例中，箭头括号表示必须替换为有效值的变量。请求  与路径：

请求参数：
{

__
_







}
这里以   =    = 为例拼接签名原文，则拼接的签名原文为：
=====_==__===
对原文进行加密处理：
签名原文 
最终得到签名串为：
=请求  为：
{

=
}
返回结构
  返回结果
语音全文转写识别的   请求返回结果如下表所示：



参数名称
类型
说明






服务器错误码，为成功




服务器返回的信息




经过编码的合成语音数据



返回示例
返回消息示例如下：
 {
  
 
  
 }
返回码  表示成功。
代码示例

  

 
 
 
   
 

 = 
_ = __
_ = __

 = {
         _
         
        __ 
        _ 
         
         
         
         
             
          
}

_ = =    
_ = _
 = _ _ 
 = { }

 = _
_ = 
 = { _ }
 = = = =
 = 
 = 

 =  


代码示例

__ 
__
 = 
 = 

 = _
 获取 和   
_ = __
_ = __

_ = 
     = _
     = 
    __ = 
    _ = 
     = 
     = 
     = 
     = 
     =     
     = 


_
_ = 
_   =  {
    _ = =
}
_ = _ 

 计算签名
_ = _
 = __ _ _ 

 请求消息体，格式
_ = 
_ = _\\
_ =   = =_\\
_ =  \\
_ = \\
_ = 你好啊吃饭了没\\
_ = _\\
_ =   = =\\
_ =  \\
_ = \\
_ = 最近雾霾很严重最好留在室内\\
_ = _\\
_ =   =\\
_ = \\
_ = \\
_ = _\\

 =  _  \\
 =  \\
 =  \\
 =   =_\\
 =  
 = _
 = \\\\
 = _
 ===================   ===================\
 \
 ===================   ===================\
 = __ _ _
  {
     _   _\
     
}
 = _ 
  {
     _   _\
     
}
 = _
{
     _   _\
     
}
 = 
 = _{
     = 
}
 ===================  ===================\
  \\
_作者：熊节

前文讲到，在云计算的时代大背景下，我们推荐采用研发技术栈管理平台来集中管理组织中的技术栈，允许基于一个技术栈创建开发测试  和生产  两个  服务，从而支撑开发、测试、生产三种运行时环境。通过三种运行时环境的区分，技术栈管理平台实质上设置了一条标准的精益软件生产流水线，为软件研发生命周期中的三个核心工种——开发、测试、运维，布置了标准的“工位”。在实施技术栈管理平台时，从这三个核心工种之中的任何一个切入，都可以优先建设该工种对应的工位，从而拉动整条云化生产流水线的实施。

从开发切入，打造规范的软件开发底座
在数字化的大背景下，众多组织都面临技术能力短缺的境况。尤其是传统企业的部门，需要用有限的研发专业技能交付越来越多、变化越来越频繁的系统，还需要管理外包合作方的团队，对于开发底座规范化的要求日益显著。这些开发团队常见的一些挑战包括：

技术实践能力有限，不能保证每个项目采用业界最佳的框架与工具组合。

开发流程不规范，代码质量关注不够，技术债累积严重。

外包团队管理乏力，对外包团队的开发实践缺乏约束。


实施技术栈管理平台以后，整个组织可以识别并聚焦几种具有普遍代表性的软件形态例如“  微服务”、“   应用”、“安卓移动应用”等，集中技术骨干力量，搭建项目基础架构，以技术栈的形式固化下来。开发团队要启动一个项目时，只需要从技术栈管理的  平台上选择自己需要的技术栈，就可以立即生成自己的构建运行时，其中包括代码仓库、应用基础框架、依赖软件、自动化构建工具等。基于这个构建运行时，开发团队可以基于已经搭好的脚手架立即开始编写代码，并在  云上进行基本的验证，然后提交到团队代码仓库。团队的技术领导者不需要考虑开发环境应该如何配置，开发人员也不需要在自己的电脑上做任何环境准备工作，从而极大地降低了项目启动的技术门槛。
作为对开发工位的规范要求，技术栈中会规定“提交门”的质量标准，达不到质量标准的代码将无法提交到团队代码库中。这个实践与持续集成一样，都是源自丰田生产方式的“安灯”实践：如果出现质量隐患，应该立即停线修复，而不是让带着质量隐患的生产线继续运转。在一般的开发团队中，提交门的质量标准至少包括代码能通过编译；代码能通过静态质量检查。通过引入代码复杂度、代码规范性检查等基本质量标准，能促使开发团队关注代码质量，避免基本的技术债不断累积。水平较高的团队会在提交门中包含单元测试，单元测试不通过、或单元测试覆盖率达不到标准的代码将无法提交。
如果需要引入外包团队来协助开发，外包团队可以直接从技术栈管理  服务商获得自己的构建运行时，绝大部分的开发规范可以用提交门验证的形式来承载，从而将组织的质量要求固化到开发环境中，降低规范化管理外包团队的难度和成本。

从测试切入，建立云测试平台
在数字化、互联网化的大背景下，软件系统上线的周期不断缩短，两周一迭代已经成为众多团队的标准配置，一些创新型业务已经要求将上线周期缩短到一周、几天、甚至一天几次。不断缩短的上线周期，使很多  组织在测试方面的问题暴露出来：

测试自动化程度低，手工回归测试跟不上频繁上线的节奏。

测试环境争用，环境管理工作量大。

性能、安全等非功能性需求的测试投入不足，到项目晚期才开始测试。


如果这些问题是一个组织当前最大的痛点，技术栈管理平台的实施也可以从测试工位开始入手，为整个组织打下坚实的质量保障基础。测试和开发的技术骨干可以一同选择适宜的自动化测试工具，将其连接配置好，准备好自动化测试的脚手架，打包到技术栈的验证运行时中。测试人员只需按照业务需求编写自动化测试例，并放在技术栈中规定的“验证门”环节自动执行。当系统最重要的功能都能被自动化测试覆盖，测试人员就能从繁重的手工回归测试中解脱。
自动化测试需要可靠且可复制的测试环境来执行，这正是云计算的优势所在。在技术栈管理  中定义了测试运行时环境后，每当测试人员或自动化的验证门要执行自动化测试例时，就会从云中取出一个测试运行时，其中除了被测系统的依赖软件外，还包含了配置好的各种测试工具。被测系统会被加载到测试运行时环境中，执行自动化测试例，收集测试报告，然后测试运行时环境就会被销毁回收。整个过程中不需要测试人员手工管理测试环境，也不需要与其他测试或开发人员共用一套环境。
一旦测试人员不用“人肉回归”大部分软件功能，他们就可以把更多的精力投入非功能性测试。性能测试、安全性测试等非功能性测试所需的工具集同样可以被内建在技术栈中，方便测试人员日常工作。同时，测试人员还可以把非功能性测试编写成自动化的测试例，将其加入验证门的测试集，从而使非功能性需求也持续得到保障，以免在项目晚期才发现重大性能或安全问题。

从运维切入，构建高响应运维能力
同样，数字化、互联网化的大背景也对运维团队提出了新的挑战。从业务客户的角度，他们不仅希望自己的需求能尽快上线被用户使用，而且还希望及时获得来自用户的反馈，帮助他们做出调整。在一些领先的企业，运维更是能支持业务客户针对真实用户进行快速的受控实验，从而验证自己的业务假设。在这些新的要求下，很多  组织的运维团队暴露出了能力上的不足：

运维自动化程度低，需要大量手工操作，工作量大，可靠性低，容易出错。

系统监控不完备，出现故障时不能及时发现和快速排错。

生产系统的信息不能快速转换成业务洞见，无法支持频繁的线上受控实验。


技术栈管理平台的实施同样可以从运维工位入手，以打造高效的  体系为优先目标。
你说的是哪种  ？
由于历史原因，如今大家在谈起 “  ” 这个词时，其中包含的可能是三重相关但不同的含义：

如何借助基础设施即服务、运维自动化等手段，加快代码部署到生产环境的速度。

如何借助日志和监控手段，及时把生产环境的情况反馈到开发团队。

如何借助端到端的埋点、数据采集、分析和可视化，把用户行为反馈到业务。


以运维视角优先切入时，技术栈的建设就自然地偏向运维工具。在支持计算资源弹性分配的  层例如基于  的私有云之上，将自动化配置管理工具例如  、  、  及其他常用的运维工具打包在应用运行时中，运维人员可以随时从技术栈管理的  服务中获得完整且配置好的应用运行时，再从通过了测试验证可能是手工验证的发布候选镜像中选择一个版本放入应用运行时，即可快速完成应用的部署上线。生产环境的配置以代码形式记录，可以由技术能力较强的  团队专门维护，从而省去了大多数运维人员手动管理运行时环境的工作量与风险。
在应用运行时环境中，可以根据软件系统的特征预先配置好日志工具例如  、  和服务指标监控工具例如  ，使开发团队无需额外工作就能获得丰富有用的生产环境信息。一些水平更高的团队会在应用运行时环境中设置更智能化的运维功能例如基于  的服务熔断机制，使运维更具响应力。
应用运行时环境中还可以植入端到端综合语义监控所需的工具设置，从而支持对业务场景埋点和分析，甚至是结合流量路由技术进行受控实验，用数据为业务决策提供支撑。业务有了缩短反馈周期的诉求，运维有了快速响应变化的能力，两端夹击可以倒逼研发环节提升响应力、缩短交付周期，这也是研发组织变革的一个套路。

小结
技术栈管理平台的目标是为现代  组织创造云环境下的精益软件生产流水线。但对于很多组织而言，这条流水线并非一步到位，而是一个分阶段建设的过程。在这条流水线上，开发测试运维三个核心工位都可以成为实施技术栈管理的切入点。从组织当前最显著的痛点出发，选择一个工位开始实施云化的技术栈管理平台，并依循瓶颈理论拉动其他工位的逐步改进，这对于众多不以能力见长的组织而言，是一条可行的云化、数字化道路。