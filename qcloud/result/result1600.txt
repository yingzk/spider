作者：王少飞

浏览器工作大致流程
废话少说，先来看个图：

从上面这个图中，我们可以看到那么几个事：
浏览器会解析三个东西：
一个是，事实上，有三个的类对应这三类文档。解析这三种文件会产生一个 。，解析会产生规则树。，脚本，主要是通过 和 来操作 和     
解析完成后，浏览器引擎会通过  和    来构造  。注意：
  渲染树并不等同于树，因为一些像或的东西就没必要放在渲染树中了。 的  主要是为了完成匹配并把 附加上 上的每个。也就是结点。也就是所谓的。然后，计算每个也就是每个的位置，这又叫和过程。
最后通过调用操作系统 的绘制。
解析的 解析如下：



      


    
          
             
    


上面这段会解析成这样：

解析
的解析大概是下面这个样子下面主要说的是也就是的玩法，假设我们有下面的文档：

  

           


           


于是 是这个样子：

然后我们的文档是这样的：
      {     }
     {     }
     {   }
    = {   }
于是我们的  会是这个样子：

注意，图中的第条规则出现了两次，一次是独立的，一次是在规则的子结点。所以，我们可以知道，建立  是需要比照着 来的。匹配 主要是从右到左解析的，好多人以为这个事会比较快，其实并不一定。关键还看我们的的怎么写了。
注意：匹配元素是一个相当复杂和有性能问题的事情。所以，你就会在多地方看到很多人都告诉你，树要小，尽量用和，千万不要过渡层叠下去，……
通过这两个树，我们可以得到一个叫  ，也就是下面这样把 结点到 上：

所以，基本上来说是通过 解析 生成   ，然后，通过比对生成  ，然后通过把  和其  关联上，就完成了。注意： 会把一些不可见的结点去除掉。而中所谓的就是一个结点，不要被其名字所迷惑了。

注：不像要用两个树来干这个，也有对象，它直接把这个对象存在了相应的结点上了。
渲染
渲染的流程基本上如下黄色的四个步骤：


计算样式
构建 
 – 定位坐标和大小，是否换行，各种  属性 ……
正式开画



注意：上图流程中有很多连接线，这表示了动态修改了属性或是属会导致重新，有些改变不会，就是那些指到天上的箭头，比如，修改后的 没有被匹配到，等。
这里重要要说两个概念，一个是，另一个是。这两个不是一回事。


 ——屏幕的一部分要重画，比如某个的背景色变了。但是元素的几何尺寸没有变。
 ——意味着元件的几何尺寸变了，我们需要重新验证并计算 。是 的一部分或全部发生了变化。这就是，或是。使用的是  ，也就是流式布局，所以，如果某元件的几何尺寸发生了变化，需要重新布局，也就叫 会从这个 开始递归往下，依次计算所有的结点几何尺寸和位置，在过程中，可能会增加一些，比如一个文本字符串必需被包装起来。


的成本比的成本高得多的多。 里的每个结点都会有方法，一个结点的很有可能导致子结点，甚至父点以及同级结点的。在一些高性能的电脑上也许还没什么，但是如果发生在手机上，那么这个过程是非常痛苦和耗电的。所以，下面这些动作有很大可能会是成本比较高的。


当你增加、删除、修改结点时，会导致或
当你移动的位置，或是搞个动画的时候。
当你修改样式的时候。
当你窗口的时候移动端没有这个问题，或是滚动的时候。
当你修改网页的默认字体时。
注：会触发，而只会触发，因为没有发现位置变化。


多说两句关于滚屏的事，通常来说，如果在滚屏的时候，我们的页面上的所有的像素都会跟着滚动，那么性能上没什么问题，因为我们的显卡对于这种把全屏像素往上往下移的算法是很快。但是如果你有一个的背景图，或是有些不跟着滚动，有些是动画，那么这个滚动的动作对于浏览器来说会是相当相当痛苦的一个过程。你可以看到很多这样的网页在滚动的时候性能有多差。因为滚屏也有可能会造成。
基本上来说，有如下的几个原因：


。网页初始化的时候。
。一些在操作 时。
。其些元件的尺寸变了。
。如果的属性发生变化了。
。几个的发生在同一个的子树上。


好了，我们来看一个示例吧：
  =   

 =    
 =      再一次的  和 

 =   
 =   

 =    

      

当然，我们的浏览器是聪明的，它不会像上面那样，你每改一次样式，它就或一次。一般来说，浏览器会把这样的操作积攒一批，然后做一次，这又叫异步或增量异步。但是有些情况浏览器是不会这么做的，比如：窗口，改变了页面默认的字体，等。对于这些操作，浏览器会马上进行。
但是有些时候，我们的脚本会阻止浏览器这么干，比如：如果我们请求下面的一些值：
   


中的  或 
因为，如果我们的程序需要这些值，那么浏览器需要返回最新的值，而这样一样会出去一些样式的改变，从而造成频繁的。
减少
下面是一些 ：
不要一条一条地修改的样式。与其这样，还不如预先定义好的，然后修改的。
 
  = 
 = 
 =   
  =    

 
 =  

 
 =             
把离线后修改。如：
使用 对象在内存里操作先把给有一次，然后你想怎么改就怎么改。比如修改次，然后再把他显示出来。一个结点到内存里，然后想怎么改就怎么改，改完后，和在线的那个的交换一下。
不要把结点的属性值放在一个循环里当成循环里的变量。不然这会导致大量地读写这个结点的属性。
尽可能的修改层级比较低的。当然，改变层级比较底的有可能会造成大面积的，但是也可能影响范围很小。
为动画的元件使用或的，那么修改他们的是不会的。
千万不要使用布局。因为可能很小的一个小改动会造成整个的重新布局。
几个工具和几篇文章
有时候，你会也许会发现在下，你不知道你修改了什么东西，结果一下子就上去了到，然后过了好几秒钟才完成，这种事情以的年代时经常发生。所以，我们需要一些工具帮我们看看我们的代码里有没有什么不合适的东西。
下，的是个非常强悍的工作让你看看你的浏览渲染的成本有多大。其实和都可以使用开发者工具里的一个的东东。下这个基于的叫  的插件也不错。下你可以用一个叫的扩展。最后，别忘了下面这几篇提高浏览器性能的文章：
 –     –          –        
相关阅读：
【腾讯云的种玩法】利用 节省成本 日新进用户，解密《龙之谷》手游背后的压测故事

原文链接：“智能云”一直是当下最火的话题，那么在当下“智能云”时代，中小企业开发者如何掌握正确的云端实践姿势？
 腾讯「云未来」峰会北京站开发者专场，致力于为企业以及开发者打造更加垂直的交流平台，将邀请腾讯云资深专家为你分享当下如何更快捷的云端实践技巧，都是绝不容错过的干货内容！
现场参与调研互动，还可以获得公仔和腾讯云产品优惠券！赶快报名吧！



演讲嘉宾
嘉宾简介




 秦俊  腾讯云产品总监
年加入公司，现任腾讯云  产品线负责人，技术专家；先后参与负责腾讯一系列产品的海外国际化工作，在互联网、云计算、域名建站行业拥有丰富的产品、技术经验。


 王磊  腾讯云人工智能产品总监
年加入腾讯，现任腾讯云人工智能产品总监，技术专家；先后负责 空间  、 空间移动端、 直播、人工智能产品的研发工作，在互联网行业拥有丰富经验。


张兴华 腾讯云架构师
曾协助多家大型互联网企业成功上云，在架构设计、性能优化、数据迁移等方面具有丰富经验和独到见解。曾供职于百度，负责业务架构优化和运维相关工作。


梁定安 腾讯织云负责人
目前就职于腾讯社交网络运营部，开放运维联盟委员，腾讯云布道师，复旦大学客座讲师。


陈杰腾讯架构平台部技术专家
年云计算经验，年加入腾讯，现负责弹性计算及云函数等平台研发，致力于应用容器，虚拟化等技术提升开发运营效率及服务器资源利用率。






时间　　
议题方向
演讲嘉宾




：： 　　
《高效云端开发工具发布》
秦俊  腾讯云  产品总监


：： 　　
《云端  开发快速入门——  数字识别》
王磊 腾讯云人工智能产品总监


：： 　　
《云端架构规划与案例快速成长企业篇》
张兴华 腾讯云架构师


：： 　　
《快速开发与部署——腾讯  流水线应用实践》
梁定安 腾讯织云负责人


：： 　　
《无服务器架构，让云端开发更纯粹》
陈杰　腾讯架构平台部技术专家



参会确认信息将以审核通过，短信通知为准。
报名链接： 
活动页面：引言
小程序公布新功能：、个人开放注册小程序、公众号可以与小程序绑定，从公众号菜单、模板消息、通知均可触发小程序、可以设置通过微信扫普通的二维码，直接打开指定的小程序类似摩拜单车、 分享到微信的链接，可以直接打开小程序

在小程序上线个月之后，小程序公布了几大主要新能力，再一次吸引着大家的目光，新功能意味着更低的使用门槛——个人注册、更多的流量通道——可借助线下已有二维码与链接、更多的触达手段——公众号绑定。
这些是不是让很多人心中蠢蠢欲动，感觉又可以挥洒一番？
现阶段来看，出行类小程序与线下场景结合较好，摩拜单车、滴滴、车来了等在小程序应用上用户数量都表现不错，是现在小程序应用上广受好评的应用场景；购物类小程序紧跟其后，在最近开放的新功能中，相信结合门店二维码，购物类小程序可能会有一定的增长；另外，还有一些小而美的工具类小应用，如群应用、查规范，表现出了不错的成绩。
那么，怎么做一个小程序呢？如何分析和运营一个小程序呢？
小程序简介
微信小程序是腾讯微信团队推出的基于微信生态的应用号，是一种跨平台，媲美原生操作体验的应用，它拥有，即用即走、离线存储、跨平台等特点。
小程序架构

 
应用在微信下实现如原生应用般顺滑的体验，主要靠 ，会预先加载一个，当打开小程序落地页面的时候，就直接通过下载上的资源以及数据渲染页面，请求数据则局部刷新，页面返回直接弹栈，退出小程序，状态并不会销毁。

微信小程序的前端架构设计，以及开发模式，充分参考了、这一类的前端开发框架，我们简单举几个例子：比如通过{{}}进行数据双像绑定，就像极了的设计风格；再比如一些标签语法糖，列表循环：


 ={{}} {{}} 
相信写过 和 的同学都不会陌生；再比如，事件绑定：
 = {{}} 
{
     {
       
    }
      {
        {
               
        }
    }
}
如果你开发过，那么其里面有一个的方法可以用来改变状态的值，这里的也是一样的，通过绑定的方法来改变视图中的值。模块化思想这些都是现在前端框架必备基础。
组件
微信小程序框架与其他开发框架不同，比如 都是只管安心做好框架，层面的套件库都由各路使用者来贡献，比如饿了么的，蚂蚁的，微信小程序直接提供了在小程序开发过程中常用的组件，小程序的组件遵循 标准，并使用框架实现 。视图容器、表单组件、导航、媒体组件、地图组件、画布这些基础的元素级组件分享、登录、支付这些功能性组件

在层，微信提供了多，其实就是，用于提供访问的能力和通道，像：
 访问存储相关接口
 文件操作相关
 获取机型
 获取联网状态
还有更多媒体、界面的操作不一一列举，可以直接参考文档开发部分
利用分析工具透视微信小程序
当简单了解了小程序是什么之后，我们摸索着做了一个小程序的，利用豆瓣图书的做完了才发现上已经有无数这样的，成功运行小程序之后，我们又有了对小程序做数据透视的想法，官方的数据分析模块有提供，但及其简单，只是基础的运营指标自定义事件自定义事件功能还是蛮屌的，实现了无埋点，业界搜索了一下，有微信小程序分析相关的平台产品并不多， ，，腾讯移动分析，这里，我们选择了，接下来就针对的代码和功能，来看看如何利用数据分析工具运营小程序。
数据分析源码解读
整个对外暴露了三个对象、、

{_}
做统计信息的初始化，在应用入口 方法中调用，很显然是做一些统计信息初始化的工作，其中除了常规的统计的初始化，我们发现有对使用分析统计功能的开关设计，通过反混淆源码发现：以统计分享为例：
  =   
___    
             {
                  = 
                 =  {
                    _   {
                         ____
                    }
                      
                }
            } 
获取当前页面的对象，重载页面对象的 对应的方法，在执行框架方法之前，做统计平台的统计上报，是个不错的好方法。


具体页面的统计接口，可以看到，页面的访问统计是挂在框架对外暴露的的方法，方法会在加载，返回，后台导前台等页面展示的任何时机都上报，所以统计口径可能与官方有差异

 {_}
自定义事件的上报接口，用户可以在管理台配置好自定义事件，拿到合法的统计和事件后，在任何需要统计的事件场景下进行统计其他内部实现，多是利用框架提供的等接口来上报环境、网络等信息
实时刷新的透视数据
提供了访问次数、访问人数、应用打开次数等基础指标在各个分析模型下的组合、计算和应用，并且做到了几乎全站分析模型的实时化：真正做到了所见即所得的运营数据
环境分析，让微信小程序开发者更了解运行环境
提供了地域、运营商那个、机型、网络、操作系统、平台等一系列用户客户端环境分析的报表，可以很好的帮助开发者、运营者了解自己的小程序都运行在什么的宿主环境中，其中地域分析提供了各省份及其附属市区的覆盖数据，这些应该都是拿的用户，然后匹配腾讯公共的库做的映射：
而微信版本、网络连接类型、机型、操作系统等这些都是利用微信的 等接口取值上报进行了汇总、统计：
使用分析，特定场景下的用户行为分析
以上两个功能都是不需要用户参与的，自动帮大家采集和计算的，而使用分析则不是，比如我们需要统计有多少用户分享了我的小程序、有多少用户触发了页面的下拉刷新等动作，如此精细化的用户行为分析，这边也提供了配置化的上报接口：
在{
         
      
          
}
前提是已经获得并配置了合法的_这样平台就会采集这样的用户行为数据，并进行计算
举例分享分析，还提供了具体的分享页面列表，让开发者了解自己的小程序哪些页面的内容质量更高。
自定义分析，给用户行为洞察更多的灵活性
有很多场景，比如我想统计小程序中，搜索图书这个按钮的点击量搜索图书这个事件的事件发生次数，并且我想知道每次用户都输入了什么值来搜索图书，我用的自定义事件，并配置了对应的事件和参数

_{用户输入的值}

实时访客轨迹，实时透视用户行为的鹰眼
这个功能是我觉着帮助透视小程序运营数据很有特色的一个功能，可以帮助开发者实时的查看当前应用的活跃用户的行为轨迹，并且提供了当前用户的一些基本属性：第一次访问小程序的时间，用户类型，地域，受访页面等，很清晰，有种坐在屏幕后面窥视用户的感觉：
目前利用诸如这样的小程序数据分析平台来做小程序的基础和精细化运营，摸索小程序发展的未来方向，也期待有更多用户洞察的功能以及对小程序开发者和运营者更有价值的功能推出。

文章来源：【腾讯大数据】微信号：作者简介：


李昶博腾讯 专项技术测试组长腾讯专项技术测试组长，专注年性能测试，人称“性能哥”，腾讯公司年度优秀讲师。经历 、手机、桌面、空间、音乐等客户端项目，多个项目获得了百倍的性能提升。在性能领域，共取得件国家专利。年，性能优化项目团队获腾讯公司级重大技术突破奖。

前言
作者做了年的性能测试，一直为腾讯  服务，经历了、、音乐等等项目。腾讯的职业发展通道，各位很熟悉了，这个岗位就是专项技术测试。今年会开拓一个新的领域，叫做音视频专项测试。

腾讯的价值观就是“以用户价值为依归”，所以用户满意，是测试员工做业绩举证的关键。你看下图这个曲线，横轴是日期，纵轴是投诉量投诉量是测试员工举证自己业绩的关键。

上面是我做项目以来给公司带来的价值，曲线是指数级的，横轴是时间轴，纵轴是投诉量，半年的时间，多倍的优化效率。下方这个图，一发布投诉量上升，现在贴着横轴，每天个投诉量。
、我们的专项测试方法论
 专项质量体系
下图最左边的是全流程介入，所有流程都在里面有自己的方法论。我们有各种各样的指标，这是性能测试的关键点，不是光测有多长，有多少秒，还得测很多的红色指标，给所有流程配齐工具。

我的部门老大 ，有一个分层测试理论，我们对全流程都有办法介入，大家看红框，各个环节都有。再然后，各种指标和流程。所以性能测试绝不是测一下有多少秒，这个只是时延，红色的指标是更加专业的东西。
最后，我们有各种工具和手段，如右下角这些，这些工具的名字可能你觉得奇怪，后面会展开介绍。
 腾讯专项技术测试员工能力模型
腾讯的员工能力模型从实习生到外包都覆盖了，我在的岗位是专项技术测试，红色部分值得大家看，可能与其它公司有所不同。资深的同事开始阅读操作性能原码，甚至实习的同事天然读过安卓原码 。

要搞定这么多指标和流程，对员工能力的要求是比较高的。我们从做手工测试，到自动化，再到使用性能分析工具，甚至看  的源码来帮开发解决问题，这些技能是逐级提升的，这些领域可以产生不少的专利。
我在招聘的时候看到一些特点，某些实习生在大学期间就开始深入研究操作系统原理。在职的外包同事也开始做专项自动化测试，这就是团队竞争力的提升。
 速度体验评测模型
方法论里面有重要的一环，就是需求阶段我们如何介入。自然的就是性能测试标准

去项目里给一些开发发现性能 ，首先得有提单的规则，到底多少秒算性能 ，这是发布标准。毫秒，秒，进度条在走如果连续四秒走不动用户觉得焦躁，内部有用户体验研究团队甚至有这样的研究结论，相同的时长把进度条拉长一点，用户会觉得走的快。最后这条始终要看到进度在走，流畅度不再使用 。
 技术评审模型
上面的方法论里面还有一条，我们在开发进入  之前会开展技术评审。

全景图里讲到有一些技术评审流程，初级设计阶段概要设计时就会告诉你代码应该怎么写，遇到这些东西全部逐条怎样与产品经理，该不该加进度条，需求是否应该这样设计，跟开发价格设计的方案怎样，能否做到极简，每条对应的有需要测试的点。
、我们的自研平台工具
前文的方法论里面，讲的是如何武装你的头脑。现在，我给你们几把枪，这就是我们自研的测试平台和工具。
 研发支撑平台
首先我们能看到每个版本的  解决情况，包括性能 。然后是每个 ，都能看到各个工具的运行情况。

每一个  的解决率，红色的是  不达标细化到每一个部门，每一个部门解决了没有，能否发布在平台里。底下有一些性能  直接列在上面，因为这是做性能测试必须推动的事，非常重要。
最后是合流控制，所有的工具必须通过了，才会给开发员工开启  的代码权限。

我们对所有的工具列在这，这些工具确定的时候才能合流，每一个分支每天都可以收到工具的测试报告，而且当工具只要说不到时候，开发没有权限做合流，权限是流程自动化分配的。
 安装包质量监控：体积、方法数
里面列举每一个需求测试是否通过，安装包直接细化到它应该有多大，我们拉一道红线过了红线是不合格的。安装包的体积给每一个部门有配额管理，直接告诉对应的部门经理，你们如果想植入新的特性到里面，必须得使得安装包在多少以下，包括方法数也是非常严格的要求。

现在为了让安装包不增大，方法数必须得零增长，你要上新功能把以前的水分挤干净了功能才能上。安装包检查非常细致地检查条件，不可以打包符号表进去，把符号表打包进去原码就泄露了，大家看里面的各种检查项。
 静态代码扫描

静态代码扫描，非常低成本地接入，提供了两个内容我们可以发现 。对应的测试报告就是图片中右上方这样，各种扫描器分别发现了 。

再比如在  扫描出很多 ，并且自研了多条扫描规则，基于下面大家自己看到的这些扫描器，各种各样的语言可以自研多条扫描规则每天都在运转，只要提交了基本当天都可以收到对应的  单。

  规则和性能测试有关系吗？ 有，自研十多条和性能有关的规则，头文件里如果实现了变量会导致经典的  在一夜之间从三兆增长到十三兆，十兆增长到开发把字符串的定义写在  里，用静态代码扫描的语义分析找到 ， 的趋势和所有  的类型各种分析列在这里。
 性能自动化测试工具：  

手机挂在自己做的墙上  ，每天自动运转，基于自动化测试底下采集所有性能相关的测试指标。内部把  叫自动化测试平台，界面上采集性能数据。
 稳定性测试工具： 

  稳定性测试，要求每一个界面  的测试留在界面，所以保证它不要跳出，一旦跳出要能够回来。所以我们有几个管理指标，界面的覆盖率以及界面内部的控件覆盖率，一定要通过若干个小时内把各种界面的各种控件测齐。
各种操作类型的概率，滑动、点击等概率，包括返回  键和菜单键都是可以控制概率，很低的接入成本提供每天的安装包过来就可以给你出测试报告。
所以要接很多产品，半年内刚上线发现个 ，到现在每半年接的项目越来越多，不仅有收敛的趋势，还可以找出多个 。
 卡顿监控：
 卡顿监控，这是看不见界面的监控工具就在后台里面给内网的实验室环境做测试。

当你的界面发生卡顿时，默默记下相关的分析数据，最后生成了一个对应的分析报告，直接可以把卡顿问题解决掉。任何一次随机发生的卡顿都可以把它优化解决掉，当某一个项目接入  以后，它的投诉量下降，这是一百多倍的优化成果。我们自己写了 ，填入要测的  就可以监控  的卡顿。
 专项质量体系

我们把能力分三层次，采集性能数据可以度量证明它是否有问题。分析工具和全网的数据上报，各种指标都有对应工具，有一些单元格里存在些信息叉，说明目前没有这个能力，是值得我们做并且改进的东西。
 自动分析工具破解框架效应
 框架效应：导致效率底下
测试和开发怎样吵架？把大家带入到环境测那么多指标是为什么

我们测试向开发提了一个 ，秒，我看到接  的开发把我的  拒绝了，理由是秒的体验可以接受。做开发的天天面对编译器肯定慢，所以他会接受。但用户不接受，基本的测试标准超过，你的进度条得出来，要不然接受不了。
之前我们提性能  跟开发吵架，开发认为不影响用户可以接受。然后我们去实验室里进行证明，证明你做的产品性能真的是不合格，接着就会决策上升交给领导解决，领导看了以后觉得这的确是慢应该还是要改。
接着开发会想你测出的结果十几秒这是你的测试机性能差，我的机器性能挺好的，认为测试数据不稳定。开发怼我们说“你如果不能在我这儿做我怎么改”，我们的测试会说“你来我的环境下”。
在我们的环境底下可以复现还会遇到这样的问题这个好办，复现不了怎么查，最后双方证明查了一堆问题以后发现这是系统  的 ，开发说我改不了，这不是我的问题。
最后我们还是松口了，通过了测试，付出的计算量和开销还是这么大，最后发布到外网的时候用户体验还是照样投诉。我们几个亿的用户，多写几兆字节的东西用户都可以感受到并投诉了。问题推到了测试这，测试不是实验室体验的很好的吗。
像这样的解决不了的问题困扰我很多年，我为此去研究了社会心理学这本书，大家找到了结论—框架效应。
这是人性啊，框架效应有很多的心理学测试很有意思，可以找到奇妙的心理学测试案例。
做个比较简单的测试例子，现在的大脑跟着我说的去想，不要去想母老虎，不要想华南虎，不要想东北虎，不要想老虎，这个时候你在想老虎，这就是框架效应。而框架效应真是拉低效率问题的根源。
 实现定位随机性能无需重现规律
干货来了，团队的共同努力，使得前面的那种低效状态发生了改变。现在，我们能做到不需要复现规律，也可以定位随机性能 。
因为我们提供了全面的分析工具，只要你的随机性能问题暴露在我的工具下面，就能把问题定位解决。

解决方案是这样，我们把所有的用户体验卡多久，时长多少切割成硬指标，、内存、流量等配上全部的分析工具。自研的，流量利用传统的  可以抓包。
闭环的环境下测试原本承担度量和验证，但在我的新体系下革新，将分析环节从测试这边拿过来，由性能测试团队提供了分析工具都是自研的，这时一切的一切都变化了。
所以呢，从产生问题到发现问题，再到解决、验证的闭环里面，测试团队提升了分析能力。十年前别人可能会说，你能力这么强，啥时候转开发啊；现在，开发会说，性能哥帮我们看下这个  的解决方案吧，甚至有开发同事主动转来我们团队。
 性能自动化分析能力破解框架效应
性能自动化分析实施之后触发了一个良性循环，我们提供了带分析能力的性能自动化测试，上一个版本对应的指标是多少，这个版本是多少，合格还是不合格，所有的指标我们列在这里，而且是带分析数据的。

这些指标如果不达标立即去分析工具里面找对应的日志，你可以分析出来，分析到代码。现在有了分析能力给你提单，某一个业务逻辑用了兆的，你会怎么想呢？
这个太多不合理。如果有一个开发者跳出来，告诉架构师你这样的设计肯定不行，这得改，我很欣慰，以前是开发跟我吵说这个  不需要改了，又不影响用户体验。

现在有其它的级的资深开发站在我身边，说这个代码写的不行得优化，一下子测试与开发之间的关系变的亲密，我们只需要做这点，你的代码写的好不好，通过框架效应在人性上解决这个问题。
比如，年前团队发现一个性能 ，提单的时候就说了，的红包导致启动性能下降。
开发的潜意识就是怎么优化红包，比如年后下架防止长期影响，而不会去想秒慢不慢，测试能不能复现等等。语境的变换，就打破了心理学框架效应。测试和开发越过吵架的环节，直奔解决问题。
 获取原子级硬指标—基准测试套件工具
跟你沟通时直接聊代码质量怎样，不聊用户体验，这是软改硬，软指标是用户体验，硬指标就是、内存，直接开始写对应的代码。优化之后进行测试验证，代码从原来的兆减少到兆，我们的性能提升倍，而且的用户都会用到，肯定全网的用户都会受益。
 测试
 测试，大家肯定想到  占用率，但你能想过  下  曲线率吗？

我们的创新点在于哪里呢？你看  占用率有什么问题，你忽高忽底有没有问题。给你一个曲线是否合格不好判断，除非是持续反对，持续怎么办，持续算不算问题。
其它的  为有传染，操作系统刚启动有很多的其它程序在加载，那你的性能怎样保障。安卓  系列有  的，你看黑色框里的最后一行，万，这个  怎么回事？
明明有开销但操作系统不可能让  占有率输出一个负值所以输出，那你能测出  吗。
为了解决这个问题使用最新的时间片测试，用掉了多少的时间片，可以直接表征你的代码计算量。换句话说运行某一段模块和代码之前，我取一下时间片，运行了以后取一个，两者做减法，这是这段代码用到的时间片，这个时间片我们拿去和以前的版本做对比超标不合格肯定有多的，没超标是通过的。
对应的  我们配上分析工具， 下的  就可以分析  超标的问题。
 测试

测试，提一个  启动秒，以前可是秒，慢了一倍，开发连续三周都没有找到原因。我们只好引入分析，突然发现启动增大三倍多。增长的部分是因为某一个组件导致的，把那个组件去掉性能就还原。
我们分析成本两个小时，所以我们是一个倍的效率提升。我们自研的分析工具是这样，这是它输出的日志，对应的函数站打出来，可以直接跟踪是哪一行代码。
有了它以后开始推广，所有的各种场景一股脑的清扫干净全部的性能问题，多倍的性能提升，主线程清扫到，这一下子在其中一个项目中就换得倍左右的投诉量下降。
 内存测试
内存测试，这是最简单的就是打开关闭，对应的指标就是从开始是基准，泄露就是这样算的。

首次打开之前在第一次关闭以后有的内存是复用的，缓存是否合理要监测出来。内存分析工具，，我们自研了分析工具 。
对应测试性能自动化脚本这样写，复循环，打开关闭，打开关闭，对应的采集性能测试数据，最后给你强大的性能测试报告，而且自带分析能。 可以找出内存为什么增长。
 测试

测试。因为它有一类问题是一定解决不了，用传统的方式打日志发现某一行代码有性能问题，但过一会儿测又不是这行代码又是别的行数为漂移？
我看过操作系统安卓的原码，可以把进程的所有线程都休眠，包括你的主线程。这意味着发生的瞬间壮大了函数，一个函数的耗时长。从传统的函数调用上解决问题，绝对解决不了导致的性能问题。

我们自研了一个工具 ，每一个对象分配了多少字节多少次，这个对象被谁哪一段代码分配的，可以直接的找到问题所在解决，把这个复用以后可以减少。
 掉帧率流畅度测试
流畅度测试， 不要用，我们这里是一秒  。如果每一帧时延稍微长一点，用户会觉得有问题，这时  还是。卡顿的总时长除以滑动的总时长，这样就是百分之零。

大家记得掉幀率相比  这是更加敏感的指标，这是腾讯内部的创新。平均化，性能测试要测很多次，测十次有其中一次是，那最后得出的结论是，你告诉项目组合格，就永远发现不了刚才的十帧卡顿的问题。
我们只测一次，第一次测合格了，第二次测有性能问题，你赶紧提 ，提了  的问题是什么，对应的都有分析工具。我们把卡顿那一瞬间的主线程报上去了，你直接查对应的问题是什么，直接把卡顿的问题解决掉。
在这套生态环境下，我们在某一个项目里优化它的性能，甚至超越了 。
 流量测试

流量测试。如果你使用操作系统安卓提供的  时，谷歌的官网说  ，这说明它是有问题的。
、发布后的全网监控
鸟枪换炮，还要打组合拳，就很专业了，能解决各种性能问题。现在我们团队在做原子弹，也就是全网的性能监控。为什么要做这个方向？
有经验的同学知道，很多的性能问题，在实验室环境下是复现不出来的，用户的环境非常复杂。
 用户投诉跟进

性能全网监控，最基本的指标离不开用户投诉量，这是其中的一个项目。性能投诉最原始排第一，很高，优化后排名成倍下降，数量也是成倍下降，这是基本的法则。你的项目里看用户的投诉。
 全网上报
再一个，也是最基础的， 率你要监控起来。

 做全网上报，我们内部有这样的平台，你们外部会知道这是腾讯的 ，我们内部用了更高级的版本，用户体验好一点。每天发一个日报，跟领导商量好了，这个指标的精品标准有多少，我们定的非常严格，一定要做成精品。
 卡顿全网上报
卡顿全网上报优化了倍，因为每次卡顿都上报了对应的函数对站，可以形成闭环解决。

我们可以在后台看到这样的图，每一个卡顿事件对应的函数站可以点进去仔细查阅是什么性能的原因。
当构建这样的闭环以后，对应的项目投诉量呈百倍的减少，对于你的用户体验全网耗时也报上来，这个图我相信大家第一眼喜欢看最底下的那个，逐个版本明显的增多。

经验不是看下面小于秒的用户体验，应该看长尾。如果一个用户以前启动时长要秒左右，现在优化到秒的区间，这是一个超过倍的性能提升。这是至关重要的。
如果你是从优化到，用户的感知不大，所以要看长尾。长尾下面真的是少了一半的用户，那对我们过亿的产品而言，长尾几百万用户少一半了不起，对应的投诉也是正相关的。
  ：掉帧率

掉帧率，若干个版本以后有质的提升，甚至排在其它场景的 。所有的函数站放在这里，直接看到哪一个函数耗时多少，直接定义在某一个函数导致卡顿的概率最大。
  ：、、内存

我们做 ，把、数据库和内存泄露和内存触顶率的创新指标记录下来，这些里面不详细展开。重复，你将一个文件打开再关闭，然后又重新打开读一遍再关闭，这很显然是性能问题。
我们经常会发现一个问题，某一个客户端本地的文被计算三次，启动时再校验一遍用之前再算一遍，这为了确定要不要更新，这种都是很显然的性能问题。
我们在数据库里复制进去，直接看对应的执行计划，这对含有全表扫描的我们认为这是性能问题，因为全表扫描这是忌讳的问题，我们有很多的手段可以解决，不要在用户的集成上做全表扫描。手机原本性能不一定很好，有贵的也有便宜的，所以这些是我的演讲内容。
、总结

我们第一条全流程，每一个流程给大家的方法论讲了性能和进度条，技术评审怎样跟开发，怎样与产品。我们测了这么多的指标，最后第二条各种专项指标，第三条就是各种专项分析工具，所以是全流程各种专项指标以及分析定位工具，这三者齐备就是一个成熟的专项测试团队。原文地址
在上篇《脚本错误量极致优化监控上报与   》 中，主要提到了脚本错误上报的方式，并讲解了如何使用  来解决   报错信息的方案，于是我们就可以查看到脚本报错信息了。而此时可能会遇到另一个问题：” 代码压缩后，定位具体出错代码困难！“。本篇《脚本错误量极致优化让脚本错误一目了然》  将结合示例，通过多种解决方案逐一分析，让脚本错误 一目了然。
示例 · 压缩代码定位错误困难
源代码存在错误
  {
       报错
}



经  打包压缩后产生如下代码
{ {  =={{}} =} ={}==={ }={||{}}={ =__{ }{ } }={ }==}{ {}}

代码如期报错，并上报相关信息
{       
   
   
    }
此时，错误信息中行列数为  和 。 结合压缩后的代码，肉眼观察很难定位出具体问题。
如何定位到具体错误
方案一：不压缩  代码
这种方式简单粗暴，但存在明显问题： 源代码泄漏， 文件的大小大大增加。
方案二：将压缩代码中分号变成换行
 有一个叫  配置参数，设置为  时，会将压缩代码中的分号替换为换行符，提高代码可读性， 如
{ { 
 =={{}}
 =} ={}
==={ }={||{}}={ =__{ }{ }
 }={ }==}{ {}}

此时，错误信息中行列数为  和 ，查找起来比普通压缩方便不少。但仍会出现一行中有很多代码，不容易定位的问题。
方案三： 代码半压缩 · 保留空格和换行
 的另一配置参数  设置为  时，最终代码将呈现压缩后进行格式化的效果保留空格和换行，如
 {
     
     
}   {
      {
        
    }
    
} 

此时，错误信息中行列数为  和 ，能够快速定位到具体位置，进而对应到源代码。但由于增加了换行和空格，所以文件大小有所增加。
方案四： 快速定位
 是一个信息文件，存储着源文件的信息及源文件与处理后文件的映射关系。
在定位压缩代码的报错时，可以通过错误信息的行列数与对应的  文件，处理后得到源文件的具体错误信息。

 文件中的  字段对应源代码内容，不希望将  文件发布到外网上，而是将其存储到脚本错误处理平台上，只用在处理脚本错误中。
通过  文件可以得到源文件的具体错误信息，结合  上源文件的内容进行可视化展示，让报错信息一目了然！
基于  快速定位脚本报错方案 

整套方案的代码实现可以在这  查看，效果如下

左边的为线上页面，上报脚本错误右边的为  脚本错误监控系统
此时，错误信息中行列数为  和 。 结合 ，经处理后，拿到对应的源文件上的具体错误信息，并进行展示。
方案五：开源方案 
 是一个实时的错误日志追踪和聚合平台，包含了上面  方案，并支持更多功能，如：错误调用栈， 信息，管理，多项目，多用户，提供多种语言客户端等，具体介绍可以查看 ，，这里暂不展开。

总结
以上的方案都有各自使用场景，能够解决问题的方案都是好方案。可以先快速支持，然后逐渐过渡到完整的方案。除了本篇文章 提到的方案外，社区还有不少其他的优秀方案。
关于  文件的生成，通过 ， 都可以很好支持，  的示例使用的是 ，只需要设置  ，具体示例可以查看这里 。
 查看更多文章 导语：       本文是对机器学习算法的一个概览，以及个人的学习小结。通过阅读本文，可以快速地对机器学习算法有一个比较清晰的了解。本文承诺不会出现任何数学公式及推导，适合茶余饭后轻松阅读，希望能让读者比较舒适地获取到一点有用的东西。

引言
本文是对机器学习算法的一个概览，以及个人的学习小结。通过阅读本文，可以快速地对机器学习算法有一个比较清晰的了解。本文承诺不会出现任何数学公式及推导，适合茶余饭后轻松阅读，希望能让读者比较舒适地获取到一点有用的东西。
本文主要分为三部分，第一部分为异常检测算法的介绍，个人感觉这类算法对监控类系统是很有借鉴意义的；第二部分为机器学习的几个常见算法简介；第三部分为深度学习及强化学习的介绍。最后会有本人的一个小结。
 异常检测算法
异常检测，顾名思义就是检测异常的算法，比如网络质量异常、用户访问行为异常、服务器异常、交换机异常和系统异常等，都是可以通过异常检测算法来做监控的，个人认为这种算法很值得我们做监控的去借鉴引用，所以我会先单独介绍这一部分的内容。
异常定义为“容易被孤立的离群点     ”——可以理解为分布稀疏且离密度高的群体较远的点。用统计学来解释，在数据空间里面，分布稀疏的区域表示数据发生在此区域的概率很低，因而可以认为落在这些区域里的数据是异常的。

图离群点表现为远离密度高的正常点
如图所示，在蓝色圈内的数据属于该组数据的可能性较高，而越是偏远的数据，其属于该组数据的可能性就越低。
下面是几种异常检测算法的简介。
 基于距离的异常检测算法

图 基于距离的异常检测
思想：一个点如果身边没有多少小伙伴，那么就可以认为这是一个异常点。
步骤：给定一个半径，计算以当前点为中心、半径为的圆内的点的个数与总体个数的比值。如果该比值小于一个阈值，那么就可以认为这是一个异常点。
 基于深度的异常检测算法

图 基于深度的异常检测算法
思想：异常点远离密度大的群体，往往处于群体的最边缘。
步骤：通过将最外层的点相连，并表示该层为深度值为；然后将次外层的点相连，表示该层深度值为，重复以上动作。可以认为深度值小于某个数值的为异常点，因为它们是距离中心群体最远的点。
 基于分布的异常检测算法

图 高斯分布
思想：当前数据点偏离总体数据平均值个标准差时，可以认为是一个异常点偏离多少个标准差可视实际情况调整。
步骤：计算已有数据的均值及标准差。当新来的数据点偏离均值个标准差时，视为异常点。
 基于划分的异常检测算法

图孤立深林
思想：将数据不断通过某个属性划分，异常点通常能很早地被划分到一边，也就是被早早地孤立起来。而正常点则由于群体众多，需要更多次地划分。
步骤：通过以下方式构造多颗孤立树：在当前节点随机挑选数据的一个属性，并随机选取属性的一个值，将当前节点中所有数据划分到左右两个叶子节点；如果叶子节点深度较小或者叶子节点中的数据点还很多，则继续上述的划分。异常点表现为在所有孤立树中会有一个平均很低的树的深度，如图中的红色所示为深度很低的异常点。
 机器学习常见算法
简单介绍机器学习的几个常见算法：近邻、聚类、决策树、朴素贝叶斯分类器、线性回归、逻辑回归、隐马尔可夫模型及支持向量机。遇到讲得不好的地方建议直接跳过。
 近邻

图距离最近的个点里面有个点为红三角，所以待判定点应为红三角
分类问题。对于待判断的点，从已有的带标签的数据点中找到离它最近的几个数据点，根据它们的标签类型，以少数服从多数原则决定待判断点的类型。
 聚类

图不断迭代完成“物以类聚”
聚类的目标是要找到一个分割，使得距离平方和最小。初始化个中心点；通过欧式距离或其他距离计算方式，求取各个数据点离这些中心点的距离，将最靠近某个中心点的数据点标识为同一类，然后再从标识为同一类的数据点中求出新的中心点替代之前的中心点，重复上述计算过程，直到中心点位置收敛不再变动。
 决策树

图 通过决策树判断今天是否适合打球
决策树的表现形式和类似，只是在通过数据生成决策树的时候，需要用到信息增益去决定最先使用那个属性去做划分。决策树的好处是表现力强，容易让人理解结论是如何得到的。
 朴素贝叶斯分类器
朴素贝叶斯法师基于贝叶斯定理与特征条件独立性假设的分类方法。由训练数据学习联合概率分布，然后求得后验概率分布。抱歉，没图，又不贴公式，就这样吧_
 线性回归

图 拟一条直线，与所有数据点实际值之差的和最小
 就是对函数=，通过代入已有数据，找到最合适的参数和，使函数最能表达已有数据输入和输出之间的映射关系，从而预测未来输入对应的输出。
 逻辑回归

图 逻辑函数
逻辑回归模型其实只是在上述的线性回归的基础上，套用了一个逻辑函数，将线性回归的输出通过逻辑函数转化成到之间的数值，便于表示属于某一类的概率。
 隐马尔科夫模型

图 隐藏状态之间的转移概率以及状态的观测为的概率图
隐马尔科夫模型是关于时序的概率模型，描述由一个隐藏的马尔科夫链随机生成不可观测的状态的序列，再由各个状态随机生成一个观测而产生观测的序列的过程。隐马尔科夫模型有三要素和三个基本问题，有兴趣的可以单独去了解。最近看了一篇有意思的论文，其中使用了隐马尔可夫模型去预测美国研究生会在哪个阶段转专业，以此做出对策挽留某专业的学生。公司的人力资源会不会也是通过这个模型来预测员工会在哪个阶段会跳槽，从而提前实施挽留员工的必要措施？_
 支持向量

图支持向量对最大间隔的支持
支持向量机是一种二分类模型，它的基本模型是定义在特征空间上的间隔最大的线性分类器。如图所示，由于支持向量在确定分离超平面中起着关键性的作用，所以将这种分类模型称为支持向量机。
对于输入空间中的非线性分类问题，可以通过非线性变换核函数将它转换为某个高维特征空间中的线性分类问题，在高维特征空间中学习线性支持向量机。如图所示，训练点被映射到可以容易地找到分离超平面的三维空间。

图将二维线性不可分转换为三维线性可分
 深度学习简介
这里将简单介绍神经网络的由来。介绍顺序为：感知机、多层感知机神经网络、卷积神经网络及循环神经网络。
 感知机

图输入向量通过加权求和后代入激活函数中求取结果
神经网络起源于上世纪五、六十年代，当时叫感知机，拥有输入层、输出层和一个隐含层。它的缺点是无法表现稍微复杂一些的函数，所以就有了以下要介绍的多层感知机。
 多层感知机

图多层感知机，表现为输入与输出间具有多个的隐含层
在感知机的基础上，添加了多个隐含层，以满足能表现更复杂的函数的能力，其称之为多层感知机。为了逼格，取名为神经网络。神经网络的层数越多，表现能力越强，但是随之而来的是会导致反向传播时的梯度消失现象。
 卷积神经网络

图卷积神经网络的一般形式
全连接的神经网络由于中间隐含层多，导致参数数量膨胀，并且全连接方式没有利用到局部模式例如图片里面临近的像素是有关联的，可构成像眼睛这样更抽象的特征，所以出现了卷积神经网络。卷积神经网络限制了参数个数并且挖掘了局部结构这个特点，特别适用于图像识别。
 循环神经网络

图 循环神经网络可以看成一个在时间上传递的神经网络
循环神经网络可以看成一个在时间上传递的神经网络，它的深度是时间的长度，神经元的输出可以作用于下一个样本的处理。普通的全连接神经网络和卷积神经网络对样本的处理是独立的，而循环神经网络则可以应对需要学习有时间顺序的样本的任务，比如像自然语言处理和语言识别等。
 个人小结
机器学习其实是学习从输入到输出的映射：

即希望通过大量的数据把数据中的规律给找出来。在无监督学习中，主要任务是找到数据本身的规律而不是映射
总结一般的机器学习做法是：根据算法的适用场景，挑选适合的算法模型，确定目标函数，选择合适的优化算法，通过迭代逼近最优值，从而确定模型的参数。
关于未来的展望，有人说强化学习才是真正的人工智能的希望，希望能进一步学习强化学习，并且要再加深对深度学习的理解，才可以读懂深度强化学习的文章。
最后最后，由于本人也只是抽空自学了几个月的小白，所以文中有错误的地方，希望海涵和指正，我会立即修改，希望不会误导到别人。
参考文献
【】      李航 统计学习方法 清华大学出版社 北京 
【】         ö          
【】                           
【】                           
【】       李宏毅   
【】       科研君卷积神经网络、循环神经网络、深度神经网络的内部结构区别 作者： 

王者荣耀、英雄联盟、热血传奇等等杰出作品不断，腾讯被评为爆款游戏的收割者。这句话好像有点不对？人家明明是爆款的挖掘机好吗！从到微信，哪一个不是流量帝国呢？

为什么制作爆款的总是腾讯？
我们把目光聚焦到上，能够将一款做的出色，成为爆款，这与腾讯背后强大的数据支撑，高效的系统运营能力密不可分。
越来越庞大的数据，需要更加精准的分析，支撑腾讯做出决策，以便有更好的用户体验，腾讯移动分析得以应运而生。
腾讯移动分析是一款帮助运营者推动产品增长的产品。
简单来说，就是这款产品会帮助我们的产品运营团队，更加了解每个成长阶段的数据情况，通过大数据分析对比，从而辅助运营团队做出决策，以便更好的运营产品。
“在经历过手机空间在内的诸多内部项目的成功运营后，腾讯移动分析平台积累了许多成熟的数据统计和分析能力，这些是当前市场中其他第三方统计平台所不具有的。”腾讯移动分析产品负责人黄岳浩这样说。
正是这样的优势使得腾讯移动分析在竞争愈发激烈的市场中占有较高的市场份额。
相关数据显示，截止年，我国数量已经超过万个，而截止到目前，腾讯移动分析累计接入应用达万，覆盖移动设备亿，月度活跃设备达亿。
这样的用户数量对于目前市场上很多企业服务产品都是可望而不可及的，因为就端市场而言，产品的接入成本往往要远远高于端产品。
 创新中国秋季峰会上，黄岳浩发表过“数据驱动产品精益化运营”的主题演讲。为在场参会的创业者，从数据分析的应用、从到搭建数据运营体系、辅助运营工具三个角度展现了腾讯的功能应用。
一个产品的生命周期分为：初创期、成长期、成熟期，接下来是衰退期或是延展期，几个阶段。
产品不同生命周期需要关注的数据指标以及运营重点各有不同，但是一般来说，关注核心用户群的活跃、留存、使用频率、使用时长是需要贯穿产品各个阶段的。

· 初创期的产品，需要了解清楚用户是谁，可以通过描绘用户的画像，从而验证假设，并找到产品现行指标 迭代优化 同时根据的数据反馈，帮助产品做出及时运营策略调整；
· 快速成长期，需要关注的，一是产品的自增长，即不通过任何运营的方式，产品自发的自我增长；二是精细打磨产品，当用户逐渐认可平台时，开始产生内容，即开始成为核心用户、高价值用户，再将用户细分；
· 成熟期产品的重点是流失与回流。这个阶段关注的重点指标是产品营收，和单个用户的成本等。
· 衰退期或延伸期，意味着产品发展受限，可能行业盘子就是如此大，这时可能需要开发一个新的产品来进行延展，新产品的用户可能是从老产品里的活跃用户引流过来，也可能从老产品的沉睡用户里召回而来。
在整个产品生命周期中，贯穿着数据的分析应用。而如果自建数据运营分析体系成本过高，采用第三方成熟的移动运营平台成为很好的选择。腾讯认准了这个市场前景，将在市场上推广应用获得了较好的成绩。

同时腾讯移动分析也在打通产品生命周期中用户使用场景的各个环节，来不断提高产品价值，例如与推送工具，如腾讯移动推送信鸽，进行打通，让用户可以使用的用户画像数据针对不同的用户进行精准消息推送，避免打扰用户，提高用户活跃度。
对于创业者来说，更应该借鉴腾讯的成功经验，重视产品数据分析给运营带来的价值，让“以数据说话”取代“盲目的尝试”。
最后，给大家介绍一下，这是腾讯移动分析

原文来自：腾讯大数据 公众号前言
本文分析了  进程关闭的过程，以及如何安全、缓和地关闭  实例，对这个过程不甚清楚的同学可以参考下。
关闭过程
、发起 ，发出   信号
、有必要的话，新建一个关闭线程 
如果是客户端发起的关闭，则会新建一个专用的关闭线程
如果是直接收到  信号进行关闭的话，专门负责信号处理的线程就会负责关闭工作，或者新建一个独立的线程负责这个事
当无法创建独立的关闭线程时例如内存不足，  会发出类似下面的告警信息：
 ’     
、  不再响应新的连接请求
关闭  网络监听，关闭   等渠道
、逐渐关闭当前的连接、事务
空闲连接，将立刻被终止；
当前还有事务、 活动的连接，会将其标识为 ，并定期检查其状态，以便下次检查时将其关闭；参考  语法
当前有活跃事务的，该事物会被回滚，如果该事务中还修改了非事务表，则已经修改的数据无法回滚，可能只会完成部分变更；
如果是  复制场景里的 ，则对复制线程的处理过程和普通线程也是一样的；
如果是  复制场景里的 ，则会依次关闭 、 线程，如果这  个线程当前是活跃的，则也会加上  标识，然后再关闭；
 服务器上， 线程是允许直接停止当前的  操作的为了避免复制问题，然后再关闭该线程；
在   及以前的版本里，如果  线程当时正好执行一个事务到中间，该事务会回滚；从  开始，则会等待所有的操作结束，除非用户发起  操作。
当  的  线程对非事务表执行操作时被强制  了，可能会导致 、 数据不一致；
、  进程关闭所有线程，关闭所有存储引擎；
刷新所有表 ，关闭所有打开的表；
每个存储引擎各自负责相关的关闭操作，例如  会刷新所有等待写入的操作； 会将   刷新到磁盘中从   开始，如果 __ 不设置为  的话，把当前的  记录到表空间中，然后关闭所有的内部线程。
、  进程退出
关于  指令
从  开始， 支持指定   |  两种可选项：

  和原来的一样，停止回滚事务，关闭该线程连接，释放相关资源；

  则只停止线程当前提交执行的操作，其他的保持不变；


提交  操作后，该线程上会设置一个特殊的  标记位。通常需要一段时间后才能真正关闭线程，因为  标记位只在特定的情况下才检查：
、执行  查询时，在   或   循环中，每次读完一些行记录块后会检查  标记位，如果发现存在，该语句会终止；
、执行   时，在从原始表中每读取一些行记录块后会检查  标记位，如果发现存在，该语句会终止，删除临时表；
、执行  和  时，每读取一些行记录块并且更新或删除后会检查  标记位，如果发现存在，该语句会终止，回滚事务，若是在非事务表上的操作，则已发生变更的数据不会回滚；
、_ 函数返回 ；
、  线程会迅速内存中的新增记录，然后终止；
、如果当前线程持有表级锁，则会释放，并终止；
、如果线程的写操作调用在等待释放磁盘空间，则会直接抛出“磁盘空间满”错误，然后终止；
、当  表在执行   或   时被  的话，会导致该表损坏不可用，指导再次修复完成。
安全关闭  几点建议
想要安全关闭  服务进程，建议按照下面的步骤来进行：
、用具有 、 等最高权限的账号连接 ，最好是用   方式连接；
、在  及以上版本，设置 __ = ，允许快速关闭 不进行  、  ，如果是为了升级或者降级  版本，则不要设置；
、设置 ____ = ，让  把所有脏页都刷新到磁盘中去；
、设置 _ 和 __ 为 ，也就最后除了自己当前的连接外，不允许再有新的连接创建；
、关闭所有不活跃的线程，也就是状态为   且  大于  的线程 ；、执行    确认是否还有活跃的线程，尤其是会产生表锁的线程，例如有大数据集的 ，或者大范围的 ，或者执行 ，都是要特别谨慎的；
、执行     确认    的值较低一般要低于 ，也就是未  的事务很少，并且确认   、   、   三个状态的值一样，也就是所有的  都已经做过检查点了；
、然后执行    操作，刷新所有  ，关闭已打开的表 的作用是该操作不记录 ；
、如果是  服务器，最好是先关闭 _，等待所有   都应用完后，再关闭 _，避免 _ 在执行大事务被终止，耐心待其全部应用完毕，如果非要强制关闭的话，最好也等待大事务结束后再关闭 _；
、最后再执行  。
、紧急情况下，可以设置 __ = ，然后直接执行   即可，甚至直接在操作系统层调用  或者   杀掉  进程在 _____ =  的时候可能会丢失部分事务，不过  进程再次启动时，会进行   工作，需要有所权衡。
啰嗦那么多，其实正常情况下执行   就够了，如果发生阻塞，再参考上面的内容进行分析和解决吧，哈哈：接《 ：云时代的数据库  上》
 日志驱动
在这一节中，我们介绍了数据库引擎是如何产生日志的，这样可持久化状态、运行时状态、以及复制状态永远是一致的。重点讲述了如何不通过复杂的协议来高效地实现一致性。首先，我们展示如何在故障恢复的时候，避免使用昂贵的日志重放。其次，我们介绍了一些常规操作，以及我们能如何保持运行时和复制状态。最后，我们介绍故障恢复过程的细节。
 方案概览：异步处理
由于我们将数据库建模为日志流，这样日志的不断滚动的过程可以看作一连串顺序的变更。在实现上，每一条日志记录都有一个由数据库产生单调递增的日志编号。
这让我们可以使用异步的思路简化用来维护状态的一致性协议，而不是使用这种沟通复杂且对错误容忍度低的协议。从上层来看，我们维护一致性和可持久性的状态点，并随着我们收到发出去请求的确认消息，不断地推进这些点。由于任何单个的存储节点都有可能丢失一个或者多个日志记录，这些节点与节点相互之间交流，找到并填补丢失的信息。数据库维护的运行时状态可以让我们用单个数据段的读来代替大多数读，除非是在故障恢复的时候，状态丢失了必须通过重建。
数据库可能同时发起了多个独立的事务，这些事务完成的顺序与发起的顺序是不一致的。假如这时数据库崩溃了重启，每个事务决定是否需要回滚是相互独立的。跟踪未完成的时候并回滚的逻辑还是在数据库引擎中完成，就如同它在写单个盘一样。不过，在数据库重启的时候，在它被允许访问存储之前，存储服务需要进行自己的故障恢复流程，然而重点不在用户级的事务上，而是确保数据库能看到存储的一致性视图，尽管存储本身是分布式的。
存储服务首先确定  ，能确保之前日志记录都可用最大的。在存储恢复的过程中，大于的日志就都必须被截断。数据库可以通过找到  ，并使用这些点进行进一步的日志截断。这样我们可以定义  为所有副本中最大的，必须小于或者等，所有大于的日志记录都可以被截断丢掉。举个例子，即使我们有到 的完整数据，数据库发现只有、和是点，那么，我们必须在处截断。我们有到的完整数据，不过我们只有到的可持久性。
因而，完整性和可持久性是不同的。一个可以看作描述带某种形式限制的存储系统事务，这些事务本身必须按序确认。如果客户端认为这些区分没用，它可以将每个日志记录看作一个。在实现中，数据库和存储必须如下交互：
每个数据库层的事务会被划分为多个事务，这些事务是有序的，并且被原子的执行每个事务由多个连续的日志记录组成事务的最后一个日志记录就是一个在故障恢复的时候，数据库告诉存储服务建立每个的可持久化点，并使用这些来确认，然后发送命令截断所有大于的日志记录。
 常规操作
我们现在介绍数据库的常规操作，重点依次介绍写，读，事务提交，副本。
 写
在中，数据库不断的与存储服务交互，维护状态来保持大多数派，持久化日志记录，并将事务标记为已提交。比如，在正常前台路径中，如果数据库收到写大多数派的写确认回复，它会将往前推进。在任意一个时间点，数据库中都会存在着大量并发的事务，每个事务产生自己的日志。数据库为每个记录分配一个唯一有序的，这些不能大于加上  目前被设为。这个限制保证数据库不会领先存储服务太多，以至于导致后台处理的压力过大如网络或者存储跟不上阻塞写请求。
注意到每个中的每个数据段只会看到整体的一部分日志记录。每个日志记录含有一个反向的指针指向这个中的前一个日志记录。这些反向指针可以用来追踪每个数据段的完整性点，来确认  ，是收到的连续日志的最大值。被数据库节点用来与其他节点交流，找到缺失的日志记录并添补它们。
 提交
在中，事务的提交是异步完成的。当客户端提交一个事务，处理这个提交请求的线程将事务放在一边，并将 记录在一个单独的事务队列中等待被确认提交，然后就去做其他事情了。这等同于实现了协议：确认一个事务提交完成了，当且仅当最新的大于或者等于这个事务的 。当不断的增加，数据库找到哪些事务等待被确认，用一个单独的线程给等待的客户端返回事务完成的确认。线程不会等待事务提交完成，它们会继续处理等待着的请求。
 读
在中，与大多数数据库一样，数据页是从 中读取，只有在被请求的页不在中时，才会发起一次存储请求。
如果 满了，系统会找到一个页并将其踢出缓存。在传统的数据库中，如果这个被踢出的页是脏页，它在被替换之前会被刷新到数据盘中。这是为了保证接下来读取的数据页永远是最新的数据。不过在踢出页的时候不会写磁盘，它提供了一个类似的保证： 中的数据页永远是最新的数据。这个保证通过踢出 数据页上应用的最新的日志记录的大于或者等于的数据页来实现。这个协议确保：所有对数据页的变更都已经持久化在日志中了，如果缓存失效，可以通过获取最新页来构造当前所对应的页面。
数据库在通常情况下都不要通过多数派读来获得一致性。当从盘里面读一个页的时候，数据库建一个读取点，代表请求发生时的。数据库可以选择一个对这个读取点是完整的存储节点，这样读取的数据肯定是最新的版本。从存储节点返回的数据页必须与数据库中事务的语义一致。由于数据库直接将日志记录发送给存储节点，并跟进日志处理的进程也就是，每个数据段的，通常它知道哪些数据段是可以满足一个读请求的大于读取点的数据段，因而可以直接将请求发送给有足够数据的数据段。
考虑到数据库记录了所有的当前读操作，因而可以计算出在任意时间点每个的最小读取点。如果有读副本，写副本会与它们沟通获取所有存储节点上每个的最小读取点。这个值称作最小读取点，代表低水位点。在此以下的的所有的日志记录都是不必要的。换句话说，存储节点中数据段确认不会再有读取请求的读请求点小于。每个存储节点都能通过数据库获取到这个值，并且能合并老的日志记录并继续生产新的数据页，然后放心的将这些日志记录回收掉。
跟传统的数据库一样，实际的并发控制协议在数据库引擎中执行，就像数据页和段在本地存储一般。
 副本
在中，一个写副本和多至个读副本可以挂载同一个共享的存储空间。因而，读副本不会增加任何的存储和写开销。为了减少延时，写副本产生的日志流发送到存储节点的同时，也会发送到所有的读副本。在读副本中，数据库会依次消费每一个日志记录。如果日志记录指向的是一个 中存在的页，它就用 应用日志的变更到数据页上。否则的话，它就直接丢掉这条日志。注意，从写副本的角度来看，读副本是异步的消费这些日志，而写副本确认用户事务的完成是与读副本无关的。读副本在应用这些日志的时候遵守两条重要的规则：只有小于或者等于的日志记录会被应用，一个事务中的日志记录会原子的被应用，确保副本可以看到所有数据库对象的一致性视图。在实际中，每个读副本滞后写副本一小段时间或以内。
 故障恢复
大多数传统的数据库使用类似的恢复协议，这些协议依赖可以代表所有已提交事务的。这些系统也会粗粒度的为数据库周期性的，通过刷新脏页和将检查点写入日志，来建立检查点。在重启的时候，一个数据页可能丢失一些已经提交的数据，或者包含未提交的数据。因而，在故障恢复的时候，系统重放自上一个检查点其的所有日志到相关的数据页。这个过程将数据库的页重新置为在故障发生那个时间点的一致性状态，之后通过执行相关的日志可以将正在执行的事务回滚。故障恢复是一个代价昂贵的操作。降低建立检查点的时间间隔会有所帮助，不过是以干扰前台事务为代价的。在中不需要做这样的折中。
传统数据库的一个简化规则是，在前台处理和故障恢复同步使用的日志，也会在数据库离线在后台服务中使用。在中，我们也依赖于同样的规则，只不过这里 是与数据库解耦的，一直并行的在后台运行在存储节点上。当数据库启动的时候，它会与存储服务协助进行数据恢复，因而数据库可以恢复非常快通常在以内，即使在崩溃的时候正在执行 的写入。
数据库在故障重启的时候仍然需要重建运行时状态。在这种情况下，数据库连接每一个，数据段的读多数派如果能确认发现其他数据，也可以形成一个写多数派。一旦数据库为每一个建立了读多数派，它可以计算出可以截断的范围，这个范围是新的到当前数据库已经分配的最大的。数据库能推导出这个上限值，是因为它分配，并且限制了最大的为之前已经介绍过的，值为。这些截断范围是用时间戳来标记的并且写到存储服务中，因而在截断的时候并没有任何歧义，即使恢复过程被打断或者重启。
数据库仍然需要执行恢复来回滚在故障时间点正在进行的事务。不过，恢复可以在系统启动后通过段来获取正在进行的事务之后再进行。
 整体来看
在这一节中，我们从整体来描述构成的组件，如图所示。

数据库引擎是社区版的分支，主要区别是如何从数据盘读取或者写入数据。在社区版中，一个写操作的执行包括数据页在中被修改，日志按有序写入到的中。在事务提交的时候，协议只要求事务的日志写入到数据盘。真正被修改的数据页最终会写入数据盘，这里使用了双写技术来避免数据写盘不完整。这些数据页的写入可能发生在后台，可能由于的踢出，也有可能由于建立检查点。除了子系统之外，还有事务子系统，通过树和事务实现的锁管理器。事务是只在中使用的结构，描述的是一组必须原子执行的操作比如，分裂或者合并树的页。
在版本的中，每个事务中的日志会按所属的分组打包，然后批量写入存储服务中。每个事务的最后一个日志记录被标记为一个一致性点。写副本支持社区版相同的隔离级别。的读副本会不断的从写副本中获取事务开始和提交的信息，并使用这些信息来支持本地只读事务的快照隔离级别。注意到并发控制完全在数据库引擎中实现，不会影响存储服务。存储服务为数据提供一个一致性的视图，在逻辑上等价于社区版写数据到本地存储。
使用 来作为它的控制面板。在数据实例上部署来监控集群的健康状况，是否需要做故障切换，或者实例是否应该被替换掉。每个数据库集群包括一个写副本，个或者多个度副本。集群中所有的实例都在一个地理上的区域中，通常会位于不同的可用区，连接到相同区域里面的存储服务。为安全性考虑，我们隔离了数据库，应用以及存储之间的通信。在实际中，每个数据库实例可以与三个虚拟网络通信：用户应用与数据库引擎交互的用户，数据库引擎与控制面板交互的 ，数据库与存储服务交互的存储。
存储服务部署在一个虚拟机集群上，集群最少会跨同一个的三个可用区，共同为多个用户提供存储，读取或者写入数据，备份或者恢复用户数据。存储节点操作本地的盘，与数据库实例、其他存储节点、备份恢复服务交互，持续地将数据备份到或者从恢复数据。存储服务的控制面板用 作为持久存储，存放数据库容量配置、元数据以及备份到上的数据的详细信息。为了支持长时间的操作，比如由故障导致的数据库恢复或者复制操作，存储服务的控制面板使用    。为了保证高质量的可用性，需要在用户发现之前积极的、自动的监控和探测真实的和潜在的问题。所有存储服务的关键操作都被持续的监控起来，如果发现性能或者可用性方面的潜在问题会及时告警。前言
文章是自己写了后先发到了公众号里，再转到了内部的。算是一个系列的学习笔记，一篇篇来。
本篇是大数据算法系列 第一篇《的原理和实现》， 的思想的和原理是很多算法的基础，因此我们以开篇。
既然是说大数据算法，我们先尝试给大数据算法一个定义，或者说是限定一下这个系列的范围。
大数据算法：在给定的资源约束下，以大数据为输入，在给定时间约束内可以计算出给定问题加过的算法。
大数据算法会有传统的算法有不一样的地方：

资源有约束
时间有约束
大数据作为输入
不一定是精确算法

前三点可以看作是对算法的要求，第四点可以看作是在大数据场景下算法可以做出的让步。比如说在亿的数据中求   操作，完全精确的算法会十分占用空间资源，而且也很难在快速计算出结果。如果这时候允许一定的误差，就可以在极短的时间使用少量的内容算出结果，比如基数估计算法中的。
本系列会包括 、 、 、  、 、 、  等算法。我会把这些算法一个个过一遍，看论文、写代码、整理学习笔记。
对于技术人员来讲，文章应该做到 图文码并茂，因此我会尽量做到每篇文章都有原理说明和示例代码的实现，原理说明会通过配图的方式来理解，代码的话会有一个比较简单的。
一、原理
基本原理
 的基本原理就是用一个  来标记某个元素对应的 ，而  即是该元素。由于采用一 个 来存储一个数据，因此可以大大的节省空间。
我们通过一个具体的例子来说明  的原理，假设我们要对  内的  个元素   排序，那么我们就可以采用  方法假设这些元素没有重复。
如下图，要表示  个数，我们就只需要  个 ，首先我们开辟  的空间，将这些空间的所有  位都置为 。

然后，我们要添加  这三个数到  中，需要的操作就是在相应的位置上将置为即可。如下图，比如现在要插入  这个元素，只需要将蓝色的那一位变为即可。

将这些数据插入后，假设我们想对数据进行排序或者检索数据是否存在，就可以依次遍历这个数据结构，碰到位为  的情况，就当这个数据存在。
字符串映射
 也可以用来表述字符串类型的数据，但是需要有一层映射，如下图，通过一层映射关系，可以表述字符串是否存在。

当然这种方式会有数据碰撞的问题，但可以通过   做一些优化。
二、实现
懂原理之后，还是要写代码来加深一下理解，这里用  实现一个最基本的版本。
代码用到了  库来直接操作  数组；用  来将字符串映射到数字，以便插入 。
代码很简单，看懂上面的原理的话，很容易就看懂了代码。

三、使用
 的使用场景很广泛，比如说  、 中都有用到 。当然更多的系统会有比  稍微复杂一些的算法，比如  、   ，这些会在后面逐一展开。
下面举一个在算法中用到  来解决问题的例子。

已知某个文件内包含一些电话号码，每个号码为位数字，统计不同号码的个数。

在这里就不再做和其它算法的对比，直接说一下  的思路。
 位的整数，相当于是范围在，也就是说  个 ，也就是  左右的内存，比起用类似  的方式的话能节省很大的空间。 可以理解为从 到  的数字，每个数字对应一个 位，所以只需要  左右的内存表示了所有的  位数的电话。
查询的时候就很简单了，直接统计有多少位是  就可以了。
四、总结
 的思想在面试的时候还是可以用来解决不少问题的，然后在很多系统中也都会用到，算是一种不错的解决问题的思路。
但是  也有一些局限，因此会有其它一些基于  的算法出现来解决这些问题。

数据碰撞。比如将字符串映射到  的时候会有碰撞的问题，那就可以考虑用   来解决，  使用多个  函数来减少冲突的概率。
数据稀疏。又比如要存入这三个数据，我们需要建立一个  长度的  ，但是实际上只存了个数据，这时候就有很大的空间浪费，碰到这种问题的话，可以通过引入   来解决。

算法比较成熟，因此参考的东西也挺多，就不再列参考了。本文作者： 

视频格式？编码？
如果我们想要理解  视频，首先需要知道，你应该知道，但你不知道的内容？那怎么去判断呢？ ，很简单，我提几个问题即可，如果某些童鞋知道答案的话，可以直接跳过。

你知道 前面加个点这些叫做什么吗？
那 ，， 是啥？
如果，基友问你要片源，你会说我这是  的还是  的呢？

当然，还有一些问题，我这里就不废话了。上面主要想说的其实就两个概念：视频文件格式容器格式，视频编解码器视频编码格式。当然，还有另外一种，叫做音频编解码器。简而言之，就是这三个概念比较重要：

视频文件格式容器格式
视频编解码器视频编码格式
音频编解码器音频编码格式

这里，我们主要讲解一下前面两个。视频一开始会由两个端采集，一个是视频输入口，是一个音频输入口。然后，采集的数据会分别进行相关处理，简而言之就是，将视频音频流，通过一定的手段转换为比特流。最终，将这里比特流以一定顺序放到一个盒子里进行存放，从而生成我们最终所看到的，比如， 等等音视频格式。
视频编码格式
视频编码格式就是我们上面提到的第一步，将物理流转换为比特流，并且进行压缩。同样，它的压缩编码格式会决定它的视频文件格式。所以，第一步很重要。针对于  中的 ，它实际上是支持多种编码格式的，但局限于各浏览器厂家的普及度，目前视频格式支持度最高的是 ，音频则是 。下面就主要说下视频的，音频就先不谈了。
目前市面上，主流浏览器支持的几个有：


 第  部分


免费

其它格式，我们这里就不过多赘述，来看一下前两个比较有趣的。如下图：

请问，上面箭头所指的编码格式是同一个吗？
答案是：
因为， 实际上是于  年提出的一个标准。而  则是后台作为优化提出的新的标准。简单来说就是，我们通常说的  其实就是  。而， 则是第十部分，也叫 ，又可以理解为  。而两者，不同的地方，可以参考： 的讲解。简单的区别是： 压缩率比以前的 第  部分 高很多。简单可以参考的就是：

详细参考 编码格式详解
视频文件格式
视频文件格式实际上，我们常常称作为容器格式，也就是，我们一般生活中最经常谈到的格式，，， 格式等。它就可以理解为将比特流按照一定顺序放进特定的盒子里。那选用不同格式来装视频有什么问题吗？ 答案是，没有任何问题，但是你需要知道如何将该盒子解开，并且能够找到对应的解码器进行解码。那如果按照这样看的话，对于这些 ，，等等视频格式，只要我有这些对应的解码器以及播放器，那么就没有任何问题。那么针对于，将视频比特流放进一个盒子里面，如果其中某一段出现问题，那么最终生成的文件实际上是不可用的，因为这个盒子本身就是有问题的。 不过，上面有一个误解的地方在于，我只是将视频理解为一个静态的流。试想一下，如果一个视频需要持续不断的播放，例如，直播，现场播报等。这里，我们就拿  流来进行讲解。

  静态文件流
  动态文件流

针对于上面两种容器格式，实际上是对一个视频比特流做了不一样的处理。

 将完成视频比特流放到一个盒子里，生成固定的文件
 将接受到的视频，分成不同的盒子里。最终生成带有多个盒子的文件。

那么结果就是，如果一个或多个盒子出现损坏， 格式无法观看，而  只是会出现跳帧或者马赛克效应。两者具体的区别就是：对于视频的容错率越高，则会选用 ，对视频容错率越低，则会选用 。
常用为：

：，，，，
：，
、：， 
：，，
：，，
：可以封装所有的视频编码格式。

详细参考：视频文件格式
直播协议
 年是直播元年，一是由于各大宽带提供商顺应民意增宽降价，二是大量资本流进了直播板块，促进了技术的更新迭代。市面上，最常用的是  推出的  直播协议原始支持  播放，当然，还有 、、等。 这里，再问一个问题：

 和  以及容器格式  是啥关系？

简单来说，没关系。
 根本就不会涉及到视频本身的解码问题。它的存在只是为了确保你的视频能够及时，快速，正确的播放。
现在，直播行业依旧很火，而  直播，一直以来都是一个比较蛋疼的内容。一是，浏览器厂商更新速度比较慢，二是，这并不是我们前端专攻的一块，所以，有时候的确很鸡肋。当然，进了前端，你就别想着休息。接下来，我们来详细的看一下市面上主流的几个协议。

 全称是   。这是  提出的直播流协议。目前， 和 高版本  都支持 。那什么是  呢？  主要的两块内容是 文件和  播放文件。接受服务器会将接受到的视频流进行缓存，然后缓存到一定程度后，会将这些视频流进行编码格式化，同时会生成一份文件和其它很多的  文件。根据  阐述， 的基本架构为：

服务器：后台服务器接受视频流，然后进行编码和片段化。 编码：视频格式编码采用 。音频编码为   ，。然后使用    作为容器格式。
分片：将  文件分成若干个相等大小的 文件。并且生成一个  作为索引文件确保包的顺序

分发：由于  是基于  的，所以，作为分发，最常用的就是  了。
客户端：使用一个  去下载  文件，然后，开始下载  文件，下载完成后，使用 即时播放器 进行播放。

这里，我们着重介绍一下客户端的过程。首先，直播之所以是直播，在于它的内容是实时更新的。那  是怎么完成呢？ 我们使用  直接就用一个  进行包括即可：
    
     = =  
     =        

 根据上面的描述，它实际上就是去请求一个 的索引文件。该文件包含了对 文件的相关描述，例如：
              的版本，可带可不带。下面有说明
                     文件头
    分片最大时长，单位为 
     第一个分片的序列号，如果没有，默认为 
          是否允许
              文件结束符
                     指定每个媒体段的持续时间秒，仅对其后面的有效
 不过，这只是一个非常简单，不涉及任何功能的直播流。实际上， 的整个架构，可以分为：

当然，如果你使用的是 作为链接，如：
     
     = =  
     =        

 我们看一下， 里面具体的内容是啥：
 

====

====

====

====

 这个标签头代表：当前用户的播放环境。 主要干的事就是根据 当前用户的带宽，分辨率，解码器等条件决定使用哪一个流。所以，  是为了更好的用户体验而存在的。不过，弊端就是后台储备流的量会成倍增加。 现在，我们来主要看一下如果你使用  ，那么整个流程是啥？ 当填写了   ，那么用户只会下载一次该  。接着，播放器根据当前的环境决定使用哪一个  就是 子  文件。如果，在播放当中，用户的播放条件发生变化时，播放器也会切换对应的  。关于   内容，我们就先介绍到这里。 关于 ，感觉主要内容还在   上。当然，  还分为三种 ：

  动态列表。顾名思义，该列表是动态变化的，里面的  文件会实时更新，并且过期的  索引会被删除。默认，情况下都是使用动态列表。
  静态列表。它和动态列表主要区别就是，原来的  文件索引不会被删除，该列表是不断更新，而且文件大小会逐渐增大。它会在文件中，直接添加  作为标识。
  全量列表。它就是将所有的  文件都列在  当中。如果，使用该列表，就和播放一整个视频没有啥区别了。它是使用  表示文件结尾。

  ：
 









  ：
 










  ：
 











 上面提到过一个  这样的标签，这是用来表示当前  的版本。那  有哪些版本呢？ 根据  官方文档 的说明，我们可以了解到，不同版本的区别：

当然， 支持的功能，并不只是分片播放专门适用于直播，它还包括其他应有的功能。

使用  加密  文件
快倒放
广告插入
不同分辨率视频切换

 的弊端
由于  是基于  的，所以，它关于  的好处，我们大部分都了解，比如，高兼容性，高可扩展性等。不过正由于是  协议，所以会在握手协议上造成一定的延迟性。 首次连接时，总共的延时包括：

 握手，  文件下载，  下的  文件下载。

其中，每个  文件，大概会存放  的时长，并且每个  文件会存放  个  文件。我们折中算一下， 个  文件，每个时长大约  那么，总的下来，一共延时 。当然，这还不算上  握手， 文件下载等问题。那优化办法有吗？有的，那就是减少每个  文件中的  数量和  文件时长，不过，这样也会成倍的增加后台承受流量请求的压力。所以，这还是需要到业务中去探索最优的配置打个广告：腾讯云的直播视频流业务，做的确实挺棒。 关于  的详细内容，可以参考： 详解 关于  文件的标签内容，可以参考： 标签头详解 总而言之， 之所以能这么流行，关键在于它的支持度是真的广，所以，对于一般  直播来说，应该是非常友好的。不过，既然是直播，关键在于它的实时性，而  天生就存在一定的延时，所以，就可以考虑其他低延时的方案，比如 ，。下面，我们来看一下  内容。

 全称为：   。它是专门应对实时交流场景而开发出来的一个协议。它爹是 ，后来卖身给了 。 根据不同的业务场景，有很多变种：

纯  使用  连接，默认端口为 有可能被封。
 就是   
   。在  原始协议上使用， 自身的加密方法
   。使用  的方式来包裹  流，这样能直接通过防火墙。
   。该协议常常用于  的场景中，针对延时有变态的要求。

既然是  公司开发的算吧，那么，该协议针对的就是  ，即，。不过，在移动端上，  已经被杀绝了，那为啥还会出现这个呢？简单来说，它主要是针对  端的。 出现的时候，还是 零几 年的时候， 还在大行其道，  也并未被各大浏览器所排斥。那时候  毋庸置疑的可以在视频界有自己的一席之地。
 由于借由  长连接协议，所以，客户端向服务端推流这些操作而言，延时性很低。它会将上传的流分成不同的分片，这些分片的大小，有时候变，有时候不会变。默认情况下就是， 的音频数据   的视频数据  其它数据比如 头，协议标签等。但  具体传输的时候，会将分片进一步划分为包，即，视频包，音频包，协议包等。因为， 在进行传输的时候，会建立不同的通道，来进行数据的传输，这样对于不同的资源，对不同的通道设置相关的带宽上限。
 处理的格式是   。 不过，由于支持性的原因， 并未在  直播中，展示出优势。下列是简单的对比：


 和  类似，都是针对于  视频格式做的直播分发流。但，两者有着很大的区别。

相同点 
两者都是针对  格式
两者延时都很低
两者都走的  通道

不同点 

 
直接发起长连接，下载对应的  文件
头部信息简单

 

握手协议过于复杂
分包，组包过程耗费精力大

通过上面来看， 和  确实不是一回事，但，如果了解   ，那么 对  应该清楚不少。 本质上，就是    进行传输。因为  发的包很容易处理，通常  协议会作为视频上传端来处理，然后经由服务器转换为  文件，通过  下发给用户。

现在市面上，比较常用的就是  进行播放。但，由于手机端上不支持，所以， 的  也是一个痛点。不过，现在  可以帮助高版本的浏览器，通过  来进行解析。 的使用方式也很简单。和  一样，只需要添加一个连接即可： = =
 不过，并不是末尾是 的都是  协议，因为，涉及  的流有三种，它们三种的使用方式都是一模一样的。

 文件：相当于就是一整个文件，官方称为 渐进  流。它的特点是只能渐进下载，不能进行点播。
 伪流：该方式，可以通过在末尾添加 = 的参数，指定返回的对应开始时间视频数据。该方式比上面那种就多了一个点播的功能。本质上还是  直播。
 直播流：这就是  真正所支持的流。 在内部使用的是  进行分发，然后在传给用户的使用，经过一层转换，变为  流，最终传递给用户。

上面说到， 就是长连接，简而言之只需要加上一个 即可。关键是它的响应头，由于， 传递的是视频格式，所有，它的 和  需要设置其它值。
 
     


 不过，一般而言，直播服务器一般和业务服务是不会放在一块的，所以这里，可能会额外需要支持跨域直播的相关技术。在  里面，解决办法也很简单，直接使用  即可：
 那么整个响应头，可以为：






     


 对于  来说，关键难点在于  和  协议的转换，这里我就不多说了。因为，我们主要针对的是前端开发，讲一下和前端相关的内容。
接下来，我们在主要来介绍一下  格式的。因为，后面我们需要通过  来解码 。
 格式浅析
 原始格式， 可以直接看 格式详解。我这里就抽主要的内容讲讲。 也是与时俱进，以前  的格式叫做 ，新版的可以叫做 。两者的区别，简单的区分方法就是：

 是专门针对  播放器的
 是有点像  格式的  播放，主要为了兼容 。 不支持 两者本来都不是同一个格式

这里我们主要针对  进行相关了解。因为，一般情况下，后台发送视频流时，为了简洁快速，就是发送  视频。 由于年限比较久，它所支持的内容是 ， 。 一般可以嵌套在 文件当中，不过，对于  等  直播流来说，一般直接使用 文件即可。在  年的时候，提出了  这个视频格式，当然， 等也会向前兼容。

这里，我们来正式介绍一下  的格式。一个完整的  流包括     。
 
 格式头不难，就几个字段：




 








“”
有三个的大小算是一种身份的象征





只有  是有效的。其实就是默认值



 

表示该流的特征。 是 ， 是 ， 是 


 
_

用来跳过多余的头



 
在  的头部之后，就正式开始发送  文件。文件会被拆解为数个包 进行传输。每个包都带有  的头。前  个字节是用来代表前一个包的头部内容，用来完成倒放的功能。整个包的结构为：

具体解释如下：



字段
字段大小
默认值
详解




   
_

关于前一个包的信息，如果是第一个包，则该部分为 


 


设置包的内容，如果是第一个包，则该部分为  元数据


 
_

该包的大小


 
_

起始时间戳


 


持续时间戳，通常加上  实际上戳，代表整个时间。


 
_

流的类型，第一个流设为 


 


传输数据



其中，由于   的值可以取多个， 需要额外说明一下。

 
  包的大小
  字节读包反馈， ， 服务器带宽， 客户端带宽
 音频和视频的数据
   流
 经过封装的  。

上面是关于  简单的介绍。不过，如果没有    的帮助，那么上面说的基本上全是废话。由于，  已经被时代所遗弃，所以，我们不能在浏览器上，顺利的播放  视频。接下来，我们先来详细了解一下  的相关内容。
 接《 全面进阶  直播下》

原文链接：接张亦鸣   简史 上篇
进化：   
自  伊始，一个套源于  的全新设计开始逐渐进入人们的视野，并最终被添置到了   下。这一全新设计最终被命名为了  ：顾名思义，有全面扩充既有  功能之意；而相对应的，为了后向兼容，传统的 仍被保留了下来，并被重命名为  。相对于 ， 带来的改变可谓是革命性的：一方面，它已经为内核追踪 、应用性能调优监控、流控 等领域带来了激动人心的变革；另一方面，在接口的设计以及易用性上， 也有了较大的改进。 内核代码的  目录下有大量前人贡献的 ，这里笔者先挑选其中相对简单的  来帮助读者们建立一个  的初步印象：
清单      _
 …
 篇幅所限，清单  和  都只罗列出部分关键代码，有兴趣一窥全貌的读者可以移步 深入学习
    
{
       的伪代码位于 _ 中，这是一个由  生成的  格式文件，指令集为 
      _ 
     __ {
         __定义于 _，利用  来解析 _
         并利用 __ 将解析出的伪代码  进内核
    }
      因为 _ 中  程序的类型为 ____
     所以这里需要用用 __ 来指明程序的 _ 要挂载到哪一个套接字上
     = __
     _ __ _
    _ == 
    ……
      =      {
          利用  机制获取经由  发出的  报文的总长度
         = _
        ____  _ == 
         ……
    }
     
}
清单                 _

 ……
 预先定义好的  对象
 这里要注意好其实  是需要由用户空间程序调用 __进行创建的
 在这里定义的  对象，实际上会在 __解析  文件的同时被解析和创建出来
 这里的 宏表示在当前  文件中新增一个段
 __  _ = {
     = ___
    _ = 
    _ = 
    _ = 
}

 _ ___ 
{
     这个例子比较简单，仅仅是读取输入报文的包头中的协议位而已
     这里的 _ 实际指向了  的  函数 
     用于生成  指令 __ 和 __
      = _ _    
     
     ……
     根据 ，注意这是一个指向函数的引用获取对应的 
     = ____ 
     
        _____  这里的_____ 是  中的内嵌函数，表示  加操作
     
}

 为了满足  毒药的需求，所有会注入内核的  代码都须显式的支持  协议
 _  = 
对比一下清单  以及清单  的代码片段，很容易看出一些  显而易见的革新：

用  写成的  代码_；
基于  的内核与用户空间的交互方式；
全新的开发接口；
除此之外，还有一些不那么明显的改进隐藏在内核之中：
全新的伪指令集设计；
 由一个文件进化到一个目录， 的蜕变三言两语间很难交代清楚，下面笔者就先基于上述的几点变化来帮助大家入个门，至于个中细节，就只能靠读者以后自己修行了。

再见了汇编
利用高级语言书写  逻辑并经由编译器生成出伪代码来并不是什么新鲜的尝试，比如  就是在代码中内嵌了一个小型编译器来分析  传入的   从而生成  伪码的。只不过长久以来该功能一直没有能被独立出来或者做大做强，究其原因，主要还是由于传统的  所辖领域狭窄，过滤机制也不甚复杂，就算是做的出来，估计也不堪大用。
然而到了  的时代，情况终于发生了变化：现行的伪指令集较之过去已经复杂太多，再用纯汇编的开发方式已经不合时宜，于是，自然而然的，利用  一类的高级语言书写  伪代码的呼声便逐渐高涨了起来。
目前，支持生成  伪代码的编译器只有  一家，即使是通篇使用  编译的  内核， 目录下的     范例也要借用  来编译完成。还是以  为例，用户态下的代码 _ 是利用   定义的编译器编译的；但 _ 就需要用到  和  了。在中，可以看到：
清单      
 
     
 = __
 = 
 ……
 = _  _
 ……
 注意，这里有一个小 ，就是如果在内核的  中，
 有某一个目标文件你不希望使用内核的通用编译规则的话类似于本文的 _，
 可以像这里一样，并不把该文件加入任何  或 ，
 而是直接放入 ，这样内核就会在本地  中搜索编译规则了。
 = 
 = _
 ……
 = 
 = 
 ……
 _ 就是使用了下述规则编译为  代码的，请注意笔者加粗的部分
 
 _  _ \
____ ____   \
 \
 \
  \
 \
     |
 = = 

能用  书写  自然是便利了许多，但也不代表余下的开发工作就是一片坦途了：首先  的输出是 文件，这也意味着想要获取能传入内核的代码，我们还需要额外做一段解析  的工作，这也是为什么  下的范例几乎无一例外地都链接了  库；其次，同时也是比较重要的一点，不要忘记 的代码是跑在内核空间中的，因此书写时必得煞费苦心一番才好，以防一个不小心就做出个把内核干趴下的漏洞来：下文中提及的 就是为了这一点而生，每一个被放进内核的  代码，都须要经过它的检验才行。
 程序的类别以及  机制
清单  中我们看到 _ 是由 __函数载入内存的，但实际上  提供用来将   代码载入内核的正式接口函数其实是 __，该接口负责通过参数向内核提供三类信息：

 程序的类型、
 代码
代码运行时所需要的存放  的缓存地址位于用户空间；

有意思的是，目前所有注入内核的  程序都需要附带  协议支持信息，__的 参数就是用来载入协议字串的。
由  伊始， 程序开始有分类了，通过 __ 的参数 __，我们可以看到  支持的程序类型。这里笔者将一些常用的类型罗列于下表之中供读者参考：
表  常见                __ 定义



__
  入口参数
程序类型




____
 ___
用于过滤进出口网络报文，功能上和  类似。


___
 _
用于  功能的  代码。


___
这类  的参数比较特殊，根据  位置的不同而不同。
用于在各个  节点运行。


___
 _
用于控制   的  代码。


____
 ___
用于定义   发生时回调的  代码。


____
 ___
用于在   中运行的 代码。功能上和 _ 近似。具体用法可以参考范例 __。


____
 _
另一个用于在   中运行的  代码，范例 __ 中就展示了一个利用  来控制  和  间通信的例子。



深入对比清单 和清单 的实现的差异，还会发现一个比较明显的不同之处： 代码进内核之后， 和内核通讯的方式是                ；而  则将  丢到一边，使用一种名为  的全新机制和内核通讯，其大致原理下图所示：

图   的                 机制
从图上看，这套设计本身不复杂：位于用户空间中的应用在内核中辟出一块空间建立起一个数据库用以和    程序交互__；数据库本身以    的形式进行组织，无论是从用户空间还是内核空间都可以对其进行访问，两边有着相似的接口，最终在逻辑上也都殊途同归。
不难发现， 带来的最大优势是效率：相对于  一言不合就把一个通信报文从内核空间丢出来的豪放，  机制下的通讯耗费就要小家碧玉的多了：还是以  为例，一次通信从内核中仅仅复制 个字节，而且还是已经处理好了可以直接拿来就用的，做过内核开发的人都知道这对于性能意味着什么。
 机制解决的另一个问题是通信数据的多样性问题。 所覆盖的功能范围很简单，无外乎是网络监控和  两块，数据接口设计的粗放一点也就算了；而   的利用范围则要广的多，性能调优、内核监控、流量控制什么的应有尽有，数据接口的多样性设计就显得很必要了。下表中就列出了现有  中的 机制中常见的数据类型：
表        机制下的常见数据类型

新的指令集
 对于既有  令集的改动量之大，以至于基本上不能认为两者还是同一种语言了。个中变化，我们可以通过反汇编清单  的源代码                略知一二：
清单                       _
_   
   
_
          = 
          =  
             = 
          =    
           =   
          = 
          = 
                  = 
          
           ==   
          =    
              = 
_
          = 
         
我们不用管这段汇编写了点儿什么，先跟清单  开头的那段  代码对比一下两者的异同：
寄存器： 支持更多的寄存器；

：    
：   ，显然，如此的设计主要针对现在大行其道的                             位硬件，同时更多的寄存器设计也便于运行时和真实环境下的寄存器进行对应，以提高效率；

：两者的格式不同；

        
          

其他：_ 设计的比较简单，但还是可以从中看出  的一大改进：可以调用内核中预设好的函数                    ，这里指向的函数是 ___，如果需要比较全的预设函数索引的话可以移步这里。除此之外， 命令集中比较重要的新晋功能还有：

：仅可以读 即 以及读写 ；
：可以读写包括 ，也即                                      的传入参数可读写。换句话说，任意传入  代码的数据流均可以被修改；
 多样化：
除开预设函数外，开发者还可以自定义  函数__；
除了前向跳转外 ， 支持，还可以后向跳转 ；

至于  具体的指令表，因为过于庞杂这里笔者就不作文抄公了。不过  中的几个寄存器的利用规则这里还是可以有的，否则要读懂清单 中的代码略有困难：

：一般用来表示函数返回值，包括整个  代码块其实也可被看做一个函数的返回值；
：一般用于表示内核预设函数的参数；
：在  代码中可以作存储用，其值不受内核预设函数影响；
：只读，用作栈指针；

   
其实结合前面那么多的内容看下来不难发现 其实近似于一种改头换面后的内核模块，只不过它比内核模块更短小精干，实现的功能也更新颖一些罢了，但无论是什么样的架构，只要存在注入的代码就会有安全隐患，                也不外如是——毕竟注入的代码是要在内核中运行的。
为了最大限度的控制这些隐患， 时代就开始加入了代码检查机制以防止不规范的注入代码；到了  时代则在载入程序__时加入了更复杂的 机制，在运行注入程序之前，先进行一系列的安全检查，最大限度的保证系统的安全。具体来说，机制会对注入的程序做两轮检查：
 首轮检查 ，实现于_可以被认为是一次深度优先搜索，主要目的是对注入代码进行一次                      ，有向无环图检测，以保证其中没有循环存在；除此之外，一旦在代码中发现以下特征， 也会拒绝注入：

代码长度超过上限，目前内核版本  的代码长度上限为  条指令——这在                             时代很难达到，但别忘了  代码是可以用  实现的；
存在可能会跳出  代码范围的 ，这主要是为了防止恶意代码故意让程序跑飞；
存在永远无法运行的  令，例如位于  之后的指令；

 次轮检查 ，实现于_较之于首轮则要细致很多：在本轮检测中注入代码的所有逻辑分支从头到尾都会被完全跑上一遍，所有的指令的参数寄存器、访问的内存、调用的函数都会被仔细的捋一遍，任何的错误都会导致注入程序被退货。由于过分细致，本轮检查对于注入程序的复杂度也有所限制：首先程序中的分支不允许超过                     个；其次经检测的指令数也必须在  以内。
   的架构
诚然， 设计的复杂程度已是超越   太多太多，笔者罗里吧嗦了大半天，其实也就是将将领着大家入门的程度而已，为了便于读者们能够把前文所述的碎片知识串到一起，这里笔者将    的大体架构草绘一番，如下图所示，希望能帮助大家对  构建一个整体的认识。

图     
追求极简：  
现在让我们将目光聚焦到  的使用——相信这是大部分读者最感兴趣的部分，毕竟绝大多数人其实并没有多少机会参与  的开发——重新回到清单  中的 ：说句良心话，虽然现在可以用  来实现 ，但编译出来的却仍然是 文件，开发者需要手动析出真正可以注入内核的代码。这部分工作多少有些麻烦，如果可以有一个通用的方案一步到位的生成出   代码就好了，开发者的注意力应该放在其他更有价值的地方，不是吗？
于是就有人设计了   ， 是一个  库，但是其中有很大一部分的实现是基于  和 的， 只不过实现了对  应用层接口的封装而已。
使用  进行  的开发仍然需要开发者自行利用  来设计  程序——但也仅此而已，余下的工作，包括编译、解析 、加载 代码块以及创建  等等基本可以由  一力承担，无需多劳开发者费心。
限于篇幅关于  笔者不再过多展开，文章的最后笔者再给出一个基于  实现的  的例子，读者可以感受一下使用   带给开发者们的便利性：
清单        

   
 和清单  一样，篇幅所限，这里只贴一部分源码，完全版请移步 
=
  可以接受直接将  代码嵌入   之中
 为了方便展示笔者使用了这一功能
 注意： 中的中文注释是由于笔者需要写作之故加入，如果读者想尝试运行这段代码，
 则请将中文全部删除，因为目前  还不支持在内嵌  代码中使用中文注释
 = 
 
 
  中专门为  定义了一系列的宏，以方便使用
 宏中的  下还定义了相应的函数，让开发者可以如 一般操作 
 这里笔者定义了一个  类型的 ，名为 _
__ 
  下的  程序中不再需要定义把函数或变量专门放置于某个  下了
 _ ___ 
{
     ……
     _  = _ 
     ……
     _  = _ 
      = 
      =    下的  书写还是有很多坑的
     例如，这里如果不去定义一个局部变量 ，
     而是直接用常量  作为 __的变量就会报错
      类下的各个方法的具体细节可以参照 _
     = ___ 
     
        _____ 
     
}

 = =  = 
 注入 _ 函数
 = __ _
 这是一段 _ 类型的 ，所以需要挂载到某一个  上
__ 
 利用  机制获取进出  的各个协议的报文总长
_ = _
 
       {}   {}  {}
__
 …
结束语
本文从  的源头开始，一路讲到了近年来刚刚杀青的 ，虽说拘泥于篇幅，大多内容只能蜻蜓点水、浅尝辄止，但文中        的原理、设计、实现和应用均有所涉猎，勉强也能拿来入个门了。加之近年来基于    的应用层出不穷，希望本文能激发读者们的奇思妙想，从而设计出更多基于  的优秀应用来。
参考资源

                 的源头，可在这里查阅；
_  的     内核的  文档；
  套接字的  ，其中有对   中  接口的大致介绍，不过论及详细程度还是不及参考文献  的；
， 上刊载的      首次被引入的消息：    
  上刊载的   的介绍文献：  。由于年代久远接口相关的内容已经落后于最新代码了，权作参考；
 的源码，但由于编译需要比较多的依赖，如果想偷个懒的话可以移步这里直接获取    ；
_                     开发指南；
    源码阅读利器。


本文来源于  微信公众号对于做站的朋友来说，快照无疑是最直接体验一个网站好与不好的参考指数。但是很多站长都在为网站的快照过慢而发愁，甚至快照过慢还会影响到站长更新内容、增加外链的积极性。今天笔者跟大家说说做站两年来的关于快照新旧的解决方法。网站快照主要影响因素有四点：一心态。二内容。三外链。四框架结构。下面一一分析
　　影响快照新旧因素一：淡定的心态
　　不管做什么事，从事哪个行业，心态都是最重要的。一个冷静的头脑加上一颗淡定的心，可以使你少走不少的弯路，拒绝许多不必要的麻烦思想和决定。网站优化更需要这份心态。今天快照不更新就愁眉苦脸的，这不想干，那不想做，如果一个快照就把你搞成这个样子，那么你的心态会好都有限了。网站快照跟站长本身的心态有一定的联系，俗话说，不是一家人不进一家门，那么我们要做的是摆正心态，不以快照新而喜，不以快照慢而悲。用第三方的心态去正确的看待网站的快照，相信收获的不只是快照的快速更新，也可能达到一个新的境界。
　　影响快照新旧因素二：优质的内容
　　内容是一个网站的灵魂所在，也是搜索引挚蜘蛛的唯一“食物”。一个网站几天甚至一个多月都不更新一次内容，那么即使是蜘蛛来了，也没东西“喂”它，会给你好印象才怪呢。打个比方，就像你去街市买菜，如果你天天去市场买茄子，但是一连三天都没有茄子卖，不管你去得如何的早都没得卖，那么你还会继续去那里买吗所以，内容也是一样，做站长就要天天更新不同的内容，给蜘蛛天天来的时候有东西“吃”，“吃”得饱不饱那是另一回事了。而且内容要优良一些，大量转载来转载去的内容劝你不要还好，省得让蜘蛛觉得吃别的蜘蛛吃过的东西。明白吧。
　　影响快照新旧因素三：强力的外链
　　外链的强大与否影响很多的因素，最基本一点就是网站的快照了。很多站长都是有时间就猛地做外链，不管三七二十一，能加链接的地方通通加上去，加到不能加了就走人，这样一天之内做了几百条，甚至几千条，让网站的反链猛的一下子呈几何的形势增长上去。然而过几天忙起来了，又把增加外链这事给耽搁了，不做了。这就是许多站长反应的外链在坐过山车，时上时下的。究其原因就是站长本身做外链无规律所引起的。如此一来别说快照不更新了，能保住网站不被掉已经是不幸中的大幸了。所以想快照时常新就要做外链，强力的外链不是垃圾链，做外链要有规律的做，不可三天打鱼两天晒网。
　　影响快照新旧因素四：框架结构
　　为什么现在的查询网站会有一个功能叫做查询自己网站与其他同类程序的相似度。这就是框架原因。搜索引挚对框架的认知是很敏感的，如果你的站跟网上大部分同类站的结构一模一样的话，那么你有难了，搜索引挚会认为你的站是另外的站的附属站，或者直接定义为垃圾采集站。对于采集站，搜索引挚一开始也许会给予一定的排名，但是不长久，这样会形成一个欺骗搜索引挚的印象，那么对于友好度的问题就会大打折扣了。相信这种站即使快照是新的，排名也会烂到底或者直接没排名。所以，快照新旧跟框架也存在一定的关系，不要道听途说。自己分析一下就可以得出来的答案。 日，在  易观  大数据应用峰会上，针对“有序漏斗”难题进行行业攻坚的“ 易观  算法大赛”公布了最终结果。 参赛组以超过原始基准测试近  倍的成绩，获得了商业组的冠军，并作为优秀案例在大会进行了解题思路分享。

 作为本次算法大赛商业组参赛队，借助  的算法引擎，展现了强大的复杂  处理能力。 作为  的核心产品  受  启发，具备强大的水平扩展，强一致性的多副本数据安全，分布式事务，实时  等特性。依托这些特性， 彻底改变以往数据库弹性扩容与事务处理不可兼具的境况，将在线事务处理和在线分析处理融为一体，完美适配大数据背景下各行业的数据存储、计算需求。
作为  项目中针对解决用户复杂  需求的重要组件， 将   直接运行在  存储层上，同时融合  分布式集群的优势，并融入大数据社区生态。至此， 可以通过一套系统，同时支持  与 ，免除用户数据同步烦恼。
本次  易观  算法大赛以攻坚“有序漏斗”为考题， 的算法引擎在处理时将性能作为首要目标，运用多种存储布局和索引手段，对数据进行快速扫描和有效过滤，大量使用  技术的向量化计算，优化布局，极大减少编解码开销，并根据场景进行智能化存储和  策略。最终以超过原始基准测试近  倍的成绩亮眼胜出，获得了专家评审的一致认可。
大数据环境给企业运营带来了新的挑战和机遇，精准捕捉和分析用户行为，以进一步帮助企业的用户增长及留存，成为互联网时代企业产品运营的核心价值。漏斗转化是帮助企业更快、更好的了解在哪一环节提升运营，实现精细化运营的重要手段。行业内已将实现“漏斗”升级作为当前数据应用领域的重要议题。其中，相较用户路径重合率极低的“无序漏斗”，“有序漏斗”的数据研究更有价值。
此次  作为商业组冠军提交的优异成绩，为业内攻坚“有序漏斗”计算效率的技术瓶颈提供了突破口。在会上， 联合创始人兼  刘奇还进行了解题思路详解。他表示，在数据驱动的今天，通过对数据的分析，快速挖掘潜在的用户需求与市场机遇，这其中，高效是关键。 融合了   与  能力，将数据价值最大化，通过技术创新研发，为市场提供更好的技术解决方案，希望能够降低实时数据分析行业的门槛。
作为世界级分布式  数据库厂商， 的代表作  现已发版至   版。准生产测试用户  余家，其中摩拜单车、同程旅游、 金融、游族网络，盖娅互娱、猿辅导，去哪儿等数十家不同行业的领先企业已经应用在实际生产环境，涉及互联网、游戏、金融、政府、电信、制造业等多个领域，帮助企业解决了海量数据存储、超大规模并发访问及交易问题。同时与腾讯云、 等国内外多家主流的大型公有云厂商深度集成，提供公有云数据库服务。导语
随着版本升级，关系型数据库和缓存数据库整体性能比之前都有大幅度的提升，衡量数据库性能的三个重要指标是：数据库吞吐量、延迟时长和稳定性，以下从这三个方面对几种数据库进行了对比测试。
一、性能测试报告与分析
测试是在服务器上的测试结果，测试对比数据库在和上性能。
、各数据库的峰值吞吐量对比

结果分析：    在典型业务模式下=，和差不多，的峰值能到每秒万左右，为万；    数据写入速度方面，的在每秒万以上，为万， 万。
、不同业务模式的峰值吞吐量

注：横轴为业务模式，表示与比例为比其他类似；纵轴为。
结果分析：    和数据库，峰值随写比例的提高逐渐下降，相反，各种业务模式的峰值见上图。
、典型业务模式，不同并发压力的数据库性能


注：横轴为并发数；左侧曲线图的纵轴为，右侧曲线图的纵轴为延迟时间。
结果分析：
    和在个并发时吞吐量达到峰值，平均延迟随并发度增加基本呈线性趋势；    并发超过后，下降很快，跟客户端驱动的连接池默认配置个连接有关，增加测试客户端或调大连接池，还可以更高。
、和服务器性能对比

结果分析：    典型业务压力下，和在的吞吐量是的倍，变化不大；    对于写入测试，在的写入速度是的倍，和变化不大。
二、测试环境
、硬件环境



设备型号
配置描述
型号





个核，内存， ， ，万兆网卡




个核，内存， ，万兆网卡




、软件环境



测设设备
数据库版本




_ _
 ， ， 


_ _
 ， ， 



、数据库参数配置



数据库
参数





_ = __ = ___ = __ =  __ =  __ = ___ =  __ = __ = __ = __ = ____ = __ = __ = _ = _ = __ = __ = __ = _ =  = _ = __ = ___ = ___ = __ = __ = ___ = ___ = ___ = __ = ___ = ___ = __ = ___ = _____= ___ = ___ = ____ = ____ = ___ = ___ = 







三、测试方法

每个测试的硬件环境和数据量基本一致，数据库都按单实例方式部署。各数据库都包含单张表个字段，万条记录，每条记录长度。

测试工具是   详细介绍见这里，使用的不同压力配置模版，模拟以下业务场景组合，对数据库进行压测。
 读写比例：      ，读写对应为：操作
 并发线程：      

测试前预热数据，避免缓存数据加载引起的性能降低。

测试数据库部署为单实例，测试客户端部署一个实例，发起多个并发线程对数据库进行压力测试。作者丨唐文广：腾讯工程师，负责无线研发部地图测试。 
导语：近两年才流行起来的超轻量级虚拟机，它可以让你轻松完成持续集成、自动交付、自动部署，并且实现开发环境、测试环境、运维环境三方环境的真正同步。本文从定义，作用，技术架构，安装和使用等全方位带你看懂。

是啥？
打开翻译君输入 结果显示码头工人，没错！码头工人搬运的是集装箱，那么今天要讲的其操作的也是集装箱，这个集装箱就静态而言就是一个应用镜像文件，就动态而言，就是一个容器。蒙了吧？好吧，上图解释。
从狭义上来讲就是一个进程，从广义上来讲是一个虚拟容器，其实更专业的叫法是应用容器   ，进程和普通的进程没有任何区别，它就是一个普通的应用进程。不过是用来操作镜像文件的。所以进程构建的应用镜像文件就等于容器。本文所有讲的都是指容器哦。
再继续下文之前我们首先要明确几个重要的基本概念吧，镜像，容器，仓库。
镜像 ，就类似于虚拟机里面的快照，但是可比快照轻量化多了。快照不懂？那可以把直接理解成一个文件夹。我们可以通过或者易识别的名字来确认唯一的目标镜像。是一个位的字符，但是一般我们都是使用前面位就足够区别了。
如图中左边红框中 和右边的红框中都唯一表示为同一个镜像。所以我们一般的镜像可以命名为类似、等等。
镜像是分层的，有基础镜像，仅仅包含操作系统，比如镜像；有中间件镜像，比如等数据库镜像；最后是应用镜像，就是指具体的应用服务了，应用镜像可以非常丰富，随时可以发布，这三者之间依次叠加。
所以当我们在使用 构建镜像的时候，每一个命令都会在前一个命令的基础上形成一个新镜像层。如下图，基础镜像就是镜像，中间件镜像就是两个红色圈，应用镜像就是紫色圈。其中这样叠加组合的中间件镜像就可以供服务或者服务使用，这样叠加组合更加灵活。仍和一种镜像都可以从 公共仓库中拉取。
容器 ，你可以从镜像中创建容器，这如同从快照中创建虚拟机，不过更轻量，启动更快，秒启。应用是在容器中运行的，打个比方，你首先下载了一个的镜像，然后又安装和应用及其依赖，来完成对它镜像的修改，一个个人觉得非常完美应用镜像生成了！就把这个镜像分享给大家使用，大家通过这个镜像就生成一个容器。容器启动之后就会运行服务了。
上面也说到了，容器就是一个个独立的封闭的集装箱，但是也需要对外提供服务的，所以允许公开容器的特定端口，在启动的时候，我们就可以将容器的特定端口映射到宿主机上面的任意一个端口，所以，如果几个服务都需要端口，那么容器的对外端口是，但是映射到宿主机上面就是任意端口，就不会产生冲突，所以就不需要通过代理来解决冲突。容器对外端口与宿主机的端口映射可以通过下面的命令来完成。

启动容器      容器名 镜像名 守护容器，就是后台运行，退出命令窗口容器也不会停止 交互式容器 退出命令窗口容器就停止运行了宿主机端口和容器端口映射  宿主机端口容器公开的端口


仓库 ，仓库和存放集装箱的仓库是一样的，不过使用来存放镜像的。仓库存在公有和私有之分，公有仓库 提供了非常多的镜像文件，这些镜像直接拉取下来就可以运行了，你也可以上传自己的镜像到 上面。同时也可以自己搭建私有仓库用于团队项目管理。
结合前面介绍的基本概念，我们可以将的几个概念使用大致串起来，他们之间是如何运作的，也就是的生命周期。看下图，主要是三步走。
、 开发构建镜像并将镜像到仓库、 测试或者运维从仓库拷贝一份镜像到本地、 通过镜像文件开启容器并提供服务
为啥要用？能干些啥？
为啥要用这要从目前软件行业的痛点来讲起 、软件更新发布及部署低效，过程繁琐且需要人工介入，、环境一致性难以保证，、不同环境之间迁移成本太高。有了可以很大程度解决上面的问题。
首先，的使用简单至极，从开发的角度来看就是三步走：构建，运输，运行。其中关键步骤就是构建环节，即打包镜像文件。但是从测试和运维的角度来看，那就只有两步：复制，运行。有了这个镜像，那么想复制到哪运行都可以，完全和平台无关了。同时这种容器技术隔离出了独立的运行空间，不会和其他应用争用系统资源了以及还不需要考虑应用之间相互影响，想想就开心。
其次，因为在构建镜像的时候就处理完了服务程序对于系统的所有依赖，所以在你使用的时候，你可以忽略掉原本程序的依赖以及开发语言。对测试和运维而言，更多专注于自己的业务内容上。
最后，于开发者而言提供了一种开发环境的管理办法，与测试人员而言保证了环境的同步，于运维人员提供了可移植的标准化部署流程。
所以，  能干啥，总结如下：

构建容易分发简单
隔离应用解除依赖
快速部署测完就销

是个进程级的轻量化虚拟机，和传统虚拟机有啥区别呢？
这个虚拟机超级轻量级，仅仅是一个进程而已。与传统的虚拟机比如有着巨大的差别，区别看下图：
我们来看一下二者的区别，因为  的  需要实现对硬件的虚拟化，并且还要搭载自己的操作系统，其中虚拟机操作系统占用内存是比较大的，一个操作系统有好几个，自然在启动速度和资源利用率以及性能上有非常大的开销，如果在本地，或者个人电脑，那么影响还不是那么大，但是在云端就是一个非常大的资源浪费。
咱们很多时候做事情的时候不会考虑与事情本身无关的问题，比如造飞机的不会考虑飞机是否要潜水，对于我们目前很多移动互联网的应用来说，很少会涉及到对操作系统的部分，其实我们主要关心的是应用的本身，而虚拟机的上层是运行的运行时库和应用，整个虚拟机的空间是非常的庞大，但是容器化技术技术的出现后，省去了操作系统这一层，多个容器之间相互隔离且共用了宿主操作系统和运行时库。
所以 应用容器相对于  有以下几个优点：

启动速度快，容器启动本质就是一个开启一个进程而已，因此都是秒启，而  通常要更久。
资源利用率高，一台普通  可以跑成百上千个容器，你跑十个  试试。
性能开销小，  通常需要额外的  和内存来完成  的功能，这一部分占据了额外的资源。

所以很多移动互联网的应用或者云计算的后端节点都可以用来替换物理机器或者虚拟机。比如腾讯地图的很多后台服务基本上都迁移部署了。
是个啥架构？底层又是用的啥技术？
前面说了那么多，始终还是雾里看花。下面就详细介绍一下技术架构，底层又是用的啥技术来实现上述那么多优点的？
技术架构图：
从依赖的底层技术来看，原生态是不能直接在平台上运行的，只支持系统，原因是依赖 三项最基本的技术充当隔离的第一级，是对容器进行隔离，让容器拥有独立的，同时确保一个容器中运行一个进程而且不能看到或影响容器外的其它进程是容器对使用的宿主机资源进行核算并限制的关键功能。
比如内存磁盘等， 主要是对镜像也就是这一块作支持，采用技术，让大家可以共用某一层，对于某些差异层的话就可以在差异的内存存储，是一个库，是对上面这三项技术做一个封装。
  用来控制容器的运行，以及镜像文件的拉取。
咋装呢？怎么用呢？
安装之前，我们首先确保自己的系统内核版本高于，并且系统是位，才能体验哦。
通过 查看是否满足要求。
安装
通过脚本的方式安装，非常简单。
、 获取最新的安装包
    | 输入当前用户的密码后，就会下载脚本并且安装及依赖包。显示上图内容就表明安装完成。
、 启动 后台服务
         启动守护进程   能够看见版本号，说明的安装成功。简单吧！至此就差一个镜像了。自己制作还是从公共仓库拉取就随你啦。         关闭守护进程
使用
的使用，我们主要从【增删查】几方面来说说怎么使用为什么没有【改】呢，因为在我看来容器一旦出现问题了，根本没有修复的必要，直接把容器停止并删除，再启动，这样来得快。所以我们只需要掌握几个基本命令即可，具体如下。【查】查看本地已有的镜像     【增】运行一个镜像，即启动一个容器    镜像名 ，比如我们运行  键入这个命令的时候完成了三样操作、 检查本地是否有这个镜像有就跳过第二步   没有依次执行、 就自动去 下载这个镜像、 就把镜像加载到容器并且运行再用 查看的时候本地就增加了镜像。为就表示是最新版本的系统镜像。因为会从 拉取没有的镜像，所以算【增】里面。
【增】拉取指定的镜像文件   镜像名
上面那种通过直接运行的方式拉取的是 中最新的镜像，但是有时候我想拉取指定的镜像文件就需要使用 命令来拉取。因为从官方拉取镜像文件，通常是比较慢的，所以我们可以通过加速器技术来从国内的镜像仓库拉取。【查】查看所有的容器   可以用来查看所有的容器，包括运行中的和已经停止的。第一个字段就是已经启动的容器，第二个字段就是这个容器是根据哪个镜像生成的。但是上面这个命令只是临时启动一下容器，上面图中的 是表示容器是退出状态。如果想容器在后台运行，所以我们需要启动守护式容器才可以，只要在启动命令中添加一个 参数，即   就可以了。
【查】查看镜像容器的具体信息   镜像镜像名容器容器名    
这个命令是返回一个镜像或者容器详细信息的串。其中包括，，版本，容器的主程序等非常多的信息，根据这些信息我们可以进行二次开发。在这个命令的基础之上增加一个参数我们可以指定获取自己需要的信息，比如获取容器的地址，内存信息，使用情况。   {{}}  【查】进入容器      即启动一个交互式容器 完成容器终端和当前终端进行关联，即当前终端的显示就会切换到容器终端的显示。
查看容器目录结构，发现和物理机器的目录结构完全一致，这就是为什么有的人称容器也称之为虚拟机的原因啦。可以退出容器终端。
【删】删除容器，  容器，删除多个容器就可以多个容器之间用空格隔开即可。
怎么用完成持续集成、自动交付、自动部署？
这年头见面不聊点自动化什么的，持续什么的，都不好意思。所以，咱们也要了解一下持续集成，自动交付，自动部署。但是上面说了这么多，没发现有那三样功能啊，是的，是没有这个功能，但是你在完成上述三样自动化的步骤都是依赖的。是这些流程实现的基础，就如同软件开发，软件代码才是根本，开发工具是辅助。所有搭建一个完整的自动化流程还需要 三样帮助。
持续集成和自动部署的原理如下图所示：

推送代码到 仓库或者等代码服务器上面，服务器就会通过通知。
 克隆代码到本地，并通过文件进行编译 。
打包生成一个新版本的镜像并推送到仓库 ，删除当前容器 ，通过新版本镜像重新运行。

而在整个过程中 只需要敲入三个命令     – “” 即可完成持续集成、自动交付、自动部署。后面通过案例实际演示这个过程的神奇！
还可以很方便的自动扩容哦，一般的自动扩容的两种方式，一种就是容量扩大，另一种就是节点数扩充。第一种就修改配置文件即可，第二种通过简单的拷贝，运行就完成了节点的扩容。
总结
虽好，可不要贪杯哦！虽然具有超轻量化，但是不建议一台机器上面部署太多的应用，同时部署的时候一定要差异化部署，什么意思呢，就是将大量计算的，和内存需要大的，操作频繁的对系统资源需求不一致的部署到同一台宿主机上。
欢迎关注【腾讯织云】，获取最新技术资讯接上篇：十问  虚拟内存管理   一  
五  的内存真的释放了吗还给   
前面所有例子都有一个很严重的问题，就是分配的内存都没有释放，即导致内存泄露。原则上所有  分配的内存，都需  来释放。但是，  了的内存真的释放了吗？
要说清楚这个问题，可通过下面例子来说明。

初始状态：如图  所示，系统已分配  四块内存，其中  在堆内分配，  使用  分配。为简单起见，图中忽略了如共享库等文件映射区域的地址空间。

= ：分配  内存，小于  ，从堆内分配，堆内剩余空间不足，扩展堆顶  指针。

 ：释放  的内存，在  中，仅仅是标记为可用，形成一个内存空洞  碎片  ，并没有真正释放。如果此时需要分配  以内的空间，可重用此空间，剩余空间形成新的小碎片。




 ：  空间大于  ，使用  分配，如果释放  ，会调用  系统调用来释放，并会真正释放该空间，还给  ，如图  所示。

 ：与释放  类似，释放  同样会导致一个空洞，获得空闲空间，但并不会还给  。此时，空闲总空间为  ，但由于虚拟地址不连续，无法合并，空闲空间无法满足大于  的分配请求。

 ：释放  ，由于与  连续，两者将进行合并，得到  连续空闲空间。同时  是最靠近堆顶的空间，  的  实现中，只要堆顶附近释放总空间包括合并的空间超过  ，即会调用  来回溯堆顶指针，将原堆顶空间还给  ，如图  所示。而堆内的空闲空间还是不会归还  的。



由此可见：

 使用  分配的内存  大于  ，  会调用  系统调用马上还给  ，实现真正释放。

堆内的内存，只有释放堆顶的空间，同时堆顶总连续空闲空间大于  才使用  回收内存，真正归还  。

堆内的空闲空间，是不会归还给  的。
六 程序代码中  的内存都有相应的  ，就不会出现内存泄露了吗？


狭义上的内存泄露是指  的内存，没有  ，导致内存浪费，直到程序结束。而广义上的内存泄露就是进程使用内存量不断增加，或大大超出系统原设计的上限。
上一节说到，  了的内存并不会马上归还  ，并且堆内的空洞碎片更是很难真正释放，除非空洞成为了新的堆顶。所以，如上一例子情况  ，释放了  和  两片内存，但如果此时需要申请大于  如  ，没有可用碎片，必须向  申请，实际使用内存仍然增大。
因此，随着系统频繁地  和  ，尤其对于小块内存，堆内将产生越来越多不可用的碎片，导致“内存泄露”。而这种“泄露”现象使用  是无法检测出来的。
下图是  存在大量分区表时的内存使用情况  和  ，疑似“内存泄露”。

因此，当我们写程序时，不能完全依赖  的  和  的实现。更好方式是建立属于进程的内存池，即一次分配  大块内存，小内存从内存池中获得，当进程结束或该块内存不可用时，一次释放  ，可大大减少碎片的产生。
七 既然堆内内存不能直接释放，为什么不全部使用  来分配？
由于堆内碎片不能直接释放，而问题  中说到  分配的内存可以会通过  进行  ，实现真正释放。既然堆内碎片不能直接释放，导致疑似“内存泄露”问题，为什么  不全部使用  来实现呢？而仅仅对于大于  的大块内存才使用  ？
其实，进程向  申请和释放地址空间的接口  都是系统调用，频繁调用系统调用都比较消耗系统资源的。并且，  申请的内存被  后，重新申请会产生更多的缺页中断。例如使用  分配  空间，第一次调用产生了大量缺页中断  次  ，当  后再次分配  空间，会再次产生大量缺页中断。缺页中断是内核行为，会导致内核态  消耗较大。另外，如果使用  分配小内存，会导致地址空间的分片更多，内核的管理负担更大。
而堆是一个连续空间，并且堆内碎片由于没有归还  ，如果可重用碎片，再次访问该内存很可能不需产生任何系统调用和缺页中断，这将大大降低  的消耗。
因此，  的  实现中，充分考虑了  和  行为上的差异及优缺点，默认分配大块内存  才使用  获得地址空间，也可通过 __ 来修改这个临界值。
八 如何查看进程的缺页中断信息？
可通过以下命令查看缺页中断信息
    _
    
其中，  代表   ，指大错误，  代表   ，指小错误。这两个数值表示一个进程自启动以来所发生的缺页中断的次数。其中  与  的不同是，  表示需要读写磁盘，可能是内存对应页面在磁盘中需要  到物理内存中，也可能是此时物理内存不足，需要淘汰部分物理页面至磁盘中。
例如，下面是  的一个例子。
 __     
 
 
如果进程的内核态  使用过多，其中一个原因就可能是单位时间的缺页中断次数多个，可通过以上命令来查看。
如果  过大，很可能是内存不足。
如果  过大，很可能是频繁分配  释放大块内存  ，  使用  来分配。对于这种情况，可通过 __ 增大临界值，或程序实现内存池。
九 如何查看堆内内存的碎片情况？
 提供了以下结构和接口来查看堆内内存和  的使用情况。
  {
             
          
           
            
           
          
            
        
        
        _  
}


 返回 _ 的内存使用情况，以  结构返回 
  
 将  和  的使用情况输出到   
 _
可通过以下例子来验证  和 _ 输出结果。
 
 
 
 
 
 
_  __ __
                _ _
 _
{
           = 
          \
        \__= __= __=\\
\_= _=\
                __ __ __  __
                _ _
          \
        \__= __= __=\\
\_= _=\
                  
                 
       _\
        _
}

 _ 
    
{
         __
         
          =    _  {
                _ =   
                    
                        __ = 
                 {
                        _ = 
                        _
                }

        }
        _
          =    _  {
                     == 
                        
                _
                    
                        __ = 
                 {
                        _ = 
                        _
                }
        }
        \ \
        _
         
}
该例子第一个循环为指针数组每个成员分配索引位置  大小的内存块，并通过  为分界分别对  和  内存分配情况进行计数；第二个循环是  索引下标为奇数的项，同时更新计数情况。通过程序的计数与 _ 接口得到结果进行对比，并通过 _ 打印到终端。
下面是一个执行结果：
  
        __= __= __=
        _= _=
  
        __= __= __=
        _= _=
 _
 
      =    
       =    
  
      =   
       =   
   =         
     =   

 

  
        __= __= __=
        _= _=
  
        __= __= __=
        _= _=
 _
 
      =    
       =    
  
      =   
       =   
   =         
     =   
由上可知，程序统计和  得到的信息基本吻合，其中 __ 表示堆内已释放的内存碎片总和。
如果想知道堆内片究竟有多碎 ，可通过  结构中的  、  、  值得到，这些值表示不同大小区间的碎片总个数，这些区间分别是  字节，  字节，  。如果  、  的值过大，那碎片问题可能比较严重了。
不过，  结构有一个很致命的问题，就是其成员定义全部都是  ，在  位环境中，其结构中的  很容易就会导致溢出，应该是历史遗留问题，使用时要注意！
十 除了  的  ，还有其他第三方实现吗？
其实，很多人开始诟病  内存管理的实现，就是在高并发性能低下和内存碎片化问题都比较严重，因此，陆续出现一些第三方工具来替换  的实现，最著名的当属  的  和  的  
网上有很多资源，可搜索之，这里就不详述了。
总结
基于以上认识，最后发现  的疑似“内存泄露”问题一方面是   分区表使用更多的内存，另一方面跟内存碎片有关，这也是  一个优化方向。
然而，以上主要介绍了  虚拟内存管理主要内容，事实上，在并发情况下，  的虚存管理会更加复杂，碎片情况也可能更严重，这将在另一篇再做介绍。
参考文章
《深入理解计算机系统》第  章___

相关推荐上一篇 十问  虚拟内存管理  一  性能监控—— 常用操作及命令作者：李雄政，年 证券、电信、互联网领域开发、系统集成、运维经验。 现任腾讯高级工程师，负责社交平台业务运维组管理工作。
导语：鹿晗关晓彤公布恋情，造成微博服务短暂不可用。相关的运维们也不得不提前结束国庆假期，执行各种紧急扩容预案。 而腾讯社交平台运维团队历经数次亿级热点活动，如“春节红包” “ 军装照图”，他们又是如何应对每次的服务保障呢？

前言
又是一年国庆，月日点，鹿晗在微博公布与关晓彤恋情，截至当日 该微博共收获次转发、条评论，个点赞。造成微博服务短暂不可用。作为运维同行，对此深表同情和理解。那么，面对这种突如其来的花式秀恩爱热点，作为运维的我们，该如何提前预防呢？腾讯的业务运维团队通常会从业务准备，容量评估，资源准备，扩容与压测四个阶段着手，配合热点应急机制，提前一个月进行节日保障准备。当然，还有对于海量业务的稳固运营至关重要的成熟的运维体系。这一切互相配合，最大化地保障节假日的运维工作有条不紊。
节假日保障
由于社交平台部产品众多，包含空间、微云、相册、图等，业务运维团队一般会提前一个月进行节日准备，一般会包含以下几个阶段：
 业务准备
指标搜集由业务运维团队牵头对产品进行梳理，由产品团队提供产品技术指标，如某功能上涨多少的业务量。这些业务产品团队的输入作为扩容需求的原始输入。
柔性准备柔性是以应对大量业务量冲击时，以降低业务体验为代价而实施的一系列运维策略，如在业务高峰期降低客户端拉取后端数据的频率，从而减少对后端的冲击。
 容量评估
业务运维与相关开发进行业务指标 与业务模块对应关系适配，进一步评估设备量，通常评估模块设备量有以下几种办法：
反向评估： 结合业务上涨量倍数与当前单负载，计算出扩容的设备数量公式为扩容设备量 = 业务上涨倍数当前单机负载设备数量 目标负载 – 当前设备量。例如： 当前模块有台设备，单机负载，目标负载， 业务量需要上涨倍，需要扩容的设备量为：     =  台。
正向评估：需要有明确的高峰期交易量和单机承载指标。公式为扩容设备量 =  高峰期交易量  单机负载 – 当前设备量。例如： 业务高峰期交易量为 万秒，单机最承载千秒，当前模块 台设备，需要扩容的设备量为：      = 台。  
随着经验不断完善，自动容量评估工具也在不断建设与完善中。
 资源准备
评估的设备量提交资源团队进行准备。一般设备量不大的情况下会利用存量资源满足，反之则需要提前进行采购备货。
织云设备供给平台依托强力的织云接口对业务设备进行分配，上层业务只需选择对应地域、机房、机型，即可提供，实体机，机型。分配过程对业务透明。
 扩容与压测
如前文所述，模块非常规范的情况下，织云能对其进行半自动全自动扩缩容。扩容后进行压测，进一步确认是否能达到业务上涨的需求。
业务压测通常业务多地化部署，每地各有一条读访问链，我们可以通过前端调度，将业务调度到单地，以评估单地的支撑能力。
单机压测通过名字服务，将流量逐步调度到某一台机器，测量单机的业务支撑能力。从而推导模块设备能否支撑业务量。
扩容完成后，如果仍然存在短板，则重新补齐后进行压测。对于不可预见的突发热点，又该如何来保障业务呢？下面给大家介绍下突发热点容量管控机制。
热点应急机制
节假日难免会有一些突发的事件产生，如前所述，基于织云标准，我们的模块非常容易伸缩，可借助织云托管功能进行服务托管，模块出现容量紧缺时，提前进行自动扩容干预。如果由于资源等问题，自动扩容无法解决问题，可由运维启动柔性机制，保障业务可用。
节假日的运维准备工作，以上并不是全部，这背后还需要成熟的运维体系来支撑。
运维体系构成
一个成熟的运维体系通常包括三个部分：人员组织、工具体系和技术规范。三者随着业务的扩张而日益成熟。从组织上保障人员技能专业度与服务质量成熟度，良好的规范约束为组织协同、工具自动化提供了基础；工具解放生产力，提升运维效率，使人员成长更为专业。
技术运营团队组织架构
组织架构在随着业务形态在不断地演变，一般来说，互联网公司的组织架构演变会经历过几个转变期：
小团队混合期一般在组织相对较小的时候，开发人员即运维人员。此阶段一般出现在人以下的团队，但由于开发要兼做运维工作， 随着人员、业务的增长，容易造成组织混乱、团队效率、故障风险不可控等问题。
分离初期此阶段运维开始从开发中分离出来，负责所有运维工作，如设备资源、环境、运维工具体系建设等。团队趋于扁平，但人员分工相对不明确。既管理机房、资源，又要管理运维工具、解决现网业务问题。随着业务的复杂性进一步增大，伴随人员流动性等问题，团队难以应对技术多样化场景，容易因为技术框架不统一而导致运维效率低下、组织运作混乱。从而对团队分工演进提出了更深的要求。
运维团队模块化、职业化运维团队到了一定的规模后，运维设备数量达到数以万计或十万计，整体架构会分散自治，运维团队的分工因此需要更加细致明确。
团队分工没有标准或准则，典型的分工可能是这样的：

资源职能团队   负责设备资源采购、机房管理或云上资源管理、 操作系统层及以下的管理，跨部门运作以保障资源的调度及供应能力。

组件运维团队 – 负责各自的组件运维， 一般根据人员技能要求、组件响应要求，可以划分成有状态组件团队和无状态组件团队。


因为无状态组件是水平可伸缩的，短暂单机故障并不会引起服务不可用，所以对业务服务要求较低。该团队负责整个无状态服务框架及基于其承载的服务的运维工作。而由于有状态服务保存了业务数据，一般会对业务服务要求较高，在单机故障时甚至需要运维及时介入检查或操作。
当然随着大型业务架构演进，自动化的增强，存储层实现故障自愈，我们的业务也实现多地部署，整体业务或模块粒度可进行多地切换容灾。内存型业务的服务也可以相对放松，在这里先不细述。

业务运维团队 – 负责业务的整体运维，包括业务规划、架构部署、容灾演练、节假日保障等整体协作性工作。

比如业务的多地容灾部署架构，需要业务运维团队来牵头实施，以项目实施管理的形式将整个项目进行推进，以达到最终保障业务高可用的目的。
如上图所示，以上团队职责相对比较明确，运维工具的开发与健全贯穿在整个运维工作中，并逐步形成工具体系。
运维规范
庞大的业务体系运作，运维团队不可能随着业务的急剧增长而扩张，从而需要有一系列的规范来保证业务运维的有序运作。
传统行业的运维规范相对较为严格，包含以下内容：

运维操作 – 严格约定操作的步骤、甚至细化到命令操作等。
流程 – 一般指变更、故障处理的审批、确认流程，比较常见的规范有等。
协议 – 流程中点之间的时长或整体时长限制。因故障变更等级不同而可能有所差异。
其他运维规范

而在互联网行业，过于僵硬的规范不易于满足快速迭代的业务需求，所以平时更需要关注现网运行规范，如织云体系中的几个常见规范：
 设备模块化、化管理理念依据微服务的差异，将设备划分到不同的模块，多个模块可组成一个。这是织云管理设备的理念。
化后，一方面可以将模块间访问尽量限制在单地，防止跨城流量穿越而带来额外的流量开销，另一方面可以实现跨地域容灾，保障业务高可用。
 统一的包管理规范统一的包安装、卸载、启停脚本名称，统一的配置文件管理版本管理、创建、发放等机制，以便上层管理系统能够统一对其进行管理。
 名字服务接入业务间调用时，所有被调方对业务透明，只需要知道名字服务，而对被调方扩缩容时只需要通过名字服务管理系统管理名字服务后端的即可。杜绝写死在代码中或写死在配置文件中的现象。
 程序开发规范这里的开发规范不是指代码规范，而是指通过一定时间的积累，形成的程序逻辑规范，以典型的无状态组件为例，我们从程序逻辑中剥离出来一套框架，框架上实现微线程处理、网络通信、监控等功能，而开发人员只需要根据业务逻辑开发  进行挂接即可。 
运维工具体系架构
从而需要有一整套机制来规范，运维工具体系对规范进行支撑，总的来说，运维工具体系可以分为以下几个方面：支撑平台、监控、管理体系，我们统称为织云体系。
 支撑平台：
所有自动化工作开展的基石，运维体系中不可缺少的部分，包含但不限于以下组件：配置管理平台，管理设备信息与模块属性、人员与被管设备模块间运维关系，基本配置信息等。自动化命令通道等，提供底层在大批服务器上执行命令。基础设施监控平台，如：基础设施运营事件发布、机房设施、服务器性能、故障监控系统等。
 监控系统
主动监控：一般采用从组件框架或业务代码埋点，或采用部署探针形式，上报业务数据到监控系统，监控系统进行集中监控。如：业务模块间调用监控、终端监控、手机命令字监控等。被动监控：比较典型的是拨测系统，从内外网模拟客户端访问业务，对业务进行速度或成功率等测试，测试数据集中上报表监控系统，集中进行处理和监控。旁路监控：在不接触业务本身的情况下对业务进行监控，比较典型的是舆情监控，对外网的舆情进行搜集，进行统一监控。
一切监控的基础是数据，但细粒度数据显然不可能直接让运维人员使用，基于以上数据产生的织云监控体系产品如： 多维监控、日志监控、全链路监控系统，都是一些非常重要的监控产品。
 标准化管理体系
支撑运维标准能严格执行的是一个成熟的管理体系，这个体系包括以下组成部分。
 标准化：模块管理： 功能粒度上对服务器打散，形成许多独立的模块，每一个模块有自己的自治体系。包管理，配置管理：规范开发人员按照标准来进行开发业务包。统一的包安装、卸载、启停、方法。集中式配置文件管理方法等。标准化组件管控  名字服务、容错体系、存储层内存型、、硬盘等基础服务的管控工具。
 容量管理：一系列的容量评估体系，支撑运维人员快速评估容量。为资源规划提供支撑，合理保障活动资源。高低负载管理，扩缩容、单机负载权重调整、调度等。
 其他支撑工具：为业务场景设计的工具 如：运营事件管理、机房裁撤、智能调度、等工具。
后记
海量业务稳定运营的背后，一定有一套成熟的运维体系，需要从组织、规范、工具上进行不断演进、持续积累，才能在节假 日准备时有条不紊，做到有备而战，从而做到“高效运维”。 
欢迎关注【腾讯织云】公众号，获取最新技术资讯。在本文的运维体系下，腾讯社交平台运维团队又是运用了何种技术来保障节假日服务的？ 点击下文阅读。↓↓↓
亿人晒军装，背后的运维技术大揭密！作者：

导语
正如  所说微信将会发展为数字社会的基础设置，做一个很好的产品，做一个很酷的产品，这个理念对于微信团队来说，已经不足够。
 在这里，微信的技术团队也希望更多的将我们的技术精神与积累分享出去。 是一种尝试， 是另外一种尝试。 在一个月内获得  的  是一个不错的开端，在未来微信终端将开源更多优秀的项目，例如  月底的跨平台组件 。  
不仅仅微信终端，微信后台也开源了大量优秀的项目，、 以及文中的 。事实上，腾讯的开源也在大力发展中，当前也有超过  个项目正在审核的流程中。在不久的将来，我们可以在  发现更多优秀的项目。
 是微信后台大规模使用的  协程库， 年至今稳定运行在微信后台的数万台机器上。 在  年的时候作为腾讯六大开源项目首次开源，我们最近做了一次较大的更新，同步更新在  上。 支持后台敏捷的同步风格编程模式，同时提供系统的高并发能力。
 支持的特性

无需侵入业务逻辑，把多进程、多线程服务改造成协程服务，并发能力得到百倍提升；
支持  框架，轻松构建  服务；
支持 、、 等常用第三库；
可选的共享栈模式，单机轻松接入千万连接；
完善简洁的协程编程接口：
类 _ 接口设计，通过 _、_ 等简单清晰接口即可完成协程的创建与恢复；
类 _ 的协程私有变量、协程间通信的协程信号量 _ ；
非语言级别的  实现，结合协程原地编写并执行后台异步任务 ；
基于  实现的小而轻的网络框架，基于时间轮盘实现的高性能定时器



 产生的背景
早期微信后台因为业务需求复杂多变、产品要求快速迭代等需求，大部分模块都采用了半同步半异步模型。接入层为异步模型，业务逻辑层则是同步的多进程或多线程模型，业务逻辑的并发能力只有几十到几百。随着微信业务的增长，系统规模变得越来越庞大，每个模块很容易受到后端服务网络抖动的影响。
异步化改造的选择
为了提升微信后台的并发能力，一般的做法是把现网的所有服务改成异步模型。这种做法工程量巨大，从框架到业务逻辑代码均需要做一次彻底的改造，耗时耗力而且风险巨大。于是我们开始考虑使用协程。
但使用协程会面临以下挑战：

、 业界协程在  环境下没有大规模应用的经验 、 如何控制协程调度 、 如何处理同步风格的  调用，如 、 等 、 如何处理已有全局变量、线程私有变量的使用

最终我们通过  解决了上述的所有问题，实现了对业务逻辑非侵入的异步化改造。我们使用  对微信后台上百个模块进行了协程异步化改造，改造过程中业务逻辑代码基本无修改。至今，微信后台绝大部分服务都已是多进程或多线程协程模型，并发能力相比之前有了质的提升，而  也成为了微信后台框架的基石。
 框架
 在框架分为三层，分别是接口层、系统函数  层以及事件驱动层。

同步风格  的处理
对于同步风格的 ，主要是同步的网络调用， 的首要任务是消除这些等待对资源的占用，提高系统的并发性能。一个常规的网络后台服务，我们可能会经历 、、 等步骤，完成一次完整的网络交互。当同步的调用这些  的时候，整个线程会因为等待网络交互而挂起。
虽然同步编程风格的并发性能并不好，但是它具有代码逻辑清晰、易于编写的优点，并可支持业务快速迭代敏捷开发。为了继续保持同步编程的优点，并且不需修改线上已有的业务逻辑代码， 创新地接管了网络调用接口，把协程的让出与恢复作为异步网络  中的一次事件注册与回调。当业务处理遇到同步网络请求的时候， 层会把本次网络请求注册为异步事件，本协程让出  占用， 交给其它协程执行。 会在网络事件发生或者超时的时候，自动的恢复协程执行。
大部分同步风格的  我们都通过  的方法来接管了， 会在恰当的时机调度协程恢复执行。
千万级协程支持
 默认是每一个协程独享一个运行栈，在协程创建的时候，从堆内存分配一个固定大小的内存作为该协程的运行栈。如果我们用一个协程处理前端的一个接入连接，那对于一个海量接入服务来说，我们的服务的并发上限就很容易受限于内存。为此， 也提供了  的协程共享栈模式，可以设置若干个协程共享同一个运行栈。同一个共享栈下的协程间切换的时候，需要把当前的运行栈内容拷贝到协程的私有内存中。为了减少这种内存拷贝次数，共享栈的内存拷贝只发生在不同协程间的切换。当共享栈的占用者一直没有改变的时候，则不需要拷贝运行栈。

 协程的共享协程栈模式使得单机很容易接入千万连接，只需创建足够多的协程即可。我们通过  共享栈模式创建  千万的协程       内存，每  万个协程共享的使用  内存，整个稳定  服务的时候总内存消耗大概为  可达到  ；
协程私有变量
多进程程序改造为多线程程序时候，我们可以用_ 来对全局变量进行快速修改，而在协程环境下，我们创造了协程变量 ，极大简化了协程的改造工作量。
因为协程实质上是线程内串行执行的，所以当我们定义了一个线程私有变量的时候，可能会有重入的问题。比如我们定义了一个_ 的线程私有变量，原本是希望每一个执行逻辑独享这个变量的。但当我们的执行环境迁移到协程了之后，同一个线程私有变量，可能会有多个协程会操作它，这就导致了变量重入的问题。为此，我们在做  异步化改造的时候，把大部分的线程私有变量改成了协程级私有变量。协程私有变量具有这样的特性：当代码运行在多线程非协程环境下时，该变量是线程私有的；当代码运行在协程环境的时候，此变量是协程私有的。底层的协程私有变量会自动完成运行环境的判断并正确返回所需的值。
协程私有变量对于现有环境同步到异步化改造起了举足轻重的作用，同时我们定义了一个非常简单方便的方法定义协程私有变量，简单到只需一行声明代码即可。
 的  方法
对于现网服务，有可能需要通过系统的   接口去查询  获取真实地址。我们在协程化改造的时候，发现我们  的  族函数对  不适用，当一个协程调用了  时会同步等待结果，这就导致了同线程内的其它协程被延时执行。我们对  的  源码进行了研究，发现  不生效主要是由于  内部是定义了_ 方法来等待事件，而不是通用的  方法；同时  还定义了一个线程私有变量，不同协程的切换可能会重入导致数据不准确。最终  协程异步化是通过  _ 方法以及定义协程私有变量解决的。
 是  提供的同步查询  接口，业界还有很多优秀的  的异步化解决方案，但是这些实现都需要引入一个第三方库并且要求底层提供异步回调通知机制。 通过  方法，在不修改  源码的前提下实现了的  的异步化。
协程信号量
在多线程环境下，我们会有线程间同步的需求，比如一个线程的执行需要等待另一个线程的信号，对于这种需求，我们通常是使用   来解决的。在  中，我们定义了协程信号量  用于处理协程间的并发需求，一个协程可以通过  与  来决定通知一个等待的协程或者唤醒所有等待协程。
总结
 是一个高效的  协程库，提供了完善的协程编程接口、常用的  族函数  等，使得业务可用同步编程模型快速迭代开发。随着几年来的稳定运行， 作为微信后台框架的基石发挥了举足轻重的作用。

本文来源于： 微信公众号作者：

街景  官网中有在视网膜屏幕中实现  的需求。首先，来看下面视觉给的输出图中的 ：

从上面的视觉图可以看到， 是一根非常细的线。这篇文章将说明如何使用  实现在视网膜屏中 的  效果。

注：因为硬件条件的限制，设备像素比为的非视网膜屏手机无法达到这样的效果

首先准备一张符合你要求的 ：

通常手机端的页面设计稿都是放大一倍的，如：为适应  ，设计稿会设计成×的分辨率，图片按照倍大小切出来，在手机端看着就不会虚化，非常清晰。同样，在使用时，将设计为物理，如下：
样式设置：
 {
        
          
          
}

上文是把设置在边框的底部，所以使用的图片是高，上部的颜色为透明，下部的使用视觉规定的的颜色。如果边框底部和顶部同时需要，可以使用下面的：

样式设置：
 {
      
        
        
}

到目前为止，我们已经能在上展现 的效果了。但是我们发现这样的方法在非视网膜屏上会出现显示不出来的现象，于是使用 做了一些兼容，样式设置如下：
 {
       
} 

      {
     {
         
            
              
              
    }
}


参考文档：

下面介绍一下其他方法：

设置
直接按照设计师提供的宽的设计稿来重构，然后通过控制的值为进行缩放，这种方案在下可以完美运行淘宝就是这么做的，但是由于下不支持，所以这个方案不适用于。


 = ===


跟的方法一样，你要先准备一张符合你要求的图片：


此例是准备将设置在底部样式设置：
 {
        
      
      
}




 {
          
}

使用都会让线有阴影，甚至颜色变浅。但是使用与使用类似，代码量少，使用方便，而且可以设置圆角矩形，在精细度要求不高的情况下可以尝试使用这种方案。

渐变背景与方案类似，只是将图片替换为渐变。

样式设置：
{
                
     
}

该方案不能满足圆角矩形。

缩放边框由一个元素来承载，将这个元素的高度或宽度设置为，然后再将该元素缩放倍。样式设置：

{
    
}
{
   
    
   
   
   
     
   
    
}


听说和已经支持的单位了，代码可以像下面这样写：

{
     
}

  {
 {
    
 }
}

不过这个单位有点过于颠覆前端开发的认识了上有位哥们已经被震惊的不知所云

基于和使用的线下解决方案：中使用声明混合，可以传递参数，参数名以符号开始，多个参数以逗号分开，也可以给参数设置默认值。声明的通过来调用。

基于：


_ 
        {
  {} {
    {}   
  }

       {
    {} {
      {} 
        ==  {
            
              
              
      }    ==  {
            
              
              
      }    ==  {
            
              
              
      }    ==  {
            
              
              
      }  
    }
  }
}


 

 {
      
}

  
 

执行文件：

     

生成代码：
  {
     
}
      {
    {
     
        
          
          
  }
}

 {
     
}

      {
   {
     
        
          
          
  }
}
 {
     
}

      {
   {
     
        
          
          
  }
}


基于的缩放：

_ 
 _       {
       {
      ==  {
      {}{} {
         
         
          ==  {
            
        }    ==  {
            
        }
      }
    }    ==  {
      {}{} {
         
         
          ==  {
            
        }    ==  {
            
        }
      }
    }    ==  {
      {}{} {
         
         
          ==  {
            
        }    ==  {
            
        }
      }
    }
  }
}

       {
    {}{} {
        
       
         
       
       
       
    }
    {} {
         
        {} {
           {} == {
             
          }   {} ==  {
             
          }
        }
    }
     _   
     _   
     _   

}


 

 {
   
}

    

执行文件

     

生成代码：
  {
    
   
     
   
   
   
}
  {
   
}
  {
   
}
      {
    {
     
     
      
  }
}
      {
    {
     
     
      
  }
}
      {
    {
     
     
      
  }
}

 {
    
   
     
   
   
   
}

 {
   
}
 {
   
}

      {
   {
     
     
      
  }
}
      {
   {
     
     
      
  }
}
      {
   {
     
     
      
  }
}

好处：可以使用习惯的写的实现方案，并且支持传参，更加灵活。

参考：=谢谢导师的指导。


原文链接：


相关推荐图片流量节省大杀器：基于的自适应图片技术实践利用神经网络编辑图片的调研这是来自我们服务保障中心一名高级工程师的工作思考，他列出了一份中小企业的上云清单，在此分享给大家。
以下是分享全文：
这两年中国公有云市场爆发，腾讯云在这个大潮中也不断接入各种类型的客户；有幸跟进一些中小企业，关于帮助客户从自有租赁完成云化，如何帮助企业用户高效的向公有云迁移，怎样才能帮企业客户真正用好腾讯云，用户关注的焦点在哪里，这里和大家分享一些思路。
谈到企业云化，上云的好处就不赘述了，虚拟化资源快速伸缩，高效的网络覆盖能力，大容量的安全防攻击，分钟的响应服务，这些能力都是企业在传统租赁所不能达到的。企业云的不同演变可以列一个示意图：

不论是私有云还是公有云，企业用户最后都可以云化，也可以采用混合云的模式；但混合云模式对平台提出了更高的要求，包括自定义子网自定义安全策略公网等，这些要点目前在腾讯云已实现，有的通过等方式来逐步满足企业客户的需求。
站在企业用户的角度，在进行云化的过程中，会有较多的思考点，我把它浓缩成六个部分，包括：基础和设施、安全、价格、性能、通用能力、存储。

企业云化的前期，对这六个部分逐点进行评估，以找到适合的云服务提供商。
如果企业用户开始计划在公有云进行部署，前期会接触我们的大客户经理或相应的技术支持来启动，在云化的过程中，会分为四个阶段来实现云化：

从客户的角度看，可以看一下云是否满足需求，我列一个 的范例供参考：

毫不夸张的说，四个阶段对云服务商的专业度都提出较高的要求，云服务商需要了解行业客户的特点，明析用户对计算资源的需求和调度来做优化。一、环境准备
、挂载分区
：通用方法，此处略过，以下为示例挂载配置，方便直接复制粘贴。
                                     _   
                                     _   
                                     _   
                                     _   
                                     _   
                                     _   
                                     _   
                                     _   
                                     _   
                                    _   
                                    _   
、根据分区数批量创建目录
  {}
   {}
、安装
    
  _ 
  
 _=
 =\_\

 
、其他
   
   
   
   
   


   
__=

二、安装
、解压安装包

    
   
   
、修改配置
 编辑配置文件，添加如下选项：

   
  
 
 
 
_ 
__ 
   
  
 
 

 ： 项目名称
 ： 节点名称，约定为{最后一段}
：机架，按照机架填写
 ：文件分布目录，默认个盘，形式约定为 
： 因为不支持，而默认__为进行检测，所以导致检测失败，失败后直接导致不能启动；
：集群节点
： 对外服务地址，用于数据写入和读取
：限制内存使用

修改启动文件

  
 在之后 添加
__= 
、启动

    
三、安装
、解压安装包

  _  
  _
   _
  _ 
、修改配置

  
   
 
 
 以下为可选配置
 
 
、启动

        
四、自拉起
、自拉起脚本


 

{
      
}
_
{
    =
    =
    =
    =`  |    |    |  `
          
    
        
           
    
            
         
           
    
}

_      
_         
、添加

        
五、反代
、创建认证文件

      
、配置反向代理

 {
  
 _ 
   {
            _  
            ___ 
            _ 

    }
 以下略
、访问


六、附录
、附录一：部署问题记录
问题①、虚拟内存区域报错

              
   
     __         
                      
临时修复：   __=永久修改：修改 文件，添加 “__”设置并执行： 
问题②、系统不支持而报错
              
   
                      
原因：这是在因为不支持，而默认__为进行检测，所以导致检测失败，失败后直接导致不能启动我们系统是 也有这个问题。
解决：在中配置__为，注意要在下面_ __ 
可以查看
：更多问题会持续补充。
、附录二： 详细配置

的文件夹里面有两个配置文 件：和，第一个是的基本配置文件，第二个是日志配置文件，也是使用来记录日 志的，所以里的设置按普通配置文件来设置就行了。下面主要讲解下这个文件中可配置的 东西。

 
配置的集群名称，默认是，会自动发现在同一网段下的，如果在同一网段下有多个集群，就可以用这个属性来区分不同的集群。

  
节点名，默认随机指定一个列表中名字，该列表在的包中文件夹里文件中，其中有很多作者添加的有趣名字。

 
指定该节点是否有资格被选举成为，默认是，是默认集群中的第一台机器为，如果这台机挂了就会重新选举。

 
指定该节点是否存储索引数据，默认为。

__ 
设置默认索引分片个数，默认为片。

__ 
设置默认索引副本个数，默认为个副本。

 
设置配置文件的存储路径，默认是根目录下的文件夹。

 
设置索引数据的存储路径，默认是根目录下的文件夹，可以设置多个存储路径，用逗号隔开，例：
 

 
设置临时文件的存储路径，默认是根目录下的文件夹。

 
设置日志文件的存储路径，默认是根目录下的文件夹

 
设置插件的存放路径，默认是根目录下的文件夹

 
设置为来锁住内存。因为当开始时的效率 会降低，所以要保证它不，可以把__和__两个环境变量设置成同一个值，并且保证机器有足够的内存分配给。 同时也要允许的进程可以锁住内存，下可以通过`  `命令。

_ 
设置绑定的地址，可以是或的，默认为。

_ 
设置其它节点和该节点交互的地址，如果不设置它会自动判断，值必须是个真实的地址。

 
这个参数是用来同时设置_和_上面两个参数。

 
设置节点间交互的端口，默认是。

 
设置是否压缩传输时的数据，默认为，不压缩。

 
设置对外服务的端口，默认为。

__ 
设置内容的最大容量，默认

 
是否使用协议对外提供服务，默认为，开启。

 
的类型，默认为即为本地文件系统，可以设置为本地文件系统，分布式文件系统，的，和的服务器，其它文件系统的设置方法下次再详细说。

__ 
设置集群中个节点启动时进行数据恢复，默认为。

__ 
设置初始化数据恢复进程的超时时间，默认是分钟。

_ 
设置这个集群中节点的数量，默认为，一旦这个节点启动，就会立即进行数据恢复。

___ 
初始化数据恢复时，并发恢复线程的个数，默认为。

__ 
添加删除节点或负载均衡时并发恢复线程的个数，默认为。

___ 
设置数据恢复时限制的带宽，如入，默认为，即无限制。

_ 
设置这个参数来限制从其它分片恢复数据时最大同时打开并发流的个数，默认为。

__ 
设置这个参数来保证集群中的节点可以知道其它个有资格的节点。默认为，对于大的集群来说，可以设置大一点的值

 
设置集群中自动发现其它节点时连接超时时间，默认为秒，对于比较差的网络环境可以高点的值来防止自动发现时出错。

 
设置是否打开多播发现节点，默认是。

   
设置集群中节点的初始列表，可以通过这些节点来自动发现新加入集群的节点。

下面是一些查询时的慢日志参数设置
 
 
 
 
 

 
 

 作者： 刘博
背景知识
 作为一个分布式数据库，在多个节点分别配置安装服务会相当繁琐，为了简化操作以及方便管理，使用自动化工具来批量部署成为了一个很好的选择。
 是基于  研发的自动化运维工具，糅合了众多老牌运维工具的优点实现了批量操作系统配置、批量程序的部署、批量运行命令等功能，而且使用简单，仅需在管理工作站上安装  程序配置被管控主机的  信息，被管控的主机无客户端。基于以上原因，我们选用自动化工具  来批量的安装配置以及部署 。
下面我们来介绍如何使用  来部署 。
 安装环境配置如下
操作系统使用  或者更高版本，文件系统使用 。

说明：低版本的操作系统例如   和  文件系统会有一些内核 ，会影响性能，我们不推荐使用。











    _



  _



  _



 _



 _



 _



我们选择使用  个 、 个 、 个 ，这里简单说一下为什么这样部署。

对于  。 本身是一个分布式系统，由多个节点构成一个整体，并且同时有且只有一个主节点对外提供服务。各个节点之间通过选举算法来确定主节点，选举算法要求节点个数是奇数个  ， 个节点的风险比较高，所以我们选择使用  个节点。
对于  。 底层使用分布式存储，我们推荐使用奇数  个备份，挂掉  个备份之后数据仍然可用。使用  备份或者  备份的话，有一个节点挂掉就会造成一部分数据不可用，所以我们选择使用  个节点、设置  个备份 默认值。
对于  。我们的  是无状态的，现有集群的  服务压力大的话，可以在其他节点直接增加  服务，无需多余的配置。我们选择使用两个 ，可以做  和负载均衡。
当然如果只是测试集群的话，完全可以使用一个  、一个  、三个  少于三个的话需要修改备份数量

下载  安装包并解压
创建目录用来存放  安装包
                  

切换目录
                     

下载安装包
      

解压压缩包到当前目录下
                       

查看安装包结构，主要内容说明如下
   
部分内容含义
  配置文件
 组和主机的相关配置
  相关配置模版
_ 相关变量配置
  监控  模版
_ 用来下载相关安装包
 初始化集群各个节点
 在各个节点安装  相应服务
   的集合
 启动所有服务
 停止所有服务
__ 清除数据
_ 销毁集群
修改配置文件
主要配置集群节点的分布情况，以及安装路径。
会在 _ 组中的机器上安装  服务其他类似，默认会将所有服务安装到变量 _ 路径下。
将要安装  服务的节点
_



将要安装  服务的节点
_




将要安装  服务的节点
_




将要安装  服务的节点
  
_


将要安装  服务的节点
_


将要安装 _ 服务的节点
_
_
_
_


服务安装路径，每个节点均相同，根据实际情况配置
_ = 

 
方式一：使用  用户安装
   
 _ = 
 _ = 
 __ = 

方式二：使用普通用户安装需要有  权限
    
_ = 

集群的名称，自定义即可
_ = 

 
_ = 
_ = 
_ = 

  
是否开启 ， 生成  的  
如果有从此  集群同步数据的需求，可以改为  开启
_ = 
安装过程可以分为  用户安装和普通用户安装两种方式。有  用户当然是最好的，修改系统参数、创建目录等不会涉及到权限不够的问题，能够直接安装完成。但是有些环境不会直接给  权限，这种场景就需要通过普通用户来安装。为了配置简便，我们建议所有节点都使用相同的普通用户；为了满足权限要求，我们还需要给这个普通用户  权限。下面介绍两种安装方式的详细过程，安装完成之后需要手动启动服务。
 使用  用户安装

下载  包到  目录下，并解压拷贝到  下，之后的安装过程就是使用的  下的二进制程序

   _

初始化集群各个节点。会检查  配置文件、 版本、网络状态、操作系统版本等，并修改一些内核参数，创建相应的目录。

修改配置文件如下
 
   
_ = 
 _ = 
__ = 

    
 _ = 

执行初始化命令
        命令说明请见附录



安装服务。该步骤会在服务器上安装相应的服务，并自动设置好配置文件和所需脚本。

修改配置文件如下
 
   
_ = 
_ = 
__ = 

    
 _ = 

执行安装命令
    




 使用普通用户安装

下载  包到中控机

   _

初始化集群各个节点。

修改配置文件如下
 
   
 _ = 
 _ = 
 __ = 

    
_ = 

执行初始化命令
     



安装服务


     
启停服务

启动所有服务

    

停止所有服务

   
附录

     
   执行之后需要输入  连接用户的密码，如果做了中控机到所有节点的互信，则不需要此参数
   执行之后需要输入  所需的密码，如果使用  用户或者  无需密码，则不需要此参数

 源码地址： 源码地址：随着微软 将在 召开，预期将发布    邀请深圳地区技术专家和从业人员，一起分享与交流 技术的发展方向提高技术氛围，发掘高级人才，为改善生态贡献一份力，使技术在深圳地区被广泛采用。
活动海报 日在活动行网站编辑完成，然后通过微信群和微信朋友圈简单宣传，截至 通过公众号宣传已经报名超过位，原定名额人 ，在通过公众号发出海报信息不到小时就被抢光了，赶快和提供场地的朋友联系，非常荣幸的为活动的争取到个名额，通过活动行网站调整参加活动的人数到，经过小时又被抢光了，还不时接到电话询问是否可以参加，很多我只能抱歉因为场地原因无法提供报名，我也很期望谁能够提供更大的场地来举办活动，欢迎赞助。从这次活动的报名情况来说，大家对这次活动很期待，对  非常的期待，这次活动得到了深圳珠宝创客空间、微软项目组，还有一些朋友的帮助，虽然筹备时间很短，目前进展顺利。作者 | 陈龙编辑 | 京露

陈龙，腾讯即通产品部开发工程师，负责 的开发与维护。热衷于机器学习的研究与分享。

对于人类来说，识别手写的数字是一件非常容易的事情。我们甚至不用思考，就可以看出下面的数字分别是。

但是想让机器识别这些数字，则要困难得多。
如果让你用传统的编程语言如写一个程序去识别这些形态各异的数字，你会怎么写？写很多方法去检测横、竖、圆这些基本形状，然后计算它们的相对位置？我想你很快就会陷入绝望之中。即使你花很多时间写出来了程序，精确度也一定不高。当你在传统编程方法的小黑屋里挣扎时，机器学习这种更高阶的方法却为我们打开了一扇窗。
为了找到识别手写数字的方法，机器学习界的大师 利用      美国国家标准技术研究所的手写数字库构建了一个便于机器学习研究的子集。由张手写数字图片灰度图组成，由很多不同的人写成，其中张是训练集，另外张是测试集，每张图片的大小是  像素，数字的大小是  ，位于图片的中心。更详细的信息可以参考 的网站：
已经有很多研究人员利用该数据集进行了手写数字识别的研究，也提出了很多方法，比如、、神经网络等，精度已经达到了人类的水平。
抛开这些研究成果，我们从头开始，想想怎样用机器学习的方法来识别这些手写数字。因为数字只包含，对于任意一张图片，我们需要确定它是中的哪个数字，所以这是一个分类问题。对于原始图片，我们可以将它看作一个  的矩阵，或者更简单地将它看作一个长度为的一维数组。将图片看作一维数组将不能理解图片里的二维结构，我们暂且先这么做，看能够达到什么样的精度。这样一分析，我们很自然地就想到可以用回归来解决这个问题。关于 可以参考下面的文章：

我们的模型如下：

对于一张图片，我们需要算出它分别属于的概率，哪个概率最大，我们即认为这张图片上是那个数字。我们给每个像素个权重，对应于，这样我们的权重矩阵的大小就是  。将上图的模型用公式表示，即为：

写成向量的形式：

函数将个非负的值归一化为之间的值，形成一个概率分布。

模型有了，我们的代价函数是什么呢？怎样评估模型输出的结果和真实值之间的差距呢？我们可以将数字表示成一个维的向量，数字是几则将第几个元素置为，其它都为，如下图所示：

比如可表示为：         。这样我们就可以用交叉熵来衡量模型输出结果和真实值之间的差距了，我们将其定义为：

其中，是模型输出的概率分布，一撇是真实值，也可以看作概率分布，只不过只有一个值为，其它都为。将训练集里每个样本与真实值的差距累加起来，就得到了成本函数。这个函数可以通过梯度下降法求解其最小值。
关于交叉熵可以参考下面这篇文章：

模型和成本函数都有了，接下来我们用来实现它，代码如下：
 ____  _
 ____  
 ____  _

   
   _

  
 = ____ _=

   
 =   
 =  
 = 
 =    
_ =   

    

     

   ___  
                                 _=

    

     ____   
         

_ = _
      ____=_ =
_ = _

 = 

__

 
 _  
    _ _ = _
    _ _={ _ _ _}

   
_ =   _ 
 = __ 
 _={ 
                                    _ }
下面我来解释一些比较重要的代码：
  = ____ _=
这行代码用来下载如果没有下载和读取的训练集、测试集和验证集验证集暂时可以先不用管。的安装包里就有了_这个，所以我们直接进来就好了。将数据读到内存后，我们就可以直接通过和来获得测试集的图片和对应的标签了。提供的方法从训练集里取了个样本作为验证集，所以训练集、测试集、验证集的大小分别为：、、。
_是你存放下载的数据集的文件夹名。
 =  
 = 
这里简单的将参数都初始化为。在复杂的模型中，初始化参数有很多的技巧。
 =    
这一行是我们建立的模型，很简单的一个模型。表示矩阵相乘。
_ = _____=_ =
这一行等价于：
_ = ___   _=
_  做的事情就是计算每个样本的，因为这样算数值不稳定，所以换成了____这个方法。
_ = _
这一行就是用提供的梯度下降法在成本函数最小化的过程中调整参数，学习率设置为。
 _  
    _ _ = _
    _ _={ _ _ _}
这行代码是进行训练，因为训练集有个样本，太大了，所以采用了  随机梯度下降，这样做大大降低了计算量，同时又能有效的训练参数，使其收敛。_方法就是从训练集里随机取个样本来训练。迭代的次数为。
_ =   _ 
 = __ 
 _={  _ }
这行是在模型参数训练完之后，在测试集上检测其准确度。
运行我们的代码，其结果如下：

可以看到，这样一个简单的模型就可以达到的准确度。

相关推荐前端识别验证码思路分析【腾讯云的种玩法】  整合万向优图图片管理能力，打造高效图片处理服务爬虫如今是一个非常热门的技术领域，不仅因为它是获取大数据的一种有效方式，还在于它入门还是比较简单、快速，小白学完比较容易有成就感，而且可以「学以致用」。
本系列文章中，笔者将带领大家从零开始学习爬虫编写。在跟随笔者一起实操之前，要求大家有一定的  基础。之前没接触过的同学也不用担心， 号称是世界上最容易学的语言，如果之前没有了解，可以先看看  这本入门书。这是  社区爱好者共同翻译的一本开源教材，对于零基础的同学来说很有价值。

第一天的任务
本系列教程一共八篇，将持续在腾讯云技术社区更新。前七篇介绍从机器配置到爬虫运行的全过程，最后一篇分享动态页面爬取、反爬虫等进阶建议。
第一天的任务，也就是本文的主题，即 完成爬虫项目的机器配置。
机器及操作系统
在学习爬虫的过程中，可能会碰到由于机器原因导致的软件安装错误，尤其是  系统。因此，本教程建议大家使用统一的机器机型和操作系统。
确保这个要求的绝佳方式，就是使用腾讯云等云计算平台提供的云服务器。这些都是标准化的机器，每台机器的初始配置都相同，而且可以选择使用一模一样的操作系统，如我们计划使用的  。
另外，由于直接使用云服务器，在爬虫开发完成之后，就可以直接投入实际使用，做到  小时持续运行。
因此，笔者建议大家使用腾讯云提供的云服务器。如果你是新注册用户的话，还可以申请免费天使用。如果已经是注册用户，建议选择核内存的实验机器，尽量降低实验成本。这也是本系列教程所使用的机器。
购买服务器之后，建议先按下文进行初始安全配置：
如何正确配置   服务器？
基础软件
 登录实验服务器之后，我们需要安装以下软件依赖，才能继续后面的任务：

 




安装过程也非常直接明了：
     
然后再使用  命令安装 ：
  
在  系统下，这些操作完成的都特别快，而且基本不会出错。 系统下的过程会稍微复杂一些。
后续计划
完成上面的配置之后，爬虫项目需要的实验机器就准备好了。明天，我们将介绍具体实验环境准备工作，主要包括安装 数据库和  爬虫库等。
本系列教程的完整内容预计包括：

：机器配置
：环境配置
：创建  项目
：编写爬虫代码
：接入 
：编写数据处理管道
：运行爬虫的几种方式
：延伸阅读，如何避免反爬等什么是 
架构，或者称为无服务器架构，是最近几年新冒出来的一种架构风格。这究竟是一种什么样的架构？无服务器，就是真的没有服务器了么？其实，对于来说，只是用户不用更多的去考虑服务器的相关内容了，无需再去考虑服务器的规格大小、存储类型、网络带宽、自动扩缩容问题了；同时，也无需再对服务器进行运维了，无需不断的打系统补丁、应用补丁、无需进行数据备份、软件配置等工作了。但是没有服务器，如何来将程序、应用运行起来呢？这里要介绍的是下包含的两个概念：函数即服务，    ，后端即服务，    。
函数即服务 
函数即服务 ，作为一种新的计算能力提供方式，让用户抛弃了对服务器的配置和管理，仅需编写和上传核心业务代码，交由平台完成部署、调度、流量分发、弹性伸缩等能力。的出现，会从底层开始变革计算资源的形态，提供了一种新的方式来提供计算资源，同时也会给软件架构与应用服务部署带来新的设计思路，进一步降低云计算的使用门槛，推动全行业在服务架构上的创新步伐。
后端即服务 
后端即服务 ，其实大家已经使用很久了，这里的后端，指的就是各种云产品和云服务，例如对象存储，消息队列，云数据库、，云缓存、，甚至到各种以  形式提供的服务如万象优图 ，视频处理 。这些产品或服务，用户直接开通即可使用，无需考虑部署、扩容、备份、优化、安全等各种运维工作，做到了开箱即用，无需自己去进行服务器或应用的维护和管理，因此同样也是的一部分。
为什么要 
介绍了什么是，但是为什么会出现 ，或者为什么要使用  呢？我们这里可以从三个方面来看看，这三个方面可以类比为：天时，地利，人和。
天时，这里突出的时，即时间。传统的服务器模式，应用上线前，还得完成服务器准备，环境部署，数据库准备，存储准备等各种工作；上线后，还得面临计算扩容，存储扩容，数据库维护和扩容等各种运维工作。这这个过程中，应用上线和迭代的时间、节奏，受限于各种准备和维护工作。而利用，通过使用产品，专注于完成业务相关的核心代码，通过直接使用，，，等产品，解决数据存储，数据库，消息队列，缓存等问题，不再费心运维，而专注在业务开发和迭代上，能更快的完成应用上线，在这个互联网加速发展的时代，做到一步领先，步步领先。
地利，这里突出的利，即费用支出。传统的服务器模式，无论有没有用户正在访问，应用始终要保持运行，而在有用户访问时，又要关注服务器的资源使用率，在使用率达到一定程度时就要考虑扩容，避免突发访问量导致的资源不足。在这个过程中的费用，始终是有一部分为未使用的计算资源而支付。而  架构，能确保所有的费用，都是用在了实际的程序运行、数据存储、用户访问中。 云函数的计费方式，就是通过函数的调用次数和执行时间来统计费用，有用户访问或事件产生，才会有函数执行，才会有费用计算；相反，没有函数执行时，则没有费用支出。同理，其他的相关云产品，也是类似，例如  仅收取存储、外网流量的费用， 仅收取请求次数、外网流量费用， 仅按实际使用内存大小收费。据测算，根据不同用户的应用压力情况， 能为用户带来  的费用节省程度。
人和，这里突出的是人。传统的服务器模式，运维人员要投入大量的精力去维护服务器、数据库、存储等各种基础设施，解决各种集群、分布式系统的搭建问题，而实际运维解决自身应用问题的时间，可能只会占到很小一部分，而开发人员除了对自身业务应用的开发外，也需要投入时间，解决可能存在的各种外围系统的问题。而  架构，无需运维人员再投入到基础设施中去了，而开发人员也可以全面关注业务系统的开发。 产品，可以让开发人员直接编写业务逻辑核心代码，利用微服务架构，快速上线应用。，，， 各种云产品，无需搭建配置，开通即可使用，而将基础运维工作交由云来完成。在这种情况下，脱离了基础运维的运维人员，可以提升自身视野，从更高角度来看待运维工作，实现业务运维；而开发人员，可以充分利用 、能力，提升整个应用或业务的集成能力。
怎么用 
、、、 这类  型云产品，由于面世的时间已经很长，对其使用的方式，基本和原有使用 、等产品相同，或者通过产品提供的 、直接访问使用。而  云函数，作为  产品，有着稍有不同的使用方式。

事件触发： 的工作模式为事件触发，因此要考虑好触发方式。例如，利用  来处理图片生成缩略图，就可以利用  事件，在图片文件上传  后，上传事件就能自动触发函数执行，来生成新的缩略图并再次存入  中。

无状态服务：函数需要是无状态的，缓存、日志、数据库等全部通过、、这类云产品来支持，这样才能保证在业务请求突增时服务能迅速扩展。

微服务：事件驱动和无状态属性正是微服务架构所需要的。因此，在一开始就将自身的应用设计为微服务架构，解耦各模块间关联，使得应用成为可生长可进化的系统。


无服务器云函数  实现独立开发、简化测试和加速部署，能够助力公司在关键时期快速上线和迭代，为初创期的产品提供了很好的解决方案。近期有同事需要做跨机器将一个数据文件导入到的需求，所以将以前做的笔记及随带脚本分享一下。
跨机器  
若本机有一个文件 ，需要导入到远端的  的 _ 里，可以用如下命令：
      = 
              _

解析
\= 参数 打开远端服务器的  开关，允许   操作。
 中：  语法不同于 ，前者从客户端机器读取文件，后者从服务器读取文件。官方参考：


问题解决
如果服务器端 启动时指定了 \=，则   中的  不会生效，即使在  命令中指定 \=，也无用。
这个限制为了避免一些安全问题：
附：通用脚本
通用的一个脚本，改改其中的这些参数：    即可使用， 的文本数据必须是  编码的，若是其他编码，修改脚本中  中的   部分。

_



=     = = 

 
{
     `   `  
}

    

     
           _
     


=`  `
=
=
_=

={_}    {}   {}    {}

 {}

 {}  {}

      {}   {} 
     

      {}   {} 
     


调用样例
_ _ _    
         _
          
          
         
      =    = 


如果不需要自动创建数据表，最后这个参数可以不要。如果不指定列名，倒数第二个参数也可以不要。
即下面两种写法都可以：
  _ _ _   
  _ _ _上周，我们在社区发起了名为「程序员，怎么应对你的三十岁？」的话题讨论，得到了近  位用户的热烈参与，有同学甚至专门撰文一篇抒发了自己的感慨。
主持人王拥军几乎对每位参与话题讨论的用户评论，都进行了回复。下面，我们摘取一些比较精彩的评论及主持人回复，与大家分享。话题讨论结果将在近期公布，敬请关注。
腾讯云用户的评论：

已到，当初入行除了真心喜欢之外，更大的原因是不擅长与人沟通，不然早去做了销售。除了编码也喜欢画图，曾考虑过编码不成可以做个室内设计，当初一股冲劲跑去创业公司，各种加班、各种中小项目，遇到不错的项目，然后开始被走杀驴卸磨的套路；心累了，跑去大公司，一开始各种不适应，不适应各种慢，不适应做事风格，不适应人和事。然而回头想下，房子没有、车没有，连女朋友还没有，而立，中年吗？很多人岁才开始赚得来钱，不知道有多少人想没想过，到了放下所有，重新再来，去创业、去拼，然而生活告诉我们，没多少时间了。苍天饶过谁？

主持人回复：

少年，我看你根骨奇特，实乃练武奇才。一个人想要变得睿智、坚定，单靠智商和情商是远远不够的，更需要现实的经验和磨砺。尝遍所有的酸甜苦辣，才最终觉悟：什么才是自己想要的。一碗浓浓的鸡汤送给你：乔吉拉德岁才开始卖汽车，然后卖到全世界最牛；王德顺岁才开始真正的事业起步。有些人，岁已经老了；有些人，岁也不会老。苍天对每个人都不同，但，我们自己有选择是否老去的权力。

腾讯云用户的评论：

做了年开发年项目经理，一点感悟：技术层出不穷，总有一天你会跟不上。而且新的技术出来后，老的技术就面临被淘汰的结局。对于技术人员来说，如果不想一直吃老本，要么随时能掌握新技术，要么要对项目管理、运营、业务、产品、解决方案有了解和实践，准备转型。发挥团队的力量，永远大于你一个人的力量。学习怎样和人打交道，比和技术打交道有难度的多，成就也会更高。如果有可能，建立自己的管道，摆脱靠自身劳动力赚钱，才能更好的实现自我价值。

更多精彩评论及回复，请移步：程序员，怎么应对你的三十岁？。
再次重申，以上内容不代表活动最终结果，第一时间获取活动结果，请关注腾讯云技术社区。周末花费时间在云服务器  系统上搭建了一个  服务器。搭建过程中还是遇到了一些小问题，在这里记录下来。
一、安装服务器所需软件
在终端输入以下命令：
      
是版本控制的核心软件。
安装和是由于  需要通过 协议在服务器与客户端之间传输文件。
中间有个确认操作。如果安装提示失败，可能因为系统软件库索引文件太旧。更新一下，命令如下：
   
更新后重新执行安装命令即可。
安装的和 ，由于安装需要依赖的一些工具，下面安装的命令如下：
    
接下来准备安装安装之前需要初始化一下服务器用户信息。随便填
     
     
下面安装主要用于给用户授权。通过一些命令获取版本文件：
   
注意：中间有两个是数字零。
获取文件后，进入下面目录：
下面使用命令安装目录下的的脚本进行安装：
安装完成，下面开始对进行一些基本配置。
二、创建管理员账户、配置
创建一个账户作为服务器的管理员，可以管理其他用户权限。
     
    
然后再目录下创建一个项目仓库存储点，并设置只有用户拥有所有权限，其他用户没有权限。
    
     
     
由于默认状态下将仓库放在用户的目录下，添加一个链接，指向连接仓库的项目
     
这里我使用在客户机中生成的公钥：使用
       

上面是已存在的提示，因为我已经初始化过了
实际应该是：
     
     
对文件添加可执行权限。
    
三、服务器上创建项目仓库与权限配置
使用账户在服务器上创建一个目录：
  
  
  
  
   
 
对进行配置，以便克隆项目：
先在客户端机器上克隆下打开 
   
  
    
     
        
      |   
    
  
只有第一条是命令哈，下面是执行结果
克隆下来有一个用于配置权限。 
用于存放公钥文件，一般以“用户名命名”。中使用相同的用户名。
注意：在中生成的文件最后会有一个用户名。使用该名称比较好
将文件复制到目录下 。修改文件
 

 为用户名 与文件对应 多个用户以空格隔开
 可写项目组 ，以空格隔开
 只读项目组，以空格隔开
提交修改到服务器：
  
    
   
新增用户不能生效：重启服务
    
配置完成可以进行克隆：

提示文件夹为空，但是已经克隆下来了 ：

有问题欢迎补充    

相关推荐
【腾讯云的种玩法】微信个人订阅号后台搭建入门教程【腾讯云的种玩法】  单机环境搭建与初步学习前言
人类又输了
创新工场组织的一场“人工智能和顶尖牌手巅峰表演赛中”，机器人  冷扑大师赢了人类代表队龙之队  记分牌，最后  万奖励归机器人所有。
在围棋项目上人类的一票大师已经被  虐得得不行。然而这还不算完，最近有在朋友圈里看到不少 “  首次在德州扑克战胜人类职业玩家，新算法让机器拥有直觉 ” 这类新闻。
所以简单给大家介绍下本次获胜的    ，以下解读来源于胡开亮同学的知乎回答。
 的  原理，也是发过  论文的内容

首先跟大家简单介绍下纳什均衡的概念——纳什均衡是指一个策略组，任何玩家都无法通过单方面的改变策略来增加收益。纳什均衡策略组中的每个玩家的策略都是对策略组中其他策略的最佳反应。纳什均衡策略组很重要，因其在两人零和博弈中有额外的属性。在两人零和博弈中若某玩家从纳什均衡策略组中选中一个策略，其他玩家改变策略不会获得更大的收益。 而在大部分   中都是希望求解出来的策略组跟真正的纳什均衡足够的近记为  。 所以这样策略组的   是足够小的，在假定对手有足够能力的来利用我的缺点     的情况下，我的策略也是可行的。
介绍完纳什均衡后，我们可能在想怎么求解德州扑克中的纳什均衡，接着介绍用来求解均衡的       中文名字叫：虚拟遗憾最小化算法。  来源于    算法，然而   算法只能适用于正则博弈中，对于德州扑克这类扩展式博弈中无法直接使用    通过定义   在每一个   上进行   来减少每一个   上的    ，而    的和是小于  而   跟      之间是有关系的，从而可以使用  来求解出纳什均衡解。但是  的空间复杂度为 对于二人限制性的通过一些  后就可以直接求解，对于二人非限制性游戏空间大概为 根本无法直接求解，故先用   然后再 ，大致的流程如下：

然而到了年的时候    的师兄， 的   首次将  残局的思想引入到了二人非限制性中来了上图的框架变成了如下图所示。

在  中  会根据玩家的在前几轮的 ，然后根据  所反映出来的手牌信息，对  进行实时求解。实时计算需要具备强大的计算能力，这也是为什么  在实际比赛中需要  的原因。
上面就是  的          和    的简单介绍，在实践中会用到很多   就拿  的改进来说如何       以及  等等。在    过程中如何选择特征进行聚类等等。
   ，会让触手可及
其实除了 ，   领域还有  大学的 当的来临变得不可避免的时候，开发者们需要思考如何让自己更快的拥抱  时代。对于开发者而言，在深度学习领域常用的一些算法其实未来都可以通过腾讯云等公有云厂商的  方式进行调用。
例如把游戏或者  服务器上的日志实时地同步到  对象存储中，采用  调度云端强大的  和  计算能力对用户行为或其他游戏日志进行数据清洗等预处理；接下来采用  等特征工程技术进行特征处理后的特征信息即可进入模型训练环节，训练完毕的模型将会被保存于  对象存储中，以便于进行游戏流失率的预估。
游戏运营专家可以在游戏动态运营系统上，根据游戏流失率的预估结果选择策略以进行低活跃用户召回、用户流失原因分析、推广活动效果评估等动态运营。
小结：
人工智能处理人机对弈的信息模式可大致分为完美信息、不完美信息两类，大致对应两类博弈：围棋  扑克。在这两个领域，人类都已经输给了人工智能，对于未来的开发者而言，拥抱而非排斥  更为现实，而云计算会把  的能力变得像水和电一样，更加触手可及。

相关推荐：深度学习平台人人都可以做深度学习应用：入门篇上前言
皮卡丘又回来啦，由于上一周有些事情要处理，就没有写文章，真的很对不起大家。
不过这次笔者给大家带来了一个非常好玩的东西
看标题——机器学习实战——训练你的皮卡丘

那现在我们就开始让我们的皮卡丘变得越来越聪明吧！
所有密码均为
正文
在这里我们运用到的是一个名为神经演化的算法。该算法的原理简单说就是通过不断地学习迭代，总结失败和成功，最终使机器变得越来越聪明。

这里是它相关的介绍
首先，我们先写一个的小游戏代码网上一大堆
这是笔者的游戏代码
开始学习
首先设置一些参数
              神经网络的结构
                  第一代数量
                    后代的优秀率
            下一代的随机行为率
               突变率
              突变范围
                     最后一代
              历史最低？
                   如何排序
                       育种数
创建各种对象神经元、神经网络层、神经网络等等然后输入第一代，通过训练得到下一代
创建第一代
     =   {
          = 
          =     {
              =  
            
                        
                                          
            
        }

         
         
    }
    
创建下一代
     = {
         == {
             
        }

          =   
                
         
         
    }
    
添加基因信息到代中
     = {
          =     {
              {
                  {
                    
                }
            }{
                  {
                    
                }
            }

        }
          
    }
    
这是第一代皮卡丘，还没出门就撞水管了

然后通过一代又一代的迭代，我们得到的皮卡丘越来越聪明
开始训练时有许多皮卡丘，最后有只最聪明的，下面是训练了代得到的皮卡丘，基本保持不死了

这是一个示例，读者可以来体验一下，下面的按钮是改变运行速度
这是上面示例的代码
好了，到这里我们就得到了一只越来越聪明的皮卡丘啦。导语
关于慢日志的信息，源码分析，良心制作。
    
      
 _  _  _  _  
 = 
  
  
  =   =  
   
什么是慢日志？
的慢查询日志是提供的一种日志记录，它用来记录在中响应时间超过阀值的语句，具体指运行时间超过__值的，则会被记录到慢查询日志中。__的默认值为，意思是运行以上的语句。默认情况下，数据库并不启动慢查询日志，需要我们手动来设置这个参数，当然，如果不是调优需要的话，一般不建议启动该参数，因为开启慢查询日志会或多或少带来一定的性能影响。慢查询日志支持将日志记录写入文件，也支持将日志记录写入数据库表。
参考文档：

官方说明

官方说明


什么情况下产生慢日志？

看图说话，有很多开关影响着慢日志的生成，相关的参数后面会挨个说明。从上图可以看出慢日志输出的内容有两个，第一执行时间过长大于设置的__阈值；第二未使用索引，或者未使用最优的索引。这两种日志默认情况下都没有打开，特别是未使用索引的日志，因为这一类的日志可能会有很多，所以还有个特别的开关_____用于限制每分钟输出未使用索引的日志数量。
关键代码如下：
    代码路径 _  
     __ 
    {
       __
      {
         __= _ 
                              ____ |
                               _____ 
                             _____ 
                             ___ 
                               __
         __=  _  ___ ||
                               __ 
                              ___ =
                               ___
         _= __ __
         _  __
          _
      }
      _
    }
 调用栈  ：
_       | | ___
_       | | ___ 
_       | | __
_       | | | __
_       | | | __ 
_       | | | __
_        | | | | _
_      | | | | _
_      | | | | _ 
             | | | | __
_       | | | | | ____
_       | | | | | |   
  _         | | | | | | _
  _         | | | | | | |      
  _        | | | | | | _ 
_       | | | | | ____ 
             | | | | __ 
_       | | | __ 
_       | | __ 
慢日志相关参数

以上应该是最完整的和慢日志相关的所有参数，大多数参数都有前置条件，所以在使用的时候可以参照上面的流程图。官方文档：


慢日志输出内容

第一行：标记日志产生的时间，准确说是执行完成的时间点，改行记录每一秒只打印一条；
第二行：客户端的账户信息，两个用户名第一个是授权账户，第二个为登录账户，客户端地址，还有的线程；
第三行：查询执行的信息，包括查询时长，锁持有时长，返回客户端的行数，扫描行数。通常我需要优化的就是最后一个内容，尽量减少语句扫描的数据行数。
第四行：通过代码看，貌似和第一行的时间没有区别。
第五话：最后就是产生慢查询的语句；
=：
如果启动时指定了参数，则不会输出第一、第二行。
=   

_____   
如果启用了以上两个参数，每分钟超过_____配置的未使用索引的慢日志将会被抑制，被抑制的信息会被汇总，每分钟输出一次。格式如下：

   
           
 _   _  _   _ 
 =
              
慢日志分析工具

官方自带工具：  

开源工具：  

：工具包中的工具可以分析汇总慢查询信息，具体逻辑可以看这个函数；


总的来的日志内容本身不复杂，上面个工具都是用脚本实现，代码行数不超过行，有兴趣的同学也可以自己尝试着解析下。详情可以参阅下这篇文章：
《 慢查询设置和分析工具 》
以上的工具可以支撑慢日志的常用统计，但是当我们需要做到级别的统计时，我们还需要取解析把参数提取出来。
慢日志的清理与备份
删除：直接删除慢日志文件，执行 必须的
备份：先用重命名文件不要跨分区，然后执行 必须的；
另外修改系统变量___也可以立即生效；
执行 ，系统会先当前的句柄，然后重新；  日志文件系统并不会报错，具体的原因可以下  _   _ ；由于腾讯云上提供了系统，所以我们这次编程选用腾讯云主机实验。
我的腾讯云主机预装了 ，截图如下：

系统版本是  位。
编程目标
首先说一下本次编程的目标任务：
、基本任务达标任务
完成两台主机之间的数据通信数据链路层

仿真协议获得网段内主机的表
使用帧完成两台主机的通信 ’ …

、高端任务优秀任务
完成两台主机通过中间主机的数据通信网络层

增加基于地址的转发功能
增加网络层封装

编程概述
一句话，我们需要利用这个库用语言编程来实现以上的任务。
讲解
那么是什么？
大多数网络应用程序通过被广泛使用的操作系统原件来访问网络，如。由于操作系统已经处理了底层的细节问题如协议的处理、数据包的封装等，并提供了与读写文件类似的函数接口，因此使用该方法可以很容易的访问网络中的数据。
然而有些时候，这种简单的方式并不能满足任务要求，有些应用程序需要直接访问网络中的数据包，也就是说，需要访问哪些没有被操作系统处理过的数据包。
就是为平台的应用程序提供这种访问方式，提供下列功能：
捕获原始数据包。无论是发送到运行的机器上的数据包，还是在其它主机存在网络共享介质上的主机上进行交换的数据包，都可以被捕获。
在数据包传递给应用程序之前，根据用户指定的规则过滤数据包。
将原始数据包发送到网络上收集网络流量与网络状态的统计信息，它提供给我们什么呢？
它包含一个内核空间数据包过滤器   ，一个底层动态链接库和一个高层独立于操作系统的动态链接库。
各部分关系见下图：

：为了能够访问网络上传输的原始数据，数据包捕获系统需要绕过操作系统的协议栈。这就需要有一部分程序运行在操作系统的内核中，只有这样才能与网络接口驱动直接交互。在中，与操作系统密切相关的是一个名为的设备驱动程序，同时对不同版本的操作系统提供了不同版本的驱动程序。这些驱动程序提供了数据包捕获与发送的基本功能，同时提供了一个可编程的数据包过滤系统、一个网络监视引擎等高级功能。
动态链接库：为了让应用程序能够使用内核驱动提供的功能，数据包捕获系统必须导出相关的接口。对此，提供两个不同层次的动态链接库：和。 提供底层的，用来直接访问驱动程序的函数，用来提供独立于微软公司不同操作系统的编程接口。
库导出了更强大、更高层的捕获函数接口，具有与捕获库的兼容性。这两个库可使数据包的捕获独立于底层的网络硬件与操作系统。
编程流程
了解了之后，我们要做的就是利用它提供的类库来实现网络传输，网络解析等一系列的功能。
需要我们做好的准备有：

语言的相关基础
计算机网络的基础知识
对开发环境的相关了解

如果对于上述中任何一个不熟悉，请先去补习一下基础知识吧。
参考资料

吴功宜等，《计算机网络高级软件编程技术》第版，清华大学出版社
徐恪等， 《高级计算机网络》，清华大学出版社
 ，《计算机网络》第版，清华大学出版社
吕雪峰等， 《网络分析技术揭秘原理、实践与深入解析》，机械工业出版社

相关推荐腾讯云上网络编程二之环境配置腾讯云上网络编程三之协议获得地址表腾讯云上网络编程四之主机通信接《 算法原理及其在  中的应用上》
三 在中的应用
早期我们在的基础上搭建了一套可扩展消息中间件，由于的同步算法在性能等方面存在瓶颈，所以自研了基于算法的内部版本和腾讯云，在保证强一致高可靠的前提下，性能和可用性都有显著提升。实现上采用了生产  消费机制保证消息不丢失，和机制均通过来保证。生产的消息通过转为同步到大多数节点并提交，完成后各节点状态机应用该，将消息内容写入磁盘，之后由节点回复客户端，表示消息生产成功。消费时客户端从节点拉取消息，消费完成后通过命令通知服务端消息已消费可删除，请求经同步后，各节点应用该请求，之后消息被删除不会再投递。下面介绍详细过程：
生产流程：
生产者将生产消息的请求发往的模块。
模块完成的创建和同步。
大多数节点上持久化并返回成功后标记为。
所有节点的 应用该日志，取出实际的生产请求，将消息内容写入磁盘，更新。该步骤不需要刷盘。
回复客户端，通知生产成功。
如果此后机器重启，通过日志恢复生产消息，保证了已的消息不丢失。

消费流程：
消费者从节点拉取消息。
收到后从磁盘加载未删除的消息投递给客户端。
客户端处理完成后消息，通知服务器删除消息。
请求经同步后标记为。
各节点状态机应用该日志，将消息对应的置位，将其设置为已删除并更新。
通知客户端删除成功。
如果机器重启，通过日志恢复请求，保证了已删除的消息不会再投递。

快照管理：
快照管理与业务紧密相关，不同系统快照制作的成本差异很大，中快照的内容十分轻量，一次快照的耗时在毫秒级，平均创建一次，各节点独立完成。实现上内存中维护了一份动态的快照，制作快照时首先拷贝出动态快照的副本，之后处理流继续更新动态快照，用拷贝出的副本创建快照文件，不影响实际的处理流。快照具体内容包括：
：快照对应的 参照算法
：快照对应的  参照算法
_：时的集群配置信息。
 ：每个队列一项。中同一队列生产的消息顺序写入，分片存储，因此只需记录最后一个分片的状态分片文件名，文件偏移量。
 ：每个队列一项。中采用记录消息的删除情况，在内存中维护，在制作快照时到快照文件。

可靠性：业界统一的衡量标准为  ，反映故障时数据恢复完整性的指标。由于只有提交的日志才会被应用到状态机，且日志在写入时会强制刷盘，所以故障重启后通过快照日志即可恢复，不会丢失数据，=。不过，如节所述，故障时可能会产生重复数据，需要通过幂等性保证或去重机制来解决该问题。
可用性：业界统一的衡量标准为  ，反映故障时业务恢复及时性的指标。故障对系统没有影响=，故障时其他节点通过自发选出新，而且中前端具备自动重连功能，当连接断开后会自动寻找新，系统不可用时间大大降低。目前中配置的选举超时时间为，在不考虑选举冲突的前提下，上限为。
在中，通过与的心跳判断自己是否已网络分区，当检测到分区时大多数节点上次心跳回复时间距现在超过，主动断开前端连接，前端发现后会自动寻找新。这段时间内客户端请求会超时，在连上新后，客户端重试之前超时的任务，后续请求恢复正常。
四 算法性能优化
算法的性能瓶颈主要有两方面：
    每次日志写入后都需要刷盘才能返回成功，而刷盘是一个比较耗时的操作。
    由于算法限制，所有的请求都由处理，不能做到所有节点皆可提供服务。
针对以上两个问题，我们做了以下优化：
 ：在请求量较大时，并不是每一条日志写入都刷盘，还是累积一定量的日志后集中刷盘，从而减少刷盘次数。对应的，在同步到时也采用批量同步的方式，接收后将日志批量写盘。
： 进程中同时运行多个实例，机器之间组建多 组，客户端请求路由到不同的上，从而实现多主读写，提高并发性能。通过将分布在不同机器上，提高了系统的整体利用率。
： 在日志同步过程中采用同步方式，在一端处理时另一端只能等待，性能较差。我们采用异步的方式使得端发送和端处理并发进行。发送过程中端维持一个发送窗口，当待确认的数达到上限停止发送，窗口值上限：

在与同属于高可靠多副本同步刷盘的性能对比中，相同压测场景下速度可以达到的四倍左右。
以下为机器消息大小时性能数据：

测试中采用单组方式以保证测试公平性。监控显示、内存和网卡均未达到瓶颈，系统瓶颈在磁盘，显示_远大于。主要原因在于刷盘耗时，造成写操作排队等待。
实际生产环境中我们将组和磁盘进行绑定，实现组之间磁盘的隔离，一方面保证了磁盘的顺序读写，另一方面充分利用机器的 、内存、网卡等资源。
五 通用库
中完整实现了算法并解决了很多细节难点。考虑到分布式系统设计的复杂性，如果开发者只专注于业务相关部分，将可以显著降低开发难度，提高系统的质量，所以我们将中的部分以库的方式独立出来，使用者用它即可搭建一套强一致高可用分布式系统。目前该库已经完成基线版本开发并在部门落地使用，验证完成后会陆续开放给更多业务使用。
六 总结
消息中间件通常分为高可靠版本和高性能版本两种。是一款金融级的高可靠分布式消息中间件，通过保证了消息的可靠不丢失。同时在性能和可用性方面相比竞品都有显著提高。此外，我们自研的高性能版本的消息中间件也已在腾讯云上线，完美兼容版本客户端，关于的具体技术介绍请关注后续技术文章。
算法强调了的地位，选举和日志同步都是围绕展开。由负责处理所有请求保证了系统的强一致性；选举和日志同步算法保证了数据的可靠不丢失；此外上述步骤只需要大多数正常互联即可，从而极大提高了系统的可用性，少量机器故障不受影响。不过，所有请求由处理并没有充分利用从节点的资源，目前的已支持从从节点读取，后续我们也会在这方面作更进一步的研究。算法易于理解和工程化，相信未来会应用在越来越多的分布式系统中。作者：蒋鹏

问题结论
由于接入层在调用后方逻辑层接口，使用的调用方法_没有设置超时默认，会由于后台单点故障，导致调用没返回而一直等待，引发雪崩，使接入层的也被占满未释放空闲，导致所有的控制台服务都不可访问。
 
问题场景
近日，测试同学  反馈整个测试环境，的相关页面都不能访问了，实在找不到问题原因。表现如下：
、三套的测试环境都拉取不出页面，页面一直弹登录框，登录态校验失败。
、做账户的登录态、用户信息校验等，校验接口大概率超时。
、浏览器抓包，发现许多请求一直处于状态。
问题分析过程
 、套环境都这样，首先考虑是机器底层网络有问题？
通过与其他的测试环境运行情况，发现就只有的环境这样，排除一种可能。
、页面一直弹登录框，首先需要定位登录校验失败问题，难道是官网组件运行异常？
同样查看其他的环境，是否有登录的问题存在，发现不存在问题。那么排查的环境是否连接鉴权的地址不正确？环境不通？
首先解决鉴权失败问题：    
 ___
 |=|={_
\\\\\\\\\\
\\\\{{___
}{}}}|=|=    
    
通过日志发现，鉴权相关接口出现超时，=|=        
提取请求单独测试，发现请求一直不返回，那么我们往后端继续定位，发现被请求组件的日志展示，鉴权的接口是正常处理，没有失败的情况。
 ：我发起请求正常 ——————————：我处理请求也是正常，内部没有超时
这时候，问题的关键点就在到之间了，他们直接的距离就是，由于经验的转发能力是很强大的，这里考虑慢，结合定位的日志，逻辑耗时正常，这里考虑的进程占用满了。
、看进程数量
、查看中_。
 、该问题场景，两者数量相等，于是考虑的进程占满。
尝试解决问题，重启下，刷新页面，出现下面情况：
页面可以正常刷新出来，多次刷新后，又陷入了大量超时失败，浏览器请求。   
判断重启不是根本办法，要定位出具体的是什么导致了线程急速耗费完。 
于是我就去看 的请求处理日志了要看所有的请求日志：
 ___     
通过发现打印内容很久才会有一条，这里我们要知道一点：
是在处理返回后，返回内容给请求端时候才会打印请求的日志。
于是修改的日志打印规则，看看请求具体耗用时间，设置规则参考日志规则配置。通过在_中查询‘_ ’、‘_ ’等看看超过的请求处理。得到了如下的情况：

有请求耗时达到了，浏览器的请求也在后返回，这里需要从代码角度考虑，有哪些场景可能导致耗时很长：
、代码中可能存在大的循环。
、代码中出现阻塞，一直等待。
通过在代码中打桩，插入语句，发现在如下的_函数前后打桩，浏览器分别会正常返回或者一直，所以考虑是这个函数的问题。

通过代码调用实现中，没有看到关于_的设置，而使用了默认的超时时间，并与研发对齐，的确是没有超时设置。初步定位到由于这里没有超时，而有一些逻辑一直在等待后台返回，导致了接入层机器的进程耗用完。
这里又有问题了，什么情况导致_一直等待未返回，用同样上面方法了解，有一台逻辑层组件机器，也耗用满了，导致接入层请求逻辑层一直，没有返回。这样由于一台机器的问题，而影响到接入层，从而扩散控制台所有用户都不能使用。
补充问题：为何没有返回？
  \ {
_ 
_ 
 _
_ _ ___
_ _ _
___ 
__ 
__ 
__ 
}
配置代理转发，超时时间是分钟，大于我们_的而没有出错。
补充问题：在定位过程中，多次点击列表拉取按钮，每次会触发两个访问，其中一个会，当点击到第六次后，两个都会，场景必现。
第一次刷新
    返回
    
第二次刷新
    返回
    
第三次刷新
    返回
    
第四次刷新
    返回
    
第五次刷新
    返回
    
第六次刷新
    
    
这个主要是浏览器本身限制了单域名的连接个数，定位环境使用，限制个数为个连接。                       ’          通过可视化信息，我们可以绘制出一道眼睛可以看到的蓝图，一种信息地图。当你迷失在信息中时，信息地图就有作用了。
—— 大卫·麦克坎德莱斯

 在演讲《    》中给我们讲述了数据可视化的意义和美丽之处，在大数据迅速发展的时代，研究数据可视化的价值显而易见。本篇文章主要对数据可视化中的基本元素——基础图表进行相关探索。
数据的视觉表达方式
人们感知信息中约是通过眼睛获得，视觉化信息成为最重要的信息之一，也是最容易被处理并记住的。数据可视化是关于数据的视觉表现形式的研究；其中，这种数据的视觉表现形式被定义为一种以某种概要形式抽提出来的信息，包括相应信息单位的各种属性和变量【】。简言之，数据可视化的目的是让数据说话，让复杂抽象的数据以视觉的形式更准确快速的传达。
【】注释：              
 
如上图图例一，可视化展示让数据更清晰直观的呈现出来。基础图表是数据可视化的一个基本、重要的视觉化表达方式。图表之所以重要，在于它对数据信息的有效提炼、梳理、传达的功能价值。图表能对枯燥、复杂的数据，根据传达目的，提炼成更简洁、直观的视觉信息。
图表发展史
早在几个世纪前就已出现数据可视化的表现方式，其中公元前年希腊哲学家创造了第一个出版的世界地图。


第一个图表则始于公元年的欧洲，被认为是最早的基于时间变化的折线图，展示太阳、月亮等行星的位置变化趋势。

_
公元年法国人尼科尔·奥雷斯米 在出版物 《   》中发明了第一个柱状图，展示加速对象与时间速度的关系，使用图表直观的展示变量之间的关系。
 

威廉·普莱菲尔 被称为图表设计之父，条形图、饼图、折线图等都是他发明的，在年出版的《商业和政治图解》中的条形图也被看成图表中的里程碑，在许多数据可视化研究中都有用到这幅条形图。


随着时间的流逝，图表发展到现在，在《华尔街日报》、《纽约时报》、《商业周刊》等商业杂志应用最为优秀。我们也对图表类型有一定的认知度，像展示百分比的圆饼图、体现趋势变化的折线图、对比数据的柱状图等。不管在商业中，还是日常工作汇报中，图表都体现了它的价值。好的图表能用简单的视觉元素，清晰快速的传达复杂的数据信息。更多数据可视化发展史：
图表设计过程
图表设计的目的是通过图表的视觉表现形式，直观、清晰、准确的展示已知多数据或单数据的联系。首先要获得已知数据，对其进行整理分析筛选，找到想要了解的内容，确定该数据之间的关系，选择视觉表现形式，最后输出想要的图表。

可以看到图表设计过程可分为数据处理层面和视觉展示层面。数据处理：获取数据、整理数据、清洗分析数据。数据源有、、、数据库、、、、等，数据处理层面腾讯云都有大数据相关工具。视觉展示：确定数据关系、选择图表形式、输出图表展示。确定数据之间的关系，关系有对比、构成、分布、关联，比如例图一可知道三个产品的销量变化是对比关系，最后选用折线图的展示方式。
图表分类和选择
图表的主要分类有柱状图、条形图、折线图、饼图、圆环图、面积图、散点图、气泡图、雷达图、曲面图等。下图为数据可视化专家发布的图表建议导图。图表选择方式通过数据关系的四个方面来区分：对比、构成、分布、关联，再根据变量、类别、时间关系来选择图表。


对比
对比型的图表可以展示多个数据之间的相同和不同之处，也可以展示单个数据在时间上的变化趋势，是基于时间或分类的维度来进行对比，通过图形的颜色、长度、宽度、位置、角度、面积等视觉变量来对比数据。典型的对比类图表有柱状图、条形图、折线图、雷达图。
下图为《华尔街日报》年全球股市前十排行。各国间的股市市值是一种对比关系，选用条形图的方式让数字信息展示的更为清晰直观。


构成
构成顾名思义在同一维度的结构、组成、占比关系，可以是静态的，也可以是随时间变化的。最典型的构成型图表就是饼图、环状图，还有百分比堆积柱状图、条形图、面积图。
下图为年统计的流行电视设备销量占比。构成关系的数据通常会采用圆形图，通过圆弧长度面积大小来区分数据之间的构成情况。


分布
分布型图表通常用于展示连续数据的分布情况，通过图形的颜色、大小、位置、长度的连续变化来展示数据的关系。散点图、直方图、正态分布图、曲面图表现方式都能体现数据的分布关系。
例图是一个正态分布图，被称为“  ”，它显示从小于到大于的范围人数的分布情况。在智商规模从到的情况下，人数呈现递增分布，最高人数达到后，随着递增人数开始下降，很小一部分达到了超过的智商。可知世界目前的平均智商是，标准偏差为。

_
关联
关联型图表用于展示数据之间存在的关系。散点图、气泡图主要通过图形的颜色、位置、大小的变化关系来展示数据的关联性。
《纽约时报》的文章推广与浏览量关系的可视化展示，采用气泡图的表现方式，直观的展示了文章放在首页与否的浏览情况。气泡图中数据以圆泡的形式展示在轴、轴构成的直角坐标系上，使用气泡的大小、密度来代表强度，颜色来区分分类，通过这些视觉方式清晰的呈现了数据间的影响程度。从而快速的找到最合适的推广方式。


图表的基本构成元素如图：标题副标题、图例、网格线、数据列、数据标签、坐标轴、、轴标签、轴标签、辅助信息。根据结构的不同会相对增加或减少一些元素，饼图只需要标题、数据列、数据标签就能把数据呈现的清楚。点、线、面是数据列基本视觉元素。

图表层次：文字信息、图表视觉图形、坐标系网格。

小结
本文主要对数据可视化的基本元素图表进行了基础研究，主要阐述了图表基础介绍、图表发展史、图表设计过程、图表的分类、图表选择方法以及图表的视觉元素和层次。
那怎样的视觉元素结合能产出好的图表？好的图表应该具备哪些条件？图表的设计原则、设计误区又是什么？图表设计二将进行详细阐述。打造黑苹果五设置系统盘引导，以及安装驱动
前情回顾
打造黑苹果一组装硬件的选择与组装打造黑苹果二制作黑系统安装盘打造黑苹果三设置打造黑苹果四安装系统
前言
经过前面的一系列工作，我们已经把系统安装在我们的硬盘上了，但是我们启动的时候还必须通过盘启动，那是因为我们还没有给我们的系统设置引导，另外看上去貌似不正常，甚至有掉帧等现象的出现，这是因为我们还没有安装驱动。
这一章，我们就来讲解如何设置引导，以及安装驱动。
设置引导，以及安装驱动
首先，可还记得在第二章节，我们在制作黑系统安装盘的时候的最后一步，将 这个复制到我们的盘当中了？
现在，就该用这个软件了。首先，我们把它从盘中复制到我们的桌面上在盘中也可以直接运行，但是，我们可能要多次安装驱动，因为可能你一开始选择的不正确，所以复制到桌面上，便于我们下次再安装。
下面的图片来自于网站，原文地址点击这里，原文是英文的，你英语好的话，可以直接去读的哦。
我们打开复制到桌面上的软件，如下图所示：

我们点击左上角第一个按钮  ，快速开始。然后就进入下一步，如下图所示，我们点击左侧的   ，

选好了之后，我们点击上方的  图标，进入到下面的界面：

这里是设置你的驱动程序的，主要有两个，左侧的 和 两个，分别是音频驱动以及网卡驱动。之前，我让你查看一下你的主板上的声卡芯片型号和网卡芯片型号，就是在这里用的。
我们在右侧勾选我们的声卡芯片型号，然后切换到 里面，选择我们的网卡芯片型号，选择好了之后，我们点击上面的  图标，打开如下图所示的界面：

这里是设置我们的显卡驱动，如果你是用的核显，就选择你对应的核显型号，    或者   。如果你是使用的 英伟达的显卡，就勾选   。
选好了之后，我们点击上方的  按钮，就进入到了下方的界面。

我们可以看下左侧的内容，这里显示了我们刚刚选择的引导方式，以及我们选择的驱动程序。
右侧的下拉菜单，选择我们的系统，例如图中所示的，确定没有问题之后，我们点击右下角的  图标，进行安装。
一般情况下，是不会出错的。
但我就遇到错误了，原来我之前在第四步格式化的时候，方案没有选择    而是用了默认的，导致在这里出错，而且无论如何也引导不了系统。之后重新来过菜解决问题。
不过胆大心细，即便重来也是能够解决问题的。
点击  之后，就会有安装进度条，等待安装完成之后，我们即可重启电脑，正式进入我们的黑系统了。
正式进入黑系统
首先，我们重启系统此时，你可以拔掉你的盘了。选择开头的系统安装盘启动启动菜单中可能会出现几个　  这样的选项，不用管。，当然，我们也可以在  中直接设定我们的开头的系统安装盘为默认启动盘。
然后会进入下面的界面：

很熟悉，对吧，和刚刚的盘启动过程中的选择是一样的，默认应该选择的是  这个图标，默认等待三秒，就会直接进入系统，如果你是个急性子，也可以直接按回车键进入系统。
经过几个小时的折腾，我们终于进入到了我们的苹果系统中了。如下图所示：

好啦，终于完成了，歇一会儿吧！
黑后记

一定要用对的硬件，否则非常折腾，而且可能折腾不成功。
国内有很多的黑教程，但我粗略看了一下，各种版本，各种懒人版。我感觉，还是安装原版的好，我的这个系列教程可是安装的原版的哦！
没折腾过笔记本，但是网上的反应是笔记本很不好折腾，触摸板和无线网卡几乎是无解的。如果你希望在你的笔记本上安装，最好是在搜索引擎中输入你的笔记本型号和黑苹果关键词，看看网上有没有成功的案例。反正基本上是没戏的。
内存条要靠一侧的插槽上插！这是我遇到最大的坑！
是一个专业的黑苹果的网站。我基本上没有参考国内的资料，按照这个网站的安装教程就一路安装下来了，没有什么大坑。
我们装黑苹果是为了工作的，不是为了黑苹果而黑苹果。所以我这篇教程中没有什么特殊的东西。只要系统能用，就好，不折腾。
主板自带的麦克风我在几台电脑上尝试都没有驱动起来。无奈买了的声卡，可以完美使用，淘宝上某品牌的只要块钱包邮。
无线网卡上网是个小坑，我下一章讲如何处理。

最后，祝大家都顺利成功的黑上，当然，在资金充足的情况下，建议入手一台笔记本用于前端开发。我自己的 内存固态硬盘的黑在性能上只超越款的的，比较让我郁闷。
我推荐的配置是前端工程师的配置，如果你是要组装一台视频工作站，请参考网站，整一台预算在万左右的比较合适，我就不说了。
本文由原创，资料参考于，允许转载，但转载必须附注首发链接。谢谢。
首发链接：作者：徐凯

《大话  》系列文章通过通俗易懂的语言并结合基础实验，用最简单的描述来讲解  中的重要概念。让读者对分布式存储系统有一个清晰的理解。
引言
这篇文章主要介绍了  中的一个重要系统   认证系统。简要介绍了  的命名格式。并介绍了从集群启动到用户连接集群这一系列流程中  所起的作用。最后通过实验操作讲解如何在集群所有秘钥丢失的情况下将其完整恢复，以及在实际生产环境中使用  的一些注意事项。
 是什么？
 理解起来很简单，就是整个  系统的用户名密码，而这个用户不单单指我们平时在终端敲   而生成的 ，在这套认证系统中，还有一个特殊的用户群体，那就是 ，也就是说，， ，  也都需要一对账号密码来登陆  系统。
 的命名规则
而用户名密码遵循着一定的命名规则：
用户名
用户名总体遵循    的命名规则，这里的有三种：。而  根据不同的类型的用户而有所不同：

 ： 为空。
 ： 为  的 。
 ： 为该客户端的名称，比如。 密码密码通常为包含个字符的字符串，形如：==。

默认用户
想要和一个  集群进行交互，我们通常需要知道最少四条信息，并且是缺一不可的

集群的 。
集群的  的  地址，必须先连上  之后才能获取集群信息。
一个用于登陆的 用户名。
登陆用户对应的 密码。其实，很多同学会发现，在我们日常和  集群交互时，并不需要指定这些参数，就可以执行 得到集群的状态。实际上，我们已经使用了  提供的几个默认参数，而   加上默认参数后的全称是：

       
从上面的指令可以看出， 使用的默认用户为 ，而这个用户的秘钥文件通常是保存在  路径下。如果这里，我们从目录下删除这个秘钥文件，再次执行  ，就会得到下面这个最最常见的错误：
                 
            
              
    
从报错信息我们可以看出一点，因为我们使用了默认用户 ， 就会以下四个默认路径去寻找 这个用户的密码：： 实际上命名格式为：。

 ：命名格式为 ：。
。
。如果不存在这四个文件，或者在这四个文件里面均没有保存用户  的秘钥，那么就会报错：  。也就是说，用户登陆  系统失败！

谁才是  中的鼻祖？
隐藏 之 

一段对话：  当然是我！用我的账户密码登陆  后可以执行任何指令  哦。  你谁？我这有所有账户密码悄悄得查了下   ，怎么没看到你？  嗯。  哎呀，哪个二货把我的秘钥文件删了，我不能连接集群了！  让一让，我来帮你把秘钥找回来。  你？确定？  嗯。

一直以为自己权限很大的，忽然因为丢失了保存密码的秘钥文件而不能访问集群了。而从未露面的  却号称能够找回 的秘钥，难道说 才是真正的鼻祖？！
现在我们回到故事最初的起点，也就是集群搭建之初，我们使用    后，生成了三个文件：

 


除了，还默认生成了一个  文件，不出意外的话，这个文件几乎是不会在后面的集群交互中使用的，因为在   之后，会生成用户，而后面的交互一般都会使用这个用户了。但是集群生成的第一个用户却是  ，对应的秘钥文件保存在部署目录下的 。
查看  的，可以看到在步骤   时，有一段日志记录如下：

       = = = _
       = =   =   
       = =   =   
       = =   =   
       = =   =       
       = =   =   
       = =   =   
实际上，这些秘钥文件都是通过用户创建的，包括  用户及其秘钥。所以在整个  的历史中， 才是第一个生成的用户，而其他的用户均由  用户生成或者依次向下生成。
用一张图来表明秘钥的生成关系：通过这张图，我们可以很容易理解  的几个用户的用处了，就是用于引导生成对应类用户的用户，比如 用于引导生成所有  用户。
 使用场景
聊完了各个用户的生成时间，我们来看看这些用户是在什么时候使用了它们的账户和密码的！

在整个集群启动的时候，首先是  启动，再然后是  启动。在  启动的时候， 会携带自己的秘钥文件启动进程，也就是说， 启动的时候，是不需要向任何进程进行秘钥认证的，通俗点讲， 的秘钥哪怕被修改过了，也不会影响  的启动，这里通过一个小实验来具体说明：
    

 = ==
  =  
     
   

 = ==
  =  
    
 将秘钥文件内容的一部分改成了，再重启
    

 = ==
  =  
    
     
   

 = ==
  =  
 的数据库里面，记录着除了  以外的所有用户密码，在  启动之后，才真正开启了认证这个步骤，之后的所有用户想要连接到集群，必须先要通过  和   连上  集群，通过了认证之后，就可以正常访问集群了，下面继续介绍下  的启动认证过程。

 在启动的时候，首先要__，也就是拿着自己的账户密码去登陆集群，这个账户密码在  的数据库里有记录，所以如果互相匹配，那么就可以正常启动，否则，就会报下面的错：
      __ {=}
       
             
            
   _
日志里面的   也就是认证不通过的意思，说明这个  携带的秘钥文件和  所记录的内容不一致，导致了  的启动失败。这时候，需要比对下  的秘钥内容和  的是否一致：

    

 = ==
     
   

 = ==
  =   
  =  
的确，内容不一样，这时候用     得到的值替换秘钥文件的部分即可正常启动 。

通常我们执行  时，就相当于开启了一个客户端，连接到  集群，而这个客户端默认是使用  的账户密码登陆连接集群的，所以平时执行的  相当于执行了      。需要注意的是，每次我们在命令行执行  的指令，都相当于开启一个客户端，和集群交互，再关闭客户端。现在举一个很常见的报错，这在刚接触  时，很容易遇到：

   
            
    
报错信息很好理解，操作不被允许，也就是认证未通过，由于这里我们使用的是默认的 用户和它的秘钥，说明秘钥内容和  集群记录的不一致，也就是说  内容很可能是之前集群留下的，或者是记录了错误的秘钥，这时，只需要使用 用户来执行   就可以查看到正确的秘钥内容：
          
   

 = ==
  =  
  =  
  =  
细说 
仔细查看    的输出，除了用户名和对应的秘钥内容外，还有一个个以 开头的内容，这就是  中对各个用户的权限的细分，比如：读、写、执行等

  =  
  =  
  =  
而针对不同的应用，同样的读权限或者写权限的作用是不同的，下面依次对这三个应用的  权限进行分析。

 权限
那么问题来了，想要执行 的最低权限是什么呢？ 那就是   = ，也就是  的  权限。那么这个读权限到底读了什么呢？首先要强调的一点，这里读的数据都是从  来的，和  无关。
 作为集群的状态维护者，其数据库内保存着集群这一系列状态图 ，这些  包含但不限于：

 
 
 
 
 而这里的读权限，就是读取这些  的权限，但是这些  的真实内容读取出来没有多大意义，所以以比较友好的指令输出形式展示出来，而这些指令包含但不限于： 
   
  
   
  
只要有了  的  权限，那么就可以从集群读取所有  维护的  的数据，宏观来看，就是可以读取集群的状态信息但是不能修改。

这里简单介绍下验证流程，我们通过生成一个只包含  的  权限的秘钥，来访问集群：
   _     
  _         
  _          
  _          

  _              

  _             
 权限
 权限比较有趣，必须配合  权限才能有效力，否则，单独  权限执行指令时，是会一直  的。所以我们在测试  权限时，需要附加上  权限才行：

   _     
这时，假象集群的各个  摆在你的面前，你可以清晰得读取每个  的状态，每个  的状态，但是，如果赋予了你  权限之后，你就可以对这些实体进行操作，比如踢掉一个   ，修复一个    ，修改  结构   ，删除一个    ，而这些操作，如果在仅有  权限时，是不能执行的 。
由于这里可以执行的指令实在太多了，我仅仅对  权限做一个简单的总结：

  读取集群各个组件的状态，但是不能修改。
  读取并可以修改集群的各个组件的状态，可以执行对组件的各个动作指令。
注意：目前讨论的组件读写权限，均不包含集群对象的读写权限的，也就是说，你单单有了  的  权限，是不能从集群读写对象的。



 权限
 的  权限也比较有趣，因为这个权限仅仅和  相关。也就是说，如果你想要执行   ，  之类的所有和 相关的指令，那么拥有了  权限就能执行了。但是和  权限类似，也需要  权限组合在一起才能有效力：
   _     
  _    
 权限
一句话说明 ： = 

可以通过将多个用户秘钥写入同一个文件中，比如上面的 中，就包含了
 =_   _===_   = ==
在指令指定 后， 就会到  后面的文件中找寻对应的用户名下的秘钥。

  权限
官方的解释是：给用户以一个  的身份 连接到 其他  的权限。给  授予这个权限，使得  能够处理副本心跳和状态汇报。暂时没找到比较通俗的理解

相比于  的各个权限， 的  比较简单理解一下， 权限就是读取对象的权限，  权限就是写对象的权限， 权限比较有趣，可以调用任何 的权限，这里引用   上的一段话来介绍：

                                                                

举个例子，你可以实现一些自定义的方法，通过调用这些方法，可以读写具有某一类特征的对象，比如都是以_开头的对象。目前只有调用层才能使用自定义方法，而上层，之类的是不能使用的。

权限除了包含了 ，还包含了  这类指令的权限。

官网的这个页面比较好的介绍了几个实例，这里简单介绍下一个比较长的指令的意义：

 =   _ _         
第一个权限：_ 是一个类方法，而这个方法的作用是给予所有以_为名开头的对象的也就是读权限。只能读，不能写。
第二个权限：给予池的读权限，可以执行方法的权限。也就是说，客户除了可以读这个池的对象外，还能自己实现形如_这种系统自带的类方法来读取对象，比如读取具备某一类特征的对象。
第三个权限：给予池  的读写以及执行方法的权限。
丢失所有秘钥的恢复流程
讲了这么多理论知识，某个二货运维同学不耐烦了，一口气把所有的秘钥全部删除了，这些秘钥包含：

 ： 
 ： 
 ：总之，所有包含秘钥内容的文件都被删除了，并且连同目录都删的干干净净。这时候能否将所有的秘钥文件恢复出来吗？答案是：可以！

在管理秘钥方面， 做了一个比较有趣的设定：所有除了 用户的账户密码都保存在  的数据库中，但是  用户的信息并没有保存在数据库里，而是在  启动时读取  目录下的  文件得到的。所以，我们甚至可以随便伪造一个，放置到  目录下去。然后同步到各个  节点，然后重启三个 。 这时候，就拿着人造的启动生效了。有了 用户的账户密码，我们很容易的可以使用        指令来得到所有的秘钥内容！
等等，如果真的删干净了目录的话， 上面的这个指令是不能执行的，因为没有去指定集群，这时候，我们可以从任意一个目录下的_ 得到集群的， 的信息也很容易恢复。简单得重构了 后，使用 的用户密码就可以得到正确的  的信息啦。
再等等，现在的内容太精简了，比删除之前少了很多东东，这些东东还能恢复吗？答案是，能！
找寻任何一个未重启的，执行     ，这样，就可以看到这个启动加载的配置项和默认的配置项的不一样的地方，通过仔细比对很容易恢复成删除之前的配置文件样。

疑问相信这里就会有同学有疑问了，为什么不直接把  里面的  改为  后直接重启集群呢，首先这样做的成本较高，因为要重启必须重启，否则会在重启一段时间内全部自杀。所以上面的方法只重启了，影响范围小。

 实际使用中的注意事项
 使用
在部署后，通过拉取  的指令输出得到返回值，但是却会报：
_    
_   
前往  节点执行脚本，却能得到正常的输出。
这里查看 _ 的  发现，日志里面总是报 ：

       
原来是_ 对 没有读权限，将秘钥  之后，就能正常读取数据了。
所以，在我们的日常使用中，一定要注意的读权限，很多不是运行在  用户上的应用读取不到秘钥内容后，就会连接不上集群，造成比较奇怪的现象。
  
在关闭  功能时，要遵循一定的顺序：

关闭： 重启  重启
开启： 重启  重启如果关闭后未重启，过一段时间，会随机挂掉。

 的分布
通常我们可以在  节点执行 ，但是到了  节点，就会因为缺失的秘钥文件而无法执行 。
 的秘钥保存路径为： 。 的秘钥保存路径为： _。 的秘钥保存路径为：。
实际上，我们甚至可以在  节点没有 ，通过执行：

     
来读取集群的状态。
配置只能访问一个的用户权限
具体介绍可以参考这篇文章这里主要说下秘钥的创建指令的意义：

    

 
 
  _ _ 
  _ _ 
  _ _ 
 
这里通过 _前缀方法，赋予了用户对和某个所有相关的对象的读写权限，是一个比较有实用价值的应用。
总结
本文介绍了  在  系统中的生成过程以及互相之间的依赖生成关系。详细讲述了各个权限在不同应用中的作用和使用场景。最后通过秘钥丢失的例子来将理论应用到实际生产环境中，使大家对  的使用游刃有余。
大话系列文章
《大话》之那点事儿《大话 》之  那点事儿《大话  》之  那点事儿

本文来自： 公众号作者：陈忱 

目前移动端运营素材大部分依赖图片，基于对图片流量更少，渲染速度更快的诉求，我们推动，内核，即通产品部共同推出了一套业务透明，无痛接入的图片优化方案：基于的自适应图片无痛接入方案。据统计效果可在原图基础上节省的流量，比之前无痛接入方案效果提升，减少流量的同时提高页面渲染速度，提升用户体验。
效果数据
目前手增值业务：中心、游戏中心、动漫、游戏公会、特别关心 以及增值渠道的钱包，空间的个性化商城已经接入自适应，优化效果数据：
自适应方案在原有自适应方案效果提升，提升效果主要来自高于的编码压缩率，同时能优化到无法覆盖的图片备注：之前无痛方案只实现了的支持，方案和原图对比可以节省的流量。
以我们的中心为例，之前方案：

上方案后

在图片增加的情况下 图片流量减少了近，页面速度也有提升，并且图片的效果也经过设计同学的验证，肉眼几乎无法区分，图片质量参数细节后面会介绍。
方案概述
利用自建结点的缓存，以及带请求头的回源能力做到同一个根据终端分辨率，以及是否支持解码，按需返回不同的原图副本，做到图片资源的最合理利用：手 内核支持图片的解码，请求图片时会带上 标识，中会加上手机的分辨率参数，节点收到请求后，先检查如果有对应的自适应副本直接返回，如果没有则将请求回源到源站，源站会根据请求的、参数返回对应分辨率的图片副本原图上传后，或第一个用户请求触发源站服务器图片转换，生成不同尺寸的图片 如果请求头没有标识，则按原有逻辑返回原图，不影响业务。整套优化方案接入对基于内核的业务完全透明，无需改动代码，即可让页面的图片获得可观的图片专项优化效果；业务接入，音视频有提供解码的的接入。
方案详解
何为
是腾讯公司即通产品部音视频技术中心推出的一种图片压缩组件，现已支持、、、四个平台。编码压缩率、编码耗时、解码耗时相比有明显的优势。
 方案
在原有自适应无痛方案基础上，我们联合终端、进一步升级优化，做了如下优化改造：终端支持：增值业务大部分是基于手 的应用，安卓平台基于内核，内核于版本开始引入了组件，支持解码，并约定支持的版本发起的请求会在请求的头部带上 字段，同时内核中会带上终端分辨率字段平台由于系统对内核的限制，暂时无法很好的嵌入组件，未能支持解码。未来可以在原生引入组件，原生请求带上，就可以使用到的能力。
侧改造：源站转换工具集成了组件，的结点新增支持 副本的缓存，整体流程大致如下：

客户端发起请求后，结点根据请求检查字段是否带有，并获取分辨率信息，结点判断是否有满足要求的原图副本缓存，没有缓存则将请求头回源，源站识别请求头中的信息，返回图片对应的副本，结点缓存下来。源站图片如果未转换完成图片上传后或第一次请求触发源站异步转换，源站会先返回原图=让结点暂时不缓存，再次请求时，判断转换完成才返回图片并设置默认的缓存时间=。目前 已支持了我们流量的域名：
、、、、
整体方案：结合之前我们做的自适应、方案，与可以完全兼容，在源站是项单独的配置，可以按需配合或单独使用，整体方案如下图

优先判断是否有自适应，然后检查，如果和都支持优先返回。
项目中踩过的坑
运营商内容劫持，由于同一个可能返回不同的内容不同分辨率的原图 线上观察发现联通运营商会在请求到我们自建结点之前加一层缓存，默认会按来缓存内容，其实就是内容劫持，导致不同请求头，返回错乱与我们期望的不一致，后面找到一种解决方法，基于协议的字段，源站以及结点返回内容的时候带上 ：， 字段，告诉运营商的缓存服务器根据请求的来缓存内容，经验证可以解决问题。
质量参数设置，尽可能保证图片压缩的更小，效果与原图差距不大，采用有损压缩，转换工具会读取原图质量参数，适当降低：如果原图质量参数低于则保持原质量参数直接转，如果质量参数高于，则在原图基础上降低一些质量参数，根据业务要求自行设置，目前根据观察质量参数不低于的图片基本肉眼无法区分。
新的业务开启自适应，源站图片转换导致磁盘压力过大。用脚本凌晨闲时对存量图片预转换生成各尺寸的副本；转换工具监听图片目录的新增文件，用户上传后就做转换；转换脚本做了优化，只有第一次请求触发转换。
转换工具对某些图片转换失败，生成空文件，捕获转换失败错误码，空文件用原图替换，避免返回给结点空文件。
有时候业务图片需要强制使用原图，支持参数，带上参数后，强制返回原图。
图片缓存清理：由于一 个图片，对应了多份结点缓存副本，如果图片更新的时候，可能有个别副本缓存刷新不及时，导致不同分辨率、、原图的用户看到的图片不一致，需要优化缓存刷新工具，支持一次清理所有缓存副本。
以上皆为项目推进中遇到的问题，未考虑周全可能就会影响功能，线上实施前得在测试结点充分验证，结点部署要控制节奏，并且要有完善的线上监控机制，以及功能回退的能力。
图片检测监控
为了提高接入效率，减少人工验证步骤，我们开发了图片检测监控工具，定时监控业务页面图片在各结点返回是否正常。原理：工具根据业务，抓取页面内所有域名的图片，随机抽取一部分结点，构造，，原图种请求，根据返回的图片格式，大小对比验证图片是否正常。
现网图片加载数据上报：为了监控更多用户的图片加载真实数据，我们在业务中接入了图片加载上报组件，原理是利用内核收集的资源加载信息，过滤出图片信息，上报图片类型，返回码，加载耗时，网络类型等。
开启验证
上传一张新图片，使用手安卓版本访问已支持域名的图片，如果请求带了，检查返回图片格式是否为。



如果旧的图片未按预期返回，返回了或原图可能是结点缓存，正常天后过期回源则会返回图片。
未来规划
业务接入优化方案目前只有安卓平台基于内核的应用能得到这套 方案的优化效果，根据日志的流量统计内最大的流量还是来自终端发起的请求，后续我们计划联合大流量的终端业务接入解码组件，让这套方案能给更多业务带来收益，同时也为公司和用户节省流量成本。
工具优化 组件在不断优化，包括转码效率、成功率，格式支持等，转换工具也将迭代支持。

文章来源公众号：小时光茶社 


相关推荐谷歌开源图片压缩算法实测体验报告借助腾讯云开启全站及问题解决分享为了方便的对网站流量进行数据监控和分析一般会用到交换机的端口镜像功能将数据复制一份发送到监控平台或分析系统而如果将网站部署到腾讯云平台是否也可以将服务器流量进行复制转发呢答案是可以的实现的方法就是通过 这个流量监控利器下面以为例介绍其部署和验证方法

部署架构操作系统  
为服务器添加双网卡弹性网卡检查主机网卡配置和路由
   

下载并安装 

所有版本下载地址
以为例运行
   _ 当前版本
         启用
   编辑配置文件
配置文件示例详细配置说明见注意事项
 {
    采样比
     = 
    截取包大小为
     = 
    设置收集器地址和端口
     { = = }
    设置采样的网卡
     {  =  }
    }
启动采样
   

下载并安装收集分析器以为例支持协议的软件都可以

下载页面或在服务器运行 
 _
安装并运行        依赖环境      _ 包安装       查看状态       启动
使用 查看分析数据
 浏览器中打开
 浏览器中打开
正常的话很快就可以看到以下内容
注意事项

安全组放通相应监听和传输端口
等其他版本下载相应安装包即可
  详细配置说明 
   
         
       


     {
   ======     ======
      
       
      = 
      
      = 

   ======  ======
        __
      { }
    
      
        = 
       
        =  采样比默认为 可设置分母为表示全采样
   = 
    截取包大小默认为 可以修改为需重新编译 尽量不要设置太大否则会产生很多分片包影响性能
   = 
          
        = 
        = 
        = 
        = 
         
        = 
          
        = 
      收集器地址可修改为数据分析系统所在的地址收集器可以设置多个
   { = = }
        

   ======   ======
      
      {  =  }
    
      
        {  =  }
       设置要采样的网卡
   {  =  }
        {  =  }
        {  =  }
       
        { = }
    
      {  =    =  }
    
      {  =    =  }
      
      { }
       
      { }
      
      { }
        
      { }
     
      { }
      
      { }
      
      { }
    
      { }
       
      { }
}

查看地址
       或指定使用网卡地址   = 前言
在使用 的过程中对于计算产生结果的进行持久化时，我们往往需要操作数据库，去统计或者改变一些值。
最近一个实时消费者处理任务，在使用 进行实时的数据流处理时，我需要将计算好的数据更新到和中，所以本文对操作和的内容进行总结，并且对自己踩到的一些坑进行记录。
 持久化设计模式
输出操作

：打印结点上每个中的前个元素，常用于开发和调试


 ：将当前保存为文件，每个 的文件名命名规则基于  和  ：”__”

 ：将当前的内容作为可序列化对象的序列化文件进行保存，每个 的文件命名规则基于和： “__”

 ：将以文件的形式进行保存，每个 的文件命名规则基于和： “__”

：最通用的输出操作，可以对从数据流中产生的每一个应用函数。通常会将每个中的数据保存到外部系统，如：将保存到文件，或者通过网络连接保存到数据库。值得注意的是：执行在跑应用的进程中，并且通常会包含 以促使数据流开始计算。


使用的设计模式
对于开发而言提供了很大的灵活性，但在使用时也要避免很多常见的坑。我们通常将数据保存到外部系统中的流程是：建立远程连接通过连接传输数据到远程系统关闭连接。针对这个流程我们很直接的想到了下面的程序代码：
 {  =
    =       
   {  =
         
  }
}
在上一篇文章《踩坑记——初试》中，对的和进行了整理，我们知道在集群模式下，上述代码中的需要通过序列化对象的形式从发送到，但是是无法在机器之间传递的，即是无法序列化的，这样可能会引起     的错误。为了避免这种错误，我们将在当中建立，代码如下：
 {  =
   {  =
      = 
    
    
  }
}
似乎这样问题解决了？但是细想下，我们在每个的每条记录当中都进行了的建立和关闭，这会导致不必要的高负荷并且降低整个系统的吞吐量。
所以一个更好的方式是使用即对于每一个的建立唯一的连接注：每个是内的是运行在同一之上的，代码如下：
 {  =
   {  =
      = 
     = 
    
  }
}
这样我们降低了频繁建立连接的负载，通常我们在连接数据库时会使用连接池，把连接池的概念引入，代码优化如下：
 {  =
   {  =
             
      = 
     = 
             
  }
}
通过持有一个静态连接池对象，我们可以重复利用而进一步优化了连接建立的开销，从而降低了负载。另外值得注意的是，同数据库的连接池类似，我们这里所说的连接池同样应该是的按需建立连接，并且及时的收回超时的连接。
另外值得注意的是：

如果在 中使用了多次，它们之间是按照程序顺序向下执行的

对于输出操作的执行策略是的，所以如果我们在中不添加任何 ，那么系统仅仅会接收数据然后将数据丢弃。


访问
上面我们阐述了将 的输出到外部系统的基本设计模式，这里我们阐述如何将输出到集群。
通用连接类
连接是通过获取信息，所以在配置时需要提供的相关信息，如下：
 
 
 
 

    {
     = 
     =   为配置类，获取的配置
  __ 
  _    
     = 

     = 
}
根据网上资料，的连接的特殊性我们并没有使用连接池
输出操作
我们以操作为例，演示将上述设计模式应用到输出操作当中：
 = {
    {
     = {
          =   获取连接
         = {
              = 
              = 
             {
                =  __   
                 
              __ __ __
              
                 显示在上
            }  {
                 =
                  
                
            }  {
              
            }
      }
    }
       显示在上
  }
}
关于的其他操作可以参考 下操作  新 
填坑记录
重点记录在连接过程中配置_的问题：

由于的连接不能直接使用地址进行访问往往需要配置例如我在上述代码段中任意，我们在中需要配置

 

在单机情况下，我们只需要配置一台所在的即可，但是当切换到集群是遇到一个诡异的

问题描述：在中将保存到时会卡住，并且没有任何错误信息爆出没错！它就是卡住，没反应
问题分析：由于集群有多台机器，而我们只配置了一台机器的，这样导致集群在访问时不断的去寻找但却找不到就卡在那里
解决方式：对每个上的配置了所有的节点，问题解决
访问
同访问类似，我们也需要有一个可序列化的类来建立连接，这里我们利用了的连接池
通用连接类
 
 

 

    {
      =  
     = 
   {
    _==
    
    
    
    
    
    
    
  }  {
       = 
  }
     = {
     {
       
    }  {
         =
        
        
    }
  }
}
  {
     = _
     = {
     {
        ==  {
         =  
      }
    }
    
  }
}
我们利用建立连接池，然后访问的时候每次从连接池中取出连接用于数据传输。
输出操作
同样利用之前的设计模式，将输出到的代码如下：
 = {
      {
       = {
        从连接池中获取一个连接
          = 
          = 
         {
          
           = {
              =     需要执行的操作
            
          }
          
          
        }  {
             =
               
        }  {
          
          
        }
      }
    }
}
值得注意的是

我们在提交的操作的时候，并不是每条记录提交一次，而是采用了批量提交的形式，所以需要将，这样可以进一步提高的效率。

如果我们更新中带索引的字段时，会导致更新速度较慢，这种情况应想办法避免，如果不可避免，那就硬上吧 


部署
提供一下连接和所需要的包的配置：
  
    
    
    


    
    
    


    
    
    


  
    
    
    


    
    
    

参考文献：

   
介绍
 下操作  新 
开发快速入门
实时数据处理示例
  中使用连接池操作数据库


相关推荐
踩坑记——初试美国时间  月  日，亚马逊弗吉尼亚州数据中心出现单点存储区域故障，使得其云存储服务  出现了较高的错误率，造成长达小时的服务不可用。、 、、、雅虎网络邮箱等互联网服务受到明显影响。
亚马逊的本次『失误』也在警示业界所有云计算厂商，在云服务日益发展的今天，云存储的数据可靠性和服务可用性应该如何保障。当企业应对人为误操作、软件错误、病毒入侵等“软”性灾害和硬件故障、自然灾害等“硬”性灾害，应该如何实现稳定的容灾？如何实现高效的容灾？如何实现低成本的容灾？
腾讯云对象存储服务基于多年海量数据存储的经验，针对以上一系列问题，提供五个维度的解决方案：跨地域容灾，机房级别容灾，集群级别容灾，服务器级别容灾和磁盘级别容灾。
用户如何应对云厂商单点存储区域故障？
跨地域级别容灾：跨地域自动备份
目前腾讯云已经在华北大区，华南大区，华东大区，西南大区和东南亚大区提供了数据存储服务，并且提供『主备数据中心』的解决方案。

用户可以选择将主站的数据服务保留在某一区域，同时在上千公里之外保留备份数据，腾讯云将代替客户将主数据中心的数据在短时间内自动搬迁到备份数据中心，当发生运营商网络大规模瘫痪或者大面积灾难来临，用户可以将服务指向备份数据中心存储区域，应对异常问题。
作为云厂商，腾讯云如何避免单点故障问题？
机房级别容灾：可用区物理隔离
腾讯云目前在每个存储大区配备了多个可用区，每个可用区之内配备多个机房。每个可用区保证一定物理距离，当发生爆炸，洪水等恶劣的物理情况或者小规模运营商网络瘫痪，腾讯云将自动调度数据的写入和读取，暂停灾难受影响区域的机房使用，保留存量数据不改变。在灾难过程中新的数据写入和读取，将迁移到同城的其他机房或者临近城市的机房，整体存储大区的服务不中断。同时腾讯云拥有跨机房跨可用区的数据冗余备份能力。
集群级别容灾：不同集群互为主备
腾讯云在每一个机房中会配备多个集群，每个集群可以提供完整服务，用户的数据块被分布在不同集群的不同服务器中。如果某个特定集群失去服务能力，修复方式如同服务器异常。该集群整体暂停数据的写入和读取，保留异常现场，将数据写入迁移到同机房的其他集群中，集群内部开始自动修复逻辑模块或者存储模块。在修复过程中，用户可以从其他健康集群中持续获取数据，服务持续可用。
服务器级别容灾：条带化打散数据
第一、腾讯云利用『条带化』技术，将多备份的用户数据分解成多个数据块均匀放置在不同服务器之间。第二，集群的中央模块会定时巡检每个服务器的每块磁盘的健康程度。第三，一旦检测出单台服务器出现异常，会停止对整个集群的数据写入，将数据写入迁移到同机房的其他集群中，然后集群内部针对异常服务器启动坏盘修复，如果修复失败，×值班的运维人员将人工介入，更换坏盘。在修复过程中，用户可以从异常集群中健康的服务器中持续获取数据，服务持续可用。
磁盘级别容灾：多备份数据冗余
第一，对于保存在腾讯云存储服务中的每个数据块，腾讯云都实现了『  备份』，即一份数据会存在多个副本或者校验码。第二，腾讯云利用底层磁盘的接口将其每个磁盘且分为多个扇区。采取『心跳响应』管理的模式统一管理所有扇区。服务器的中央模块会如同如『巡逻员』一般，周期性的巡检每个扇区的状态，保证扇区的健康。第三、一旦检测出部分扇区发生异常，会对停止针对该扇区的写入和读取，然后利用冗余数据对原有的扇区进行修复。在这个修复过程中用户仍然可以读取冗余数据，服务持续可用。
数据持久和服务可用是云服务厂商的生命线，只有完备的预案才能获得用户信赖。腾讯云对象存储服务向客户承诺的数据可靠性和的服务可用性。基于这五个维度的数据容灾解决方案，腾讯云数据存储已经向快手，芒果，等多家厂商提供可靠稳定的服务。
此外腾讯云即将推出离线存储服务，让用户以领先行业的极低成本享受到灾备数据的保护。
更多产品详情，请登陆腾讯云官网。

相关推荐【腾讯云的种玩法】跨园区容灾，升级不停服——高可用负载均衡集群实践   项目实战总结导语：本文用了从数学层面和代码层面，再结合一些通俗易懂的例子，详细地描述了回归主要涉及的原理和知识，希望对于机器学习的初学者或者有兴趣研究模型具体实现的同学带来一点帮助。

接上篇文章 《机器学习之数据清洗与特征提取》 我们知道了，机器学习中重要的一步是数据的分析处理。其简单的流程图如下：

上篇文章中我们了解了数据的预处理方式，今天我们聊聊，已经有了多维特征的数据，怎么得出我们想要的结论。这部分的内容无疑是机器学习的核心，这里我们会涉及怎么建模，建模后怎么求解模型等一系列问题。
方法论
说这些问题之前，我们先聊聊建模时候的一些方法论。和工作一样，一些方法论的建立能很大程度上提高我们的效率。在我们建模计算中，合理地假设总是必要的。

合理性： 假设是在常理上是正确的。比如说，我们要统计一个人的体重的区间。我们的取值范围要是取为  ，显示是没必要的。我们可以假设为  ，显然绝大多数人都在这个范围内，这样就能一定程度上减少我们的计算量，这在大数据处理是很有意义的。

简化性：举个例子，相信大家都见过这句话 “研表究明，汉字的序顺并不定一能影阅响读，比如当你看完这句话后，才发这现里的字全是都乱的”，这一定程度上反应了简化性的意义。我们说一句话的时候，其实词与词之间是有相关联的，但是实际处理的时候，我们可以酌情把部分当成独立来处理。这样做的结果就是在某个模型中 ”研表究明 = 研究表明“，至少在人眼中它还是过关的，哈哈。

发散性：还是举上面的例子，在一个”蒙蔽人眼模型“中”研表究明 = 研究表明“这个是成立，但事实上，我们对这个模型做的部分独立的假设缩得到的这个结论，并不一定只能用于这个模型。换句话结果的适用性往往会比你想象的更广。


什么是回归
这个相信大家都比较了解了，这里简单的提一下这个名次的意义。
看最开始那张大图，我们所有想做的事情都是围绕得出一个”结论“。而这个”结论“从数学上来说有不同的形态。
一种形态是比如说，下棋的时候，在的棋盘上，它最多有种选择，我们对每个选择计算它赢的概率，这种有种离散的结果的过程，我们把它叫分类。
而对于链家房子的价格，我们会根据房子大小、是否学区等因素，得出一个房屋的总价。这个总价的可能性在数学上来说可能是连续的。我们把这个过程叫做回归。
一句话就是：结论是有限的离散个数叫分类，反之就是回归。当然只是一种叫法而已！
线性回归
还是以预测房屋价格例子来引入，我们知道每个房子有很多个特征。那么我们可以开始第一个假设，如果排除其他任何因素，房子的价格会和房子的面积呈线性关系，房子的价格会和学区的好坏呈线性关系。怎么量化学区的好坏呢，再打个广告参考上一篇 《机器学习之数据清洗与特征提取 》，可以使用编码等实现 。考虑这个两个因素，我们认为房屋的总价和面积、学区好坏有这么一个关系：
寻找目标函数
先忽略什么是目标函数。对于上面的结论我们显然可以延展，对于维的特征，如果用线性模型来求解的话，有：

而对于某个特征 ，其实际值与理论值肯定存在误差，

此时，我们做第二个假设，我们假设每个特征值的误差都满足：独立、同分布。那么可以写成：

由于我们假设了误差满足独立同分布，因此由 中心极限定理 可知误差之和必定能满足一个均值为，误差为 的高斯分布。因此，对于误差，其概率密度函数都可以写出：

把误差代入上述概率密度函数中，其结果就变成，在指定下关于的函数。也就是这样：

这样对于个样本我们可以求它的似然函数，经过一系列化简后得到

求似然函数的最大值，前一项为固定值，因此我们提取后一项，得到一个关于的函数，我们把这个函数叫做损失函数或者目标函数，因此我们只需要求目标函数的最小值即可。目标函数会贯穿整个机器学习的几乎所有模型中，几乎所有模型都在找它的目标函数，有了这个目标函数就可以对进行求解了。

目标函数求解
方法一： 最小二乘法
先把目标函数写成矩阵的形式，由于是我们的预测值，因此在线性回归中它就等于，这样目标函数就可以写为：

对目标函数求梯度导数，求得的偏导为：


令梯度等于，这时候就可以求出的显示解。

方法二：大名鼎鼎的“梯度下降算法”
对于无显示解的函数，我们通常会采用此法。所谓梯度下降算法，就是使函数沿着负梯度方向，随着步长不断的迭代下降，直到不能下降为止。这样算法，肯定能使得某个函数能取到局部最小值不一定为全局最小。因此，跟随我们对梯度下降算法的认识，我们肯定需要几个步骤：、初始化变量，、找到梯度方向，、选择步长，、比较最近两次函数值决定是否继续下降。
对于线性回归，我们要求目标函数中的，只需要不断下降，找到使目标函数最小的。因此算法可以简单描述成这样，其中代表步长：

对于线性回归，我们对目标函数求梯度就可以得到：

好了有了这些算法，我们可以兴致勃勃的写代码实现看看效果。由于 库中已经包含了线性回归的模型，我们直接调用。这里我们采取个纬度的数据，看看其效果：

图：代码见后 ”无校正线性回归代码“
可以发现在阶以后准确性就已经很高了，但是在阶的时候曲线很明显发现了震荡。我们使用模型的目的是为了让模型来预测未知的数据，虽然阶的时候精度是的，但是带来的显然震荡的效果并非我们想要的。为了避免这种震荡，我们需要采取一些限制了。怎么限制呢？下面慢慢说来。
先看图中给出的各阶的系数结果如下：

可以看到，阶的时候为了保证拟合，模型被迫调大参数来配合模型的精度。这好比我们想要模型把一个数精确到，被迫地采用了  来拟合，而不是用  这样毫无震荡的来估计。所以我们要解决的问题，就变成了避免这种过大的参数问题。
怎么解决呢？一个最简单最简单的方式就是限定一下的大小。怎么限定呢？
如果直接把的平方和做加法，使它小于我们一个我们给定的数，这种限定方法的线性回归，我们把它叫做： 回归

而如果直接把的绝对值和做加法，使它小于我们一个我们给定的数，这种限定方法的线性回归，我们把它叫做： 回归

这种做法我们可以从一个图像来解释，以维的来举例子：

如图我们的可能在等值线的原点，但是它过大，已经超出另外限定圆的范围了，因此我们以做圆心，逐渐扩散到最先触碰到限定圆的那个点，以那么点来代替值。
对于维的也是类似：

由上引出的另一种方式，即是以上两中限定方式以一定的比例结合的回归，我们叫 回归
其表示方式为：
对于以上几种升级版的线性回归，代码跑出来的效果如下：

可以看到在经过限定后，曲线就几乎不再有震荡的效果了。
但是这里有引入一个问题，的值该如何去取呢，这个值不和任何样本、结论关联，所以是无解了。实际的做法可能是假设一个范围，然后在里面等范围地取一些值，然手从一系列值中选取效果最好的作为最后的。
到这里，大部分和线性回归相关的知识就已经完成了。
不过，文章未完待续。。。
附：无校正线性回归代码：

   

   
 _  
   
   
   
   
   
 

   

 ____ == ____
    = =
    
    _=
     获取个随机点 坐标
     = 
     =     
     = 
     =       
     声明是列向量
     =  
     =  

     模型采用线性回归，且是多项式的形式
     = 
         
         _=

     = 
    _ = 
    _=

     个点，最多只需阶就能拟合，把阶数留下来画图用
    _ =   
     = _

     为每一阶的团分配不同的颜色，画图用
     = 
          =
          
    _ =   

     = 线性回归

     画这个点
       = =

     对每一阶画出它的预测值曲线
        _
        ___=
         

         获取多项式的系数并输出
         = _
         = ：阶，系数为：   
         _

         把坐标分成分，分别得到其预测值，并相连绘制成曲线
        _ =   =
        _ =  

         模型的预测值
        _ = _

         模型的准确度
         =  
         = 阶，=   

         画这一阶的曲线
        _ _ = =_ = =

    = 
    
     =
     =
     =
    引言：有很多小伙伴应该会把腾讯云用作建站服务器、后端应用容器、自动化云计算处理程序的运行场所，今天我想突破这个思维，让变身面向大众的云桌面办公平台！
这里，我将介绍如何将腾讯云的操作系统变为系统。
关于如何压缩盘容量开辟新的分区压缩卷，详见度娘！在这里就不再撰述了。


准备工作——把你的换回系统、备份你的服务器数据，可以通过内网上传到进行暂存；、在腾讯云控制面板选择重装系统，切换系统到 。温馨提示：这里如果你是本地磁盘的，从系统切换到时可能需要提交工单来完成切换哦。

关键信息导出备用由于待会儿要新装的系统时微软官方镜像，导致其镜像内没有自动初始化程序。所以，地址等信息不会被自动配置。、你需要记录你的网卡配置信息如地址、子网掩码、默认网关、主备服务器地址等等；、然后通过类似于驱动精灵的驱动管理类软件备份网卡驱动程序备用，注意如果备份档案有压缩请先解压该驱动备份包，以防后续在新系统时没有解压软件导致无法解压腾讯云目前用的是基于虚拟化的虚拟网卡，该驱动默认不内置于微软原版镜像；、对盘进行压缩卷操作，腾出新的分区空间用于存放镜像和驱动备份档案如果你有数据盘，那么可以省略此步骤。

开始安装系统、下载官方原版镜像此步注意，不要使用镜像，在新的分区解压后直接运行启动安装；、在启动后会有提示执行安装时是否保留数据，请选择删除所有用户数据执行全新安装；、在安装过程中会重启进入  恢复环境继续安装过程，此过程远程桌面连接会中断。此时，请使用控制台登录继续观看系统安装过程并适时对自己想要修改的安装模式进行修改！每次重启的瞬间，会发生连接中断，重新刷新页面即可重新建立连接；、系统安装完成后进入桌面，会发现没有网卡驱动。此时，请找到之前备份的驱动包解压档案，并右键后缀名为的安装信息文件进行驱动安装部署。如果发生驱动强制签名校验不通过的情况，请关闭的驱动强制签名校验后重试。关闭方法见度娘！

恢复网卡配置信息把之前备份的网卡配置信息应用到系统网卡，开启远程桌面连接、在系统防火墙允许端口数据包通过，并为当前管理员帐户配置一个密码即可正常通过远程连接了。注意：如果想要免密登录，请自行配置本地安全策略！



相关推荐
【腾讯云的种玩法】在  上使用腾讯云  镜像加速构建
【腾讯云的种玩法】如何利用腾讯云搭建个人网盘导语：每天分钟，用去食堂吃饭的时间解决一个知识点。

缘起
笔者目前的岗位与机器学习无关，在学校时修过人工智能的选修课，其实浮于表面，没学到什么技能。在学校的时候一直挺喜欢下棋的曾经的李世石脑残粉一枚，去年火了一把，因此对机器学习产生了兴趣。看了几本书“入门”，“白话与”，各种公众号也经常推文章，但术语虽然是熟悉了，还是觉得好像隔着一层。后来修了三门板书小王子吴恩达的《 》，台大萌娃林轩田的《机器学习基石》与《机器学习技法》，才有种补上了点基础的感觉。
这个系列只是梳理下机器学习用到的部分基础知识，以及自己的管窥之见。有哪里说的不对的话，希望各位猛烈地怼我。
第一篇先列一些贯穿始终的点。
不适定
首先要提的是，机器学习的问题是不适定的。适定性问题要满足下面三个条件：
解是存在的
解是唯一的
解连续地取决于初值条件
我们用机器学习处理的问题，样本只是所有数据的一小部分，解不唯一，所以是一个 。
过拟合
我们用代价函数来衡量假设对训练集的拟合程度。如果我们有非常多的，通过学习得到的可能完美适应训练集，甚至代价函数为，但是进行预测时效果就不好了。这就是，过拟合。与之相对应的就是，欠拟合。
一般来说，我们的应对思路有两种：
减少可以手动选择保留的特征，也可以使用一些降维的算法，如，可通过发现相关度协方差高的特征，转换到低维空间。
正则化不减少，但是给代价函数加一个衡量参数的项，即 ，这样可以达到“惩罚”一些特征的效果。
神经网络容易过拟合。像线性模型的参数少，不容易过拟合，这也是它的主要优点。所以满足性能的条件下，模型越简单越好，这是奥卡姆剃刀告诉我们的道理。
凸性
我们在机器学习里经常要考察函数的凸性。这是因为凸函数只有一个极值，即“谷底”。如果我们的代价函数是一个凸函数，那么我们就可以通过梯度下降，逐渐逼近全局最优解，一点一点滑落到谷底。
画个示意图，比如在基于最小二乘法的回归算法中：其实我都差不多下定决心了：去应聘我们当地的培训机构做讲师。以我的条件，十拿九稳，除非他们瞎。甚至条件都想好了：工资嘛，将就一下都行，但是要自由点，我上完课就走人，或者做自己的事……
这就是在打自己的脸了，因为前两天我还信誓旦旦的讲：我为什么不做培训。现在算是明白了，当你咬着牙说你不会怎么怎么的时候，其实就是你很想做的时候。和走夜路唱歌差不多，声音越大胆越小。
没办法啊，人总得吃饭不是？而且，我觉得我还是蛮适合，或者有点喜欢做老师的？以我的条件，传奇的经历，我不去做老师，这是培训界的损失啊？我这是为中国界贡献力量，是不是……我越想越觉得顺溜，这绝对是一个非常非常正确的选择！确定一定以及肯定，对此我深信不疑！！！
想到就去做。
于是我风风火火开始准备简历的时候，手贱，一不小心就点开了这个培训机构的网页。画风是这样的：

墙都不扶我就服你！人才啊，高。
这文案，对付十八九岁的半大小伙子，那是一个精准啊！直击青春萌动的小心脏，然后就啪啪，啪啪，啪啪啪……
我展开了无限的瞎想。

我想起了差不多十年前，也是在这个种类培训班，我的同桌，一个戴着厚厚眼镜的小女生。
她无力的趴在课桌上，“听不懂啊……”刚才想歪了的同学自己去面壁，呵呵
“听不懂你去问老师啊！”我觉得很奇怪。
她扭头瞅我一眼，“全部都听不懂，怎么问？”

所以现在我就在想，假如我是老师，我站在讲台上，我怎么办，我会告诉这些孩子什么？想来大概是：
“学费这么贵，你们得认真学啊！凡是有不懂的，就要来问……”
有用么？怕是没什么卵用。如果这就有用的话，每个人都可以上北大清华了。我们读书的时候，老师不就是这么的苦口婆心么？结果呢？还不是要来上培训班。凭什么上个培训班你就变了性呢？！从此就好好学习天天向上，六个月后西装革履月薪八千……做梦呢，你！
扰人清梦，罪过罪过。何况还是个美梦。
哦？是谁说的，“他们愿意付钱给我，是因为我能给他们梦想！他们花钱买一个梦想，他们心甘情愿。”说得好有道理，我都不知道怎么反驳。好吧，我承认，我只是眼红，为什么收钱的人不是我。
所以我不是正准备改么？从头开始学，从一个培训机构的小兵开始做起……
然而，我不知道怎么面对那一双双年轻的眼睛，更不敢想象他们的父母，是如何的含辛茹苦。这些孩子的父母，大都没有见过世面——见过世面的人不好骗。那钱，是真正的搬砖、擦鞋、扫马路挣来的，是用红肿、皲裂、长着茧子的手指头一张张数出来的，是真正的血汗钱啊！
……
站在讲台上的时候，我怕我会心虚。
就在前几天，我做直播的时候，可能有些同学都看到了，一个网友问我“遇到合同诈骗怎么办”。合同诈骗？我被吓了一跳。仔细一问，居然就是一个行业培训纠纷。学校宣传的“包就业”兑不了现，一个班个人就个人找到工作，十几个人在学校门口堵门拉横幅……问我有什么办法，接下来该怎么办？
凉拌。
这些机构，玩这些套路已经玩得很溜了。合同上写的是“推荐就业”，推荐而已，白字黑字，你还能怎的？怕麻烦的，会找几个公司当“托”，先把你扔进去试用试用，但能不能留下来就看你自己了；更横一些或者更惨一些的，连这些表面功夫都懒得做……
果不其然，学校叫来警察，几下就把这些学生娃儿像赶麻雀一样的给赶散了。“你这是民事纠纷，不服的去法院，不能干扰人家的正常经营活动。再闹就请你进局子里喝茶……”
 
我也想过，能不能自己做个培训机构？有良心的那种。
但想想还是算了。
市场就是这样。难道只有你才有良心？能站着挣钱难道有人愿意跪着？难道那个美女老师的广告，不是被这个操蛋的社会给逼出来的？！
毕竟不再年轻不再天真。
我学法律的时候，以为可以“持法律之利剑，除人间之邪恶”；毕业了干着干着，我觉得法律管不了太多，但还是社会的底线；现在，呵呵，有些话不好说……；
他们说，教育是社会的良心。良心都被狗吃了吧？或者，有良心的人都被狗吃了，吃得渣都不剩。活下来的都是狼，一群饿狼。所以要狼性嘛，狼走千里才能吃肉！
如果我还傻乎乎的以为自己是振臂一呼应者云集的英雄，怕是还得像我当年做装修一样，赔得连内裤都没有，再当一次老赖了。
醒醒吧！你只是个喜欢做白日梦的傻子。
 
这篇文章本来写到这里就结束了，我没打算发，牢骚而已。而且我写着写着泪也流了气也顺了，该干嘛干嘛。不做培训也没关系，进企业呗，古人早就说了：世上不如意十之八九……
直到我收到了一条没头没脑的留言：

我一时没有回过神来。
然后，那一晚上，我睡不着了。
我想起了很多事。
我想起十年前，我一遍又一遍的读金旭亮老师《一个普通人的十年》，泪流满面。
我想起李安的故事，“安，要记得你心里的梦想”，想起我快要淹没在庸碌生活里的梦想，心底仿佛刮起了一阵大风。
我想起那年春节，我再一次开到多年未见的、我少年时代的偶像，看到岁月磨灭他所有的光芒，心里一遍又一遍的感叹，“可惜啦！可惜啦！他是本应该在历史上留下名字的人啊！”
我想起厚厚三本《曾国藩》，我唯一记得的那封信：“孟子曰“天将降大任于斯人也，必先苦其心志，劳其筋骨”，贤弟数十年来，已备尝人世艰苦，现正当年富力强，担当大任之时……虽然，老夫亦知，今日办事，千难万难。但古人说得好：世无艰难，何来人杰？”
我想起黎叔意味深长的笑容，“你这是碰到困难就躲，你得迎着困难上！”
……
其实，我应该感谢段亚东；我相信，这是命运之神给我的照拂：在我最软弱最迷茫最需要慰藉的时候，告诉我我存在的意义。
再给我一点点的时间，我还要再试一试。引言
当前，用户体验已成为一种新的产品价值。当技术实现不再是产品核心竞争力时，产品的竞争就是用户体验的竞争。而用户弹指间感知到的性能体验对于用户体验尤为重要。
移动互联网产品因为用户的手机型号繁多、手机操作系统版本不一致、版本难统一等问题，很难在开发或测试环节就完全解决掉移动的性能问题，这使得移动产品在运维过程中，不得不面对用户体验不优、性能不佳的问题。

 
如何让开发可以高效定位性能问题？让开发，测试，运维清晰的把控各个产品的性能状况？我们结合了当前业界商用的技术，实现了一套腾讯社交运维的方案。
是什么
  应用性能管理，它是一套集终端，网络，服务端性能管理方案。在这里，就不展开介绍了。
，专注于移动端的性能管理。既能监控定位性能问题卡慢，也能应用于日常的性能运营分析，提升产品用户体验。
监控方式
采用注入方式，实现业务方法粒度监听。在注入技术选型时，采用了类的注入技术，其注入效率，校错能力，学习成本，都比要好一些。
注入阶段
实现性能监控与功能开发零耦合。在编译阶段注入监控能力。对开发零感知。
 
特点

实现方法粒度的自动化注入监控；

采用插件化设计：各个特性功能能自由组合，以满足开发者定制化需求。


可以做什么
当前，我们利用的能力，主要从以下四个方面进行探索与实践：

 包大小分析
卡慢监控分析
启动性能分析
 核心链路性能分析

大小分析
一个，随着新功能的持续增加，其的大小也在不断地膨胀。 的问题，越来越困扰和限制着开发同学，影响某些功能的上线，同时，也降低了用户体验。
同时，运营时间越长，功能迭代  代码重构次数越多，“垃圾”代码就是没有被实际调用过的代码的数量就会越多。
由于代码量大，代码调用层次深，每个开发同学只负责部分功能开发。如果让开发同学人工去做全局“垃圾代码”的分析，显然，其难度很大，效率不高。
而的包大小分析，就是用来帮助开发同学，快速暴露这些“垃圾代码”，开发同学只须集中精力，针对梳理出来的问题代码，做进一步确认和清理即可。
包大小分析原理

会在类或方法中，注入一个唯一；内测环境部署，通过大量的自动化用例，过滤掉有调用关系代码；对未调用代码，进行重新注入，灰度外网，收集线上真实用户的行为。通过内网测试，可以过滤掉部分常用代码，从而减少因注入增加的包量；通过长时间，大用户量的数据运营，我们即可定位出无实际调用的代码。开发小伙伴即可集中精力在这些问题方法的确认及清理。
包大小分析应用场景
定位完全无调用或被引用的类粒度粗，清理方便；定位孤岛方法：即没有主调和被调的方法粒度细，清理全面；定位无调用的方法链路。
包大小分析特点
结合线下模拟测试行为大数据分析 ；结合线上用户实际行为大数据分析 ；性能消耗小 ；自动注入 。
开源工具  包分析
可能有同学，会罗列出一系列开源的工具，也可以很方便地甄别出这种无调用代码。
但对于有调用关系的一条链路一组方法，仅仅通过线下分析，无法判断其是否有被调用。我们只能利用线上大量用户的真实行为分析，更好地去判断和确认。
方法注入样例
 
通过一个唯一来上报，既避免了代码中敏感信息的泄漏风险，同时，也大大节省上报量。 
 –应用实例
  ，针对业务代码以及第三方包代码，采用类无调用分析类中所有变量或方法，没有被引用或调用。
内部测试阶段：
在内部测试中，由于机型，测试用例有限，分析结果是的类没有调用或引用。
 
灰度外网阶段：
在灰度外网用户后发现，所有类都被调用或引用。但类被调用次数少于次。由于灰度用户是，即的代码只有万分之二的用户有调用。针对这些，后续我们可以分析，调整这些类的启动加载顺序如：延时加载。

结论：

当前空间 ，不存在多余无调用类文件。
后续，在监控粒度上，我们会从“类方法”进行深层面的挖掘分析。

卡慢分析
在用户体验上，除了故障外，相信主线程卡慢负责与用户交互的线程，是用户最不能忍受的。
我们这里所说的卡慢分析，是指对主线程代码的卡慢监控分析。
工作原理
卡慢监控，实现对目标代码的“方法粒度”的注入、卡慢监听。
其本质，是在目标方法调用的前后，注入时间，进行卡慢监听及分析。原理图，如下：

卡慢分析全流程
 
、编译时，注入。
跟上面“包大小分析”的注入阶段一样：在编译后，实现监控逻辑注入。注入时，我们会根据当前注入方法的“主调方法被调方法”方法对，生成。同样，也是用于信息加密及节省上报量。
、卡慢监控
版本上线后，会监控目标方法线上运行耗时，出现卡慢，则触发卡慢方法上层全链路上报，同时上报当前基本软硬件等使用率等环境信息。
、后台，会根据上报的一组，进行链路还原。开发同学，可以针对卡慢方法，以及上层链路进行性能分析；
说明：上报的卡慢链路，还原了业务方法运行调用的过程。是一种轻量级的堆栈快照。其好处是避免打印堆栈的性能消耗。因为，在卡慢监控中，最消耗性能的就是打印堆栈。
、收集堆栈，辅助分析
若某些卡慢方法，通过卡慢链路没法分析定位出问题，可以将指定方法推送到指定用户上，收集线上用户指定卡慢方法再次出现时，对应的堆栈信息，用于辅助开发同学的分析定位。
卡慢实例
在主线程卡慢监控中，比较常见的案例是：主线程加载文件，底层读写，图片处理这些比较耗时的操作。我们优化的方案，通常是将这些耗时操作移到异步线程中进行处理。
以下是四个案例片断：
实例一
主线程进行查询导致卡慢。
平均耗时视图：
后台，会先统计卡慢链路的次数，计算链路中每个节点的平均耗时。
卡慢链路最后的两组数值含义：代码调用行号， 方法平均耗时。耗时单位为。
 
明细视图：
在明细视图中，我们会列出所有卡慢实例，以及用户基础环境信息。
卡慢链路最后的两组数值含义：代码调用行号， 方法耗时。耗时单位为
 
实例二：
主线程中加载文件引起的卡慢实例。
 
实例三：
在主线程中，加载本地文件导致卡慢。
 
实例四：
在主线程中，图片处理耗时比较大。
方法消耗了秒，，也另外消耗了秒。

卡慢的优势与不足
优势：

监控粒度：卡慢监控的粒度为方法。
性能消耗：卡慢方案，采用卡慢业务链路上报，是一种轻量级的业务堆栈，避免直接使用原生堆栈。避免了打堆栈的性能消耗。打印原生堆栈：，打印业务链路：。
数据上报：采用了的一组链路。而非堆栈信息。上报量小，不用加解密过程。
代码依赖：卡慢逻辑与业务代码完全解耦，对开发者透明，零感知。只是在测试，发布前注入。

不足：
，也存在不足。由于采用注入方式，会使的包，稍微变大。
以  注入进行全量业务代码时，其大小增长，增长率为。
方案：
若用户对大小比较敏感，可以采用部分注入分析。可以配合的包大小分析方案，做瘦身分析。
新特性
卡慢只是用于问题方法的性能优化。其实，对于一个产品，我们不但要关注及处理卡慢的问题，还需要关注应用常规的性能状况与监控。因为，这个性能波动，不会像卡慢那么明显。但是在一次次新版本迭代中，可以会让总体性能变慢。
、监听启动性能
我们可以将卡慢监控范围进行定制缩小，提供个性化功能：只监听启动方法。通过数据分析及比对，我们可以知道：每个版本的启动性能及变化；接入的各个产品在启动性能上的差异，让各个产品间可以相互借鉴与提升。
、核心链路分析
无论是产品，开发，测试与运维，都会想知道：一个中，哪些代码是属于核心链路？这些核心链路的性能怎样？每个新版本中，这些核心链路的性能是否受到明显的损耗？我们可以继续将卡慢上报范围扩大，上报全量方法。通过数据分析及筛选，我们可以挖掘出核心链路及其性能数据；
、延时加载
通过链路特性分析，我们也可以抽取出调用次数很少，非主场景调用的代码。对于这些代码，在启动加载时，我们可以使用延时加载。从而提升的启动效率。
对于以上常规性能分析，我们将在后续做单独的介绍。
最后
，是我们结合部门实际需求和理念，在移动端性能管理的一个新探索，新实践。不仅面向性能问题的定位，也应用于日常的性能运营分析。
简单分享在移动性能管理方面的一点思考及应用，希望大家打造好自己移动端的性能小船，关键时刻，不会说翻就翻。共勉！导语 每天分钟，用去食堂吃饭的时间解决一个知识点。

全目录
分钟梳理关系数据库基础知识一——三范式
分钟梳理关系数据库基础知识二——存储结构
分钟梳理关系数据库基础知识三——树
分钟梳理关系数据库基础知识四——两阶段多路归并排序
分钟梳理关系数据库基础知识五——查询优化
连接
本文复习下做等值时不同的连接方式与代价，通过粗略的估算给大家一个直观的认识。
假设我们有和两张表，现在要做。表的记录数设为，占据的块数设为；表的记录数设为，占据的块数设为。
嵌套循环连接
就是最简单的，以一张表的每一行记录，与另一张表的每一行记录比较。直接来两层循环。我们来估算下代价。
若从表的每行记录出发，那么最坏情况下，块传输次数是×=，搜索次数是=。
若从表的每行记录出发，那么最坏情况下，块传输次数是×=，搜索次数是=。
块嵌套循环连接
一个小小的优化思路是，我每次以块的方式处理关系，这样不就可以减少块读写次数了么。
若从表的每块出发，最坏情况下，块传输次数是×=，搜索次数是×=。与前面相比，思路上小小的变化造就了性能上大大的提升。
索引嵌套循环连接
如果连接的字段上有树索引，设每个节点有个索引项，表记录数为，那么树的高度就是，回表假设再加一次磁盘，此时访问次数为×=，每次访问都有一次搜索和一次块传输。咦，怎么用了索引反而代价更高了？大家注意下，这里只说了表上有索引，如果表上也有索引且有个选择操作的话，行数会大大减少。使用索引会比块嵌套要快得多得多。
好，今天就到这里。年也就到这里了。祝大家新的一年里都有好运气。：安装介绍
的安装有多种方式，它支持版本及以上或版本及以上。下面说明环境下的安装过程。
依赖的库比较多，至少需要依赖库有 ， ， 。而在不同平台环境又各不相同，所以在安装之前最好确保把一些基本库安装好，尤其是。
腾讯云有、多个版本系统，在这里分别介绍。

各平台安装简介

这种方法是一种比较简单的安装的方法尤其是对来说，你可以使用该方法安装，也可以选用下文中专用平台的安装方法。
是包含了常用的数据科学库的发行版本，如果没有安装，可以到下载对应平台的包安装。
如果已经安装，那么可以轻松地通过命令安装。
安装命令如下：
  


安装

最好的安装方式是通过文件来安装，，从该网站找到的相关文件。假如是版本， 位系统，那就找到‑‑‑‑_ 这个文件并下载，然后通过安装。

下载之后，运行如下命令安装：
  
  ‑‑‑‑_
即可完成的安装，其他文件替换文件名即可。

安装

到官方网站下载对应版本的文件，然后安装。比如 版本， 位系统，就下载_。

然后安装文件即可，命令如下：
  _
其他版本替换文件名即可。

安装

官方网站下载文件，，如当前最新版本名称是，下载后安装即可。
  

安装

同理，下载文件，利用安装即可。如 版本， 位系统，下载 ‑‑‑‑_，然后安装。
  ‑‑‑‑_

安装

从官方网站  下载对应版本的安装包安装即可。

安装

最后安装即可，依然使用，命令如下：
  
、、

依赖库安装

确保一些必须的类库已经安装，运行如下命令：
    
       

安装

利用安装即可，运行如下命令：
  
、、

依赖库安装

首先确保一些必须的类库已经安装，运行如下命令：
          

安装

利用安装即可，运行如下命令：
  
虽然腾讯云没有系统，不过在这里还是加上的安装。
 

依赖库安装

在上构建的依赖库需要编译器以及开发头文件，它一般由提供，运行如下命令安装即可：
 

安装

利用安装即可，运行如下命令：
  
验证
安装之后，在命令行下输入，如果出现类似下方的结果，就证明安装成功。

常见错误

_    =

包版本过低，包是一个提供兼容和的库，升级包即可。
    

__        

缺少这个库。什么是？“” 的全名是   ，通常指的是允许以一种语言编写的代码调用另一种语言的代码。而库只提供了最底层的、与架构相关的、完整的””。
安装相应的库即可。
、：
      
、
      

    

这是缺少加密的相关组件，利用安装即可。
   

    

缺少这个包，它提供了包的核心功能，利用安装即可。
   

    

缺少这个包，它用来确定文件目录，利用单独安装即可。
   

相关推荐
腾讯云主机环境安装爬虫框架过程
【腾讯云的种玩法】云服务器搭建爬虫环境
高性能高稳定云服务器一、基础知识
字符集
什么是字符集？顾名思义，字符集就是字符的集合这里的集合是数学意义上的集合。比如汉字字符集，英文字符集等。
 也是一种字符集，它包含了所有字符。
字符编码
字符编码是一套规则。是在字符与比特串之间建立对应关系的一种规则。
系列：，，，，
中文系列：，，，
其他：，，_，
特殊名词
不是一种编码方式。这是中使用的一个词，可以认为是一个地区的默认编码。在简体中文操作系统中， 编码代表  编码；在繁体中文操作系统中，编码代表编码；在日文操作系统中， 编码代表 _ 编码；在韩文操作系统中，编码代表编码值。
附一则笑话：
话说计算机是由美国佬搞出来的嘛，他们觉得一个字节可以表示个编码表示英语世界里所有的字母、数字和常用特殊符号已经绰绰有余了其实只用了前个编码。后来欧洲人不干了，法国人说：我需要在小写字母加上变音符号如：é，德国人说：我也要加几个字母Ä ä、Ö ö、Ü ü、ß。于是，欧洲人就将没用完的编码为自己特有的符号编码后来称之为“扩展字符集”。等到我们中国人开始使用计算机的时候，尼玛，个编码哪够？我泱泱大中华，汉字起码也得多万吧，就连小学生都得要求掌握两三千字。
国标局最后拍板：一个字节不够，那我们就用多个字节来为汉字编码吧，但是，国情那么穷，字节那么贵，三个字节伤不起，那就用俩字节吧，先给常用的几千汉字编个码，等以后国家强盛了人民富裕了，咱再扩展呗于是就产生了。
台湾同胞一看，尼玛，全是简体字，还让不让我们写繁体字的活了，于是台湾同胞也自己弄了个繁体字编码大五码。同时，其它国家也在为自己的文字编码。最后，微软苦逼了：顾客就是上帝啊，你们的编码我都得满足啊，这样吧，卖给美国国内的系统默认就用编码吧，卖给中国人的系统默认就用编码吧，卖给韩国人的系统默认就用编码，但是为了避免你们误会我卖给你们的系统功能有差异，我就统一把你们的默认编码都显示成吧。本故事纯属虚构，但“编码”确实只存在于系统。摘自：
二、   
属于字符集，不属于编码，里的编码指的是下面会介绍。
 不仅是一种字符集，并且还为每个字符分配了一个数字，范围是。所以，也是一种字符编码方法，不过它是由国际组织设计，可以容纳全世界所有语言文字的编码方案。
的文件头有两种：
大端模式为  
小端模式为  
三、常用编码
     
相信大家都知道吧？标准是个，范围是。

四字节。这个简单粗暴的将中每个字符对应的数字存在四个字节里面。范围是，不过通常使用的范围是。

四字节。的子集，范围是。

双字节。里的编码说的就是它了。它将中范围是的字符保存在两个字节中，其他字符没法编码保存。

双字节或四字节。
编码点分为个平面，每个平面包含个码位 ，而第一个平面称为“基本多语言平面”  ，简称，其余平面称为“辅助平面” 。其中“基本多语言平面”中之间的码位作为保留，未使用。只能编码“基本多语言平面”中的字符，此时与的编码一样都直接使用的码位作为编码值，例：“汉”在中的码位为，而在编码也为。另外，还可以利用保留下来的区段的码位来对“辅助平面”的字符的码位进行编码，因此可以为中所有的字符编码。
中如何对“辅助平面”进行编码呢？
的码位区间为，除“基本多语言平面”外，还剩个码位并且其值都大于或等于。对于“辅助平面”内的字符来说，如果用它们在中码位值减去，则可以得到一个的区间该区间中的任意值都可以用一个的数字表示。该数字的前位加上，就得到四字节编码中的前两个字节；该数字的后位加上，就得到四字节编码中的后两个字节。例如：
    这个字念啥？_
上面这个汉字的码位值为，减去得到二进制值为    ，前位加上得到，后位加上得到。于是该字的编码值为该值为大端表示，小端为。
  
 字节。
允许含，但通常不含。的头为   。包含全世界所有国家需要用到的字符，是的实现方式之一。
转方式：
第一种：从  到  范围的，是不是有点熟悉？对，其实就是标准码里面的内容，所以直接去掉前面那个字节 ，使用其第二个字节与码相同作为其编码，即为单字节。
第二种：从  到  范围的，转换成双字节。
第三种：从  到  范围的，转换成三字节，一般中文都是在这个范围里。
符号范围 | 编码方式

十六进制                   | 二进制

       

          | 

          |  

          |   

          |    
系列
编码是中国创造的编码方式。包括、、等，从字符集范围看，属于属于。
：单字节英文或双字节中文。
：单字节英文或双字节中文。
：单字节、双字节和字节。
双字节２是全角的二，单字节即的是半角的二。
高字节的最高位为则为，为则为中文。
年一共收录了个字符，包括个汉字和个其它符号。汉字区的内码范围高字节从，低字节从，占用的码位是=。其中有个空位是。
支持的汉字太少。年的汉字扩展规范收录了个符号，它分为汉字区和图形符号区。汉字区包括个字符。
年的是取代的正式国家标准。该标准收录了个汉字，同时还收录了藏文、蒙文、维吾尔文等主要的少数民族文字。从汉字字汇上说，在的个汉字的基础上增加了扩展的个汉字码，一共收录了个汉字。
简体中文编码表 

双字节，兼容。又称为大五码或五大码，是使用繁体中文正体中文社区中最常用的电脑汉字字符集标准，共收录个汉字

又叫，单字节。可以认为是的扩展。
怎么区分不同的编码呢？有头的，可以按照头区分。没有头的，只能按大量的编码分析来区分。神经网络基础
、神经元——就像形成我们大脑基本元素的神经元一样，神经元形成神经网络的基本结构。想象一下，当我们得到新信息时我们该怎么做。当我们获取信息时，我们一般会处理它，然后生成一个输出。类似地，在神经网络的情况下，神经元接收输入，处理它并产生输出，而这个输出被发送到其他神经元用于进一步处理，或者作为最终输出进行输出。 

、权重——当输入进入神经元时，它会乘以一个权重。例如，如果一个神经元有两个输入，则每个输入将具有分配给它的一个关联权重。我们随机初始化权重，并在模型训练过程中更新这些权重。训练后的神经网络对其输入赋予较高的权重，这是它认为与不那么重要的输入相比更为重要的输入。为零的权重则表示特定的特征是微不足道的。
让我们假设输入为 ，并且与其相关联的权重为 ，那么在通过节点之后，输入变为  。  

、偏差——除了权重之外，另一个被应用于输入的线性分量被称为偏差。它被加到权重与输入相乘的结果中。基本上添加偏差的目的是来改变权重与输入相乘所得结果的范围的。添加偏差后，结果将看起来像   偏差。这是输入变换的最终线性分量。
、激活函数 ——一旦将线性分量应用于输入，将会需要应用一个非线性函数。这通过将激活函数应用于线性组合来完成。激活函数将输入信号转换为输出信号。应用激活函数后的输出看起来像   ，其中 就是激活函数。
在下图中，我们将个输入给定为  到  而与其相应的权重为  到 。我们有一个给定值为  的偏差。权重首先乘以与其对应的输入，然后与偏差加在一起。而这个值叫做 。
 =Σ 
激活函数被应用于 ，即 ，并且我们会从神经元接收最终输出，如  = 。


常用的激活函数

最常用的激活函数就是 ， 和 
——最常用的激活函数之一是 ，它被定义为：
=  

 变换产生一个值为  到  之间更平滑的范围。我们可能需要观察在输入值略有变化时输出值中发生的变化。光滑的曲线使我们能够做到这一点，因此优于阶跃函数。
整流线性单位——与  函数不同的是，最近的网络更喜欢使用  激活函数来处理隐藏层。该函数定义为：  
=
当  时，函数的输出值为 ；当 = 时，输出值为 。函数图如下图所示：

使用  函数的最主要的好处是对于大于  的所有输入来说，它都有一个不变的导数值。常数导数值有助于网络训练进行得更快。
 —— 激活函数通常用于输出层，用于分类问题。它与  函数是很类似的，唯一的区别就是输出被归一化为总和为 。 函数将发挥作用以防我们有一个二进制输出，但是如果我们有一个多类分类问题， 函数使为每个类分配值这种操作变得相当简单，而这可以将其解释为概率。
以这种方式来操作的话，我们很容易看到——假设你正在尝试识别一个可能看起来像  的 。该函数将为每个数字分配值如下。我们可以很容易地看出，最高概率被分配给 ，而下一个最高概率分配给 ，依此类推……  

、神经网络 ——神经网络构成了深度学习的支柱。神经网络的目标是找到一个未知函数的近似值。它由相互联系的神经元形成。这些神经元具有权重和在网络训练期间根据错误来进行更新的偏差。激活函数将非线性变换置于线性组合，而这个线性组合稍后会生成输出。激活的神经元的组合会给出输出值。

一个很好的神经网络定义：

神经网络由许多相互关联的概念化的人造神经元组成，它们之间传递相互数据，并且具有根据网络经验调整的相关权重。神经元具有激活阈值，如果通过其相关权重的组合和传递给他们的数据满足这个阈值的话，其将被解雇发射神经元的组合导致学习。
、输入输出隐藏层     ——正如它们名字所代表的那样，输入层是接收输入那一层，本质上是网络的第一层。而输出层是生成输出的那一层，也可以说是网络的最终层。处理层是网络中的隐藏层。这些隐藏层是对传入数据执行特定任务并将其生成的输出传递到下一层的那些层。输入和输出层是我们可见的，而中间层则是隐藏的。 

、多层感知器——单个神经元将无法执行高度复杂的任务。因此，我们使用堆栈的神经元来生成我们所需要的输出。在最简单的网络中，我们将有一个输入层、一个隐藏层和一个输出层。每个层都有多个神经元，并且每个层中的所有神经元都连接到下一层的所有神经元。这些网络也可以被称为完全连接的网络。 

、正向传播 ——正向传播是指输入通过隐藏层到输出层的运动。在正向传播中，信息沿着一个单一方向前进。输入层将输入提供给隐藏层，然后生成输出。这过程中是没有反向运动的。
、成本函数 ——当我们建立一个网络时，网络试图将输出预测得尽可能靠近实际值。我们使用成本损失函数来衡量网络的准确性。而成本或损失函数会在发生错误时尝试惩罚网络。
我们在运行网络时的目标是提高我们的预测精度并减少误差，从而最大限度地降低成本。最优化的输出是那些成本或损失函数值最小的输出。
如果我将成本函数定义为均方误差，则可以写为：
=  ∑–，
其中  是训练输入的数量， 是预测值， 是该特定示例的实际值。
学习过程围绕最小化成本来进行。
、梯度下降 ——梯度下降是一种最小化成本的优化算法。要直观地想一想，在爬山的时候，你应该会采取小步骤，一步一步走下来，而不是一下子跳下来。因此，我们所做的就是，如果我们从一个点  开始，我们向下移动一点，即Δ，并将我们的位置更新为 Δ，并且我们继续保持一致，直到达到底部。考虑最低成本点。

在数学上，为了找到函数的局部最小值，我们通常采取与函数梯度的负数成比例的步长。
、学习率 ——学习率被定义为每次迭代中成本函数中最小化的量。简单来说，我们下降到成本函数的最小值的速率是学习率。我们应该非常仔细地选择学习率，因为它不应该是非常大的，以至于最佳解决方案被错过，也不应该非常低，以至于网络需要融合。  

、反向传播——当我们定义神经网络时，我们为我们的节点分配随机权重和偏差值。一旦我们收到单次迭代的输出，我们就可以计算出网络的错误。然后将该错误与成本函数的梯度一起反馈给网络以更新网络的权重。 最后更新这些权重，以便减少后续迭代中的错误。使用成本函数的梯度的权重的更新被称为反向传播。
在反向传播中，网络的运动是向后的，错误随着梯度从外层通过隐藏层流回，权重被更新。
、批次——在训练神经网络的同时，不用一次发送整个输入，我们将输入分成几个随机大小相等的块。与整个数据集一次性馈送到网络时建立的模型相比，批量训练数据使得模型更加广义化。
、周期——周期被定义为向前和向后传播中所有批次的单次训练迭代。这意味着  个周期是整个输入数据的单次向前和向后传递。
你可以选择你用来训练网络的周期数量，更多的周期将显示出更高的网络准确性，然而，网络融合也需要更长的时间。另外，你必须注意，如果周期数太高，网络可能会过度拟合。
、丢弃—— 是一种正则化技术，可防止网络过度拟合套。顾名思义，在训练期间，隐藏层中的一定数量的神经元被随机地丢弃。这意味着训练发生在神经网络的不同组合的神经网络的几个架构上。你可以将  视为一种综合技术，然后将多个网络的输出用于产生最终输出。 

、批量归一化 ——作为一个概念，批量归一化可以被认为是我们在河流中设定为特定检查点的水坝。这样做是为了确保数据的分发与希望获得的下一层相同。当我们训练神经网络时，权重在梯度下降的每个步骤之后都会改变，这会改变数据的形状如何发送到下一层。 

但是下一层预期分布类似于之前所看到的分布。 所以我们在将数据发送到下一层之前明确规范化数据。 

卷积神经网络
、滤波器—— 中的滤波器与加权矩阵一样，它与输入图像的一部分相乘以产生一个回旋输出。我们假设有一个大小为    的图像，我们随机分配一个大小为    的滤波器，然后与图像不同的    部分相乘，形成所谓的卷积输出。滤波器尺寸通常小于原始图像尺寸。在成本最小化的反向传播期间，滤波器值被更新为重量值。
参考一下下图，这里  是一个    矩阵： 

与图像的每个    部分相乘以形成卷积特征。  

、卷积神经网络——卷积神经网络基本上应用于图像数据。假设我们有一个输入的大小    ，如果我们使用正常的神经网络，将有     参数。并且随着图像的大小增加参数的数量变得非常大。我们卷积图像以减少参数数量如上面滤波器定义所示。当我们将滤波器滑动到输入体积的宽度和高度时，将产生一个二维激活图，给出该滤波器在每个位置的输出。我们将沿深度尺寸堆叠这些激活图，并产生输出量。
你可以看到下面的图，以获得更清晰的印象。

、池化——通常在卷积层之间定期引入池层。这基本上是为了减少一些参数，并防止过度拟合。最常见的池化类型是使用  操作的滤波器尺寸的池层。它会做的是，它将占用原始图像的每个    矩阵的最大值。

你还可以使用其他操作如平均池进行池化，但是最大池数量在实践中表现更好。
、填充——填充是指在图像之间添加额外的零层，以使输出图像的大小与输入相同。这被称为相同的填充。

在应用滤波器之后，在相同填充的情况下，卷积层具有等于实际图像的大小。
有效填充是指将图像保持为具有实际或有效的图像的所有像素。在这种情况下，在应用滤波器之后，输出的长度和宽度的大小在每个卷积层处不断减小。
、数据增强 ——数据增强是指从给定数据导出的新数据的添加，这可能被证明对预测有益。例如，如果你使光线变亮，可能更容易在较暗的图像中看到猫，或者例如，数字识别中的  可能会稍微倾斜或旋转。在这种情况下，旋转将解决问题并提高我们的模型的准确性。通过旋转或增亮，我们正在提高数据的质量。这被称为数据增强。

循环神经网络

、循环神经元 ——循环神经元是在  时间内将神经元的输出发送回给它。如果你看图，输出将返回输入  次。展开的神经元看起来像连接在一起的  个不同的神经元。这个神经元的基本优点是它给出了更广义的输出。
、循环神经网络——循环神经网络特别用于顺序数据，其中先前的输出用于预测下一个输出。在这种情况下，网络中有循环。隐藏神经元内的循环使他们能够存储有关前一个单词的信息一段时间，以便能够预测输出。隐藏层的输出在  时间戳内再次发送到隐藏层。展开的神经元看起来像上图。只有在完成所有的时间戳后，循环神经元的输出才能进入下一层。发送的输出更广泛，以前的信息保留的时间也较长。
然后根据展开的网络将错误反向传播以更新权重。这被称为通过时间的反向传播。
、消失梯度问题  ——激活函数的梯度非常小的情况下会出现消失梯度问题。在权重乘以这些低梯度时的反向传播过程中，它们往往变得非常小，并且随着网络进一步深入而消失。这使得神经网络忘记了长距离依赖。这对循环神经网络来说是一个问题，长期依赖对于网络来说是非常重要的。
这可以通过使用不具有小梯度的激活函数  来解决。
、激增梯度问题  ——这与消失的梯度问题完全相反，激活函数的梯度过大。在反向传播期间，它使特定节点的权重相对于其他节点的权重非常高，这使得它们不重要。这可以通过剪切梯度来轻松解决，使其不超过一定值。本文作者： 高磊

背景
当前互联网时代，技术门槛越来越低，人人都可以建立并生成各式各样，多元化、多样化的站点。
文档站点一般作为各行各业领域内的知识技术介绍及使用的资料站点，可提高资料的使用效率，保证资料的质量。
目前市面上有大致这么几款主流的文档生成站点，分别为、、等，可帮助用户快速搭建文档站点。
今天我们详细介绍下的使用文档及实现原理。
介绍
是由现饿了么前端团队的编写的一套文档站点生成框架，上已有 ，这款框架和其他框架如等相比，最大的区别就在于不是静态生成，而通过动态请求编译生成。
还具有轻应用、全文搜索功能、支持多个主题、兼容、支持等特性。
快速入手
提供了一个名为脚手架工具，通过这个脚手架工具，可以快速生成站点并部署到本地或远程服务器。
安装
  安装
   
初始化
  初始化将模板文件拷贝至下
  默认为若设置为，则将等资源文件拷贝到本地下的目录下
   默认为主题可选
 
 
|                  |
|                                             |
|                               |
 
部署服务
   初始化后，才能部署，否则会报出下方的
          
   默认为，若为，则部署后自动打开默认浏览器该站点地址
   ，默认为，可自定义其他未被占用的端口
 
 
|                   |
|                                             |
|                               |
 
经过这三步，就可以顺利的部署一个属于自己的文档站点了，不过要想一键部署一个站点，也未尝不可，下面让你快速掌握装逼技巧：
更快速——一键生成
原理及特点：

生成初始模板页面结构配置，若通过读取到配置文件，那么合并模板页面结构配置，若未读取到，则读取下是否有，并读取中的配置，若配置存在，则合并，否则用初始的模板页面结构配置。
文档通过服务端渲染输出
没有模式下的热加载，所谓热加载，即监控文件更改并重新加载浏览器对于部署在远程服务器上来说，最好别用热加载  一键生成文档站点
  默认为 需要加载的配置文件可自定义配置
  默认为可自定义其他未被占用的端口


|                 |
|                                             |
|                           |



源码解读  
初始化工作
在初始化的流程如下： 

首先通过、、、、等方法向对象原型注入方法和属性
然后初始化全局对象、、、，即挂载到对象之上。
加载完成触发回调事件 _

接下来我们看下在每个模块具体都干了些什么事情：

源码如下：
     {       为原型对象
  _ =   {
      = 
     =  || {}

       
       
     
       
        
       
       
     
  }
}
 
这里_方法依次由上至下调用了上图所示的方法，完成初始化工作。

这里定义了六个钩子函数，即、、、、、，钩子函数初始化为空数组。下面介绍下钩子的生命周期：

 仅在第一次初始化页面时调用。
 开始解析  内容时前调用。
  解析成  后调用。 和  支持异步处理，通过回调返回结果。
 路由切换后数据全部加载完成后调用
 首次初始化页面且加载完数据后调用。
 渲染完成后调用


引入用户自定义插件，即其设置的钩子函数，来替换默认钩子函数。

调用钩子函数，为当前实例。

设置路由模式，默认为，用户可设置为或。

 类似中的模式，使用  的  来模拟一个完整的 ，当  改变时，页面不会重新加载，支持所有浏览器，包括不支持    的浏览器。
 通过完成  跳转而无须重新加载页面，依赖   。 


这里主要为编译层，初始化编译器，重写了的一些标签编译方法，例如、、、、等，最终生成的实例，并添加到中注意：此时、和仅仅是模板实例，内容数据还未获取。

为切换的按钮绑定事件。

通过请求获取、、、的数据然后填充进实例中。

调用钩子函数，为当前实例。

源码如下：
    {     为原型对象
   = {}
}
我们看到，模块在运行周期中初始化仅仅定义了一个名为的原型对象的对象属性。

源码如下
     {     为原型对象，下面代码细节就不讲了，感兴趣的话可以一份研究下
    _ =     {
         如何插入， = |
        
    }
    _ =   {
         读取并解析配置，渲染
        
    }
    _ =   {
         滚动条滑动模块以及对配置项、的处理
        
    }
    _ =   {
         渲染内容处理上活动标签样式
        
    }
    _ =    = {} {
         渲染内容，首先调用钩子，然后将编译成，最后调用处理后返回最后渲染
         然后读取配置，若为，则执行内嵌脚本。若想执行外链脚本，需要引入插件
        
    }
    _ =   {
         渲染封面页
        
    }
    _ =   {
         渲染文档站点标题
        
    }
}

源码如下：
    {         同的所述
                                      记录上一次请求信息
    _ =   =  {
                                          强制结束上一次请求，加载、以及数据
    }
    _ =   {
                                          请求并渲染封面数据
    }
     =   =  {
                                          封装了一个方法用作路由切换的数据请求
    }
}

源码如下
     {         同的所述
   =   {         滚动到当前路由中=的块，并使的活动标签实时响应，获取活动标签
    
     
  }
}

源码如下：
    {
   = {     }
   = 
   = 
   = 
}
这里导出一个方法，里面主要暴露了四个全局对象，方便提供使用。

 对象包含了工具类方法、操作方法、请求内容方法、缓存处理方法
 为构造函数生成的对象，是对开源项目做了一些扩展性，自定义了一些如前文所述的标签编译方法。
 即如上所述的对象
  即开源项目，一个轻量级，强大，优雅的语法高亮库。

最后
好用之处就在于其提供了丰富的可扩展性，用户可以做更多想做的事情。除此之外，还提供了一些实用的功能也可查阅官方文档：

可将文档站点部署到 或远程服务器，若要配置到远程服务器的话且在模式下，可在手动关掉，因为它会单独开启一个端口服务来监控文件更改。
开发者的福利——可在写代码，来演示的
离线功能，虽然还没试过此功能，但感觉会瞬间让站点高大上起来。
服务端渲染，主要依赖的模块，官方示例直出。

若本文内容有不足或需要改正的地方，欢迎在评论区拍砖！

原文出处：社区对内核来说，读写要经过层层路径，才能真正读写硬盘。从路径来说，要经过 ，调度队列，队列，队列和硬盘，才能真正到达硬盘。
 ： 是内核提供的缓存接口， 的名字就说明内核是通过单元通常大小来管理。读操作首先在 查找，如果找到，就复制 的内容返回，找不到，才真正调用下层处理。写操作，  写到 就返回，真正的磁盘写，是由内核的内核线程负责
调度队列：
内核提供了四种调度算法，。每种调度算法都实现了一个调度队列，首先在队列中排序最简单，不排序，然后根据条件，决定是否到队列。从调度队列下发，涉及一个的概念。也就是说，调度队列通常处于阻塞状态，当执行操作时，离开调度队列，开始下发。是个循环动作，将调度队列的所有都尝试下发，直到不能下发为止。
总结一下，执行有下列条件：

第一个启动了三毫秒的定时器，定时器到了，会，开始下发

请求超过设定的限制缺省是，执行，开始下发

标志的，立即，开始下发。

标志的，清空调度队列后，执行，开始下发

一个执行完毕，也要队列。


队列：队列对应用关系不大。但是内核层对日志文件系统的数据，提供了一种 ，这个主要在队列实现。
队列：
是硬盘自身的队列。硬盘的队列叫。队列是由操作系统创建的，但是加入到队列的，是由硬盘来决定执行顺序。为了实现这个，队列创建在内核的内存中，然后通知硬盘，至于硬盘选择那个执行，是硬盘自身选择的结果。
硬盘
硬盘是硬盘内部的。如果打开硬盘的话，写硬盘的，首先是到硬盘，而非直接落到硬盘。
一 的回写逻辑
提供了四个参数来控制回写。在内核实现中，的回写策略控制还比较复杂。
但是简单一点说，内核缺省情况下，每秒钟扫描脏页，如果脏页生存时间超过秒缺省数值，就刷脏页到磁盘。

详细的可参考本人写的《 内核回写机制和调整 》一文。

二 数据下盘和一致性分析
从上文的分析，通常的写，到 层就结束返回了，并没真正写到硬盘。这样机器掉电或者故障的时候，就有丢失数据的风险。为了尽快下，系统又提供了一些措施解决这个问题。
_打开文件的时候，可以设置_标志，在 的写完成后，如果文件有_标志，立即开始将下发，进入调度队列。随后将文件系统的 数据也下发，然后开始循环执行操作，直到所有的写完成。和回写机制比较，_没有等脏页生存秒，就尝试立即下发到硬盘。
_本质就是下发，然后执行操作。_的几个问题是：

写 时候要把拆成的单元。回写也是每次写的页面，如果是大，就需要内核的调度层把的重新再合并起来。这是冗余的过程

每个都要立即，这样就不能实现的排序和合并。_的性能相当低。

如果多个进程并发写，不能保证写操作的顺序。队列根据硬盘磁头的位置和磁盘旋转位置确定执行的顺序。一般是 数据一起写，这样存在不同步的风险。

如果硬盘打开了，那么写只到硬盘就返回了。存在丢数据的风险。通常存储厂商都要求硬盘关闭。不过腾讯的服务器都是打开硬盘的。


_：打开文件的时候，可设置_标志。_不使用内核提供的 。这样读操作，就不会到 中检查是否有需要数据存在。而写操作，也不会将数据写入 ，而是送入调度队列。
_执行写的时候，会置_标志。这个标志在进入调度队列后，会执行一次操作。而不是像_那样，循环执行操作。
为了避免_每个写都要阻塞等待的问题，系统提供了和系统调用，可以让应用层自己控制同步的时机。
：将文件范围内，所有的脏页面都下发到硬盘。然后也要将脏的元数据写到 硬盘。如果文件的本身有变化，同样需要写到硬盘。
：和的区别其实很轻微。比如文件系统，如果文件的只有轻微的变化，此时不更新。典型的轻微变化是文件的变化。而在文件系统，和是完全一样的。不管是否轻微变化，都要回写。
和都是对整个文件的操作，如果应用只想刷新文件的指定位置，这两个系统调用就失效了。所以新的内核还提供了__来指定范围写。不过要注意，__是不回写文件的 。必须应用层保证 没有更新。
三 的回写逻辑
提供了四个参数来控制回写。在内核实现中，的回写策略控制还比较复杂。
但是简单一点说，内核缺省情况下，每秒钟扫描脏页，如果脏页生存时间超过秒缺省数值，就刷脏页到磁盘。
详细的可参考本人写的《 内核回写机制和调整 》一文。
四 内核的 
从上文的分析看出，内核没有为用户态提供保证顺序的，确定写到硬盘的系统调用。但是对于内核文件系统来说，必须提供这样的接口。比如日志文件系统，必须要数据落到硬盘后，才能修改元数据的日志。否则，出错情况下就可能造成文件系统崩溃。为此，内核专门提供了一个方式实现日志的准确写到硬盘。
文件系统的 ，意味着，这个 之前的写必须完成。同时，在 完成之前是真正写到硬盘，不是写到就返回，也不能有别的写再执行。为此，上文分析的 队列完成了这个功能。
当写从调度队列进入队列的时候，要检查是否是一个 。如果是 ，首先在队列中插入一个命令_，这个命令指示硬盘刷所有的写到硬盘。然后再下发 ，之后再插入一个_命令，指示硬盘将刚才的 真正写到硬盘还有一种方式，是通过命令携带标志实现不经过直接下盘。
五 总结
对于单一的存储系统来说，数据一致性，性能和可靠性是几个矛盾的指标。标准的内核在这方面也有些左右为难。比如内核在失败的情况下，一般会重试内核设置了次的重试。这样重试时间可能超过分钟，这对互联网系统的业务来说是不可承受的。如何找到合适点，平衡几个指标的关系，从操作系统最底层提升产品的可靠性和性能，是一项长期的任务。一、引言
本次腾讯社交广告算法大赛以移动广告转化率预估为背景，以移动广告为研究对象，预测广告点击后被激活的概率：，即给定广告、用户和上下文情况下广告被点击后发生激活的概率。由于我是一个数据挖掘比赛的新人，所以我就说一下我参加比赛的体验吧，和我们的一些结题思路吧。
二、初赛历程
数据分析：
每天的交互行为即点击数、安装次数即转化数、转化率如下图：

每天出现的用户数量、数量、种类数量如下图：
等等，数据的初始分析让我们更好地理解数据的分布，加深对赛题的理解。
特征提取：
类特征，统计特征，基于业务的特征以及一些。
类特征：年龄 性别 平台 联网方式以上的特征都采取编码
统计特征：用户 素材  广告主 广告位 站点集合 联网方式 运营商以上特征分别计算点击数，下载数，下载率
基于业务的特征：重复点击的情况不同年龄段重复点击的下载率
一些本题是一个用户下载率的问题，下载的主体是客户，所以要做细用户的特征，但由于每一天新用户这里的新用户是指之前没有发生过交互行为的用户占了很大的比重，所以之前对用户做的一些统计特征会变的很稀疏，起不到什么作用。但从业务的角度，当一个用户对某个发 生了多次点击行为，这个用户就会有更大的可能性会下载，所以我们可以利用这种业务的情况来做一些统计特征。举一个例子，之前对用户的年龄做统计特征时，发 现各个年龄段的用户的下载率都差不多相同，但对重复点击的这种行为做统计后就可以发现，不同年龄段的人下载率就会有比较大的差异，年龄比较小的人多次点击 的下载率就比较高，年龄比较大的人多次点击的下载率就比较低。其它的一些特征也是如此。
模型搭建
 ：、、、、 ： ：
单模型：，，，，等等我们都尝试过。目前来看基于我们提取的特征，单模型效果会好点。
模型融合：目前我们正在尝试的方式，其基本思路与方法为：训练过程：预测过程：
最后感谢一下大赛的主办方，为我们提供了一个锻炼并提升自己的机会！本文作者： 王少飞

启用硬件加速
 在的地址栏中输入回车

 滚动页面到地步，点击 ==显示高级设置==

 再次滚动到页面地步，找到 ==使用硬件加速模式==

开启硬件加速
 在的地址栏中输入找到==硬件加速的视频解码==，点击==启用==

完成上面两步后重启浏览器。

原文链接：性能测试内存性能及内存泄漏篇
数据源
占用内存的测试，要比的更为简单。 数据来源是。程序内存主要是两部分：和，就是我们平常说的堆，我们创建的对象是在这里面分配的，而是直接在上分配的，对于内存的限制是不能超过最大限制，否则。

图一信息
数据采集
与耗电数据的采集一致，直接继承基类，然后使用定时器来每隔秒运行一次____，调用来获取相关内存信息。如下图中，只收集了的数据，如果要具体分析和的内存信息，也可以将其数据单独过滤出来保存。在主路径的_中调用，保证在执行 自动化场景用例时，定时器一直在收集数据，直到_调用将定时器取消。

图二 内存信息收集逻辑
数据使用
评估一个使用场景是否存在内存泄漏，如从首页进入一个二级页面，我们只需要将这个操作封装成自动化，重复执行遍，即可获得如下数据曲线。只要数据曲线不是如下图中的灰色平缓曲线，则可以证明该场景是有内存泄漏的。

图三 内存泄漏示意图
同样，如果只提供上述的曲线给开发，定位问题也会比较麻烦，测试在内存泄漏的测试中，也可以多做一些。如果是内存泄漏，也可以使用  出一份文件别忘了先手工 。

图四内存
拿到文件后，可以导入 中查看，一般查看 占用最大的类，分析是否有内存泄漏，一个对象的   指的是该对象自身占用内存的大小。一个对象的   指的是当该对象被回收时 所释放掉的内存大小。由于该对象先前可能直接或间接持有对其他多个对象的引用，那么当它自己被回收时，被它所引用的其他对象有些也可能会被回收，所以这种情况下，该对象的   既包括他自身占用内存的大小，也包括所有被它直接或间接引用的某些对象占用内存的大小。

图五 使用 查看内存泄漏
 的分析不够强大，也可以借助来分析内存泄漏：更多内容。在链接内容中，可以关注下相关的内容，因为在中因为内存泄漏引起一般会跟图片有关，其他对象往往没有对象大，所以解决图片相关的内存泄漏是优先级非常高的。
笔者目前水平止步于此，后续将继续深入学习内存泄漏测试的相关内容。

文章来源于：腾讯移动品质中心 导读
今天给大家分享一个通过改写而独辟蹊径的优化案例。
待优化场景
发现  中有下面这样一条记录：

 _   _   _   _   _ 

      
=  
___  =  
___     
     
实话说，看到这个我也忍不住想骂人啊，究竟是哪个脑残的狗设计的？
竟然把日期时间中的  和  给独立出来成两列，查询时再合并成一个新的条件，简直无力吐槽。
吐槽归吐槽，该干活还得干活，谁让咱是呢，优化是咱的拿手好戏不是嘛
优化之路
优化思路
不厌其烦地再说一遍优化思路。
想要优化一个，一般来说就是先看执行计划，观察是否尽可能用到索引，同时要关注预计扫描的行数，以及是否产生了临时表  或者 是否需要进行排序 ，想办法消除这些情况。
性能瓶颈定位
毫无疑问，想要优化，先看表以及执行计划：
  `` 
  ``     _
  ``     
  ``     
  ``     
  ``     
  ``     
  ``     
  ``     
  ``     
  ``   
    ````
    `` ``````````````
 = _=  =
     ``
       = 
        = 


        
=  
___  =  
___     
     \
   
            
  _ 
         
     
          
_ 
           
      _ 
           
          
      
              
明显的，这个效率非常低，全表扫描、没有索引、有临时表、需要额外排序，什么倒霉催的全赶上了。
优化思考
这个是想统计符合条件的列总和，虽然  列已有索引，但子句中却对  列加了函数，而且还是  和  两列的组合条件，那就无法用到这个索引了。
还好，有个聪明伶俐的妹子，突发起想事实上这位妹子本来就擅长做优化的，可以用   方法来改造下，改成像下面这样的：
  

    
              =        
                       
    
    = 
       
       
     
是不是很有才，直接把这个没办法用到索引的条件给用 来改造了。看看新的执行计划：
   
            
  _ 
         
    
          
_ 
           __
      _ 
           
          
      
               
看看这个的执行代价：

| _              |    |

| __         |        |
| __           |  |
| __          |        |
| __          |  |
| __          |        |
| __           |   |
| ___      |   |

及其  记录的信息：
 _   _   _   _   _ 
 _   _   __   __ 
 __ 
 _   _   _   _   ___ 
    __   _ 
   ___   ___   ___ 
   ___   __ 
   __ 
看起来还不是太理想啊，虽然不再扫描全表了，但毕竟还是有临时表和额外排序，想办法消除后再对比看下。
有个变化不知道大家注意到没，新的  记录多了不少信息，这是因为用了分支版本的插件才支持，这个功能确实不错，甚至还能记录的详细信息，强烈推荐。
我们新建个  列上的索引，看看能除临时表及排序后的代价如何，看看这个的开销会不会更低。
      _
    

    
              =        
                       
    
    = 
       
       
     \

   
            
  _ 
         ____
    
          
_ _
           _
      _ 
           
          
      
          
看看添加索引后的执行代价：

| _              |    |

| __         |        |
| __           |        |
| __          |        |
| __          |  |
| __          |        |
| __           |        |
| ___      |        |

及其  记录的信息：
 _   _   _   _   _ 
 _   _   __   __ 
 __ 
 _   _   _   _   ___ 
    __   _ 
   ___   ___   ___ 
   ___   __ 
   __ 
我们注意到，虽然加了  列索引后的  扫描的   更多了，但执行效率其实是更高的，因为消除了临时表和额外排序，这从  的结果中也能看出来，很显然它的顺序更多，随机更少，所以虽然需要扫描的   更多，实际上效率却是更快的。
后记
再想想这个还有优化空间吗，显然是有的，那就是把数据表重新设计，将  和  列整合到一起，这样就不用费劲的拼凑条件并且也能用到索引了。背景
是一个应用广泛的开源数据库，在腾讯云开发过程中，我们比较深入地对其进行了研究和应用，并和自研的等数据库系统做了一些对比，总结出了在运营中可能有的一些缺陷：
          数据存放在私有内存，升级版本和更新困难，且危险性高由于内部使用需要给源码内嵌一些自研的库或针对实际需求做一些源码修改，不能直接使用原生
        内存使用率低，碎片多
      备份、全量同步机制采用的方式，且对内存增长没有做控制，为防止，一般都需要留一半空闲内存
      死机恢复采用全量增量方式，如果数据量太大并且写量也足够大，有可能占用大量缓冲且出现反复失败的情况
        对于所有命令串行处理，有些慢查询如会阻塞其他命令
      存在大包回复时，可能会消耗一大块内存用于存放临时对象，且像上面说的一样会卡顿如命令等
    没有防雪崩之类的海量数据运营机制
通过总结等自研系统和的优缺点，以及一年多以来的运营情况，公共组件组认为的很多问题和其直接使用进程私有内存管理数据有关，若能像自研数据库一样做到数据逻辑分离，则不但能提高健壮性，对以后的改造也能提供一个安全的基础解决升级问题，以后再怎么改至少不会危及数据
于是，我们从实现方式入手，设计了一种综合二者优点的方案：将做成数据逻辑分离，数据存放共享内存，进程只负责存储逻辑，同时解决长命令卡顿和引发的相关问题
需求
主要技术需求有两点：
大数据要直接存放在共享内存，能直接进行数据结构的存取，操作速度在复杂度上要足够低
由于数据和逻辑分离，且有的需求，需要针对特定情况，开发对应渐进式存取的需求；同时由于不能使用来利用的机制实现精确快照，也需要其他算法；更进一步地，考虑到将来的发展，可能还需要考虑通用的渐进式存取，并发式存取等，原理类似，这里暂不涉及
内存管理机制
对于共享内存采用式的管理，类似的，将一块共享内存视作固定大小的数组，考虑到字节对齐，每个大小最好是的倍数，内存头部可以开辟一块头内存，存放一些元信息，也可以利用开头的若干来做元信息储存，下面的设计描述中不区分元信息和数据，仅将其看做以为单元的集合
注：由于是在共享内存中管理数据，因此不能用普通的指针来做数据之间的指向和关联，为方便起见，本文档下面描述共享内存数据的指向依然采用“指针”这个词，但是读者应理解为描述共享内存中相对位置的一个整数
共享内存形式和扩缩流程
由于需要实现内存的扩缩，而 的系列接口的共享内存对这方面支持并不好，因此选用的共享内存形式，具体地，就是在一般是在目录下创建文件，然后用的方式映射为共享内存，扩缩流程可采用文件操作：
 取消对文件的映射
 打开文件并执行操作，改变文件大小
 重新到目标大小
如此便可实现共享内存的扩缩容
实际上通过新建文件删除文件，还可以把当成是共享内存版本的和来用，但不推荐采用大量小文件的方式，频繁打开关闭文件，或者维持大量文件句柄都是比较耗资源的做法
申请和释放
的管理方式类似的，但是做了一些改进，和一样，通过将已释放的用链表或其他结构串起来，同时配合一个指针即可实现常数时间的扩容：

如图是一块共享内存空间，其中的格子为固定大小，表示存放着数据，可以看到，可以将空闲的串在一起，但是仅包含指针之前的空闲块，指针表示目前的内存最多用到的位置，其之后的内存块可能是新扩容出来或从上次创建就从来没用到的，全部是空
当申请一个时采用如下步骤：
 若指针不为，则从头部获取一个空闲，同时指针指向这个的 
 否则，说明里面没有空闲，此时如果指针没有达到内存尾部，则说明存在还未使用的新块，将指针指向的作为申请到的空闲，同时指针后移一个
 否则，说明本内存区已被用满，此时如果允许扩容，则使用前述扩容方法，扩充共享内存大小，然后执行第步骤，即可申请成功
 如果无法扩容，则返回无法申请资源的错误
可以看到，引入指针是为了减少扩容的消耗，否则的话，每次扩容需要将新的一批顺序加入，从而是的时间，引入指针则可将这个过程变成近似如上所述，新扩容采用 文件来做，只是页表修改，实际使用时才映射到共享内存，所以比较快的
释放一个则比较简单，直接加入即可，若采用单链表设计，则做一次头插入
缩容
上述过程只涉及到扩容，对于释放则是直接加入，如有必要，我们还需支持一块共享内存数据区的缩容操作，以避免在长时间运行后由于删除操作带来大量浪费内存的空闲，缩容操作策略一般可以在数据占有率即数据的数量除以总数量低于一定程度时进行，且应该是渐进式执行

  如图，假设此时我们需要缩容这块内存，即采用扩容的反向动作：
 指针前移
 通过前述扩缩步骤，缩小内存到目标大小即这个文件
主要问题来自于第步，由于指针前面的要么是存放数据，要么是中，因此需要先将其变成没有任何地方引用的，即自由空闲，才能前移，具体的做法：
 所有的块有一个标记，表示自己当前是什么类型在中，或者是在某种数据结构中
 如果前面的空闲，则将其从中摘除，为了实现快速摘除，不能是单链表，必须是其他结构，比如双向链表就可以实现的摘除操作；而如果是一个数据，则和具体数据结构有关，需要将这个从所属结构摘除，并从中得到一个新的空闲上图的红色迁移线路，由于这个就在指针前面，因此只可能往前迁移，将数据迁移过去并调整好和原数据结构的关系比如各种指针等，要保证这个过程足够快，数据结构必须支持快速迁移任意节点的功能，下述用于实现功能的数据结构都会支持
 由于是一个个缩减，因此是可渐进式进行的，指针的位置达到目标大小后，调用上述的扩缩容流程将整个内存区缩小，即可向操作系统释放内存
可能需要的改进：上图中，最右边数据的迁移是迁到指向的第一个空闲，但是显然我们将其迁移到更前面的空闲第二个是更优的一个做法，这样在需要大量迁移数据时可以避免重复劳动，每次都迁到最靠前的，要做到这一点，可以将改进为一个以为节点的平衡树，使得所有空闲按地址有序排列，这样一来就算在正常的申请释放过程中，也可以保证数据的前向聚集，在缩容时也可以实现更快的速度，只迁移必要的数据，而且有些平衡树结构的当右侧是连续的空闲时，可以通过的旋转来批量释放，使得指针一次前向移动若干块，来加速这个过程，所付出的代价是本身的实现复杂性，以及每次申请释放内存会稍慢一些
基于的基本数据结构
在上述共享内存中实现复杂数据结构存储，基本思路就是以为节点，将其组织为对应的数据结构，在一般的数据结构中，一个节点只包含一个数据，但是在以为节点的数据结构中，一个的大小是固定的，如果存放一个较小数据，则浪费空间，而较大数据明显也不可能在一个存下，因此，一个可能会承载多个数据，或一个数据需要拆分到多个存放
我们采用两种基于的数据结构：双向链表和平衡树，其节点是，数据组织形式设计如下
 
双向链表

如图，每个矩形为一个，若干构成一个双向链表，内部有一个独立的，用于存放类型、前后指针以及其他一些元信息，其中每个存放一个或多个数据，且数据在内部按序紧凑排列，例如上面的结构就相当于在普通的私有内存中，用一个有个节点的双向链表管理到一样，二者等价
如果一个数据比较大，就算单独占用一个节点也无法存放，则需要将其拆为若干份，比如一个超长的字符串，如图假设这个字符串是直接隶属于：

如果一个链表中的数据存在超长字符串，则链表本身可以只记录其指针，将字符串另外存放在链表中，如图假设这个是直接隶属于，由于过大，是单独用链表存储，然后对象中存储其指针，即带方框的：
这里，所有的实现都是双向链表，不能实现为单向，因为如上面缩容算法所述，需要从任意节点得到其前驱后继，用来做的迁移
链表操作
查询数据
这里只讨论一般的查询第个数据，从链表第一个开始遍历，中存放了本的数据数量，因此遍历时可以快速跳数量如果中没有存放，则需要分析本数据，当找到第个数据所在的后，用减去已跳过的数量，则为本中的相对位置，分析本的紧凑数据，取出即可；针对长字符串的查找第字节也是类似做法；由于是双向链表，倒数第个数据也可从尾节点开始往前用同样的算法进行
查找是否存在值为指定值的数据，则需要顺序遍历所有的所有数据进行比较，也是通过遍历进行，不再赘述
插入数据
通过中的查询算法找到要插入的位置，插入数据并重新组织数据，若因为这次插入而无法存下新组织的数据，则需要一次分裂过程：

如图，上面的一个节点因为插入了数据而导致数据放不下，于是新引入一个节点右下方红色，从原节点分出去两个数据，并将新节点插入链表，从而保证了插入过程成功进行
删除数据
通过中的查询算法找到需要删除的数据，删除掉并重新组织数据，若由于这次删除被清空，则将节点从链表中删除，归还
数据合并
删除数据操作中，如果一个没有被清空，则不会归还，当一个数据结构的数据经历若干插入和删除后，可能形成占用大量，但是很多中数据并不多的情景，这样会导致内存浪费，所以需要一个操作来合并一些，合并操作基本上就是上述分裂节点的逆操作，当一个被删除数据，没有被清空的时候，实时查看其前驱和后继，看是否满足合并条件，如果满足，则将两个合并，这样可以省下一个归还

如图，从中删除后，检测到左边节点由于数据量变小，可以和其后继右边节点合并，于是将右边节点的数据和迁移过来，并将右边节点从中删除，释放空间
合并过程的一些关键问题：
数据合并时机，可以采用每次删除时候都触发，也可以通过后台任务渐进式遍历检查来进行，前者实时性好些
合并操作触发的数据大小阈值，如果两个可以合并，但是合并后比较满，则很可能在下次插入数据时又重新分裂，所以可以定一个阈值，当合并后数据占大小仍然小于一定比率，才认为合并操作是有价值的
前向和后向合并，两个存在前驱和后继的关系，从哪个向另一个合并，也是需要考虑的问题，但在链表结构中这个问题不严重
如果不是删除，而是修改中某个数据，使得其数据长度变短，进而整个的数据打包后变短，可以和前驱或后继合并的时候，也适用合并操作，当然，如果数据被修改后变长，也可能需要分裂操作
数据分摊迁移
上面提到，链表操作在插入的时候，如果由于插入导致被处理的的新的数据大小超出限制，则需要分裂节点，但是在有些情况下，我们可以不用分裂节点，而是通过将数据向这个的前驱或后继移动来实现

如图，和上面插入的例子类似，由于插入了，导致左边的数据超出空间大小，与上面描述的申请新节点分裂和的方法不同，这里是将这两个数据迁移至后继节点假设后继节点空间足够，从而形成了下面的数据布局，不用申请新的
分摊迁移的时机可在每次需要分裂时进行判断，尽可能减少的分裂，从而提高内存使用率；同上述合并的情况，可以向前驱或后继迁移，具体如何做则看具体需求和算法了
如果是修改中的数据，数据长度变长的情况，也适用本操作
平衡树
和双向链表类似，用做节点，每个节点内部有多个数据方便起见这里只描述，则可以看做的一个附属数据：

如图，每个后面的字母可看做是的值，可以看到整个平衡树中数据是有序排列，只是每个节点可能存放连续的多个
同时，平衡树中每个节点还有一个属性，用来记录这个节点为根的子树中的的数量，通过这个属性可以对树中的数据求其排行，或者求第个数据，也能方便实现的之类的操作
平衡树中单个节点的数据存放，以及存放超长字符串的方案同双向链表，不再赘述
平衡树类别的选择
由于此处使用的平衡树是以为节点，因此和普通的二叉平衡树没有什么区别，可以任意选用，比如，红黑树，等都可以，具体的选择可能在效率、实现难度以及一些操作细节上有差别，需要看情况而定
为了能支持前面一节设计的内存缩容整理算法，必须能从树中任意一个节点得到和其相关的节点，因此节点必须有一个父指针指向父节点，这样也可以避免相关操作在编程上的递归方式
平衡树的操作
根据查找数据
类似普通平衡树的查找方式，但是由于每个节点可能有多个数据，而且我们希望在查找失败时并不仅仅告知失败，能同时告知这个需要被插入的位置，以便于接下来的操作
因此在做某个节点数据和待查询数据比对时，采用限定范围的方式，范围采用的左闭右开空间来表示，其中和都是，表示可能在这两个所表示的区间中，显然应该是的前驱直接或间接
一开始查找时，将区间设置为，和是两个特殊值，类似数学中的正负无穷，表示到树的开头和虚拟的结束即最后一个之后的一个假想的节点，从树根开始查找：
若小于当前节点的第一个数据，则区间中的更新为本节点，之后在左子树递归查找
若大于当前节点的第一个数据，则区间中的更新为本节点，之后在右子树递归查找
若等于当前节点的第一个数据，则立即返回查找成功，以及本节点
步骤和中，若被递归的子树为空，则判断当前区间，在区间内部的的所有数据中依次找此时区间中的数量最多为，若找到则按步骤进行返回，否则返回查找失败，以及可以可以插入的节点
举例说明：

如图，假设我们要在这个平衡树中查找 ，步骤：
初始化区间为
和根节点的第一个数据 比较，由于，更新区间为 
在的左子树查找，和左子树的根节点的第一个数据 比较，由于，更新区间为 
在的右子树查找，和右子树根节点第一个数据 比较，由于，更新区间为
在的左子树查找，由于左子树为空，则区间结果就是，这个区间仅包含一个节点，在这个中顺序查找 ，找到后返回；若 并不存在于上面这棵树，则步骤返回，表示 可以插入到中
根据排名查找数据
由于每个节点的属性保存了当前节点为根的子树的数据数量，根据就可以实现的查找第个的算法，从根节点开始比较
定义：简单起见，对于每个处理到的节点，下面用表示当前节点的，左右子树的分别是和，若某个子树为空，则为
判断的合法性，假设名次从开始，则范围是==，若不合法则根据具体情况返回相应的结果
若=，则在左子树查找第个数据
若，即比左子树和当前节点的数量总和还要大，则在右子树查找第个数据
若和步骤条件都不符合，则说明第个数据就在当前节点，遍历当前找到第个数据即可
由于步骤中已经判断了合法性，因此一定能找到一个数据并返回除非数据已损坏，字段出错
举例说明：

 如图，假设我们要查找树中第个数据，则流程如下：
根据上述步骤的，根节点为，==，因此输入合法，从根开始处理
的左子树是，根据上述步骤的，问题转化为为根的子树查找第个数据
的左子树是，右子树为，根据上述步骤的，继续在右子树中查找第=个数据
没有子树，因此左右子树均为，根据上述步骤的，数据就在这个，顺序查找到第个数据，返回 ，结束
插入数据
通过中的查找算法找到数据可以插入的假设数据不存在，之后遍历解析出内部数据，将需要插入的数据和原数据合并并保证按有序，再写回，如新数据过大，则按照上述双向链表中插入后分裂节点的算法，新申请节点，分裂原数据并将新插入至原的后继位置
插入数据后，需要调整插入到向上树根的路径的所有节点的
的分裂过程也适用上述链表的数据分摊迁移算法，不再赘述
删除数据
通过中的查找算法找到数据所在，然后从中删掉此数据即可，若因为这个删除操作变空，则调用节点删除流程将其从树中摘除并释放到
删除数据后，也需要调整插入到向上树根的路径的所有节点的
和链表一样，删除操作也适用合并的算法，不再赘述
从平衡树删除一个数据的时间复杂度是，而连续删除个数据则是，但是，如果需求是删除平衡树中一段连续数据比如的的，则可以通过的旋转，将这段数据旋转为一棵独立子树，然后将其从原树摘除，再用时间来释放空间，整体操作复杂度，不过只有少数平衡树比如支持这样做，可以作为一个优化点的跳表也是支持这样搞的
节点插入删除  平衡树旋转调整  查找最大最小值  查找节点前驱后继
这几种操作与普通的二叉平衡树没有什么区别，针对节点进行，唯一的区别可能在于旋转过程中的调整有些差别，本设计不再赘述
数据结构数据存取
有了上述基于的数据结构设计，对于的各种数据结构就可以比较方便地实现了，需要注意的有几点：
长的实现，上面的例子是用链表，而的还需要实现和的相关功能，所以用平衡树可能更好一点
长的中是一个字符串片段，域表示的是字节数
为省空间，短可以用各种压缩存储的方式，比如像对于整数做特殊处理
、、和都可以用平衡树，但各自有一些区别：
          是普通的映射，没有域，的域是一个类型的
        每个需要两棵树，第二棵是映射，按的值排序，一致的时候按的字母序
      的实现特殊一点，每个不仅对应一个，还需要存储一些元数据，比如创建时间，信息等
接《在共享内存实现 下》作者：

首先要解释一下为什么叫浏览器自动化测试，因为本文只关注发布后页面功能的自动化测试，也就是层面的自动化。
浏览器测试有别于代码的单元测试，后者一般是发布前的代码功能逻辑测试，在这方面已经有很多比较成熟的方案，如  
为什么要做自动化
个人认为自动化测试的主要出发点有两点：

减少重复的工作。让机器自动帮我们完成需要的交互操作，验证我们的页面功能。

自动监控。通过自动回归我们的页面功能，可以在功能出错的时候提供报警，为我们手动排除问题提供参考。


开胃菜
说到浏览器自动化测试，不得不介绍大名鼎鼎的及。可以理解为一个无界面的浏览器，可以通过流水线式的代码来驱动其页面的浏览行为，而后者是前者在易用性上的一些封装。
这里演示下使用截取百度首页

关于这两个东西的安装，有兴趣体验的建议去看官方文档，其实很简单，这里不一一赘述。

首先创建一个文件：
  = 

   {
     
}


以上代码主要做了三件事：

创建一个实例，可以理解为一个浏览器进程

打开一个页面；

截取页面图像


在命令行运行
 

看看此脚本生成的图片结果
等等！为什么这个图只有的大小？
原因是我创建了一个浏览器进程去加载页面，但是没有指明用什么浏览器去加载。所以在创建实例的时候，可以指定浏览器的窗口大小，甚至我们可以通过指定的方式冒充手机端的浏览器。例如我们将其指定为的，并设置窗口大小：
  = {
     {

         冒充浏览器
              _            
    }

     浏览器窗口大小
     {
         
         
    }
}

再次运行后我们的是这样，是不是手机浏览时的样子了？
简单应用
以上的例子，可以知道了怎么使用一个无界面的浏览器去加载页面，并获得页面的界面截图。
我们可以不打开浏览器，一行命令就可以知道页面长啥样了，所以每次我们只要运行这个脚本，通过截图就能看到我们页面是不是正常的。
但是，通过肉眼去判断，肯定是有违“自动化”的初衷的，所以必须要借助工具来帮我们分析。
最简单直观的办法就是“像素对比”，也就是把两次或多次的截图，逐一对比每一像素或一定范围区域，这样就能产出图片的差别了，如下图：

实际应用中，可以指定一个图片作为基准图，每一次我们截取的页面图与之对比，如果不一样，就可以说明线上的页面出现了异常。
像素对比这样的工具已经比较成熟，这里介绍一个与前端开发非常亲近的方案：。
为什么说它和前端亲近，因为它使用的是。我们知道，每一个图片的每一像素，都可以通过三个值来确定：

的主要原理就是把我们需要对比的图片绘制到中，读取需要对比的像素点或区域的 ，从而确定图片的差异。
为了与更好的结合，作者同时做了基于的封装。
使用了简单的来做图片对比：
   
   
 

假如对比的图片有不一致的地方，会生成一张对比图，同时有差异的地方会用显眼的颜色标出，类似这样：
注意

页面截图对比出现不一致，并不能证明我们的页面就出现了异常，例如广告位等，这些变化频繁的区域，每一次对比都有可能出现差异，所以对广告位或其他经常变化的位置不宜所差异对比。实际应用中，对整个页面进行截图对比是不推荐的，这样的方式过于简单粗暴，我们更应该对页面的各个区域进行细分对比，做细粒度的监控。


既然是浏览器测试，不能没有的参与，没有对的操作作封装，可以使用直接“种”：
{
     
     
     
     
     
     
               
}

在前面的开胃菜中，我们访问到的页面都是没有登录态的，这里通过手动植入百度帐号登录态的值来实现登录访问。
在端中打开百度首页，并用你的帐号登录，在开发者工具中复制百度帐号关键 的值

并 到你的脚本中：
{
     
     你复制的值
     
     
     
     
               
}

完整代码看这里运行之后我们再看一下结果

右上角已经有用户名，说明此时我们已经登录了！
交互
简单的截图对比还远远达不到我们的测试要求，对于自动化原则来说，为我们实现自动化的页面交互才是王道，别急，这就来。
前面介绍了手动种植的方式实现登录，下面看下怎么实现手机端百度的登录过程。
先预览下整个脚本的代码，下面解释一下整个过程：
 创建实例。与开胃菜中的配置基本一致，这里为了更快，实例化的配置选择了不加载图片
 

 加载页面
 截取无登录态的页面：
 

 这一步会得到图片，并且右上角是没有用户名的未登录：
 读取当前的所有并输出
  = 
   =   =      {
         
}

这一步输出到命令行的结果：
可以看到，当前的中还没有百度账号的关键 。
 点击登录按钮


支持了非常丰富的可以支持复杂交互的鼠标事件：








鼠标事件支持指定操作目标的路径
 点击登录后，会跳转到一个填写用户名和密码的登录页，这里为了方便，强行等待秒确保登录页加载完


 截取登录页界面
 

 填写表单
  {
    = = 
    = = 
}

这里使用了一个非常有用的方法。
 截取填写登录表单后的样子
 点击登录按钮
 等待跳转回首页
 截取登录后的首页界面
 逐一读取并显示到命令行中
最后，运行测试脚本 能得到张截图，分别记录了整个登录交互过程中关键步骤的交互效果：

：未登录
：登录页
：填写信息
：登录成功

对比图和图，区别在于图右上角的用户名：

同时，在命令行中最后还读取到了登录后的 值：
再来点猛料

里的操作

不仅可以在当前页面操作，还可以把当前切换到里进行操作，这点给嵌入的页面测试带来了很多方便。

操作区域

支持使用选择器及的方式对我们需要操作的目标进行操作点击、截图等，还可以通过指定区域边界的来操作例如可以指定坐标来进行点击或截图等：
 {
     
     
     
     
}

交互的一些局限
现实世界的里，有些交互功能不是机械的操作，有时候出于安全或其他因素考虑，页面会做一些限制，要求我们的交互需要根据一些动态输出，这种功能是很难做到完全自动化的，例如，上面的百度登录功能，有时候会出现验证码的情况：

这时候就很难借助机器来帮我们做登录了，所以在前面我要介绍通过手动植入的方式实现登录。
单元测试
通过前面的介绍，使用已经能实现很多自动化的功能，在此基础上，实现单元测试就很简单了。
提供了相对比较完善的单元测试
单元测试中，每一个都被包装在一个闭包中：
     {
     单元测试代码
}

例如下面是一个测试百度页面及位置是否正确的一组测试用例：
     {

    

       {

         测试页面是否正确
        百度一下  

         测试的位置信息

         获取
          = 
         = 

         验证是否符合
         {} \ 

    }

      {
        
    }

}

完整代码在这里
运行  
可以在命令行中看到以下输出：

两个都已！
与前面的截图肉眼查看的方式相比，单元测试为我们提供了更加简洁的测试结果。
另外，的模块还可以在测试后产出结果，例如上面那个例子的结果如下：
 = = 
 =
     =  = = = =
    = =
         =  = =
        
         =  = =
        
        
        
    


利用这个结果，与报警等系统结合，可以实现各种强大的自动化功能。
问题

浏览器兼容。说到底，提供的还是一个无界面的内核浏览器，所以无法覆盖浏览器。目前内核的无界面浏览器已经有解决方案并且支持与一模一样的。

设备兼容。在各种手机等终端设备良莠不齐的情况下，服务端的无界面浏览器在这点上更难以做到模拟所有的软硬件环境。



原文链接：适用范围本文主要针对中小型互联网公司，特别适用于手机或者的后台架构，基本可以支撑万日活本文会对可能用到的相关技术进行技术选型的说明，以及技术的架构介绍，技术架构的介绍课程后面有地址，可以点进去查看。
技术指标说一下一些技术指标的计算过程可以作为其他同学的参考， 如果是万日活，使用集中在每天的小时，每个用户大概产生的请求，那么平均下来，我们系统大概应该支撑的请求为：         =  业务数据 业务量，我们自己是新闻业务，可能会有其他的业务，比如游戏，商城等等，基本每天新增的业务数据都会在同一个量级， 每日， 另外跟用户相关的信息也是比较大的一块，比如用户的订阅等行为，一共万的用户，保存相关信息可能大概需要条的数据。缓存大小 主要业务数据和用户相关的热点数据限时保存在缓存中， 大概需要个左右。日志大小 用户日志和请求日志。 大概每天个左右
技术架构整体架构因为是小公司，我们基于阿里云来搭建，对图中的内容和技术选型进行一下说明：
负载均衡可选方案：  要收钱，但是比较便宜，有保证，不会挂。 但是可配置的很少，不能根据域名做映射 没啥缺点，需要一定的知识。建议：    绑定域名作为统一的入口，然后每个服务器上再搭建
用于缓存静态文件等等。 七牛和阿里的都还可以。七牛要做的久一点， 各种图片处理的接口要完善一些阿里的要稍微好一点点， 但是没有不安全的访问方式，访问稍微没有那么灵活。 图片处理功能弱一点。分布式调用框架目前可选的有         。 阿里的服务治理框架，已经不维护了，切换反应有点慢 当当基于搞的，还在维护可以一用，推荐。 微博的服务治理矿建， 刚开源，需要学习一下， 推荐。 阿里云服务，要收钱，侵入型很强，不推荐
可选的有：  ， 各有好处， 但是考虑到运维的难度，推荐。
用来做缓存， 自建成本有点高，需要 分片，集群，主从等等，很麻烦。 建议直接用阿里的数据库主要基于读写分离和主从复制考虑，目前可以自建和选用阿里的。 要花钱，成本较高，没有必要自建， 不用中间件，直接写只读， 然后配置读写分离的数据源，内网进行读集群。解决之。
搜索建议， 可以自动同步数据库，除了搜索引擎的功能外，还可以做日志搜索，监控系统。一些典型的业务场景说明把业务底层做成模块，通过分布式调用框架对外提供服务。后期进行到微服务的改造都会涉及。单独做一个小的系统来运行定时任务热点数据放缓存，然后通过来更新缓存日志等数据有必要可以考虑上个
架构师之路：作者：莫家文，腾讯事务型开发工程师
商业转载请联系腾讯获得授权，非商业转载请注明出处。
原文链接：

 导读
全新的全局流控实现方案，既解决了目前流控的实现难点，同时保证运行稳定且流控准确的前提下，实现更简单，部署成本更低，容灾能力更强。 该方案组件化之后，可以推广到别的有需要的部门使用，只需简单的接入和部署即可获得全局流控的能力。
一、背景
流控作为容灾体系中必不可少的一环，在请求量超过系统容量的时候，通过拒绝超量请求的方式，防止服务接口的雪崩和系统挂掉。
目前部门只具备单机流控的能力，随着业务的增长和系统复杂度的增加，单机流控越来越不能满足需要，升级流控能力日趋重要。
一流控分类
升级流控之前，先简单了解不同流控方式的优缺点：
对比可知，全局流控能能弥补单机流控的缺点，而动态流控又是在全局流控的基础上做更精细化的流控。
二现有方案分析
目前全局流控方案主要需要解决两个实现问题：
、全局计数器使用何种存储
全局计数器存储可以使用，也可以使用。
分布式流控很关键一点是将流控服务做成原子化。而做流控需要记录两个信息，计数和计时。比如全局流控阈值设置了的值，计数器记录了当前的请求数计数，在达到时计数器需失效或清零计时。
计数和计时要保证原子操作，目前已知的方式有：
使用加锁的方式，比如的计数，或者技术，但在并发量大的时候，加锁的性能比较无法保证；
使用的方式，由于目前和的都没过期时间设置，要满足要求计数和计时同时原子操作，需改造或，使得支持过期时间设置，目前已知有改造支持过期时间的案例。
、 如何上报请求
一般统计的方式分两种：
  请求全量上报，这样要求存储的访问能力足够强大，优点是流控实时性得到保证；
  请求定时批量上报，这样存储的访问压力较小，资源消耗也更少，缺点是流控可能不实时；
一般还需要每台机器部署来完成上报和流控判断，业务模块与之间要实现通讯。
大体的逻辑结构如下：
注：图片来自文章《全局流控介绍》
实现难点：
将流控服务做成原子化，目前无论使用还是，加锁方式并发下无法保证性能，原生的方式要解决过期时间的问题，需要的技术门槛和开发成本都比较高；
从上报统计方式看，全量上报对请求量巨大的业务部门来说不大可行，定时批量上报又无法保证实时流控；
接入全局流控每台机器都需要部署，能否正常工作影响全局流控的使用，同时部署及运维的成本不低；
二、方案设计
面对目前困难，我们提出这样的疑问：有没有一套简单可行的方案，能解决上述问题的同时，保证开发成本较低，部署简单，运行稳定，而且流控准确的呢？
一轻量级流控方案
方案要点：
、计数器的能“计时“
首先选择使用作为计数器存储，相比开发会更熟悉，同时维护也更容易，当然该方案也可以选择作为计数器存储。
既然使用的用作计数在高并发下有性能瓶颈，那么只能使用的方式，同时要解决计时的问题。
方案没有对增加过期时间的方式，而是将时间信息写入，把一天按时间划分比如划分一个为若干个作为计数器。这样每个既能使用方式计数，同时也有”计时“的能力，当超过划分时间比如后，就顺移到下一个上做计数。
优势：方案用简单的方式将全局流控服务做成原子化计数和计时原子化，开发门槛低。
、请求统计用拉取的方式替换上报
对于请求的统计方式，一般全量上报不可行，所有业务的请求量至少：上报到，的容量和是个问题，单也容易成为热点。定时或者定量批量上报，都无法保证实时流控，特别是请求量大的时候，流控延迟的问题会被放大。
方案抛开原有的上报思维定式，引入配额拉取的概念，替换一般统计上报的方式，取而代之的是每个初始化时写入流控阈值，每个业务机器并非上报请求量，而是访问拉取配额到本地保存，本地配额消耗完毕再次拉取，类似余库存扣减。
优势：方案减少的访问量，同时保证流控的准确性。
、部署不需要
已有的流控方案都需要每台业务机器部署，完成上报请求和流控判断的功能。这样做机器都要部署，同时的正常使用也要纳入维护。
为了做更轻量的方案，我们考虑的必要性，分析发现，要完成的功能比较简单，主要功能托管到业务流控。
这样的做法会让业务在调用流控校验时有额外的开销，开销主要是拉取配额访问的时间消耗，正常是，只要每次拉取配额的值设置合理，分摊到每个请求的耗时就少的可以忽略。
比如拉取配额设置，即正常个请求要拉取一次配额，这时流控会请求一次拉取配额，这个业务请求耗时增加约。
 优势：方案不采用的方式，部署维护更简单。
、全局及单机流控同时启用
考虑全局流控不可用的情况，比如挂掉，能否保证业务不受影响且流控可用？
方案对容灾做了充分的考虑，主要解决方式是全局及单机流控同时启用，即基于的全局流控和基于单机共享内存的单机流控都同时工作。
全局流控失效挂掉或连续超时导致拉取配额失败，流控判断出这种情况后，暂时停止使用全局流控，而单机流控依然可以正常工作，流控定期去探查比如全局流控是否恢复可用，再启动全局流控。
优势：方案有很好的容灾能力，容灾方式简单有效。
、解决性能瓶颈，流控性能达百万
由于使用的以及配额拉取的实现方式，全局流控接入服务请求的能力得到成本增长。
目前方案单独申请了一块，容量为，使用的方式，压测性能达到。
对业务空接口框架做流控压测，使用台虚拟机，单机进程，压测性能达到。
单接口的请求的服务接入，同样也能满足多接口总体服务请求量的全局流控需求。
上述的压测瓶颈主要是框架的性能原因，由于拉取配额值是根据流控阈值设定一般，的请求量只有不到的访问量，没到瓶颈。
优势：方案使用同等的资源单独一块的，能满足业务的请求量更高，性能达百万。
、支持扩容和动态流控升级
支持平行扩展流控能力，一套全局流控部署能满足流控的服务请求量是达百万，更大的服务请求量需要部署多套全局流控。
支持升级到动态流控能力，写入的流控阈值是通过定时管理器完成，目前业务已经做了健康度上报，定时管理器只需要对接健康度数据，分析接口当前请求情况，动态调整流控阈值即可达到动态流控能力。
优势：方案整体简单轻量，扩容和升级都很容易。
接下来详细介绍一下具体方案的实现。
二流控逻辑架构

方案涉及几个功能简单、清晰的角色：
、管理定时器：
根据配置，将频率限制任务的配额值，写入多个带时间信息的。比如频率限制任务配了阈值为的全局流控，那么就以每一秒生成一个为例：
为_、_、_等
为
、共享内存：
保存每一个任务流控相关的本机信息，包括流控状态、本地配额、配额锁等。
、流控：
业务通过流控，请求先扣减本地配额原子操作，如果配额=，就从拉取配额到共享内存中，如果没配额拉取，就做说明流控生效。
三流控状态机
全局流控过程可以抽象出三个主要状态：
、全局非流控状态指的是全局流控可用的情况下，但还没触发限流，业务请求可以正常通过；
、全局流控状态指的是业务请求触发限流，请求不能通过；
、全局失效状态指的是全局流控由于异常不可用，比如访问超时或挂掉，业务请求可以正常通过；
四流控关键流程详解
围绕三个流控状态的跳转，抽象出整个全局流控的核心关键流程：
、当状态为全局非流控，首先会先扣减本地配额，本地配额=时，就走拉取配额流程；
、当状态为全局流控，本地配额=时，先判断是否发生变化，作用是同一个时间间隔内配额已经消耗完，减少无效的拉取；
、当状态为全局失效，会判断时间是否已经超过一个设定值，在失效时间内不会尝试拉取配额，作用是减少无效的拉取；
、 拉取配额先获取原子锁，作用是当业务进程并发拉取时，只有获取锁成功的进程，才能拉取赔额额；
整个流程考虑了所有会发生的情况，围绕三个状态的跳转，正常及异常流程处理都很好的统一到一个流程里。
比如发送不可用的故障，通过拉取配额失败的动作，很好的从正常的全局非流控状态切换到全局失效状态，又通过定时拉配额，去探查故障是否消除，如果消除就回复到全局非流控的正常状态。
三、方案关键问题
一机器时间不一致
由于以时间间隔做，划分不同的时间片并写入流控配额，当机器拉取配额面临个机器时间是否一致的问题。
据了解，时间同步是通过服务来完成，精度在之间，一般情况是。
目前的时间间隔都是以上，服务的精度已经满足。
换句话说只要保证服务正常运行，全局流控的单个时间片的计数是准确的。
如果服务没正运行，导致机器时间不一致，会导致同一时刻应该访问同一的机器，访问了多个，则会造成计数不准确。
由于服务目前处理方式是通过监控流控任务一段时间内的的变化情况，及时发现机器时间不一致的情况。具体做法是如果发现某一时刻超过两个的配额值发生变化，可以确认机器同一时刻访问的分布超过合理的范围，有时间有不一致的情况。
二计数原子化
为了保证并发情况下配计数的准确性，会使用原子操作的方式处理计数，无需加锁。
、全局配额是用的方式，保证配额拉取扣减的准确；
、本地配额累加或扣减，对共享内存使用提供的_____的原子操作方式；
三配额锁发生死锁
拉取配额使用了加锁，锁的方式是对对共享内存使用提供______的原子操作方式。
极端情况下，获取锁的进程掉，就会导致锁无法释放，其他进程需要拉取配额时也获取不了锁。死锁不会影响业务请求正常通过，但由于无法拉取配额，会导致全局流控无法使用。
处理这种情况目前的方式是，判断加锁的时长是否超过合理值 ，具体做法是加锁记录当前时间，正常释放清空这个时间值，获取不了锁的进程判断加锁的时长，大于设定值，说明有死锁情况，主动释放锁。
四配额拉取值设定
配额拉取的值的设置起到一个很关键的一步，影响流控的准确性，拉取的效率以及访问压力。
拉取配额值合理，既减少访问压力，减轻业务额外的拉取耗时一般，同时也能保证流控准确。
拉取配额值不合理，设置过大会造成机器剩余的配额浪费，需要配额的机器可能没配额，导致产生错误流控。设置过小会导致本地配额消耗完本地配额值，配额拉取滞后，造成流控生效延后，拉取次数过多，访问压力大，业务拉取效率低。
配额值的设置是：单机阈值与拉取值的比值为。比如全局流控阈值 ，机器数，平均单机流控阈，配额值设定为。
目前是通过压测观察的经验值得来，拉取值设置是否合理，还有待后续观察和分析。
四、方案运维
一部署及扩展
部署：
、管理定时器的部署，只需单独部署到脚本机上；
、业务模块添加流控，已经接入原来单机流控的业务，无需改动业务逻辑代码，只需要替换旧的静态库和依赖的的头文件即可待给出详细接入；
扩展：
方案支持平行扩展，一套全局流控部署能满足流控的服务请求量是，更大的服务请求量需要部署多套全局流控。平行扩展一套主要的变更包括：申请新的，使用新的一块共享内存以及新的流控任务配置。
二监控报警
、对流控任务做了可视化监控
主要监控及跟踪各流控任务的基本使用能够信息，以及当前和历史流量情况
、机器时间不一致的监控及上报
主要监控流控任务一段时间内的的变化情况，及时发现机器是否时间不一致
三 容灾故障处理
、管理定时器接入主从切换组件，在单点挂掉的情况下可以切到另外一台机器上，保证的可用性。
、当连接超时或无法访问时，对应的流控状态会变成全局失效，过一段时间会自动重新拉起。所以出现不可用的情况，只需要恢复，接入全局流控的服务会自动恢复可用状态。
五、方案升级
一完善监控和告警
目前流控监控只是对流控任务使用情况做了简单的展示，流控的历史情况等其他必要的信息还没能查询及展示。
还有待补充的监控有机器时间不一致监控，监控发现的问题需要告警，以便于人工及时介入。
有待规划的监控和告警后续再补充。
二流控方案升级
流控升级下一步是从全局流控升级到动态流控，所需健康度数据已经上报，而接入的方式目前可以直接在管理定时器上面增加配额调整的能力，这个扩展很方便。重点应该是怎么去根据上报的健康数据分析并实现动调整当前配额值。
配额调整大致的思路如下：
注：图片来自于理财通的《接入层限流介绍》

压测大师运用了沉淀十多年的内部实践经验总结，通过基于真实业务场景和用户行为进行压力测试，帮助游戏开发者发现服务器端的性能瓶颈，进行针对性的性能调优，降低服务器采购和维护成本，提高用户留存和转化率。
功能目前免费对外开放中，点击链接： 即可体验！
如果对使用当中有任何疑问，欢迎联系腾讯企业：是一个复杂的协议，每个机制在带来优势的同时也会引入其他的问题。 算法和 机制是减少发送端和接收端包量的两个机制， 可以有效减少网络包量，避免拥塞。但是，在特定场景下， 算法要求网络中只有一个未确认的包， 而 机制需要等待更多的数据包， 再发送回包， 导致发送和接收端等待对方发送数据， 造成死锁， 只有当 超时后才能解开死锁，进而导致应用侧对外的延时高。 其他文字已经介绍了相关的机制， 已经有一些文章介绍这种时延的场景。本文结合具体的包，分析触发 的场景，相关的内核参数， 以及规避的方案。
背景
给加了一个层， 压测的时候发现， 对写入命令，数据长度大于后， 性能下降非常明显， 只有直连的  而请求影响并不是那么明显。

分析
观察系统的负载和网络包量情况， 都比较低， 网络包量也比较小， 内部的耗时也比较短。 无赖只能祭出神奇， 果然有妖邪。

号请求包， 后服务端才返回了。 初步怀疑是网络层的延时导致了耗时增加。和上找资料， 大概的解释是这样： 由于客户端打开了算法， 服务端未关闭延迟， 会导致延迟超时后，再发送，引起超时。
原理
算法，转自维基百科
      

      =      = 

        

  

            

               

    

        

     

   

 
简单讲， 算法的规则是：

如果发送内容大于个， 立即发送；
如果之前没有包未被确认， 立即发送；
如果之前有包未被确认， 缓存发送内容；
如果收到， 立即发送缓存的内容。

延迟的源码如下：_

基本原理是：

如果收到的数据内容大于一个， 发送；
如果收到了接收窗口以为的数据， 发送；
如果处于 ， 发送；
如果收到乱序的数据， 发送；
其他， 延迟发送

其他都比较明确，  是怎么判断的呢？ 继续往下看代码：

影响 的一个因素是  的状态。 是一个状态值， 用来标识当前交互的状态， 以预测是否是这种交互式的通讯模式， 如果处于， 可以用延迟， 利用的回包， 将的回包， 捎带给发送方。

如上图所示， 默认 = ， 表示非交互式的， 服务端收到数据后， 立即返回， 当服务端有数据响应时，服务端将 = ， 以后的交互中， 服务端不会立即返回，而是等待有数据或者超时后响应。 
问题
按照前面的的原理分析，应该每次都有延迟的，为什么我们测试小于的数据时， 性能并没有受到影响呢？继续分析包：

按照算法和延迟机制， 上面的交互如下图所示， 由于每次发生的数据都包含了完整的请求， 服务端处理完成后， 向客户端返回命令响应时， 将请求的捎带给客户端，节约一次网络包。

再分析的场景：

如下表所示， 第个包发送的数据小于， 同时， = ， 被认为是交互模式， 期待通过捎带的方式来减少网络的包量。 但是， 服务端收到的数据，并不是一个完整的包，不能产生一次应答。服务端只能在等待超时后，发送响应包。同时，从客户端来看，如果在发送一个包， 也可以打破已收数据  的限制。 但是，客户端受算法的限制， 一次只能有一个包未被确认，其他的数据只能被缓存起来， 等待发送。

触发场景
一次请求的数据， 不能在服务端产生一次响应，或者小于一个
规避方案
只有同时客户端打开算法， 服务端打开__才会导致前面的死锁状态。 解决方案可以从的两端来入手。
服务端：

关闭__ 这样， 每个请求包都会有一个及时响应， 不会出现延迟的情况。 操作方式：   ___但是， 每个请求都返回一个包， 导致网络包量的增加，关闭延迟确认后， 网络包量大概增加了，在高峰期影响还是比较明显。



设置_属性。 但是需要每次后再设置一次。 对应我们的场景不太适合，需要修改服务端源码。

客户端：

关闭算法，即设置 __属性。  ___  {
  = 
 _ _  
}

避免多次写， 再读取的场景， 合并成一个大包的写；避免一次请求分成多个包发送， 最开始发送的包小于一个，对我们的场景， 把第号包的个字节缓存起来， 大于一个的时候，再发送出去， 服务端立即返回响应， 客户端继续发送后续的数据， 完成交互，避免时延。


参考资料：_


相关推荐 从三次握手说起浅析协议中的疑难杂症关闭连接为什么会能__ 设计思路学习与总结作者是一位长期服务中小型网站的顾问老师，平时教学过程中经常会遇到大量的服务器及建站问题。其中大多数都是服务器搭建和环境配置上面的问题。

比方说：购买了腾讯云服务器怎么安装个网站呢？

老师我安装个  博客怎么连接呢？ 

我要怎么打开我的服务器呢？


等等一系列的 “小白” 问题。
大多数技术论坛貌似只提供“高逼格”的技术教程，小白问题难度就可以忽略了吗？为小白新手用户打到不平

好了，下面开始进入干货教学阶段。
，啥是服务器，跟虚拟主机区别？
举个简单的例子：你去住酒店旅馆，开完房间就直接入住就行了，什么都已经准备好了。好比虚拟主机，数据库、、空间、帐号密码都不需要你自己配置，已经是配置了好的。
你自己买的新房子，光光的什么也没有，什么家当都需要自己布置。服务器就是一台新电脑，啥软件工具也没有安装就需要自己来安装配置啦。网站需要远程 ，就得配置  连接服务。配置数据库系统，配置  环境，配置 环境，配置域名、配置站点等等，这一系列都需要亲手去配置了。

当然，也可以花点请高手们代自己配置，腾讯云市场里面找这方面的技术高手。
，自己动手，丰衣足食
当然，学会自己动手学习安装更好，不仅自我成长，还能掌握点本事，也是好事。
怎么安装呢，作者如果详细教的话，估计没几十篇文章根本解释不清楚，新手站长建议直接使用“一键安装包”，也叫“傻瓜安装”，这叫法不太好听，就叫“智能环境安装包”吧。
网上有大量的安装环境包，就是一个安装文件，一路回车就安装了所有建站必备的配置。这里列举几个免费的环境包，也是作者经常使用的。

 环境包

 绿色套件

工具 

 



还有更多自行百度。
，实操安装环境配置
我们以  绿色套件，为例子，教各位新手一步步安装吧。免费且简单，记得给个赞啊！
首先去官方下载，就是这个地址
选择一个版本的包下载。

作者以  版  系列环境包为示例。功能说明自己看下就行下。

  版  系列采用  的架构搭建，  和  完全兼容使用方法一致省内存性能佳。

在服务器打开，直接下载后解压缩即可。注意，服务器要安装好 解压缩软件哦，可以百度  下载。


一句话概括：下载   版 解压 文件夹到不含中文和空格的任意盘符目录下  安装运行库  打开面板输入启动全部服务  把网站程序拷贝到默认网站目录浏览器输入即可运行网站。

，安装详细流程
、打开  版下载页找到适合自己的  系列下载最新版到本地硬盘。
、把压缩包内  文件夹解压到不含中文和空格的任意盘符路径下，  文件夹可重命名，名称不能包含中文和空格。
、、等需要安装适合自己编译版本的运行库才能运行，无法确定本机运行库都齐全的情况下建议程序目录“先装运行库再开启”文件夹里的  库全部安装或修复安装下，另外进程守护程序需要安装或后才能启动。
、进入  程序目录，双击  图标打开   版服务器绿色平台控制面板，输入小写的按回车键启动全部服务，此处可根据需求单独启动某项服务。
、打开环境所在电脑的浏览器，在地址栏输入  或  即可看到   探针页面，此时可拷贝网站程序到  默认网站目录并刷新浏览器开始运行自己的网站。
备注：有关数据库的用户名和密码等信息请查看程序目录密码相关
直接上图：这是主界面，不用代码小白都能看懂吧。

添加虚拟主机
打开  控制面板选择添加虚拟主机 进入如下画面：

在新增主机名这里填写按回车确认。

添加主机主域名、别名、泛域名
填写主机别名   没有其它域名要绑定可以不填

这里可以填写预先解析到此服务器的所有域名，中间用空格隔开
特别注意：如果此处添加的是形式的泛域名解析并且这个域名下还建有的二级域名的虚拟主机，那么请一定把泛域名解析的虚拟主机添加到最后面，否则这个域名绑定的其它虚拟主机将无法绑定到对应的主机目录上，因为此处是按虚拟主机的先后顺序进行解析的。
绑定虚拟主机目录
填写网站目录：\\
这里需要填写绝对路径，如果不填则默认建立在文件夹下的\目录下
当然网站目录也可以建立在其它磁盘的任何目录如\\目录下均可。
虚拟主机添加完毕

回车确认后将出现如上画面，到这一步您的虚拟主机已经成功建立了，按任意键即可返回现有主机列表，将看到新增加的虚拟主机。
虚拟主机添加目录列表

如果您此时已经键开启了全部服务那么在虚拟主机完成的同时会自动打开当前虚拟主机页面，可看到 探针的默认页面。
到这一步便可在新建的虚拟主机目录开始部署您的网站了！
如果你域名直接绑定自己的域名，比如博客 ，没有域名的可以使用   本地打开测试。只能服务器本地打开，别人无法访问
行了，更多就不说了，打字真累，自己尝试安装吧，如果遇到问题可以联系我哦。下期再见。

相关推荐
【腾讯云的种玩法】一个小白的自学建站史菜鸟建站入门【腾讯云的种玩法】新手教程：腾讯云安装作者：何方舟

现象
之前有发现，录播  有异常关闭的情况。
我们在月日有一次发布，而月日凌晨突然挂掉。分析服务器内存曲线。

对应的详细内存
可以发现服务器内存达到最大值  后就挂掉了，根据发布后内存有明显的上升趋势，且  回收不明显，初步判定是由于内存泄露导致。
内存分析
我们使用  这个库来帮助我们查看内存变量的情况。临时创建一个创建快照的请求地址。
    {
          
         
            {
              {  
                 
            }
            
        }
    }
 的  生成的内存快照文件，可以被  打开。
通过  进行本地压测：
        _=_==_=
这些内存快照使用方法可以参考这篇文章：

我们对程序开始时和压测结合后的内存快照进行对比，发现存在大量的 ， 变量未被回收，而其他对象都没有出现明显的堆积。是令人疑惑的是，分析相关的  后发现，这些变量并不存在泄露的可能。
考虑到    的方式：

一种是对新生代区的 算法，速度块，
一种是对老生区的标记清除算法，由于单线程的原因会导致应用被阻塞。这些变量依旧存在的原因只可能处于已移到老生区，暂时未被 。

分析未宕机前的内存图

内存有一个很健康的折线，可以看出并不存在泄露问题。
但是内存总量却在一个很高值，服务器内存上限是 ，也就是说内存总量一直处于一个很危险的值。
但是为什么之前没有出现宕机问题呢？
结合 ，， 的视图。



日由于活动的原因，录播  涨了三倍，这时可以是因为内存溢出引起的宕机。
结论
因为内存上限设置不合理，引起的内存溢出问题。
之前压测时候只关注了是否存在内存泄露与占用，而忽视了内存占用这个问题。
对于部署服务时，要根据机器的内存上限以及机器核心数合理的设置单服务器的内存上限值。

原文链接：


相关推荐    译中错误捕获的一些最佳实践本文简介
本文介绍 的基本概念。这不是一篇单独的文章，这是《谢宝友：深入理解 》系列的第篇，前序文章：
谢宝友： 深入理解 之一——从硬件说起=谢宝友：深入理解 ：从硬件说起之内存屏障
作者简介
   谢宝友，在编程一线工作已经有年时间，其中接近年时间工作于操作系统。在中兴通讯操作系统产品部工作期间，他作为技术总工参与的电信级嵌入式实时操作系统，获得了行业最高奖中国工业大奖。同时，他也是《深入理解并行编程》一书的译者。
联系方式：  微信：

一、有什么用？
主要用于对性能要求苛刻的并行实时计算。例如：天气预报、模拟核爆炸计算、内核同步等等。
假设你正在编写一个并行实时程序，该程序需要访问随时变化的数据。这些数据可能是随着温度、湿度的变化而逐渐变化的大气压。这个程序的实时响应要求是如此严格，需要处理的数据量如此巨大，以至于不允许任何自旋或者阻塞，因此不能使用任何锁。
幸运的是，温度和压力的范围通常变化不大，因此使用默认的数据集也是可行的。当温度、湿度和压力抖动时，有必要使用实时数据。但是温度、湿度和压力是逐渐变化的，我们可以在几分钟内更新数据，但没必要实时更新值。
在这种情况下，可以使用一个全局指针，即，通常为，表示要使用默认值。偶尔也可以将指向假设命名为、和的变量，以反映气压的变化。
传统的软件可以使用自旋锁这样的同步机制，来保护指针的读写。一旦旧的值不被使用，就可以将旧指针指向的数据释放。这种简单的方法有一个最大的问题：它会使软件效率下降数个数量级注意，不是下降数倍而是下降数个数量级。
在现代计算系统中，向写入、、这样的值，并发的读者要么看到一个指针要么看到指向新结构的指针，不会看到中间结果。也就是说，对于指针赋值来说，某种意义上这种赋值是原子的。读者不会看到、、之外的其他结果。并且，更好的一点，也是更重要的一点是：读者不需要使用任何代价高昂的同步原语，因此这种方法非常适合于实时使用。
真正的难点在于：在读者获得的引用时，它可能看到、、这三个值中任意一个值，写者何时才能安全的释放、、所指向的内存数据结构？
引用计数的方案很有诱惑力，但正如锁和顺序锁一样，引用计数可能消耗掉数百个指令周期，更致命的是，它会引用缓存行在之间的来回颠簸，破坏各个的缓存，引起系统整体性能的下降。很明显，这种选择不是我们所期望的。
想要理解经典实现的读者，应当认真阅读下面这段话：一种实现方法是，写者完全不知道有哪些读者存在。这种方法显然让读者的性能最佳，但留给写者的问题是：如何才能确定所有的老读者已经完成。
最简单的实现是：让线程不会被抢占，或者说，读者在读数据期间不能被抢占。在这种不可抢占的环境中，每个线程将一直运行，直到它明确地和自愿地阻塞自己现实世界确实有这样的操作系统，它由线程自己决定何时释放。例如大名鼎鼎的操作系统。这要求一个不能阻塞的无限循环将使该在循环开始后无法用于任何其他目的，还要求还要求线程在持有自旋锁时禁止阻塞。否则会形成死锁。
这种方法的示意图下所示，图中的时间从顶部推移到底部， 的_操作是写者操作，、在读端读取节点。

经典的概念即是如此。虽然这种方法在生产环境上的实现可能相当复杂，但是玩具实现却非常简单。
  ___
  _
___原语遍历所有，_函数导致当前线程在指定的上执行，这会强制目标执行上下文切换。因此，一旦___完成，每个都执行了一次上下文切换，这又保证了所有之前存在的读线程已经完成。
请注意，这个方法不能用于生产环境。正确处理各种边界条件和对性能优化的强烈要求意味着用于生产环境的代码实现将十分复杂。此外，可抢占环境的实现需要读者实际做点什么事情也就是在读临界区内，禁止抢占。这是经典读锁的实现。不过，这种简单的不可抢占的方法在概念上是完整的，有助于我们理解的基本原理。
二、是什么？
是的简称，翻译为中文有点别扭“读复制更新”。它是是一种同步机制，有三种角色或者操作：读者、写者和复制操作，我理解其中的复制操作就是不同上的读者复制了不同的数据值，或者说拥有同一个指针的不同拷贝值，也可以理解为：在读者读取值的时候，写者复制并替换其内容后一种理解来自于作者的解释。它于年月引入内核。
允许读操作可以与更新操作并发执行，这一点提升了程序的可扩展性。常规的互斥锁让并发线程互斥执行，并不关心该线程是读者还是写者，而读写锁在没有写者时允许并发的读者，相比于这些常规锁操作，在维护对象的多个版本时确保读操作保持一致，同时保证只有所有当前读端临界区都执行完毕后才释放对象。定义并使用了高效并且易于扩展的机制，用来发布和读取对象的新版本，还用于延后旧版本对象的垃圾收集工作。这些机制恰当地在读端和更新端并行工作，使得读端特别快速。在某些场合下比如非抢占式内核里，读端的函数完全是零开销。
也可以让读者和写者并发执行，但是二者有什么区别？
首先是二者的目的不一样。是为了保证读端在读取值的时候，写者没有对它进行修改，而是为了多核扩展性。
其次是保护的数据结构大小不一样。可以保护一组相关联的数据，而只能保护指针这样的 类型的数据。
最重要的区别还在于效率，本质上是与自旋锁同等重量级的原语，其效率与不在同一个数量级上面。
下面从三个基础机制来阐述究竟是什么？
由三种基础机制构成，第一个机制用于插入，第二个用于删除，第三个用于让读者可以不受并发的插入和删除干扰。分别是：发布订阅机制，用于插入。
等待已有的读者完成的机制，用于删除。
维护对象多个版本的机制，以允许并发的插入和删除操作。
、发布订阅机制
的一个关键特性是可以安全的读取数据，即使数据此时正被修改。通过一种发布订阅机制达成了并发的数据插入。举个例子，假设初始值为的全局指针现在被赋值指向一个刚分配并初始化的数据结构。如下所示的代码片段：
     {
      
      
      
  }
       = 

         

   =    _
   =  
   =  
   =  
    =  
“发布”数据结构不安全
不幸的是，这块代码无法保证编译器和会按照编程顺序执行最后条赋值语句。如果对的赋值发生在初始化的各字段之前，那么并发的读者会读到未初始化的值。这里需要内存屏障来保证事情按顺序发生，可是内存屏障又向来以难用而闻名。所以这里我们用一句 原语将内存屏障封装起来，让其拥有发布的语义。最后行代码如下。
   =  
   =  
   =  
  __  
__“发布”一个新结构，强制让编译器和在为的各字段赋值后再去为赋值。
不过，只保证更新者的执行顺序并不够，因为读者也需要保证读取顺序。请看下面这个例子中的代码。
   =  
     =   {
     __   
  }
这块代码看起来好像不会受到乱序执行的影响，可惜事与愿违，在  机器上，还有启用编译器值猜测优化时，会让，和的值在赋值之前被读取。
也许在启动编译器的值猜测优化时比较容易观察到这一情形，此时编译器会先猜测、、的值，然后再去读取的实际值来检查编译器的猜测是否正确。这种类型的优化十分激进，甚至有点疯狂，但是这确实发生在剖析驱动优化的上下文中。
然而读者可能会说，我们一般不会使用编译器猜测优化。那么我们可以考虑  这样的极端弱序的。在这个上面，引起问题的根源在于：在同一个内部，使用了不止一个缓存来缓存数据。这样可能使用和被分布不同一个的不同缓存中，造成缓存一致性方面的问题。
显然，我们必须在编译器和层面阻止这种危险的优化。_原语用了各种内存屏障指令和编译器指令来达到这一目的。
  __
   =  _
     =   {
     __   
  }
  __
其中 和__这对原语定义了读端的临界区。事实上，在没有配置_的内核里，这对原语就是空函数。在可抢占内核中，这这对原语就是关闭打开抢占。
_原语用一种“订阅”的办法获取指定指针的值。保证后续的解引用操作可以看见在对应的“发布”操作__前进行的初始化，即：在看到的新值之前，能够看到、、的新值。请注意，__和_这对原语既不会自旋或者阻塞，也不会阻止 的并发执行。
虽然理论上__和_可以用于构造任何能想象到的受保护的数据结构，但是实践中常常只用于构建更上层的原语。例如，将__和_原语嵌入在链表的变体中。有两种双链表的变体，循环链表 _和哈希表_ _。前一种如下图所示。

对链表采用指针发布的例子如下：
      {
      _  
       
       
       
  }
 _

         

    =   _
   =  
   =  
   =  
 __ 
发布链表
第行必须用某些同步机制最常见的是各种锁来保护，防止多核_实例并发执行。不过，同步并不能阻止_的实例与的读者并发执行。订阅一个受保护的链表的代码非常直接。
  __
  ____     {
     __   
  }
  __
__原语向指定的链表发布了一项条目，保证对应的_ _可以订阅到同一项条目。的其他链表、哈希表都是线性链表，这意味着它的头结点只需要一个指针，而不是象循环链表那样需要两个。因此哈希表的使用可以减少哈希表的 数组一半的内存消耗。向受保护的哈希表发布新元素和向循环链表的操作十分类似，如下所示。
      {
      _  
       
       
       
  }
 _

         

    =   _
   =  
   =  
   =  
 ___ 

和之前一样，第行必须用某种同步机制，比如锁来保护。
订阅受保护的哈希表和订阅循环链表没什么区别。

 __
 ____      {
    __   
  }
  __
表是的发布和订阅原语，另外还有一个删除发布原语。

请注意，__、__、_和 _这些引入了一点复杂性。何时才能安全地释放刚被替换或者删除的数据元素？我们怎么能知道何时所有读者释放了他们对数据元素的引用？
、等待已有的读者执行完毕
从最基本的角度来说，就是一种等待事物结束的方式。当然，有很多其他的方式可以用来等待事物结束，比如引用计数、读写锁、事件等等。的最伟大之处在于它可以等待比如种不同的事物，而无需显式地去跟踪它们中的每一个，也无需去担心对性能的影响，对扩展性的限制，复杂的死锁场景，还有内存泄漏带来的危害等等使用显式跟踪手段会出现的问题。

在的例子中，被等待的事物称为“读端临界区”。读端临界区从__原语开始，到对应的__原语结束。读端临界区可以嵌套，也可以包含一大块代码，只要这其中的代码不会阻塞或者睡眠先不考虑可睡眠。如果你遵守这些约定，就可以使用去等待任何代码的完成。
通过间接地确定这些事物何时完成，才完成了这样的壮举。如上图所示，是一种等待已有的读端临界区执行完毕的方法，这里的执行完毕也包括在临界区里执行的内存操作。不过请注意，在某个宽限期开始后才启动的读端临界区会扩展到该宽限期的结尾处。
下列伪代码展示了写者使用等待读者的基本方法。
．作出改变，比如替换链表中的一个元素。．等待所有已有的读端临界区执行完毕比如使用_原语。这里要注意的是后续的读端临界区无法获取刚刚删除元素的引用。．清理，比如释放刚才被替换的元素。下图所示的代码片段演示了这个过程，其中字段是搜索关键字。
      {
      _  
       
       
       
  }
 _

         

    =   
     ==    {
             
   
  }
    =   _
    =  
   =  
   =  
 __ 
 _
  
标准替换示例
第、和行实现了刚才提到的三个步骤。第至行正如其名读复制更新，在允许并发读的同时，第行复制，第到行更新。
_原语可以相当简单。然而，想要达到产品质量，代码实现必须处理一些困难的边界情况，并且还要进行大量优化，这两者都将导致明显的复杂性。理解的难点，主要在于_的实现。
、维护最近被更新对象的多个版本
下面展示如何维护链表的多个版本，供并发的读者访问。通过两个例子来说明在读者还处于读端临界区时，被读者引用的数据元素如何保持完整性。第一个例子展示了链表元素的删除，第二个例子展示了链表元素的替换。
例子：在删除过程中维护多个版本
   =    
     =   {
     __
     _
     
  }
如下图，每个元素中的三个数字分别代表字段、、的值。红色的元素表示读者此时正持有该元素的引用。请注意，我们为了让图更清楚，忽略了后向指针和从尾指向头的指针。

等第行的__执行完毕后，“、、”元素从链表中被删除。因为读者不直接与更新者同步，所以读者可能还在并发地扫描链表。这些并发的读者有可能看见，也有可能看不见刚刚被删除的元素，这取决于扫描的时机。不过，刚好在取出指向被删除元素指针后被延迟的读者比如，由于中断、内存错误，就有可能在删除后还看见链表元素的旧值。因此，我们此时有两个版本的链表，一个有元素“、、”，另一个没有。元素“、、”用黄色标注，表明老读者可能还在引用它，但是新读者已经无法获得它的引用。
请注意，读者不允许在退出读端临界区后还维护元素“、、”的引用。因此，一旦第行的_执行完毕，所有已有的读者都要保证已经执行完，不能再有读者引用该元素。这样我们又回到了唯一版本的链表。
此时，元素“、、”可以安全被释放了。这样我们就完成了元素“、、”的删除。
例子：在替换过程中维护多个版本
   =    _
    =  
    =  
    =  
 __ 
 _
  
链表的初始状态包括指针都和“删除”例子中一样。

从链表中替换元素
和前面一样，每个元素中的三个数字分别代表字段、、。红色的元素表示读者可能正在引用，并且因为读者不直接与更新者同步，所以读者有可能与整个替换过程并发执行。请注意我们为了图表的清晰，再一次忽略了后向指针和从尾指向头的指针。
下面描述了元素“、、”如何替换元素“、、”的过程，任何特定读者可能看见这两个值其中一个。
第行用分配了要替换的元素。此时，没有读者持有刚分配的元素的引用用绿色表示，并且该元素是未初始化的用问号表示。
第行将旧元素复制给新元素。新元素此时还不能被读者访问，但是已经初始化了。
第行将的值更新为，第行将的值更新为。现在，第行开始替换，这样新元素终于对读者可见了，因此颜色也变成了红色。此时，链表就有两个版本了。已经存在的老读者可能看到元素“、、”现在颜色是黄色的，而新读者将会看见元素“、、”。不过这里可以保证任何读者都能看到一个完好的链表。
随着第行_的返回，宽限期结束，所有在__之前开始的读者都已经完成。特别是任何可能持有元素“、、”引用的读者保证已经退出了它们的读端临界区，不能继续持有引用。因此，不再有任何读者持有旧数据的引用，如第排绿色部分所示。这样我们又回到了单一版本的链表，只是用新元素替换了旧元素。
等第行的完成后，链表就成了最后一排的样子。
不过尽管是因替换的例子而得名的，但是在内核中的主要用途还是用于简单的删除。

本文来自  微信公众号《亿级流量电商详情页系统实战：缓存架构高可用服务架构微服务架构》，简称第二版，在原有节教程的基础之上，新增了多讲，深入讲述了亿级流量电商详情页系统的完整大型架构。同时最重要的是，在完全真实的大型电商详情页系统架构下，全流程实战了整套微服务架构，包含了基于领域驱动设计进行微服务建模、 、基于的持续交付流水线与自动化测试套件、基于的自动化部署。此外，还包含了大型电商详情页系统架构中的多种复杂架构设计的详细介绍。
《亿级流量电商详情页系统实战第一版》的内容，主要是基于简化以后的大型电商详情页系统的背景，重点包含了三块内容：集群架构、大型高并发缓存架构以及基于的高可用服务架构。而《亿级流量电商详情页系统实战第二版：缓存架构高可用服务架构微服务架构》会站在一个更高更大的角度，来架构和开发一整套完整的大型电商商品详情页系统架构，具体内容如下：
、完整的大型电商详情页系统架构：不再只是关注电商详情页架构中的缓存架构部分，而是关注全链路、全流程的完整架构，对完整的架构进行设计以及开发，包括了动态渲染系统、系统、前端页面、大型工程运维四个部分。
、完全真实的业务服务：这是与课程第一版内容的最大区别。课程第一版中，基于大幅度简化后的业务场景来讲解，虽然技术架构是完全真实的，但是业务场景基本属于级，跟实际生产脱离较大，不利于同学们理解和学习。因此课程第二版中的内容，基于完全真实而且完整的业务服务，将多个服务中完整而且真实的业务逻辑都实现和开发了，大家可以基于完全真实的业务场景来学习和实战整套架构，包括了商品服务、价格服务、库存服务、配送服务、促销服务。
、完整的微服务架构的项目实战：微服务完整的架构中，一定是包含了微服务建模模型设计、基础技术架构、持续交付流水线、容器部署几个环节的，而市面上已有的微服务课程，几乎很少有完全涵盖这些环节的，更不用说微服务架构的实战了。课程中，将会讲解完整的微服务架构，包括基于领域驱动设计来完成微服务建模，基于 作为微服务架构的基础技术架构，基于思想与构建持续交付流水线以及自动化测试套件，基于作为容器部署和运行微服务。同时最有价值的地方在于，课程中基于第二点中讲的完全真实的电商业务，第一点中讲的大型电商详情页的完整系统架构作为背景，来进行项目实战，真正让同学们可以在项目的真实业务以及完整架构中，动手实战整套微服务架构。
、多机房部署架构下的级缓存架构：大公司里真实的亿级流量高并发系统，都是采取了多个机房的部署架构，以实现高可用以及异地灾备。课程会重点讲解，在多机房部署架构下，如何设计和实现高并发系统的级缓存架构。
、复杂业务场景下的多层次消息队列架构：在复杂的业务场景下，需要设计多层次的消息队列架构，包括了去重队列、优先级队列、本地队列、容错队列等个层次的复杂架构设计与实现。
、后台服务的多线程并发架构设计：对于后台运行的服务，需要采用多线程并发设计大幅度提升系统的资源利用率以及吞吐量，因此课程中会讲解如何设计后台服务的多线程并发架构。
、集群的批量数据查询性能优化：对于分布式的集群，数据在多个实例中分布式存储，如果要优化大批量数据的批量查询性能，就需要采用 分片路由单分批大批量读取的优化设计。
、高可用架构设计：整套大型系统如何实现高可用架构的设计和部署？需要对基础设施进行全链路高可用部署，同时对整个读链路进行多级降级机制的设计，并且还需要进行基于的依赖调用隔离、基于 异步化的多业务请求隔离、多服务隔离。
、基础设施技术涵盖了大型系统中常用的各种技术，包括了：负载均衡、请求接入高性能服务器反向代理、磁盘内存的分布式与读写分离双集群、高可用主从架构、主从架构的读写分离
、直接可以二次开发的代码：本次升级，采取了大型电商网站商品详情页系统完整的全链路架构，包括基础设施如何部署，以及整体代码架构，都是完全按照公司里来做的。而且各个服务的业务完全用的是真实的业务，只是去掉了一些公司特有的业务而已比如什么汽车频道、化妆品频道之类特殊的业务背景。因此本次课程最后做完，产出的架构和代码，对于那些做电商类系统的公司，都是可以直接拿到手，部署基础设施环境之后，就可以进行二次开发的，工业价值非常高！
、大公司的一站式入口服务：基于商品详情页依赖数十个服务的业务特点，深入讲解了如何设计与开发大公司中常见的一站式入口服务，代理后端数十个服务，作为统一入口，打造服务闭环，实现服务合并后端服务业务逻辑前置前端页面业务逻辑后置统一监控统一降级。
、大型电商网站的前端页面的核心业务逻辑：完整讲解了大型电商网站的前端页面如何与后端整套系统配合的业务逻辑，包括了动态渲染系统直接渲染首屏的商品基本信息，滚屏时异步加载分段存储的商品介绍，异步调用系统来加载时效性要求很高的价格、库存等数据。
、大型电商网站的工程运维实践：在大型系统中，一定是需要对整套工程的运维流程做良好的设计的，包括了线下压测、线上压测、灰度发布、高峰期限流。
、视频教程：说起创业公司，在创业初期面临的一个比较大的痛点，莫过于如何实现高效低成本的项目管理模式  小步快跑、快速迭代？如何将研发团队有效组织起来，在可控、可视化的范围类进行产品版本迭代更新？
现如今，大多数互联网创业公司都追崇者敏捷开发的思路，甚至很多成熟型大公司都沿用这种开发管理模式。敏捷开发是一种以人为核心、迭代、循序渐进的开发方法。“    ”是敏捷迭代的核心理念。
在创业公司，很多创业者初期在项目管理上都使用任务看板、每日站会、计划纸牌等手段进行项目管理，这也是比较常见的项目管理手段。因为这种方式会更加便捷，没有“套路”，能让人一目了然、快速看到现在在发生什么，未来将要发生什么。但是这里会存在以下几个难题：

人工线下操作、记录粘贴耗费时间和精力；
修改删除麻烦，不方便随时更新；
历史记录看不到，无法回顾历史数据；
子任务拆分不方便，拆分后无法修改；
对人员管理不便，随着团队扩张，操作越来越困难。

最近两年在创业的道路上，认识一位新朋友  。我称呼为“先生”。“先生 ”就是专程出现为我们解决创业过程中敏捷开发的难题的。最近一年在做“够格”的项目，与“先生 ”结缘，相处甚久后，尤其认识到“先生”带来的便利。下面我就结合“够格”这个项目的实战过程简单介绍“先生 ”为我们这个创业团队带来什么。
够格是一个做“直播电商”领域的创业项目，整个研发团队近人。包括产品项目经理共人、设计人、测试人，其余为开发团队。工作地点都在一个办公区域基本不存在异地沟通问题，整个项目采用敏捷开发、版本迭代的过程在跑。产品至今上线一年时间，版本迭代将近次。基本保持每周一次迭代的过程。
整个够格产品分为网页端端等多系统多平台。够格这个产品从成立之初就认识了“先生”，整个团队也是从一开始就和“先生 ”进行磨合。在项目跑的过程中，整个团队也尝试过用任务看板等线下的方式进行项目研发管理。然而依然会碰到上述的几个问题。

耗费时间和精力：最初 大家还是愿意接受线下手工的方式写字操作各自任务记录，后面每人每日都要花费大量时间手写任务列表，进行卡片粘贴。到最后整个团队都觉得这样写起来很麻烦，逐渐放弃了手动写的过程，转而进入进行系统自动管理。
更新删除麻烦：团队每个人每天都需要对今天完成的任务进行更新，多数时候当大家拿起笔去更新时重写内容时就开始愁苦。写了一天代码要下班了还得重新写字更新今日任务，尤其碰到需要删除重新的需求任务更是崩溃。
历史记录找不到：每天只能看到当天完成了什么，昨天完成了什么。当整张墙贴的密密麻麻时，想找一个人任务时，眼睛都要瞅半天。此时大家真想有个“搜索”功能。尤其在每期迭代结束后，统计每个人任务进度时，简直要崩溃。此时多希望有个工具能帮我做这件事。
子任务拆分不方便：产品需求永远都会拆分子任务，研发在开发时也需要拆分更细的子任务。此时自己用人工的方法来做就显得特别麻烦，尤其拆好的子任务要做拆分修改时，更是麻烦。
人员管理麻烦：我们当初整个看板名字是固定的，随着后续有新同事进来，旧同事离开，整个看板都需要更新。这时就需要把看板上的所有任务全部清除后再重新布局。
在认识“先生”后，整个研发团队的迭代节奏明显加快许多，原先将近两周才完成的迭代、现在相同任务量缩短到一周。每日晨会、站会时间也由半小时缩短到分钟。研发团队每日下班的时由原先花费将近分钟更新今日任务的时间，缩短至分钟搞定下班回家。
说到“先生”究竟为什么方便了团队在敏捷开发过程中的使用，这里需要先说我们团队的产品研发节奏。整个产品研发的迭代顺序大致是需求收集  需求分析  功能策划  原型设计  需求评审排期  开发阶段   测试阶段  上线阶段，这里实现一个完整的迭代。在上，我们使用其提供的丰富功能实现项目管理效率的提升和节奏的把控。

需求收集阶段： 我们会在上建立一个“需求池 ”，产品会将收集来的各方面需求收录到池子里。利用提供的需求分类功能，会对池子里的需求进行分类管理，比如端需求、运营需求、网页端需求等等。定期对需求池中的需求进行合并删减。
需求分析阶段：对建立的“需求池”，产品对定期进行评估，利用提供的优先级和重要性功能 一一对其进行标记。对标记重要和高优先级的需求，会利用提供的迭代管理功能，创建新迭代，并关联该迭代。

功能策划阶段：确定要做的需求，需要从产品功能层面对其进行任务拆分，利用提供的快速创建子任务功能， 拆分出多个子功能模块，逐一进行策划，并快速关联该功能负责人。对应该负责人即可实时跟进任务进度，进行策划。此外还可以利用的关联父需求功能，快速对新任务进行父需求关联，分类排版一目了然。

原型设计阶段：“先生”提供实时更新设计好的原型和交互说明，只需要复制粘贴就可以修改需求任务说明。其中最大的便捷便是只需更新一个任务，就能实时更新所有“复制”该需求的任务。设计师也可以实时同步提供附件功能，将设计稿关联上去，方便同步设计稿文件。

需求评审排期：需求评审会上，只需要打开“先生”就可以跟研发同学一起过需求评审，遇到对某个需求的疑问可以实时在上面备注修改。需求过完，即可以接着排出每个需求对应的开发人员、测试人员、开发周期、测试周期。整个需求评审会结束后，“先生”就能为我们展现这期迭代的全景，包括对应需求、子任务、对应负责人、开发人员、测试人员、开发周期、上线时间。

开发阶段：开发人员只需按照每个子任务的排期时间，每日晨会对着看板就可以一目了然知道当前进度是否延期或提前，能提前避免遇到的项目风险问题。每日只需要在上下班时修改对应任务的进度状态，就可以实时同步给所有人。完成开发即可提测给测试人员。

测试阶段：测试人员根据的需求内容可提前编写测试用例，更新到每个任务下。开发人员即可实时同步看到该功能测试范围和要求。在提测后，测试人员能及时将测出的同步到提供的库里，关联给对应的开发人员。对进行统一管理，不遗漏。
上线阶段：当所有任务测试 完成后，即可上线。上线前产品、运营都可以在看板中列出上线，对应指定负责人员。一项项检查管理，确保上线工作准备充分。

以上只是从够格的实战项目中介绍了“先生”在项目迭代过程中带来的便处。除此之外，提供的版本记录和历史操作能在帮助更好地进行操作记录和删除操作管理。项目报表和故事墙能刚好的对项目整体进行数据分析和节奏把控的管理。能帮助进行团队知识、规则、流程的沉淀。自定义字段、状态流转能更方便开发和测试人员进行任务管理。项目团队邀请、人员一键搜索可轻松实现团队人员增删修改。
现在我们不仅在产品研发团队使用“先生”进行研发项目的管理。我们同时将运营部门、商务部门也按照迭代的模式在“先生”上进行统一管理。让各部门之间信息互相同步，实时了解公司整体发展进度。作者：陈航特
团队：腾讯移动品质中心

导读
年月份，已正式宣布停止对集成开发环境的支持，虽然早在推出 时就早已知道这一天迟早会到来，但由于多年的使用习惯及项目中的其他原因，自动化测试工程仍然使用中进行开发与维护。在自动化测试适配版本时，发现已无法很好支持用例的编写与调试，故迁移至 已成必然。
本文记录介绍在上的基于自动化测试工程如何迁移至 ，如何配置项目，及如何基于持续构建测试工程。
一、环境准备
、安装 ；
下载地址：
、升级至推荐；
新版的工具大多用的，不过如果是用的 ，则推荐使用内建的环境。

、检查确认安装好的 关联好正确的 路径。
二、按官方文档导入项目
官方详情文档：_按文档中所介绍的，将项目导入 中，导入后工程目录结构如下：

目录下包含了原测试工程作为项目的主要文件，包含代码文件、清单文件等。同时 自动生成了、等等构建相关的文件。
三、设置代理
若国内网络受限，可以对 设置网络代理。

四、调整测试工程
 是将被测工程与测试工程放一起的，而我们这个基于的自动化测试不想依赖源码。当时是为了独立工程，因此迁移后，需要将下的目录全拷贝一份至目录，同时为了使目录下能正常编译，创建了个空壳项目，即下只包含一个简单的最简工程。结构如下：

需要注意的是， 默认会将目录下的测试工程的设置为被测工程的加后缀，即若工程的为，那么测试工程的则为。而为了让包名与原来保持一致，需要修改，设置。
五、配置依赖库
刚将工程导入 后，依赖库可能设置有误，此时需要修改相应依赖库—— 。

相应的有、、、 等等。
 ：构建测试工程时用到的依赖包；
：编译时需要，但不需要打包进的依赖包。
设置后，构建文件中会自动生成类似如下的内容： 

也可直接修改文件调整依赖包。
六、修改签名
类似于，测试工程需要与被测工程同样的签名，为了在平时调试时就能正常运行用例，需要 对测试工程的打包默认就用被测工程的签名。

配置后，相应的文件就会包含相应的签名信息：

七、运行测试用例
、运行用例类中的所有用例：
右键选中测试用例类，选择 ；
、运行用例类中的某个用例：
打开该用例类，光标放在该用例的代码中，右键选择即可要修改运行配置，则如下图点击 。

运行用例后可以在命令行中看到 调起用例：

至此，中的测试工程就已经迁移至 ，且可以正常运行测试用例了。
八、持续构建测试工程
 的工程根目录下有可执行文件，该文件即的封装版，可以不用事先手动安装。运行 可以看到当前项目的任务列表，如下图所示，可以看到使用 即可构建测试工程。

参考附录：
、测试工程官方详情文档：
；
、工程迁移至 文档：
_；
、 用户指南：
=。
获取更多测试干货，请搜索微信公众号：腾讯移动品质中心！ 导语 一个支持文本类目标注和关键词打分的通用标注工具，为文本分类模型和关键词抽取任务提供训练和测试数据。  慕福楠  孙振龙
 背景
很多  任务训练和评估都依赖大量标注数据，对于文本分类，使用标注数据进行模型训练和评测，如商业兴趣分类、电商分类、分类；对于关键词抽取，使用标注数据进行评测。在标注数据获取过程中存在以下问题： 标注方式效率低下；腾讯系数据源多，标注数据难于管理；标注质量难以保证，依赖人工抽样，费时费力。因此，我们快速开发了一个通用的文本标注工具并开源，工具名称为，翻译成“来标我”，现在已经支持组内所有的标注任务。
 支持的特性

图 支持的特性
 多场景
目前支持文本类目标注图和关键词标注图两个场景。类目标注支持树状类目体系，标注时自顶向下标注，从标注到叶节点，例如图中，先标一级“餐饮美食”，再标二级“餐馆”。关键词标注支持正在打分的关键词在文档中高亮和增加候选中没有的关键词功能。

 图 类目标注界面

图 关键词标注界面
 多任务
支持多个任务同时标注，通过简单的配置即可增加新的标注任务，配置如图，然后在系统登录页选择相应的进行标注，如图所示。

图 配置定义

图 系统登录页
 质量校验
为了保证标注数据质量，引入质量校验特性，利用专家标注的数据验证普通标注人员的标注数据的准确率。将开发或者产品定义为专家，将外包同学定义为普通标注人员，标注的数据作为 ，每天的标注数据中掺一定比例的 ，比例可配置配置定义中的__字段，每天以 作为正确答案，计算标注的准确率。之间的标注数据不会有交集，见图，每天分配给的 是没有标注过的，所以一旦 用完，系统无法计算准确率，需要定期标注一些 计算的准确率。

图  各角色标注数据交集情况
  待实现
对于类目标注， 为了提高标注效率和减少不必要的标注，可以利用已有标注数据训练弱分类器，对未标注数据进行预测，假定预测的结果为  =   ；是类目的个数，预测结果为 =  _ ，即样本的预测类别为，概率为，将低于的样本返回给标注人员进行标注，高于的样本认为是跟已标注样本很相似，不需要再标注。每天重新训练弱分类器，重新预测未标注样本的类别，重新估计。另外，为了降低系统复杂度，弱分类器与解耦，提供接口给弱分类器，接口包括获取已标注数据和未标注数据，更改未标注数据预测类别，弱分类器由用户自行选择。另外，优先展示概率比较大的类目，提高标注效率。
 数据管理
采用管理标注数据，使用，保证数据安全，毕竟标注数据需要大量人力。
 报表推送
会向任务的和推送报表，报告样本总量，已标数据，剩余数量，每个人前一天标注数量和准确率。

 未来计划
未来工作包括优化和 。优化包括上一页按钮和查询界面，上一页按钮为了修改误标的数据，查询界面是报表的扩展，提供更多维度的查询，比如某个外包同学特定时间段内所有任务的标注量和正确率。对于 上文提到了未来的实现方式，这里不再赘述。这是《使用腾讯云  学习深度学习》系列文章的第二篇，主要介绍了  的原理，以及如何用最简单的代码进行功能实现。本系列文章主要介绍如何使用 腾讯云服务器 进行深度学习运算，前面主要介绍原理部分，后期则以实践为主。
往期内容：
使用腾讯云  学习深度学习系列之一：传统机器学习的回顾
 神经网络原理
神经网络模型，是上一章节提到的典型的监督学习问题，即我们有一组输入以及对应的目标输出，求最优模型。通过最优模型，当我们有新的输入时，可以得到一个近似真实的预测输出。
我们先看一下如何实现这样一个简单的神经网络：

输入  = 

目标输出  =  

中间使用一个包含四个单元的隐藏层。

结构如图：


求所需参数 _ _ _ _， 使得给定输入  下得到的输出 ，和目标输出  之间的平均均方误差     最小化 。
我们首先需要思考，有几个参数？由于是两层神经网络，结构如下图图片来源 其中输入层为 ，中间层为 ，输出层是 ：

因此，其中总共包含    =  个参数需要训练。我们可以如图初始化参数。参数可以随机初始化，也可以随便指定：
 
   
_ =        
                        
                        
_ =    
                    
                    
                    

_ =     
_ =   

我们进行一次正向传播：
 

 = 
 =  

 =  _   _
 =  
 =  _  _
 = 

再进行一次反向传播：
 

 = 
_ =      
_ = _ _  
_ = 
_ = 


_    = _    _
_    = _    _



如此反复多次，直到最终误差收敛。进行反向传播时，需要将所有参数的求导结果都写上去，然后根据求导结果更新参数。我这里就没有写全，因为一层一层推导实在是太过麻烦。更重要的是，当我们需要训练新的神经网络结构时，这些都需要重新推导一次，费时费力。
然而仔细想一想，这个推导的过程也并非无规律可循。即上一级的神经网络梯度输出，会被用作下一级计算梯度的输入，同时下一级计算梯度的输出，会被作为上一级神经网络的输入。于是我们就思考能否将这一过程抽象化，做成一个可以自动求导的框架？，以  为代表的一系列深度学习框架，正是根据这一思路诞生的。
深度学习框架
近几年最火的深度学习框架是什么？毫无疑问， 高票当选。

但实际上，这些深度学习框架都具有一些普遍特征。  认为，大部分深度学习框架都包含以下五个核心组件：

张量

基于张量的各种操作

计算图 

自动微分 工具

、、等拓展包


其中，张量  可以理解为任意维度的数组——比如一维数组被称作向量，二维的被称作矩阵，这些都属于张量。有了张量，就有对应的基本操作，如取某行某列的值，张量乘以常数等。运用拓展包其实就相当于使用底层计算软件加速运算。
我们今天重点介绍的，就是计算图模型，以及自动微分两部分。首先介绍以  框架为例，谈谈如何实现自动求导，然后再用最简单的方法，实现这两部分。
 深度学习框架如何实现自动求导
诸如  这样的深度学习框架的入门，网上有大量的 几行代码、几分钟入门这样的资料，可以快速实现手写数字识别等简单任务。但如果想深入了解  的背后原理，可能就不是这么容易的事情了。这里我们简单的谈一谈这一部分。
我们知道，当我们拿到数据、训练神经网络时，网络中的所有参数都是 变量。训练模型的过程，就是如何得到一组最佳变量，使预测最准确的过程。这个过程实际上就是，输入数据经过 正向传播，变成预测，然后预测与实际情况的误差 反向传播 误差回来，更新变量。如此反复多次，得到最优的参数。这里就会遇到一个问题，神经网络这么多层，如何保证正向、反向传播都可以正确运行？
值得思考的是，这两种传播方式，都具有 管道传播 的特征。正向传播一层一层算就可以了，上一层网络的结果作为下一层的输入。而反向传播过程可以利用 链式求导法则，从后往前，不断将误差分摊到每一个参数的头上。
图片来源：博客

进过抽象化后，我们发现，深度学习框架中的 每一个模块都需要两个函数，一个连接正向，一个连接反向。这里的正向和反向，如同武侠小说中的 任督二脉。而训练模型的过程，数据通过正向传播生成预测结果，进而将误差反向传回更新参数，就如同让真气通过任督二脉在体内游走，随着训练误差逐渐缩小收敛，深度神经网络也将打通任督二脉。
接下来，我们将首先审视一下  框架的源码如何实现这两部分内容，其次我们通过  直接编写一个最简单的深度学习框架。

举  的  项目的例子是因为 的代码文件结构比较简单， 的规律和比较近似，但文件结构相对更加复杂，有兴趣的可以仔细读读相关文章。
  模块 源码 这个目录下的几乎所有  文件，都有这两个函数：
 
 
   _
      
      
   
    


  
   _
      
      
      
      
   
    


这里其实是相当于留了两个方法的定义，没有写具体功能。具体功能的代码，在  目录 中用  实现实现，具体以  函数举例。
我们知道  函数的形式是：

代码实现起来是这样：
 
 __ 
   
   
  
{
  _ 

  __   
    _ =   _
  
}

 函数求导变成：

所以这里在实现的时候就是：
 
 __
           
           
           
           
           
{
  __ 
  _ 
  __     
      =  _
    _ = _      
  
}

大家应该注意到了一点，  函数 _ 在等号左边， _ 在等号右边。 而  函数， _ 在等号左边， _ 在等号右边。 这里， =  对应的是 正向传播  =  对应的是 反向传播。
  用  直接编写一个最简单的深度学习框架
这部分内容属于“造轮子”，并且借用了优达学城的一个小型项目 。
数据结构部分
首先，我们实现一个父类 ，然后基于这个父类，依次实现    等模块。这里运用了简单的   继承。这些模块中，需要将  和  两个方法针对每个模块分别重写。

代码如下：
 
 
    
          

    

        `_`         
    
     ____ _=
        
                
            
        
                 
        _ = _
                 
           
         = 
                 
        _ = 
                  
                 
            
         = {}

                  
           
           _
            _

     
        
                  
             `` 
        
         

     
        
                  
             `` 
        
         


 
    
         
    
     ____
        ____

     
        

     
         = { }
           _
             = 

 
    
           
    
     ____   
        ____   

     
        
              
        
         = _
         = _
         = _
         =    

     
        
               
        
         = { _    _}
           _
            _ = 
            _ = _ _
            _ = _ _
            _ = _ = =


 
    
            
    
     ____ 
        ____ 

     _ 
        
             ``  
            ``  

        ``    
        
             

     
        
               
        
        _ = _
         = __

     
        
              
          
        
         = { _    _}
           _
            _ = 
             = 
            _ =       _

 
     ____ 
        
           
                 
        
        ____ 

     
        
          
        
        _ = _
          = _

     
        
             
        
         = { _    _}
           _
            _ = 
             = 
            _ =         _



 
     ____  
        
             
                 
        
        ____  

     
        
            
        
         = _ 
         = _ 

         = _
         =   
         = 

     
        
             
        
        _ =     
        _ =     

调度算法与优化部分
优化部分则会在以后的系列中单独详细说明。这里主要将简单讲一下图计算的算法调度。就是实际上的各个模块会生成一个有向无环图，如下图来源

在计算过程中，几个模块存在着相互依赖关系，比如要计算模块，就必须完成模块和模块，而要完成模块，就需要在之前顺次完成模块、；因此这里可以使用  算法作为调度算法下面的 _ 函数，从计算图中，推导出类似  的计算顺序。
 
 __
    
            

    `_`        ``            

         
    
    _ =     _
     = {}
     =     _
       
         = 
            
             = {   }
           _
                
                 = {   }
            
            
            

     = 
     = _
       
         = 
          
             = _

        
           _
            
            
              == 
                
     


 __
    
                 

    

        ``     `_`
    
       
        

       
        


 _ _=
    
           

    

        ``    ``   
        `_`   
    
       
         =   _  

使用模型
 

   
   


_ =        
                        
                        
_ =    
                    
                    
                    
_ =     
_ =   

_ =   
_ =  
_ = _

_ = _
_ = _
_ = _
_ = _

  =  
  =  
  =  

 =   
 = 
 =   
 = 
 =  

_ = {
     _    _
     _  _
     _  _
}

 = 
 = _
_ = 
__ =   _

 = __
 =    

__ = _
__ = _
__ = 

_ = 
   
     = 
       __
        _ _ = _ _ _=_
         = _
         = _
        __
        _ 
         = 

    _ = 
    _ = 
       
        
               ==    == 
                _ = 
               ==    == 
                _ = 
        
            

    ___
    ___
    __

来观察一下。当然还有更高级的可视化方法：__
 
   
 

 =  =
 = _
 = _   
 = __ == = = =
_

 =  =  



 = _
 = ____  == =
_
 =  =__ __

 = _
 = ____  == =
_
 =  =__ __

_
_ 

_
   __

我们注意到，随着训练轮数  不断增多，  值从最初的   不断接近   =   其背后的原因，是模型参数不断的从初始化的值变化、更新，如图中的   两个矩阵。

好了，最简单的轮子已经造好了。 我们的轮子，实现了     以及  这几个模块。 接下来的内容，我们将基于现在最火的轮子 ，详细介绍一下更多的模块。
最后，本篇只是造了个最基本的轮子，我们集智的知乎专栏上，有一个系列文章，正在介绍如何在上手写深度学习框架，传送门： 框架开发直播——全连接层的实现和优化，欢迎大家围观。
目前腾讯云  服务器还在内测阶段，暂时没有申请到内测资格的读者也可以使用普通的云服务器运行本讲的代码。但从第三讲开始，我们将逐渐开始使用  框架分析相关数据，对应的计算量大大增加，必须租用 云服务器 才可以快速算出结果。服务器的租用方式，以及  编程环境的搭建，我们将以腾讯云  为例，在接下来的内容中和大家详细介绍。什么是 ？
 是国人尤雨溪开发的一套前端框架。从去年开始，就火遍了国内外。究竟有多火？我们看下面这张图摘自：   ：

这是二月份  上的前端框架排名， 的  数位居第三，而去年十月时该排名页面中并未看到 。
腾讯工程师怎么玩 ？
 不只是创业公司在用，腾讯这样的大厂也用在了自己的项目中。 腾云阁上分享了不少鹅厂工程师的  实战经验。有教你如何入门的，有分享项目实战经验的，质量都很高。
快速上手
 包学会之浅入浅出 
该系列文章由腾讯用户体验设计部  空间高级  工程师蔡述雄分享，曾参与《众妙之门》书籍的翻译工作。目前专注前端图片优化与新技术的探研。
本系列包括： 开学篇、 升学篇、 结业篇。
 实战经验
上面提到，有不少鹅厂的项目用到了 ， 哥  妹们总结了以下这些经验，不要错过！
 企鹅社区移动版  升级手记
作者刘小松  年加入腾讯，从事区域业务的应用开发，具备十余年的项目经验。在  的应用、腾讯新闻和微信的  开发有深度实践。
企鹅社区移动版前端采用   开发。随着官方  的推出，前端界反响良好，由于项目本身在  的时候存在没有解决的问题，正好在  中得到解决，所以义无反顾地决定升级框架至  版本。
 动画在项目使用的两个示例
作者李萌是一位  前端开发从业者，目前就职于腾讯，喜欢 、 等技术，热爱新技术，热爱编程。 在文中分享了  在  项目中的动画使用案例，她认为，相对于  来说， 的动画效果完全带来了一种全新的体验。
 初体验： 插件开发实录
作者陈纬杰是一位  开发，平时跟  浏览器打交道最多，于是就利用  整了一个  插件可以及时预览对应  中的动画效果并生成对应的动画代码，这样在实际开发中碰到一些需要使用到  中的动画效果时，可以大大的提高我们的开发效率。
 进阶
用  开发完一个项目，就算精通  了吗？没看过源码，没学会做好优化，就别说这样的话哦。
  源码解析之前端渲染篇
作者王鹤是腾讯前端高级工程师，参与过  情侣、 星影联盟、 个性化装扮等项目的研发工作。秉承「不想当产品经理的程序员，不是好的设计师」。除敲敲代码外，对产品、设计、摄影也有一定的兴趣。
本文是系列文章，主要想通过对于   源码的分析，从代码层面解析  的实现原理，帮助读者能够更深入地理解整个框架的思想。此篇文章主要介绍前端渲染部分。
 前后端同构方案之准备篇——代码优化
还是王鹤同学的文章。 所在团队最新上线的项目是基于  的前端后端同构一体化实现的，运用了   。从代码的编写和维护角度上，已经比较不错了。而且本身  的开发效率就很高。此篇是准备篇，工欲善其事，必先利其器。我们先在代码层面进行优化，对我们完成整个技术架构是起到基础作用的。此准备篇是独立的，即使你们的项目不使用 ，也不影响文章的阅读，是代码的基础优化。
结语
如果你有一定的技术分享习惯，也想和鹅厂前端、后台技术大牛们深度交流。 大家好，很高兴今天能有机会和大家进行这个分享。我是腾讯云负责网络产品策划的产品经理高航，今天和大家分享的主题是《人人都是网络工程师》。
网络是个很复杂的东西，经常晚上有美女家里上不了网，就打电话给我说“高老师，我家网络坏了，快来帮我修一下”。修了几次之后，我就有了这样一个心得：网络工程师的桃花运都比较好。
当然，修复无线路由器只是小菜一碟：我一般都带个新的路由器过去，网络工程师的日常更多的时候是这样的：
凌晨点，刚刚完成网络变更的你，躺在舒服的床上准备睡觉，望着枕边熟睡的儿子，嘴边泛起一丝微笑，感觉未来都是亮的。突然手机“”声响起，短息告警显示核心交换机网络异常，内网丢包率。你不能多想，立即然后穿好衣服，奔向机房，看着下面一坨网线，陷入沉思，想到底是哪里又出了问题。

所以大部分网络工程师都有一个特点：黑眼圈。哈哈，这里就不调侃了，我们进入正题。

今天的主题是人人都是网络工程师，但是很明显在过去的很长一段时间，网络工程是一件很专业的事情。那么，我们先基本罗列一下在传统的环境下，一个组织想获得稳定可靠的网络环境需要做哪些事情呢？
一般来讲，网络系统的交付可以分成两个部分：网络的规划建设  网络的监控运营
    网络规划和建设
一个典型的网络可能像下面一样图片来自互联网，仅用于本次交流分享：

为了完成网络的规划和建设部署，工程师需要了解以下内容：

网络基础知识：协议、路由协议、、等、内网组网、联网

网络设备知识：常见品牌的交换机、路由器规格配置、性价比、可维护性

运营商知识：中国各省市运营商状况、专线及公网接入


其中第一条的网路基础知识，花年时间学习并完成课程应该可以搞定；
第二条的网络设备知识需要工程师有多个项目交付经验，对市场中常见品牌及型号有了解，同时具备熟悉的操作能力，年左右时间可以搞定；
第三条需要有实际项目和运营商经验，可以在第二条基础之上一同学习。简单来说，至少需要年左右时间，才可以具备独立搞定一套网络的知识储备当然大神学习特别快的不特殊而论哈。不过很明显，一般人真搞不定！
 网络监控及运营
网络建设整体交付后，为了保证整个网络的可运维性，需要配套开发一整套网络监控和管理系统。一般私有云交付会提供配套的网络监控系统，如果是按照自己的需求从头到尾自己弄，那配套需要一个运营开发团队才能按照基础架构库的模式搭建起一套完成的网络监控、故障派单的系列管理系统。
系统搭建起来后，还需要雇用一个专业的网络运营团队×小时不间断进行网络的运维监控，发现问题在一定时间内完成系统的应急修复。如果发现基础业务网络架构拓扑无法满足需求，还需要额外补充建设环路以保证网络互连可用性。下面是一个看起来比较酷炫的网络运营中心监控中心形象。

说了这么多，总结起来一句话：
在传统的架构中，人人来做网络工程师，痴心妄想不仅建设规划的时候要下血本，后期的监控运维也要付出很大的人力代价。
然而，公有云的普及给人人都是网络工程师一个机会！

这是一个典型的公有云和用户的服务分界。无论是通过标准的网络虚拟化协议，还是通过腾讯云这样自研的层隧道封装，公有云服务商都普遍在网络层来划定用户和平台的边界。层协议全世界都是标准的，刚刚上面写的传统网络部署中，不标准的交换机、路由器和运营商网络环境，都被公有云提抽象成了标准的网络服务组件，复杂的运营商网络环境通过统一的出口和附带有的标准网络服务来代替。
只要你在计算机专业学过简单的图知识，花天时间看一下协议和基本的静态路由知识，就可以分分钟在公有云平台上部署起一套金融级网络架构。下面我分别简单介绍一下公有云提供的网络服务，并和传统网络环境做一下对比。

    公网服务
用户在公有云上部署的集群，大部分用于对外提供服务。公有云的用户不需要理解中国有多少家运营商电信、联通、移动、长城宽带、教育网……还有几十家可以列出来，也不需要理解各家运营商分布在哪些区域，覆盖哪些客户，自己的客户都在用什么网络。你只要知道有你有一个很的公网，这个很牛逼可以服务所有的客户就好了。如果你是一个有追求的人，还可以从监控平台看一下这个辐射中国大江南北各种用户的时延和可用性。
公有云厂商为了实现这样简单的用户体验，至少要做以下几样事情：

运营商融合：购买支持多运营商的公网和带宽腾讯云聚合了家运营商，还在增加。如果是传统网络，只能用户自己一家一家的去接入，同时还要自己估算每家的接入带宽，事实告诉我们这些预估总是不准确的，一部分超出的会导致成本徒增，一部分低估的会在业务增长时成为瓶颈。公有云平台一般都是按量的，不存在这样的问题

大带宽出口预备：通过足够大的公网带宽保证用户的服务波峰不会阻塞网络出口，同时入流量攻击不会影响正常网络服务，单出口没有个都不好意思说平台是搞公有云的。如果是传统网络架构，多买的带宽，就要付的成本，为了保证不停服需要提前购买很多网络带宽导致网络带宽成本居高不下，而公有云上面就可以实现全面的按量计费，用多少付多少的钱，平台通过足够多的客户来削峰填谷降低单个客户的成本。

网络流量调度：使用或手动方式使网络流量可以跨出口调度以应对运营商的网络故障，比如北京电信的网络断了，就把流量切到上海电信。这个能力在国内也只有腾讯、阿里这样的互联网公司提供的网络有，其他中小型公有云厂商最多只能做到运营商之间来做流量切换电信流量临时切换至联通，业务峰值时跨运营商的流量切换业务时延基本没有保证。而传统网络下，基本没可能做此类流量调度方案，原因很简单：一个字，贵！

流量清洗：由于用户体量大，公有云平台被攻击的风险也很大，过去一段时间我统计腾讯云左右的攻击每天平均次，以上的攻击每个星期也会出现几次，因此强大的流量清洗能力也是公有云平台的必备能力。传统网络中只能借助第三方清洗平台，而且价格十分之贵。


    内网服务
内网服务方面，公有云平台为了方便用户配置，一般会提供这样的虚拟专有云服务。通过对基础网络环境进行虚拟化，用户可以自行规划自己云主机的内网、内网网段、划分子网、指定路由等等，底层的交换机、路由器设备可能有各种各样的型号，但是最终都通过虚拟化整合成了一套虚拟化后的网络结构，这样用户只要学习一边公有云的网络架构后，再也不需要去感知硬件厂商的各种变化和更新了。
公有云上，划分子网、变更路由等操作都是在可视化的  控制台中操作的，不用担心对网络对象的变更是否会影响到其他业务服务触发重大事故。鼠标点一点，输入一下核心参数，一个网络变更就完成了。像、腾讯云这样在设计上还支持了子网的策略路由功能，每次路由变更也只会对关联子网范围内生效，其他子网根本不受影响。是不是感觉心里顿时少了一块大石？
为了更加简化用户使用公有云的网络服务，公有云厂商还会对标准的边界网关进行开发，提供黑核型的边界网关服务，以腾讯云为例，我们提供了：

网关：用于云主机主动访问

 网关：用于建立 连接

  网关：用于建立 连接

专线网关：用于接入专线，并提供专线两端的网络地址转换功能

对等连接：用于公有云上同地域或不同地域之间的互联


各种边界网关、内网路由的可用性等都无需考虑双路由等设计，因为云平台厂商已经在底层网关设计、路由设计底层做了主备容灾切换逻辑，部分容灾是在同机房的不同设备上，部分容灾是在不同机房的不同设备上而已。
内网服务部分，各大云厂商平台还会提供安全组这样的通用安全策略工具，通过为云主机配置差异化的安全策略，就可以实现金融级的网络访问权限管理。
    网络监控、告警及故障处理
完成了系统部署之后，大部分公有云平台还会提供全面的网络监控和告警功能，当每个监控对象触发了告警策略之后，即会通过你所配置的通信方式联系到你。如果是容量告警，您可以在控制台分分钟搞定网络扩容而不停服；如果是底层网络故障，那么无论是运营商层、设备层、服务对象层都会有云平台的工程师第一时间为您处理，您自己无需做很多现场的操作。
这里交给大型公有云厂商的好处显而易见：网络的故障不仅会影响你的服务，也会影响、微信等服务，你在云上的部署相当于享受着和国际顶尖服务一样的网络运维管理能力当然中小型厂商的云服务运维能力我这儿无法一一鉴定，比起自己搭建私有云，自己雇人来管理可靠得多！
那么看着这么眼花缭乱的功能，真的能做到人人都是网络工程师吗？
当然可以！只要你掌握了下面几个基础知识，就可以完全胜任公有云平台上的网络管理工作：
大学计算机基础  计算机网络等级考试  及格即可我记得大学考网络三级考试也就花了天时间刷刷题，就过了…
有了上面的基础知识，如果让我面授一下，基本上天之后可以完成控制台所有的网络操作和管理了。如果是看文档会比较抽象，不过自学能力强的同学有个星期也可以玩个差不多了。
核心知识点：

定义和子网 ；

公有云路由优先级的匹配规则一般是最精确路由匹配；

根据业务需要，熟悉常见的网关对象，比如网关、网关等；

配置基本的安全组策略；

上手实操，边玩边学；

网络地址转换高级功能，上手可以先不用看。


只需要这几步，已经可以给公有云上的用户做网络架构规划了，而自学这些最多不需要周的时间，你说未来是不是一个“人人都是网络工程师”的年代？
当然“人人都是网络工程师”也不是特别好，因为越来越多的公司转向公有云后，很多公司原有的网络工程师会被开发或者少数的几个运维替代，从而不可避免的面临失业问题。不过从全世界角度来看，私有云和混合云的部署方式还会长期存在，所以也不用特别担心这些问题哈。
好，今天的分享到此结束，感谢大家的参与！大家有什么问题可以在线上提问哈。
相关推荐腾讯云总监手把手教你，如何成为工程师？腾讯云技术公开课：零基础入门高可用云端架构设计架构的分析模型
一    讨论的背景
现代电子游戏，基本上都会使用一定的网络功能。从验证正版，到多人交互等等，都需要架设一些专用的服务器，以及编写在服务器上的程序。因此，游戏服务器端软件的架构，本质上也是游戏服务器这个特定领域的软件架构。
软件架构的分析，可以通过不同的层面入手。比较经典的软件架构描述，包含了以下几种架构：

运行时架构——这种架构关心如何解决运行效率问题，通常以程序进程图、数据流图为表达方式。在大多数开发团队的架构设计文档中，都会包含运行时架构，说明这是一种非常重要的设计方面。这种架构也会显著的影响软件代码的开发效率和部署效率。本文主要讨论的是这种架构。

逻辑架构——这种架构关心软件代码之间的关系，主要目的是为了提高软件应对需求变更的便利性。人们往往会以类图、模块图来表达这种架构。这种架构设计在需要长期运营和重用性高的项目中，有至关重要的作用。因为软件的可扩展性和可重用度基本是由这个方面的设计决定的。特别是在游戏领域，需求变更的频繁程度，在多个互联网产业领域里可以说是最高的。本文会涉及一部分这种架构的内容，但不是本文的讨论重点。

物理架构——关心软件如何部署，以机房、服务器、网络设备为主要描述对象。

数据架构——关心软件涉及的数据结构的设计，对于数据分析挖掘，多系统协作有较大的意义。

开发架构——关心软件开发库之间的关系，以及版本管理、开发工具、编译构建的设计，主要为了提高多人协作开发，以及复杂软件库引用的开发效率。现在流行的集成构建系统就是一种开发架构的理论。


二    游戏服务器架构的要素
服务器端软件的本质，是一个会长期运行的程序，并且它还要服务于多个不定时，不定地点的网络请求。所以这类软件的特点是要非常关注稳定性和性能。这类程序如果需要多个协作来提高承载能力，则还要关注部署和扩容的便利性；同时，还需要考虑如何实现某种程度容灾需求。由于多进程协同工作，也带来了开发的复杂度，这也是需要关注的问题。
功能约束，是架构设计决定性因素。一个万能的架构，必定是无能的架构。一个优秀的架构，则是正好把握了对应业务领域的核心功能产生的。游戏领域的功能特征，于服务器端系统来说，非常明显的表现为几个功能的需求：

对于游戏数据和玩家数据的存储

对玩家客户端进行数据广播

把一部分游戏逻辑在服务器上运算，便于游戏更新内容，以及防止外挂。


针对以上的需求特征，在服务器端软件开发上，我们往往会关注软件对电脑内存和的使用，以求在特定业务代码下，能尽量满足承载量和响应延迟的需求。最基本的做法就是“时空转换”，用各种缓存的方式来开发程序，以求在时间和内存空间上取得合适的平衡。在和内存之上，是另外一个约束因素：网卡。网络带宽直接限制了服务器的处理能力，所以游戏服务器架构也必定要考虑这个因素。
对于游戏服务器架构设计来说，最重要的是利用游戏产品的需求约束，从而优化出对此特定功能最合适的“时空”架构。并且最小化对网络带宽的占用。

图：游戏服务器的分析模型
三    核心的三个架构
基于上述的分析模型，对于游戏服务端架构，最重要的三个部分就是，如何使用、内存、网卡的设计：

内存架构：主要决定服务器如何使用内存，以保证尽量少的内存泄漏的可能，以及最大化利用服务器端内存来提高承载量，降低服务延迟。

调度架构：设计如何使用进程、线程、协程这些对于调度的方案。选择同步、异步等不同的编程模型，以提高服务器的稳定性和承载量。同时也要考虑对于开发带来的复杂度问题。现在出现的虚拟化技术，如虚拟机、、云服务器等，都为调度架构提供了更多的选择。

 通信模式：决定使用何种方式通讯。网络通讯包含有传输层的选择，如；据表达层的选择，如定义协议；以及应用层的接口设计，如消息队列、事件分发、远程调用等。


本文的讨论，也主要是集中于对以上三个架构的分析。
四    游戏服务器模型的进化历程
最早的游戏服务器是比较简单的，如《网络创世纪》的服务端一张寸软盘就能存下。基本上只是一个广播和存储文件的服务器程序。后来由于国内的外挂、盗版流行，各游戏厂商开始以为模型，建立主要运行逻辑在服务器端的架构。这种架构在类产品的不断更新中发扬光大，从而出现了以地图、视野等分布要素设计的分布式游戏服务器。而在另外一个领域，休闲游戏，天然的需要集中超高的在线用户，所以全区型架构开始出现。现代的游戏服务器架构，基本上都希望能结合承载量和扩展性的有点来设计，从而形成了更加丰富多样的形态。
本文的讨论主要是选取这些比较典型的游戏服务器模型，分析其底层各种选择的优点和缺点，希望能探讨出更具广泛性，更高开发效率的服务器模型。
分服模型
一    模型描述
分服模型是游戏服务器中最典型，也是历久最悠久的模型。其特征是游戏服务器是一个个单独的世界。每个服务器的帐号是独立的，而且只用同一服务器的帐号才能产生线上交互。在早期服务器的承载量达到上限的时候，游戏开发者就通过架设更多的服务器来解决。这样提供了很多个游戏的“平行世界”，让游戏中的人人之间的比较，产生了更多的空间。所以后来以服务器的开放、合并形成了一套成熟的运营手段。一个技术上的选择最后导致了游戏运营方式的模式，是一个非常有趣的现象。

图：分服模型
二    调度架构
  单进程游戏服务器
最简单的游戏服务器只有一个进程，是一个单点。这个进程如果退出，则整个游戏世界消失。在此进程中，由于需要处理并发的客户端的数据包，因此产生了多种选择方法：
图：单进程调度模型

同步动态多线程：每接收一个用户会话，就建立一个线程。这个用户会话往往就是由客户端的连接来代表，这样每次从中调用读取或写出数据包的时候，都可以使用阻塞模式，编码直观而简单。有多少个游戏客户端的连接，就有多少个线程。但是这个方案也有很明显的缺点，就是服务器容易产生大量的线程，这对于内存占用不好控制，同时线程切换也会造成的性能损失。更重要的多线程下对同一块数据的读写，需要处理锁的问题，这可能让代码变的非常复杂，造成各种死锁的，影响服务器的稳定性。

同步多线程池：为了节约线程的建立和释放，建立了一个线程池。每个用户会话建立的时候，向线程池申请处理线程的使用。在用户会话结束的时候，线程不退出，而是向线程池“释放”对此线程的使用。线程池能很好的控制线程数量，可以防止用户暴涨下对服务器造成的连接冲击，形成一种排队进入的机制。但是线程池本身的实现比较复杂，而“申请”、“施放”线程的调用规则需要严格遵守，否则会出现线程泄露，耗尽线程池。

异步单线程协程：在游戏行业中，采用的作为网络，以期得到高性能，是一个常见的选择。游戏服务器进程中最常见的阻塞调用就是网路，因此在采用之后，整个服务器进程就可能变得完全没有阻塞调用，这样只需要一个线程即可。这彻底解决了多线程的锁问题，而且也简化了对于并发编程的难度。但是，“所有调用都不得阻塞”的约束，并不是那么容易遵守的，比如有些数据库的就是阻塞的；另外单进程单线程只能使用一个，在现在多核多的服务器情况下，不能充分利用资源。异步编程由于是基于“回调”的方式，会导致要定义很多回调函数，并且把一个流程里面的逻辑，分别写在多个不同的回调函数里面，对于代码阅读非常不理。——针对这种编码问题，协程能较好的帮忙，所以现在比较流行使用异步协程的组合。不管怎样，异步单线程模型由于性能好，无需并发思维，依然是现在很多团队的首选。

异步固定多线程：这是基于异步单线程模型进化出来的一种模型。这种模型一般有三类线程：主线程、线程、逻辑线程。这些线程都在内部以全异步的方式运行，而他们之间通过无锁消息队列通信。


  多进程游戏服务器
多进程的游戏服务器系统，最早起源于对于性能问题需求。由于单进程架构下，总会存在承载量的极限，越是复杂的游戏，其单进程承载量就越低，因此开发者们一定要突破进程的限制，才能支撑更复杂的游戏。
一旦走上多进程之路，开发者们还发现了多进程系统的其他一些好处：能够利用上多核能力；利用操作系统的工具能更仔细的监控到运行状态、更容易进行容灾处理。多进程系统比较经典的模型是“三层架构”：
在多进程架构下，开发者一般倾向于把每个模块的功能，都单独开发成一个进程，然后以使用进程间通信来协调处理完整的逻辑。这种思想是典型的“管道与过滤器”架构模式思想——把每个进程看成是一个过滤器，用户发来的数据包，流经多个过滤器衔接而成的管道，最后被完整的处理完。由于使用了多进程，所以首选使用单进程单线程来构造其中的每个进程。这样对于程序开发来说，结构清晰简单很多，也能获得更高的性能。
图经典的三层模型
尽管有很多好处，但是多进程系统还有一个需要特别注意的问题——数据存储。由于要保证数据的一致性，所以存储进程一般都难以切分成多个进程。就算对关系型数据做分库分表处理，也是非常复杂的，对业务类型有依赖的。而且如果单个逻辑处理进程承载不了，由于其内存中的数据难以分割和同步，开发者很难去平行的扩展某个特定业务逻辑。他们可能会选择把业务逻辑进程做成无状态的，但是这更加加重了存储进程的性能压力，因为每次业务处理都要去存储进程处拉取或写入数据。
除了数据的问题，多进程也架构也带来了一系列运维和开发上的问题：首先就是整个系统的部署更为复杂了，因为需要对多个不同类型进程进行连接配置，造成大量的配置文件需要管理；其次是由于进程间通讯很多，所以需要定义的协议也数量庞大，在单进程下一个函数调用解决的问题，在多进程下就要定义一套请求、应答的协议，这造成整个源代码规模的数量级的增大；最后是整个系统被肢解为很多个功能短小的代码片段，如果不了解整体结构，是很难理解一个完整的业务流程是如何被处理的，这让代码的阅读和交接成本巨高无比，特别是在游戏领域，由于业务流程变化非常快，几经修改后的系统，几乎没有人能完全掌握其内容。
三    内存架构
由于服务器进程需要长期自动化运行，所以内存使用的稳定是首要大事。在服务器进程中，就算一个触发几率很小的内存泄露，都会积累起来变成严重的运营事故。需要注意的是，不管你的线程和进程结构如何，内存架构都是需要的，除非是这种不使用堆的函数式语言。
  动态内存
在需要的时候申请内存来处理问题，是每个程序员入门的时候必然要学会的技能。但是，如何控制内存释放却是一个大问题。在语言中，对于堆的控制至关重要。有一些开发者会以树状来规划内存使用，就是一般只一个主要的类型的对象，其他对象都是此对象的成员或者指针成员，只要这棵树上所有的对象都管理好自己的成员，就不会出现内存漏洞，整个结构也比较清晰简单。图对象树架构
在 语言中，有所谓的特性，这种特性实际上是一种引用计数的技术。由于能配合在某个调度模型下，所以使用起来会比较简单。同样的思想，有些开发者会使用一些智能指针，配合自己写的框架，在完整的业务逻辑调用后一次性清理相关内存。
图根据业务处理调度管理内存池
在带虚拟机的语言中，最常见的是，这个问题一般会简单一些，因为有自动垃圾回收机制。但是，中的容器类型、以及变量依然是可能造成内存泄露的原因。加上无规划的使用线程，也有可能造成内存的泄露——有些线程不会退出，而且在不断增加，最后耗尽内存。所以这些问题都要求开发者专门针对变量以及线程结构做统一设计、严格规范。
  预分配内存
动态分配内存在小心谨慎的程序员手上，是能发挥很好的效果的。但是游戏业务往往需要用到的数据结构非常多，变化非常大，这导致了内存管理的风险很高。为了比较彻底的解决内存漏洞的问题，很多团队采用了预先分配内存的结构。在服务器启动的时候分配所有的变量，在运行过程中不调用任何关键字的代码。
这样做的好处除了可以有效减少内存漏洞的出现概率，也能降低动态分配内存所消耗的性能。同时由于启动时分配内存，如果硬件资源不够的话，进程就会在启动时失败，而不是像动态分配内存的程序一样，可能在任何一个分配内存的时候崩溃。然而，要获得这些好处，在编码上首先还是要遵循“动态分配架构”中对象树的原则，把一类对象构造为“根”对象，然后用一个内存池来管理这些根对象。而这个内存池能存放的根对象的数目，就是此服务进程的最大承载能力。一切都是在启动的时候决定，非常的稳妥可靠。
图预分配内存池
不过这样做，同样有一些缺点：首先是不太好部署，比如你想在某个资源较小的虚拟机上部署一套用来测试，可能一位内没改内存池的大小，导致启动不成功。每次更换环境都需要修改这个配置。其次，是所有的用到的类对象，都要在根节点对象那里有个指针或者引用，否则就可能泄漏内存。由于对于非基本类型的对象，我们一般不喜欢用拷贝的方式来作为函数的参数和返回值，而指针和应用所指向的内存，如果不能的话，只能是现成的某个对象的成员属性。这回导致程序越复杂，这类的成员属性就越多，这些属性在代码维护是一个不小的负担。
要解决以上的缺点，可以修改内存池的实现，为动态增长，但是具备上限的模型，每次从内存池中“获取”对象的时候才。这样就能避免在小内存机器上启动不了的问题。对于对象属性复杂的问题，一般上需要好好的按面向对象的原则规划代码，做到尽量少用仅仅表示函数参数和返回值的属性，而是主要是记录对象的“业务状态”属性为主，多花点功夫在构建游戏的数据模型上。
四    进程间通讯手段
在多进程的系统中，进程间如何通讯是一个至关重要的问题，其性能和使用便利性，直接决定了多进程系统的技术效能。
  通讯
协议是一种通用的、跨语言、跨操作系统、跨机器的通讯方案。这也是开发者首先想到的一种手段。在使用上，有使用和两个选择。一般我们倾向在游戏系统中使用，因为游戏数据的逻辑相关性比较强，由于可能存在的丢包和重发处理，在游戏逻辑上的处理一般比较复杂。由于多进程系统的进程间网络一般情况较好，的性能优势不会特别明显。
要使用做跨进程通讯，首先就是要写一个 ，做端口监听和连接管理；其次需要对可能用到的通信内容做协议定制；最后是要编写编解码和业务逻辑转发的逻辑。这些都完成了之后，才能真正的开始用来作为进程间通信手段。
使用编程的好处是通用性广，你可以用来实现任何的功能，和任何的进程进行协作。但是其缺点也异常明显，就是开发量很大。虽然现在有一些开源组件，可以帮你简化 的编写工作，简化连接管理和消息分发的处理，但是选择目标建立连接、定制协议编解码这两个工作往往还是要自己去做。游戏的特点是业务逻辑变化很多，导致协议修改的工作量非常大。因此我们除了直接使用 以外，还有很多其他的方案可以尝试。
图通讯
  消息队列
在多进程系统中，如果进程的种类比较多，而且变化比较快，大量编写和配置进程之间的连接是一件非常繁琐的工作，所以开发者就发明了一种简易的通讯方法——消息队列。这种方法的底层还是通讯实现，但是使用者只需要好像投递信件一样，把消息包投递到某个“信箱”，也就是队列里，目标进程则自动不断去“收取”属于自己的“信件”，然后触发业务处理。
这种模型的好处是非常简单易懂，使用者只需要处理“投递”和“收取”两个操作即可，对于消息也只需要处理“编码”和“解码”两个部分。在规范中，就有定义一套消息队列的规范，叫， 就是一个应用广泛的实现者。在环境下，我们还可以利用共享内存，来承担消息队列的存储器，这样不但性能很高，而且还不怕进程崩溃导致未处理消息丢失。
图消息队列
需要注意的是，有些开发者缺乏经验，使用了数据库，如，或者是这类运行效率比较低的媒介作为队列的存储者。这在功能上虽然可以行得通，但是操作一频繁，就难以发挥作用了。如以前有一些手机短信应用系统，就用来存储“待发送”的短信。
消息队列虽然非常好用，但是我们还是要自己对消息进行编解码，并且分发给所需要的处理程序。在消息到处理程序之间，存在着一个转换和对应的工作。由于游戏逻辑的繁多，这种对应工作完全靠手工编码，是比较容易出错的。所以这里还有进一步的改进空间。
  远程调用
有一些开发者会希望，在编码的时候完全屏蔽是否跨进程在进行调用，完全可以好像调用本地函数或者本地对象的方法一样。于是诞生了很多远程调用的方案，最经典的有方案，它试图实现能在不同语言的代码直接，实现远程调用。虚拟机自带了方案的支持，在进程之间远程调用是比较方便的。在互联网的环境下，还有各种 方案，以协议作为承载，作为接口描述。
使用远程调用的方案，最大好处是开发的便捷，你只需要写一个函数，就能在任何一个其他进程上对此函数进行调用。这对游戏开发来说，就解决了多进程方案最大的一个开发效率问题。但是这种便捷是有成本的：一般来说，远程调用的性能会稍微差一点，因为需要用一套统一的编解码方案。如果你使用的是这类静态语言，还需要使用一种语言来先描述这种远程函数的接口。但是这些困难带来的好处，在游戏开发领域还是非常值得的。
 图远程调用
五    容灾和扩容手段
在多进程模型中，由于可以采用多台物理服务器来部署服务进程，所以为容灾和扩容提供了基础条件。
在单进程模型下，容灾常常使用的热备服务器，依然可以在多进程模型中使用，但是开着一台什么都不做的服务器完全是为了做容灾，多少有点浪费。所以在多进程环境下，我们会启动多个相同功能的服务器进程，在请求的时候，根据某种规则来确定对哪个服务进程发起请求。如果这种规则能规避访问那些“失效”了的服务进程，就自动实现了容灾，如果这个规则还包括了“更新新增服务进程”的逻辑，就可以做到很方便的扩容了。而这两个规则，统一起来就是一条：对服务进程状态的集中保存和更新。
为了实现上面的方案，常常会架设一个“目录”服务器进程。这个进程专门负责搜集服务器进程的状态，并且提供查询。就是实现这种目录服务器的一个优秀工具。
图服务器状态管理
尽管用简单的目录服务器可以实现大部分容灾和扩容的需求，但是如果被访问进程的内存中有数据存在，那么问题就比较复杂了。对于容灾来说，新的进程必须要有办法重建那个“失效”了的进程内存中的数据，才可能完成容灾功能；对于扩容功能来说，新加入的进程，也必须能把需要的数据载入到自己的内存中才行，而这些数据，可能已经存在于其他平行的进程中，如何把这部分数据转移过来，是一个比较耗费性能和需要编写相当多代码的工作。——所以一般我们喜欢对“无状态”的进程来做扩容和容灾。分享本周一些特别精选的极客设计和技术内容，希望大家喜欢并且持续关注
房间展示
来自法国的网站，使用基于的技术来展示房间的造型及其参观体验，相信大家一定会有身临其境的感觉


一个帮助你寻找设计灵感和效果的网站，每天都会发布新的设计内容

   
一个新的 的移动组件类库，方便你快速定制化开发

实现的细胞变形效果
使用 来实现的多中细胞样式的变形效果，超级炫酷，大家可以体验一下

 
一些惊为天人的效果演示，绝对值得一看

实现的绘图特效
来自的一个使用实现的铅笔绘图效果


一个符合现代版本特性的终端工具实现，包括： 自动补齐， 永久的命令行历史记录等等高级特性

   
开发者使用的标准指南网站

以上就是本周新奇设计技术相关的玩意儿荟萃， 有兴趣的朋友，可以持续关注更多内容。我们每个人每天都会使用到不同的推荐系统，无论是听歌，购物，看视频，还是阅读新闻，推荐系统都可以根据你的喜好给你推荐你可能感兴趣的内容。不知不觉之间，推荐系统已经融入到我们的生活当中。作为大数据时代最重要的几个信息系统之一，推荐系统主要有下面几个作用：

提升用户体验。通过个性化推荐，帮助用户快速找到感兴趣的信息。

提高产品销售。推荐系统帮助用户和产品建立精准连接，从而提高产品转化率。

发掘长尾价值。根据用户兴趣推荐，使得平时不是很热门的商品可以销售给特定的人群。

方便移动互联网用户交互。通过推荐，减少用户操作，主动帮助用户找到他感兴趣的内容。


以应用宝为例，对于两个不同用户和，打开应用程序的界面是很不一样的。用户是一个年轻男性用户，平时可能喜欢玩手机游戏和看小说，所以应用宝的推荐系统会给他推荐游戏的应用。而用户是一个年轻女性用户，平时喜欢购物和轻游戏，所以应用的推荐系统就会给她推荐购物的应用。这样一来，从用户的角度，减少了他找到自己喜欢的应用的时间；从产品的角度，用户更愿意去点击和安装他喜欢的应用，所以提高了产品的转化率。

图 应用宝首页界面
除了应用宝之外，腾讯云推荐系统还应用在腾讯的空间、、企鹅、会员和黄钻贵族等个不同的业务的多个不同推荐场景，每天处理的推荐请求有上百亿个。那么，这个日均百亿级请求的推荐系统是怎么打造而成的呢？主要需要解决两个问题：

支持众多业务和场景。

支持海量用户请求。


通用化推荐算法库
首先要解决的问题是如何支持众多业务和场景。对于不同的场景，用到的数据、算法和模型都会有很多的不同，如果对于每个场景都从头开发，将会耗费非常多的时间和人力。那么有没有更好的方法呢？毕竟常用的推荐算法就是那么几种，有没有一种方法使得同一个推荐算法可以复用到不同的推荐场景呢？那就需要对推荐算法库进行通用化设计。
下面举一个例子来说明推荐系统是什么，又是怎么工作的。如图所示，一个推荐系统是由学习系统、模型和推荐系统三部分组成的。其中，学习系统通过机器学习的方法对用户的历史数据进行统计、分析，从而训练得到一个模型。这个模型是用户行为规律的总结，会在后面预测系统中对新用户的请求进行预测。比如图中简单的例子，学习系统的输入是个不同用户的行为，对于男性用户，他喜欢的《王者荣耀》这个游戏，对于女性用户，她喜欢的则是《奇迹暖暖》，那么对于这个用户统计得到的模型是男性用户喜欢《王者荣耀》的概率是，而女性用户喜欢《奇迹暖暖》的概率是。有了这个简单的模型以后，如果在预测系统中有一个新的用户请求，来自一个男性用户，那么按照前面的模型，会按照概率的大小，把《王者荣耀》推荐给这个用户。

图 推荐系统例子
实际的推荐系统中，学习系统处理的用户数据量会更大，数据的维度也更多，用到的推荐模型也会更复杂，常用的有协同模型、内容模型和知识模型。其中，协同模型主要通过我的朋友喜欢什么来猜测我喜欢这么；内容模型则是根据物品本身来预测用户喜欢所以也可能喜欢；知识模型则是根据用户的限定条件，按照他的需要进行推荐。

图 通用化推荐算法库
一个常见的推荐系统由下面四个部分组成：样本库、特征库、 算法和模型。其中，样本库存储从流水日志中提取的用户行为和特征；特征库存储用户和物品的属性等特征；算法是用于训练模型用到的机器学习算法；模型库存储的是从样本和特征计算得到的训练模型。为了不同的算法可以用于不同的样本和特征，我们可以使用图中的算法配置表来存储数据、算法和模型的映射关系，将模型、算法、样本和特征的关系解耦，使得算法可以复用。比如，我的模型是从样本和特征使用算法训练得到。

图 推荐系统的离线和在线计算分工
学习系统训练一个模型一般会花比较长的时间，这部分我们称为离线计算，对实时性要求并不高，比如，可以在几个小时的时间内计算出来，重要的是模型的质量。而预测系统则不一样，因为预测系统是直接面向用户请求，所以要求它响应快，同时必须能够处理海量用户的请求，系统必须稳定可靠。接下去我们会使用一个实时计算平台来满足这部分的要求。
面向海量在线服务的实时计算平台
除了前面提到的通用化算法库，我们需要解决的第二个问题是如何处理海量的用户请求。这部分我们用的是一个名为的面向海量在线服务的自研实时计算平台。有下面几个特点：

海量，目前在系统上，每天处理上百亿的个性化推荐请求；

实时，每个请求的处理平均延时为；

可靠，系统稳定性为。


从一开始就是围绕线上服务而设计。首先，为了快速处理海量请求，我们参考了 ，把定义成一个流处理框架。其次，为了系统的高可用性，在设计的时候，考虑了系统不会出现单点故障。第三，为了方便扩容，计算资源是可插拔的。第四，系统可以支持动态调度以方便负载平衡。第五，为了方便运维，还紧密结合运维工具提供告警和监控。
我们先来看一下这个流处理框架是如何处理推荐请求的。如图所示的推荐场景用于猜测用户喜欢的手机应用，可以分为三步来计算：

根据得到用户特征；

使用决策树判断喜欢某个应用的概率；

对结果重新排序。其中，使用决策树这一步因为计算量大，可以通过并行计算来缩短处理时间，每个处理单元可以处理子树的一部分，最后在第三步将结果汇总以后重新排序。



图 流计算场景：猜测用户喜欢的手机应用
的架构如图所示，分为业务层、通信层和全局配置层三层。其中，业务层负责业务处理逻辑；通信层负责基于名字的通信和分布式流处理；全局配置层负责可适应的拓扑配置、动态扩缩容和动态负载调度。

图 实时计算平台架构
其中，业务层由两部分组成：计算拓扑图和计算单元。计算拓扑图负责数据的流向，而计算单元负责业务的逻辑计算。通信层负责之间的通信以及拓扑图执行跟踪。其中，负责从业务接入请求，负责跟踪拓扑图执行情况，而负责转发之间的通信、启动和监控心跳。之间的通信都通过转发。全局配置层负责拓扑管理和名字服务，通过来进行动态配置。其中，拓扑管理将逻辑拓扑映射到物理拓扑，名字服务提供地址查询。
腾讯云推荐引擎
基于上面的经验，我们打造了腾讯云推荐引擎。腾讯云推荐引擎是面向广大中小互联网企业打造的一站式云推荐引擎解决方案，提供安全、便捷、精准、可靠的推荐系统服务，提升其业务的点击转化率和用户体验。如图所示，由算法模型和在线计算两部分组成。算法模型部分由于采用了通用推荐算法库设计，用户在接入推荐场景时只需要通过简单配置，就可以直接使用已有的算法模版。在线计算部分集成了的优势，系统稳定可靠，并且支持快速扩容。

图 腾讯云推荐引擎
腾讯云推荐引擎具有下面的功能：

一天接入，快速上线；

模板化算法，节省代码；

快速扩容，应对业务快速增长；

稳定可靠，节省运维开销。


这些功能降低了推荐系统的技术门槛，使得搭建推荐系统变得简单便捷。更多有关腾讯云推荐引擎的信息请点击查看
总结
综上所述，要打造一个百亿级通用推荐系统，需要考虑下面几点：
为了能够支持尽可能多的业务和场景，推荐算法库需要做通用化设计。
为了支撑海量在线用户的实时请求，实时计算平台必须低延时，可扩展，而且稳定可靠。
云推荐引擎的解决方案，在通用化的基础上，同时考虑了易用性，方便用户接入。

相关推荐 大规模排行榜系统实践及挑战作者：

首先看的使用方法，详细的看这里。
使用配置如下：

    ={{
        
        
        
        
        
        
    }}
    ={}
    ={}
    ={}
    ={}
    {}


源码分析
基于。我们首先分析的代码。我们先创建一个空的组件，命名为。
 {}  

   {
    {
         
            
        
    }
}

接下来我们来完善这个组件。
类型验证
的属性包括









七个。其中||是一个布尔值，用于标识是否开启这个过度动画。||是一个数值，用于指定对应过渡动画的总时长。如果||等于，那么对应的||就必须存在并且类型为。根据以上论述，组件的应该为：
 = {
     = 先搁置这部分 
     
     
     
     
     
     
}

方法用于根据过渡类型生成验证函数，其代码为：
  =  = {
      = `{}`
         = 
      = {
         当过渡为时
        {
            如果对应不存在，验证不通过
             == {
                  
            如果不为数值类型，验证不通过
            }   == {
                  
            }
        }
    }
}

现在来看属性的类型。可以是一个字符串
={}

也可以是一个对象，如果是对象的话，必须包含以下六个属性。
={{
   
   
   
   
   
   
}}

所以的属性值限制为：
 
    
    {
         
         
         
         
         
         
    }


过渡实现原理
会在数量发生变化时候调用对应的钩子方法。在下面的例子中：

     


初次加载的时候会给每个加一个，然后通过接口调用的方法。当第一个组件被移除的时候，会调用这个组件的方法。所以，运用此原理，只要给每个列表元素包装一个组件用于接受这些钩子方法，就可以知道何时对列表元素运用过度效果了。例如
假设一个原始的组件是这样的：
 省略属性配置
     
     
     


其实，它最终会被渲染成这样：
  
    
         
    
    
         
    
    
         
    


所以，当有列表元素添加或删除的时候，其实是组件接收到钩子函数的方法。比如，当添加了第四个列表元素时，实际上时添加了

     


组件接收到方法调用，给 添加一个，变成了
 = 

然后又在下一个帧添加另一个：
 =  

这时过度动画就产生了！！然后在的时间后，组件负责消除和这两个类名。
实现
我们需要两个组件来实现以上功能。第一个是组件，什么也不做，只是一个外部封装，并且告诉用来包装每个元素。
   {
    _{
         
            {}
       
    }
    {
         封装函数用传递给
          {} ={_}
    }
}

然后就实现组件，实现三个钩子方法：、、。
   {
    {
         设置并消除的过渡
          
    }
    {
         设置并消除的过渡
          
    }
    {
         设置并消除的过渡
          
    }
    {
         
    }
}

关于的实现方法简要如下
  =      {
      = 


      =  ||     
      =    ||   
      = 

      =   {

      
       清除两个
       
       

        
    }

     
     在下一个添加类名
     

     后清空类名
     =  
}

整个组件的实现方法就是大体如此。

原文链接：腾讯云微信小程序解决方案元优惠套餐免费预约领取！
现在，大多数互联网创业者最缺的是流量，第二缺的是钱。之前开发者们追捧小程序的重要原因就是在于认为这可能是下一个微信公众号体量的流量入口，因为大家都想从微信的亿多用户中收获自己的一部分用户。
近期部分开发者不看好小程序的主要观点，也提到小程序过于克制，不支持用户留存，也不支持分享到朋友圈，线上二维码等为小程序导流。
本次小程序开放的大能力来看，比开放个人开发者注册，更为重要的是支持线下商家已有二维码扫描启动小程序，公众号体系和小程序体系的打通，以及从中分享小程序至微信生态这三方面的能力，对于开发者而言意味着可以从更多的应用场景为自己的小程序找到触达用户的方式。

小结来说，还是看好这波能力开放所给小程序生态带来的新用户。
秒速看懂小程序新增六大新能力
、个人开发者可申请小程序。
、公众号自定义菜单点击可打开相关小程序，具体代码解析如下：
 {
     
     {    
          
          今日歌曲
          __
      }
      {
           菜单
           _
            {
                  自定义菜单支持小程序，为
                 
                 
                 
                 
             }
       }
 }
 、公众号模版消息可打开相关小程序。
数据示例如下：
{
             
             =
           }
、公众号关联小程序时，可选择给粉丝下发通知。
、移动可分享小程序页面特别注意：不支持分享“朋友圈”和“收藏”。

、扫描普通链接二维码可打开小程序。
前期其实已经有不少工具类的小程序，比如小睡眠，群名片助手，朝夕日历享受到了第一波的小程序红利。我们腾云阁也把一些相关的干货整理如下，一起分享给大家。
可能是最全的微信小程序教程合辑
 ：新手必看
产品解析
小程序发布后最全解析！
腾讯独家详解小程序，给你一份商业化场景应用指南
后台部署步曲，自主动手一键部署
如果你不嫌麻烦，你大可自己动手部署后台，一下是后台部署的标准步骤：
、 快速域名注册  ——、快速添加域名解析 —— 、域名备案 ——、接入 ——、创建云主机
如果你已经被这后台部署“绕晕”了，或是不知道怎么部署后台，没有关系，可以直接使用腾讯云微信小程序后台一键部署服务，通过自动化部署，帮你完成完成复杂的架构初始化工作，看下图：
元体验腾讯云小程序解决方案即将开始，名额有限，有兴趣的同学可以立即预约抢先占坑！
 ：菜鸟进阶
在小程序开发中，需要特别注意哪些地方？过来人对此有哪些开发建议？前车之鉴，后事之师。
富途牛牛云上小程序开发一手体验简约而不简单——大众点评小程序开发经验谈从前端界面开发谈微信小程序体验
 ：微信小程序开发高阶
优化小技巧
微信小程序之提高应用速度小技巧三步瘦身，做名副其实的「小程序」
架构进阶
微信小程序的编程模式 一起脱去小程序的外套和内衣  微信小程序架构解析
跃跃欲试？赶紧预约腾讯云微信小程序元优惠套餐，快速开发您的小程序！

相关推荐微信小程序的编程模式微信小程序解决方案详解对于常在终端下工作的人来说，输入命令是家常便饭。但是当我们的命令输入错误的时候，需要调整就比较麻烦了。
一般来说，不经过学习都知道，使用左右方向键可以在输入的字母上进行跳转。但是问题是，这样操作效率太低。
因此，我们常用的命令有下面几个：



命令
解释





跳转到命令最前面



跳转到命令最后面



向前跳转一个字符作用相同于左方向键



向后跳转一个字符作用相同于右方向键



向前跳转一个单词



向后跳转一个单词



这几个常用命令在  上是没有问题的。  没有测试过，应该也没有问题吧。
但是在  上面有一些不一致。前面四个  的组合键没有问题，都是可以支持的。但问题是  没有  键。尝试用  键来做同样的操作，结果是不可以的。

 键相当于普通键盘的  键

怎么解决这个问题呢？通过不停的查找资料，终于解决了这个问题。
 自带终端工具的配置
我们打开  自带的终端工具，按    打开设置界面，点击上面的 描述文件 选项卡，然后在左侧的风格列表中点击你当前使用的风格，然后在右侧出现的选项卡中点击 键盘 然后，勾选当前页面的 将键用作键，如下图操作：

然后就可以了。最终效果如下：

  设置方法
自带的终端的问题解决了，但是我们还是更多的使用  这个功能更加强大的终端工具，那么在  里应该如何设置呢？

首先用  快捷键打开  设置面板
点击左下角的   按钮
然后就打开了  设置面板，确保在该面板的  选项卡中。
点击下方右侧的选项卡标签 。
然后将下方默认的  选项换成  选项

关闭后自然保存，然后就设置生效了。设置过程见下图：

然后就  了。实际效果如下图所示：

好，经过这个配置之后，我们终于可以愉快的使用终端啦！
本文由  原创，允许转载，但转载必须保留首发链接。
首发地址：   水平自动伸缩，通过此功能，只需简单的配置，集群便可以利用监控指标使用率等自动的扩容或者缩容服务中数量，当业务需求增加时，系统将为您无缝地自动增加适量容器 ，提高系统稳定性。本文将详细讲解的核心设计原理和基于的使用方法。

 概览

在中被设计为一个，可以简单的使用 命令来创建。 默认秒轮询一次，查询指定的中的资源使用率，并且与创建时设定的值和指标做对比，从而实现自动伸缩的功能。

当你创建了后，会从或者用户自定义的获取定义的资源中每一个利用率或原始值取决于指定的目标类型的平均值，然后和中定义的指标进行对比，同时计算出需要伸缩的具体值并进行操作。

当没有设置时，不会工作。

目前，可以从两种取到获取数据

稳定版本，仅支持使用率，在使用腾讯云容器服务时，需要手动安装。
自定义的监控版本，不推荐用于生产环境  。


当需要从自定义的监控中获取数据时，只能设置绝对值，无法设置使用率。

现在只支持     的扩缩容。


 自动伸缩算法

 会通过调整副本数量使得使用率尽量向期望值靠近，而且不是完全相等．另外，官方考虑到自动扩展的决策可能需要一段时间才会生效：例如当所需要的负荷过大，从而在创建一个新的过程中，系统的使用量可能会同样在有一个攀升的过程。所以，在每一次作出决策后的一段时间内，将不再进行扩展决策。对于扩容而言，这个时间段为分钟，缩容为分钟。

 中有一个容忍力的概念，它允许一定范围内的使用量的不稳定，现在默认为，这也是出于维护系统稳定性的考虑。例如，设定调度策略为使用率高于触发扩容，那么只有当使用率大于或者小于才会触发伸缩活动，会尽力把的使用率控制在这个范围之间。

具体的每次扩容或者缩容的多少的算法为：
        前采集到的使用率  用户自定义的使用率  数量

每次最大扩容数量不会超过当前副本数量的倍

  文件详解
下面是一个标准的基于的 文件，同时也补充了关键字段的含义
 
 

   
   
   
   
   
   

    资源最大副本数
    资源最小副本数
  
     
      需要伸缩的资源类型
       需要伸缩的资源名称
    触发伸缩的使用率

    当前资源下的使用率
    当前的副本数
    期望的副本数
   
 如何使用

在上文的介绍中我们知道， 有两种途径获取监控数据：和自定义监控，由于自定义监控一直处于阶段，所以本文这次主要介绍在腾讯云容器服务中使用基于的方法。

腾讯云容器服务没有默认安装，所以如果需要使用需要手动安装。

此方法中需要使用命令操作集群，集群地址，账号和证书相关信息暂时可以提工单申请，相关功能的产品化方案已经在设计中。


 创建
创建 
 
 

   
   
  
     
     
创建 
 
 

   
   
  
     
     
     
     

   
  
    
       
       
  
    
      
         
         
      
         
    
      
          
           
          
            
               
               
               
             
             
          
             
             =_
          
           
          
            
               
               
            
               
               
          
             _
             =
             =
             =
             =
             =
             =
             =
             =
             =
       
创建 
 
 
 
   
   
   
     
     
     
 
   
      
       
   
     
保存上述的文件，并使用    创建，当创建完成后，可以使用  查看
     =
                                 
                                            
     =
                    
                  
 创建服务
创建一个用于测试的服务，可以选择从控制台创建，实例数量设置为
 创建
现在，我们要创建一个，可以使用如下命令
     = = =
  
                                                            
                                   
                                      
此命令创建了一个关联资源的，最小的副本数为，最大为。会根据设定的使用率动态的增加或者减少数量，此地方用于测试，所以设定的伸缩阈值会比较小。
 测试
 增大负载
我们来创建一个，并且循环访问上面创建的服务。
      = 
         
         
下图可以看到，已经开始工作。
   
                                   
                                      
同时我们查看相关资源的副本数量，副本数量已经从原来的变成了。
    
                    
                                            
同时再次查看，由于副本数量的增加，使用率也保持在了左右。
   
                                   
                                      
 减小负载
我们关掉刚才的并等待一段时间。
        
                                   
                                      
    
                    
                                            
可以看到副本数量已经由变为。
 总结
本文主要介绍了的相关原理和使用方法，此功能可以能对服务的容器数量做自动伸缩，对于服务的稳定性是一个很好的提升。但是当前稳定版本中只有使用率这一个指标，是一个很大的弊端。我们会继续关注社区自定义监控指标的特性，待功能稳定后，会持续输出相关文档。为了应付突发的访问压力，我们常常会使用弹性伸缩功能，在系统遭遇突发压力的时候迅速生成新的主机加入集群来分担压力。但是随着系统越来越大，打包的系统镜像也越来越大，生成主机的速度也就越来越慢。我的一些服务器扩容速度从一开始的分多中已经增加到了分中左右，对突发性访问压力的响应速度大打折扣，用户体验也开始受到影响。
咨询了 团队专家之后，终于找到了优化方案：
、 制作系统盘镜像之前，确保制作镜像使用的主机的系统盘是盘云硬盘。如果主机用的是本地硬盘的话，先制作一个本地硬盘镜像以后，按量临时购买一台使用做系统盘的新服务器，把镜像装上去，然后再关机打包新服务器的系统盘镜像。
 、关机打包系统盘的完整镜像
 、确保弹性伸缩的启动配置里面，系统盘使用的是而不是本地硬盘。
也就是说，确保这三件事：被打包的系统盘是盘，被生成的服务器系统盘是盘，并且打包的时候关机了。原理是，满足这几个条件的情况下，生成镜像的时候会同时生成快照云盘快照，并且创新新主机的时候会采用云盘快照的回滚机制进行回滚创建，比原来的系统镜像方式生成主机快的多。
具体的讲，快了多少呢，贴一个两种方式的对比就知道了：

在这个例子中，原本生成一台主机需要七分半钟，优化后生成一台一模一样的主机只花了分秒。

相关推荐【腾讯云的种玩法】利用 节省成本如何使用腾讯云开发一款  应用介绍腾讯移动分析，为研发者提供完整的数据采集、分析洞察、精准触达的精细化运营支持，并首家推出可视化埋点功能，方便运营者可视化配置数据埋点，简化原有数据代码、审核、发布上架流程；快捷配置，即时生效，精细化运营瞬间加速。

年月日，腾讯大数据前端开发负责人郑灿双，在 年全球移动技术大会上分享了：腾讯移动分析在精细化运营中的优秀实践经验。

针对精细化运营，需要运用技术和工具，完成用户数据获取、用户识别、用户洞察、用户触达完整闭环，结合标准的数据分析方法，解决实际业务运营中的问题。
背靠数据平台部多年积累的大数据处理、计算的能力，腾讯移动分析每天处理近亿的日志流水。从数据接入、到数据计算、任务调度、数据存储、数据应用、机器学习，为移动应用研发者和运营者的实际数据分析的个性化需求，提供坚实的数据计算和处理保障。
目前腾讯移动分析提供移动全平台的统计分析服务，从的原生应用，到轻应用，微信小程序，通过采集应用内的用户行为数据，为运营者提供基础运营指标、质量体系、运营支持、画像等几大类的数据分析服务。腾讯移动分析与腾讯移动推送信鸽共同组成了精细化运营的完整链路，从数据采集到数据分析，从价值挖掘到用户触达。演讲精彩纷呈，现场气氛十分热烈，听讲座的观众已经排到了会场门口，更有很多观众席地而坐，听得津津有味。

会后，我们的讲师郑灿双也接受了编辑的采访，主要就“精细化运营”的概念与实践做了进一步的阐述。
     能否介绍一下对精细化运营的理解，主要包括哪几个方面？
我对精细化运营的理解主要是一个中心，两个基本点。
一个中心就是，以用户为中心，两个基本点就是：数据、技术。
以用户为中心，意思说，所有的精细化运营所做的数据分析，所使用的工具，平台，最终运营的端点是用户，这个用户是指端用户，而不是本身工具平台的用户。所以我们要清楚用户在上的属性，事件行为，活跃留存情况，以及与业务相关的内容，比如付费、内容产生等等。
数据则是承接用户而来，围绕着数据，需要有完备的采集体系和方法、用户属性的聚类分析、用户行为的透视、以及结合运营场景的应用数据，有时候甚至需要挖掘，比如，充分利用数据，才能将用户运营做到极致。
而另外一个基本点：技术，是指在精细化运营阶段，要具备和使用合适的工具和技术手段来辅助运营，缩短运营周期，强化关键路径。比如利用分析帮助定位问题，利用在线参数、云控实现云端运营，利用可视化埋点将固有的代码埋点变成配置化和云化。
抓住这一个中心，两个基本点，是我理解的精细化运营的思路和方法。
     请介绍一下大数据基础架构使用的主要技术有哪些？规模多大？
我们目前专注的移动开发者工具平台，数据分析正式享受到了部门大数据处理能力的红利。目前数据平台部拥有业界最大的大数据处理集群，规模过万台，并且计算能力也是业界领先，在去年 全球排序大赛中，以的时间完成的数据排序，而去年某公司的夺冠记录是秒。
同时也在对端政企提供大数据私有云解决方案、在云端提供公有云大数据套件，囊括了从数据接入、数据计算、任务调度、资源管理、数据交互、机器学习等大数据处理全流程的模块，采用的技术架构是社区自研的模式，像数据接入的，数据交互的，数据存储的、，，数据计算的、，机器学习有自研的等等，技术组件太多就不一一列举。
     对于可视化埋点，如何生成可视化的界面？
可视化埋点生成可视化的界面确实是关键路径功能。我们在与建立专有的通道，并通过维持长连接的方式，来实时与终端通信。终端有个跑马的策略，每一秒钟做一次屏幕的截图，并将当前屏幕爬取的元素，通过长连接，将信息上新到 节点，而端有一个，轮询的去 节点去取的页面截图以及元素坐标位置信息，并通过运算在前台的截图页面将位置自动绘制出来，让运营者可以便捷选择。
这里还有一个界面刷新的机制，比如我终端做了界面切换，界面如何实时感知呢，我们这里针对页面做了，得到的指纹作为跑马的一个上行数据维度，当页面切换，指纹改变的时候，端就去 取最新的截图和位置信息。这就是可视化埋点界面和实时刷新的简要原理。
     云控实现的动态化程度很高，采用哪些动态化技术，对性能有何影响？
云控这里主要是云端运营的一个技术手段，我们提供配置下发的通道的和机制，将动态化运营的全力交给运营者，这里的配置下发涉及到机型、在线状态、以及版本等多个配置下发的策略。
而实际下发的方式主要是拉和推两种方式，在腾讯移动分析中，我们做接入层与设备建立连接主要是短连接，所以这种情况下客户端主动拉取更新更合适，所以这里采取拉并全量覆盖配置的方式，显然这种方式简单粗暴，但是效率不高。
而在腾讯移动推送中，因为是长连接，所以我们采用推的方式，并且将增量变更的配置推送到相应设备上。这个整个搓成对性能几乎不会有任何影响。
     接下来我们的发展方向是什么？
我们的现在平台上主要的产品是腾讯移动分析与腾讯移动推送信鸽，未来我们整个开发者平台的发展方向大致会分为三块：
一块是我们基础建设，包括基础集群的质量、数据的准确性、系统的稳定性和安全性、推送速度时效性等。
一部分是为开发者提供更多的服务，例如为开发者提供分析、推送的通道、系统的监控、热更新、安全加固这样一系列的工具类产品。
第三部分是为产品运营者服务，提供精细化运营的能力，帮运营者做用户画像，做精准推送，提供的分析，帮他实现可视化的埋点，帮他可以提升运营效率。
以上是我们的大致方向，为开发者提供一揽子的工具化平台服务。接《道器相融，由  谈一个优秀机器学习平台的自我修养上》
在您看来，如何才能高效的搭建一个优秀的机器学习平台？
黄明： 先讲个大家都知道的小插曲：的前身是，当时并不太受深度学习界待见，大部分人做深度学习，要么，要么，基本忽略，后来推出，就很受欢迎。这里有个时间细节，是年加入的，而是年开始研发的，是年发布的， 由始至终，都在负责这个项目。作为外人，不太可能知道到底对做出了什么样的贡献，但是效果是很明显的。之前工程性太强，对深度学习的模型本质和算法友好度不足，加入后，第二代的的水准远远超越第一代的。整个系统的设计，从上层到底层，从名字到周边，都透露着对深度学习工程师的贴心理解。这也是成功的原因。
所以要设计和搭建一个优秀的机器学习平台，在我看来要具备如下个条件：
首先，要搭建一支工程和算法模型能力都很强的团队。整体上的这个团队，需要很好的互补能力，要有算法工程师，也要有系统架构师，大家互相配合。算法工程师的数学功底和表达能力很重要，而系统架构师的理解能力和快速实现能力很重要。另外最好能将学术界的创新能力和工程界的落地能力结合，才能使系统创新性和可靠性兼得。腾讯的项目从一开始，就是北大的博士生和腾讯的工程师联合主导的项目，虽然远比不上和 这样的大神级别，但是模式是类似的，这是非常关键的一个要素。
其次，需要有大数据作为驱动。之前我们研究过，发现有些理念很不错，但是稳定性非常差，在大数据量下很难跑通，而且搭建也很难。所以在的研发过程中，我们始终坚持以大数据为驱动的原则，各种和设计必须以最终压测通过为原则，并紧密依靠内部业务，通过场景落地来检验效果，以此保障系统的设计合理性和可用性。这点对于大公司来说其实没有太大的难度，只要有正确的理念和合作即可。但是这对于小公司来说则比较困难。所以这也是等大企业开源的框架，和实验室或者初创公司出品的框架相比的优势之一。
最后，需要保持很快的演进速度。现在经常被批评接口改动太快。其实最近的接口改动也很多，而且有些不能向后兼容。这其中原因很简单，一个是因为业界的深度学习发展太快，新算法和模型、技巧层出不穷，作为一个平台必须能快速适应，不进则退。另一个原因是开发的人太多，即便是目前还比较少，但是内部大量的并行开发，很难保证所有的模块都是合理的，定期重构是消除这些不合理的唯一方法。整体来看，只要是合理的重构，能提升性能，就标识着这个项目还在快速的生长期中，不失为一件好事。
：创新工场的王咏刚老师在《为什么工程师要懂一点架构》中提到，研究不能只懂算法，算法实现不等于问题解决，问题解决不等于现场问题解决，架构知识是工程师进行高效团队协作的共同语言。能不能谈谈您对架构能力的看法？
黄明： 王咏刚老师说的要懂“一点”。这个词在我看来代表了两个意思：
确实需要懂，不能什么都不懂。企业里的算法工程师和数据科学家一定要有动手能力，不能整天只会做研究、写，和单机版的试验一下，自己独占一台机器玩得很开心，模型做完了不会上线，沟通一到工程部分就聊不下去……其实是处于一种很不好的状态。这样的工程师，除非某方面特别强或特别突出，否则在企业是很难落地生存的。
不能指望懂太多。毕竟做算法和做工程的思维重点不一样，脑回路也不太一样，方法论也不一样。两方面都精通的人才，有，但是难找。这也是腾讯做的初衷和目的，就是让算法工程师不需要懂太多底层框架优化，也能轻松地写出高效的、能分布式运行的生产代码，把一些通用的体系化的系统和架构细节屏蔽掉，这样才能极大地提高企业生产力。
目前来看，包括、这些比较好的框架，也正是因为它们能够使数据工程师和工程师，在适当屏蔽掉底层的架构细节后，依然能够写出高效的算法代码，才取得了成功。
平台的新变化和展望
：通过您之前的投稿，大家对平台开源前所做的一系列重构和升级已经有所了解，开源以来想必又有了不少新变化，能否介绍一下近三个月你们对平台又做了哪些优化？
黄明：开源以来，低调的发布了个小版本：和，主要是加入了新的算法和优化方法，加强了稳定性，细化和完善之前的功能。这个月内的优化，以稳定和性能提升为主。因为的定位是工业级可用的平台，所以非常看重大数据量下的稳定性和性能，我们公布的算法都是生产验证过。同时我们对  的接口进行了反复的重构，尽可能和本身的接口接近一致和复用，这方面的工作到时候会在这次的大会重点介绍。
另外根据用户的反馈，开发团队正在开发个大功能，尚未发布，包括：
接口：接口优化和重构，以提升易用性。因为之前宣传的时候，很多用户的第一个问题，就是有没有接口……所以我们不得不把这个作为第一优先级来满足。
   ：支持在线学习，加入算法。就像之前说的，实时性也是机器学习必不可少的。那本身不做实时这块，但是支持  ，那通过 来接入实时训练，也是水到渠成的事情，成本也很低，不过对的和内存管理，需要进一步的优化。
这两个新功能应该在下个版本就能够和大家见面了。至于深度学习的支持，其实也在进行了，但是有些难度，会晚点就推出。
：开源后这段时间，平台的推广情况如何？有没有什么印象特别深刻的问题反馈？
黄明： 开源以来，其实我们并没有太刻意推广，包括我们在上的第一天月日都没有准备做任何，不过由于之前的影响力，最终各大媒体都报道了。但是腾讯开源委员会最近一年对开源项目的扶持非常大，态度也很，所以我们主要是借着腾讯开源的力量在做这个事情，发了几篇文章。目前整体的数接近，我们比较欣慰的是和数的比例比较高的，看得出很多人还是对项目很有兴趣的。整体上，我们还是按照自己之前定好的节奏，小步快跑地进行新功能和版本的研发。
据了解和接触，目前有部分公司如小米、新浪微博等正在试用，也有了不少贡献者。印象深刻的有几个：
华为的一位工程师，项目刚发布不久就提交了一个比较大的，帮忙把版本升级了，非常给力。后来他想把集成进来，但是我觉得这个方向不太对，就掉了，不太好意思。
微软的开发者之一提了个，和开发的同学互动了个来回左右，详细地讨论了机器学习任务中和的网络通讯开销到底谁更小的问题，进行了很有意思的学术互动。
海外的一个用户主动帮忙翻译的文档，之前为了开源，团队花了快个月的时间边写文档边改，所有文档加起来应该有篇左右，翻译工作量巨大。但现在基本全部都翻译完了。
这些都让我们体会到了开源的力量和益处，一个平台在开源之后，会受到来自全球的关注，只要你用心经营，并保持良好的功能和性能，能帮助到用户，用户就会主动帮你做很多事情。而你的视野，也会变得更加的开阔。很多外部用户的需求非常客观到位，正是他们推动着我们往前走。
：开源三个月后再看，与一众机器学习平台相比比如、、、，的优势是什么？的什么特性最能吸引机器学习开发者？
黄明：首先目前其实、都不开源，没有可比性。在研发初期借鉴参考过的一些思路，但是后来实验中发现，在可靠性和稳定性上都达不到工业可用级别，所以基本上也都推倒重做了。
和比的话，目前的重心还是在上，这从每个版本的数就可以看出来，的比例很小。这在某种程度上也是因为的本质局限导致的。相比之下，重点是机器学习算法，而基于的编程模型可以让各种机器学习的优化和都很方便地实现，对于算法工程师非常友好。伴随着接口的提供，这个优势将会变得更加明显。
目前在深度学习上的地位还是遥遥领先，从个数就可略见一斑。但是在多机多卡的性能上的做得并不好，最近发布的最新版本还在尝试走路线，这是业界难题之一。目前不会独立做一套新的深度学习框架去和竞争，而是会发挥自身优势，把做好做极致，来加速并行训练并形成互补。
关于传统机器学习算法的生命周期问题，我觉得不用太担心。很重要的一点是传统机器学习算法比深度学习更贴近 而非模拟智能。深度网络模拟大脑结构，所以在人类擅长的智能领域优于传统算法，比如视觉听觉，各种对外界信号的理解……但是还有一些非智能领域，人大脑展现出各种认知缺陷 ，比如对模式是随机还是真实的判断，对概率的认知，对风险评估等等。这些方面传统机器学习方法仍然更有效，不需要通过大量的野蛮暴力尝试，就能得到更好的结论。也许以后会改变。但目前传统思路的机器学习还是有必要的，在很多场合，简单有用，包括腾讯的很多场景，还是有刚需，所以还是要把它经营好。
整体上来看，目前是业界，包括国内和国外，比较成熟的开源参数服务器框架，能够在十亿级别的维度其实百亿也可以，只不过没生产完全验证过，所以不这样宣传、级别大小的样本量规模下，开发和运行通用的机器学习算法的平台。另外值得一提的是，的算法开发难度也比较低，有一位开源贡献者很轻松地在上实现了阿里巴巴用于预估的算法，并贡献给社区，这正是团队所期待的。
：您认为目前机器学习平台还存在哪些问题和难点？未来改进的重点是什么？
黄明：目前机器学习平台还存在个大问题：算力的水平扩展、模型的高效压缩、快速的推理能力。
机器学习平台最大的难题还是算力。性能再强，接口再好用，底层优化再极致，单机能力终有极限，需要能水平扩展，而深度学习大规模通用的多机多卡的分布式方案，目前依然是个难题，即便也没解决得很好。这也是腾讯致力于系统的原因，希望无论是还是，我们都能提供高性能分布式机器学习方案。
除此之外，利用庞大的集群规模，长时间训练出来的精细模型，其大小一般比较大，像训练出来的模型一般都会上百，而深度学习的模型，多数也到级别。这么大的模型，需要压缩之后才能给终端使用，如何在尽量减少精度损失的情况下，最大化的压缩模型，也是平台需要考虑的。
最后一个是快速的推理能力。无论是终端推理手机端，无人驾驶车……，还是服务端推理广告，推荐……，要求都是一样的，要尽可能速度快和高吞吐量。这时如何合理地利用和设计流式实时系统，来快速接入数据进行推理，也是平台需要考量的点。
在未来一年里，相信大部分的机器学习框架，包括深度学习框架，都会围绕着上述几个问题重点发力。这也是需要面对的挑战和机遇。

采访嘉宾介绍：黄明，腾讯专家，早期的研究者和布道者，对分布式计算和机器学习，有独到的经验和研究。目前于数据平台部担任海量计算组，负责构建大规模分布式计算和机器学习平台，助力腾讯各大数据和机器学习业务快速发展。作者简介：王少飞 

前言
 “前端脚本错误监控及跟踪解决方案” 可以有效的提升前端业务质量，但部署和使用都有一定的门槛。现在我们把这个服务制作成了腾讯云镜像，使接入和使用都很方便，不用考虑申请硬件资源以及服务的安装部署等复杂工作。
前端脚本错误监控及跟踪解决方案有如下优势

一站式体系化解决方案：业务只需要简单的配置，引入上报文件，即可实现脚本错误上报，每日统计邮件跟踪方便。

可视化查询系统，快速定位错误信息： 应用程序脚本数量庞大，开发人员在如此之多的脚本中定位某个问题变得困难。 能够巧妙定位错误脚本代码，进行反馈。通过各种查询条件，快速找到详细错误日志。

跨域、  等棘手问题不再是难题：  帮你发现一切。

真实用户体验监控与分析：通过浏览器端真实用户行为与体验数据监控，为您提供  、 请求错误诊断和页面加载深度分析帮助开发人员深入定位每一个问题细节。即使没有用户投诉，依然能发现隐蔽 ，主动提升用户体验。

用户行为分析：细粒度追踪真实的用户行为操作及流程，前端崩溃、加载缓慢及错误问题，可关联到后端进行深度诊断。 


产品质量的保障：浏览器百花齐放，用户环境复杂，巨大的差异导致开发人员难以重现用户遇到的问题。无法像后台一样上报所有用户操作日志。通过，上报用户端脚本错误，为产品质量保驾护航。
更详细的请查看 
腾讯云  镜像使用说明

直接点击   镜像 连接进入镜像详情页，或在腾讯云服务市场中搜索 “前端脚本错误监控及跟踪解决方案”， 进入  镜像详情页 。



点击“立即使用”进入“云服务器  ”购买页面，这里对机型的要求是内存不低于由于系统需要安装 ，，，如果系统内存小于，会导致  服务启动不起来，硬盘大小不小于 越大 需要的硬盘越大每条上报大小大致占用硬盘是  ，所以每增加  条上报， 就要增加硬盘  。



镜像选择已经选好了“前端脚本错误监控及跟踪解决方案 ”，这里可以直接进入下一步 。



选择完存储和网络，设置相关必要信息比如密码等，最后点击“开通” 。



点击“开通”后将进入“云主机创建”页面，这里主机创建需要分钟 。



创建完成后会得到地址，如图 ：


如果是已有云服务器的可以选择  镜像重装系统
选择重装系统 
 
选择镜像 

重装完成后地址不变
系统如何使用
首先访问服务器的端口服务器 ， 进入帮助页面 ：

点击“我的业务”，登录管理员，初始用户名和密码是：登录进管理页面可以修改密码，登录进去后点击顶部菜单“申请接入”，进入 “新业务申请” 页面 ：

填写完相关信息点击“申请”按钮， 到“项目申请列表”页面审核通过后，这个业务就可以正常使用了。可以先进行简单的测试看系统是否正常，按照  项目的指引测试下。

管理页面右侧为展示、搜索条件：
每个条件解释如下：
点击每个字段可以开启或关闭相关列 。

选择要查看的业务 。

选择消息类型，点击可以开启或关闭 。

查找日志的起始和终止时间。

过滤包含或排除的关键字。 

配置邮件订阅
当前版本配置邮件订阅功能步需要部署完整版单机部署。

登录到服务器，杀掉当前进行 ；

拉取全量代码    ；

进入到的目录，运行    ，拉取各个模块 ；

运行   安装依赖，这个步骤很容易出现问题 ，对于新用户建议进入各个模块进行 ；

 安装不成功，请查看  ；

进入 ，将里面的  导入到 中 ；

运行    ，启动各个模块 ；

访问 服务器 ，进入页面确定启动成功。


具体可以参考 单机部署邮件配置参考。
订阅邮件效果展示
如下图日报邮件，包含最近一个月的量趋势，以及当天错误有哪些类型：

以上是腾讯云镜像的使用，以及系统的简单介绍，最后附上地址：


相关推荐在 上使用腾讯云  镜像加速构建利用腾讯云轻松建立服务器同步镜像站点引言
在开发中使用动画时，可以通过设置动画的、、、属性，来设置动画的时长、速度、起始时间及起始偏移。用一个简单的例子来说明各个参数的的作用。动画很简单，一个红色的方块从左移到右边。动画的持续时间是，没有重复，效果如下。

      = 
      =   
      = 
     =   
     
     
做修改以后，效果如下：

与上面相比，三处不同

动画的速度是原来的两倍。
点击开始动画的按钮，到开始动画，有一个延迟。
动画起始时，滑块的位置为中央，而不是在左边。

我们已经看到了这些属性的效果。翻阅文档，发现、等属性是这协议的属性，并且、都遵守了协议。
那么协议是什么呢？有什么作用呢？
层级时间结构
根据文档，协议构建了一个层级的时间系统，并用这个层级的时间系统来协调各个、的时间。
这个协议被及遵守，每一个遵守协议的的对应一个 。根据之间的关系，不同的 有层级关系。比如 有一个 ，那么 对应的 就是 对应的 的  。每一个 中时间的数值都是根据  的数值，以及、等属性，根据一定的规则来计算的。
为了便于理解层级时间系统，先看下在屏幕上的显示位置是如何确定的，然后做一个类比。

层级如上。要确定在屏幕上的显示位置，一共分三步。

确定 在屏幕位置
根据及 的属性，确定 在屏幕中的位置
根据及的属性，确定在屏幕中的位置

与此类似，要确定中的，也要分三步。

确定 中的
根据及 的、等属性计算出 中的
根据及的、等属性计算出中的

和确定的位置相比，确定时间有一些复杂，主要提现在下面两点
  层级时间系统的构成复杂。 的每一级都是，而只要遵守协议，就可以作为层级时间系统的一部分。比如、及其子类都可以作为层级时间系统的一部分。
 不同层级之间时间转换规则复杂计算当前的位置时，只需要知道父的位置，以及当前的属性。计算当前层级时间时，不仅需要知道上一个层级的时间，还需要知道当前层级的、、等属性。转换的规则也比较复杂，要经历两次转换。从 到  ，再到  。
  
这次转换是为了处理当前层级的在父层级的的时间线上的位置，以及当前层级和父层级之间时间流逝速度的关系。
和这次转换相关的属性有、以及

 子层级相对于父层级的起始时间。也就是父层级的时间经过多久，子层级才开始计算时间。比如子层级被加入层级时间系统时，它父层级的时间是，子层级的是，那么当它父层级的时间变为时，子层级才开始计算时间。
子层级相对于父层级的时间流逝速度。如果是，那么当父层级的时间增加了时，子层级的时间增加了的倍。
为本地时间增加一个偏移。 如果是，那么本地时间的起始就是。从 到  有一个公式，可以用来参考。

 =       
  
这次转换是为了处理当前层级的重放、以及重放之前是否要倒放 等操作。
比如当前层级是一个动画遵守协议，是，经过第一次转换之后的  是。如果动画的是，那么经过第二次转化以后，  会是，因此当前是动画展示一半的状态。
 及当前的层级要重复的次数或重复的时间，两者不可同时指定。以动画为例，如果指定那么指定了动画要重复几次。如果指定了，那么指定了动画重复的时间。 在重复之前是否要倒放。
文首的例子
根据这些知识，可以解释文章开始时设置参数的效果。当动画被加到上时，动画对应的 被加到层级时间系统中，是对应的 的子层级。
 动画的速度是原来的两倍设置动画的是，这样子动画中的时间流逝速度时中时间流逝速度的倍。当中时间经过时，动画中时间已经流逝了，动画已经完成了。动画的是 点击开始动画的按钮，到开始动画，有一个延迟我们首先得到了当前的时间，然后把动画的设置为。这样子当动画被加到之后，中的时间是，此时动画中的时间才开始计算，之前动画没有开始。 动画起始时，滑块的位置为中央，而不是在左边我们设置了动画的为。当动画开始时，动画对应的 的时间是，对应动画的一半，即滑块位置在屏幕中央。
更多应用
了解了协议后，可以实现很多动画的效果。

让某一个上的动画停止设置的为即可。
实现门打开然后关闭的效果实现一个门打开的动画，然后把动画的属性设置为即可。
上的若干动画依次延迟启动分别设置这些动画的为不同的值即可
手动控制动画的进度设置动画的为，然后改变动画的即可。

苹果已经把工具给我们了，可以做出什么样的产品就看大家的想象力了。
参考
 控制动画时间： 
   ：作者：黄雪兰
团队：腾讯移动品质中心

为了进一步加强测试质量，同时探索测试左移在同步中的实践，同步助手尝试接入静态代码扫描工具。希望通过不同的途径提前发现日常测试中难发现的问题。
然而静态代码扫描工具有不少，它们都有什么不同？我应该选哪一个？因此，本文主要针对主流的几个工具，对同步助手的代码进行扫描，并分析对比它们的扫描结果，再敲定后续的接入计划。
该文章从以下几部分进行阐述，可按需阅读：
一、工具介绍
二、遇到的坑点
三、扫描能力对比
四、部分结果分析 
一、工具介绍
本次选取了四个主流的扫描工具： 、、、。
、
是检测和解决、、和源代码中最严重的缺陷的领先的自动化方法。它将基于布尔可满足性验证技术应用于源代码分析引擎，分析引擎利用其专利的软件图谱技术和技术，综合分析源代码、编译构建系统和操作系统等可能使软件产生的缺陷。
、
作为编译器框架的前端，最主要的任务是词法分析、语法分析，中间代码生成。源代码通过语法分析后，生成了语法分析树后，可作为静态分析工具对进行分析。
命令行调用方法：
下载：
命令行到项目代码所在目录：  
使用扫描，命令开头为的所在目录：     
可以看到生成报告在指定目录下

、
是开源的用来执行增量分析的一款静态分析工具，由语言编写的目前能检测出空指针访问、资源泄露以及内存泄露，可对、和代码进行检测。
命令行调用方法：
前置条件
安装 ：自带；
安装：   ；
安装；
下载：
安装 
  =
   
     
将的执行目录配置到环境变量
命令行到所在目录：  
  =\\\\  _   _
  验证是否安装成功：  
使用扫描
命令行到项目代码所在目录：  
     
项目代码所在目录下生成结果文件夹：、
、
是针对、和 代码的静态扫描分析工具，可以和、、等集成，使用命令行方式生成分析报告。这里主要使用对产生的进行分析，获取相关数据以后生成文件。
命令行调用方法：
下载：
配置环境变量，将的目录添加到文件中：=
验证是否安装成功： 
命令行到项目代码所在目录：  
进行 ：  
与结合，将 的输出信息记录在中，并使用生成文件：
  |   |  
生成的文件在代码目录下，名字为_，和默认生成的文件命名和路径均不同，因此需要移至代码根目录并重命名为_。
生成文件
  =
二、遇到的坑点
、缺少证书问题
代码的时候可能会遇到缺少了部分证书的问题，因此命令行调用时使用了模式，可忽略部分证书问题；
、安装
在扫描过程中提示出错，需要安装。但由于公司网络问题，按照网上教程使用  安装时会出错。这里可以采用离线安装的方法：下载文件，并下载对应依赖版本的文件，离线文件下载地址：

命令行打开离线文件所在目录： 
安装：    
安装：     
查看是否安装成功：  –
、增量分析
为增量分析工具，通常默认只有修改过并提交编译的文件才会被分析。如果想要全量分析，可以调用前先清除扫描记录：
   
   
、：    
使用执行最后一步生成文件时出现该错误，最后排查到是开始没有 ，因此在进行扫描之前先执行这一步。
三、扫描能力对比
在未加任何过滤规则的情况下，四个工具对同一份代码进行扫描，并于开发童鞋一起对扫描结果进行了初步筛选和整理：

准确率：     ；
扫描维度更多、发现问题更精准；、能发现部分未发现的问题，但误报率较高，可作为补充扫描；
发现的大部分问题为第三方库问题，后续加入过滤计划可提高扫描准确率；
扫描出的问题数量最多，但大多是开发不关注的问题，可过滤特定结果类型关注，更适合作为扫描代码复杂度的工具。

四、部分结果分析
、缺陷类
无法执行到的代码

和分支的代码一样

废弃代码
已经走到，后面的代码不会再执行：

、误报类
复制粘贴错误
代码中存在，没有问题；

中缺少
开发故意设计如此，没有问题：

没有判断是否为空
提示行传传入的可能为空，但实际前面已赋值，且排查没有问题：

未使用的值
提示不会被使用，实际是在打印日志时使用了，而扫描时日志为关闭状态，没有走到下面的路径：

获取更多测试干货，请搜索微信公众号：腾讯移动品质中心！作者：

前言
 是微信官方使用  编写的业务性无关、平台性无关的终端基础组件，目前在微信 、、、、  等多个平台中使用，并正在筹备开源，它主要包含以下几个独立的部分：
、：基础库，包括 、线程、消息队列、协程等基础工具；、：通用日志模块，充分考虑移动终端的特点，提供高性能、高可用、安全性、容错性的日志功能；详情点击：高性能日志模块 、：网络诊断模块；、：信令传输网络模块，负责终端与服务器的小数据信令通道。包含了微信终端在移动网络上的大量优化经验与成果，经历了微信海量用户的考验。
本篇文章将为大家介绍 信令传输网络模块，由于  的复杂性，该模块将被分解为多个篇章进行介绍，本文主要内容为微信中关于读写超时的思考与设计。
读写超时与设计目标
中的超时设计
微信信令通信主要使用  协议，数据经过应用层、传输层、网络层、链路层见图。其中，链路层与传输层，协议提供了超时重传的机制。
图 使用  协议
链路层的超时与重传
在链路层，一般使用混合自动重传请求即 。 是一种结合 前馈式错误修正与 自动重传请求的技术，原理如图所示。
图  原理
通过使用确认和超时这两个机制，链路层在不可靠物理设备的基础上实现可靠的信息传输。这个方案需要手机和  都支持，目前在 、、、和  上都已实现支持。
传输层的超时与重传
传输层即  层提供可靠的传输，然而， 层依赖的链路本身是不可靠的， 是如何在不可靠的环境中提供可靠服务的呢？答案是超时和重传。 在发送数据时设置一个定时器，当定时器溢出还没有收到 ，则重传该数据。因此，超时与重传的关键之处在于如何决定定时器间隔与重传频率。
传统  实现中，定时器的间隔取决于数据的往返时间即 ，根据  进行一定的计算得到重传超时间隔即 。由于网络路由、流量等的变化， 是经常发生变化的， 的测量也极为复杂平滑算法、 算法、 算法等。在《详解》中，实际测量的重传机制如图所示，重传的时间间隔，取整后分别为、、、、、和多个秒。这个倍乘的关系被称为“指数退避”。
图 实际测量的重传机制
在移动终端中， 的设计以及重试频率的设计是否与传统实现一致呢？对此我们进行了实测，实测数据如下：
图所示为手机超时重传的间隔，依次为 ，，，，，，，，，， …：
图  手机  超时重传间隔
而  中  超时重传的间隔依次为          …，见图。
图 三星手机  超时重传间隔
经过多次实际测试我们可以看出虽然由于不同厂商的  系统实现， 的值可能会有不同的设定，但都基本符合“指数退避”原则。
接下来再看  系统中，  的实验数据，图所示为实验中第一次的数据 ，，，，，，，， … 。
图  系统   第一次实验数据
上面的数据看起来并不完全符合指数退避，开始阶段的重试会较为频繁且  最终固定在  这一较小的值上。
进行第二次测试后发现数据有了新的变化，，，，，，，， …，如图所示。
图  系统   第二次实验数据
 终值由秒缩减至秒，最终经过多次测试并未发现  中   的规律，但可以看出  确实采用了较为激进的超时时间设定，对重试更为积极。
读写超时的目标
通过上述的调研与实验，可以发现在  中，协议栈已经帮助我们进行了超时与重传的控制。并且在 、 的移动操作系统中进行了优化，使用了更为积极的策略，以适应移动网络不稳定的特征。
那是否意味着我们的应用层已经不需要超时与重传的控制了呢？其实不然。在链路层， 提供的是节点之间每一数据帧的可靠传输；在传输层， 超时重传机制提供的是端与端之间每个  数据包的可靠传输；同理，在微信所处的应用层中，我们仍然需要提供以“请求”为粒度的可靠传输。
那么，应用层的超时重传机制应该提供怎样的服务呢？
首先，我们来看一下应用层重传的做法。在应用层中，重传的做法是：断掉当前连接，重新建立连接并发送请求。这种重传方式能带来怎样的作用呢？回顾  层的超时重传机制可以发现，当发生超时重传时，重传的间隔以“指数退避”的规律急剧上升。在  系统中，直到分钟， 才确认失败；在  系统中，直到分半到分半之间， 才确认失败。这些数值在大部分应用中都是不为“用户体验”所接受的。因此，应用层的超时重传的目标首先应是：

在用户体验的接受范围内，尽可能地提高成功率

尽可能地增加成功率，是否意味着在有限的时间内，做尽可能多的重试呢？其实不然。当网络为高延迟低速率的网络时，较快的应用层重传会导致“请求”在这种网络下很难成功。因此，应用层超时重传的目标二：

保障弱网络下的可用性

连接是有固定物理线路的连接，当已  的线路中，如果中间设备出现较大波动或严重拥塞，即使在限定时间内该请求能成功，但带来的却是性能低下，反应迟钝的用户体验。通过应用层重连，期待的目标三是：

具有网络敏感性，快速的发现新的链路

我们总结应用层超时重传，可以带来以下作用：
、减少无效等待时间，增加重试次数：当  层的重传间隔已经太大的时候，断连重连，使得  层保持积极的重连间隔，提高成功率；、切换链路：当链路存在较大波动或严重拥塞时，通过更换连接一般会顺带更换获得更好的性能。
微信读写超时
方案一：总读写超时
在层的超时重传设计中，超时间隔取决于，即包往返的时间。同理，在微信的早期设计中，我们分析应用层“请求”的往返时间，将其分解为：

请求发送耗时  类比包传输耗时；
响应信令接收耗时  类比传输耗时；
服务器处理请求耗时  接收端接收和处理数据包的时间相对固定，而微信服务器由于信令所属业务的不同，逻辑处理的耗时会差异明显，所以无法类比；
等待耗时  受应用中请求并发数影响。

因此，我们提出了应用层的总读写超时如图所示，最低网速根据不同的网络取不同的值。
图 应用层的总读写超时
方案二：分步的读写超时
在实际的使用过程中，我们发现这仅仅是一个可用的方案，并不是一个高性能的解决方案：超时时长的设置使用了差网络下、完整的完成单次信令交互的时间估值。这使得超时时间过长，在网络波动或拥塞时，无法敏感地发现问题并重试。进一步分析可以发现，我们无法预知服务器回包的大小，因此使用了最大的回包进行估算微信中目前最大回包可到 。然而， 传输中当发送数据大于  时，数据将被分段传输，分段到达接收端后重新组合。如果服务器的回包较大，客户端可能会收到多个数据段。因此，我们可以对首个数据分段的到达时间进行预期，从而提出首包超时，如图所示。
图 首包超时计算
首包超时缩短了发现问题的周期，但是我们发现如果首个数据分段按时到达，而后续数据包丢失的情况下，仍然要等待整个读写超时才能发现问题。为此我们引入了包包超时，即两个数据分段之间的超时时间。因为包包超时在首包超时之后，这个阶段已经确认服务器收到了请求，且完成了请求的处理，因此不需要计算等待耗时、请求传输耗时、服务器处理耗时，只需要估算网络的 。
在目前方案中，使用了不同网络下的固定 。由于有了“首包已收到”的上下文，使得包包超时的间隔大大缩短，从而提高了对网络突然波动、拥塞、突发故障的敏感性，使得应用获得较高的性能。
方案三：动态的读写超时
在上述的方案中，总读写超时、首包超时都使用了一些估值，使得这两个超时是较大的值。假如我们能获得实时的动态网速等，我们能获得更好的超时机制，如图所示。
图 实时动态网速下的超时估算
但是，理想是丰满的，现实是残酷的：

动态网速需要通过工具方法测定，实时性要求高，并且要考虑网络波动的影响；
服务器动态耗时需要服务器下发不同业务信令的处理耗时；
真实回包大小则只能靠服务器通知。

上述的三种途径对客户端和服务器都是巨大的流量、性能的消耗，所以动态化这些变量看起来并不可行。
因此，这里需要换个角度思考动态优化，手机的网络状况可以大概地归为优质、正常、差三种情况，针对三种网络状况进行不同程度的调整，也是动态优化的一种手段。这里选择优质网络状况进行分析：

如何判定网络状况好？网速快、稳定，网络模块中与之等价的是能够短时间完成信令收发，并且能够连续长时间地完成短时间内信令收发。
即使出现网络波动，也可以预期会很快恢复。

图 优质网络状况优化
根据对网络状况好的分析，我们可以做出这样的优化如图所示：

将客户端网络环境区分为优良、评估两种状态；
网速快、稳定就是条件，信令失败或网络类型切换是条件。

进入状态后，就缩短信令收发的预期，即减小首包超时时间，这样做的原因是我们认为用户的网络状况好，可以设置较短的超时时间，当遇到网络波动时预期它能够快速恢复，所以可以尽快超时然后进行重试，从而改善用户体验。
总结
虽然  协议栈中的链路层、传输层都已经提供了超时重传，保障了传输的可靠性。但应用层有着不同的可靠性需求，从而需要额外的应用层超时重传机制来保障应用的高性能、高可用。应用层超时重传的设计目标，笔者从自身经验出发，总结为：

在用户体验的接受范围内，尽可能地提高成功率；
保障弱网络下的可用性；
具有网络敏感性，快速地发现新的链路。

依从这些目标，  的超时重传机制在使用中不断的精细化演进，使用了包含总读写超时、首包超时、包包超时、动态超时等多种方案的综合。即使如此， 的超时重传机制也有着不少的缺点与局限性，例如相对适用于小数据传输的信令通道、局限于一来一回的通信模式等。  也会不断发现新的问题持续演进，并且所有的演进都将在微信的海量用户中进行验证。同时也期待随着   的开源，能收获更多、更广的经验交流、问题反馈、新想法的碰撞等。

本文来源于： 微信公众号

相关推荐微信终端跨平台组件  系列一：高性能日志模块导语
   是之项目组 ， ，陈松等以及陈莉君老师正在致力于打造的一个开源项目，这是文档《是什么为什么怎么办》的第一部分。
是什么？
的全称是  易用剖析器，核心特点在于简单，主要功能在乎剖析。的网址是 ，网站基于部署，代码仓库位于：
的设计目标是：便利的程序员，以最快最直接的方式，定位到系统里面一些的源头，以及一些性能瓶颈的原因。有很多现成的调试和剖析工具，比如、、、、、、、、等，这些工具通过读取、，分析硬件的  数据、监控内存的申请释放以及读写等手段，获知单一进程或者系统的运行状态，以及进行故障分析。除了在功能上是这些工具的超集以外，在可视、交互、深度分析、数据比对、场景贴合等角度对这些工具进行进一步的增强。
 的架构
实际上是一个的调试工具，它的软件架构如图。与现有工具重大不同的地方是：被监控的服务器或者开发板只需要部署 ，该程序完全用语言，只需要完成基本的数据采集功能，因此它能最小化对被监控系统本身的影响。数据的分析和处理，都移动到了服务 和浏览器一端。采集被监控目标的运行数据，这些数据被服务端通过请求获得，以对从获得的原始数据进行有针对性的加工，再发送给浏览器，浏览器用等形式，把加工过的数据，以各种丰富的图形进行显示。
这种架构的主要好处是：和分离，这样使得易于部署在资源贫乏的嵌入式电脑板上当然更加可以运行在服务器上，而一般则运行在比较强壮的 上。当然，和虽然分离，在实际部署的时候，也可以部署于同一个 。因此，也可以用于非网络环境下的单机自身监控。

值得一提的是，目前基于进行部署，这对的安装和使用提供了很大的帮助，避免了不同环境下、不同用户要安装各种依赖的底层工具的繁琐动作。可运行于直接支持的平台以及间接支持的 和平台。
图演示了的一个典型的数据流程。运行于被监控系统的读取数据，这些数据没有格式，是原始的，类似“  …”，而收到这些数据后，将其进行语义加工为、、这种过去分钟、分钟、分钟系统平均负载，浏览器获取这些数据后，绘制为条生动活泼的动感曲线。

图 的数据流程
 的特点
在功能角度上，全面集成了的多数常用工具，但是在调试和剖析能力上，更加“给力”，它进行了进一步的高强度增强，这些增强主要表现在个方面：

是的。意味着有了后，用户不用再满世界去寻找和集成众多的工具。由于本身的绝大多数工作并不集成在被监控的目标，被监控的目标仅仅需安装一个最简单的 做后台数据采集，因此，这种的集成本身也不会增加被监控者文件系统的。

是可视化的。当我们用命令去观察利用率、平均负载等的时候，进行周期性的刷新，它显示的只是此一时刻的数据，因为没有图形，所以它无法显示变化，而则可以以时间为轴，数据为轴，显示系统一段时间的状态变迁，如图。



图 可显示变化

是可交互的。由于界面丰富，因此，用户可在浏览器网页上面，对监控本身的频率、数据类型等进行设置，以及进行方便的数据过滤，譬如在的众多进程中，设置只关心某些进程。以图为例，在进程利用率的监控窗口，我们可以通过简单的输入进程名，过滤掉我们不关心的进程。



带预警和分析能力。目前的命令，更多的只是显示数据，本身分析和预警能力不足。比如命令，它显示系统的内存，但是当系统出现内存泄漏时，它彻底缺乏提示和预警能力。与之不同的是，可持续跟踪系统，因此，发现内存泄漏等异常状况后，可给用户预警，并进一步给出更深的提示，比如提示内存泄漏的源头是、还是用户态应用程序。

具备数据存储能力。可以将采集的历史数据进行保存，并在保存后进行档案调取。程序员经常会修改代码，并进行修改代码前和修改代码后的运行性能比对。历史数据与当前数据的比对，可便利程序员获知代码变更对系统真实的影响。我们姑且称呼上述比对为时间比对，那么，另外一种可能的比对就是空间比对，比如程序员会比对同样的软件，运行于不同的硬件平台时性能差异的不同。的此一能力，可帮助程序员折叠时空。

可深度贴合用户场景。使用工具，除了可以依据   进行监控外，用户可依据应用场景，进行进程的人工干涉分群，比如，对于多媒体播放场景，把播放相关的和归于一个进程群，并观察此一群的运行状态和资源占用。


的
是基于 发布的，这意味着任何人都可以获得其开源的源代码，并部署使用之，但是对其本身的修复和提高，也必须再次开源。也欢迎与厂商合作，并可能以功能插件的形式，对厂商的部分源代码，使用商业，从而对这部分代码进行闭源。
为什么要做
 三类开发者与对他们各自的作用
主要的目标还是解决现实的问题，加快问题的调试和定位过程，减轻程序员的痛苦，从而提高生产力。
我们大体认为在上从事开发的程序员，依据其与平台本身的亲密度可分为类：

专家，类似游泳健将。
熟悉的开发者，类似会游泳的人。
不熟悉平台本身知识的开发者，类似不会游泳或者只会狗爬式游泳的人。

项目坚决反对程序员的鄙视链，提倡以平常心以公平心看待不同的技术领域。游泳健将不能鄙视狗爬式，虽然别人游泳不行，在体育界不好混，但是说不定人家戏演地好，在演艺圈成功了。技术上倡导百万齐放，行行出状元。
根据著名的二八定律，我们认为有的程序员，掌握了的知识；而有的程序员，只掌握了的知识。第二、三类用户数量远大于第一类用户。
的主要目的是给第二、三类开发者扔一个救生圈防止他们淹死，同时这个救生圈，也可以给第一类用户节省体力，可以缩短他们的调试周期。所以，它对第二类和第三类，达到了救命或者续命的效果，对第一类，更多的是达到锦上添花的作用。
如图，一旦系统出现问题，专家级开发者，由于心中有丘壑，他的需求很可能只是，敲一些命令，然后看看命令的结果，寻找调试方向，所以，他更多的需求是“我看看”；熟悉的用户，通过冰冷的命令输出，可能很难窥探到系统的运行秘密，但是如果能以图形显示，他大概能够知道个七七八八，所以他的诉求，更多的是“帮帮我”；而对于第三类开发者而言，你可能就必须直接给他指出问题出在哪里，他的诉求是“救救我”。

图 三类用户以及他们的诉求
下面我们以一个内存泄漏为例，看看第一类工程师和第三类工程师的区别。故事的背景是，某使用做产品的公司，从开发板的制造商买了一批开发板，而后在其提供的之上，增加了一个的应用程序。但是，不幸的是，此开发板的某内核驱动有极其缓慢的区域以进行申请内存泄漏。下面第一类工程师和第三类工程师同时开始调试这个。
 第一类开发者调试方法
第一类开发者，理解进程内存消耗的、、、概念，并理解内核空间的、以及用户空间的都可能是堆内存的泄漏源头。他的调试过程如下：

以命令跟踪系统，发现系统内存随着时间迁移而持续减小，他确立内存泄漏存在；

怀疑自己写的应用程序有内存泄漏，于是以类似工具，持续跟踪自己写的应用的，经过一段时间的观察，它发现应用本身耗费的内存没有变大，排除自身问题；




持续观察，跟踪和区域的变化，发现区域随着时间迁移增大，确立内核空间类似行为有泄漏；



查看，并使能内核类似选项，最终定位到泄漏的那一行源代码。

结果上述个步骤，第一类开发者比较轻松地修复了这个内核空间内存泄漏的。
 第三类开发者调试方法
第三类开发者没有这么幸运。他的调试步骤是：

以命令跟踪系统，发现系统内存睡着时间迁移而持续减小，他确立内存泄漏存在；
怀疑自己写的应用程序有内存泄漏，怀疑本身有内存泄漏；升级的版本，反复查看自己的代码；
怀疑自己写的应用程序有内存泄漏，怀疑本身有内存泄漏；再次升级的版本，反复查看自己的代码；
怀疑自己写的应用程序有内存泄漏，怀疑本身有内存泄漏；降级的版本，反复查看自己的代码；
怀疑自己写的应用程序有内存泄漏，怀疑本身有内存泄漏；再次降级的版本，反复查看自己的代码；
怀疑自己写的应用程序有内存泄漏，怀疑本身有内存泄漏；升级的版本，反复查看自己的代码；
…

光阴似箭日月如梭，第三类程序员，在不断地重复试错中“鬼打墙”，耗尽了青春，也辜负了年华，一晃就过去了大半年。
第一类程序员这个时候就会鄙视第三类程序员，但是，殊不知，第三类程序员，也有鄙视第一类程序员的理由，因为“术业有专攻，闻道有先后”，彼此关注的领域并不一定一样。对于第三类程序员，如果他在调试的第一步就有了，那么，的数据采集和深度分析能力，将可以直接提示它问题出在内核的，直接提示其进一步的调试方向。
类似项目以及的优势
 
如图是一款  性能实时监测工具，提供界面的界面视角，是上的年度星标项目，项目网址：

图 的用户界面
以分钟为单位，持续刷新系统的运行情况。的端部署于被监控的平台。它目前的局限性有三：

不具备历史数据分析能力只有分钟
不适合部署于嵌入式系统，服务本身的开销大
更大地是面向运维，缺乏对开发人员的支持

在具备比更强大功能的前提下，也要解决上述的个问题，也可更多的面向程序员。
 
如图是一个基于界面的提供分布式系统监视以及网络监视功能的企业级的开源解决方案。能监视各种网络参数，保证服务器系统的安全运营；并提供灵活的通知机制以让系统管理员快速定位解决存在的各种问题。项目网址：

图 的用户界面
仍然是面向运维的，缺乏调试和分析能力。但是，其“灵活的通知机制以让系统管理员快速定位解决存在的各种问题”特征这部分值得学习。
 
如图是用于系统的监控软件，可以监控系统的各项数值之外，最大的好处是可以自己编写插件自定义监控需要的数值。除了可以监控结果，也可以设置报警。项目网址为：

图 的用户界面具备性能分析能力，”设置报警”和“自定义监控”数据等特征都值得我们学习，但是它仍然缺乏面向程序员的深度分析能力，也不适合嵌入式系统。
 带插件的
  ，集成开发环境提供了一个类似 的集成开发环境。它可以集成一些插件，类似：

此方法的主要问题在于实施难度较大，本身过于庞大，对嵌入式的支持也不太完善。安装了插件的更像是一个工具大熔炉，它仍然需要用户知道每个工具以及每个工具的具体用法，另外也缺乏持续监控和直接的预警能力。
就易用性角度，直面狗爬式游泳人员，可以进一步降低开发者对本身知识的了解程度的要求。
的当前状态
 代码托管
目前的代码托管于上面，地址： ，代码仓库中和是分离的。分别位于：


下面演示在位机器上，同时运行和，最后用浏览器监控本机或者板的操作流程：
下载、编译和运行
  
 
  
   
注意，如果要编译的版本，命令为：
  =
编译后将拷贝入电路板或者手机即可。
下载、编译和运行
  
 


开启浏览器访问


在弹出的对话框设置监控本机：

如果是监控电路板或手机，填写它们的地址。
：

 支持平台
我们已经在 电脑板、 位手机和双核、四核上部署过，并以进行数据跟踪和采集。
目前仅支持运行于 位机器上，位机器暂时不支持。
 目前功能
目前具备概况、处理器、内存、磁盘和五个视角。

 概况视角
概况视角显示、内存、总体的状态：

 视角
视角显示各个进程的利用率，多核下负载均衡，，每个核的占用情况，的比例等：

上述视角，对指导中断负载均衡、负载均衡网络下—— 等，有很强的指导意义。

 内存视角
内存视角显示系统的内存消耗、、 等，以及每个进程的内存占用比例，进程的、、和等信息：

 视角
目前可显示队列情况以及每个进程的访问流量：

 视角
目前可显示系统运行时，基于的时间分布，类似 命令的功能：

 目前缺陷
目前的缺陷及改造方向：

监控是浏览器触发的，如果浏览器不点击开始，不会开始。改造目标：自动监控，无论浏览器连接不连接。所以需要后台，后台设置后就连续从采集数据。
没有数据库，没有历史数据。未来考虑除了显示最近五分钟视图以外，增加类似股市的日线图、周线图、月线图。另外，需要增加采集数据和分析后数据的保存与读取能力。
功能性缺失，比如中断、软中断、上下文切换次数，基于的、内存、分析。改造方向：增加中断、软中断、上下文切换、、、、等的视角，增加的分析视角。
没有系统的测试以及剖析本身对监控目标的消耗。改造方向：增加测试案例，执行，执行本身对监控目标性能影响的报告。
深度分析能力仍然不够。比如，我们只是单纯的显示负载，没有办法提示用户目前负载重，没有办法监控到内存泄漏后进行提示。界面上也缺乏对用户适当的提示，对于初级用户来说，还是看不懂。
缺乏中文英文的自动切换，目前暂时只有中文版。改造方向：默认根据浏览器语言，选择英文、中文，提供用户设置的能力。
以监控为主，控制能力不足。理想上面，我们可以对目标监控系统进行一定的配置，比如设置某个进程的，可以在里面点右键来设置；比如，我只想监控某个进程，某个进程的所有线程等。


来自微信公众号  前言
由于深度学习近年来在图像领域的巨大成功，其他领域如语音、等领域的研究也逐渐被深度学习所统治，而且其结果几乎都是    。为了跟上这波趋势，我使用深度学习中的网络对短视频分类进行了尝试，并与目前使用的传统分类方法进行对比，的确取得了更好的效果。
短视频分类任务介绍
对我们浏览器来说，短视频内容都是合作方提供，拿不到视频内容，只有视频链接和视频标题。所以如果想通过机器学习的方法对短视频进行分类，能拿到的信息只有视频的标题。幸运的是，短视频基本都是标题党，标题基本也包含了视频内的主要信息，如下图所示：
图
我们的短视频分类任务包括两部分：
从上报的所有视频站点标题里识别出短视频，这是一个二分类的问题。
对识别出的短视频，需要进行类别的识别。目前我们运营主推的短视频包含类：娱乐、生活、搞笑、奇闻，是一个分类的任务。
另一方面的问题是整个任务的训练样本构造。由于人力有限，没有专门的同事来对短视频及短视频的类别进行标注，只有合作方提供的一些带标注的样本，累计差不多条。这么少的样本量来训练机器学习模型基本上会过拟合。所以我写了个爬虫抓取了合作方之一的的站点的所有短视频及其分类信息，去除不需要的类别，剩下的就可以加入到有类别的短视频中。这样处理后，有标注的短视频总量为。在从上报的视频站点标题里抽样本部分非短视频的样本，两部分加起来样本总量为。另外，从爱奇艺、腾讯视频拿了最近个月内标注好的热门短视频和帅选的一些非短视频标题作为新测试集，共条，用来测试模型的泛化能力。
传统机器学习方法
对文本分类来说，由于维度高，特征也高度稀疏，传统机器学习方法中效果较好的就是和线性。对标题的建模方法是采用经典的词袋模型，先对标题进行分词，去除停用词和其他词频较小的词，词库大小为，对词采用向量化。
 识别短视频二分类
主要尝试了和线性模型，训练时按来切分训练集与测试集，效果如下：
表：



模型
样本中测试集准确率
新测试集准确率















可以看到，和在训练集上都已达到了很高的准确率，而且相差不大。但是，在新的测试集上，准确率有明显的下降。这个主要是采用建模方式的固有缺陷。新测试集上出现了不少没有在训练集上出现的新词，这些词不能映射到已有的词典里就只能丢弃，而原来的模型也没有学到这些信息，所以会降低模型的泛化能力。
 短视频多分类
短视频目前共分类，每类的数量为：奇闻 ，生活 ，搞笑 ，娱乐 。新测试集中主要是奇闻和娱乐，其他类别太少，不参与评估。奇闻数量为，娱乐数量为。多分类的分类器是，效果如下：
表：
可以看到，对这个多分类问题，的总体准确率还不错。但在新测试集中，娱乐的分类准确率很差。这个主要是新测试集中娱乐的样本出现了不少新明星娱乐类短视频就是明星相关，所以基于词袋模型的就有点无能为力了。而奇闻类的样本则取得了优于训练样本的结果。新测试集中的娱乐类样本相对有点极端，模型上线的时候每天进行一次训练能一定程度上降低这个问题的影响。
使用网络分类
、简介
  是一种包含循环结构的神经网络，主要用来处理连续的序列问题，比如股票预测、机器翻译、语音识别等。它的问题主要是当网络变深变大后会带来梯度消失或梯度爆炸的问题，非常难以训练。而  是一种改进的网络结果，部分上解决了传统网络难以训练的问题。目前，在自然语言处理等领域已经有了很多成功的应用，如文本分类、机器翻译等。关于网络的具体介绍推荐看这篇文章：《  》。
、训练词向量
由于原始样本只有条，单纯用这么少的数据量训练词向量。由于训练词向量并不要求对样本进行标注，所以词向量的训练并不受这批样本的影响，原则上肯定是数据量越大越好。由于此向量能很好地反映词的相关性，我刷选了一天可能要预测的视频站点标题加入到原有的短视频样本中，使样本量扩展到如果上分布式训练可以用更大的样本集。由于在 上进行开发，就用版的工具来训练词向量。词向量维数设置为，训练出来的词向量词典大小为。训练词向量的代码特别简单：
 =  = 
        = _= =  __=_
__
                 =
、 识别短视频二分类
从上面的实践可以看到，使用线性模型就能对短视频分类取得比较好的效果，复杂的非线性模型如、效果可能还不如。因此对短视频分类来说，由于特征是高维稀疏的，所以是一个偏线性的模型。在异乡文献中对文本分类的实践也一般都是简单模型反而能取得比较好的效果。所以我在使用网络对短视频进行分类时，也只设计了一个隐含层，输入层就是标题分词后 的结果，输出层采用全连接的回归进行分类。另一方面也是由于样本量特别少，设计过于复杂的网络结果也很容易造成过拟合。网络结构如下：
图
由于数据量较少，直接用公司办公机进行训练，训练框架采用  版本。公司的办公机配置还可以，是显存。
对于上述网络结构，隐含层设置为，序列长度设置为，层的值设置为。其中序列长度原则上应该选分词后的标题的最大词数。经统计发现，词数最大是，词数小于的达到了。但是，随着序列长度的增大，训练时间会变得越长，而且由于样本量较少，过大的序列长度也容易引起过拟合。所以，综合上述考虑就选择序列长度为相关代码如下：
  
_ = 
_ = _ 
_ =       
_ =  
  
 =   _ _
 =   _
  
 = {
  __ _
}
 = {
 __
}

   _
           _    _ _
     =  _ 
          
    _ = _ _=
        
      = __  =
            
    _ =    
    _ = _ _
     _

_ = 
 =    _
    
 = _____= =
 = _=_
  
_ =  
 = __ 
训练结果与做了对比如下：
表：



模型
样本中测试集准确率
新测试集准确率















从对比可以看到，在样本测试集中准确率提高了，而且在新测试集中仍然表现了较好的性能，比具有更好的泛化能力，准确率提高了。这个提升个人觉得除了模型本身的能力外，还有就是因为训练词向量时采用了更大的数据集，词库也更大。这就使得原来没有在有标注的样本中出现过的词但是在词向量训练集中出现的词的信息没有丢失，这些词在新测试集中出现时能对分类发挥作用，但是原来使用基于词袋模型的建模方法就只能丢弃这个词。举个例子，词向量结果中“李易峰”相似度最高的前三个词为：
陈伟霆  赵丽颖  杨洋 
如果“陈伟霆”并没有出现在有标注的短视频标题中，但是出现在新测试集里，它会发挥与原来“李易峰”在有标注的短视频标题中类似的作用。
 短视频多分类
对于分类的短视频问题，的网络结构跟上述二分类的一样。开始时直接对样本进行训练。整体准确率为，比的效果还差。后来发现进行多分类时对类别平衡具有一定的敏感性，于是对样本中类别少的类进行过采样再进行训练，分类效果就有了很大的提升： 
表：
跟二分类的结果一样，的效果对比的结果也有了一定的提升。从对比可以看到，在样本测试集中准确率提高了，而且在新测试集中仍然表现了较好的性能，总体准确率提升了，其中娱乐类提升较大，从提升到了，而且也提升了召回率。新测试集中总体准确率看起来提升不大明显是因为新测试集的样本分布太不均衡奇闻数量为，娱乐数量为，在实际数据中的类别分布并没有这么不平衡，所以实际效果肯定有更大的提升。这个提升的原因分析与二分类的结果类似。
总结
从短视频分类的实践中，可以看到在文本分类中的确能取得比传统分类模型更好的效果。虽然在应用中的网络的深度都不太深只有层隐层，但是取得的效果也已经非常不错。当然，如果有更多有标注的样本，设计更复杂的网络肯定能取得更好的效果。另一方面，由于深度学习的黑盒特性，调参的确是个苦力活，比如网络的层数、序列长度、的设置、训练事_的大小等等，这些参数都有可能对结果产生很大的影响。对应深度学习调参，需要多看，多实践，目前还是缺乏有效理论指导。腾讯云容器服务监控系统可以监控集群中所有的节点，服务，实例，容器的相关信息，并且以曲线的方式展示给用户，同时支持多种粒度的统计方式。监控的基础数据是由  获取，然后上报至监控平台进行聚合。本文将讲解容器监控框架和指标统计方式。
 框架概览

 
 为当前该集群节点上所有的容器，包括但不限于：

腾讯云容器服务创建的
  创建的
  创建的

 
 做为一个运行中的 ，会自动收集所有运行时容器的监控信息，例如  等，经过一定的计算和分类通过页面或者  的方式提供调用。 已经将  功能集成到  组件中同时通过节点 端口也可以直接进行   访问。

  访问方式： 

 
每一台集群节点上会部署一个专门收集监控信息的 每个  会在集群节点创建时默认安装并运行， 会每分钟调用   获取容器的监控信息进行汇总，并且按照多种视图的方式进行聚合计算等等操作，最终汇总成一个包含容器，服务，节点，集群，命名空间的有层级的原始数据上报至    
    腾讯云监控服务
    获取  每分钟上报的结果，通过我们在监控平台上配置的不同视图，不同维度的统计方式进行二次聚合，最终以标准的腾讯云  的形式提供给用户调用。具体的调用方式可以查看  获取容器服务监控数据
 指标详细说明
容器服务以多种视图的方式提供监控视图，视图可以看做是一种分类，每一个视图通过不同的聚合方式，维度，和指标提供独立的监控数据。下面会列举出现在容器服务支持的所有视图和其监控指标，并且解释其统计方式
 集群视图



监控项
指标名称
单位
说明
统计方式




集群  利用率
__

集群内节点的平均  利用率
 分钟  分钟  小时  天 


集群内存利用率
__

集群内节点的平均内存利用率
 分钟  分钟  小时  天 



 服务视图



监控项
指标名称
单位
说明
统计方式




服务  使用情况
__
核
服务内所有容器实例  使用之和
 分钟  分钟  小时  天 


服务  使用率占集群
____

服务使用  占集群比率
 分钟  分钟  小时  天 


服务内存使用情况
__

服务内所有容器实例内存使用之和
 分钟  分钟  小时  天 


服务内存使用率占集群
____

服务使用内存占集群比率
 分钟  分钟  小时  天 


服务网络入流量
__

服务内所有实例在该时间窗口入流量之和
 分钟  分钟  小时  天 


服务网络出流量
__

服务内所有实例在该时间窗口出流量之和
 分钟  分钟  小时  天 


服务网络入带宽
__

服务内所有实例的入带宽之和
 分钟  分钟  小时  天 


服务网络出带宽
__

服务内所有实例的出带宽之和
 分钟  分钟  小时  天 


服务网络入包量
__
个
服务内所有实例的入包量之和
 分钟  分钟  小时  天 


服务网络出包量
__
个
服务内所有实例的出包量之和
 分钟  分钟  小时  天 



 实例视图



监控项
指标名称
单位
说明
统计方式




实例网络入带宽
__

同一实例内容器共享网络，实例 的网络入带宽
 分钟  分钟  小时  天 


实例网络出带宽
__

同一实例内容器共享网络，实例 的网络出带宽
 分钟  分钟  小时  天 


实例网络入流量
__

同一实例内容器共享网络，实例 的网络入流量
 分钟  分钟  小时  天 


实例网络出流量
__

同一实例内容器共享网络，实例 的网络出流量
 分钟  分钟  小时  天 


实例网络入包量
__
个
同一实例内容器共享网络，实例 的网络入包量
 分钟  分钟  小时  天 


实例网络出包量
__
个
同一实例内容器共享网络，实例 的网络出包量
 分钟  分钟  小时  天 



 容器视图



监控项
指标名称
单位
说明
统计方式




容器  使用情况
__
核
容器  使用量
 分钟  小时  天 


容器  使用率占主机
____

容器  使用占主机
 分钟  小时  天 


容器  使用率占 
____

容器  使用占 
 分钟  小时  天 


容器  使用率占 
____

容器  使用占 
 分钟  小时  天 


容器内存使用情况
__

容器内存使用量
 分钟  小时  天 


容器内存使用率占主机
____

容器内存使用占主机
 分钟  小时  天 


容器内存使用率占 
____

容器内存使用占 
 分钟  小时  天 


容器内存使用率占 
____

容器内存使用占 
 分钟  小时  天 


容器磁盘读流量
___

容器对磁盘读流量
 分钟  小时  天 


容器磁盘写流量
___

容器对磁盘写流量
 分钟  小时  天 


容器磁盘读 
__

容器对磁盘读 
 分钟  小时  天 


容器磁盘写 
__

容器对磁盘写 
 分钟  小时  天 



 统计方式说明
上面所描述的统计方式，例如__服务  使用量  分钟  分钟  小时  天 ，解释如下：
 分钟  服务下的所有容器每分钟上报的  使用量之合 分钟  基于  分钟的统计结果， 分钟共  个点，取其中最大值 小时  基于  分钟的统计结果， 小时共  个点，取其中最大值 天  基于  分钟的统计结果， 小时共  个点，取其中最大值
其他统计方式与这个类似，其中容器视同中的指标没有  分钟统计方式，因为容器为最小粒度，顾只需取得上报的值，即为最后的输出值，不需要做聚合。
总结
腾讯云容器服务的监控是基于  来获取基础数据，并且通过一系列的计算，汇总最终呈现给用户。指标覆盖集群，服务，实例，容器四大部分，共  个监控指标，基本涵盖了大部分用户诉求，同时提供控制台页面和云  两种方式输出。欢迎大家使用！开放技术能力，探索产业变革，分享腾讯云助力各行业的转型经验，腾讯“云未来”上海峰会将于月日在上海中星铂尔曼大酒店盛大举行。
本次峰会以“连接·智能·未来”为主题，邀请政企精英、行业领军企业、业界权威专家齐聚一堂，共探云计算、人工智能、大数据等前沿技术的应用场景，助力智慧政府、企业升级变革。
诚挚邀请您前来报名，与各领域专家们深入交流，分享您在专业领域的前瞻之见。
活动时间：月日活动地点：上海中星铂尔曼大酒店
参会大咖：

更多大咖请关注活动官网：


更多详细议程请关注活动官网：
最后，与您相约月日「云未来」上海峰会，不见不散！
参会确认信息将以审核通过，短信通知为准。
报名链接：活动页面： 徐怀宇

 月  日， 发布了一篇如何十分钟成为   系列的第二篇文章，向大家介绍如何为  重构  函数。
截止到目前，得到了来自社区的积极支持与热情反馈， 参考社区  的建议，对计算框架进行了部分修改以降低社区同学参与的难度。
本文完成以下 项工作，希望帮助社区更好的参与进  的项目中来

对尚未重写的  函数进行陈列
对继上篇文章后，计算框架所进行的修改，进行详细介绍

一 尚未重写的  函数陈列如下：
共计  个在  目录下运行   \    |    { |    { } |    { }   命令可以获得所有未实现的  函数




















































































































































































































































二 计算框架进行的修改
此处依然使用  函数 _ 为例进行说明，与前文采取相同目录结构
 _
 方法 简化类型推导实现 
 方法用来生成  函数对应的函数签名，在构造  时被调用
         {
     此处简化类型推导过程，对  实现进行修改，新的实现中，传入  返回值类型  表示返回值类型为 ，参数类型  表示返回值类型为  
    =    
    =  {
      
  }
   此处参考  实现，设置返回值长度为  
   对于  类型返回值，已在  中默认调用  方法，此处无需再进行设置
   = 
   = {{}}
    
}

注： 

对于返回值类型为  的函数，需要，注意参考  行为设置
  |  | 查看  行为可以通过在终端启动
    \\，这样对于每一个查询语句，可以查看每一列详细的 对于返回值类型为  的函数，以  为例，当存在类型为  且包含   的参数时，其返回值也应设置  

对于返回值类型为  的函数，需要注意，根据函数行为，设置 
  =   |  |   ，若为  ，还需注意推导  即小数位数

不确定性的函数：







































实现  方法：保持不变，此处请注意修改该函数的注释   
 __
     {
    
    =  {
           {}
       
          
         
   }{
     
   }

    _  =   {
        =   {}{}
       
        = 
      注意此处不再对  函数的返回值类型进行测试，相应测试被移动到 _ 函数中，注意不是_
        {
          
      }  {
          
           {
              
         }  {
              
         }
      }
   }

    测试函数是否具有确定性
    在  社区的  过程中发现，这个测试经常会被遗漏，烦请留意
     = {} 
    
    
}

 _
与上一篇文章保持不变，需要注意的是，为了保证可读性，  方法仅对 _ 文件中的  函数进行测试。如果 _ 文件中不存在对应的  方法，可以新建一个对应的测试函数。
 _
     {
  
    =  {
           
            
           
          
          
       
   }{
     
      此处添加对  函数返回值类型的测试
      此处注意，对于返回值类型、长度等受参数影响的函数，此处测试请尽量覆盖全面
      {_ _     }
     
   }
    _  =   {
      
   }
}

注： 
当有多个  同时在该文件中添加测试时，若有别的  的  先于自己的   进 ，有可能会发生冲突，此时在本地  一下  分支，解决一下再  一下即可。

成为   赠送限量版马克杯的活动还在继续中，任何一个新加入集体的小伙伴都将收到我们充满了诚意的礼物，很荣幸能够认识你，也很高兴能和你一起坚定地走得更远。
成为   获赠限量版马克杯，马克杯获取流程如下：

提交 
提交之后，请耐心等待维护者进行 。目前一般在一到两个工作日内都会进行 ，如果当前的  堆积数量较多可能回复会比较慢。代码提交后  会执行我们内部的测试，你需要保证所有的单元测试是可以通过的。期间可能有其它的提交会与当前  冲突，这时需要修复冲突。维护者在  过程中可能会提出一些修改意见。修改完成之后如果  认为没问题了，你会收到     的回复。当收到两个及以上的  后，该  将会被合并。
合并  后自动成为 ，会收到来自   的感谢邮件，请查收邮件并填写领取表单

表单填写地址：


后台  核查   及资料信息，确认无误后随即便快递寄出属于你的限量版马克杯

期待你分享自己参与开源项目的感想和经验，   将和你一起分享开源的力量

了解更多关于  的资料请登陆我们的官方网站：
加入    请添加我们的  微信：当前浏览器不能支持视频播放，请采用或以上浏览器
序言
大家好，这节课是十分钟架构课程的第三节课：更大的存储。在这节课，我们来了解下面这个四个方面

应用发展过程中不可避免的存储问题

什么是对象存储

对象存储的优势

对象存储的最佳实践


应用发展中不可避免的存储问题

随着我们的应用的不断发展，应用的文件、图片等附件，会不断的增加，总会有一天会占满我们的磁盘。而存储量的提升，将会带来  用量的提升和综合带宽占用的提升。但是，附件问题有个特点：低频，大部分的附件都很少被读取，但是它们往往占用较大。当我们的磁盘空间用完后，就需要调整磁盘的空间。磁盘的变更可能会要求我们的重启我们的机器。除了重启问题以外，使用我们自己的硬盘存储文件还有另外一个问题硬盘空间和主机带宽的增长循环

随着存储量的增加，我们需要提升带宽来保证我们的文件可以被高速的访问。带宽的提升会优化用户的体验，促使它们再次上传更多内容。
这样的循环会让我们的支出不断的提升。在上一节课中我们提到过，带宽的价格是非常高昂的，带宽越大，单价越高。
那么有没有一种产品可以让我们不用支付昂贵的带宽费用呢？有，那就是对象存储！
什么是对象存储？

对象存储为用户提供海量存储的能力。它独立于云主机之外，而且为我们提供单个存储空间  的总容量，我们可以放心的存储我们想要存储的内容，而且，腾讯云没有限制用户可以创建多少个，也就是说，我们的容量可以认为是无限的。

腾讯云对象存储主要有以下几个优势

单个  的存储总量可以达到  

可以实现在用户之间上传到  ，而无需经过主机中转，不占用主机带宽

文件的访问通过进行， 不占用主机的和网络带宽


如何接入对象存储

接下来，我们来说一说如何在应用中接入对象存储。
如果要在应用中接入对象存储，我们就需要把我们的应用拆分成两个部分。一部分是我们的计算能力，比如我们常说的业务逻辑。 另一部分是存储能力，存储能力分为两块，一部分是我们常说的数据库存储，另外一部分就是我们常说的文件存储。对于文件存储的这一部分，我们可以借助  的  ，将文件存储的能力交给来处理。用户在使用时，只需要把接入到系统中，替换对应的代码。就可以实现使用来进行文件存储。
对象存储的最佳实践

我们希望借助对象存储，提升系统的性能。另一方面，我们也希望他可以帮助我们减少更多的费用。既然要降低费用，我们就要知道，对象存储都收取哪些费用。
对象存储收取存储的费用、流量的费用和请求的费用。其中流量费用和请求费用是其中的大头。我们可以借助，来减少我们的对象存储的请求费用和流量费用，从而实现对象存储的费用的降低。
除了费用之外，我们也建议大家使用  直传，这样文件的上传就可以直接从用户到达  ，而无需借助主机中转，降低了主机的带宽和的使用。

相关推荐：
【腾讯云的种玩法】十分钟轻松搞定云架构之一 ：从上云开始直播回看：高可用架构入门 —— 腾讯云架构演变及经验作者：

首先看一个有趣的问题
 

     {
         
            为设置一个，希望以后能直接
    }
     {
         
             {
                 
            }
        
    }

  
 
 =

     =
    


      
    
        
    



想象中理想的输出
  

     =


 
  {
     
}

实际结果
  
 =
     不会有的引用，也就意味着并不能发现用直接引用的依赖 
      =


 
  {
     
}

解读

实际上只决定本身的语句。

要让识别出类似的短引用，可以配置的映射。


 {
     {
         
    }
}


寻找文件依赖是在阶段完成，阶段并不是一个包含所有文件的阶段，而是处理单个文件的阶段，因此没有所有文件的映射表。函数需要返回两个信息 和 用于替换语句 注②，加入依赖中，所以返回的需和相关文件的一致，否则会出现以下错误：

  {
}

  

    
        
    


注② 返回的
  = 

编译成：
  {
      = 
}


原文链接：


相关推荐     前端开发框架简介和腾讯云免费体验作者：程柳锋

导语
任何软件项目都是一个协作项目，它至少需要个开发人员参与，当原始的开发人员将项目开发几个星期或者几个月之后，项目步入正规。不过他们或者后续的开发人员仍然需要经常提交一些代码去修复或者实现新的。我们经常有这种感受：当一个项目时间过了很久之后，我们对于项目里面的文件和函数功能渐渐淡忘，重新去阅读熟悉这部分代码是很浪费时间并且恼人的一件事。但是这也没法完全避免，我们可以使用一些技巧尽可能减少重新熟悉代码的时间。 可以满足需要，它也反映了一个开发人员是否是良好的协作者。
编写良好的 可以达到个重要的目的：

加快的流程

帮助我们编写良好的版本发布日志

让之后的维护者了解代码里出现特定变化和被添加的原因


先来看看一个比较好的例子，感受一下：

下面谈谈，如何让项目里面的 步入规范化，流程化。
 的基本语法
 
 

 


表示提交类别，表示标题行， 表示主体描述内容。
的类别说明：

 添加新特性
 修复
 仅仅修改了文档
 仅仅修改了空格、格式缩进、都好等等，不改变代码逻辑
 代码重构，没有加新功能或者修复
 增加代码进行性能测试
 增加测试用例
 改变构建流程、或者增加依赖库、工具等

 格式要求
 标题行：个字符以内，描述主要变更内容

 主体内容：更详细的说明文本，建议个字符以内。 需要描述的信息包括

  为什么这个变更是必须的 它可能是用来修复一个，增加一个，提升性能、可靠性、稳定性等等
  他如何解决这个问题 具体描述解决问题的步骤
  是否存在副作用、风险 

 如果需要的化可以添加一个链接到地址或者其它文档

这个问题给代码的变更建立了良好的上下文，可以让其他的代码人员或者项目成员直观的判断修改点是否正确。一条良好的 也可以让维护者知道这个是否适合发布到稳定的版本中去。
如果一个没有回答上面的这几个问题，那么它是无意义的。它会给的人员造成负担，让他们花费大量时间去评审讨论这个的作用和意义。更糟糕的是，如果一个项目实施纪律，则这个会被拒绝掉，然后开发人员需要花费时间重新编写一个新的。重新编写一个复杂的代价是巨大的，而把 写好只会花费几分钟。
 书写建议

尽可能多的提交，单个 包含的内容不要过多；

标题行以   开始，采用命令式的模式。不要使用  等等；

始终让第二行是空白，不写任何内容；

主体内容注意换行，避免在里面滚动条水平滑动；

永远不在   上增加  或 = 参数，提交的时候 即可；

如果你是用户，将下面这行代码加入到。这会帮助你检查拼写和自动换行。
     =



使用工具
可以让你的 更加规范统一，适合项目团队使用，使用也很简单，使用安装后，提交代码的时候使用 去替代以前的 命令即可。
安装：
    

使用截图：

自动生成 
是用来从的元数据中生成  文档的工具，只要你提交的格式满足它定义的标准，此处以标准为例子。使用它生成的 包含以下三个部分：

  修复的信息

 增加的特性

  重大变更


可以参考它生成的文档，使用如下：
    
  
      

这不会覆盖你之前的文档内容，会在这个文件的最上面插入新生成的日志信息。
参考链接

     

      



 

  





原文链接：


相关推荐使用自动部署简单网站  和工作流规范微信小程序 扶持计划导语： 之前一直忙于项目工作，一直没有好好去系统学习，完善自己的知识体系，以致于在腾讯两年知识体系都没有深度发展，还是停留在原来的领域，所以从月份开始学习。中间穿插的学习了内核和爬虫。

简介
是发起的一个项目，早在年，自诞生起，就是整个技术界的明星项目，当时我还在上海实习，就在各种技术媒体上看到了的介绍文章，很多技术媒体宣称是一项技术突破，并且是一次技术革命，可惜当时由于本身是一个 开发者，眼界很低，对于这种虚拟化技术有点不屑一顾，而今转后台后才发现这项技术的重要性
的特征
是一个云开源项目，托管在，任何人都可以通过   或者参与进来，本身是基于的容器技术，采用当时如日中天新推出的语言实现。采用 协议开源。
镜像地址
语言与
相比语言与其它语言的对比，国内外很多技术媒体都有列举，在领域，语言相比其它语言的优势在于

相对于 开发难度低，支持向前兼容，运维维护成本小
相对于，生成的是静态文件，有效的避免的低级错误，并且性能高一个等级
并发性好，内存占用低
部署简单，毕竟生成的静态文件，有的地方就能运行

一门语言当然也有自己的缺点，比如，内存回收延迟久，图片处理库有，对包版本要求严格等一些问题，但是瑕不掩瑜，一个开发成本极其简单，性能优良，部署简单的语言与简直就是 天作之合
至于语言的优势，在的社区中都有非常详尽的讨论，这里不多讲
的目标
的是一个轻量级的操作系统虚拟化解决方案。 主要目标，用官网的概括来说就是“，    ”：编译，装载任何在任何地方都可以运行，我们大概理解就是一个容器，实现了对应用的封装，部署，运行等生命周期管理，只要在的环境下，到处都可以运行。
这点在企业的云服务部署是有非常广泛的应用前景。后面我们将详细讨论。
的引擎
的是基于自带的。 技术，在上，进行了近一步封装。正因为如此，只能在环境下运行，当然，前段时间终于支持和了，虽然还是体验尝鲜版，但更加方便开发者去开发了！
的原理
其实前面讲了这么多，的原理已经不言而喻，这里用的解释就是

容器有效的将单个操作系统管理的资源划分到孤立的组中，以便更好的在孤立的组之间平衡有冲突的资源使用需求。与虚拟化相比，这样既不需要指令级模拟，也不需要即时编译。容器可以在核心本地运行指令，而不需要任何专门的解释机制。此外，也避免了准虚拟化和系统调用替换中的复杂性。

简而言之就是，是一个盒子，一个盒子装一个玩具，无论你丢在哪里，你给他通电，他就能运行。你的玩具大就用大盒子，小玩具就用小盒子。
两个应用之间的环境是环境是完全隔离的，建立通信机制来互相调用。容器的创建和停止都十分快速秒级，容器自身对资源的需求十分有限，远比虚拟机本身占用的资源少。
  
与虚拟机虚拟机的区别可以看

左图是虚拟机的工作原理图，对资源进行抽象，着重体现在硬件层面的虚拟化上，这种方式增加了两场调用链，对性能的损耗比较大，而且还会占用大量的内存资源
有图是的工作原理图，属于级别的虚拟化，通过创建多个镜像来隔离不同的进程，由于是是共享，而且本身 也不大，性能损耗几乎可以不计，而且内存占用也不大，大大节约了设备成本。
架构总览

最核心的是  我们称之为守护进程，也就是端，端可以部署在远程，也可以部署在本地，因为端与客户端 是通过 进行通信。
  实现容器和镜像的管理，为用户提供统一的操作界面这个 客户端提供一个只读的镜像，然后通过镜像可以创建一个或者多个容器，这些容器可以只是一个  也可以是一个包含了用户应用的。容器在 中只是一个进程，两个进程是互不可见的。
用户不能与直接交互，但可以通过与容器这个桥梁来交互，由于是操作系统级别的虚拟技术，中间的损耗几乎可以不计
注
：  。命令行接口：   根文件系统
  
在中，我们重点关注的就是镜像和容器了。因为在实际应用中，我们封装好镜像，然后通过镜像来创建容器，在容器运行我们的应用就好了。而端掌控网络和磁盘，我们不用去关心，启动  和  都是一条命令的事情。后面会详细讲的启动过程。
  一个只读的镜像模板。可以自己创建一个镜像也可以从网站上下载镜像供自己使用。镜像包含了一个一个镜像可以创建很多容器。
 由 通过镜像创建的实例，用户在容器中运行应用，一旦创建后就可以看做是一个简单的，每个应用运行在隔离的容器中，享用独自的权限，用户，网络。确保安全与互相干扰
两者在创建后，都是一堆的统一视角，唯一的却别是镜像最上面那一层是只读的，不可以修改，但是容器最上面一层是的，提供给用户操作
仓库，这个东西没有单独介绍不是因为它不重要，而是因为之前做个比较多的源码编译，所以这里就没有仔细往下看，大概就是一个镜像库，最大的是 ，类似于 的，当然也可以本地搭，比如事业群就有自己的。
的应用
最后，这里讲一下的应用作为本文的终结。
为什么会想起来学习技术
年年中的时候，我转做后台，经历了一段时间的时候痛苦转型后，中学摸到了门槛，年底赶上事业群的服务器化，那段时间非常痛苦，因为相对实体机或者虚拟机，各种问题频出，因为虚拟机或者实体机是不会迁移的，我们部署一套服务后会有一些依赖库需要安装，但是那段时间经常迁移，之前也没有接触过，导致问题频出。
到年月的时候，基本稳定下来，我们也开始享受带来的种种便利，比如：

发布服务再也不用服务器的运行环境了，所有的服务器都是自动分配，自动部署，自动安装，自动运行
再也不用担心其他服务引起的磁盘问题，问题，系统问题了。之前我们固定在一台上发布我们所有的服务，导致后面这台上挂了多个服务，日志文件经常导致磁盘爆满，一旦磁盘爆满，多个服务就要挂掉一半服务。
更好的资源利用，因为今年还没有数据出来，但个人预计是会给公司节省一半的服务器资源，既避免了资源浪费的同时，又保证了服务的稳定运行
自动迁移，学历了后，我们可以自己制作镜像，后面服务迁移的时候，只要使用我们自己的镜像，无论怎么迁移都不会出现任何问题
对于运维来说，管理更加方便了。

目前事业群已经全面接入了，也证明了容器技术的成功性。
：

 已经集中支持 
 在 产品中广泛应用。


后记
看完整体架构后，内心真心感谢那些为了推动事业群化力排众议者，后面有时间自己也会去封装一些 ，毕竟很多项目需要使用特有的环境，以往每次迁移都要去安装一次软件。
这篇文章是月中开始写，写写断断，持续了一个半月，这一个半月项目组一直很忙，连续加了好几个周末。知道国庆才有时间好好整理一下所学。有时间再去写的启动流程。
纯手打的文章，写辣么多，路过就点个赞吧实验架构

任务一：创建一台云主机并登录
登录公共帐号，在云主机控制台找到自己的云主机，复制你的主机的公网
登录云主机
 下载并安装客户端软件 
从本地登录到云服务器，我们需要下载一款链接工具。 
这里我们使用来链接服务器。 
访问链接
下载
：登录到服务器 

双击打开，在中输入地址，点击下方的，进入命令行界面 

使用用户登录，密码为你自己设置的密码 

登录成功后，输入命令  切换到用户下。 


操作示例如下：
注：管理员账号的初始密码由系统分配，用户可以重置密码，详见管理员账号密码重置。同时，用于登录的公网可以在管理界面查询如下图所示

任务二：购买一个数据库实例，并初始化
登录控制台，根据你拿到的用户名和密码，找到自己的数据库

服务器端安装 

   

验证数据库是否正常连通



首先查看数据库的内外， 

    

任务三：安装并配置必要的软件
任务目标：在云主机安装必要的支持软件，包括，运行环境， 扩展。并通过成功配置一个 

更新源

  

安装

   

验证是否安装成功

   

浏览器中输入外网



安装执行环境

   

安装 扩展

   
任务四： 获取源码，完成相关配置
任务目标：从中获取源码，配置的  并创建相关的数据库表，以及和数据库连接配置

获取源码

  _

创建 工作目录 

  

将源码解压到  工作目录 

   _  

修改目录权限 

    

配置 执行如下命令下载设置脚本

   

 
在弹出提示   时，输入云服务器的，并按回车。
创建完成后，执行  重新加载配置文件 


创建数据库

在腾讯云的数据库管理页点击登录，进入到管理控制的页面
用你初始化时设置的密码登录。用户名为密码为你自己设置的密码
登录成功后，点击顶部的选择数据库，进入数据库管理页面，在下方输入框输入要创建的数据库名，点击创建
创建成功后，会自动定向到数据库页面，点击权限、新增用户账户
在新的页面中设置你的用户信息，其中需要注意的是数据库的主机应该为你的的内网 


重启 和

    
任务五：安装配置
在浏览器中访问你的服务器的， 
点击下一步安装，输入你的数据库信息，然后点击下一步安装 
详情可看下图 

任务六：使用负载均衡进行平行扩展老师演示

创建一个负载均衡
绑定之前创建的云主机，直接通过负载均衡的地址来访问服务
将现有的云主机创建镜像
新生成一台云主机，挂载到负载均衡
停止一台机器的服务，看看是否正常工作
任务七：将镜像共享到自己的帐号

将自己的云主机停止
使用云主机创建镜像
为创建好的镜像设置共享
在原有帐号上查看共享的镜像
任务八：清空数据库
使用  用户名 命令登录到数据库上
执行命令   数据库名
保存退出

相关推荐   博客平台 利用腾讯云搭建个人博客 【腾讯云的种玩法】发送邮件设置序言：

   的区别： 是腾讯  移动互联网事业群开源的，是腾讯 社交网络事业群开源的产品。实现的功能比较类似。

 准备阶段：我在云上准备一台测试服务器，看到官方在看到是安装，为了避免一些不必要的麻烦系统不一样命令可能有的不一样等问题， 选用  位。
 第一：准备代码文件
下载文件到用户登录进来，初始化目录目录其实没有什么要求，并解压。
第二：准备相关依赖





这些加官方群文件里有下载，下载到 目录下，和同级目录。
第三：修改
=     就是你自己的本地，据说不让是=  这是计算名 可以这样查看        这是增加在安装 这个文字下放。 
    __ = = =   添加加粗的字体这这一行，我就被坑在这个地方了。。。
另外里面有一些域名需要替换成自己的。
第四：修改
=    就是你自己的本地，据说不让是
第五：运行
修改运行权限：  
运行脚本：
 
：在重新安装了十多遍才搞起来了，多谢官方群内的大牛们 官方也有直接可以体验的镜像什么是
是的超集，带来了诸多新特性：

可选的静态类型
类型接口
在和被主流浏览器支持之前使用它们的新特性
编译为可被所有浏览器支持的版本
强大的智能感知

特性

可选静态类型

类型可被添加到变量，函数，属性等。这将帮助编译器在运行之前就能显示出任何潜在的代码警告。
给加上可选的类型系统，很多事情是只有静态类型才能做的，给加上静态类型后，就能将调试从运行期提前到编码期，诸如类型检查、越界检查这样的功能才能真正发挥作用。的开发体验远远超过以往纯的开发体验，无需运行程序即可修复潜在。

支持使用和的新特性

在中，你可以直接使用的最新特性，在编译时它会自动编译到或。

代码自动完成，代码智能感知

与

是一个应用程序级的开发语言。
是的超集，可以编译成纯。
跨浏览器、跨操作系统、跨主机，开源。
始于，终于。遵循的语法和语义，方便了无数的开发者。
可以重用现有的代码，调用流行的库。
可以编译成简洁、简单的代码，在任意浏览器、或任何兼容的环境上运行。
比更具开发效率，包括：静态类型检查、基于符号的导航、语句自动完成、代码重构等。
提供了类、模块和接口，更易于构建组件。

参考：《 的全部资料，以后都放这儿了》
为什么是
大型项目常见问题

类型不明确，甚至在使用中转换。

  = 
 = 

对象成员属性不明确，使用容易出错。

  = {   }


接口返回内容和格式不明确。

  {
 
}

接手代码注释不多，相关变量命名不规范，变量类型、接口类型等均难以。

重构代码、重命名符号需要改动太多相关文件。


谁在使用
框架：工具：编辑器：工具库：、：   库：
说
  拥有很好的工具。
它提供了先进的自动补全功能，导航，以及重构。有这样的工具几乎是开发大型项目的必要条件。没了这些工具，修改代码的恐惧将会导致该代码库在一个半只读状态， 并且使大规模重构变得极具风险，同时消耗巨大资金。
  使抽象概念明确。
一个好的设计在于定义良好的接口。支持接口的语言使得表达想法变得更加容易。不能清楚地看到界限，开发者开始依赖具体类型而不是抽象接口，导致了紧密耦合。
  使代码更易阅读和理解。
说

要支持强类型。
要有很好的配套工具。
已经有了成功案例。
我们的工程师可以很快上手。
能同时工作于客户端和服务器。
有优秀的类库。

  ：
是的强类型版本。是通过一组可以添加到的注解，然后通过工具检查正确性。的类型注解能自动的被移除。与相比，在类型检查中做得更好。是强类型，能使代码有更少的类型相关，更容易构建大型应用，还有着丰富的生态系统。
的一大加分项就是其生态系统，的支持库实在是太棒了。
并且还支持目前流行的编辑器，比如 和 。
此外，还支持解析。
为什么使用
 提供了先进的自动补全功能，导航，以及重构工具。
构建丰富的开发工具从第一天起就成为了团队的明确目标。这也是为什么他们构建了编程语言服务，使得编辑器可以提供类型检查以及自动补全的功能。那么多的编辑器都对有极好的支持，就是因为提供了编程语言服务。
 是的超集，从迁移方。
从迁移到不需要经过大改写。可以慢慢的、一次一个模块的迁移。
随便挑选一个模块，修改文件扩展名为，然后逐步添加类型注释。当你完成了这个模块，再选择下一个。一旦整个代码库都被类型化，你就可以开始调整编译器设置，使其对代码的检查更加严格。
 支持接口，抽象设计。
在一个静态类型的编程语言中，使用接口来定义子系统之间的界限。
 类型的支持，使代码更易阅读和理解。
我们不需要深入了解代码的实现，也不需要去阅读文档，就可以更更好地理解代码。
 生态系统完善，支持库完备，已有不少使用的成熟项目。
参考

《为什么   改用  语言实现》
《为什么  选择了 ？》
《 优秀开源项目大合集》

使用
关于的语法，更多的可参考官方文档，这里只列出常用的：基础类型、接口和类。
基础类型
支持与几乎相同的数据类型，此外还提供了实用的枚举类型使用。

 布尔值
   = 

 数字
   = 

 字符串
   = 

 数组常用
 在元素类型后面接上 
   =   

 数组泛型，元素类型
   =   

 类型常用于对现有代码进行改写
   = 
 =    
 = 

 类型像是与类型相反，它表示没有任何类型
 函数没有返回值
   {
    
}

 默认情况下和是所有类型的子类型
 可以把和赋值给各种类型的变量
   = 
   = 
接口
的核心原则之一是对值所具有的结构进行类型检查。它有时被称做“鸭式辨型法”或“结构性子类型化”。
在里，接口的作用就是为这些类型命名和为你的代码或第三方代码定义契约。
  {
 
 可选属性
  
 指定属性 
  |  | 
 只读属性 
   
 函数类型
   
}
接口继承
  {
 
}

 接口继承
 此时同时具有两个属性
    {
 
}
类
 开始，程序员将能够使用基于类的面向对象的方式。
  {
 
  {
 = 
}
 {
    
}
}

  =  
当接口继承了一个类类型时，它会继承类的成员但不包括其实现。接口同样会继承到类的和成员。
公共，私有与受保护的修饰符：

默认 可以自由的访问程序里定义的成员
 当成员被标记成时，它就不能在声明它的类的外部访问
 修饰符与修饰符的行为很相似，但成员在派生类中仍然可以访问
 将属性设置为只读的，只读属性必须在声明时或构造函数里被初始化

  {
  
  {  =  }
}

    {
  

    {

 = 
}

  {
 `    {}     {}`
}
}

  =   

  
在中，可以使用很多新的特性，其中类也是特性之一。包括和，其实都是而不是的特性。但、、等，则是中增加的。
声明文件
大多数情况下，类型声明包的名字总是与它们在上的包的名字相同，但是有前缀：
   
这里我们参考中的，在我们在中使用的时候，若无安装或是自己声明，会报错的：
 声明
   
  {
 
 
 
 
 
  | 
 
}
项目配置
：文件中指定了用来编译这个项目的根文件和编译选项。：规则定义。

 常见
{
 {
   根路径，常在使用时候结合使用
   目标版本，当需要承接的时候可设为，常设为
   保留的处理，常用在使用时
 
 
   使用装饰器
   使用元数据
 




 {
 
}
}
 
_

}
项目迁移
常用迁移步骤：

安装依赖    等
文件重命名 =  |  = 
添加和
调整配置  
添加声明文件等

最后来个小故事
刚开始，项目比较小，我一个人写，每行代码我都能记得，每个变量我都知道是什么。
后来，我有了个小弟，他进来后熟悉项目全靠注释、以及面对面讲解。我们开始愉快的合作节奏，分工进行与后台接口的对接，除了约定一些接口规范，我们通常只有一个初始版本的接口说明，联调中持续的更新并不能及时更新到文档或注释中。
再后来，又来了个小弟，我们开始了口口相传的说明。但是由于理解、表达和沟通的问题，效率开始下降。
我们每个人有各自的命名习惯，有的喜欢小驼峰，有的喜欢下划线，有的还爱用。然后我们使用，但是很多对象的属性、接口的类型等等，都无法解决。
我们使用不一样的编辑器，有，有，有。
我们还经常出现接口调整，甚至是字段名调整的情况。
然后我们上了。
当时我们的框架是版本，但是也照样使用了。从迁移到是其中一个小弟完成的，然后我们开始了制定一些规范，更新说明。
后面的情况是：
我们对每个接口和数据对象定义，缺少相关的库类型定义也能从相关社区中找到。
不管我们使用怎样的编辑器，都能有很好的自动补全功能、导航工具。
接手相互的代码，能第一眼就能知道各个变量的类型，模块大致的作用等。
再也不怕经常性的调整接口，因为我们可以一键重构相同中的某字段。
接口的引入，使得我们对代码的抽象设计变得容易了，逻辑和架构也清晰了。
以上的这些这些，随着项目增大越发觉得舒服。
结束语
很多时候，当我们维护不同重量级的应用，或是在不同的场景中使用应用的时候，面对的架构选择往往是不一样的。就像我们在很小的页面里使用会觉得繁琐，在数据类型不多的对象或接口中使用会觉得没啥效果一样，个人还是认为，好的架构在能遇见拓展性的同时，不过度设计，恰到好处才是最棒的。导语 作者简介：王鹤，高级前端工程师，隶属于腾讯增值产品部。主要负责个性化业务的功能开发及技术优化。目前专注于框架的研究，致力于提升效能，解放生产力。

一、前言
框架是和、、、、等小伙伴在框架基础上结合业务本身做的一系列优化，封装，改进的框架实践，同时也学习借鉴了部分动漫项目组的一些优秀的思想。包含脚手架，基于的组件，最新的语法特性，，内置加速方案，配套可扩展的编译系统等。因为主要语言是用编写，所以故命名为「」框架，本文只阐述和直出同构相关部分的内容，其它框架内的内容另行介绍。
在的《项目实战》中，我们增值产品部个性化商城业务已经用上了基于、、现在应该是、的一整套开发流程。在之前的实践中，我们是基于纯前端的使用，即或服务器返回纯框架，异步渲染整个页面。不过这里缺乏页面直出同构的实践场景。中型移动端项目的最佳实践，还是基于首屏页面直出，其它屏以组件形式异步加载的方式为佳，再结合比较成熟的加速方案提升页面的打开速度，提升用户体验，而且对支持友好。
二、技术选型
大方向的技术选型在《项目实战》中已经阐述得非常清楚了。具体细节选型，结合我们自身业务，有选择的使用提供的全家桶。
、是否使用。根据我们自身业务的场景，比较适合用多页面应用，路由采用后端路由，我们的后端是，后端框架是。使用在中编写功能即可。所以我们的业务不太依赖，而且部分也可以通过缓存和异步组件自行实现。
、是否使用。对于我们的业务属于中型项目，且我们的业务属于多页面应用，间接地把业务进行了二次细分。那么反而繁琐和不灵活，对于多页的支持也需要改造。所以在我们的业务中，组件的传递都是通过和  来实现，足矣满足我们的日常需求。
、是否需要后端打包。前端打包肯定是必要的，一是文件模块依赖的处理，二是各种语法的转换。后端是否要打包这个认为可选。不打包在后端来说也是没有问题的。打包也可以，就是发布文件少，扔到服务器即可用。可能也会做一些处理。我们的业务暂时没有需要后端打包。
三、同构
、环境一致性
前后端同构语言一致这是基本。另外涉及到同构，就有两个问题绕不开，一是采用  还是。二是环境不同，环境变量不同，请求访问的方式不同。
第一个问题，首先很遗憾直到最新版本也没有支持  的语法。所以后端代码使用此语法，还需要等进行转换成的模式。在我们的业务中用的是的转换能力。后端最终是，而前端要使用。那么前后端最终两者的编译方式是不同的。
所以在我们业务中的解决方案是前端在开发环境中和后端一样，使用的语法进行打包。然而在生产环境中，前端使用 进行打包，利用的能力进行代码精简和压缩。
有压缩无的打包大小
有压缩有的打包大小
这里的效果还是蛮明显的，有接近的优化。
第二个问题，因为前后端环境不同，比如前端有对象，对象，后端没有这里有对象，的识别出现问题。如果有这方面的兼容性问题，请处理好。
通信并不完全一样，前端使用的是协议网络通信，后端实际上从性能考虑，可以使用协议进行通信，不需要到协议。当然这些在使用中倒不是瓶颈。
另外不推荐使用官方推荐的，我们在实践中发现一是代码非常多，源代码多达近行，这在移动端确实有点浪费。另外还不支持常见的和方式的请求方式。所以这块建议大家根据自己需要用自己的库代替。可以参考一下我们的库，足够满足我们的业务需求。
核心代码行。满足种请求方式：

 {      }

、编写同构代码
先看目录结构，基本不需要额外的介绍，主要是方便文章中代码文件的理解：

代码同构一直是我们的理想编码方式，一份代码，前后端通用。结合框架本身，的给我们提供了实现的可能。直出的本质无非是后端输出一份字符串，而且结合，进行文件的流式输出。代码类似下面这样：

  =  {
     {
         
    }
      =
     {}
}

  = {
       =     
      _ =     
}

  = {
     
}

    = {
       
    
    
}
虽然代码行数不多，这里要着重讲一下，有很多细节在里面。
后端部分的 和前端部分的 写法略有不同：
后端部分的 ：

     
   
  =  {
     {
         
    }
      =
     {}
}
前端部分的 ：

     
   

  =  {
     {
         _
    }
      =
     {}
}


部分

 =
        

后端部分的挂载点根据，前端部分的挂载点根据组件中的=
数据部分，后端的由后端拼好数据，前端这里有点讲究。有涉及数据共享的部分。传统的做法是通过的来实现，在我们的场景中，我们没有使用。只是首屏渲染部分我们采取全局变量的方式来完成数据共享和一致性。
的妙用
中提供的上下文来传递变量给到首屏页面是个非常方便的东西，可以做很多初始化工作。
比如我们经常需要获取会员信息等，定义一个全局变量可以很方便的任意地方进行使用。不需要异步加载。
再比如我们页面做性能测试的时候，需要脚本，蹦失率脚本等，且需要进行灰度处理。这使用再方便不过了。
后端：

  = {
    灰度蹦失率的脚本，尾号为进行蹦失率统计
        ==      
}
前端模板：

四、直出与切换
在做了同构直出之后，我们惊喜地发现我们自然而然的具备了直出和页面任意切换的能力，我们只需要稍微改造一下就能实现。此处感谢动漫团队的灵感和启发。
、首屏数据部分进行一次同构，让后端和前端都可以通过同样的取到相同的数据

   {
     _ {
         _
    }  {
          
    }
}
、后端改为：

  =  
  =  {
     {
         
    }
      =
     {}
}
、前端改为：

 = {
      =  {
         {
             
        }
          =
         {}
    }
    
}
、那么我们新建一个名为_文件
这个文件是放在的，唯一和直出文件不同的地方就是一个
直出版本：

 =
    

版本：
_
 =
    

其它完全一模一样！
这样我们做的事情就可以在直出抗不住的情况下，轻松切到啦，只不过内容全部都是异步拉取的了。对于暂时的用户体验来说并没有太大影响，避免出现过载，业务出现无法访问的情况。
通过此方案我们可以制定一个流量控制策略，轻松在直出和两者间切换自如。
五、直出与的结合
是最近比较火的一个页面加速方案，方案详情见：
如果在手环境中，那接入相当简单。如果不是，请参考开源代码：
不过实际上由于的一些导致接入会出现问题，好在为大家把坑填平了。
、的部分无法保留注释
看过原理和方案的同学知道是依赖注释来拆分模板和数据的。但是因为的部分代码有个，导致无法保留注释。
这个问题在官方文档版本已提供参数来解决，并且上也有相关讨论但实际上，  ，并没有彻底解决，代码是有的。
既部分即使设置也是不行的。修改了两处的代码，修复了这里的问题。准备提给官方，看他们准备如何处理。修改如下：
行，源代码为：
  {
     _
}
修改代码为：
  {
     _
     
}
行，源代码为：

 
修改代码为：

 
改完代码，只需要轻松声明一下注释保留即可 ：
组件声明部分：
{
     
     {
         
    }
     
     { }
}
、处理好源代码的之后，我们就可以开心地使用和的结合啦
将数据块包裹在标签中

 = =

引入_模块

     _
在输出字符串的地方用模块处理一下
    = {
       

      =  
    
    
}
在页面的参数上加一个=，表示在手环境中开启模式如果是非手环境，请按照的文档进行接入。
六、直出与测速优化
测速优化是老生常谈的问题，在接入的同构方案之后，我们对测速还是需要进行优化的。不过这些优化都可以在编译流程中完成。
关于前端的测速核心还是网络耗时页面耗时首屏可交互
、网络耗时
网络耗时包含服务器的耗时纯网络耗时。
首先直出的页面和页面相比，服务端有渲染的耗时问题。我们之前在使用直出的时候还担心这里会有性能问题，但实际在中型项目中使用，实验室数据还可以，如下图所示：

纯网络耗时比较好的思想是充分利用缓存，那么方案就是一个很好的方案，上面已经详细介绍过了。主要优势体现在局部刷新和完全上面。测速数据如下：
、页面耗时
关于页面耗时，我们先看我们的页面结构分解
由于我们使用同构，并且对底层库进行了大量的重构。我们的业务完全脱离，只使用的行核心代码。也就是我们只依赖作为我们的库。
那么库采用手离线包的方案，将公共库缓存到手里，减少公共库加载的阻塞。
 标记为「」，编译系统通过任务和插件先进行的打包和，再识别标识「」，将文件替换为本地文件并打在里面。
 标记为「」，编译系统通过任务和插件先进行的打包和，再识别标识「」，读取的依赖声明文件「」，将文件替换为文件。
整个流程通过编译系统来处理，然后交给发布系统进行发布。
此时目前我们实验室的数据，页面耗时在左右。
、黑科技
首屏可交互的点在中，尽管公共库有离线包的存在，但是还是会有一些阻塞。并且也是有执行耗时。更彻底的办法是通过插件将首屏需要用到的监听事件和方法抽离出来，不依赖公共库，即可直接事件响应。
此处和动漫团队学习交流了一下。核心思路是把数据和小方法提前到公共库以前，这样可以在没有公共库的情况下，也可以完成简单的交互比如跳转，对话框，选中态等，因为在没有驱动的情况下，核心思想是需要数据和事件方法的。
在
预计再提升。
七、结束语
此篇为系列文章中的四篇中的第三篇。短期总共规划应该有四篇，分别是：
、《框架的脚手架环境搭建新手必备踩坑》作者：  月初完成，目前草稿
此篇为新手入门必备
、《框架的初级实践》作者：已完成，其实就是《项目实战》
此篇学习之后可以完成简单的前端开发
、《框架的中型移动端项目直出同构实践》作者：   已完成。
就是本文，此篇学习后可以完成中型移动端项目的前端开发，并且提供经过线上检验的性能优化方案。
、《框架的》作者： 十月初完成，目前草稿
主要结合组件进行快速组件开发
希望可以在基于的架构之上深度挖掘，最终能提高效能和性能。早点下班回家