接《    爬虫实战：爬虫之  自动化终极杀手  上》
再理一下方案步骤：

模拟用户登录
进入个人播放页
获取
获取 并将其添加到中。
请求页面，获取数据

代码
   
      _ = 
      _ = 
      _ = 
      _ = 

       模拟用户登录
       浏览器访问登录
      _
       休息一下等待网页加载。还有另一种方式：_
      

       获取页面元素对象方法本次使用如下：
         ___  通过标签获取元素对象 可在页面中获取到唯一一个元素，因为在规范中。一个树中标签不能重复
         ____  通过标签类名获取元素对象，可能会重复有坑
         ___  通过标签获取元素对象，类同，可获取唯一一个元素。
       获取页面元素对象用户名
       = ___
       
       坑：获取页面元素对象密码
         在通过类名获取标签元素中，遇到了无法定位复合样式，这时候可采用仅选取最后一个使用的样式作为参数，即可稳定性不好不建议使用。尽量使用_
        = ____       
       = ___
       
       获取页面元素对象登录按钮
      _ = ___
       通过 调用模拟键盘的输入用户名
      __
       通过 调用模拟键盘的输入密码
      __
       通过 调用模拟鼠标的点击操作，进行登录
      _
       休息一下等待网页加载
      _

   __
      
      进入 播放器
       浏览器控制对象
      
      

       请求个人信息页
      _ = 
      _
      

       = ___
      
      

   __
      
      使用自动化工具获取网页数据
        待获取网页
       页面数据
      

       初始化浏览器
       = 

       用户登录
      

       进入播放页
      __

       搜索打开歌曲
      _ = {_}
      _ = __=_

      _
      
       搜索获取网页代码并返回
       = _
       
通过上边的代码我们可以获取到网页完整的数据，再使用对源代码进行解析获取数据内容就可以了。可是在想一下。我们利用浏览器自动化进行操作的时候效率很低，相比于调用接口的方法获取数据慢很多，并且在对数据进行解析的时候会比较麻烦，到这里我准备使用第二个方案再次进行完成这个需求。不多说动手吧。
方案：
在方案的研究基础上，方案仅针对获取数据的部分进行更改，使用访问数据接口，获取数据并解析。
实现步骤：

获取登录并进入播放页获取和其他
请求数据接口
解析返回数据

代码实现：
   _
      
      收集
        浏览器控制对象
       字典
      
       从浏览器获取
       = _
       解析并返回结果
      _ = {}
         
          _ = 

       _

    ，，
       获取的
       = 
       解析
       =  
       =  

       省略对数据解析。注意判断，将解析到是数据保存在两个中即可。

   ___                        
      
      使用自动化工具获取网页数据
        待获取网页
       页面数据
      

       初始化浏览器
       = 

       用户登录同上
      

       进入播放页同上
      __

       获取
       = _

      
      搜索歌曲，专辑
       _ 待搜索歌曲名
       歌曲、专辑搜索结果
      
       = =={_}_=_===_

       = _=_
        = 
        = 

       伪装浏览器，避免被
       = {
           
                     
           
             
           
           =
           
           {_}
              _=_
           组装认证信息，解决错误 
              __
      }

       代理
       = {
           
           
      }

      
       =  = = =
             == 
               ，，
        
           
       
至此我们已经获取到了平台的结果数据。同样获取到了网易和百度的数据信息。
数据存储实战
到这里我们就需要将获取到的数据进行保存了。本次才用保存。
这里介绍两个操作库：
：读取

_ 读取文件，返回对象
__ 根据工作下标读取，返回对象
___ 根据工作名字读取，返回对象
 工作行数
_ _= _=返回行数据

：写

=’’ 创建一个表格对象，指定编码方式，建议用户开启。
__ 添加一个
  =”” 向写入数据
_    =”” 向合并单元格并写入数据前四个参数控制区块：起始行 结束行 起始列 结束列


避免给同一个单元格重复写内容

基于此我们就可以将获取到的数据进行保存了。
表格操作代码：
   ___ = _=
      
      根据名称获取表格中的数据
        文件
       _ 默认从中取数据 
       返回表格数据也可按照表格定义对象进行列于对象进行映射
      
       打开表格
       = _
       获取工作
       = ___
       获取工作行数
       =    行数
       = 
       遍历每行数据进行读取
          
           = _
           
              _ = 
              _
       返回结果
       

   _
      
      创建表格
      
      _ = =

   _  ={} =
      
      写入数据到中
        工作
       待写入的数据
        开始行数
      
      
      _ = 
        == 
          _    查找歌曲名
          _    百度
            歌曲名
            歌手
            专辑
          _    网易
            歌曲名
            歌手
            专辑
          _    
            歌曲名
            歌手
            专辑
      
          _ = _ {}
          _ = _ {}
          _ = _ {}

           _  
               = 
                 __
                    _
                    
                    
                   = 
               _  
                  _ = 
           _  
               = 
                 _
                    _
                    
                    
                   = 
               _  
                  _ = 
           _  
               = 
                 _
                    _
                    
                    
                   = 
               _  
                  _ = 
主程序：
   
       数据写入开始行
      _ = 
       数据写入结束行
      _ = 
       读取待搜歌歌曲名
       = ___=_ =
       创建搜索结果
       = _
       添加工作 名为         
      _ = _
       写入表格标题栏
      __ =

       遍历待搜索歌曲名。并存储搜索结果。    
         
          _ = __
          _ = __
          _ = __

          _ = {
              _ _  _  {}
              _ _  _  {}
              _ _  _  {}
          }

           写入单个单元格
          _ = __ =_ =_

           _ = _
               合并写入单元格
              ___ _   
              _ = _  
  结果

本文采用根据完成功能进行的学习，并逐步完善代码，本文记叙了我完成这个项目的过程，目前只关注功能的实现，对于工具原理并未涉及过多。在本次爬虫编写中，主要遇到的问题是在网易云音乐加密解析的理解和破解能力。在上文贴出的代码可能有运行不成功的可能，这是从项目提取出来的相关代码。 如有错误请多多指教！
涉及的环境和工具：
 ：开发环境：包管理工具： 包管理工具库：内置的请求库库：封装后的库，使用更加方便 库：提供一些简单的、式的函数用来处理导航、搜索、修改分析树等功能。库：可以模拟真实浏览器，自动化测试工具，支持多种浏览器，爬虫中主要用来解决渲染问题。浏览器：是一个基于的 。它使用作为它核心浏览器的功能，使用来编译解释执行代码。驱动：是 开发维护的，它是实现有线协议的一个单独的服务。通过的自动代理框架控制浏览器。库：读取工具库：写入工具   完前言
我们知道是基于消息循环的系统，我们通过向包含的投递 不过我们常见的用法是这样吧？
   {

       {  } 
}
一般我们比较少接触 其实它内部的接口有很多有趣的用法，首先看看它的定义

                
         
     
        {
        
                      
                      
                       
                     
             
         
         
    }
简而言之，就是在里面的暂时处理完了，这个时候会回调这个接口，返回，那么就会移除它，返回就会在下次处理完了的时候继续回调，让我们看看它有哪些有趣的用法吧
提供一个没有的声明周期回调时机
如果有这种需求，想要在某个绘制完成去做一些事情，那这个时机是什么时候呢？有同学可能觉得是一个合适的机会，不是可是这个 真的是各种绘制都已经完成才回调的吗？    

你看谷老师说了，是用户可见，是用户可交互，谷老师可没说是绘制完成吧那么那些耗时的  是在什么时候执行的呢？它们跟又有何关系呢？让我们先来看看源码吧
 
我们知道的进程其实是 那么的生命周期自然是它来执行了，
   
      {
省略部分代码

 的
  =  

省略部分代码
  = 

  = 
  = 
 = 
 = __
 |= 
  {
 = 
这里就是关键代码了
 
就是回调了， 我们继续看方法， 这个是一个接口，其实现者是


            {
        
           
    }
这个是对象，我们继续

      
      {
 我们跳过不相关代码 
   =    
   
   
  
   
 { 
     
}   { 省略 } } }
这里我们 出了对象， 我们知道这个对象就是 的根对象了，负责绘制的  的巨长的方法 就是这个类的，我们继续看方法

         {
省略部分

                

省略部分
                     {
                     
                                          
                     
                                         
                     
                                          
                     
                        
                     
                                        
                     
                                        
                     
                                         
                     
                     
                                           
                    
                                    
                    }

    }
这个函数调用了关键方法  我们继续跟踪，顺便说下，后面一连串的就是我们常常遇到的相关抛出的，也有些特殊场景也会出这个异常，可以到这里查看线索
   {
         {
            
             = 
            
        }

    }
调用了， 从名字就能看出来了吧
  {
         {
             = 
             = 
              
            
        }

    }
它往里面了一个， 这个是负责帧率刷新相关的东西，我们暂时可以不关注它，可以理解为往主线程一个消息是一样的，顺便说下这个可以做帧率检测相关的东西，，可以用于卡顿检测什么的。。。
     {
         {
        }

           {
            
        }
    }
  {
         {
             = 
            
             {
                
            }

             

             {
                
            }  {
                
            }

             {
                
                 = 
            }
        }

    }
我们看这个果然是去执行了那个巨长无比的函数函数  现在我们可以总结下流程了

结论：所以如果我们想在界面绘制出来后做点什么，那么在里面显然是不合适的，它先于等流程了， 有人可能会说在里面一个可以吗？还是不行，因为那样就会变成这个样子

所以你的行为一样会在绘制之前执行，这个时候我们的主角就发挥作用了，我们前面说了，它是在里面暂时执行完毕了就会回调，顾名思义嘛，就是队列为空的意思，那么我们的和  都是一个个的话，这个就提供了一个它们都执行完毕的回调了，大概就是这样

说了这么多，那么现在获取到这个时机有什么用呢？ 

这个是我们地图的公交详情页面， 进入之后产品要求左边的页卡需要展示，可以看到左边的页卡是一个非常复杂的布局，那么进入之后的效果可以明显看到头部的展示信息是先显示空白再毫秒左右之后才展示出来的，原因就是这个页卡的内容比较复杂，用数据向它填充的时候花了较长时间，代码如下
  = 
        
        省略部分不相关代码
        
               

可以看到这个就是这个侧滑的页卡了，填充里面的数据花了，如果这个时间是用在了界面绘制之前的话，就会出现以上的效果了，先是白的，再出现，这样就体验不好了，如果我们把它放到里面呢？代码如下
  {
            
               {
                  = 
                
                省略部分不相关代码
                
                       
                 
            }
        }
效果是这样的

看出不同了吗？顶部的页卡先展示出来了，这样体验是不是会更好一些呢。虽然只有短短，不过我们做也应该关注这种细节优化的，是吧 这个做法也提供了一种思路，本身提供的框架和框架并没有提供绘制完成的回调，如果我们自己实现一个框架，就可以使用这个来实现一个这种回调了。
可以结合 用于单线程消息通知器
我们先思考一个问题，如果有一个数据管理模块，怎么设计？比如地图的收藏模块的部分。就是下面这个图的小星星

它原来的设计大概是这个样子的
   {
        =  

        {
         
    }

      {
    }

    收藏点数据
       =  

    同步锁
      

    添加收藏点
        {
         {
            
        }
    }

    删除一个收藏点
        {
         {
            
        }
    }

    获取当前收藏列表
       {
         
    }

    同步服务器收藏数据
       {
         {
            
        }
    }
}
由于这个是单例的，而且是多线程可以访问的，所以它的增删改查都加上了锁，而且由于外部访问需要遍历有哪些收藏点，所以外部遍历列表也需要加锁，大概是这样的
   {
         {
                 {
                
            }
        }
    }
因为是多线程可访问的，如果遍历不加锁的话，其他线程删除了一个收藏，就会的，原来的这样设计有几个不好的地方
外部使用者需要关系锁的使用，增加了负担，不用还不安全
如果在主线程加锁的话，可能另一个线程执行操作会阻塞主线程造成
总之，多线程代码就是容易出错，而且真的出错的时候查起来太费劲了，目前收藏夹模块就有多，所以我想用单线程来解决这个问题，由于层的访问需要数据库和网络等，所以需要异步线程，那么单线程队列异步线程，首先想到的就是 大概架构如下

现在，我们把原来多线程的逻辑改到了单线程里面，各种收藏的共用一个，这样我们增删改查都不用加锁了，出错几率大大减小，而且这种的设计有点类似插件的意思，可以很方便的增加其他收藏
， 那么跟我们的主题有什么关系呢？思考这样一个问题，地图上的小星星需要实时更新，也就是的任何变化都需要显示到地图上，那么收藏的小星星就应该作为的观察者，以前的做法是向收藏注册监听，在每一个增删改查操作后都对观察者回调，大概是这样
添加收藏点
        {
         {
            
            
        }
    }

    删除一个收藏点
        {
         {
            
            
        }
    }
这样有一个小小的问题，就是如果有一个操作生成个快速连续的增删改查操作，那么我们的就会收到次回调，而这种场景下我们其实只需要最后一次回调就够了，中间操作其实不用刷新的
那么现在改成单线程模型，我们又该如何处理这个问题呢？当然我们也能在每个到异步线程的里面去回调观察者，但这样未免不够优雅，所以这个时候不就又可以发挥作用了吗？它是在消息暂时处理完的时候回调的呀，不是很符合我们的时机么，对吧
  {
          ==  {
             =  
            
        }
         =  

         {
              = 
            
              =  
              {
                
                   {
                      = {
                             {
                             
                        }
                    }
                     
                }
            }
        }    {
            
        }
    }
 就是这个样子了，这里为什么不用第一个场景下的呢？注意这个地方如果在主线程调用就会使用主线程了，所以我选择反射这个的来设置它，这个我们返回了 表示我们要长期监听消息队列，因为返回，下次就没有回调了哦。
好了，结论是这个地方用作了一个消息的触发器，是不是挺有意思的呢？
结语
如果你没有用过它，从今天开始试试吧，这篇文章只是我个人的一点小思路，说不定这个有很多其他的用法呢如果喜欢的话请点个赞哟，有任何不正确的地方也请随时指出
    悉尼时间年月日， 奖项在悉尼峰会  上正式揭晓，腾讯云团队成为入围四家公司中的最后赢家。
此次获奖团队由产品设计、技术架构、产品开发、运营保障等个团队组成，将基于开发专有云平台，为中国政府企业提供完整的混合云服务。同时，腾讯公司宣布加入基金会，成为其黄金会员，全力支持开放源代码云计算平台的开发。
▲腾讯云团队上台领奖
基金会是一家旨在推动云操作系统在全球发展、传播的非盈利组织，成立于年。该基金会目标是在全球范围内服务开发者、用户及整个生态系统，为其提供共享资源，以扩大公有云和专有云的成长，从而帮助技术厂商选择平台，助力开发者开发出行业最佳的云软件。
在加入基金会之前，腾讯已成为最大的用户之一。腾讯专有云已经运行了个集群，共计个节点，稳定运行时间超过年，可用率超过。
对于此次加入基金会，腾讯云首席架构师 表示：腾讯致力于进军云计算市场，旨在建设完善的混合云生态系统，服务全球市场，是该战略中重要的一部分。我们希望和共同成长，对社区做出贡献。
作为腾讯“互联网”战略的重要平台和技术开放总出口，腾讯云已将平台以及运营服务经验推广到中国政企市场，并与全国多个省、多个城市签署合作协议，为包括四川省政务云、广东省政务云、云南公安厅警务云等在内的各级政府和企业构建基于的云平台。
在今年月于厦门举行的金砖国家会议上，腾讯云部署了基于构建的政务云，并与腾讯云安全团队共同为会晤期间的云上安全保驾护航，获得厦门政府的热情点赞。下一阶段双方还将在公安、医保、环保、财政等领域展开深度合作。
未来，腾讯云期望与企业用户探讨，与优秀产品合作，与业界同行，在飞速发展的云计算浪潮中能够把握住时代的命脉，并将互联网海量实践经验不断分享到开源社区，为社区云生态建设添砖加瓦。前言
文本分类应该是自然语言处理中最普遍的一个应用，例如文章自动分类、邮件自动分类、垃圾邮件识别、用户情感分类等等，在生活中有很多例子，这篇文章主要从传统和深度学习两块来解释下我们如何做一个文本分类器。
文本分类方法
传统的文本方法的主要流程是人工设计一些特征，从原始文档中提取特征，然后指定分类器如、，训练模型对文章进行分类，比较经典的特征提取方法如频次法、、互信息方法、。
深度学习火了之后，也有很多人开始使用一些经典的模型如、这类方法来做特征的提取， 这篇文章会比较粗地描述下，在文本分类的一些实验。
传统文本分类方法
这里主要描述两种特征提取方法：频次法、、互信息、。

频次法频次法，顾名思义，十分简单，记录每篇文章的次数分布，然后将分布输入机器学习模型，训练一个合适的分类模型，对这类数据进行分类，需要指出的时，在统计次数分布时，可合理提出假设，频次比较小的词对文章分类的影响比较小，因此我们可合理地假设阈值，滤除频次小于阈值的词，减少特征空间维度。

相对于频次法，有更进一步的考量，词出现的次数能从一定程度反应文章的特点，即，而，增加了所谓的反文档频率，如果一个词在某个类别上出现的次数多，而在全部文本上出现的次数相对比较少，我们认为这个词有更强大的文档区分能力，就是综合考虑了频次和反文档频率两个因素。

互信息方法互信息方法也是一种基于统计的方法，计算文档中出现词和文档类别的相关程度，即互信息

基于的方法是把文章序列，通过大小为的窗口，形成一个个，然后对这些做统计，滤除出现频次较低的，把这些组成特征空间，传入分类器，进行分类。


深度学习方法
基于的文本分类方法

最普通的基于的方法就是上的做情感分析，接，指定大小的 来遍历文章，加上一个，如此多接入几个，得到特征表示，然后加上，进行最终的分类输出。

基于的文本分类方法，最出名的应该是 的      ﬁ，使用不同的网络，然后加入， 然后到一起。



这类的方法，通过设计不同的 来建模不同尺度的关系，但是很明显，丢失了大部分的上下文关系，      将每一个词形成向量化表示时，加上上文和下文的信息，每一个词的表示如下：

整个结构框架如下：

如针对这句话”             ”，的表示包括___ _编码 的语义，而_编码          的信息，每一个词都如此处理，因此会避免普通方法的上下文缺失的信息。
基于的方法

和基于的方法中第一种类似，直接暴力地在之后加入，然后输出到一个进行分类，基于的方法，我觉得这也是一种特征提取方式，可能比较偏向建模时序的特征；
在暴力的方法之上，      ，将输出不直接接入，而是接入到，通过得到一些序列，然后吧这些序列再接入到，文章说这么做会提高最后分类的准去率。

代码实践
语料及任务介绍
训练的语料来自于大概个新闻类别的新闻语料，但是其中有一些新闻数目比较少，所以取了数量比较多的前个新闻类比的新闻语料，每篇新闻稿字数从几百到几千不等，任务就是训练合适的分类器然后将新闻分为不同类别


对语料处理，得到 ：
 ____
          
    
     = __ 
     _   
         = 
          
           
            
                _ = \
                 = _
                
                 = _
                _ = __
                 _
                __
                \\\_\
                =
               
                 = _
                 
                 ===== ======
                
    _ = ____
         _
    _ = 
    
然后，  以频率阈值进行滤除，然后对每篇文章做处理来进行向量化：
 ___ _=
    __ =          _ 
    ___
    

 
           
    
    ____
          {}____
    ___
          {}____
     = 
     _  
        _ = _
        _
           
    __ = __ 
    __
    __
    __ = __ 
    __
    __
最终就得到每篇文章的的向量，由于这块的代码是在我的笔记本上运行的，直接跑占用内存太大，因为每一篇文章在 中的表示是极其稀疏的，因此我们可以选择将其转为表示，然后进行模型训练，转为并保存中间结果代码如下：
 _
     = __ 
     = __ 
     = 
     = 
     = 
    _ = 
       
           
            _
            
            
        _ = 
       {}{}_ ____
    __ = _ =_ ____
     _   
     __
     ==_
    _ _ _ _ = ____  _=
        
     _
    __ = ___ 
    ___
    __ = ___ 
    ___
    __ = ___ 
    ___
    __ = ___ 
    ___
最后训练模型代码如下：
 
         
    _ = 
    __ _
             
        {}__ _
    _ = __
     __ _
     __ _
          _
    _ ___ 

和的操作十分类似，只是在向量化使使用的方法：

 
           
    
    ____
          {}____
     = _=
     = 
      
     = __
     = __
       {}
      
       {}{} 

           
    __ = __ 
    __
    __
    __ = __ 
    __
    __
这两类方法效果都不错，都能达到的准确率。

语料处理的方法和传统的差不多，分词之后，使用 的，这里我遇到一个坑，我开始对我的分词太自信了，最后模型一直不能收敛，后来向我们组博士请教，极有可能是由于分词的词序列中很多在 里面是不存在的，而我这部分直接丢弃了，所有可能存在问题，分词添加了词典，然后，对于 不存在的词做了一个随机初始化，然后就能收敛了，学习了！！！
载入模型和构建网络代码如下增加了一些和的手段：
 __ =
     __    
    
     
        _____
    
        ____
          {}
        ____
    ___
          {}
        ____
     = 
     _  
        _ =      _
         _
        _

    _ = 
    _ = _ _
       {}
        
        _ = 
         _   
            _ = _
        
            _ = _  
     _  {}_

 ___
    _ = 
        _
        _
        =_
        _=__
        =
           
    _ = =__  =
    _ = __
     =  _
     = 
     = 
     = 
     =  
     = 
     = 
     = 
       _
     =  
     = 
     = 
     = 
     = 

     = 
     = 
     = 
     = 
     _
     = _ =
     _
     = =
     = _ 
    
        =_ = =
另外一种网络结构，韩国人那篇文章，网络构造如下：
 ___
    _ = 
        _
        _
        =_
        _=__
        =
           
    _ = =__  =
    _ = __
    _ = 
       _
         = 
            _
            
            =
            =
            =_
         = 
         = 
        _
     = 
        _
        =  _    _
     = 
     = _ =
     = _ =
     = =
     = _ 
    
        =_
        =
        =

由于我这边的是对文章进行分类，序列太长，直接接后直接爆内存，所以我在文章序列直接，接了两层来提取维度较低的向量表示然后接入，网络结构代码如下：
 ___
    _ = 
        _
        _
        =_
        _=__
        =
           
    _ = =__  =
    _ = __
     = 
        _  =_
     = 
     = _  =
     = 
     =  _= _=
     = _ =
     _
     = =
     = _ 
    
        =_
        =
        =
 结果：

 结果：

整个实验的结果由于深度学习这部分都是在公司资源上跑的，没有真正意义上地去做一些来调参来提高性能，这里所有的代码的网络配置包括参数都仅做参考，更深地工作需要耗费更多的时间来做参数的优化。
 这里发现了一个 的， 在写回调函数，当_=时，显卡占用明显增多，的不够用，个人感觉应该是一个，但是考虑到而非，可能后面都优化了。
所有的代码都在上_
总结和展望
在本文的实验效果中，虽然基于深度学习的方法和传统方法相比没有什么优势，可能原因有几个方面：

  并没有覆盖新闻中切分出来的词，而且比例还挺高，如果能用网络新闻语料训练出一个比较精准的 ，效果应该会有很大的提升；
可以增加模型训练收敛的以及优化器，看看是否有准确率的提升；
网络模型参数到现在为止，没有做过深的优化。作者介绍：胡彬 腾讯云高级工程师

 的前身是  ，是一款开源的  系统，使用  开发，数据库采用  ，系统以  协议发布。
 作为一款开源软件，功能却非常完善，涵盖了账户、、销售、支付、仓储、项目管理、网站建设等等模块，并且还支持开发自定义模块。
本文主要介绍如何在腾讯云的环境下，通过简单的步骤，快速搭建一个  的站点。
准备工作

云校园认证通过

扫码获取元通用代金券

检查电脑上面是否有程序


实验架构
 
任务一：创建一台云主机并登录
任务目标： 购买并创建一台云主机，设置云主机管理员密码，通过客户端成功登陆云主机。
购买并创建云主机
 
 
 
 
登录云主机
、下载并安装客户端软件
从本地机器登录到云服务器时，需要使用客户端软件建立连接。建议使用发布的工具进行登录。在本地机器上下载并安装客户端下载地址。
、登录到服务器
操作示例如下：
 
步骤详细描述如下：
    使用命令行连接云服务器：
   云服务器登录账号   云服务器的公网
命令行各参数说明：
云服务器登录账号：输入管理员账号详见管理员账号管理
云服务器的公网：在云服务器“管理视图”页面可查看云服务器的公网
注意：系统的默认管理员账号为。
     回车后，如果控制台询问是否继续链接“      
”，输入”“。
     在后输入密码，密码为管理员账号的密码，回车后即完成登录。
注：管理员账号的初始密码在上面购买过程中设置过，用户也可以重置密码，详见管理员账号密码重置。同时，用于登陆的公网可以在管理界面查询如下图所示。
 
     当你输入密码，看到如下所示界面，恭喜你，成功登录云主机。
 
任务二：购买一个数据库实例，并初始化
任务目标：成功创建一个云数据库实例，初始化其密码，验证从云服务器是否可以正常的连接数据库
创建数据库实例
数据库云数据库
目前属于内测阶段，如果没有购买入口，可在腾讯云官网页面点击申请内测资格，审批通过后，访问 链接 创建实例

初始化数据库

服务器端安装客户端
   
验证数据库是否正常连通
首先查看数据库的内网：
 
 上图的内网  –初始化时指定的用户名  –
输入初始化时指定的密码，登录成功的界面如下：
 
输入：\退出数据库登录
任务三：安装并配置
任务目标：安装组件，完成系统和数据库相关配置，启动服务
安装组件
 =
   
注意，本文以 系统为例，对于其它系统，详细的安装指引可以参考官方文档。
修改配置文件
 
配置文件内容如下：

        
_ = 
__ = 
_ = 
_ = 申请的实例的内网
_ = 
_ = 初始化时设置的用户名
_ = 初始化时设置的密码
_ = 
_ = 
_ = 
_ = 
_ = 
 = 
 = 
 = 
_ = 
 = 
创建运行环境需要的目录
 
 
   
启动
   
任务四：初始化配置
任务目标：通过浏览器访问，初始化管理数据库，进入主页面
访问：云主机外网，输入相关参数，完成初始化数据库的工作。此过程耗时较长，请耐心等待。同时可以通过查看文件浏览系统日志
初始化结束，页面会自动跳转到应用页面，如下：
 
这样一个基本的框架就搭建完成。
参考： 文档 

相关推荐 技术理解微信支付商户系统架构背后的故事云服务器作者：

年一月以来，自己接触前端开发已经两年多了，记录一下自己前端学习路上看过的，以及道听途说的一些书，基本上按照由浅入深来介绍。

入门
《权威指南第六版》 ★★★★★

淘宝前端团队翻译的，看译者列表都是一堆大神。这本书又叫犀牛书，号称开发者的圣经，网上对此书评价很多，大概意思都是说这本书是一本文档手册，没有完整看过一遍此书的都不能算是一名合格的前端工程师。
我也是从这本书开始接触前端开发的，当时还是华章出版社的校园大使，免费申请到了这本书，可惜的是两年来我一直把它作为一本来查阅，一直没有好好通读一遍。个人感觉这本书还是写得枯燥了些，不过内容绝对是五颗星，无可挑剔！
《高级程序设计》 ★★★★★

又称红宝书，雅虎首席前端架构师，的作者出品。虽然书名带了“高级”二字，但是讲得也很基础，而且行文风格很流畅，每一小节就像是一篇博客，读起来并不枯燥，个人感觉比上面那本犀牛书可读性更强。说到这里，也推荐大家多多关注作者的博客：  ，上面也有许多高质量的博文。感觉这本书就像是作者平时的博文按照前端知识体系组织成了一本技术书。
《 编程艺术》 

作为初学者如果觉得上面两本书作为入门书来说太厚了，也可以看看这本，不厚，评价也很高，但是由于本人没看过，就不作过多评价了。
《编程精解》 ★★★★

用上下班时间看完的第三本书。看起来比较吃力，第五章函数式编程和第六章的面向对象编程很多都没看懂。全书游戏式的编程教程还是很有意思的。译者大叔名头很大，翻译的质量也只是中规中矩吧。不过，还是到很多技巧！这本书的推荐语说这本书用来入门很好，但是个人认为初学者并不合适看这本书入门，作者在代码示例中不自觉得使用了一些高级用法，初学者看容易晕菜。听说最近出了第二版，加入了的内容，这本书是开源的：
《权威指南》 ★★★

当时在北京实习时，在每天下班回家的地铁上把这本书看完了。错误很多啊，不过其中的语法示例的形式，确实很适合初学者。但是错误实在太多了，而且有些语句还不通顺，看着很累啊，只能说写得好代码的人，书不一定写得好。
《入门》 ★★★★

前端工程师当然要关注的发展。阮老师的这本科普小书！短小精悍，通俗易懂。这本书也是开源的：
进阶
《编写可维护的》 ★★★★

又一本的书，还没读完，基本上是那本红宝书的子集，重点是代码风格、规范以及最佳实践。
《异步编程》 ★★★★

掌握异步编程，显然是一位开发者必备的技能，用多看的畅读优惠看完了这本介绍异步编程的科普小书，书中介绍了异步编程的概念、场景和工具，不过更重要的是把这些工具给用起来。
《设计模式》 ★★★

作者似乎很偏爱的源码，不过这本书大叔翻译的很烂，代码也很多没有缩进。。。 不推荐。
《 》 ★★★★

这本书我当时看到最后一章“并发”的部分就很吃力了，显然这是一本进阶的书籍，还是先把那本权威指南啃完吧！听说这本书上的技巧对于有很好的优化效果，不过显然书上提到的这些技巧肯定已经大量的运用到、这样流行的库中，这些第三方库已经帮我们把这些优化细节封装得很好了。
《语言精髓与编程实践》

一本讲的硬书，以这门语言为栗子，讲述编程语言的特性动态语言、函数式编程、面向对象编程等等。作者周爱民老师是前支付宝架构师，现豌豆荚架构师。
《高性能》

大神的又一本神书，高工推荐的。
最近开始看《   》了，看了个开头，感觉也很不错！

入门
《  与、中文版》

进阶
《权威指南第三版》

虽然是一本老书，但是 是基础
《精通第版》

好吧！以上三本书，我都没看过。。。
网络协议  架构
《权威指南》 ★★★★★

涉及开发的前端、后台、运维的同学都可以看看。应用架构师必看。其中对其中“缓存”、“负载均衡“等章节印象很深，标准的教科书啊，肯定比看枯燥的规范好多了。
《性能权威指南》

工程师教你优化性能，刚看了个开头，高工推荐，听说讲得比较深。
《大型网站技术架构》 ★★★★

网站架构入门科普。刚刚看完，写得挺好的，通俗易懂。开篇明义：“大型网站是演化出来的，而不是设计出来的。”，书中阐述了缓存为王，分层，解耦，模块化等网站架构中应该遵循的原则。其中负载均衡那一节，基本上是参考的《权威指南》负载均衡的内容。总结来说，纵向和横向分层以及可线性伸缩的能力是大型网站面对复杂业务和海量访问的制胜法宝！

入门
《了不起的》 ★★★

作为入门挺好的一本书，可惜讲得太浅了，基本上就是介绍开发一个简单的应用所要用到的一些技术和工具，对里面的原理以及本身没有做太多的介绍，停留在介绍第三方库及其的阶段。
《开发指南》

读了一半，就是看这本书理解了的事件循环。作者是大神啊。
进阶
《深入浅出》

很出名的一本书，对的一些原理做了深入介绍，挺不错的，还没看完。
用户体验  产品
《点石成金》 ★★★★

恰好读过第二版和第三版，第三版中添加了 的内容，并且更新和添加了一些新例子，总得来说，我更喜欢第二版的精简。曾经推荐过的好书。
《结网改变世界的互联网产品经理》 ★★★★

这本书读了挺久。用产品开发过程中的实际案例介绍了产品经理的工作内容以及如何开展工作。并从创建产品和个人修炼两个方面描述了需求分析，产品设计，项目管理，产品运营，产品经理的沟通能力以及个人和团队的创新能力等等，附录的推荐书目和工具质量也很高！作者是前腾讯产品经理，糗事百科的创始人，不过好像在知乎上因为创始人股权纠纷的问题，被黑臭了。。。
《参与感》 ★★

 很出名的一本书，但其实营销部分讲得一般，老生常谈，不如我的朋友何老湿讲的好啊，不过可能对传统企业转型互联网有一定参考价值。设计那一块说的还挺有意思的，不过肯定还是不如我的另外两位设计师朋友开花和佐叔咯。哈哈！
《创京东》 ★★★

一本骗钱的书。看完之后的感受是，京东的核心部门是采销，仓储和物流，排名分先后。

原文链接：


相关推荐打造前端工程测试体系与前端性能从入门到精通，轻松上手云计算腾讯云已在近期上线了  网关产品，协助开发者通过简单方式即可完成  配置管理、发布版本、访问控制等功能，并可进一步对接腾讯云云市场中的  市场，参与到  经济的大潮中。

 网关通常是在用户自身系统期望对内部或外部提供  时使用。除了提供应用程序访问入口外， 网关还实现了对接入客户端的认证，防止重入和篡改攻击，后端业务隐藏和鉴权，请求和响应的数据映射及修改，流量控制和并发控制。而如果  网关的使用客户，如果有将  提供给第三者的需求，一定程度上还会依赖  网关提供计量和计费能力。
适用多种场景，提供更多安全与便利
 网关虽然常常是伴随着微服务架构的使用而出现，但其作用可以不局限于微服务架构的应用程序上。除了为   提供入口外，针对移动 ，后端服务可以通过  网关进行暴露，同时  网关还一定程度上可以承担移动设备管理能力；传统遗留系统，也可以通过  网关封装，实现旧系统的服务化改造；同时，利用  网关，打通企业内外部系统，打通各合作伙伴系统，可以实现业务系统的更大价值；而针对  场景，在物联网设备  化的情况下，通过  网关，不仅要能解决设备数据上行的问题，还要能解决数据下行的问题。
 网关除了封装 ，管理  外，同时也可为  使用者提供更多便利。针对一组 ，通常包括了  提供者和  使用者两种角色，且在很多情况下，两种角色是互相交叉的，例如   的提供者，有可能就是   的使用者。在这样的情况下， 网关需要做到对两种角色都提供他们所需要的能力。针对  提供者， 网关要能提供  配置、发布、流控、认证、甚至计量、计费能力；而针对  使用者，则要提供  调试，帮助文档，多语言 ，代码示例等能力，以便更方便更容易的使用 。
无论  的提供者还是使用者，对  网关都还有统一的需求，例如网关的安全性，性能，可用性，扩展性，运维能力，的全生命周期的管理能力等等。腾讯云的  网关，集合腾讯多年的底层  建设和管理能力，在安全性上，依托云已有的攻击防护能力，保证用户所托管  的可靠和安全；在性能上，利用腾讯的高性能网关能力，和多地域多可用区的集群，可支撑高并发大流量的请求，同时多地域和多可用区的集群，能够保证不会由于单台设备或单个集群的故障而导致服务不可用，保障用户  服务的可用性；同时，腾讯云对  网关产品也将会不断迭代，根据用户需求持续扩展功能，后续会增加例如多种认证方式、 服务可用性监控、更细粒度更多层次流控、扩充更多语言和框架的 支持等等功能或能力，全方面去满足客户需求；而针对用户  提供的配置、调试、上线、更新、升级、版本切换、下线等完整生命周期管理，和  运维过程中的请求日志、运行监控、错误告警等能力，在目前已经提供的情况下，腾讯云会持续优化和迭代，提升用户体验，便于用户使用。同时，除了对协议的支持外， 网关也开始了对  的探索，会尽早完成支持以便客户可以更方便的与客户端进行交互。
经济，互联网的新变革
随着互联网和云计算的发展， 做为系统和系统间交互信息的桥梁，已经在用户和用户、用户和企业、企业和企业之间，发挥着越来越大的作用。而 ，不仅仅是互联网企业可以提供，银行、政府、企业、个人，都可以提供 ，也可以使用 ， 在整个大的环境中，已经是成为了一种服务。提供数据、提供计算能力、提供存储能力，均可以使用  来进行，从公共的天气数据查询、车辆品牌查询，到私有的个人帐号认证、私密照片存储，均可以通过  完成。通过在信息化、网络化时代的发展， 已经产生了一种新的经济现象，即  经济。 经济是基于  所产生的经济活动的总和，在当今发展阶段主要包括  业务，以及通过  进行的业务功能、性能等方面的商业交易。 经济是当今各行业零售、金融、物联网、医疗等中驱动数字变革的主要力量。

在腾讯云， 网关为企业提供了更加便捷的加入  经济的方法。通过  网关，用户可以将已经完成配置的  一键发布至腾讯云云市场，将自身  提供给外部用户所使用，并通过市场售卖，在  被使用的过程中赚取合理收益。在这个过程中，企业将自身的数据、计算能力等通过  进行了供应，同时，企业也同样能从  市场中去寻找自身所欠缺的能力，并通过付费购买后，将能力集成和结合到自身的业务中，进一步扩充自身业务。
打通多种服务，行成完整方案
除了通过  网关对  进行管理外，与其他各产品结合，形成更加完整的解决方案，也是腾讯云在不断推进的方向。包括容器，企业中间件，服务总线，甚至到架构， 网关产品都将会不断的探索和结合，提供给用户更加简单的与自身系统、开发流程和，特别是目前热门的架构，无服务器云函数作为腾讯云提供的函数即服务类型产品，和  网关结合后，能通过  提供函数调用能力，实现无服务器的后端服务，因此， 网关也是腾讯云无服务器应用架构中的一款重要产品。
腾讯云  网关已经上线并开发内测，欢迎大家申请试用：商业转载请联系腾讯获得授权，非商业转载请注明出处。
原文链接：


一、项目背景
月，拥有著名游戏，击中玩家“情怀”痛点的手游《魂斗罗：归来》启动不删档测试，上线后不久就杀进国内各家应用分发平台畅销榜前三甲，良好势头一直保持至今。
《魂斗罗：归来》的游戏品质、著名、以及腾讯游戏所处的平台的优势等等各方面因素，给魂斗罗带来海量的游戏玩家。海量玩家也意味着海量挑战，适配兼容就是其中一个难题。《魂斗罗：归来》从项目初期研发测试期间，就开始非常关注适配兼容的问题，尽量每个外发迭代版本都交付可测版本给到适配测试团队，进行系统的机型适配及兼容性测试。
二、面临挑战
《魂斗罗：归来》测试过程需要针对游戏大量的内容进行个性化定制，而面对游戏上线后玩家的大覆盖率，项目组也面临着低配机型的兼容性考验。
三、结果
《魂斗罗：归来》游戏共提交轮次适配测试，共发现并解决个有效适配兼容问题。在每个迭代版本对外发布前，尽可能测试覆盖中的绝大部分玩家机型，以此为玩家的适配兼容体验奠定了比较好的基础。
四、实战方案
案例一
游戏对【三星 】机型不兼容，基本上游戏界面展示都异常
出现原因：《魂斗罗：归来》月初不删档发布时，三星 机型新上市，且是较为特殊的大分辨率版本，游戏在发布前，未对该分辨率的机型进行过任何适配工作。
解决方案：紧急协调测试机型进行资源适配，与适配测试团队确认，也已经及时采购相应的设备以满足后续适配需求。
案例二
【魅族】以及【魅蓝】机型登录到游戏大厅主界面，会出现屏幕不停旋转，无法游戏
出现原因：魅族这两个机型对陀螺仪的支持存在缺陷，而游戏大厅主界面开启了陀螺仪。适配测试过程中发现了这个问题，问题修复后，降低了问题出现的概率，但仍有不少玩家被困扰在这个问题中。
解决方案：由于机型比较老，项目组未有相应的机型进行问题定位，最终使用了云真机，通过远程调试功能复现了问题并定位了问题原因。游戏后续通过更新补丁方式屏蔽了问题机型的陀螺仪功能，魅族官网也会发固件修复机型缺陷。
案例三
启动游戏后，点击华为手机的虚拟的向下按钮，会出现游戏停止在黑屏。
出现原因：启动游戏时播放启动动画，同时华为手机又触发了隐藏导航栏的操作，这时视频就会被跳过并且停止在黑屏，需要点击导航栏的返回按钮才能解锁黑屏。适配过程中发现该问题，因该问题出现需要在特殊的时机触发虚拟按钮，在平时的测试中，有虚拟按钮的手机较少，对启动场景都是在引导视频动画时跳过。
解决方案：根据适配测试时录制的视频，使用有虚拟按钮的手机，开发定位到原因，减少了启动动画与引导动画的衔接时间，降低了问题出现的概率。
在进行兼容测试过程中，测试人员发现适配问题机型后，可以在云端立刻找到对应的手机，告知开发进行调试。调试过程中，实时日志信息、性能数据一目了然，精准定位问题。

用户说
“提供的移动端游戏测试一站式解决方案在适配 性能等专项方面给了项目组很大的帮助 及时发现并帮助定位问题所在 为保障产品基础体验质量 打好了坚实的基础。”
                                                                                ——胡波

                                                                          《魂斗罗：归来》客户端主程序

除了兼容性测试，腾讯还帮助腾讯游戏提供性能、安全等方面的质量服务，全面保障玩家体验。
目前，腾讯移动兼容性测试团队除了负责腾讯所有游戏的兼容性质量，也通过平台向外部开发者开放了同品质的兼容性测试服务。 欢迎对兼容性测试同样精益求精的同行们来体验服务，共同交流。
点击链接即可使用专家兼容测试服务：
如果对使用当中有任何疑问，欢迎联系腾讯企业：识别数字在机器学习任务中的地位和   在编程中是一样的。
主要步骤：

获得数据：   
建立模型：
定义 ，：，，
定义损失函数，优化器：－， 
训练模型：，
评价：准确率


 获得数据

来自   ：
分为 ，，，每个  代表一个图片， 是它的 
其中图片由  像素组成，转化成  的形式，变成  维
 变为 － 的形式，即属于哪个数字，就在哪个位置上为 ， 其余为 


目标：给了  后，预测它的  是属于 ～ 类中的哪一类

如果想要看数据属于多类中的哪一类，首先可以想到用  来做。

 建立模型
  有两步：

把  转化为某类的 
把  转化为 

 把  转化为某类的 


某一类的  就是像素强度的加权求和，再加上此类的 。
如果某个  可以作为一个  证明图片不属于此类，则  为负，否则的话  为正。下图中，红色代表负值，蓝色代表正值：


 把  转化为 

简单看， 就是把  先做指数，再做一下归一：


归一的作用：好理解，就是转化成概率的性质
为什么要取指数：在 《常用激活函数比较》写过 
第一个原因是要模拟  的行为，所以要让大的更大。
第二个原因是需要一个可导的函数。



用图形表示为：


上面两步，写成矩阵形式：

模型的代码只有一行： =    

 定义  和 ：


 定义损失函数，优化器：
用  作为损失来衡量模型的误差：

其中， 是预测， ′ 是实际 
按照表面的定义，代码只有一行：
_ = ___   _=
不过因为上面不稳定，所以实际用：
_ = _
      ____=_ =
然后用 ， 且   作为优化器，来训练模型，使得  达到最小：
_ = _

 训练模型
 _  
  _ _ = _
  _ _={ _ _ _}

 评价
看  和  ′ 有多少相等的，转化为准确率。再测试一下  数据集上的准确率，结果可以达到 。
_ =  _
 = __ 
 _={  _ }

这只是最简单的模型，下次看如何提高精度。
完整代码和注释：温馨提示，用打开，代码格式比较好看
    
   
_

 ____  _
 ____  
 ____  _

 
 

   _

   

 = 


 _
    
   = ____ _=

     
   =       
                
                    
   =  
   = 
   =    
                  

      
  _ =   

       
  
     ___  
                                   _=
                   _          
                      _= 
                   _          
  
      
  
       ____   
           

  _ = _
      ____=_ =
  _ = _
                        

   = 
                
  __
                 

   ～～ 
   _  
    _ _ = _
                  
                          
    _ _={ _ _ _}

     
  _ =   _ 
                        
                            
                _    
   = __ 
                       
   _={ 
                                      _ }
                    ， 

 ____ == ____
   = 
  __ = =_
                      =    
    = __
  = =  

学习资料：_前面在过载保护章节中已提及了负载均衡，顾名思义，本节要探究的对象为负载请求。负载均衡除了起到过载预防的作用，本质上是提高了系统的吞吐量，最小化响应时间，到达资源利用最大化。
一、算法与架构
 算法
目前，负载均衡算法不管是在学术研究还是在工程实现上都已比较成熟，算法大体可分以下几种：

随机算法
轮询算法
哈希算法
一致性哈希算法
静态权重调度算法
动态权重、自适应算法

非自适应类算法不要求从服务节点实时获得负载的更新，而自适应算法通常需要负载均衡器能感知节点的负载变化动态调整分发策略，提高负载平衡的效果。也因此，两类算法在实现上架构设计也有较大的差别。
那么节点的负载如何衡量呢   根据不同类型的系统应用，通常会定义不同的度量方式，如：资源、内存资源、当前进程数、吞吐量、成功率、响应时间等指标都可以作为负载度量的指标，各个指标的重要程度根据实际情况有所不同。
 架构
由于这里探讨的是软负载均衡技术，一些基于硬负载均衡的架构设计不做具体涉及。软负载均衡架构大体可以分为：

基于客户端
基于
基于反向代理
基于第三方应用或系统，如：哈雷、、

除了基于客户端方式，其他架构上实际上都是引入一个均衡服务器做控制或代理，或是返回请求的调度结果，亦或是直接对请求做转发。结合的设计理念和架构做思考，负载均衡器其实可以放到主控侧来实现，但是我认为由于负载均衡策略的复杂性，单是对调度决策数据分析已经非常繁重，因此负载均衡通常还是单独引入一个接入层统一接入网关来实现，比如目前在使用的 、哈雷接入、四层、七层、、 等都是此类接入层系统的实现方案。
负载均衡器周期性计算出每个被调机器的权重，再使用高效的配额算法分配各个主调机器的访问路由，主调机器上的业务进程通过来取得这些路由，调用结束时通过来反馈路由的好与坏。
而的实现，我们把重点放在客户端。
二、实现
根据前面对调用的分析可知，客户端会采用选定的负载均衡策略选择一个，对请求进行路由分发。若采用静态策略，显然在客户端做选择更为直接；若是考虑根据负载调整动态权重，和容错一样，客户端直接统计成功率、响应时间等更为精确。
首先根据前面提到的容错策略，初始化服务节点列表如下：
使用不带权重的
  = 
  ==  ||  {
          
}

  =  
     {
      {
        
          屏敝后尝试重新调用    
         
          = 
          ||        {
            
        }
    }  {
        
    }
}
  如果全死，是否需要随机取一个尝试？
  {
              =         
}
目前支持的负载均衡策略有轮询、带权重轮询、、带权重、一致性； 默认使用的策略是轮询，若客户端调用时在请求上下文中对应的有设置对应的参数则优先使用相应的策略，策略选用的优先级为： 一致性    。其中，
 轮询
相当于简单随机化，适用于各个节点无差别的情况。
  省略服务节点列表初始化
   =   _  
  均衡
根据请求上下文的值对服务节点列表大小取模运行，进行路由分发，在系统正常运行情况下，可以保证相同值路由到同一服务节点。
  =    
 一致性均衡
根据一致性算法生成一定空间虚拟节点大小的调用序列哈希环，整个空间按顺时针方式组织，将对应的服务节点根据哈希映射到环上，在发生移除添加操作时，它能尽可能小的改变已存在的值映射关系。构造算法如下：
      
                                                                        {
      =  
         {
         ___  =  {
            
            
        }
         __    
    }

       =   
     {
          = 
          =     

             {
              =   __   
               
                 = 

             =    =       
               =      {
                  =   
                   =      {
                      =  
                     
                }
            }
        }

    }    {
              
         
    }
     
}
 带静态权重策略
上述算法的简单实现都假定每个服务节点都是完全对等的，而实际上每个服务节点的处理能力不尽相同，因此我们可以给每个节点根据处理能力的大小分配对应的权值。权重大的节点处理更多的请求，降低权重小的节点的系统负载。实现上，根据权重序列计算出节点调用序列，权重越大的节点在调用序列中出现的次数越多。生成调用序列算法如下：
     
                                                           {
      =  
         {
         ___  =  {
             
        }
         __    
    }

      {
         
    }

      {
             
    }

      = _
      = _

         {
          = __ 

             = 

             = 
    }

      =   
         = 

         = 

       =  
       =   
       =   

      = 
         {
          = __     
         = 
           
         
          {
                                  
        }
    }
      =  
       =      {
          = 
           =   
           = 
          {
               = 
              {
                 = 
                
                       
            }  {
                     
            }
        }
         = 
    }
     
}
目前还没有提供基于动态权重的方案实现，但是设计上可扩展性较强，之后可以通过继承接口来做更多策略的实现。
感谢阅读，有错误之处还请不吝赐教。

本系列暂时告一段落，以后有时间再继续补充
再次感谢实习以来和导师的指导，感谢学习上浩哥、哥、菠菜哥、哥等小伙伴的热情帮助国内网络访问  官方的仓库速度不快，伟大的腾讯云提供了  镜像地址： ，这个地址直接用浏览器打开肯定是看不到效果的，本人试过了，这个地址只有在腾讯云网络里面才可以访问到，所以不对外开放哦，相信这也是为腾讯云的用户有一个质量上的保障。
我这里使用的是最新版本的 和   ，其他的系统具体的配置文件可能不同，我这里就以   为例子，说一下镜像的配置。
很多文章说是这个文件，但是我这里修改没有起作用，后来网上搜索资料，发现如果是使用  这样的方式启动的话，需要修改的是这个配置文件  ，具体操作是：
修改=  这一项的值，修改为 =   =
修改后保存，然后执行   ，系统会提示           意思就是配置文件发生了变化，需要执行上面给的命令重新加载配置。
所以我们按照提示执行：   重新加载一下配置文件。
然后重新执行   ，如果启动成功了，我们通过 查看一下控制台输出的信息，如果控制台输出的内容中  的值是，那就说明配置成功了。
然后我们运行    去获取镜像的时候就非常的迅速了。

相关推荐
如何搭建及使用 在腾讯云服务器上体验目录

需求背景

红包类别
体验流程
后台需求


需求分析

礼包列表
区服信息
领取礼包


整体方案与项目分解

需求开发

功能需求开发
性能需求开发
容错需求开发
监控需求开发


系统保障

系统容灾
过载保护
柔性可用
立体监控


演习验证

灰度演习
压测演习
异常演习


总结



接上篇《海量服务实践：手  游戏春节红包项目设计与总结上篇》
系统保障
第四部分讲述了业务需求的开发，但是否功能开发完成后我们就这样就可放到线上安心睡大觉了呢？
如果出现一部分机器乃至整个机房挂了，服务是否可用？
外部的服务突然故障了，比如  突然挂了，不能写入消息了，服务是否可用？
说是红包入口流量 ，万一来了  呢？系统会不会挂掉？服务是否可用？
以下从系统容灾过载保护柔性可用立体监控来讲我们这方面做的一些工作，我们对于除夕当天出现各种问题系统还能正常运行，用户能正常体验服务的信心从何而来？
系统容灾
容灾就是在整体服务一部分出现异常时，另一部分能顶上，不影响整体服务的使用，保障业务可用、数据安全。但容灾设计会使得系统复杂度增加，成本和代价也增加，需要额外的开销和资源，应该在合理的范围内考虑容灾。 
容灾级别一般划分为多机容灾、多机房容灾，多地容灾，红包的后台服务主要使用公用组件的均衡负载和系统容灾能力，服务无单点问题，采用同地多机房部署，按多机房容灾标准设计。
接入层
典型的  接入， 解析域名把请求带到离用户最近的  的  接入机， 再通过内网专线，把请求转发到实际提供  服务的  服务器上。

：    的首字母缩写，意为全局负载均衡，主要提供提供域名解析的就近接入和流量调度。实现在广域网包括互联网上不同地域的服务器间的流量调配，保证使用最佳的离自己最近的客户服务器服务，从而确保访问质量；它对服务器和链路进行综合判断来决定由哪个地点的服务器来提供服务，实现异地服务器群服务质量的保证。红包使用独立的  域名。

： ，是一套实现多网统一接入，支持自动负载均衡的系统， 把外网不同运营商的请求，通过内网隧道转发给 ， 返回数据时，再把数据通过内网隧道返回给 ，再由  发送给不同的运营商。红包  外网部署了上海电信联通双 香港  。

： 服务器，负责将  请求转成逻辑层使用的  协议，采用同地多机房部署部署。 作为  的 ， 会周期性的探测  的状态，在  分钟内自动把故障  从可服务列表中踢除，当  检测到  恢复正常后，自动把它加回可服务列表中。由  提供负载均衡和容灾。


逻辑层
逻辑层使用  容器开发，礼包列表区服选择礼包发货三个功能均是无状态服务，多个服务器在服务容量足够的情况下任意踢掉一部分都不会影响正常服务，使用  进行负载均衡容灾过载保护。

：机器级别容灾，业务程序调用   从   获取后台服务器的 ，使用该 对应的后台服务器进行通信，访问结束时调用   上报访问接口和处理时延，  对   上报的访问结果和处理时延进行统计和上报，当服务器出现故障， 一般在  到  分钟内就会自动剔除故障服务器。

数据层
数据层主要使用了作为  存储的  和作为分布式消息队列的 ，这两种服务都采用接入层存储层划分，逻辑层访问数据层的接入层使用  进行负载均衡容灾，数据层的存储层都采用一主一备双机热备容灾，并落地磁盘支持掉电重启后重建内存数据，支持多机容灾但是不支持多机房多地容灾。

过载保护
红包入口流量说是 ，万一基础侧有问题发到了  怎么办？
每个模块的容量都是从入口流量按照用户行为漏斗模型推算转化率设计的，万一评估有误转化率偏高超过了设计容量怎么办？
对于可能出现的超过了设计容量的流量尖峰，就要应用过载保护方法，保障系统能拒绝超过容量的部分请求，保障设计容量内的请求还能正常响应，实施的时候有四个要注意的地方：

从源头上减少无效请求；
从接入层开始拒绝；
各层互相不信任；
要照顾用户的情绪。

流量预加载
 做为页面访问的关键路径，前端页面制作离线包，预先下发到客户端，减少除夕当天  的流量压力。
频率限制
前台对用户发起请求的频率进行限制，超出频率的请求提示用户失败而不走到后台每  秒只允许请求一次到后台，前台保护后台。
后台接入层根据压测数据配置  接口的每分钟接受的请求数，超出接口处理能力的请求丢弃并进行告警。接入门神系统，配置  等规则限制恶意用户刷请求，保障服务的正常运行。
降级开关
前台调用后台的接口，设置开关以一定概率丢弃请求，对于关键路径返回错误提示用户稍后重试，对于非关键路径提供降级体验，结合频率限制功能，可以限制前台的流量传递到后台的比例，当比例设为  的时候则关闭该模块，实现前台保护后台。
队列堆积丢弃
后台逻辑层使用  框架， 处理消息前先检查消息在  消息队列中等待时间是否超出了预设阈值，在队列中堆积过久的消息前端已经超时，对于用户已经无意义，服务丢弃请求并进行告警，预防队列式过载雪崩。

柔性可用
柔性可用，柔性是为了保护系统，保证系统整体的稳定性，可用性。可用是为了用户，尽最大努力为用户提供优质的体验可能是部分服务体验。一个是从系统本身角度出发，一个是从用户角度看，在真正实施过程中只有将两者分析清，并融合在一起才能真正做到系统的柔性可用。关键问题是找准用户的核心诉求，找出符合求场景的核心诉求作为关键路径，出现异常可以放弃的诉求作为非关键路径。
找准用户的核心诉求
春节游戏红包用户的核心诉求有三个：

看到礼包列表
选择区服角色
领取礼包到账

其他的都可以作为非关键路径，有可以提高用户体验，没有也不影响用户的核心诉求。
保障关键路径的可用

看到礼包列表：作为页面关键模块的礼包列表，在红包活动前，十种游戏的礼包内容作为前端静态数据已经预先通过离线包下发。红包活动时，后台接口根据用户偏好返回的游戏礼包列表，只是提供前端礼包内容进行过滤和排序，失败了也有前端默认的游戏礼包列表，用户依旧能看到礼包列表，只是排序不够智能化。

选择区服角色：除夕前一周游戏中心的主站页面和运营活动增加一个后台接口请求，预先请求用户的区服角色信息缓存到本地，既降低了除夕当天的区服接口请求量又保证了游戏中心核心用户的区服信息是有效的。

领取礼包到账：对于领取操作是关键路径服务，用户领取礼包后需要写入才能算成功。故业务对消息队列做了逻辑层面的容灾，当出现故障时，可以打开容灾开关，领取操作写完应发流水后直接返回成功，不再往写入消息，采用分时段对账的方法替代实时发货，达到消息队列容灾效果，参见容错需求开发。


放弃异常的非关键路径

前端页面展示模块化，对于请求数据不成功的非关键模块进行隐藏

红包页面导流到游戏中心，游戏中心展示按红点逻辑展示，只显示第一屏的数据，默认不加载第二屏数据，用户往下滚动时再加载，牺牲用户往下滚动会短暂卡顿的体验减少后台的请求压力。

后台读取算法接口返回的推荐排序失败时使用默认的礼包排序

后台读取接口返回的礼包是拉活跃还是拉新失败的时每款游戏默认返回低价值的拉活跃礼包



立体监控
“我们对外提供的服务是否正常的么？怎么证明我们的服务是没有问题的？”，是监控告警首先要回答的根本问题。有效的监控告警需要保证能完备地监测业务指标，当发现问题时能有效通知负责人并帮助分析问题，强调的是“完备性”和“有效通知”，两者缺一不可。春节红包的监控告警从用户、业务和机器三个层面上描述。
 用户层面
从用户的角度监控系统是否有问题，模拟用户行为从系统外部发起请求，判断请求结果和时延是否符合预期，使用的是的自动化用例。
，，是社交、开放平台测试组使用的测试管理工具，它是功能用例、自动化用例管理的平台。通过模拟真实的用户访问并校验返回数据，确认访问延时、功能正确性的用户层的监控手段，从业务侧进行实施监控功能的正常运行状态的工具。
 业务层面
监控红包系统内部的各个子业务模块是否运行正常，分为两种：

模块间的调用监控

监控系统内部各个模块间的调用是否正常，使用的是模调系统。

模块内的状态监控

监控某个业务模块当前的状态是否正常，使用的是各个子系统自建的监控告警系统，春节红包这方面的监控主要有两个：礼包领取剩余数量和消息队列消息堆积数量。春节红包由于准备的礼包数量较为充足，故没有引起告警；队列由于生成速度远超消费速度，设置的告警阈值是，但实际最终堆积超过了，引发了告警。

 机器层面
监控机器的内存磁盘网络是否正常，使用的是网管系统。网管系统是一个功能非常强大的采集服务器、内存、网络、等指标的监控系统，同时还能对设备的进程和端口异常、磁盘使用率、硬件故障等进行告警，同时对外部系统提供功能丰富的调用接口，关于网管系统的监控能力，请参考其网站首页的监控能力白皮书 。

演习验证
演习是一种将被动相应转换为主动服务的手段，在演习前设定演习目标和演习方法，在演习过程中进行验证并收集数据，在演习后进行总结并提出改进方案。通过演习，可以实际验证用户行为与评估预期是否一致灰度演习，系统各个模块的容量是否符合预期压测演习，各类容灾和柔性的措施是否生效异常演习，提前发现架构中存在的问题。
灰度演习
核心问题：实际的用户行为与评估预期是否一致
已知游戏红包的入口流量设定是最大，红包系统内的各个模块需要支持的流量是多少？每个模块要部署多少机器以支持多大的流量？这个就要涉及到对用户行为和各个模块的转化率的评估？
解决方案：现网灰度用户收集数据进行验证
在现网灰度一部分用户对游戏红包进行验证，收集数据修正评估模型。结果如下：

入口卡券也到游戏礼包列表页的转化率评估为，实际为，评估与实际相当接近。

区服组件数据前端有缓存，评估请求缓存命中率为，请求到后台的比例为，实际为，评估与实际相当接近。

游戏礼包列表页有款游戏，评估每个用户平均会领取个礼包，实际为个礼包，评估与实际有很大出入。



从以上三个接口的流量评估来看，我们的开发和产品根据以往经验评估的用户行为数据大部分还是比较接近实际情况，但也有不太好评估的接口的灰度数据跟评估预期相差很大。根据灰度数据我们重新修正了评估模型和模块容量设计，极大地节约了领取接口的机器。活动当天的数据与灰度得到的数据相差无几，也证明了灰度验证手段是确切可靠的。
压测演习
核心问题：系统能否抗住压力
细分又可以划为两个问题：

对于系统容量内的合理请求，系统能否正常处理
对于系统容量外的超额请求，系统能否成功丢弃

解决方案：全链路压测和单模块压测
最理想的情况是先红包各个模块的进行压测后评估没有问题，再灰度用户使用现网流量进入红包系统进行全链路压测，但由于使用现网流量进行演习需要实际地发送红包，成本较高，灰度  万用户红包入口峰值仅为 ，远低于设计的 。故对系统的压力测试验证主要以单模块压测结合灰度演习得到的用户行为数据评估系统的整体能力。

对于未上线的接口的   和  ，采用  模拟请求压测


对于已经上线的接口，除了隔离现网机器用  模拟请求压测外，还使用了小组自研的压测系统，通过调整  权重把现网流量逐步导到一台机器上来进行压测


经验证，在  的机器上，礼包列表区服接口 的 在  之间，礼包领取接口达到  的 。在部署足够的机器后，对于系统  的请求量，是可以正常处理的。
在配置了接入层  的限速选项后，超出限速的超额请求会被  直接返回错误而不传递到后端处理；在配置了逻辑层  的超时丢弃后，在队列中堆积超过超时时间的堆积请求会被框架丢弃而不进行实际处理。对于超出系统容量的请求，系统是可以成功丢弃的。
异常演习
核心问题：系统发生异常时各种柔性逻辑容灾措施能否生效
系统中的柔性容灾措施，往往只有系统异常时才会生效，导致在实际现网服务运行中，柔性逻辑经常无法测试到，容灾措施一般也不会启用。这样，当运营环境真正异常时，柔性逻辑容灾措施是否有效还是个未知数。
解决方案：验证柔性逻辑和容灾措施
在红包正式上线前，通过模拟故障发生的真实异常场景，列出重点可能发生的故障问题，验证柔性逻辑和容灾错误是否真实有效。

后台  修改神盾的  为错误的 ， 调用神盾出错，预期后台依旧能按默认排序返回礼包列表。

后台  修改  的  为错误的 ， 调用  出错，预期后台依旧能按全部游戏推荐拉活跃礼包返回礼包列表。

后台随机停掉一台 ， 调用 出错，预期服务短时间内有部分失败， 能在  分钟内踢掉该出错机器，服务恢复正常。

打开  容灾开关，用户领取成功消息不再放入 ，而是直接走流水对账，预期游戏能够成功到账。

前台用户操作频率超过了限制 次秒，预期前台直接返回领取失败，抓包看到请求不走到后台。

前台调用后台接口通过设置  指向错误 ，前台调用后台推荐接口出错，预期前端页面依然能正确显示作为关键路径的礼包列表。

前台调用后台接口通过设置  指向错误 ，前台调用后台非关键信息接口出错，预期前端页面对非关键模块进行隐藏。


经测试同学验证， 中的柔性逻辑和容灾措施确切有效，符合预期。
总结
三个系统功能：礼包列表区服选择礼包发货
四个开发阶段：功能开发性能开发容错开发监控开发
四种业务保障：系统容灾过载保护柔性可用立体监控
三场演习验证：灰度演习压测演习异常演习

相关推荐海量服务实践：手  游戏春节红包项目设计与总结上篇日请求亿级的会员平台升级实践事故总结，几招教你规避风险导语： 每年暑期都是各路顶会扎堆，今年也不例外，，，这三个我们一直关注的领域顶会相继召开，本期“技术快报”将重点关注这三大顶会的内容，摘录与游戏开发，游戏体验相关的内容做一个归纳点评。

本期“机器学习”部分的内容主要来自  这个相关的内容。强化学习是目前机器学习中和游戏最接近的领域，本次重点听了这部分的内容。整个强化学习一条线听下来，从方法纬度看，今年做 和变成趋势。能做的也就几块，近两年 的方法做的差不多，尤其，放出来之后，开始转到 方法，以及本身的预测。是解决多任务，多目标问题的利器，和互补，放到框架来也很自然。另外还有些其他领域的方法和的结合，比如里的。下面将从面临的问题的角度详解几篇文章。
泛化和迁移  
网络模型的泛化和迁移是目前深度学习领域的一个巨大挑战。泛化和迁移问题又可以细分成多种形式：
●     从训练环境到测试环境的泛化
●     从训练环境到其他未曾见过环境的泛化
●     从简单训练环境到复杂陌生环境的泛化
●     从模拟环境到真实世界的泛化
●     多个训练模型的经验迁移
   
原文链接：
【摘要】
和今年合作的这篇文章主要想解决强化学习的模型怎样从模拟环境到真实环境，从训练环境到测试环境的迁移，同时增加模型的健壮性。主要思想是采用反策略在训练中增加噪声，提高模型的抗干扰能力和泛化性。下列几个 仿真场景中，红色的箭头表示训练中的干扰力，这些干扰因素也会被参数化并参与学习，在训练中充当角色。

【问题】

由于缺乏真实数据，强化学习中从模拟到真实世界的迁移十分困难；

即使在真实世界训练，训练到测试的泛化也很困难。


【解决方法】
在训练主同时，训练一个对手，对手要学习的策略就是破坏主的策略。从而，模拟在泛化过程中，或是向真实世界迁移过程中的意外情况。举个形象的例子，两个人一起开车，一个人学习正常开车，另外一个人阻止正常开车。对手除了的行为外，还被赋予“超能力”，比如改变路面的摩擦力，改变车子的质量。本质上是在制造噪声数据，让主更加。
【结果分析】
优势：通过对，，，等几个问题的实验，相对于基线方法，文中的在训练和测试过程中表现出了更强的鲁棒性：对初始化状态不敏感；对测试环境适应性强；测试中对噪声情况也更加鲁棒。
不足：  随不同问题场景变化，较难设置；竞争训练的过程，较单个训练复杂，不易收敛，较依赖于参数。
【应用落地】

中训练结果难以在测试环境中泛化。

模拟器向更加复杂的真实环境迁移。


      
原文链接：
【摘要】
这篇文章主要想解决 中的一类问题： ，即在一个领域学习的模型，在结构基本不变的情况下，能适应另外一个领域，这里的领域可以理解为模型的输入分布。之前研究者通过对齐源领域 和目标领域 的内在表示来提升模型的适应性，但是这种方法通常需要知道目标领域信息，而这种信息很多时候很难获取，或是根本就不知道。于是 的美女 另辟蹊径，在 的情况下，通过分解 到一个低维的表示比如游戏环境中的颜色，位置，尺度，几何图形，光照等等，“过滤”掉领域相关的信息，进而增强模型对  的适配性。他们还为这套方法取了个很别致的名字：   。这个模型在 仿真环境和 ，上 的 测试结果都远远高于目前的基线算法。

【解决方法】
分三步走，第一步：从环境中学习基本的视觉概念，如颜色，物体，位置等等，也就是所谓的  ；第二步：在 中，使用上一步得到的低维的分解的视觉表示作为观察，学习策略模型；第三步： 上测试。模型如下：

上图中主体部分是蓝色的提取低维无关的信息和灰色策略网络，旁边黄色的模块是用来给提供特征空间而不是像素重建的。
【应用落地】
存在 的场景，比如游戏规则相同，场景变化 。文中仅仅展示的该算法在简单任务上的游戏，多目标，多阶段任务还是要结合其他方法综合治疗。
回报函数 
 是强化学习中牵引训练目标的重要手段。训练中设置 是件非常不容易的事，被研究者戏称“ ”。前卫的研究者很早就开始探索各种自动化获取的方法，从稍早的  到这次中出现的，从 到难以设置的 
    
原文链接：
：
【摘要】
增强很难设定，本文提出了一个思路：既然外在的难以确定，那么自发的“好奇心”呢？的在这篇文章中将好奇心建模成：预测行为在视觉特征空间的结果与观测的误差视觉特征空间是通过自监督的反向动力学模型得到的。这种方法在只有  甚至没有 的情况下，可以有效的提升的探索能力，同时还有模型泛化性上的增益。但是文中只举了马里奥和 的例子，这两个例子偏简单，说明内生的比着先验丰富的 还是要差不少，但是针对没有 的情况下，好奇心至少能驱动持续。

上图是马里奥的例子，在第一关中使用好奇心去做探索，习得的模型，在关卡二中接着用好奇心探索，探索效率就要高很多，说明用好奇心探索得到的模型泛化性能更佳，主要原因可能是这两关基于的结构类似，但这并不是出来的，是学出来的。
【解决方法】

上图左半部分除去是一个标准 上的 ，右边是  的展开图，先看左图，和一般的 不同的是里除了  外还引入了  。再来看看上图右侧，模块输入当前状态，当前动作和下一帧状态，输出  。和映射到空间联合当前动作，这块其实是用来训练两个状态的 的，这样做的优势是抽取像素中与决策相关的信息，过滤无用的信息，让预测更加鲁棒。再看左边前向部分，输入是当前的动作，和在空间的映射，输出用来预测下一状态在 空间的映射，两者的误差作为  输出。看上去很绕，但是思想很朴素，环境的预测误差作为 ，预测误差越大，好奇心越大，探索也越有效，越值得鼓励。和之前用 作为 有点神似，把当前动作对环境的改变作为驱动的一个要素。
【应用落地】
中，尤其是做 的时候，在没有 或是很稀疏时，对于简单的可以尝试一下这种方法，或是把这种方法改成 之一，辅助主探索更多系统隐含的回报因素。
     
原文链接：
【摘要】
在这篇文章里，主攻里最难解的一类问题：推理规划类问题。本应该放在下一节里，但是因为这篇的核心贡献还是阶段性的自动探索，姑且放在这里吧！问题如下图： 中玩家需要操纵角色先通过梯子下到地牢，然后爬上梯子拿到钥匙，再回到上层打开门进入下一关。这类问题的很难设定，如果只是拿过关分值作为，会有个  问题，也就是说等到谜题解开的时候，不知应该给前面哪一步决策加分；同时伴随的还有探索空间非常大，回报非常稀疏的问题。

于是大家就想到解规划问题的利器层次结构，将问题  ，比如上面这个解谜问题可以切分成若干个子问题，子问题解决了，主要目标也就达到了，子问题可以设置自己的，看上去很完美。但是这帮人觉得这样解太了，因为需要太多的，不同的问题，需要人工先解一遍，然后让神经网络解决每个的子问题。于是开挂想用一个更加的层次模型来解决这个问题。算法框架分两层，上层叫，主要负责生成中间一个个小的，下层叫，主要负责完成。这样只要设定一个最终的，负责探索阶段性的回报函数，用这个回报函数完成阶段性的目标。算法框架如下图：

【应用落地】
简单的线性推理，可以考虑一下这种方法，毕竟只有两层嘛，上层探索的周期是的，只能探索这一周期内的 ！当然可以加多层，那么到底加几层是不是也很呢！猜想这篇虽然设计精妙，却没有得到提名，也许就是因为以上原因吧。当然， 今年拿到了  也是实至名归，也算是拿了今年两项大奖之一。作为跟着在上集入门的人，还是想送给由衷的祝福。
复杂的多任务，如果带并行，带循环，带计数的推理，还是需要更加复杂的结构来解，或是如下节将会提到的让人的先验能有机的和现有的结合。
多任务
多任务通常指较复杂的多目标任务，这些任务通常有时序上的依赖关系，在状态空间不大，状态转移概率已知的情况下，可使用规划类的算法解决。但是当模型未知，状态空间很大维度，尺度的情况下，尤其当连续时，规划类算法各种搜索技巧也会无能为力。而以解问题见长的神经网络似乎天生就不是用做推理的，这次，看到不少重拾方法，尝试优雅的结合神经网络来解决多任务，多目标的规划类问题。其实，这也不是个新鲜玩法，早在去年， 就将和放在一起解围棋中的推理问题，只不过虽然形式上是个层次结构，但本质上是个带权值适应的搜索树，层次中并没有的概念。
      
原文链接：
 
：=
【摘要】
这篇是本届增强学习这个唯一入选 提名的文章，细读一遍发现是个 ：引入 高层的干预，虽然会被人说，但从实用角度还是忍不住点个赞！代码也放出来了，试验结果也很抢眼球。 红人 团队放出来的文章干货居多，推导漂亮，实验充分，值得精读。

上图中是两个多任务的问题，左边图的目标是 ，需要完成这个任务，首先需要砍树取得木头，然后使用完成任务。右边一个任务则是 ，和左边任务公用一个高层动作：砍木头。这篇文章最大的贡献是将人类完成一项复杂任务的先验抽象成高层动作的序列，即文中所谓的 ，然后将其做到框架里。对于比较长而复杂的 ，还设计了一层，很工程，很实用！里的每个高层动作都对应这一个，下面是算法框架，除了部分，做的人应该能秒懂：

贴个算法在这里又不做解释除了凑点篇幅，更想说的是          伯克利这一脉家风严谨，公式中的符号系统设计精美而一致。偏应用的文章要想拿提名最直接的途径就是推理严谨，简单易懂，并且放源码，一码胜千言嘛！
【应用落地】
这篇文章最大的特点，看上去很实用！至于实际疗效如何，待拿复杂问题试下来才知道。
       
原文链接：
：=
【摘要】
这篇文章是密歇根大学的 教授去现场讲的，正会和 听了两趟， 略带催眠属性的汗蒸英文，听第二遍的时候实在忍不住打了个盹儿  这篇文章主要尝试解决多任务环境下的两层泛化问题：未见过的指令和长指令序列。针对前者，通过学习指令之间的相关性，很常规的想法；针对后者，依然是，主要是学了一个元控制器 使用习得的技能去完成高层的指令，同时决定何时去子任务，解决 问题。

如上图，实验是拿做的，里加入了里没有的指令蓝色部分，并且增长了指令序列。不难发现，蓝色部分新增的指令，其实只是换了施动对象，动作本身并没有改变。这篇可以和上篇对比着看，一样用高层指令序列，一样用，一样的，却做出了不同的风格。
【应用落地】
这两篇的实用性较强，两篇的侧重点稍微不同，前者着重一个高层指令和的结合框架，后者考虑较简单的指令泛化，两者都展示了较好的级别指令序列的泛化。在解多任务问题时可以综合考虑这两篇的思路。
多智能体
开会的这几天中，和暴雪联合放出了星际平台，伴随发布的还有大量玩家数据；在国际邀请赛中战胜了高手，职业选手，并约战明年 在此之前，的也放出了的大量玩家数据，并且发布了一个轻量级的实验平台。由此可见俨然成为众多顶级团队角逐的下一个目标。是人类通向途中必须迈过的坎，对比单智能体，状态空间维度和尺度骤增， ，集中和分散的平衡， 受信 问题，高层的，都带来了极大的挑战。同时，拥有巨大的商业前景，如：无人驾驶，人机，无人机多机协同，智能物流系统 
   
原文链接：
 =
【摘要】
这是一篇在 的文章，注意上面视频不是现场的。情况下，如果把所有联合在一起训练，状态空间和空间都会随数量指数级增长。这篇文章提出了一套方案，准确的说是：   。中用使用训练，而每个单独训练，仅用于训练过程中，所以在的时候只需要 。本文的另外一个是采用 去出单个行为的价值，解决多授信问题。这种的方法能够达到接近方法训练出来的策略，还是不错的！

上图中红色的是训练中需要的 ，蓝色是 ，对应的分别是 和 。
【应用落地】
文中使用的做实验，取得了和方法接近的效果，但是训练难度降低了不少，所以类似的场景可以试试这种方法。
   原文链接：
【摘要】
中稍复杂的协同配合很难直接用强化学习得到，借助 来习得是个很直观的思路。但是用来学 也有自己的挑战，比如协同策略是隐含在中不易得到； 数据噪声问题；从中习得的协同策略的泛化性问题等等。这篇文章以和足球为实验场景，提出了一套半监督的方法同时学习隐含之间的协同策略，以及单个的。














【解决方法】
对于单个的，每个一个策略网络，是个的训练过程；对于的协作模型，文中则是设计了一套基于变分推理 的方案。总体思路上有点类似上篇：    。

算法构架如上图，左边是 训练，右边是 ，即隐含的角色分配模型，用 表示。每个训练周期，先固定右边的 ，用有导师的训练左边的策略网络；再固定左边的策略网络，通过最大化角色分配，来训练右边的角色分配模型。这样做可以部分的避免由于中的角色变换带来的。
【应用落地】
游戏中解决角色动态分配带来的问题可以考虑试试这种方法。 部分没有太多新意。建模角色分配的图模型，文中用的是一阶的 ，针对更加复杂的协作问题可能需要替换成更加的图模型。


技术快报：快速扫描学术／技术前沿进展，做出必要的分析归纳，寻找它们在产品中落地的可能性。希望能帮助大家了解前沿，拓宽视野，提高决策效率。在 微信读书  中，排版引擎负责解析  或  格式的书籍源文件，将排版后的书籍内容如文字、图像、注解等元素渲染至屏幕上，是最常用、最复杂的组件之一。
而开发同学对排版引擎的日常修改，可能影响了海量书籍的排版结果。对排版引擎代码变更的测试，往往耗时多、难度大、容易漏测。本文介绍了为解决测试的难题，如何逐步将人工测试步骤自动化，最终构建了一套微信读书排版引擎自动化测试流程，以确保微信读书排版引擎的质量。
一背景
排版引擎日常修改
为了获得极致的阅读体验，产品同学经常会提出细致的排版需求，交给开发同学修改。而排版引擎的修改，往往牵一发动全身，可能导致书城上万本书籍排版结果受影响。
举个例子，有个需求是增加正文段落的 ：

再举个极端的例子，有个需求要把章节标题往右移动个像素：

那么，如何确保微信读书的排版质量？最开始，我们用人工测试的方法来确保质量。
人工测试方法
当开发按需求修改排版引擎、自测后，会把代码提交到 ，然后交给测试同学进行测试。
测试同学使用持续集成工具编译打包，得到排版引擎修改后的  安装包；然后在两台设备安装排版引擎修改前、后两个版本的 ，同时打开需要测试的书籍，翻页，对比，通过肉眼观察排版差异是否符合预期。
人工测试方法比较耗时，需要打开每本书，一页一页地翻页、对比，而且无法覆盖很多书籍，存在漏测的风险。
另外，通过人眼检查两台设备上的排版结果有没有差异，是很困难的任务，一是容易疲惫导致判断失误，二是对细致的排版变更如第二个例子很难判断是否符合预期。
为什么需要自动化测试？
前面提到，人工测试费时耗力，且容易漏测。
此外，排版需求的特点是细节多、变更快，且修改影响范围大，全网书籍上万本，无法一一验证。一旦出错，直接影响口碑。这些因素都增加了人工测试的工作量和压力。
除了精细化的排版需求会对排版引擎代码做修改，在日常的维护中，也会重构排版引擎、修改排版引擎相关但不影响排版结果的代码。每次重构、修改后，也会交给测试同学验证此次修改对排版结果没有影响。由于人工测试比较耗时、无法一一验证，每次重构排版引擎代码压力很大，轻易不敢改动。
还有一种情况，是在开发其他需求、修复缺陷时，意外地导致排版结果受影响。这种错误一旦发布到现网，后果很严重。
所以，把人工测试流程自动化十分有必要。自动化以后，可以大大减少人工测试的时间，同时方便开发同学自测。开发同学对排版引擎也可以大胆重构、持续改进代码质量。最终，达到确保排版引擎质量的目的。
二如何自动化测试？
首先，我们要分析一下，在人工测试中，主要有哪些步骤？每个步骤是否能自动化？
在人工测试中，对每次变更的测试，有步骤如下：

需要把变更前、变更后的  包安装到两台设备
打开 ，登录，把要测试的书购买、加入到书架
打开要测试的书，设置排版偏好，翻页，用眼睛查看屏幕上的排版结果，对比屏幕中的排版结果是否有差异
如果有差异，根据需求判断差异是否符合预期

其中步骤 、 利用自动化测试工具是比较容易完成的。步骤  借助算法能够使其自动化，会在后面详细展开。步骤  自动化的难度比较大，可能需要借助非常高阶的人工智能完成，我们把这个步骤交给测试和开发同学。
那么，如何完成步骤  的自动化，让机器做人类的事情呢？我们把它再细分成三个步骤：
 获取排版结果的数据表示
首先，需要找到一种机器能读懂的数据表示，这种数据表示要既能够表示排版的结果、反映代码的修改，也能够通过算法来对比，对比的结果要便于可视化的展示，方便开发、测试同学判断差异是否符合预期。
我们的选择有：

，是从 、 处理后得到的中间数据，包括文字和排版样式。这种数据结构比较抽象，没有一种很好的差异计算方法、和差异结果可视化方法。

阅读器屏幕截图，位图格式，借助各种成熟的数字图像处理算法，容易计算差异


考虑到  容易计算差异，可视化输出效果较好，我们选取阅读器屏幕截图作为数据表示。
 对比图像差异
选择了图像作为排版结果的数据表示，那么如何对比图像差异呢？
首先，我们要选取图像特征，然后才能对比图片差异。图像的特征，从视觉认知概念上，有低、中、高级特征：

低级特征：如像素域、频率域、
中级特征：如  边缘特征
高级特征：抽象视觉概念，比如从  算法训练得到的标签，如车、枪、球

这里我们希望每个像素的差异都能检测到，所以选取像灰度化处理过的图像矩阵作为特征。
有了特征后，我们需要定义差异，就是两个灰度图像矩阵的距离函数，如：

，表示两个灰度图像矩阵之间，不一致的像素点的个数
，曼哈顿距离或棋盘距离，不一致像素点差值的绝对值之和
，不一致像素点差值的平方和

我们关心有多少像素点不一致，所以我们这里取 距离，即两个图像有多少个像素点不一样，作为差异衡量的指标。
当距离大于时，我们认为这一页的排版结果有差异，把它可视化输出，给开发或者测试同学作为参考。
 可视化输出
检测到差异后，我们把两个图像矩阵灰度化后相减，得到一个新的矩阵，把它归一化得到差异图像，如右图所示：

三通过  生成排版结果
人工测试步骤 、 的书籍购买、加入书架、打开书籍、翻页、截图等任务，可以利用    自动测试脚本来模拟人工点击来完成任务。
但是考虑到  模拟翻页、截图速度慢，且  变更频繁导致  脚本后续维护麻烦等问题，所以我们通过提供一个测试  接口来完成这个任务。
在  设置彩蛋的『执行  页面』中，输入  并执行后， 会在后台对指定书籍购买、加入书架、排版、生成排版结果截图，并把结果保存在本地磁盘。用户也可以选择  到  上。

运行
 格式如下：
=三体乔布斯传失控乌兰拖拉机简史=====
  输出排版结果到目录
    需要排版的书单
    首行不缩进 首行缩进，默认
      字体大小，默认
    字体  系统字体    为对应选项字体，默认
    背景颜色 白 黄 绿色 夜间，默认
    输出文件夹名，默认
通过这个 ，在真机或者模拟器都可以随时得到排版结果，而且速度比模拟翻页要快。
四自动化测试流程
下面，将介绍我们完整的排版引擎自动化测试流程。
 生成排版结果
首先，用户需要确定参数：待生成排版结果的  版本范围 、书单、阅读偏好设置字体、缩进、主题模式。把这些参数传给脚本_，然后自动化流程开始，脚本会执行以下步骤：

在指定  版本范围内，找出排版引擎有变更的版本，
对每个  的版本，用  编译项目，安装到模拟器
通过  的   脚本，打开模拟器，运行微信读书，进入到测试彩蛋页面：执行 ，生成排版结果
把结果从模拟器移动到指定的目录下


 生成排版结果差异
得到排版结果后，执行脚本 _，对相近的版本，每本书的每一页通过  对比，如果有差异，则输出可视化的差异结果。

 人工检查差异
自动化流程结束后，我们得到排版结果差异，需要人工去检查差异是否符合预期。
我们以文件夹的形式组织展示差异的可视化结果：版本 修改前与 修改后，对书籍  排版差异可视化结果，保存在文件夹 ___ 中。
可视化结果图像中，深色字体是  修改前的排版结果，浅色字体是  修改后的排版结果。
另外，排版性能变化也纳入了监控。

五自动化测试的优势
自动化流程的建立，使排版引擎的测试时间缩短了 ，测试期间无需人工干预，对比数据如图：

例如，人工测试一本 页的 《哈利波特与被诅咒的孩子》需要约  分钟，而自动化测试脚本扫描、对比差异只需  秒不含编译时间；人工测试  本书籍，用时约  小时，而自动化测试用时约  分钟；人工测试  本书籍需  小时，而自动化测试用时约  分钟。
除了大大减少人工测试的时间，开发同学借助自动化测试工具，能大胆重构代码，通过自动化测试来确保重构不影响排版结果，拥抱快速变更的需求。
随着自动化测试覆盖的变更版本、测试的书籍数量越来越多，带来的收益越大。
借助自动化测试流程，对于任何代码修改而导致样本书籍、每一页、每个像素点的排版结果变更，都能够纳入我们的监控，最终达到确保微信读书排版引擎质量的目的。
六未来工作
目前，自动化测试工具已经投入使用。未来会持续优化、增加特性，以满足测试、开发同学的需求。
未来工作包括但不限于
邮件通知：执行脚本得到结果后，如果两个版本之间的排版结果有差异，通过邮件通知相关同学；另外，排版的性能对比结果也可以生成一份报告，通过邮件通报。
运行速度优化：目前对  本书生成排版结果，耗时约  分钟，对比耗时约  分钟。可以进一步优化运行速度，争取覆盖更多样本书籍
支持微信读书安卓版
尝试应用在其他模块：对运行预期结果相对固定、测试代价大的功能模块，可以通过支持测试 ，输出运行结果截图，以插件的形式接入这一套自动化测试流程。
七总结
本文介绍了微信读书排版引擎的日常修改时，人工测试所面临的问题，以及为什么需要自动化测试的原因。
然后本文分析了人工测试的流程，以及这些流程改造成自动化的可能性。
最后，介绍了我们整套自动化测试流程，以及应用自动化测试以后所来的好处，最终达到确保微信读书排版引擎质量的目的。

相关推荐手游自动化测试 基于模型的自动化测试工具：本文为年月《程序员》原创文章，未经允许不得转载，更多精彩文章请订阅《程序员》。责编：仲培艺，关注数据库领域，寻求报道或者投稿请发邮件。

接《  深度探索二》
 的事务处理
基于和，实现的是单点写的一主多从架构，所以在事务处理方面，没有大的变动，事务处理技术得到继承。整体上是依据和技术实现了事务模型参见《数据库事务处理的艺术 事务管理与并发控制》一书的、节和并发控制参见《数据库事务处理的艺术 事务管理与并发控制》一书的第、章。
 持久性
对于，事务的特性，只有特性与和有很大的不同。利用的和在存储节点构造数据页基本过程参见节。
如前所述，的存储层与计算层分离。存储层其功能在节讨论，其设计思想在节讨论。本节从事务的角度来讨论与存储层紧密相关的持久性，如表所示存储层是表中的“存储节点、、、、、”。
在存储层，日志被写到持久化的存储设备后，主节点收到应答则不被阻塞，上层工作能够继续进行，且存储层的日志落盘操作保证了整个的日志持久化。然后存储层的利用日志做实时恢复，这样使得日志数据转变为了“”中存储的页面格式的数据。这些工作完成，才相当于传统架构的数据库持久化完成。
但是，因为存储层不再是单点而是分布式结构，故存在故障的种类变多，如多节点的数据在实时运行过程中的一致性问题、在系统故障后的数据恢复时多节点的数据一致性问题。使用如表的几个概念来表示关键的一些日志点信息，然后凭借这些点来解决“日志数据的不一致”问题，这几个概念，分别是：

   ，日志序列号：单调递增，唯一标识每一条日志记录。如表所示，到表示共有条日志记录，每条有独立的值。

   ，一致性点：的每个事务产生的最后一个为一个即一致性点一个事务包括多个事务，一个事务包括一到多个日志记录。这是在描述以事务为基本单位的一个局部一致，尚不能达到事务一致。如表所示，“”事务的第一个事务的一致性点，是，如果此时系统故障，之后做恢复，事务不会被恢复成功；如果事务在主节点被标识为了提交的事务提交标志，是在内存标识为事务已经提交，然后才刷出日志，这点不符合预写日志的要求，事务日志尚没有持久化到存储层，这意味着数据可能会丢失。但是，对这种先标识事务提交后刷日志的方式给出了不丢失数据的解决方式，而改变了日志的刷出机制，可能会改变或不改变原有的数据一致性保障机制，如果改变了原有机制，论文对这一个重要点没有加以描述，只能存疑待问。

，  ，段完整：每一个存储节点对应的最大连续，在系统存活期间，可以利用与其它节点交互，采用协议，填补丢失的日志记录。如表所示，只标识出了节点的是，而对于节点，其是。

，  ，卷完整：每个存储节点接收到的最大连续日志，因为多数派协议的使用，每个存储节点的会不不同。如表所示，没有表示出到各个存储节点的，而是只标识出了六个节点中所有中的公共最大点，这个点，是系统故障后恢复所能恢复到的一致点。注意依旧不是事务一致而是事务一致，存疑的是，不能达到事务一致，其意义何在？还有什么重要的细节没有公开吗？留意到下面这段话，我们可以看出一点端倪存储层的恢复不需要保证事务一致，存储层恢复之后，计算层还会继续恢复工作，这样才能达到事务一致：



                                           

 ，  ，卷持久点：传统的数据库提供功能，在日志中加入一个点，作为故障恢复时的起始点。就是存储层的“点”，在之前的日志，已经无用可以被，但因存储层的日志一直在持续不断地被用于“恢复”日志为“”中的数据页，所以其作用和原始的“点”相反。注意是所有存储节点上的日志比较后得到的一个共同点，不是一个级的点，这和相似，都是 级别的。其定义如下：
                            
表 日志在主节点和存储层的作用表持久化实现表

 事务与数据分布
在节，我们曾说，目前制约存储层内的“”起更大作用的因素，主要在于分布式事务的机制的选取和自身的事务实现机制。
这有两层含义。一是自身的事务实现机制制约了存储层内的“”起更大作用。二是分布式事务的机制的选取关联着存储层内的“”是否有机会起更大作用。
首先：的事务信息，几乎不在数据上除了元组头上有个事务用于版本可见性判断外再无其他信息，而是位于内存中。这其实是在说，的行级锁即索引项的记录锁，其锁表位于内存，不能随着的数据分布而“分布”。而的可是在数据页上存储了足够多的事务信息参见《数据库事务处理的艺术 事务管理与并发控制》一书的第六章，所以中的其他节点，就能够随着被分布的数据而获取事务相关的信息从而在分布的各节点上处理事务的特性。此点是能否走向分布式事务的一个关键点当然选用不同的分布式事务实现机制会反过来影响这点结论。
其次：分布式事务的机制的选取为什么会影响着的存储层内的“”是否有机会起更大作用呢？
有的分布式事务架构，采取的是集中式架构，即中央点总控事务管理。事务的决策判断，都要经过中央点进行，多个子节点需要和中央节点多次交互。比如提供了全局事务管理器。如果或者的分布式架构向这个方向发展，则存储层内的“”就没有多少机会起更大的作用了。
而有的分布式事务架构，采取的是事务信息随同存储分布。这样不同的节点就可以进行“分布式”的事务处理。比如基于的系统，其核心不在于两阶段提交，而是在于分布的数据项上，有着丰富的事务信息，这些信息足以被任何节点用于做的实现判断参考《       》。如果或者的分布式架构向这个方向发展，则存储层内的“”就有很大的机会起更大的作用。
走向哪条路，或走向另外的路，需看的雄心有多大。目前的告诉我们的是，其分布式架构的选择，仅是用户数据分布。事务数据的分布，其实是更大的一个话题。
 事务处理
和的事务处理技术，采用了，把强严格两阶段锁融合到平板事务模型中，以提交和回滚机制实现特性，并进一步在读数据时加锁确保特性，通过实现了特性中的和隔离级别以提高并发度。这些技术，在目前的中没有大的改变。如前所述，改变的是依据事务日志做持久化处理特性和系统故障后的恢复的一部分流程处理、特性的一部分，从整体上看，没有革命性的变化。但是，的事务提交却是异步的且和相关确保持久化，这点在论文中描述很细致如下：

                          “ ”                                             ’                                                   

在节我们提到“鉴于以上几点，备机数据获取和更新的这个细节，算是个谜”，即备机的数据获取，是从存储层而来还是从主节点而来？我们不妨做个论文没有提及的猜想：备机的数据，源自存储层和主节点，存储层统一向上层提供数据页的缓冲服务，用以不断响应计算层的数据缺页请求，这起到了传统的数据缓冲区的作用。而主节点传输日志给备节点，备节点可以从中解析出日志信息也是受到的保护的，从而能够构造出主节点在某个时刻的完整的计算环境状态数据缓冲区信息，这样，备机就可以为接到的读请求构造一致的“”，为读操作提供了事务读数据的一致性状态。如为此点，则是一个巧妙的设计。更进一步，主机直接传输给备机的，可以只是准备写入的信息。
 锁管理
基于的同样使用了基于封锁的并发访问控制技术。但是，改造了的锁管理器，这点论文没有提及，而在年的技术大会上，的一个分享展示了如图的内容。图中显示，在的锁表管理器上，对于、、三种操作，把互斥了三种类型的并发，而分别按操作类型加锁“ ”，提高了并发度，这样的锁，看起来是一个系统锁，把一个粗粒度的系统锁拆分为三个细粒度的系统锁。但是，较为奇怪的是，如图，展示了其效果却十分的惊人图是测试环境的配置。
 
图 锁管理器改进图
 
图 锁管理器改进后的性能测试对比图

图 测试环境配置图
 云服务能力
 强化的云服务能力
除了通过更多的数据冗余跨个的 个副本提高高可用性外，还有着其他强大的云服务能力，这是云数据库需要重点建设的能力。
 存储方面，存储的单位是段，每个段的大小为，单实例数据库存储最大限是 。
 处理系统故障方面：

秒内完成一个 的的网络迁移。秒完成故障转移。

以为单位周期性并行备份。

以日志为单位周期性并行备份。

通过日志实时地持续恢复，提供了更快的 。


  性能方面：

更快的索引构建。采用自底向上的索引构建方式，比快２倍到４倍。

无锁并发算法。构造采用无锁算法减少竞争提高性能。

无锁队列提高审计功能的速度。

其他如热行竞争、批量数据插入等性能提升明显。


  其他云服务：

提供快速  和部署。

自动安装补丁和软件升级。

备份和  恢复。

计算和存储的扩展性支持。

如图所示，存储系统的元数据存于 中，使用 提供的工作流实现对的自动化管理，这也是云中规模化服务的重要能力。


 万能数据库
的不只是的一个分支版本，更像是一个万能的数据库系统，这样的系统，通过兼容各种主流数据库的语法、功能，也许能在云上一统数据库的服务，把各种数据库的用户应用接入，通过统一的一个分布式的数据库引擎，提供各种数据库的数据服务能力。
的官网，声明了“兼容 的 ”如下：

      正在提供   预览版，即兼容  的  。 是一种完全托管的、兼容  和  的关系数据库引擎。

单从字面看，不再是，而是，所以将来将会是 “”，各种数据库都将融于当中。这样提供强大无比的云数据库服务，此点非常重要，用户基于任何数据库的应用均不用修改应用的代码，无缝接入。
从技术的层面看，实现这样的目标，有多种方式。简单的方式，就是利用相同的云基础设施和云服务概念，把各个数据库单独云化，然后用统一命名。但如果进一步把计算层分离，如把语法解析、查询器、执行器拆分，不同种类的数据库使用各自的语法解析和查询优化，然后统一执行计划交给统一的执行器去执行，事务处理和数据存储则可以独自研发独立于上层的计算。如此，想象空间得以打开
 小结
本文探讨了的实现方面的技术内容，由于作者水平有限，错漏之处，请不吝指正。在实现方面的诸多细节，论文并没有提及，期待以此文抛砖引玉，期待多方指点讨论，共同进步。
附录
参考资料

《          》



《数据库事务处理的艺术 事务管理与并发控制》，机械工业出版社，年月出版

      

《      》

《    》在分布式程序架构中，如果我们需要整个体系有更高的稳定性，能够对进程容灾或者动态扩容提供支持，那么最难解决的问题，就是每个进程中的内存状态。因为进程一旦毁灭，内存中的状态会消失，这就很难不影响提供的服务。所以我们需要一种方法，让进程的内存状态，不太影响整体服务，甚至最好能变成“无状态”的服务。当然“状态”如果不写入磁盘，始终还是需要某些进程来承载的。
在现在流行的开发模式中，很多人会使用这种模型，在这里，就是无状态的，因为状态都是放在里面。这种做法对于来说，是可以随时动态的毁灭或者新建，但是进程就要保证稳定才行；而且作为一个额外的进程，和它通信本身也会消耗更多的延迟时间。因此我们需要一种更灵活和通用的进程状态保存方案，我们把这种任务叫做“分布式缓存”的策略。我们希望进程在读取数据的时候，能有最高的性能，最好能和在堆内存中读写类似，又希望这些缓存数据，能被放在多个进程内，以分布式的形态提供高吞吐的服务，其中最关键的问题，就是缓存数据的同步。

常用做缓存
为了解决这个问题，我们需要先一步步来分解这个问题：
首先，我们的缓存应该是某种特定形式的对象，而不应该是任意类型的变量。因为我们需要对这些缓存进行标准化的管理，尽管语言提供了运算重载，我们可以对“=”号的写变量操作进行重新定义，但是现在基本已经没有人推荐去做这样的事。而我们手头就有最常见的一种模型，适合缓存这种概念的使用，它就是——哈希表。所有的哈希表或者是接口，都是把数据的存放，分为和两个部分，我们可以把想要缓存的数据，作为存放到“表”当中，同时我们也可以用把对应的数据取出来，而“表”对象就代表了缓存。
其次我们需要让这个“表”能在多个进程中都存在。如果每个进程中的数据都毫无关联，那问题其实就非常简单，但是如果我们可能从进程把数据写入缓存，然后在进程把数据读取出来，那么就比较复杂了。我们的“表”要有能把数据在、两个进程间同步的能力。因此我们一般会用三种策略：租约清理、租约转发、修改广播
租约清理，一般是指，我们把存放某个的缓存的进程，称为持有这个的数据的“租约”，这个租约要登记到一个所有进程都能访问到的地方，比如是集群进程。那么在读、写发生的时候，如果本进程没有对应的缓存，就先去查询一下对应的租约，如果被其他进程持有，则通知对方“清理”，所谓“清理”，往往是指删除用来读的数据，回写用来写的数据到数据库等持久化设备，等清理完成后，在进行正常的读写操作，这些操作可能会重新在新的进程上建立缓存。这种策略在缓存命中率比较高的情况下，性能是最好的，因为一般无需查询租约情况，就可以直接操作；但如果缓存命中率低，那么就会出现缓存反复在不同进程间“移动”，会严重降低系统的处理性能。

租约转发。同样，我们把存放某个的缓存的进程，称为持有这个数据的“租约”，同时也要登记到集群的共享数据进程中。和上面租约清理不同的地方在于，如果发现持有租约的进程不是本次操作的进程，就会把整个数据的读、写请求，都通过网络“转发”个持有租约的进程，然后等待他的操作结果返回。这种做法由于每次操作都需要查询租约，所以性能会稍微低一些；但如果缓存命中率不高，这种做法能把缓存的操作分担到多个进程上，而且也无需清理缓存，这比租约清理的策略适应性更好。

修改广播。上面两种策略，都需要维护一份缓存数据的租约，但是本身对于租约的操作，就是一种比较耗费性能的事情。所以有时候可以采用一些更简单，但可能承受一些不一致性的策略：对于读操作，每个节点的读都建立缓存，每次读都判断是否超过预设的读冷却时间，超过则清理缓存从持久化重建；对于写操作，么个节点上都判断是否超过预设的写冷却时间，超过则展开清理操作。清理操作也分两种，如果数据量小就广播修改数据；如果数据量大就广播清理通知回写到持久化中。
这样虽然可能会有一定的不一致风险，但是如果数据不是那种要求太高的，而且缓存命中率又能比较有保障的话比如根据来进行一致性哈希访问缓存进程，那么真正因为写操作广播不及时，导致数据不一致的情况还是会比较少的。这种策略实现起来非常简单，无需一个中心节点进程维护数据租约，也无需复杂的判断逻辑进行同步，只要有广播的能力，加上对于写操作的一些配置，就能实现高效的缓存服务。所以“修改广播”策略是在大多数需要实时同步，但数据一致性要求不高的领域最常见的手段。著名的系统的缓存就是接近这种策略：我们要修改某个域名对应的，并不是立刻在全球所有的服务器上生效，而是需要一定时间广播修改给其他服务区。而我们每个服务器，都具备了大量的其他域名的缓存数据。

总结
在高性能的服务器架构中，常用的缓存和分布两种策略，往往是结合到一起使用的。虽然这两种策略，都有无数种不同的表现形式，成为各种各样的技术流派，但是只有清楚的理解这些技术的原理，并且和实际的业务场景结合起来，才能真正的做出满足应用要求的高性能架构。

相关推荐上一篇 高性能服务器架构思路 四 编码复杂度和通信自然、人类、商业，似乎测试无所不在。我们感叹大自然奇妙的同时，也被进化的奇妙所震撼。自有人类和商业以来，我们探索生产力和生产效率的脚步未曾停歇，而测试也在此种施展着奇妙的魔法。
那么不禁会问，测试的边界在哪里？
 
加拉巴哥群岛上生活着各种雀鸟，喙的大小形状各异。在旱灾导致食物匮乏的年份，鸟喙上仅仅毫米的长度差异就决定着雀鸟的生死。大喙的雀鸟磕开蒺藜的种子吃到食物，小喙的雀鸟则只能饿死，这便是自然选择。

大自然“设计出”喙大小不同的雀鸟不同的版本，让它们为生存做斗争，同样的环境下，喙的大小成为决定雀鸟生死的关键因素，这便是物种进化中大自然所做的测试。
“微小的差异决定了谁将生存，谁将毁灭”达尔文概括了测试的精髓：细节的累积最终决定成败。
 
年，一家美国公司推出了一种叫做“年轻人唱片俱乐部”的会员资格，他们在《纽约时报》进行推广，但一开始推广的效果并不好。这让另一家广告公司看到了机会，他们承诺能用科学的方法让推广效果提高。
为了探索不同广告的效果，这家广告公司在当天报纸上使用了两套不同的广告文案。一半的报纸以“让孩子进入音乐殿堂”作为主题，另一半登着直接诉诸父母的“帮助你的孩子进入音乐殿堂”的主题文案。不同的广告文案上用不同的通信地址以及不同的热线电话来区分计算哪种文案更有吸引力。经过实验对比他们发现，后者的效果是前者的。
在另一个分刊广告中，他们试验了营销手法的改变：从之前的每年需买张唱片一次付清货款，改为每月寄上唱片，每月结款，这一尝试把销量提升了。
之后，他们尝试把入会方式从至少需订购张唱片，放宽为没有最低限制且可随时取消会员资格，愿意加入的消费者增加了。减少广告上儿童形象的插花而增加唱片封面影像，则可提高的订购率。
经过一年的努力，广告的整体效果提升了一倍。这是测试在广告领域比较早期的尝试。广告行业对测试的探索从未停歇。多年前，广告之父   就说过这么一句话：           ！
 
让“  搜索体验”成为一种柏拉图式的理想：从来不会直接达到完美，只有通过不完美的推导和变化来实现。
年月日，  的工程师们进行了第一次测试。他们那时候想知道搜索引擎结果里每页显示的条目数，是不是对用户体验最好。他们拿出搜索引擎流量的，每页提供个结果；另一组个，还有一组个，对照组是默认提供的条结果。试验结束后依然采用条搜索结果。
由于技术故障，这不是一次成功的实验，但标志着测试在互联网领域应用的正式兴起。此后，  把测试用到了极致，到年，其搜索算法上运行了超过个测试，通过测试带来的优化每年为  带来超过亿美元的收入增长。
过去年里，测试的洪荒之力已经成为高风险  开发行业的公开秘密，现在已经是整个硅谷改进其在线产品的标准方式。
 
年月，时任民主党总统候选人的巴拉克奥巴马在山景城  总部发言时说：“我是一个忠实的信徒，坚信理性、事实、证据、科学和反馈，所有这一切才能让你做到你要做的事，这就是我们政府应该做的。”当时的  浏览器产品经理  也在场。
之后，  离开  作为数字顾问加入奥巴马竞选团队，为竞选团队引入一项关键技术——这项技术是  依赖于开发和完善其产品的一种管理理念，这开启了测试在政治领域的尝试。
 使用测试重新思考竞选网站的基本元素。他们最大的挑战是将网站的访问者转化为订阅者，并对所有的邮件地址进行评分，以便鼓励最终将活动邮件转化为捐赠。访问从一个背景为奥巴马的发光的绿松石照片和明亮的红色“注册”按钮的启动页开始，但是点击按钮的人太少了。在  的领导下，团队用新的精度来解决问题。他们把页面分为不同的组成部分，并为它们准备不同的替代选择。对按钮用个新单词进行了测试，“了解更多”、“立即加入我们”和“立即注册”，结果显示“了解更多”按钮每个访客的注册次数比默认值“注册”多。同样，奥巴马家族的一张黑白照片比默认的绿松石照片好，同时使用家庭形象和“了解更多”，注册惊人的增加了。
最令奥巴马团队震撼的是测试给直觉所带来的颠覆。工作人员几乎一致地以为奥巴马在一次集会上的演讲视频会胜过任何照片，但实际上，这个视频甚至比绿松石照片还差了。如果团队倾听了直觉，继续把“注册”作为按钮文本，把照片替换为视频，注册率将滑落到基准的。“假设往往是错的”，  简短地说。没有严格的数据收集和测试的控制，团队甚至可能不知道为什么他们的数字已经下降，并在对候选人的热情下降和劣质网站带来的下降之间混淆不清。相反，当比率上升到基准的的时候，团队知道应该归功于那些事，那些人。
到竞选结束时，收集到的万个邮件地址里大约有万个邮件地址，以及大约万美元的筹集资金由  的仔细试验产生。
竞选结束后，  功成身退。但他也被测试产生的惊人结果震撼到了，于是他和另一位  员工创办了  ，把测试的方法推给企业群体。
 
同样是一位  员工，在亲身见证了测试的神奇魔法之后，决定把这种科学的方法论和工具带回中国，推给更多的国内企业，于是有了吆喝科技。
两年，服务数百家企业，从网站到  ，横跨在线教育、金融证券、直播、电商、企业服务等多个行业，转化率的提升，用户体验的优化，决策风险的降低，营收的增长，测试与这些行业结合的意义可能远不止于此。或许还是科学决策与实验的文化，企业决策大脑的锤炼。
结语
  和   在他们合著的《灭绝的人类》一书这样写道：
在每一代中，越来越多的个体都能够活到成年并繁殖自己。那些成功的“最适合的”个体所携带的可遗传特征不仅提高了它们自身的生存能力，而且会优先遗传给后代。这样看来，自然选择只是将能够促进一些个体成功繁殖的所有因素以及其他个体中缺乏的因素汇总在一起的过程。再加上时间因素的作用，几代之后自然选择将改变每个进化世系的局面，因为有利变种会成为群体中的主体，而那些不太有利的变种则会被淘汰。
同样，在对产品的持续测试中，那些最成功的元素得到筛选，沉淀，在产品迭代中汇总在一起，时间的推力，会让这种细节的累积最终迸发出真正的价值。
那么，测试有边界吗？如果有，那它的边界会在哪？或许测试会有边界，但想象无界。在想象力的驾驭下，测试会有无限的场景与应用可能。
参考文献：
《直打正着》莱斯特·伟门《证析大数据与基于证据的决策》郑毅《灭绝的人类》塔特萨尔与施瓦兹 概念
英文名：  
是一种前馈神经网络，即表明没有环路，普通神经网络的  算法只是用于方便计算梯度，也是前馈神经网络。
是深度学习结构的一种，是一种深度、前馈神经网络。
可以使用  算法进行训练
                    
卷积神经网络的前提：输入是二维结构或者三维结构，但起比较大作用的是空间维度，深度那一维并没有太明显的作用。
 空间维度 
是宽和高，不包含深度
 什么是卷积

这条知乎解释得非常清楚！
卷积的离散和连续解释，其实就是求和符号和积分符号换一下而已
 中卷积的体现在于，在神经元的感受野里的输入和权重滤波器做点积，然后权重滤波器对整个输入在空间维度上一边移动一边做点积，然后求和，所以跟一般的卷积是在时间上移动不同的是，这里是在空间上移动。

这是二维离散卷积的表达方式，因为权重滤波器是在空间上移动，空间上是有高和宽两个维度的
 滤波器和输出数据体
滤波器是权重滤波器，是待学习的参数
输出数据体才是卷积层神经元
不同的滤波器的权重不同，表达的是对图片要素的关注点不同，比如说如果某个滤波器对红色敏感，即对于红色的像素点会有正向输出，那么扫描一张大部分是红色的图片的时候，该滤波器得到的   会有大面积的正向输出。所以说，滤波器是不同的特征提取器。
 卷积层的输出
滤波器在输入数据体空间上移动，得到一张  ，多个滤波器个数是超参数都与输入数据体进行卷积，会得到多张在深度方向上堆叠在一起的  ，然后呢，下一层的滤波器会把这些   的结果相结合作为输入，而不是把一个滤波器在空间移动后的点积结果相加，因为滤波器在扫描完整个输入体之后，得到的是一张  ，而不是一个值哦！所谓卷积中移动求和的概念，应该是体现在把点积的结果汇聚成一张  ，这也算是求了个和吧！然后一个卷积层的输出就是多个  在深度方向上的叠加。
一张   其实就是滤波器权重参数与小块输入的点积偏置，然后组在一起
  其实是这样的：

如图所示：× 个神经元的输出，每个神经元都只看它的感受野的输入，每个神经元的权重和偏置相同。神经元的输出也是 
上面的图只说明了一张  ，其实多张   就是深度方向上堆叠在一起的神经元的输出，只不过深度方向上的神经元不会共享权重和偏置，但深度方向上重叠的神经元的感受野是一样的。

 图片的表达转换
原始图像假如是一个 ×× 的输入数据体，经过一层卷积层的输出假设有  个 ×× 的滤波器  ，则变成了一个  的输出数据体，也就是说，图片的表达由原来的输入数据体来表达，变成了现在的输出数据体来表达。 
 参数的个数
每一个卷积层的参数个数是滤波器的感受野×输入深度×滤波器个数，比如滤波器的感受野是 ××，个数是 ，则这一层卷积层的参数个数是×= 个，其中加的那个  是偏置，也就是说一个输出数据体的整个深度切片上的神经元共享同一个权重向量，和同一个偏置，不同的深度切片的权重和偏置不同
 卷积层总结
卷积层接受 ×× 的输入数据体  
卷积层输出 ×× 的输出数据体
需要  个超参数：\\\
 代表滤波器个数， 是神经元视野即滤波器大小， 是  步长， 是 
根据超参数，可以由输入数据体的大小，计算出输出数据体的大小
=
=
=
因为参数共享，因此总共有  个权重和  个偏置参数
 补充
 视频中补充了一些可以进行卷积层计算的 ，其中提到一些计算框架
 是一个科学计算框架，内置大量的机器学习算法，  特性。 语言接口，底层是  实现。 –                   
 是一个深度学习框架，              
 是  中的一个轻量级的库，用于建立和训练神经网络
 –             。                  
 池化层  
  和   是两种常见的方法
输入的数据体是 ××，输出数据体是 ××
超参数有两个 ， 是  ， 是  即步长
=
=
=
没有参数，因为   计算的是      
对  ，不常用  
   
最后是一个   减少，但深度依然是滤波器个数的全连接层，这一层的数据体会全部和输出进行全连接
  层
无论是教学视频还是学习资料里都提到了  层，这其实让人难以理解，至少给我带来了困扰，因为  只不过是一种神经元激活函数而已，后来经过和大家的讨论，得出的结论是：其实就是卷积层的神经元的激活函数是  函数而已，即 × 中的 ，其中  和  之间是卷积而不是传统  中的点积。
  
        
 趋势
目前的趋势是使用更小的  和更深的结构
另外一个趋势是抛弃  和  层，只留下  层
 讨论
根据另一个同学的学习结论， 不但可以运用于图像，还可以运用于  即自然语言处理，不过在卷积层的参数设置，以及池化层的参数设置上有些不同，如下图所示。这是对自然语言语句进行二分类的  结构图，论文是《》。

①滤波器的空间视野，宽度需要与词向量的长度一致，高度可以自由调节，由高度的不同形成多个卷积层，同样的高度下可以由滤波器个数这个超参数形成多个  
②图中的步长为 ，因此绿色的高度为  的滤波器得到的   的高度就为 ，黄色的高度为  的滤波器得到的   的高度就为 ，这里的图像可以认为是侧面视角，宽度与滤波器宽度一致，看不到而已。
③池化层是  ，即整张   中只选择一个最大值！因此从  张   中就产生了一个一元的特征向量
④最后的  层就是把这个一元的特征向量作为输入，用来得到句子的类别
除了这些参数外，论文中还提出了一些有趣的结论，这里不一一列举，具体看论文：
①滤波器的视野高度选择，最好选择效果最好值的紧邻值，比如说  效果最好，那么就没有必要尝试 ，应该尝试  和  作为下一个卷积层的视野高度作者：

本文属于翻译文章，原文链接为  ’ 。是至今为止见过最好的  入门文章。额。。。没有之一。
这篇教程简单介绍了  并且讲解了一些  可以解决的简单任务。这里，我们假设  已经安装在读者的机器上。如果没有，可以看一下如何安装 。这篇教程主要讲解的是如何启用和停止，和重新加载配置，描述配置文件的基本结构和怎样搭建一个  静态辅助器，怎样配置  作为一个代理服务器来。
 有一个主进程和其他子进程。主进程的主要工作是加载和执行配置文件，并且驻留子进程。子进程用来作为实际的请求处理。 采取基于事件的模型和  依赖的机制，在多个子进程之间高效的分配请求。子进程的个数会直接写在配置文件中并且，对于给定的配置可以是固定的，或者根据可用的  核数自动的进行调整参考 子进程。
 和它模块的工作方式是在配置文件中写好的。默认情况下，这个配置文件通常命名为  并且会放置在 ，，或者 。
启用，停止和重载配置
运行可执行文件就可以开启 ，比如：
  为  的配置文件
  
如果， 已经开启，那么它就可以通过使用  参数的可执行命令控制。使用下列格式：
  
 可以为下列命令之一：

 — 直接关闭 

 — 会在处理完当前正在的请求后退出，也叫优雅关闭

 — 重新加载配置文件，相当于重启

 — 重新打开日志文件


比如，等待当前子进程处理完正在执行的请求后，结束  进程，可以使用下列命令：
  
执行该命令的用户需要和启动的  的用户一致。
如果重载配置文件的命令没有传递给  或者  没有重启，那么配置文件的改动是不会被使用的。重载配置文件的命令可以使用：
  
一旦主进程接收到重载配置文件的命令后，它会先检查配置文件语法的合法性，如果没有错误，则会重新加载配置文件。如果成功，则主进程会重新创建一个子进程并且发送关闭请求给以前的子进程。如果没有成功，主进程会回滚改动并且继续使用以前的配置。老的子进程在接受关闭的命令后，会停止接受新的请求并且继续处理当前的请求，直到处理完毕。之后，该子进程就直接退出了。
在  工具的帮助下，比如使用  工具，该信号会被发送给  进程。在这种情况下，信号会被直接发送给带有进程  的进程。 的主进程的进程  是写死在  文件中的。该文件通常放在  或者  目录下。比如，如果主进程的  是 ，为了发送  信号来使  优雅退出，可以执行：
   
为了得到所有正在运行的  进程，我们可能会使用到  工具，比如，像下列的方式：
   |  
 结果为：下面是单核  的情况
             = 
                   
                  
更多关于发送信号给 ，可以参考  控制。
配置文件结构
 是由一些模块组成，我们一般在配置文件中使用一些具体的指令来控制它们。指令被分为简单指令和块级命令。一个简单的指令是由名字和参数组成，中间用空格分开，并以分号结尾。例如：
 简单指令
 
块级指令和简单指令一样有着类似的结构，但是末尾不是分号而是用 { 和 } 大括号包裹的额外指令集。如果一个块级指令的大括号里有其他指令，则它被叫做一个上下文比如：，，，和 。
在配置文件中，没有放在任何上下文中的指令都是处在主上下文中。 和  的指令是放在主上下文中， 放在  中  放在  中。
以  开头的行，会被当做注释。
    
 {
  _      
}

 {
     { 
                
         _   
         _     
                  

           \ {
           _   
         }
    }
}
静态服务器
一个重要的网络服务器的任务是处理文件比如图片或者静态  文件。这里，你会实践一个例子，文件会从不同的目录中映射取决于请求：放置  文件和 放置图片。这需要配置一下文件，将带有两个  的指令的  的块级命令放在  指令中。
首先，创建一个  目录，然后放置一个事先写好内容的  文件。接着，创建一个  目录，然后放置一些图片。
下一步，打开配置文件。默认的配置文件已经包含了一些关于  指令的样式，大多数情况下直接把他们给注释掉。现在，注释掉其他的区块，然后写一个新的  区块：
 {
     {
    }
}
通常，该配置文件可能会包含多个  指令。这些  指令监听不同的端口和服务器名。一旦  决定哪个服务进程处理请求，它会根据在  块级指令中定义好的  指令的参数，来匹配请求头中指定的 。
将下列  指令添加到  指令中：
  {
     
}
该  指令相对于请求中的  执行了 “” 的前缀。为了匹配请求， 会被添加到  命令指定的路径后，即 ，得到本地文件系统中请求文件的路径。如果，有几个  匹配到，那么  会选择最长的前缀。上面的  提供了长度为  的前缀，所以，仅当其他的  匹配失败后，该指令才会使用。
接着，添加第二个  区块：
  {
     
}
它会匹配到以  开头的请求  也会匹配到该请求，只是前缀更短 块级命令的配置结果如下：
 {
      {
         
    }

      {
         
    }
}
这已经是一个可用的服务器配置，它监听标准的  端口并且可以在本地上通过  访问。对于  以  开头的请求，服务器会从  目录中，返回对应的文件。例如， 会返回  文件，当接收到  的请求响应时。如果该文件不存在， 会返回一个  错误的响应。没有以  开头的  的请求，将会直接映射到  目录中。比如，响应  的请求， 会发送  文件。
为了使用新的配置文件，如果还没开启  需要先开启，然后将重载信号发送给  的主进程，通过执行：
  
如果你发现有些地方出了问题，你可以在  或者  目录下的  和  文件中，找到原因。
搭建一个简易的代理服务
 常常用来作为代理服务器，这代表着服务器接收请求，然后将它们传递给被代理服务器，得到请求的响应，再将它们发送给客户端。
我们将配置一个基本的代理服务器，它会处理本地图片文件的请求并返回其他的请求给被代理的服务器。在这个例子中，两个服务器都会定义在一个  实例中。
首先，通过在  配置文件中添加另一个  区块，来定义一个被代理的服务器，像下面的配置：
 {
     
     

      {
    }
}
上面就是一个简单的服务器，它监听在  端口之前， 并没被定义，是因为默认监听的  端口并且会映射所有的请求给 本地文件目录 。创建该目录，然后添加  文件。注意， 指令是放在  上下文中。当响应请求的  区块中，没有自己的  指令，上述的  指令才会被使用。
接着，使用前面章节中的  配置，然后将它改为一个代理服务配置。在第一个  区块中，放置已经添加被代理服务器的协议，名字和端口等参数的 _ 指令在这里，就是 
 {
      {
        _ 
    }

      {
         
    }
}
我们将修改第二个  区块，使他返回一些典型后缀的图片文件请求，现在它只会映射带有  前缀的请求到  目录下。修改后的  指令如下：
  \|| {
     
}
该参数是一个正则表达式，它会匹配所有以 ， 或者  结尾的 。一个正则表达式需要以  开头。匹配到的请求会被映射到  目录下。
当  在选择  去响应一个请求时，它会先检测带有前缀的  指令，记住先是检测带有最长前缀的 ，然后检测正则表达式。如果有一个正则的匹配的规则， 会选择该 ，否则，会选择之前缓存的规则。
最终，一个代理服务器的配置结果如下：
 {
      {
        _ 
    }

      \|| {
         
    }
}
该服务器会选择以 ，，或者  结束的请求并且映射到  目录通过添加  给  指令的参数，接着将其他所有的请求映射到上述被代理的服务器。为了使用新的配置，像前几个章节描述的一样，需要向  发送重载信号。
这还有很多其他的指令，可以用于进一步配置代理连接。

原文链接：


相关推荐网站使用之后禁止用户真实访问的方法【腾讯云的种玩法】   负载均衡配置详解前言
在此之前，玩九宫格数独一和 玩九宫格数独二分别介绍了如何从九宫格图片中提取出已知数字和如何用训练数字识别模型。在这些前期工作都已经完成的基础上，接下来我们需要做什么呢？
我们要做的有三部分：
生成九宫格，也就是生成一个的矩阵，把已知的数字按照图片中的位置填到矩阵中的相应位置，其他位置全部置。
编写数独求解算法，对九宫格矩阵进行求解。
把填完的九宫格重新填充到图片中去。
我们仍然是一步一步来说。
生成九宫格
这里就需要用到我们之前两篇的内容了，生成九宫格的步骤如下：
从九宫格图片中提取数字第一篇内容

用训练的数字识别模型对上一步的数字进行识别。
这里需要注意的是，提取之后的数字，要按照训练模型之前的数据处理方式进行处理，然后输入模型识别。识别效果如下图所示。就像上一篇结尾说的一样，本文用不到一百个样本训练出来的模型仅仅能保证在本文的示例图片上取得完美效果。其他情况下不作保证。如果想要得到更完美的数字识别模型，请优化数据预处理方式和加大数据量。

按照位置顺序把数字填入相应的矩阵位置中。
矩阵初始化为零阵
 =  

然后按照位置求解数字在矩阵中所处的位置
 求在矩阵中的位置    
__ = 

得到的矩阵如下所示：

跟上面的图片比较一下，是不是位置一样呢？
编写算法求解九宫格矩阵
数独的求解算法有很多种，热爱数独的且热爱数学的人对此进行了深入研究，提出了各种各样的算法。这里用的是传说中的回溯法。回溯法具体内容感兴趣的可以自行搜索，我这里只是用，没有深究。
至于为什么用这个算法？。。。因为我在上找到了可用的代码捂脸逃
代码里标注了出处：

 数独求解算法，回溯法。来源见下面链接，有细微改动。

 
   
       
           
              == 
                 
       
           
              == 
                 
     

    
     =  =     
     
         =  =     
         
                         
              =    
                
                    
                      == 
                         
                 
     

  = =
     =   
      == 
         
       
         
             = 
               
                 
                  
             = 
     

然后我们根据算法对前面生成的数独求解。只需要这么一句就行：



这里为了便于观察，分别原始数独、求解后的数独，为了验算，输出结果数独的每行每列的和，如果求解正确，每行每列和都应该等于=。
\生成的数独\

\求解后的数独\

 数独求解



\验算：求每行每列的和\
_ = 
_ = 
_
_

输出的结果如下：

最后两行可以看到各行各列的和确实都是。数独求解成功。
在黑窗口里看最后的数独可能不那么友好，接下来我们就把生成的九宫格填充到图片里来看。
填充图片九宫格
我们只需要在图片中九宫格中相应的位置写相应的数字就可以了，这一部分乏善可陈。还是直接看代码和效果图吧。
 把结果按照位置填入图片中  
   
       
         = _
         = _
               _
_
 _
 


最后的效果你应该在预告篇就看到过了。为了便于对比，保留了上一步数字识别的结果。

尾声
到此，整个玩数独项目告一段落。容我感慨几句。
玩数独项目最早可以追溯到一年前，那时候就开始尝试用来对数独图片进行处理，但是最终受限于当时的水平和心态，只完成了一小半。为什么说心态呢？因为那时候很多东西不会的也不敢去尝试，如果当时敢于尝试，畏难心理没有那么重的话，也许这个项目会提前很久完成。
其实我本来最擅长的是的，然而最近用越来越顺手了。这个项目坐下来受益最大的显然是我自己。分享出来，感兴趣的人也许会有很多，但是真正会去做一遍的应该没有几个。会完整做下来的应该更是寥寥无几。
这个小项目都对高手来说也许不算什么，但是对于初学和的人来说应该是一个不错的锻炼。希望有人能做一遍，能做下来的相信会做的更好。欢迎感兴趣的人来一起交流学习。
代码
：

相关推荐
 玩九宫格数独：预告篇 玩九宫格数独一：九宫格图片中提取数字 玩九宫格数独二： 数字识别翻译： 科技大本营参与 ： 姜沂，焦燕

导语
机器学习中的模型参数和模型超参数在作用、来源等方面都有所不同，而模型超参数常被称为模型参数，这样，很容易对初学者造成混淆。本文给出了模型参数和模型超参数的定义，并进行了对比，指出了二者本质上的区别：模型参数是模型内部的配置变量，可以用数据估计模型参数的值；模型超参数是模型外部的配置，必须手动设置参数的值。
我们在做研究的时候，会碰到很多术语。有时，在不同的研究领域还会出现同样名称的术语。比如，统计学、经济学中经常使用的“模型参数”和“模型超参数”，在机器学习中也同样存在。
机器学习领域中的“模型参数”“模型超参数”在作用、来源等方面都有所不同，初学者如果对二者没有明确的认识，学习起来往往会比较吃力，尤其是那些来自统计学和经济学领域的初学者们。
为了让大家在应用机器学习时，对“参数模型”和“超参数模型”有一个清晰的界定，在这篇文章中，我们将具体讨论这两个术语。
首先，我们来看一下“参数”是什么？
参数作为模型从历史训练数据中学到的一部分，是机器学习算法的关键。
统计学中的“参数”：

在统计学中，你可以假设一个变量的分布，比如高斯分布。高斯分布的两个参数分别是平均值μ和标准差。这在机器学习中是有效的，其中这些参数可以用数据估计得到并用作预测模型的一部分。

 编程中的“参数”：

编程中可以将参数传递给函数。在这种情况下，参数是一个函数参数，可以有一个值范围。在机器学习中，您正在使用的具体模型就是函数，需要参数才能对新数据进行预测。

“参数”和“模型”有什么关系？
根据经典的机器学习文献，可以将模型看作假设，而参数是根据特定的数据集对假设进行的具体调整。
模型是否具有固定或可变数量的参数，决定了模型是“参数”模型或“非参”模型。
什么是模型参数？
简单来说，模型参数就是模型内部的配置变量，可以用数据估计它的值。
具体来讲，模型参数有以下特征：

进行模型预测时需要模型参数。
模型参数值可以定义模型功能。
模型参数用数据估计或数据学习得到。
模型参数一般不由实践者手动设置。
模型参数通常作为学习模型的一部分保存。

通常使用优化算法估计模型参数，优化算法是对参数的可能值进行的一种有效搜索。
模型参数的一些例子包括：

人造神经网络中的权重。
支持向量机中的支持向量。
线性回归或逻辑回归中的系数。

什么是模型超参数？
模型超参数是模型外部的配置，其值不能从数据估计得到。
具体特征有：

模型超参数常应用于估计模型参数的过程中。
模型超参数通常由实践者直接指定。
模型超参数通常可以使用启发式方法来设置。
模型超参数通常根据给定的预测建模问题而调整。

怎样得到它的最优值：对于给定的问题，我们无法知道模型超参数的最优值。但我们可以使用经验法则来探寻其最优值，或复制用于其他问题的值，也可以通过反复试验的方法。
模型超参数的一些例子包括：

训练神经网络的学习速率。
支持向量机的和超参数。
邻域中的。

“模型参数”和“模型超参数”
二者的联系：

当针对特定问题调整机器学习算法时，例如在使用网格搜索或随机搜索时，你将调整模型或命令的超参数，以发现一个可以使模型预测最熟练的模型参数。许多模型中重要的参数无法直接从数据中估计得到。例如，在近邻分类模型中这种类型的模型参数被称为调整参数，因为没有可用的分析公式来为其计算一个合适的值。

第页，应用预测建模，


区分：

模型超参数通常被称为模型参数，这种叫法很容易让人产生误解。解决这个问题的一个很好的经验法则如下：如果你必须手动指定一个“模型参数”，那么它可能就是一个模型超参数。

进一步阅读

超参数维基百科 
什么是机器学习中的超参数？ 
模型超参数和模型参数有什么区别？
什么是超参数？

总结
读完这篇文章可以了解模型参数和模型超参数的明确定义和区别。
总而言之，模型参数是从数据中自动估计的，而模型超参数是手动设置的，并用于估计模型参数的过程。

原文链接：作者 | 周东谕编辑 | 京露

周东谕，年加入腾讯，现任职于腾讯互娱运营部数据中心，主要从事游戏相关的数据分析和挖掘工作。            

信息增益原理介绍
介绍信息增益之前，首先需要介绍一下熵的概念，这是一个物理学概念，表示“一个系统的混乱程度”。系统的不确定性越高，熵就越大。假设集合中的变量={…}，它对应在集合的概率分别是={…}。那么这个集合的熵表示为：

举一个的例子：对游戏活跃用户进行分层，分为高活跃、中活跃、低活跃，游戏按照这个方式划分，用户比例分别为，，。游戏按照这种方式划分，用户比例分别为，，。那么游戏对于这种划分方式的熵为：

同理游戏对于这种划分方式的熵为：

游戏的熵比游戏的熵大，所以游戏的不确定性比游戏高。用简单通俗的话来讲，游戏要不就在上升期，要不就在衰退期，它的未来已经很确定了，所以熵低。而游戏的未来有更多的不确定性，它的熵更高。
介绍完熵的概念，我们继续看信息增益。为了便于理解，我们还是以一个实际的例子来说明信息增益的概念。假设有下表样本

第一列为，第二列为性别，第三列为活跃度，最后一列用户是否流失。我们要解决一个问题：性别和活跃度两个特征，哪个对用户流失影响更大？我们通过计算信息熵可以解决这个问题。
按照分组统计，我们可以得到如下信息：

其中为正样本已流失，为负样本未流失，下面的数值为不同划分下对应的人数。那么可得到三个熵：
整体熵：

性别熵：


性别信息增益：

同理计算活跃度熵：   

活跃度信息增益：

活跃度的信息增益比性别的信息增益大，也就是说，活跃度对用户流失的影响比性别大。在做特征选择或者数据分析的时候，我们应该重点考察活跃度这个指标。
使用 实现信息熵的计算
从表中我们不难发现，在计算信息熵和信息增益之前，需要对各维度做汇总计数，计算各公式中出现的分母。 中，能帮助我们很快的做汇总计算，话不多说直接上代码：


_
_  
__  计算信息增益率的分母
___  _信息增益率计算


     
    _
    _
    _
      对于整体熵，要记得更换符号的出现是防止计算得
     
     _=  ________
     ________
       
    
    
         
        _
        _
          _=  _     _
          _=  _     _
          _=  _     _
        
        
             
            _
              对值和值做汇总统计，、用于熵计算的分母，、计算整体熵情况
              _=    _   _
              _=    _   _
              _
            
                            
                 ___  _

              ___
          __
    
  

     信息增益计算时，需要给出样本总量作为分母
     _    _
      _
  _=_
  _
数据表结构如下：

关键步骤说明：
：各特征的熵计算

：各下的信息增熵

信息增益计算结果：

结束语：
以上为信息熵计算过程的版本，其关键点在于使用实现了和所需要的汇总计算。需要的同学只需要按照规定的表结构填入数据，修改代码即可计算信息增益。文中如有不足的地方，还请各位指正。
参考文档
 算法杂货铺——分类算法之决策树 

 为什么使用信息增益比来选择特征？


相关推荐
接下篇《一条搞定卡方检验计算》作者：， 腾讯前端开发 高级工程师

小程序科普类的文章已经很多了，今天这里讲的是针对小程序的优化方法，可以有效提高小程序的响应速度和用户体验。当然，开发体验也提高不少。
、提高页面加载速度
在小程序这个环境下，怎样提高页面加载速度呢？ 这个问题很大，我把问题具体一下，如何缩短从用户点击某个链接，到打开新页面的这段时间？ 这里抛一个核心关键点：

从页面响应用户点击行为，开始跳转，到新页面事件触发，存在一个延迟，这个延迟大概在之间安卓响应比慢些。

这个延迟说短不短，我们可以利用这段时间，预先发起新页面所需要的网络请求。这样一来，就节省了或者一个网络请求的时间。
知道有这个后，代码如何实现呢？
说白了，就是实现一个在页面预加载页面数据的功能。但而这种跨页面的调用，很容易把逻辑搞复杂，将不同页面的逻辑耦合在一起。所以，我们希望将预加载的逻辑隐藏于无形中，不增加任何的页面间耦合，以及开发复杂度。
下面以腾讯视频小程序为例，讲解下技术实现。
小程序首页：

当用户点击海报图后，会执行以下代码就一行：

接下来程序会加载播放页：

播放页主要代码：

可以看到，不管是外部页面的调用还是实际逻辑的实现都非常简洁。在第二个页面中，我们扩展了的生命周期函数，增加了方法。该方法在页面即将被创建但还没开始创建的时候执行。

老司机也许会发现这里有点蹊跷。在首页点击的时候，播放页根本就没有创建，对象都不存在，怎么访问到里面的方法呢？

这里就要说下微信的页面机制。
在小程序启动时，会把所有调用方法的存在一个队列里如下图。每次页面访问的时候，微信会重新创建一个新的对象实例实际上就是深拷贝。
也就是说，在页面在执行点击响应事件的时候，页面的实例还没创建，这时候调用的方法，实际上是对象的原型小程序启动时候创建的那个。
而接下来马上要被创建的页面，又是另外一个。所以，在和方法中，指针指的不是同一个对象，不能把临时数据存储在当前身上。因此我们封装了一对全局的缓存方法，和。

为了通用性，上用到的公共的方法，比如、、都定义在了一个的基类里面。基类还同时保存了所有页面的，这样就可以做到根据页面名调用具体页面的方法。 当然，并不是每个页面都需要实现方法，对于没有定义方法的，函数会跳过预加载环节，直接跳转页面。所以对于开发者来说，不需要关心别的页面实现了什么，对外看来完全透明。
、用户行为预测
在上面的例子中，我们实现了用户主动点击页面，提前加载下一页面数据的方法。而在某些场景下，用户的行为可以预测，我们可以在用户还没点击的时候就预加载下个页面的数据。让下个页面秒开，进一步提升体验的流畅性。
继续以腾讯视频小程序为例，主界面分为个页卡大部分小程序都会这么设计，通过简单的数据分析，发现进入首页的用户有会访问第二个页卡。所以预加载第二个页卡的数据可以很大程度提高用户下个点击页面的打开速度。
同样，先看看代码实现。 首页预加载频道页的姿势：

频道页的实现方法：

跟第一个例子类似，这里定义了一个方法，同时给扩展了一个事件。页面调用后，基类会自动找到该页面对应的函数，通知页面执行预加载操作。 跟第一个例子不同，这里预加载的数据会保存在内，因为用户不一定会马上访问页面，而把数据存在全局变量会增加小程序占用的内存。微信会毫不犹豫的把内存占用过大的小程序给杀掉。
也许对于大部分有开发经验的同学来说，更普遍的做法是先让页面展示上次缓存的数据，再实时拉取新数据，然后刷新页面。这个方法在小程序上也许体验并不太好，原因是小程序的性能以及页面渲染速度都不如原生。将一个大的传输给层，是一个很重的操作。因此不建议采用这种方法。
、减少默认的大小
刚刚说到，页面打开一个新页面时微信会深拷贝一个对象，因此，应该尽量减少默认的大小，以及减少对象内的自定义属性。有图有真相：

以一个个属性的对象为测试用例，在上，页面的创建时间会因此增加。
、组件化方案
微信没有提供小程序的组件化方案相信一定在实现中。但开谈不说组件化，写再多代码也枉然。这里演示一个简单的组件化实现。
以腾讯视频播放页为例，页面定义如下：

其中，函数是自定义的基类。这是一个非常有用的东西，可以把所有通用的逻辑都写在基类里面，包括统计，来源统计，扩展生命周期函数，实现组件化等。
函数第一个参数是页面名称，作为页面的。第二个是对象，其中扩展了一个数组，里面就是所有要加载的组件。
以播放器组件为例：

组件的定义跟一个普通对象一模一样，有属性，、等事件，也有页面响应的回调方法。模板里定义的事件和事件一一对应。
基类做的事情，就是把这些组件对象的属性和方法复制到对象上浅拷贝。其中属性会到一起。而微信预定义的生命周期函数包括自己扩展的，则封装成队列按序执行。比如当系统调用方法时，实际上是执行了所有组件的方法，最后再执行的。
以上是代码部分，至于模板和部分，就要手工过去了。
：

：

、其他
虽然小程序已经足够小巧，但启动速度还是有那么秒，无法做到秒开。楼主尝试对小程序的启动时间做优化，但没有找到多少有价值的优化点。单个页面的初始化只需要。也许大部分时间消耗在了微信跟服务器端通信的过程中。
所幸，腾讯提供了一个可以自主进行服务器性能测试的环境，用户只需要填写域名和简单的几个参数就可以获知自己的服务器性能情况，目前在腾讯平台可以免费使用。
腾讯服务器性能测试运用了沉淀十多年的内部实践经验总结，通过基于真实业务场景和用户行为进行压力测试，帮助游戏开发者发现服务器端的性能瓶颈，进行针对性的性能调优，降低服务器采购和维护成本，提高用户留存和转化率。
功能目前免费对外开放中，欢迎大家的体验！
体验地址：
如果对使用当中有任何疑问，欢迎联系腾讯企业：
商业转载请联系腾讯获得授权，非商业转载请注明出处。 
原文链接：近年来，随着生命科学行业的不断发展，生物基因领域数据爆炸式地迅速增长，如何快速传递、安全存储、高效计算这些数据，是基因企业、科研工作者面临的新挑战。
月日，在第届全国功能基因组学高峰论坛上，腾讯云与百迈客生物科技宣布达成战略合作，并正式发布生物基因解决方案，开放腾讯云计算、存储、人工智能等各项能力，助力生物基因行业发展。腾讯云深度定制云商务总经理付雪冬
腾讯云携手百迈客，共谋基因科技服务时代
会上，腾讯云与百迈客生物科技达成战略合作。双方将在基因科技服务、基因云计算等多个领域开展深度合作，共谋基因科技服务时代。

腾讯云开放能力，助力行业发展
腾讯云将全面开放各项能力，在传输、存储、计算、管理和洞察等个方面，助力生物基因行业全面快速发展。基因数据量的暴增带来的是传输的难题。目前腾讯云已经建成国内最全的线网络环境。老师和医生，不管是在教育网，还是其他运营商的网络里，都可以很快速、稳定地向腾讯云上传和下载数据。
腾讯云还提供专线和专业数据迁移服务，帮助百迈客这样的合作伙伴做数据上云。同时，为了帮助百迈客这样的基因企业方便地传递数据给科研用户，存储于腾讯云的数据，还可以实现一键分发的功能。
解决好了传输，面对不同的数据使用场景和需求，腾讯云可以提供文件存储、对象存储和归档存储等不同场景的存储服务。针对最核心的计算环节，腾讯云上周刚刚在全国高性能计算学术年会上发布了超算云服务，科研工作者和基因企业现在可以腾讯云上选择多种高性能的虚拟机和物理机来加速基因计算，包括和机型。
除网络、计算和存储之外，腾讯云希望给行业带来更大的附加价值，所以非常关注管理和洞察。一方面开放蓝鲸这一类管理工具来帮助基因用户更好地管理和监测业务运行状况，另一方面也通过人工智能的能力协助科研工作者们更好地洞察科研对象。
腾讯云发布双螺旋平台
除此之外，为了帮助科研工作者快速基于云计算开展科研工作，腾讯云针对基因行业专门开发了一个新的平台，腾讯云双螺旋平台。
腾讯双螺旋是一个一体化的数据管理平台，基因用户可以在它上面对进行传、存、算、管的各项工作。
腾讯云双螺旋解决的问题主要有三点，第一是快速，腾讯云已经在双螺旋上使用来加速基因分析过程。对二代测序，已经可以节省的时间，后续会继续推出三代加速的服务。第二点是节省，依托双螺旋的精准调度能力，在计算每个过程中，双螺旋会按需调度最匹配的算力在执行任务，避免出现或内存大量空跑的情况，帮助基因用户节省费用。第三个点是赋能，也就是人工智能的应用。
目前腾讯云的已经精准医疗领域应用。在广东，腾讯觅影在帮助医生做早期食道癌的筛查。对一张内镜检查影响，觅影可以在秒内做出诊断，它的准确率已经达到了。与此同时，腾讯云还正在训练做肺癌等其他疾病的诊断。未来，这些能力，将来都会在双螺旋上开放。
用技术加速业务发展，腾讯云将持续与生命科学领域的合作伙伴一道，推动精准医疗落地，普惠社会。存储系统，是非常普遍的需求，几乎每个在线的互联网后台服务都需要存储，我们团队在存储方面，经历过几个时期，我自己深感要做好不容易。
这里扯远一点，展开说一下：
第一个时期，很早期的时候，我们的数据存储在表里，按照用户账号简单的分库分表，为了保证访问高并发，利用每个服务器的内存做数据缓存；主备两套分布在不同，业务逻辑自己做副本同步。当时主要的问题是：内存的数据结构扩展困难、运维工作琐碎、数据同步机制本身的缺陷导致不能做异地部署，这些缺点对于业务飞速发展、一地机房已经不够用的局面非常被动
第二个时期，我们设计了新的存储系统，其用户数据结构容易扩展、具备可以多地部署的数据同步机制，很好的应对了新时期业务发展的需要。为了设备成本考虑，我们把数据做冷热分离，访问频繁的数据会加载到专门的层，且对于不同的访问模型，挂载不同架构的，另外一个层专门做数据持久化。这样的设计，使得架构太复杂，收敛速度慢，运维工作相比以前甚至更复杂了。
第三个时期，为了应对普遍的存储需求，我们以公共组件的形式重新设计了存储，作为团队标准的组件之一，得到了大规模的应用。结合同期抽象出来的逻辑层框架、路由管理等其他组件，团队的公共基础组件和运维设施建设的比较完备了，整个业务的开发和运维实现了标准化。但这个阶段就用了我们团队足足年多时间。
不同于无数据的逻辑层框架，存储系统的架构设计会更复杂、运维工作更繁琐、运营过程中可能出现的状况更多、收敛时间会更长。一句话：团队自己做一个存储系统是成本很高的，而且也有比较高的技术门槛。
设计一个存储，需要考虑至少这些方面：

如何组织机器的存储介质，通常是内存、磁盘文件；例如用的方式组织内存

如何设计用户的数据结构，使得通用、易于扩展、存储利用率高；例如序列化、、方式

友好的访问接口，而不只是  一整个

如何做集群分布、如何、如何做到方便的扩缩容；例如一致性算法

如何做数据冗余、副本间如何同步、一致性问题；副本间如何选举

备份与恢复、数据校验与容错

读写性能

其他可能的特殊需求：例如我们设计过一个存储，用于存储一些公众号的个数不受限粉丝列表


上面八点，业内的存储组件一般都会考虑到，或者各有特色，各自优势在伯仲之间。但是综合过去的经验教训，我们觉得有一点很容易被忽视：可运维性、运维自动化、黑盒化运维。
举一个例子，前面提到的我们第二个时期的存储系统，刚开始应用的时候，一次扩容过程会有多步的运维操作，包括数据、做增量同步、多次修改机器状态、数据比对等等，需要运维同事以高度的责任心来完成。另外就是运维同事必须如该存储架构设计者一样深刻理解系统背后的原理和细节，否则就不能很好的执行运维操作，这个要求也非常高，新老交接周期长，还容易出运维事故。
基于上面的考虑，同事为了让用户更容易学习和接受，毫秒服务引擎在 的基础上，实现了运维化，并加上了集群的监控。
毫秒服务引擎 取英文名    的首字母组合是腾讯一个开源框架，其创作冲动和构建经验，来自后台团队超过年的运营思考。官网
毫秒引擎可以通过界面方便的进行：

集群概要状态查看



可以在上方便的完成日常的运维操作：新搭集群、扩缩容、故障机器的恢复：



请求量、内存使用、等各种状态信息可直观监控，也可以按粒度查看


限于篇幅和时间限制，详细的可见腾讯云服务市场、毫秒服务引擎官网，或者微信公众号李琦，年加入腾讯网络平台部。之前曾负责公司海量运营系统的规划设计，如、、、、等网络运营平台，以及参与腾讯云云主机、云网络、云安全等基础产品规划和大客户的需求管理。目前主要聚焦在私有云基础架构的统一监管控，把腾讯基础架构的自动化管理能力以产品化方式输出。

一、引言
云计算经过多年的发展，逐渐从概念到渐为人认知、到接受、到现在全行业拥抱上云，云的客户也从最初的中小初创互联网企业为主，逐步渗透到大型互联网企业、金融企业、传统企业，甚至到大型央企政企。
因此，为了应对不同客户的市场需求，云的形态也开始多样化，根据客户对资源控制权的不同，基本分为以下几类：

图 云的集中形态
在传统公有云中，计算资源主要是虚拟机的形态，以至于在云计算早期一段时间内，大部分人认为云计算技术 = 虚拟机技术，这种形态下的云，你只能接触到虚拟机，任何物理资源对你都是透明的；当这些物理资源产生冲突时，势必会影响到你的业务，所以当业务要求越来越高，他们对资源的控制权也慢慢提升，希望能独享物理机，就有了裸机云；进一步，他们还希望能自定义组网，方便其原有业务的迁移或重新规划，于是有了黑石云的解决方案顺便提一下，其实“黑石”的核心是支持的虚拟网络，而非外界解读的物理机售卖；到最后连数据中心也要求独享，就有了私有云。这时，相当于裸奔了，原来隐藏在客户背后的供应链管理、运营支撑管理、异常发现和处理等机制、系统稳定性易用性安全性、运维背后的人海战术等，都表露无遗，要把数据中心真正“交”给客户，不是那么简单的。
二、公有云  私有云
关于私有云和公有云的，业界一直有争论，大部分都认为公有云才是未来，私有云是历史的倒退，尤其是技术发展的倒退，觉得这东西就是以前传统系统集成商干的事情，不是互联网人变革的上流新事情。其实，这种说法是片面的，他们只看到了“私有”这部分，要“私有”并不难，但关键是在“云”这部分，即提供一套私有云管理系统，实现整个的自动化闭环管理，由之前的手工管理变成系统管理，减低用户的使用门槛。从某种程度来讲，私有云其实是公有云发展到一定阶段成熟后，一种产品化的结果，也是能力输出的一种最极致的表现。
另一方面，受限于安全合规的要求和商业竞争的考虑，传统金融尤其银行证券、央企国企政企和大型传统企业，一般不会把核心业务放在公有云上，宁愿花更大的成本代价，也要以私有化独享的形态来掌控自己的核心业务，因此，在很长一段时间内，私有云或混合云，都还是这些金主的主要考虑方案。
三、 诞生
关键词：站在巨人的肩膀，服务器网络融合
为什么会有？
去年，腾讯云迎来了一位新筹民营银行客户 ： 上海华通银行。
如下图，按银监会的要求，金融机构基本都是两地三中心，之间通过腾讯的互联，访问公网则通过腾讯的，他们的和腾讯内部是不能互通的，因此是独立隔离的私有环境。在外部接入方面严格控制，通过 实现点对点接入，从物理层面来做安全防护，接入后，再通过云管理门户，实现对所有资源的管理。

图 银行私有云整体网络示意图
在公有云环境中，用户只需要接触到虚拟的云资源，比如云主机、云硬盘、云数据库等，公有云会提供配套的自动化管理系统，对这些云资源进行管理，如生产、分配、回收等。但在私有云的环境里，所有基础架构设施均由用户自行管理，包括物理服务器资源的初始化安装、远程开关机、重启和部署重装等操作，如果还是通过以往人工和现场的方式来管理，效率会非常低，进而影响到云资源的管理。因此，在私有云的环境里，需要有一套类似云资源管理的自动化系统，实现物理服务器资源导入、自动发现、电源管理、系统部署、配置初始化和回收等生命周期的自动化管理，就是在这样的需求背景下应运而生的。
的产品定位
全称   ，顾名思义，定位是数据中心操作系统，这是一个很泛的叫法，业界完全对标的独立产品几乎没有。回顾 这年多摸着石头的不断探索、思考，经过近个迭代版本的试错验证，从设计到开发到应用落地，慢慢其定位也越来越清晰–私有云的物理基础架构管理引擎。如果参考行业私有云老大 – 的模型，正好补充了对物理资源监管控能力，如下图红框部分：

图 逻辑架构图
下面分别从两个维度介绍一下的定位：
从资源管理的角度看：私有云里会有腾讯自采物理资源腾讯标准服务器和网络设备、客户托管设备和云产品虚拟机、云储存、云负载均衡、云数据库等，定位是负责腾讯自采物理资源的监管控，同时提供中心化的，实现基础架构设施数据的资源管理。从逻辑功能的角度看：如果把数据中心当作一个整体业务，最低配的银行私有云至少包括四大模块：接入层模块、逻辑层模块和虚拟化模块、数据层模块，负责外部或内部的负载均衡接入，和分别负责物理和虚拟资源的逻辑处理如生产、监控、再分配、回收等，则是提供金融级数据库集群。
的设计思想
和支撑腾讯海量业务的需求场景不同，主要是面向传统企业，支撑大概万台服务器含虚拟机规模的私有环境，产品设计上和现在内部系统会很大的差异，重点不是物理分布式架构和高并发能力，而是高度集成、轻量简单、易部署、易运维、易扩展：

图 设计理念
的产品解决方案
的产品解决方案如下图，按其功能主要分为四大子产品：

图 产品解决方案
：涵盖了服务器、网络设备、网络端口、机架机位、专线、出口、资源等物理信息的生命周期管理，基于腾讯多年运营经验而建立其模型，并提供智能审计模块，形成数据管理闭环，保证基础数据的完整性和准确性。最终，以方式提供给或其他云组件，并封装好常用的裂解分配回收和服务器搬迁等流程逻辑。

图 的关系项
  ：物理裸机管理引擎，负责物理裸机的自动发现、带外管理、自动化部署、命令下发文件传输等自动化管控运维，通过外部扩展，还可以实现私有云其他组件，如控制节点、计算节点、存储节点等初始化部署。
：服务器和网络融合的一站式监控引擎，涵盖服务器基础采集、服务器硬件部件采集、服务器进程端口采集、自定义业务采集、网络设备采集、网络质量探测、网络应用数据流分析，并支持把原始监控数据转发第三方平台。
：服务器和网络融合的一站式告警引擎，实现服务器硬件异常告警、服务器性能状态告警、服务器进程端口告警、网络设备性能和状态告警、网络设备日志告警、网络质量告警、自定义业务数值字符告警，并支持把原始告警数据转发给第三方平台。
从业务场景讲，希望实现从物理资源准备、生产到运营的闭环管理如下图：

图 的业务场景
资源准备阶段：经过上游资源的申请、采购、建设交付后，得到物理配置信息和资源规划信息资源等，并导入的，建立基础架构设施数据的；
资源生产阶段：现场把服务器物理上架，并接上电源线后，即可进入远程管理阶段，服务器会通过带外自动发送请求到；根据信息进行配置验收无误后，分配带外、标记为“已开电”状态，并纳入裸机资源池；然后通过带外即可远程初始化、开机、关机和重启；当接收到上层部署需求初始密码等后，会远程触发服务器进入状态，在环境通过获取部署，通过拉取对应的镜像和配置文件，完成部署，并通过后置初始化脚本，实现网络的配置，以及应用组件的批量部署，实现私有云的初始化，全程可以做到服务器 ；
资源运营阶段：服务器和网络设备的监控采集和异常故障告警，以及服务器和网络设备的日常运营管控。

图 管理控制台
的技术解决方案：
逻辑架构

图 的逻辑架构图
采用模块化设计，每个模块红框负责部分功能，如负责带外部署，负责服务器信息采集管理，负责配置管理等。模块可单独部署，成为独立的产品组件。模块之间基本没有依赖性除外，维护和故障排查起来比较方便，同时易于进行模块扩展。
模块内部采用分层式设计，负责模块接入，可进行任务调度、数据存储等控制逻辑，完成任务执行、数据转发等，在业务机器上负责信息采集、文件传输等。模块化分层式设计，使得结构清晰，容灾方案也相对简单。
软件交付方式
为了实现离线部署，以软件包或镜像形式交付，部署在物理服务器上。
软件部署方式
采用模块化分层式设计，支持集中式部署和分布式部署。集中式部署：除部署在业务服务器外，其它程序部署在一台控制服务器；分布式部署：分为中央控制服务器如、、、区域控制服务器如、、和部署在业务服务器，可实现多机房或区域的统一管理。
所以说， 是站在巨人的肩膀上，把网平多年来海量运营经验和工具系统进行了系统化的沉淀、浓缩，并结合私有云的和传统企业需求场景的一次全新的能力输出，服务器和网络融合管理的一次新尝试。


图 系统演进
四、  成长展望
关键词：拥抱外部环境，走出自己的路随着逐步成熟，以及外部客户需求的“洗礼”，从开始，逐步拥抱外部环境，抛开腾讯海量标准化机制的一些束缚，增加客户环境适配和自定义的能力，走出自己特色的路。

图  的自定义能力
集成第三方组件监控
涵盖主流中间件数据库虚拟机容器和开源组件的常用指标，开箱即用。

图 集成的第三方组件
自定义监控
能适配不同厂家型号指标的信息采集，实现了一套采集通用框架，用户只需要定义好网络设备采集模板，系统即能自动识别通用和设备的私有，实现的统一采集调度和数据处理加工，解决不同私有云客户的网络设备兼容问题。
自定义业务监控和告警
监控和告警与 项解耦，支持用户自定义对象如集群、集群、交易数据、多维指标数据如地域、门店、支付方式、交易金额等的接入，和之前项特性的一维度管理机制相比，更通用、门槛更低、更贴近外部客户的场景，尤其在业务监控方面。 
服务器自定义部署能力
将原来标准化的服务器部署中的关键参数进行提炼、建模，实现、分区、、镜像、网络等部署方案的自定义，以满足不同客户的服务器环境需求。
 ，在路上，路还很长…

文章来源：云端专业号前段时间定了个小目标，利用晚上的时间拜读大名鼎鼎的周志明的《深入理解  虚拟机》，才看几章，“人民的名义”火起来了，唉，时间被强行夺了去，小目标眼睁睁的被失败了
 
所以在这里强行立  吧，先把这几章的心得总结在这里解解达康书记的毒。
现在的主流虚拟机一般都采用分代回收，新生代、老年代
一、分代
为什么要分代？有什么意义？这里我们假设没有分代，会怎么样呢？
答案：“  ”，程序被卡成翔。
为什么，因为  的时候需要分析死亡对象，所以不允许这个时候对象引用关系再发生变化，这就要求“  ”所以线程必然会被挂起。所以我们为了尽量让用户无感知，必然要提高  效率。怎么提高，答案就是分代。我们把长活对象放在一块称为老年代，再把短命鬼放在另一块称为新生代。这样我们一般情况下只需要扫描新生代区域回收无用对象即可减少  被  的时间，让用户在  时依然有丝滑般的顺畅感。
分代实现

我们可以看到新生代内存分配要比老年代更复杂一些，为什么会有这个区别呢？答案：垃圾清理算法的不同。 新生代：复制算法，老年代：标记整理算法。
复制算法：     

上图可以明显看到，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。它的优点就是不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。但有个致命缺点就是要“浪费“一半的内存，这太蛋疼了。
 
那可不可以少浪费一点呢？答案：可以的，就是  区 ，它与  区比例是 有两个  区，其中一个  区和  区是可用的，另一个  区是  复制区，这样被浪费的区域只有  了，大大减少了。但是这样真的合理吗，可以满足实际需要吗，当然是可以的， 公司研究过，的  对象都是”朝生夕死“，生命期很短的，这样每次  之后大部分对象都  了，真正存活下来的是少数，所以我们只用  的空间存在这些存活对象就够了。但是，异常情况也是有的，万一存活对象所占内存多于  区怎么办呢，当然也是有解决方案：分配担保。就是内存不足的时候由担保方承担，这个担保方就是老年代区。所以这里可以看到老年代扮演着最后的大佬的角色，同时可以看到这种算法的致命缺点就是必须要有一个担保方。所以老年代不能采用这种方式，因为他就是最后的担保方，没有人再能给它担保，除非  区占一半内存，但是这又太浪费了。最后，老年代使用了”标记整理“算法。
标记整理算法：

分为两个阶段，首先标记所有存活对象，接着让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存，这样就完全的利用了所有内存了。
到这里可能会有人疑问，新生代为什么不也采用这种算法，不就也能充分利用所有的内存了吗？其实这里是两种算法出发点的不同，所谓复制算法是空间换时间，而标记整理算法则是时间换空间。
复制算法在工作的时候是不没有独立的“”与“”阶段的，而是合在一起做一个动作，就叫复制。也就是说，每发现一个这次收集中尚未访问过的活对象就直接  到新地方，同时设置  。 这样的工作方式就需要多一份空间。 
标记整理算法在工作的时候则需要分别的  与整理阶段， 阶段用来发现并标记所有活的对象，然后整理阶段才移动对象来达到整理内存的目的。在  之后就可以按顺序一个个对象“滑动”到空间的某一侧。因为已经先遍历了整个空间里的对象图，知道所有的活对象了，所以移动的时候就可以在同一个空间内而不需要多一份空间。 
总结一下就是：新生代存活对象少，为了快速  我们可以浪费一点内存；而老年代存活对象多，我们更在乎内存，同时因为有效对象多，所以这块区域的  应该比新生代少。这就是我们下面要讲的   和  
二、普通  ：全局     
从上面我们知道新生代的  是快速而频繁的，老年代  是缓慢而稀少的。这也是分代的目的所在，大部分“朝生夕死”的对象可以快速被清理掉，而长存对象被放在特权区，在平常的   的时候是不会被扫描到的，这样就大大的提高了  的命中率了。
那到底什么时候   会被触发呢，当然也是老年代内存不足的时候。所以这里再说一下什么情况下，对象会被放到老年代：
  对象足够老，所谓足够老就是经过多次  之后依然存活的对象，这里的缺省设置是  次。
分配担保中标的对象，就是上面说的   的时候当新生代  区不足以存放的存活对象
 大对象，我们知道堆内存并不是连续的，有可能在一段时间之后内存很碎片化了，这样即使剩余总内存依然足够，但是在   已经找不到一块连续区域存放这个大对象了，这时候我们就知道把大对象直接放在老年代了。这样的情况如果发生多次我们可以想象，老年很快就会被占满，导致   的发生，而   就比   慢很多大概  倍， 就真被  了。所以我们尽量必须  大对象尤其是很多大对象一起 导语
是一种使用压缩，支持多张图像的容器。支持色，透明通道为。作为互联网表情包的载体，这项年代的技术依然生生不息。但它的弊端也是显而易见的：易出现毛边，色彩表现低劣，文件压缩比不高。针对这些问题，发布了来代替老旧的技术，同时许多开源组件也用格式来代替。
在的尴尬处境
长久以来，一直被吐槽不能用。造成这一局面的主要原因是：

关于照片的场景不会自动播放也没有角标。
一些应用将视为静态图像去操作，导致用户保持了一个后，结果应用将其保存成。
只能通过去操作数据，对其绝缘。

的存储结构
由于历史的原因，有两个版本，但它们的文件结构是一样的，都是由不同用途的数据块构成，可分为控制块和数据块。控制块里是决定表现的参数，数据块里的数据由前面的控制块里的参数来解释。
一个文件的内部结构如下图：

：包含文件签名与版本号。 文件结束标识符。
   与  之间就是文件的数据。
我们从一个简单的图入手，它包含两张图像：

这是它的十六进制数据我用颜色区分了不同的数据块：


文件的开头是  数据块，长度为字节，值为“”或””前三位为签名，后三位为不同年份的版本号。

利用这点，在中判断二进制文件是否为时，可以简单去判断它的前四位是否是””。事实上绝大多数图像都可以用文件签名来判断类型。
 内容
数据包含多个数据块，其结构如下
逻辑屏幕描述符

 

这一数据块由个字节组成，前四个字节分别是图像渲染区域的宽高。的数据是按照大端序存储的，为，所以这个的宽高均为。
接下来是一个压缩字节，第一个  为标志位，表示全局颜色列表是否存在。接下来三个表示图像调色板中每个颜色的原色所占用的数，表示占用个，占用个，以此类推。调色板最多只包含由颜色中选出的个颜色实际有很多优化方案能提高颜色分辨率，如加入局部调色板。
第五个为标志位，表示颜色列表排序方式。若为，表示颜色列表是按照颜色在图像中出现的频率降序排列。随后三个表示全局颜色列表的大小，计算方法是 ，其中为这三个的二进制数值。
第六个字节是表示背景色在全局颜色列表中的索引，若无全局颜色列表则此字节无效。在的图像数据中，没有被指定颜色的像素会被背景色填充。
最后一个字节是像素的宽高比，大多数时候这个值都是，若值为 则图像的宽高比：
 =     

全局颜色列表

            

由前面的逻辑屏幕描述符可知，全局颜色列表的大小是，每个颜色占三个字节，按照排列，所以它占有个字节。数据流中，颜色是按照列表中的索引存储的。
应用程序扩展

    

中扩展块都以开始，后一个字节是扩展标签，标识扩展用途。
应用程序扩展的标签是，它包含有应用程序的标识信息和应用程序数据。其中  应用程序扩展常用于控制的动画循环次数。 扩展长个字节，前个是应用程序的信息，后四个是数据子块，用于指定的循环次数 按无符号整型存储，表示无限循环。

图形控制扩展

 

图形控制扩展块属于””版本的定义。它在一个图像数据块的最前端，用来指定图像的透明度与动画属性。图形控制扩展的开端两字节是，其中表示这是一个扩展，表示扩展用于图形控制。第三个字节是块大小它到结束符之间的数据。第四个字节是压缩字段，前三个保留，四到六是 。第四、五个字节是图像控制扩展后面的图像的动画时间，以无符号整型存储。第六个字节是透明色索引，之后是块结束符。

图像描述符

  

图像描述符位于中每一个图像数据的前端，由开始，长度为个字节。第一个字节是图像描述符的标识，后面八个字节表示图像的   ，用来在动画中局部更新图像。最后一个是压缩字节，主要是关于局部颜色列表的信息，其中第二个表示图像的存储方式是交织还是连续。

局部颜色列表
如果上面的局部颜色列表标志位为，那么局部颜色列表会排列在图像描述符后面，它只对紧跟在它之后的图像数据有效。如果局部颜色列表标志位为，那么图像数据将使用全局颜色列表索引颜色。局部颜色列表的大小计算方法和像素颜色格式与全局颜色列表相同。
图像数据

        

的图像数据是经过压缩的二进制流，通过解码可以将其按照颜色列表中的颜色进行像素填充。第一个字节是最小编码大小，用来进行数据解码。第二个字节是图像数据的大小，之后的都是图像数据，直到块结束符。
结束符



的动画原理
动画的循环次数是由应用扩展来控制的，而动画每一帧的过渡方式是由图形控制扩展控制图像描述符控制图像绘制的区域。
图形控制扩展中控制动画的参数分别是： ，  ， ， 。
  
 占，能够表示。

  = 解码器不会清理画布，直接将下一幅图像渲染上一幅图像上。

  = 解码器会以背景色清理画布，然后渲染下一幅图像。背景色在逻辑屏幕描述符中设置。

  = 解码器会将画布设置为上之前的状态，然后渲染下一幅图像。

  = 保留值
  当  为时，会在有用户输入事件鼠标、键盘时才会过渡到下一幅图像。


  占两个字节，为无符号整数，控制当前帧的展示时间，单位是秒。
  如果图形控制扩展的透明色标志位为，那么解码器会通过透明色索引在颜色列表中找到改颜色，标记为透明，当渲染图像时，标记为透明色的颜色将不会绘制，显示下面的背景。
图像渲染区域
中图像描述符指定了当前帧需要渲染的区域，这样的过渡动画就只用绘制两帧之间不同的区域，前提是 的值为。
实验
根据上面的知识，将第一帧的图形控制扩展改为：

 

这里将透明色改成了红色红色在全局颜色列表中的索引是，并将 改为秒。修改完的为：作者：杨升军

镜像：服务器调试好一台制作镜像，其他机器使用镜像安装，避免重复调试，快速上线下线机器
一创建系统镜像

关闭机器再制作镜像
登录腾讯云官网，进入控制台
选择用于制作镜像的机器==更多 == 选择机器 == 关机然后选择制作镜像，镜像名称和描述尽量易懂

相关文档链接：


二使用镜像创建云主机

使用镜像创建全新云主机购买云主机
镜像 ==  == 创建云主机  == 后边按照提示选择购买云主机

使用镜像重装系统
选择需要重装系统的机器和使用哪个镜像来重装系统，填写需要重装系统机器的密码


三需要跨地区同步镜像如果有问题请联系腾讯云帮忙走后台同步
 腾讯云咨询电话：

相关推荐
如何正确配置   服务器？
创建自定义镜像
【就是快】分钟搭建一台服务器！安全让黑产成本增加
当我们跟黑客对抗的时候，我们想到了一个有趣的思路：既然用神经网络来识别我们的字符，那我们就制造出更多的字符库，使用更多的字符库跟你进行对抗。但很不幸，我们发现机器的算力和人力创造字符的算力完全是不成比例的，而且因为他是可牟利的，所以他只要有百分之三四十的盈利空间就可以做，他不需要做到非常高的标准。但你作为防御方，如果你做不到、的防御标准，你的防御可以说就是失败的，所以这是非常不对称的一个战场，但并不意味着我们并没有机会。因为我们发现就像传统安全一样，很多黑客的技术和手段稍加改善，其实对于防御非常有帮助。
比如像生成对抗网络的手段，也可以很好地来生成字库和字体，这个对于拖缓他们的攻击效率是非常有帮助的。但也不是完全有效，对攻防对抗有更深层次的理解后，我们发现由于技术发展的水平的不均衡，和黑客在如图片识别等有成熟算法和成熟体系的领域去对抗，非常吃亏。所以我们引入了更多的想法。我认为攻防成功的关键，第一个是数据，这个数据决定了天花板的高低。第二个是算法，算法决定了你有多大程度上去接近这个天花板。所以对腾讯来说，我们数据积累非常多，而且非常注重数据的积累，只要把用于此处的安全数据做好，可以做出非常高的天花板。

如果我们在算法上将数据和业务的行为数据进行关联，可以很大程度上接近于天花板。这是我们做的一个模型，我们把多个用户行为和黑客行为进行了关联，然后把这种行为数据和图像上的对抗数据结合，做成一个完整的链去考虑，用一个完整的时间窗去识别。而不仅仅是在图像领域对抗，可以发现正常用户和黑客、黑产是有显著性的行为差异。一旦建好这个模型，是可以真正抵御它的。当然，这些也非常需要你在的算法和数据上的理解和建设工作。

安全的挑战
所以总结一下，在业务安全上，我们这一两年来的体会，其实在攻防这个领域，我们觉得实际上并没有一个一招致敌的方法论，更多的是持续运营的过程，这个持续运营的过程有两个关键因素，第一，在数据的积累和剖析上，选择什么样的数据，积累什么样的数据，以及你积累的长时间的有效性和效率，这是非常关键的事。其次，你要对于数据的理解，也就是说对于业务的理解，不仅仅是基于安全层面，你也要理解本身的业务，这样对于数据的挖掘能力比较强，你就能设计出一个更高效的算法用于线上的对抗，所以这两个关键点是你决胜的关键。也就是说我们最后总结下来，就是一个持续运营和对抗的过程。
传统战场——防黑反黑
第二个领域是传统的安全领域，第一个风控领域实际上是非常好写好做，而且效果非常突出。说一个没跟大家分享过的案例，在登录领域，除了自动机识别，还有其他一些恶意行为。比如说电子商务登录上的恶意行为，包括一些刷单、刷粉的行为，非常普遍。我们通过引入人工智能，大概在个月的时间，识别率同比提高了百分之二三十。并且机器学习的技术，让我们发现并提取了很多之前没有发现的关键因子。这些关键因子的引入，让我们极大地提升了识别率。但在传统安全领域去构建攻防的技术体系非常困难，挑战也非常多。
这是我们现在的传统安全领域，也就是黑客攻防这个领域的现状，我的理解是可以用两个词来概括它，第一个叫做快，第二个词叫做专。越来越多的黑客攻防攻击，是以数据的获取为目的，以专业团体非常隐蔽的渗透为目的，而且他们所有的行为非常具有自我保护意识。这样的趋势，从外部环境来看，苹果、谷歌、腾讯这些世界上最大的公司，他们的数据是高价值的，当黑客进行攻击的时候，是可以很容易进行变现和获取利益的，所以黑客更有动机去获取这些数据。而获取这些高数据行为，很容易被抓获受到惩处，所以他们需要保护自己。外部的打击和趋势会逼着他们越来越快和专业，并且学会了隐藏。适者生存，生下来的这些专业的团体越来越善于使用零备和未公开的技巧，所以也越来越被难以发现。所以我们这个行业出现了一个趋势，黑客的行为越来越非显性化。
下图是一个现网数据，大家可以看到最高的尖刺是图表的零点，达到了三四千次一秒。从这个漏洞在社区公布出来到尖刺，半个小时我们就达到了最高峰。半个小时以后反而下降了，然后再出现几次高峰。
所以当一个漏洞公布出来，给你的反应时间大概就是半个小时。而对方攻击的所有对象都是我们的资产服务器，有相当一部分人已经把核心资产服务器纳入攻击列表，他们缺的只是一个未公开的技巧或很新鲜的漏洞，会在半个小时内完成漏洞进行马上使用，这就是我们面临的现实。
因为这个越来越隐性化，所以也是为了应对这种风险慢慢对进行探索。比如说攻击，我们现在发现也是越来越多的攻击去给我们发包，越来越多地去模拟这种游戏。我们在这里越来越多地模拟业务协议，实际上导致我们越来越难以去识别这里攻击的行为。我们引入了，发现他给我们带来一个很好的帮助。我们可以做到“千人千面”。我们发现人工智能是可以学习的，既然他可以学习，那我们就让他学习各种各样的业务。当他学习各种各样的业务以后，就可以做到不管你是什么样的攻击，不管是什么样的模拟，但因为你跟他长得不太像，所以我们就可以把你识别出来，而并不是根据黑客上识别对方，而是根据我们拥有的巨量数据，用一个比较长的时间线，让我们的机器、安全系统去正确认知一个业务，然后在这个基础上做识别。

这是在渗透方面的一个案例，也是想向大家展示一下这里的挑战性，这是我们抓到的两个真实的专业团体对我们进行渗透的木马，大家可以看到这两个木马其实代表了两代人，或者说两代技术。大家可以看到右侧的木马代表的是比较原始的技术，他实际上是一个网页木马，里面有一个很明显的特征，黑客的后门特征非常显性，我下面画的这些红框的部分都是显性特征，用传统的做法这种木马非常好识别。大家看一下我们从今年以来抓到的大多数木马都是像左侧的木马，并没有非常显性的特征，所以如果你用传统的特征、阈值、方法，对这种东西的识别是非常困难的，非常容易跟正常的文件混淆，并且有一个巨大的问题是，虽然云计算和这种互联网企业规模的扩大，当你去管一个巨量、海量的业务时，你真正面临的误报是不可承受的，这是这里最大的一个挑战，就是黑客的非显性化，越来越不容易跟正常业务区分，而本身的业务规模和体量又不断增大，这是一个矛盾体，对你传统的安全架构和安全思路提出了巨大的挑战。
这是我们最佳实践的一个尝试，严格意义上这是一个实验，并不是一个最佳实验，我相信这里未来的路还很长。我们这里做的实验是这样，一个是算法优化，我们发现用了两套机器学习的算法，一套是，另外一套是，我们发现都不能在实际应用中，满足我们以上识别率的要求，这个是指的识别，我们这里想到一个方法，根据人的特征引用变量，并把和两套算法的结合，随着新特征的引入和算法的引入，进行权重和模型的重新搭建以后，可以达到，所以我觉得算法的优化，其实选择什么样的算法和特征是这里面的关键。其次，如何选择算法也是在实际工业领域中很重要的思考点。大家可以看到，我这里的这两幅图，大家可以看到，如果用前面的思路，我们去长时间学习业务，其实我们是可以做到有一个很好的帮助。大家可以看到右边这幅图，有几个白点在模型之外，在常见的领域我们可以看到防御方最痛苦的是什么？有一个巨大的难点，你要不断地加白名单，因为正常的业务和操作员的行为是异常的，但又是正常用户的行为，如果你对这种行为，现在的传统方法只能不断地加白名单，而到一定程度是有问题的。如果用机器学习的方法，实际上可以很好地去学习，虽然是一个异常点，但依然可以识别出这是一个好人，并且对坏点进行标注，所以这是在机器学习领域和数据保护领域非常大的帮助，可以帮助我们极大地释放人力，解决传统领域的一些白名单的运用以及自然人的定性、定位问题。
在实际工作中这种方法论并不是完美的，也面临一个挑战，深度学习在实际工作领域，我们发现效果非常好，但是在线上的时候效率问题会非常大，尤其对于腾讯这样一个体量的公司，或者对于或谷歌这样的公司，运算挑战在某些场景几乎不可接受。怎么解决？我们也想了一些有意思的想法，就是我们用深度学习来思考，用浅度学习来检测，我们用深度学习模型来发觉黑客攻防领域，或者前面提到的业务安全领域的一些本质问题，一些我们没有发现的特征问题，我们用它来提取。但构建线上实时打击模型的时候，我们引用浅度模型，这样在效率、精准度和透析事物的本质之间取得平衡，我们觉得这是一个很好的收获，在工业实践中可能会对大家有参考价值的东西。
最后我进入一个尾声，再次跟大家总结一下，经过我们这段时间的实践有三个经验跟大家分享。第一，人工智能想跟安全结合，或者我们想更多地把安全领域进入下一个时代，我觉得最主要的三件事是需要我们思考的。第一，数据，我们需要有海量的数据，需要有一个真实的战场，在这个真实的战场截取海量的数据，去训练我们的，因为这决定了到底能走多远，天花板有多高。第二个事情是算法，不仅仅要对人工智能的算法有理解，更重要的是要对业务有理解，这样的话在构建算法的时候，可以更有针对性，能发掘出更多的变量，这样在识别的时候有更高精度。第三，耐心，因为这毕竟是一个长期对抗的过程。
作为来说，或者安全来说，我觉得我们不妨这样想，如果我们现在看年前的互联网，在刚刚发明的时候，我们会告诉他们你这不是真正的互联网，我觉得对于安全来说也是一样，这条路还非常长，或安全刚刚起步，这意味着我们有无限美好未来的可能，所以希望能有更多的机会跟大家交流，我们一起去探索美好的未来，谢谢大家。

更多相关内容详见：用怼黑产是一种怎样的体验？上写在前面
其实准备已经很久了，确切地说当开始介绍时就开始了。其后参加了苹果的 ，加上自己有点事，所以文章一直没发出来，现在再发一篇上手文章，也没什么意义。所以本篇文章重在上苹果工程师的解惑和我对的理解 最后会简单介绍一下相关技术。


 大家都知道，就是将模型渲染在摄像头图像之上，混合渲染达到虚拟物品就好像是现实的一部分。解决了模型定位难的问题，结合运动数据与图像处理数据，来建立一个非常准确的系统，构建虚拟世界和现实世界之间的映射。同时能够分析环境自动给模型添加光源，实际效果还是比较惊艳的。从结构上看，提供了一套简单易用的框架，但框架之外，需要很多的三维空间、游戏编程、模型、渲染的知识来理解技术。最重要的两个类是与

类似与，中由类来配置系统的建立。设置的配置选项为来追踪设备的方向与位置，并且能够检测平面。这个选项只有处理器之上才支持。其他型号处理器以下只能追踪设备的方向。
的提供了自带的两个渲染类：和，后者用来渲染模型。之前鲜有问津的算是有了用武之地。这两个类会自动开启摄像头并建立虚拟空间与现实空间之间的映射。同时也支持自定义用或实现渲染类，但要自己管理与之间的通信，同时要遵循 命令不能在后台调用的规则。
其他比较重要的类有、、、。



世界中点，可以用来放置虚拟物品，也可以代指现实物品的放置位置。在世界中是唯一的，并包含仿射变换的信息。



的返回，世界中的。与中的不同，的以设备方向配合视图坐标，建立一条世界中的射线，所有在射 线上的 会以由近到远的方式返回。此外的返回虚拟物品。



摄像头视频帧的包装类，包含位置追踪信息、环境参数、视频帧。重点是它包含了苹果检测的特征点，通过可以获取，不过只是特征的位置，具体的特征向量并没有开放。



场景中的摄像机，用来控制模型视图变换和投影变换。同时提供自由度信息，方向位置与追踪信息。
对的思考
从框架接口来看， 暴露出来的能力并不多且小心翼翼。的能力，由三部分组成：

渲染
空间定位与方向追踪
场景理解检测与识别

目前看  只提供了渲染的入口，其他两个都被封装起来了，所以目前来看渲染是差异化的主要途径，但不唯一。  上，面对大家提出的苛刻问题，苹果工程师大量提到特征点。其实计算机视觉是可以在场景理解这一层面做一些自定义的。如果苹果开放更多的能力，那的能力完全可以作为任何一个的特性。
此外，还存在一些问题：

 是基于惯性视觉来做空间定位的，需要平稳缓慢的移动转向手机，才能构建更加准确的世界，这对用户来说是一种考验，需要积极提示。
理论上  在双目摄像头上的表现应该优于单目，这里需要具体测试，如何来平衡用户体验。
文件还是知识一个简单的维模型编辑器，支持的文件格式少，对模型、光照的编辑方式不太友好。对骨骼动画的支持还有只在能用的阶段。
一旦刚开始检测平面失败，出现时间久，飘逸的现象，后期很难再正确检测，要强制重启。

最佳实践
模型与骨骼动画

如果是使用 转  文件，资源中包含骨骼动画时，加载文件到  中会丢失动画，需要在加载时手动恢复一下方法。
设计骨骼动画是，要求设计师把动画放在根节点上，不要分散地放在每个上，这样可以方便地读取出动画到。
最好不要将太远的光照加载模型文件中，这样会导致加载文件到时，你的  真实尺寸特别大，而你期望的尺寸可能只是模型对象的大小。
模型的 是用     会有更好的表现，设置比较好的环境光也比较重要。

光照

合理的阴影会大大提高的效果，贴一张纹理当然可以，但动态阴影更让人沉浸，我们还是要有追求的。
使用  效果，模型会更逼真。
光照加载到 的上，这对做碰撞检测尤其重要

 
汇总了一下上，比较感兴趣的问题和苹果工程师的回答，掺杂自己的理解。
  提供的特征，如何获取特征？
答：使用去获取特征点的值。这个我一般是用的去做，我想苹果工程师是说将图像用转成位图后，根据坐标去获取值。但特征点不多的话，直接在中利用公式计算一下不就行了吗？不过也许有更强大的方法。
  中怎么做虚拟环境？
答：利用背景。这个在中用的比较多，就是用一个贴满背景的立方体包裹住摄像机所在的空间，网上的资料较多。
  的如何模拟光源的？为什么不产生阴影。
答：通过图像的环境来设置模型的环境光强度，而环境光是不产生阴影的。我猜苹果应该是通过像素值来确定环境光的，如果用高级一点的方法完全可以添加直射光。光照有许多模型，只有带方向的光才会产生阴影，如果想用做出阴影，可以看我的回答。
  与之间的切换会有问题吗？
答： 底层也是用的，如果重新打开，只需要重新  一下  可以了，但切换时会有卡顿。我自己试了一下，切换时确实有轻微的卡顿，切换后就停止摄像头采集了，但渲染会继续，只是丧失了空间定位与检测识别的能力。
  是否支持前置摄像头？
答：不支持。并不是一个用于前置摄像头环境的技术，因为空间有限，能提供的信息也非常有限。这个问题是很多参会者关心的问题，但  团队似乎不是很  ，说到底还是因为前置摄像头的场景中，用户很少会移动，画面中一般大部分都是人脸，这样  的定位与检测能力无法很好使用。建议由类似需求的同学好好梳理，是不是想要的是渲染而不是。
  的最大应用范围是多少？
答：米是  在保持较好用户体验的最大测量距离。这个其实我有点没太听清，实际数字应该是米以上
  如何做？
答：不会提供这样的能力，如果想实现的，可以用  提供的特征点来跑自己的计算机视觉。熟悉计算机视觉的同学应该都明白，其实就是一种简单的图像识别，如果  提供的特征点可靠的话，完全可以自己做特征匹配。现场问了苹果工程师，他们的特征点是什么特征，他们不愿回答，不过看使用场景的话，应该是一种边缘敏感的低维特征，应该类似   。
  合适支持？性能如何？
答：支持处理器并不在计划中这里指的是空间定位能力，只支持空间方向追踪， 的大部分计算都是在上处理的，在处理器上的性能损耗在    在处理器上的性能损耗在   。看他们的意思，大量的计算，在上应该是比较低效的，解释了为什么上的追踪能力是阉割版的。性能应该说还不错，与游戏类似
  如何追踪实际的物体？
答：可以在已识别的物体位置上，添加一个 这样就能在之后的处理中一直保持这个物体的追踪。这次的，苹果大量提到他们的特征点，如果他们真的足够重视的话，应该开放特征检测的过程与特征向量，希望后期能够开放吧
  如何连接两个不同  世界？
答：没有计划支持这些，比较  的做法是将两个手机紧挨着启动。这个也是很多参会者关注的问题，相信不少人已经有了自己的解决方案，这里我后期会出一篇文章讲解。
相关
渲染
说到底还是一种游戏技术，提供了定位、检测平面的功能，这些功能并没有暴露出来供我们自定义，那么只能在渲染方面做出差异。
目前支持的渲染引擎，有，，。后两者都是成熟的游戏引擎，能够提供完整的游戏功能，但没有我们没有使用，主要因为：

上手较慢， 月中旬就要发布了，时间紧促。
接入会给安装包造成很大压力，成本大约。

最终决定还是用，主要出于一下考虑：

目前对，的支持没有好。
用写，可以。
是系统动态库，对安装包压力不大。
虽然能力弱，但是对于来说足够了，毕竟打造不了复杂的游戏。

坐标系
和一样，使用右手坐标系

定位
将模型加载到空间中，需要个自由度的信息来指定模型的表现：

分别是沿三个坐标轴的平移与旋转。可以使用旋转矩阵、欧拉角、四元数来定义空间旋转，的这三种方式均有运用。

旋转矩阵这个好理解，使用旋转的变换矩阵即可，维度，定义一次旋转需要个数。

欧拉角把空间旋转分解成绕三个局部坐标轴的平面旋转，分别是俯仰角，绕轴，偏航角，绕轴，翻滚角，绕轴，然后以一定顺序做旋转中是     ，欧拉角是使用三个  矩阵连乘实现，而且存在万向锁的问题。



当为°时，与的旋转轴重合了，这时飞机丧失了一个旋转的维度。



四元数将三维空间的旋转表示成四维空间的超球面上位移 概念有点复杂。简单来说，我们只需要旋转轴 →= ，和角度  来构造一个单位四元数 


那么旋转可以定位为：

对任何需要旋转的点 将它扩展成一个纯四元数 代入上面的公式，就可以得到旋转后的点。
追踪
  基于视觉和惯性的测量方法，惯性数据是指角速度和加速度，这些都由 提供，加上图像特征，能够更准确地建立系统。会将提取到的特征点映射的空间中，也就是说特征点是由三维坐标的，我们可以利用特征点来确定图像中物体的远近。实测效果不错，误差在分米级别。前言
我是一名产品经理，平时对技术比较感兴趣，也正是因为对技术有所了解也让我的工作非常轻松，平时也看过很多技术文章，我认为技术文章要么就是给纯技术写的，要么就是给那些没有很深的编程基础但是热爱编程或者抱有期待的人看的，这篇文章是写给后者的，但是不代表内容非常基础，依然使用了目前比较热门的技术。
这次我们要做一个微信机器人，就是可以在微信与我们聊天的机器人，当然目的不是用图灵机器人那种完成一些看似很好玩的聊天功能，好歹要让这个机器人有所作用。
那么来说说我的需求吧，我和朋友做了一个航模视频的自媒体，作为一个产品经理，我需要了解我发布的视频的实时播放量，但是完成这个操作需要进入优酷主页查看，包括还有每个视频的播放量数据都要自己去打开网页看，这样非常不方便，比如我们在群里聊到了播放量的话，那么就会有一个机器人告诉我们播放了多少，这样多么方便，而且看起来还很装逼，并且，想实现出来真的不难。

前提是我们已经站在巨人的肩膀上。
技术路径和实现思路

首先编程语言使用了，语法简洁、第三方扩展丰富，也因为这里采用的微信消息框架是基于的。
服务器当然使用腾讯云服务器，这里我使用的是单核内存的最低配置，因为作为个人用的这个配置绰绰有余了，并且以后有更多用途的时候可以直接升级服务器配置和存储，这就是云服务器的巨大优势。

因为对于大部分人来说，拿到一台崭新的服务器要部署服务是非常麻烦的，所以我也不喜欢，于是乎想到了使用容器来运行我的代码，这样不用手动去配置服务器的运行环境，我只需要创建一个镜像就可以了，但是这样感觉还是挺麻烦的，还要安装，还要上传镜像。然后我发现了，它可以帮助我完成容器管理和镜像生成的工作。
所以我们部署路径是这样的：
编写代码提交代码到上自动生成镜像并部署到我们的云服务器上自动运行
也就是提交代码到分支，然后，然后自动更新发布，服务就这么运行成功了
具体过程
所以对云服务器的配置而言，我只需要为其安装的被控端程序即可，然后就可以再也不用管这台服务器了，太爽了吧
恰好发现腾讯云也支持了的系统，在为云服务器安装系统的时候选择服务市场容器混合式容器管理平台即可。
哇，那这样岂不是爽上加爽，不用登录服务器做任何配置拿来即用，真刺激。

安装过程就不多说了，他们也提供了文档，非常简单，两行命令而已，然后我们可以在后台添加我们的主机了。

然后我们去创建一个项目。

需要我们设置代码源，可以选择和，确实比较人性化，那么我们就需要自己去创建好项目了，这里省略过，选择好后就可以创建了。
项目创建成功后我们只需要选择我们的代码分支构建一下就好了，这时容器镜像就创建好了，下来就是部署。
创建一个应用，会提示我们选择镜像来源，这里选择之前构建的镜像。

点击部署最新版本就好了。
然后我们分别在项目设置和应用设置里配置自动构建和自动部署，这样以后我们只要提交了代码，会帮我们自动构建镜像然后部署，不需要我们自己手动操作，只需要专注代码逻辑，不用再操心部署了。


过程就是这么简单，腾讯云服务器作为基础，我们全程不用手动配置自己的服务器，多么轻松惬意。
程序实现
前面重点讲了服务器配置和程序部署，但是实际上部署的程序我们还没讲。

容器打包必须要有一个来告诉容器如何构建镜像，为了构建方便我们采用的提供的镜像，以下是的内容：
 
 
 
可以看到，我们启动服务的文件是



 
   
 
    
 ____ == ____
    




 
   
   
   _

_
 _
    抠鼻
     你好，请在群聊里面撩我微笑

_ =
 _
     
         播放量  
             = 
              
                 查询失败！
             = __
            优酷目前累计播放量为：   
             = 
              
                 查询失败！
             = __
             腾讯视频目前累计播放量为：  
         订阅  
             = 
              
                 查询失败！
             = __
             目前优酷订阅人数为：  
         详细播放  
            查询中 
             = 
              
                 查询失败！
             = ___
             
             = 
              
                 查询失败！
             = ___
             
        
             _

 
    _=
    




 

 = ==

 

     ____=
         = 
         = 
         = _
           
             = 

    获得播放量
     __
         = 
            
             = 
             = 
             = 
        
             = 找不到播放量
         

    获得订阅数
     __
         = 
            
             = 
             = 
             = 
        
             = 找不到订阅数
         

    详细播放量
     ___
         = 
         = 
         = 

         =  优酷视频最新个视频：\  
           
             =   \ 播放量：\
         

这里程序实现很简单，使用的是提供的方法，具体可以参考项目。
总结
以上就是快速实现微信机器人的思路，其实主要想表达的就是现在的云技术对于开发者、对于编程初学者都是非常友好的，我们完全不必要投入过多精力在运维和发布维护上，只需要专注代码就可以。这也是云为我们生活带来的另一个方面的改变吧。

相关推荐【腾讯云的种玩法】腾讯云上搭建微信机器人【腾讯云的种玩法】微信个人订阅号后台搭建入门教程作者简介余果，腾讯社交用户体验设计部高级工程师，前端开发组负责人，开发通道评委，腾讯云特邀布道师，《全栈工程师的自我修养》作者

在上一篇文章中，我们定义了“未来”的时间段，也描述了如何“面向未来”去学习。简单的总结下，没有实践场景，学不到真正的技术。如果不动手去做，读再多书也不会学到新技术。
在本文中，我们继续聊聊如何“跨界开发”。我在腾讯的社交用户体验设计部工作，在这不长不短的年多工作经验中，跟很多设计师打交道，也跟很多工程师打交道。我学到的一个宝贵知识是，设计不等于艺术，工程不等于科研。
设计不等于艺术。用文艺的话说就是“艺术发现问题，设计解决问题”。也即是说，设计为商业服务。作为上市公司的设计部门，需要清晰地展现产品，构建用户的渴望。在某种程度上，需要隐藏个人的“术”，而构建一个系统性的体验给用户。设计的创作虽然也依赖灵感，但整体上是科学的、可推导的。
工程不等于科研。科研需要在一个专精的技术点上达到一百分，甚至突破人类知识的最外层，达到分。但是在工程的场景下，更重要的是投入恰到好处的技能点去实现现阶段的目标。
因此，当我想要独自创建一个自己的产品的时候，我自然而然在设计、前端、后端、客户端等都投入了恰到好处的技能点。
再强调一下，我并不是想要做全栈工程师，所以学了这些技能，而是因为想要独自做一些产品，在这个过程中，持续学习，不自觉领悟到了全栈工程师的一些心法。
我把这些心法都记录在我的新书《全栈工程师的自我修养》中。我有一个假说，那就是“好的前端工程师一定是好的全栈工程师，反之不一定”。
因为没有数据证明，所以我必须老实承认，这只是我个人的一个假说。以下是我的推导过程。
首先，如果我们都同意全栈工程师的定义是“能够独自完成一个产品的人”而不是“精通一切技术的人”。那么一般的产品或者产品会需要的能力，大体上分为“技术”、“学习”和“产品感”三个方面。
技术是实现一个产品需要的“工程能力”，包括下图列出的前后端语言，数据结构和算法，系统设计能力，数据库，移动客户端。
学习体现了持续学习和解决新问题的能力。除了图中列出的技术，还有持续增长中的新技术，所以有效的学习能力必不可少。
产品感包括对用户体验的理解，以及根据产品数据来持续迭代产品的能力。为什么产品感很重要？ 有一些优秀的，是由个人开发者独立开发的，他们完成了从构思到设计、从开发到发布的整个过程。如果没有良好的产品感，是无法实现从“程序员”到“工程师”的转变的。前端工程师在学习和产品感上都有天然的优势。
因为国内即使是最优秀的大学，也没有“前端”这门专业。的作者本科学的是艺术史，大神是学设计，都不是计算机专业。最终进入到前端领域，靠的是爱好、勤奋和学习能力。所以我想“前端工程师学习能力强”这一点应该没有人能反驳。
在产品感上，因为前端经常跟用户界面打交道，所以在工作中就会思考怎样的用户界面会吸引用户。用户可能使用多种多样的浏览器和设备访问网站，因此也需要同理心来感受用户的实际访问情况。再次强调，“没有实践场景，就不会有阵子的成长”，前端会在“产品感”上有更多实践场景。
当然，不是所有的前端都有这样的想法，但是对于走心的前端来说，提升整体能力的机会有很多很多。对于前端工程师而言，比较熟练的自然是前端技术，而熟练使用前端技术的前提，就是对系统有所理解。
系统设计是指使用软件工程的方式架构一个软件系统，能够对应解决现实生活中的实际问题。我的感觉是，在软件系统中经常会用到协议，来进行客户端和服务器端的通信，甚至服务器和服务器之间的通信。对于必须掌握的前端工程师来说，往往已经有大概的了解。
说到后端，语言其实并不构成很高的技术门槛。在服务器端，如果不是用户量特别大的系统，数据量都可以通过一台服务器来处理完成的话，前端工程师也经常会跟后台和简单的模板型语言打交道。
只要投入时间，应用层的后端语言很快就能上手，你需要的只是一个使用后端语言的机会。在学习后端语言时，我的建议是，专注项目，精简需要的技能列表。
也就是说，如果你已经精通，就直接使用开始搭建后端吧，不要去学或了。除了增加复杂度，并没有太大意义。
人类的大脑并不是为了处理复杂项目而设计。人类从原始村落进步到现代化都市，不是因为发生了基因或生理上的进化，而是协作方式发生了改变分解复杂项目，每人都遵循共同接口，只完成分解后的工作。所以全栈工程师在学习技能时也应认识到自己大脑的极限。
当然，如果团队对后端语言有要求，那必须遵循团队已有的技术能力。
总之，不要在某一特定时间同时学习多门语言，除了增加技术复杂度，没有任何意义。说到，推荐一个网站。它是《软件随想录》作者最新的革命性产品，能够让开发者以最快方式开发程序，而无需购买服务器和搭建开发环境。
如图，在的里加入新的依赖库名称和版本号，保存，服务器会自动下载好对应的库到你的_目录中。还提供库名补全功能。接下来你就可以直接在代码中使用这个库了，因为这个库已经安装在云端的“本地了”，太方便了！说说移动客户端开发吧，具体而言是指和客户端。
客户端原生开发与前端开发的相似之处是，本质上都只对数据进渲染，生成用户界面，以及对用户行为做出响应。从年开始，客户端开发和前端开发有越来越多的相似点，比如使用的架构方式来把界面、逻辑和数据分开，比如都可以用技术栈来实现。当前端工程师接触到客户端原生开发，绝对会有一种“打开新天地”的感觉！原本依赖客户端提供的设备接口，现在全都可以通过原生接口直接操作；原本超过几千行就崩溃的图文表单，使用原生可以如黄油般顺滑。
如果希望复用已有的技能，而不是从头开始学习原生语言开始学习，可以考虑混合式和两种方案。
对于无需多言，实际上就是页面在中的渲染，只要你熟悉移动站点开发，就能直接上手开发。这种方式优点是足够简单，缺点是加载会比较慢，而且无法渲染大量数据。
对于而言，虽然跟一样使用作为编程语言，但是另一种解决思路。重新定义了一种渲染界面、处理数据和处理交互的编程方法，然后在各个平台中都能渲染成原生界面。通过这种方式，宣称实现了“   ”。
因为实际上会编译成原生界面，所以性能一般比好。正在提供越来越多的组件，但是要注意的是，有一些组件比其他组件性能更好。比如和都能实现应用内导航，但是直接封装了的，所以性能更好。
在选择组件时，我们需要根据性能和开发方便做权衡。如果对性能要求不高，那么使用即可，如果对性能要求很高，就应该针对平台使用，对平台使用其他技术或者。算法和数据结构，在大学计算机课程中占了很大比重。各种竞赛也主要考察算法和数据结构，让一些学生认为这就是软件工程中最重要的部分。
实际上，“算法和数据结构”可以认为是和“系统设计”相反的技能树。理论走的是深度，是在追问在给定的计算能力约束下如何把一个问题解决得更快更好。而系统走的是广度，是在追问对于一个现实的需求如何在众多的技术中设计出最多快好省的技术组合。
现代的编程语言有很高的抽象程度，程序员无需掌控到内存级别的分配和释放，只要使用高级抽象的数据结构即可。本身没有复杂的数据结构，但是使用和闭包可以模拟出任何数据结构包括树和链表，更有甚者，通过第三方库比如可以作为增强版的来使用。
“算法和数据结构”应该是基础内功，没有内功，只剩招数，无法成为绝世高手。很多自学成才的前端不理解算法，可能会写出渲染性能很糟糕的网站。
那么如何提升算法和数据结构能力呢？推荐一个网站
现在大部分题目已经支持。下面聊一下数据库。数据库往往是网站发展到一定规模之后的最终瓶颈。
这并不是我的个人观点，而是得到了大量网站证实。在用户量激增、数激增时，第一个扛不住的就是数据库。所以当我们聊 ，可能一半的时间都在聊数据库的扩展。 是一个面向文档   的 数据库 而不是关系型数据库。面向文档有这样几个好处：
易于使用：不再有行的概念，取而代之是文档，因此更加灵活，也更符合现代面向对象语言的开发者对数据的看法。此外，跟不再是固定的类型和大小，因此，添加和删除字段变得更加容易了，实验可以很容易地进行。
易于扩展：数据库的大小正在加速增长，这也是符合安迪比尔定律的。既然数据库的增长变成必然，那么如何扩展？从技术上分为纵向扩展 和横向扩展 两种思路。纵向扩展是指增加单个计算机的性能，使用更大的内存、更快的和更大的硬盘。但是纵向扩展毕竟会遭遇性价比评价，所以现在的大型互联网系统都采用横向扩展的思路，将多个普通的计算机连接成为集群。基于此，想要增加性能只需要添加一台普通的计算机到集群就好了。
不过，管理台计算机集群显然比管理一台计算机困难的多。
采用横向扩展的架构设计，面向文档的数据类型时它能够轻松地在多台服务器之间进行数据分割。能够自动处理跨级群的数据和负载，自动重新分配文档，以及将用户请求到正确的机器上。这样，开发者能够集中精力写程序，而不用担心扩展的问题。

安迪比尔定律：    安迪提供什么，比尔拿走什么。 安迪指英特尔前安迪·格鲁夫，比尔指微软前任比尔·盖茨，这句话的意思是，硬件提高的性能，很快被软件消耗掉了。

卓越的性能：的一个主要目标是提供卓越的性能。在一些设计中，这一目标得以体现。比如能对文档进行动态填充 ，也能预先分配文件以利用额外的空间来换取稳定的性能。总之，在各方面的设计都旨在保持它的高性能关于横向扩展，腾讯云的云服务器支持弹性定价，当用户达到一定级别时可以随时扩展。此外，腾讯云还支持各种关系型数据库、文档型数据库和数据库缓存机制。现在，腾讯云有对学生的特别优惠活动，只要上传学生证，就可以以元低价获得域名服务器。参考地址好了，今天的分享就到这里，谢谢大家。涉及到的链接单独放出一页，大家可以拍照，字号很大，后排也能看到。这样也许哪天在相册翻出来也会想到吧哈哈。

相关推荐
上一篇 面向未来的跨界开发技术上
视频 人人都是网络工程师
全栈工程师的自我修养作者：韦伟

 前言
最近安全界关注的焦点实际是一类不安全的开发习惯所导致的，在上类似问题也毫不罕见，只不过很多风险被微软默认自带的防火墙缓解了。
我们前几个月发现了一个联想电脑的漏洞，和非常类似：影响上亿用户、访问一个端口发送一条指令就可以让目标系统下载一个程序并执行。
联想公司已于年月日修复了该漏洞。玄武实验室和电脑管家合作，也向用户推送了相关安全更新。在修复前，该漏洞存在于所有使用预装系统的、、以及 系列电脑。
 背景
联想  软件用于帮助用户从联想的服务器中直接下载并安装软件、驱动、的更新，极大的简化了用户更新系统的难度和工作量。其被默认预装在联想的多款产品中。
  可根据不同的网络环境及配置通过多种方式下载软件及更新，其中一种方式为通过文件共享下载，而则是完成此功能的主程序， 随 主程序启动，并建立本地服务端等待主程序连接。在早期版本中，甚至 主程序退出后，也仍然保持运行状态。
 问题描述
在 的版本中，通过的机制，通过服务器提供多种功能。
  发展自，是一项比较老的分布式处理技术。它序列化服务端的对象和数据并导出，客户端通过、、信道跨越进程边界实现对服务端对象的引用。然而的序列化机制会隐式导出对象所有的方法和属性，客户端一旦获得服务端导出的对象引用，即可调用服务端对象提供的所有方法。因此机制容易引入安全漏洞，且不建议将服务终端导出给不受信任的客户端。
 导出的对象提供、、、、、、、功能。客户端可以连接并获取其引出对象，进行文件下载、应用程序执行等操作。
其中并未对参数进行任何验证，可以用来启动任意进程，其实现代码如下：
 
      =  

    {
       
    }
    {
    }

     =  
    
同时，虽然 在防火墙策略中只添加了的出站规则，但由于缺少必要的配置，使其绑定在上。因此在缺乏防火墙保护的情况下，任何机器都可与其建立连接，最终使用其提供的和功能实现远程下载程序并执行。
 建立服务端信道并导出对象的代码如下：

      =   
      =  
      =  
      =  
     =     
      
     =  
     =  
      
     =  _
 修复
联想在日放出的  修复了包括此问题在内的多个漏洞。其重新实现了、功能，对其创建进程的参数进行了验证。并加强了服务端的配置，使其绑定在，阻止了远程请求。修复后的部分代码如下：
 
    {
          =  
         
               ==  ||  == 
            
     }
     {
     }

     =  
    
  =   
  =  
  =  
  =  
  =  
  =  
 =     
  
 =  
 =  
  
 =  _
 小结
作为上一代的分布式处理技术，由于设计时的安全缺陷早已被微软的技术取代。如果应用程序仍在使用技术进行分布式处理或通信，应意识到其潜在的安全问题，稍有不当则可能引入安全漏洞。是  远程过程调用的简称，这一机制都要面对两个问题

对象调用方式；

序列反序列化机制


在此之前，我们有必要了解什么是架构层次的协议。通俗一点说，就是我把某些接口和接口中的方法称为协议，客户端和服务端只要实现这些接口中的方法就可以进行通信了，从这个角度来说，架构层次协议的说法就可以成立了。的机制正是采用了这种“架构层次的协议”，有一整套作为协议的接口如下图：

的组件，依赖于 接口类型的支持，要求每个实现类都要确保将本类的对象正确序列化与反序列化。因此使用动态代理与反射实现对象调用方式，客户端到服务器数据的序列化与反序列化由框架或用户自己来实现，也就是数据组装时定制的。架构图如下：

动态代理
主要用来做方法的增强，让你可以在不修改源码的情况下，增强一些方法，在方法执行前后做任何你想做的事情甚至根本不去执行这个方法，因为在的方法中，你可以直接获取正在调用方法对应的对象，具体应用的话，比如可以添加调用日志，做事务控制等。
这个接口的实现部署在其它服务器上，在编写客户端代码的时候，没办法直接调用接口方法，因为接口是不能直接生成对象的，这个时候就可以考虑代理模式动态代理了，通过代理一个该接口对应的对象，然后在的方法内封装通讯细节就可以了。具体的应用，最经典的当然是标准库的，其它比如，各种框架中的远程调用，大致都是这么实现的。
接口
是所有协议接口的父接口，其中只有一个方法：
相关

一个客户端和之间的协议接口，用于数据块恢复。

与交互的接口，所有控制流的请求均在这里，如：创建文件、删除文件等；



  与交互的接口，如心跳、等；与交互的接口。

相关

内部交互的接口，用来更新的元数据；

与交互的接口，功能与相似；

与交互的接口，用来提交、获得等与相关的操作；

中子进程与母进程交互的接口，子进程即、等操作，母进程即，该接口可以回报子进程的运行状态词汇扫盲  脐带的 关系亲密的 。


实现流程
简单来说， =动态代理定制的二进制流。分布式对象一般都会要求根据接口生成存根和框架。如 ，可以通过 ，生成存根和框架。在类中有一些内部类，下边简单介绍下

用于封装方法名和参数，作为数据传输层，相当于吧。

用于存储对象，用 作为 存储结构为  。

是动态代理中的调用实现类，继承了

是的实现类。我们就需要这样的步骤了。


上类图

从以上的分析可以知道，类仅作为，类只是作为缓存，而类用于服务端的处理，他们都和客户端的数据流和业务逻辑没有关系。为了分析 ，我们需要介绍一些  反射实现   的背景。
  是由两个  实现的： 和 ，后者是一个接口。
所谓   是这样一种 ：它是在运行时生成的 ，在生成它时你必须提供一组  给它，然后该 就宣称它实现了这些 。
这个   其实就是一个典型的  模式，它丌会替你作实质性的工作，在生成它的实例时你必须提供一个，由它接管实际的工作。
这个 ，在  的  中，就是  对象。我们可以简单地理解：就是你可以通过一个接口来生成一个类，这个类上的所有方法调用，都会传递到你生成类时传递的 实现中。
在  的  中， 实现了  的  方法 方法也是  的唯一方法。  会把所有跟这次调用相关的调用方法名，参数类型列表，参数列表打包，然后利用前面我们分析过的 ，通过  传递到服务器端。就是说，你在  类上的任何调用，都通过  发送到远方的服务器上。
 使用 。  封装了一个过程调用的所有相关信息，它的主要属性有 ，调用方法名，，调用方法参数的类型列表和 ，调用方法参数。注意，它实现了  接口，可以串行化。
 实现了 ，你可以把一个对象，通过 ，升级成为一个服务器。服务器接收到的请求通过 ，解串行化以后，就发成了方法名，方法参数列表和参数列表。调用  反射，我们就可以调用对应的对象的方法。调用的结果再通过 ，迒回给客户端，客户端把结果解包后，就可以返回给  的使用者了。
我们接下来去研究的就是类中的方法了，代码如下
       
 
{
    ……
      = 
                              
    ……
     
}
一般我们看到的动态代理的方法中总会有    这句代码。而上面代码中却没有。其实使用   是在本地中调用；而在中，是将数据发送给服务端，服务端将处理的结果再返回给客户端，所以这里的方法必然需要进行网络通信。而网络通信就是下面的这段代码实现的：
  = 
   
类在这里封装了方法名和参数，充当。其实这里网络通信只是调用了类的方法。
源码
接下来分析一下源码，在此之前我们得明确下我们的目标，总结出了以下几个问题

客户端和服务端的连接是怎样建立的？

客户端是怎样给服务端发送数据的？

客户端是怎样获取服务端的返回数据的？


基于这三个问题，我们开始分析源码，主要包含以下几个类

用于封装对象，作为，写到服务端，同时也用于存储从服务端返回的数据。


用以处理远程连接对象。继承了


唯一确定一个连接

：客户端和服务端的连接是怎样建立的？
类中的方法如下
     
  
{
      =         将传入的数据封装成对象
      =     获得一个连接
          向服务端发送对象
      = 
     
    {
         
        {
            
            {
                  等待结果的返回，在类的方法里有方法用于唤醒线程
            }
              
            {
                 因中断异常而终止，设置标志为
                 = 
            }
        }
         
        {
            
        }

          = 
        {
               
            {
                
                 
            }
                  本地异常
            {
                  
            }
        }
        
        {
              返回结果数据
        }
    }
}
具体代码的作用我已做了注释，所以这里不再赘述。分析代码后，我们会发现和网络通信有关的代码只会是下面的两句了：
    =     获得一个连接
         向服务端发送对象
先看看是怎么获得一个到服务端的连接吧，下面贴出类中的方法。
   
                                  
  
{
     
    {
         如果关闭了
             
    }
     
    如果连接池中有对应的连接对象，就不需重新创建了；如果没有就需重新创建一个连接对象。
    但请注意，该连接对象只是存储了的信息，其实还并没有和服务端建立连接。
    
    {
         
        {
             = 
              == 
            {
                 =  
                 
            }
        }
    }
        将对象放入对应连接中的池，就不贴出源码了
    这句代码才是真正的完成了和服务端建立连接哦
    
     
}
类中的方法如下
     
{
    ……
    
    {
        ……
         
        {
              建立连接
              =      获得输入流
              =   获得输出流
            
            ……
             =   
                                              将输入流装饰成
             =  
                将输出流装饰成
            
             跟新活动时间
            
            当连接建立时，启动接受线程等待服务端传回数据，注意：继承了
            
            
        }
    }
      
    {
        
        
    }
}
再有一步我们就知道客户端的连接是怎么建立的啦，下面贴出类中的方法
        {
        = 
        = 
        {
         {
           =  终于看到创建的方法了
          
         ……
           设置连接超时为
            
          
          
        }    {
           设置最多连接重试为次。
            总共有 =  分钟的重试时间。
           
            
        }    {
            
        }
      }
    }
不难看出客户端的连接是创建一个普通的进行通信的。
：客户端是怎样给服务端发送数据的？
类的方法如下
    {
        {
        
      }
       =
       {
          {
           
                  
          创建一个缓冲区
           =  
          
          
            = 
            = 
                  首先写出数据的长度
             向服务端写数据
          
        }
      }   {
        
      }  {
        
      }
    }
：客户端是怎样获取服务端的返回数据的？
类和类中的相关方法如下
：

     {
      ……
        {
          具体的处理方法
      }
      
     ……
}
：
   {
        {
        
      }
      
       {
          =                      阻塞读取
         
                 
            =     在池中找到发送时的那个对象
          =       阻塞读取对象的状态
          ==  {
            =  
                      读取数据
        将读取到的值赋给对象，同时唤醒等待线程，贴出代码
                        
                         删除已处理的    
        }    ==  {
        ……
        }    ==  {
        ……
        }
      }    {
        
      }
}
：
     {
       = 
         具体实现
}
    {
       = 
                唤醒等待线程
    }
启动一个处理线程，读取从服务端传来的对象，将对象读取完毕后，唤醒处理线程。就这么简单，客户端就获取了服务端返回的数据。客户端的源码分析暂时到这，下面我们来分析端的源码
源码分析
内部类如下

 ：用于存储客户端发来的请求

 ： 监听类，用于监听客户端发来的请求，同时内部还有一个静态类，，当监听器监听到用户请求，便让读取用户请求。

 ：响应请求类，请求处理完毕，由发送给请求客户端。

 ：连接类，真正的客户端请求读取逻辑在这个类中。 ：请求处理类，会循环阻塞读取中的对象，并对其进行操作。


初始化
是怎样初始化的端的呢？
初始化时一定初始化了的端，那我们去看看的初始化源码
      {
   ……
     创建  
      = 
      =  {
        =
        _____
                    _____
      获得
       =   
           
            
       = 
      
}
获得
     =  
            
        

   ……
      启动     只允许连接该
      =  {
        启动   为服务的
    }
    
  }
的对象是通过类的方法获得的。类中的源码如下
           
                                 
                                   
                                    
 
{
            
}
是一个创建对象的工厂方法，但创建的却是类的对象。
运行
初始化后，端就运行起来了，看看的源码
  启动服务 
   
{
      启动
       启动
     =  

       =     
    {
         =  
           逐个启动
    }
}
处理请求

分析源码得知，端采用监听客户端的连接，下面先分析一下的构造函数

        {
       =   
       创建并设置成非阻塞式
       = 
      

       将 绑定到本地端口
        
       =  
       获得一个
      = 
       =  
       = 
      启动多个线程，为了防止请求多时服务端响应延时的问题
         =      {       
          = 
          =  
         = 
        
      }
       注册连接事件
       _
            
      
    }
在启动线程时，服务端会一直等待客户端的连接，下面贴出类的方法
  
{
    ……
     
    {
          = 
        
        {
            
              = 
             
            {
                 = 
                
                
                {
                     
                    {
                         
                                 具体的连接方法
                    }
                }
                  
                {
                }
                 = 
            }
        }
          
        {
            ……
        }
类中 方法中的关键源码如下：
           {
        = 
        =  
       
        =  =  { 建立连接
        
        
          =   从池中获得一个
         {
            激活，设置为
            = 将读事件设置成兴趣事件
           =    创建一个连接对象
             将对象注入
            {
             
            
          }
        …… 
        }  {
设置为，采用唤醒一个其实代码十三中启动的每个都使
用了方法等待。因篇幅有限，就不贴出源码了。
          
        }
      }
    }
当被唤醒，接着执行方法。

接收请求类中的方法和类中的方法源码如下：

： 
      {
        = 
        =   获得对象
        ==  {
          
      }
      
       {
         =      接受并处理请求  
      }    {
       ……
      }
     ……    
}
：
      {
        {
        ……
          {
            ==  {
             = 
          }
         读取请求头
           =  
              ||    {
             
          }
         读取请求版本号  
            = 
            =   {}
        ……  

           = 
        }
         读取请求  
         =  

          ==  {
         ……
            {
         ……
          }  {
            处理请求
          }
        ……
          }
        } 
         
      }
    }

获得对象

：   
      
         {
        {
        
      }  {
        
         = 
          {
                
                    
                      
        }
      }
}
：
            {
        =
          
        =        尝试读取
        =  读取参数
              

        =      封装成
          将存入
         增加请求的计数
    }

处理对象对对象的处理是类中的内部类来处理的。类中方法中的关键代码如下：

    {
         {
             =  弹出，可能会阻塞
          ……
          调用类中的方法，但该方法是抽象方法，具体实现在类中
           =   
            {
              
                         ==      
                          
             ……
            给客户端响应请求
            
          }
  }

返回请求类中的方法源码如下：

    
{
     
    {
        
          == 
        {
             返回响应结果，并激活
             
        }
    }
}导语： 随着科技和社会的进步，移动支付已经成为大众支付的第一选择，支付越来越便捷，公司在近几年也突飞猛进，随之诞生了一下巨型业务，加上各种节日，活动日的造势，支付量常常有倍，倍于日常量的突发支付量。在这个过程中，我们总结了一些经验。

 整体设计
  限流
整个支付流程下来，需要经历很多环节，如：加载商店页、加载订单页、下单、支付、发货等，其中如果涉及到活动的话，可能还有各种资格查询等。整个交易流程比较长，其中任何一个环节失败，都可能导致交易失败，最终所有已经完成的操作都浪费掉了。当洪峰流量来临时，各阶段均可能因超载而导致整个交易失败；更甚者，如果这种状况得不到有效的控制，用户反复重试，还会对系统造成进一步的伤害风暴。最终，大部分的人都不能交易成功。
通过扩容，是可以解决这里的问题的，但是任何方案都需要考虑成本因素。解决问题的阶段越早，成本越低。因此，在不大规模扩容的情况下，我们采用“及早拒绝”来解决一大部分问题。
及早拒绝：
为了避免进一步的伤害风暴导致整个支付系统瘫痪，我们采用了“入口竞争”的措施，海量用户通过竞争有限的机会，进入后续的支付环节，没有取得机会的用户被及时拒绝，保障已经取得机会的用户尽可能的完成整个支付流程。
友好反馈、频率控制：
对于没有获得机会的用户，我们会在秒之内就给出拒绝的结果，并给出建议性的提示，将用户的页面冻结秒，配上解冻倒计时，解冻后才能再次发起“竞争”购买的动作。
通过这些操作，用户可以迅速拿到结果，不用不知所措的傻等转菊花；并对自己的等待有一个预期，比如刷了几次都没有打开的话，用户可能会稍后再来，不用一直等。通过竞争和倒计时，也会增加以下用户抢购的紧迫感。
 排队
在支付环节，用户已经通过竞争，进入了支付流程，后续的就需要尽力帮用户完成整个流程。我们引入了预下单的机制，让用户通过预下单进行排队，并引入一个查单，用户可以通过查单查询自己的排队进度。排队完成后，自动拉起支付密码输入框。以排队的体验代替竞争的体验，使用户有一个更好的预期，减少中途放弃的概率。
在发货环节，用户已经支付完成，待发放的物品，也通过排队进行发放，避免对后端发货系统的一个冲击。
 有损服务
支付流程中，有涉及到用户体验的，如支付成功通知，各种提醒等体验性的流程。在洪峰情况下，可以选择性的关闭，保证支付系统核心功能的正常运转。
 分离原则
主要涉及：业务分离、渠道分离、部署分离、快慢分离、用户分离等。尽可能的保证业务之间、渠道之间、不同的系统之间、用户之间的相关影响最小化。快慢系统分离，尽可能保证整体系统的高效运转。
 单系统设计
 容量预估与资源监控
每个系统通过压测和现网演练，可以评估出一个容量，并针对、内存、磁盘、网络等指标进行实时监控，并在负载告急之前能给出告警。
 尽力而为
第一点的限流实际是整个支付系统的过载保护的一部分，这里再提一下单系统的过载保护。首先所有的系统，都具备保护自己的能力；同时所有的系统，也需具备一定的保护后端系统的能力。系统容量需要一定余量，并在左右的容量时进行预警，以提醒运维提前进行准备，在时，系统能够自己进行过载保护，确保系统不会被冲垮。
 动态调节
基于监控，实现动态扩缩容，调节单个系统的容量。目前还没完全自动化
通过以上的设计计平在面对洪峰的情况下，顺利扛下了不断增长的业务需求。并在一次次实践检验后，我们会不断的完善和细化这方面的实践。作者：谢代斌

研究测试断开和异常的各种情况，以便于分析网络应用比如断网的原因和场景，帮组分析和定位连接异常掉线的问题，并提供给相关的开发测试人员作为参考。
各个游戏接入都存在一定的掉线问题，而且有的游戏项目的掉线比例还比较高，现在互娱自研游戏的网络接入基本上都用的是和组件该组件请参考附件的《_开发指导手册》，因此参与其掉线原因分析和研究。
在参与项目的掉线问题研究分析过程中，增加了玩家每个连接的流水日志和增加了每个连接的上报日志，通过这些日志记录了每一次连接的断开原因和相关统计数据，其中包括了连接异常断开时的底层错误码。
通过对的流水日志和的日志进行统计分析，发现连接异常断开时的错误码大部分是“    ”下或“          ”下，单纯从错误码本来来说，大家都明白是“网络被对端重置了”，但究竟什么情况下会导致这种情况呢？因此就对的各种关闭情况做了进一步的测试研究。
一  异常关闭的研究测试
 服务器端只消息而不消息
 测试方法
服务器程序在接受客户端的连接后几秒钟，客户端程序在连接后立即发送很多消息给对端后做相应动作退出或等待，服务器程序完后开始消息。
注意：服务器程序测试了和版本，但客户端只测试了版本，如果是客户端则有些的结果会不一样。
 测试 

客户端程序正常运行的情况下，拔掉网线，杀掉客户端程序

目的：模拟客户端死机、系统突然重启、网线松动或网络不通等情况。
结论：这种情况下服务器程序没有检测到任何异常，并最后等待“超时”才断开连接。

客户端程序发送很多数据包后正常关闭并进程或不退出进程

目的：模拟客户端发送完消息后正常退出的情况。
结论：这种情况下服务器程序能够成功接收完所有消息，并最后收到“对端关闭”返回零消息。

客户端程序发送很多数据包后不关闭直接进程

目的：模拟客户端程序退出而忘记关闭的情况比如通过窗口的关闭图标退出进程，而没有捕获相应关闭事件做正常退出处理等。
 结论：这种情况下服务器程序能够收到部分消息，然后收到“    ”下或“          ”下错误。

客户端程序发送很多数据包的过程中直接进程

目的：模拟客户端程序崩溃或非正常方式结束进程比如下 或的任务管理器杀死进程的情况。
结论：这种情况下服务器程序很快收到“    ”下或“          ”下错误。
服务器端消息并应答消息
 测试方法
服务器程序在接受客户端的连接后几秒钟，客户端程序在连接后立即发送很多消息给对端后做相应动作退出或等待，服务器程序完后开始和消息。
注意：服务器程序测试了和版本，但客户端只测试了版本，如果是客户端则有些的结果可能会不一样。
 测试结果

客户端程序发送很多数据包后正常关闭并进程或不退出进程

目的：模拟客户端正常关闭后，服务器端在检查到对端关闭前向客户端发送消息的情况。
结论：这种情况下服务器程序接收和发送部分消息后，在消息时产生“  ”下或“            ”下错误。

客户端程序发送很多数据包后不关闭直接或进程

目的：模拟客户端程序退出而忘记关闭、或客户端程序崩溃或非正常方式结束进程的情况。
结论：这种情况下服务器程序在或消息时产生“    ”下或“          ”下错误。
 效果和总结
 总结
发现网络异常特别是下的错误或下错误的情况很多，比如网络本身的问题、中间路由器问题、网卡驱动器问题等不可抗拒因素，但下面是应用程序本身可能会导致的问题，也是我们需要进一步研究和解决的情况，特别是程序崩溃导致问题：

当连接的进程在忘记关闭而退出、程序崩溃、或非正常方式结束进程的情况下客户端，会导致连接的对端进程产生“    ”下或“          ”下错误。

当连接的进程机器发生死机、系统突然重启、网线松动或网络不通等情况下客户端，连接的对端进程可能检测不到任何异常，并最后等待“超时”才断开连接。

当连接的进程正常关闭时，对端进程在检查到关闭事件之前仍然向发送消息客户端，则在消息时会产生“  ”下或“            ”下错误。


 效果
针对项目的掉线问题，通过问卷调查和联系个别玩家等方法，发现掉线的情况很大部分是客户端程序直接退出了，因此推动项目组实现了客户端的上报功能，最后通过客户端的上报的统计数据得出客户端程序的崩溃比例比较高，占了总掉线的很大比率，当然其它情况也存在，但比例相对比较小。
因此，项目首先应该解决客户端程序的崩溃问题，如果该问题解决了，也就解决大部分掉线问题。
二 异常关闭的进一步研究测试
 背景
项目游戏在跨服跳转时的掉线比例比较高，经过分析和的日志，发现掉线出现的情况是：发送了跨服跳转消息后立即关闭了，客户端进程在接收到跨服跳转消息之前发送消息后收到 错误，然后做断线重连失败。
项目实现跨服跳转的流程是给客户端程序下发的跨服跳转命令的同时携带了请求，也就是说在向客户端转发跨服跳转消息后立即就会关闭当前的连接，而且项目的客户端程序会定期不断地向服务器上报消息。这又怎么会导致客户端程序收到错误而呢？鉴于此，对的连接做进一步的场景测试分析。
 异常进一步测试研究
 测试方法
客户端和服务器端程序建立连接，服务器程序在缓冲区中有消息或没有消息的情况下关闭，客户端在对端已经关闭的情况下继续和消息。
注意：服务器端只测试了版本，但客户端测试了和两个版本。
 测试结果

服务器端已经了，客户端再发送数据

目的：测试在对端进程已经关闭时，本端进程还未检测到连接关闭的情况下继续向对端发送消息。
结论：第一包可以发送成功，但第二包发送失败，错误码为“            ”下或“  ，同时收到信号”下错误。

服务器端发送数据到后了，客户端再发送一包数据，然后接收消息

目的：测试在对端进程发送数据后关闭，本端进程还未检测到连接关闭的情况下发送一包消息，接着接收消息。
结论：客户端能够成功发送第一包数据这会导致服务器端发送一个包 已抓包验证，客户端再去时，对于和程序有如下不同的表现：客户端程序：失败，错误码为“            ”。
客户端程序：能正常接收完所有消息包，最后收到正常的对端关闭消息这一点与下不一样，包没有被提前接收到。

服务器端在的接收缓冲区中还有未接收数据的情况下了，客户端再收包

目的：测试在的接收缓冲区中还有未接收数据的情况下关闭时，对端进程是否正常。
结论：这种情况服务器端就会向对端发送包，而不是正常的包已经抓包证明，这就会导致客户端提前包比正常数据包先被收到收到“          ”下或“    ”下错误。
 效果和总结
 总结
应用程序某些看是正常的行为下也可能会导致对端接收到异常，比如当接收缓冲区中还有未收数据的情况下关闭，则会导致对端接收到异常关闭而不是正常关闭；反过来说，当检测到异常关闭时并不一定表示业务上出问题了，因为很可能就是业务正常结束了。下面是本次测试的主要结论：

当连接的对端进程已经关闭了的情况下，本端进程再发送数据时，第一包可以发送成功但会导致对端发送一个包过来：之后如果再继续发送数据会失败，错误码为“            ”下或“  ，同时收到信号”下错误；之后如果接收数据，则下会报的错误，而下则收到正常关闭消息。

连接的本端接收缓冲区中还有未接收数据的情况下了，则本端会向对端发送包，而不是正常的包，这就会导致对端进程提前包比正常数据包先被收到收到“          ”下或“    ”下错误。


 效果
项目跨服跳转的掉线问题有相当一部分的种情况是向客户端转发跨服跳转消息后立即关闭连接，而此时刚好客户端向发送了数据包：

第一种情况：在关闭的时刻其的接收缓冲区中有未收的消息，这就使得进程的向客户端发送的是包而不是正常结束的包，所以客户端程序就会提前收到包包会比正常数据提前收到，而不会先收完跨服跳转消息后再接收到正常结束消息，这就导致客户端收到网络异常断线而做重连，但之前的连接是主动关闭的，所以不可能重连成功，从而导致掉线。

第二种情况：已经关闭了后，客户端在接收到跳转消息和检测到关闭之前向发送了消息，这就会导致客户端程序收到异常断线而做重连并失败。


最后，与项目项目组一起讨论，改进了大部分跨服跳转的业务流程后，掉线比例减少了很多，当然还是存在一定比例的掉线，但这应该就是其它一些原因了网络异常问题原因很多，国内当前的网络环境下，掉线问题是不可能完全避免的。
三结束语
通常情况下，向的发送完数据后关闭，大家认为这样很正常的方式肯定没有问题，对端应该正确收完数据后收到的关闭消息，但实际上在某些情况下并非如此：当本端的接收缓冲区中有未收的数据时关闭，这会导致对端收到的异常关闭消息；当对端在本端已经关闭的情况下再次发送消息时，也会导致对端收到异常关闭消息；还有为了避免_而设置了_选项的话，也会导致连接提前夭折使对端收到异常关闭消息。
有些时候业务流程对是否引起掉线也很重要特别是连接关闭流程，比如前面的项目的跨服跳转掉线问题很大部分就是因为请求关闭连接导致的。建议各个游戏项目的关闭流程包括跨服跳转的原连接的关闭最好都由客户端发起关闭，这样就一定程度上避免上述问题的发生因为客服端发起关闭的时候，一般业务流程都走完了，服务器端也不会再向客户端发送消息了。
程序收到网络异常的情况很多最多的就是下的错误和下的错误：有网络本身的问题、也有应用使用不当的问题；有运营商之间的跨网络问题、网络中间路由器问题、玩家机器硬件比如网卡及其驱动问题和操作系统、杀毒软件、防火墙等软件问题，还有玩家的上网设备和路由器等中间设备问题等，但客户端程序崩溃问题有可能会占掉线的很高比例，这也是值得我们注意和改进的地方。还有种情况值得我们注意，有些的路由器，当包大小超过其值时会导致用户机器的网络断开，从而引起掉线这个问题在某些项目的个别玩家中已经出现过。
网络异常关闭引起掉线是当前游戏中普遍存在的问题，区别只在于掉线的比例多少，特别是国内各运营商之间跨网络访问更是不太顺畅，要将其完全消除是不可能的，但我们的目标是将其控制在较小的可接受范围内。人工智能哲学作为一个行当，在国内基本上是还没有确立起来。总体来说国外的情况比我们好一点，马马虎虎算一个哲学分支。举个例子，玛格丽特·博登是研究人工智能哲学的一个比较大牌的人物，一个女哲学家，英国人。她为什么研究比较好？因为她和、卡耐基梅隆这些研究人工智能的重镇有非常密切的联系，和那里的人工智能界的大佬都是私下的朋友。而且玛格丽特除了是哲学专家以外，在计算机、生物学、心理学方面都有相应的学位。我们国家在文科和理科的交汇方面的确做得不是很好。
一、哲学能够为人工智能做些什么？

哲学要做的第一件事是思考大问题，澄清基本概念。

与哲学家相比较，一般的自然科学家往往只是在自己的研究中预设了相关问题的答案，却很少系统地反思这些答案的合法性。

第二，哲学在不同学科的研究成果之间寻找汇通点，而不受某一具体学科视野之局限。

举一个例子，用军事上的比方，哲学更像是战略性思考。如果你是在一个炮兵学院里面，不同的研究炮兵战术的军官会讨论炮兵战术所牵扯到的具体的几何学问题。但是站在战略层面，它可能对于这些非常细微的问题会忽略，更多的会考虑炮兵在军事编制中所扮演的功能角色，站在更高的层面去看。这可能帮助大家理解哲学应该是干什么的。

第三，重视论证和辩护，相对轻视证据的约束。

人工智能需要哲学吗？
我个人认为如果说化学家、物理学家和生物学家对哲学的排斥还有一点道理的话，人工智能对哲学的排斥是最没道理。就对于哲学文化的宽容程度而言，科学绝对算是个科学界内部的异数。从某种意义上说，该学科本身的诞生，就恰恰是“头脑风暴”般的哲学思辨的产物。
人工智能异数异到什么地步？以至于现在教育部的学科目录里面没有人工智能，这是很有讽刺意味的事。也许以后会形成一级学科，但是现在还没有形成。
我们先看下阿兰·图灵，阿兰·图灵 ，在英国哲学杂志《心智》上发表了论文《计算机器和智能》 。在文中他提出了著名的“图灵测验 ”的思想。

此文牵涉到了对于“何为智能”这个大问题的追问，并试图通过一种行为主义的心智理论，最终消弭心理学研究和机器程序设计之间的楚河汉界，同时还对各种敌对意见提供了丰富的反驳意见。这些特征也使得这篇论文不仅成为了科学的先声，也成为了哲学史上的经典之作。
年发生大事件—— 会议，在这一年夏天的美国达特茅斯学院 ，一群志同道合的学者驱车赴会，畅谈如何利用刚刚问世不久的计算机来实现人类智能的问题，而洛克菲勒基金会则为会议提供了美元的资助这些美元在当年的购买力可非今日可比的。

 年达特茅斯会议当事人重聚，左起：摩尔、麦卡锡、明斯基、塞弗里奇、所罗门诺夫
在会议的筹备时期，麦卡锡 ，～建议学界以后就用“人工智能”一词来标识这个新兴的学术领域，与会者则附议。
参加达特茅斯会议的虽无职业哲学家，但这次会议的哲学色彩依然浓郁。首先，与会者都喜欢讨论大问题，即如何在人类智能水平上实现机器智能而不是如何用某个特定的算法解决某个具体问题。
其次，与会者都喜欢讨论不同的子课题之间的关联，追求一个统一的解决方案这些子课题包括：自然语言处理、人工神经元网络、计算理论以及机器的创造性，等等。
最后，不同的学术见解在这次会议上自由碰撞，体现了高度的学术宽容度从麦卡锡完成的会议规划书   来看， 没有什么证据表明这次形式松散的会议是围绕着任何统一性的、强制性的研究纲领来进行的。让人欣慰的是，这些“哲学化特质”在美国日后的研究中也得到了保留。
为何科学对哲学的宽容度相对来得 就比较高？这背后又有何玄机呢？
这首先和科学自身研究对象的特殊性相关的。
的研究目的，即是在人造机器上通过模拟人类的智能行为，最终实现机器智能。很显然，要做到这一点，就必须对“何为智能”这个问题做出解答。
如果你认为实现“智能”的实质就是去尽量模拟自然智能体的生物学硬件。你就会去努力钻研人脑的结构，并用某种数学模型去重建一个简化的神经元网络这就是联结主义者所做的。现在我们都知道有一个类脑研究计划，这种研究有复杂版本和简单版本，复杂版本就是蓝脑计划一样，把大脑运作的信息流程尽量逼真的模拟出来，比较简单的就是简化的神经元网络。
站在专业的研究脑科学的立场上，神经元网络很不神经，离真正的神经活动来说，它是高度简化，但是站在很宏观的立场上，至少你说神经元网络也是受大脑的启发和影响。这个路线很多人认为是对的，我认为可以做出一些成果，但是不要抱有太高的期望。
如果你认为智能的实质仅仅在于智能体在行为层面上和人类行为的相似。那么你就会用尽一切办法来填满你理想中的智能机器的“心智黑箱”无论是在其中预装一个巨型知识库，还是让其和互联网接驳，以便随时更新自己的知识——只要管用就行。
由此看来，正是因为自身研究对象的不确定性，研究者在哲学层面上对于“智能”的不同理解，也才会在技术实施的层面上产生如此大的影响。很明显，这种学科内部的基本分歧，在相对成熟的自然科学那里是比较罕见的。
其次，科学自身的研究手段，缺乏删除不同理论假设的决定性判决力，这在很大程度上也就为哲学思辨的展开预留了空间。
二、哲学文化渗入的几个具体案例
下面我们讲一些案例，这些案例可以证明哲学思维对是非常有用的。
霍伯特·德瑞福斯   ，美国加州伯克利分校哲学教授，美国最优秀的现象学家之一，在海德格尔哲学、福柯哲学、梅洛庞蒂哲学研究方面很有造诣。让人惊讶的是，以欧陆人本主义哲学为背景的德瑞福斯，却写下了哲学领域最富争议的一部著作《计算机不能够做什么？》 以及其修订本 ，并使得他在领域的社会影响超越了他的学术本行。那么，他为何要转行去写一本关于的哲学书呢？

霍伯特·德瑞福斯   
  ，《机械战警》里面出现某个反对机器人有自动开火能力的哲学家和这个哲学家的名字一样的，我认为编剧是故意这么干的，因为他在美国是非常有名的搞人工智能哲学的专家。他为什么要去搞人工智能哲学？
非常有意思，根据他自己和记者的讲法，这和他在麻省理工学院教学时所遭到的一些刺激相关。在年就有学生明白地告诉他，哲学家关于人性的思辨现在都过时了，因为闽斯基等科学家据说在不久后就可以用工程学的方法实现人类智能的方方面面。
德氏觉得这话近乎于天方夜谭，但是为了做到公允起见，他还是在不久后去了美国的顶级民间智库“蓝德公司” 进行调研——因为恰恰在那个时候，司马贺、纽艾尔和肖 等界的顶级大腕也正在那里从事研究。经过一段时间的分析以后，德氏最后确定自己对于当时的规划的怀疑乃是有根据的，并在年扔出了他掷向主流界的第一块板砖：《炼金术和》 。
德氏对于主流进路的批评意见很多，其中比较有意思的一条是，真实的思维是不能够被明述的程序所穷尽的。比如说你在打网球的时候，是不是得先看到了球，然后计算其入球的角度，计算你的拍子接球的角度以及速度，最后才能够接到球？显然不是这样的，因为由上述计算所带来的运算负荷是很高的，我们人类的大脑未必“消费得起”。
实际上，熟练的网球手仅仅是凭借某种前符号规则的直觉领悟才能够把握到接球的正确时机的——而对于这些直觉本身，传统的程序设计方案却往往是无能为力的。
不过，德氏本人并不认为所有的进路都无力解决上述问题。换言之，一些更为新颖的进路或许能够对如何把握这些前符号的直观提供方案。他认为，这些进路必须更为忠实地反映身体的结构，以及身体和环境之间的互动关系，而不仅仅是在符号的内部世界中打转。他的这个想法，以后在专家布鲁克斯的理论建树中得到了发扬光大。
布鲁克斯在论文《大象不下棋》中以哲学家的口吻评价道：新潮是建立在物理根据假设  之上的。该假设说的是，为了建立一个足够智能的系统，我们就绝对需要将其表征的根据奠定在物理世界之中。我们关于这一工作路径的经验告诉我们，一旦我们做出了这种承诺，那种对于传统符号表征的要求就会马上变得黯淡无光。

专家罗德尼·布鲁克斯
这里的核心命意在于，世界就是认知系统所能有的最好的模型。世界一直能够及时更新自身。它总是包含了需要被了解的一些细节。这里的诀窍就是要让系统以恰当之方式感知世界，而这一点常常就足够了。为了建立体现此假设的模型，我们就得让系统通过一系列感知器和执行器而与世界相联系。而可被打印的字符输入或输出将不再引起我们的兴趣，因为他们在物理世界中缺乏根据。
按照布鲁克斯的看法，打败李世石很伟大吗？他第一个反应是有什么了不起？因为他认为智能的重要性不是在于下棋，举出他的反例是大象不下棋，你造一个人造大象，模拟大象的所有生命活动，其实大象有很复杂的活动。或者海豚不下棋，你造一个人造海豚，下棋算什么本事？什么德州扑克，他都不在乎。他更关心怎么制造智能系统和外部世界由嵌入式的认知，能够把外部世界本身直接当作这样的认知对象，而不是当中造出一个中间的符号。
这种想法在很大程度上具有一定哲学上的创新性，布鲁克斯本身的研究更加注重的是对机器昆虫这种低等动物的行走能力的模拟，对高级智能是比较轻视的。这也是建立在很基本的观察上，人工智能研究的特点是小孩子越是容易做到的事，现在人工智能越难做到。比如很大程度的感知、把握，这是非常困难的。
为何科学训练中缺席哲学训练？
首先，对于处于“学徒期”的科学入门者而言，学会服从既定的研究范式乃是其第一要务，而对这些范式的“哲学式怀疑”则会导致其无法入门，而不是像哲学一样，在这个范式以外还有其他的可能性，有不同意见的交流。
第二，严格的一级、二级、三级学科分类导致学生们忙于如何熟悉特定领域内的研究规范，而无暇开拓视野，浮想联翩。根据我对教育部的分类了解，人工智能在中国是不存在的学科，这是很奇怪的事。
稍微对人工智能这门学科了解的人都知道，大概十几年前搞人工智能的人不敢说自己搞人工智能，怕被扔砖头，大家认为是骗子，现在行情突然发生变化。如果你站在具体学科分类的内部来看学科，你就不容易受到其他学科的思维方式的滋养。
第三，对于权威科学模式的服从，在很大程度上使大家不愿意接受异说。人工智能学科最大的特点是很喜欢攻击对方是异说，现在深度学习起来了，但深度学习的前身是神经元网络，它最大的敌人就是符号，符号和神经网络之间的关系基本是曹操和刘备的关系，就是汉贼不两立，双方几乎在人脉、资金、学术观点所有地方展开比《甄嬛传》还要激烈的宫争。
现在从整体看来，神经元网络的儿子就是深度学习占据了比较高的位置，历史上它被打压的间很长。我自己观察下来，人工智能中不同的争论是对资金的方向的控制。
传统最典型的哲学问题是框架问题：
常识告诉我们，手若抓起了积木，只会改变积木的位置，却不会改变积木的颜色以及大小，因为手抓积木这个动作和被抓对象的颜色以及尺寸无关。但一个系统却又如何知道这一点呢？除非你在定义“手抓”动作的时候得说清，这个动作一定不会引起什么。
但这种定义必然是非常冗长的，因为这会逼得你事先将事物的任何方面都罗列清楚，并将这些方面在相应的“框架公理”中予以事先的排除。很显然，对于“手抓”命令的任何一次执行，都会调用到这些公理，这就会使得系统在执行任何一个简单任务的时候都会消耗大量的认知资源。然而，我们又都期盼系统能够用比较少的资源来解决这些看似简单的任务。这就构成了一个巨大的冲突。
语义相关性究竟是怎么一回事情？既然计算机的在句法运作的层面上只能够根据符号的形式特征进行操作，它又是如何理解自然语词之间的内涵性语义关联的？形式逻辑，或者别的形式系统，究竟是否可能以一种简便的方式刻画语义相关性？
你可以预先在逻辑、公理里面说清楚所有事情之间的相关、不相关，但是没有办法写成一个可以执行的程序。你写这样的程序，在任何一种情况下，你的机械手举起任何一块积木，这件事情只会导致它的位移，而不会改变被举起来的积木的颜色。你觉得啰嗦吗？这不是最可怕的，更可怕的是机器会不停问你，会引起这个、引起那个吗？很烦，因为机器不懂我们一下子能把握的相关性和不相关性，这是很恐怖的。
所以丹尼尔·丹尼特写了一篇论文说，如果你用这个原理去造一个拆弹机器人，剪黄线还是剪红线、剪线会引起什么，他想半天，炸弹炸了。因为剪炸弹的线是有时间限制的。你不能想象这个东西是有用的东西。
接《复旦教授徐英瑾：人工智能研究为何需要哲学参与 下》个人介绍：年加入腾讯， 成员。熟悉  编程，有音视频，图像识别开发经验。目前在团队中主要从事深度学习预研工作。

导语
学习 ， 等深度学习框架前，需要先了解一些基础概念。本文以笔记的形式记录了一个零基础的小白需要先了解的一些基础概念。
人工智能，机器学习和深度学习的关系

人工智能 ——为机器赋予人的智能
强人工智能 ：无所不能的机器，它有着我们所有的感知甚至比人更多，我们所有的理性，可以像我们一样思考
弱人工智能 ：弱人工智能是能够与人一样，甚至比人更好地执行特定任务的技术。例如， 上的图像分类；或者  的人脸识别。
强人工智能是愿景，弱人工智能是目前能实现的。
机器学习—— 一种实现人工智能的方法
机器学习最基本的做法，是使用算法来解析数据、从中学习，然后对真实世界中的事件做出决策和预测。
深度学习——一种实现机器学习的技术
机器学习可以通过神经网络来实现。可以将深度学习简单理解为，就是使用深度架构比如深度神经网络的机器学习方法。目前深度架构大部分时候就是指深度神经网络。
神经网络组成

一个神经网络由许多神经元组成，每个圆圈是一个神经元，每条线表示神经元之间的连接。 表示的输入数据， 表示的是输出数据， 表示每层连接的权重。 也就是我们构造完神经网络之后需要确定的。
最左边的叫做输入层，这层负责接受输入数据。
最右边的叫做输出层，我们可以从这层获取神经网络输出数据
输入层和输出层之间叫做隐藏层。隐藏层层数不定，简单的神经网络可能是  层，复杂的也可能成百上千层，隐藏层较多的就叫做深度神经网络。
深层网络比浅层网络的表达能力更强，能够处理更多的数据。但是深度网络的训练更加复杂。需要大量的数据，很多的技巧才能训练好一个深层网络。
问题：假设计算速度足够快，是不是深度网络越深越好？
不是。深度网络越深，对架构和算法的要求就越高。在超过架构和算法的瓶颈后，再增加深度也是徒劳。
神经元感知器
神经网络由一个个的神经元构成，而一个神经元也由三部分组成。


输入权值  每个输入会对应一个权值 ，同时还会有一个偏置值 。也就是图中的 。训练神经网络的过程，其实就是确定权值  的过程。
激活函数  经过权值运算之后还会经历激活函数再输出。比如我们可以用阶跃函数  来表示激活函数。



输出  最终的输出，感知器的输出可以用这个公式来表示


神经元可以拟合任意的线性函数，如最简单拟合  函数。

 函数真值表如上图所示。取  = ； =   = 。激活函数取上面示例的阶跃函数  表示。可以验证此时神经元能表示  函数。
如输入第一行， = ， =  时，可以得到

 为 ，这就是真值表的第一行。
在数学意义上，可以这样理解  函数的神经元。它表示了一个线性分类问题，它就像是一条直线把分类 ，红叉和分类 ，绿点分开

而实际上，神经元在数学上可以理解为一个数据分割问题。神经元是将神经网络转换成数学问题的关键。比如需要训练神经网络做一个分类器，那么在数学上可以将输入的参数，，理解为  维坐标系设  是  元向量上的  个点，而每个神经元则可以理解为一个个拟合函数。取  为 ，放在最简单的二维坐标系里面进行理解。
此时输入参数对应的是下图中的黑点，每个神经元就是黑线由于激励函数的存在，不一定像下图一样是线性的，它可以是任意的形状。神经网络由一个个神经元组成，这些神经元表示的拟合函数相互交错就形成了各种各样的区域。在下图中可以直观的看到，此时分类问题就是一个数学的问题，输入参数落在  区域，那么就认为他是分类 ，落在  区域，则认为他是分类 。依次类推，我们便建立了神经网络分类器在数学上的表现含义。

激活函数
事实上，一个神经元不能拟合异或运算。在下图中可以直观的看到，你无法直接用一条直线将分类  和分类  分隔开。

此时可以借助激活函数来做分割。激活函数选择阀值函数，也就是当输入大于某个值时输出 激活小于等于那个值则输出 没有激活。
拟合异或函数的神经网络如图所示：

图中神经网络分成三层。在第二层中，如果输入大于  则输出 ，否则 ；第三层，如果输入大于 ，则输出 ，否则 
第一层到第二层阀值 ：

第二层到第三层阀值 ：

可以看到最终结果与异或结果吻合。
其实，这里放在数学上理解体现的是一个升维思想。放在二维坐标中无法分割的点，可以放在三维坐标中分割。上面的神经网络可以理解为只有最后一层，三个参数的神经元。激活函数是用来构造第三个参数的方式。这样等同于将三个点放在三维坐标系中做数据分割。相当于在二维中无法解决中的问题升维到三维中解决。

深度学习过程

构造神经网络
确定学习目标
学习

如何进行深度学习，过程基本都可以分为这三步来做。用一个简单的例子来说明。如图，假设我们需要通过深度学习来识别手写图片对应的数字。

构造神经网络。这里可以采用最简单的全连接神经网络，也可以采用卷积神经网络。同时确定神经元的激励函数，神经网络的层数等。基础概念篇不做过多介绍
确定学习目标。这里简单假设我们所有输入的都是手写的数字图片。那么这里就有  个输出，分别对应  的数字的比例。我们用 表示，每个  值代表这张图可能对应该数字的概率 表示这张图是数字  的概率。对于上图中第一个输入图片，在训练过程中，我们知道第一张图片输出应该是数字 。于是我们期望输出是 。但是实际上，我们的模型不是完美的，肯定会有误差，我们得到的结果可能是 。那么就会有个训练得到的结果和期望结果的误差。
这时候我们的学习目标也就是希望这个误差能够最小。误差用  来表示，学习目标就是找到权值 ，使得  最小。当然，这里涉及到我们需要用一个公式来表达这个误差 ，这个公式选取也很有学问，不同的公式最终在学习过程时收敛速度是不一样的，通过训练模型得到的权值  也是不一样的。这里先不多介绍。
学习。假设我们神经模型确定下来的权值  与  的关系如图所示这里我们考虑最简单的二维坐标下的情况，原理是相通的，推广到多元坐标也是适用的。由于数学模型的复杂，这里找最小值  的过程其实是找局部最小值的过程。

我们都知道，函数某个位置可导，那么就可以确定这个点的斜率。要找到局部最小值，可以根据这个点的斜率移动 。如根据此时斜率的值我们可以确定  应该向右移动一段距离。

此时移动  的距离称为步长。步长的选取很关键，如果步长过长，那么每次  偏移过大，永远都找不到真正的最小值。而如果步长选取过小，那么收敛会变得很慢，而且有可能在中间某段平滑处停下来，找到的也不是真正的最小值。而步长怎么选择呢？其实比较坑爹，某些时候有经验值，大部分时候则只能自己调整去试验。
在学习的过程中，遇到的最常见的一个问题是走不动了。比如在下图中。从  点走到  点， 点由于斜率平滑，慢慢走到了  点，这时候可能  点斜率是平滑了，那么  将无法继续往下走，永远停留在  点！这样得到的神经网络的误差  显然不是最小的，权值  也不是最佳的。

因此，在神经网络学习过程中，常用的做法是模拟物理世界引入一个动量球。假设每次的移动看成 是一个动量球的移动。在移动过程中，动量球先从最高点往下走，虽然下载下来后斜率减少，但是由于动量球将移动下来的重力势能转变的动能，它会继续往下走，从而移动过平缓区。当动量球到达某个局部最低点的时候，动量球会依靠自己的动能继续滚动，设法寻找到下一个局部最低点。当然，动量球不是万能的，它也可能会遇到山坡上不去最终滑下来停留在某个局部最小值并不是真正的最小值。但是动量球的引入，大大增加了学习过程的鲁棒性，扩宽了局部最小值的寻找范围。

实际上，借助理解神经网络学习的过程，我们会更加理解为什么深度越高的网络不一定就越好。对于深度越高的神经网络，平滑区会越来越多，局部最小点也会越来越多。没有合适的算法，很容易就陷入某个局部最小值里面去，而这个最小值可能还不如深度更浅的神经网络获得的局部最小值小。也就是说，神经网络复杂之后，对架构和算法的要求大大加高。
卷积
如果对卷积这个数学概念还没有了解，可以先看知乎这里通俗的解释。
怎样通俗易懂地解释卷积？
如果没有做过图像处理，还需要先看看卷积核，感受一下它的神奇。
图像卷积与滤波的一些知识点
以图片的卷积为例，深度学习中的卷积计算就是使用卷积核遍历一张图片的过程。

根据对于边缘的处理不同，卷积分为相同填充和有效填充两种方法。相同填充中，超出边界的部分使用补充  的方法，使得输入和输出的图像尺寸相同。而在有效填充中，则不使用补充  的方法，因此输出的尺寸会比输入尺寸小一些。

例 ： 的卷积核在  的图像上进行有效填充的卷积过程

例  两个  卷积核在  图像上进行相同填充卷积过程。动图
图像有 ，， 三个通道。这里使用卷积核也分为  个通道分别进行卷积运算

池化
池化是卷积神经网络中用到的一种运算。在卷积神经网络中，卷积层后面一般是池化层。先进行卷积运算，再进行池化运算。
池化层在神经网络中起到的是降低参数和计算量，引入不变形的作用。
池化常用的是两种，一种是  ，一种是  。下图是   的示意图，可以看到分别找的是  矩阵中的最大值，  则是将矩阵所有值加起来，求平均值。

参考资料

==


作者：赵静
团队：腾讯移动品质中心

一、什么是
单元测试英语： 又称为模块测试，是针对程序模块软件设计的最小单位来进行正确性检验的测试工作。程序单元是应用的最小可测试部件。在过程化编程中，一个单元就是单个程序、函数、过程等。对于面向对象编程，最小单元就是方法，包括基类超类、抽象类、或者派生类子类中的方法—摘自维基百科。
二、为什么要做
年下半年对滴滴接口进行梳理，并进行了接口自动化以及截图半自动化效果验证，但是有几个问题没能得到很好的解决：
的整体代码行覆盖率是，但导航引擎的覆盖率仅；
从这层测试导航引擎，需要回放不同类型的轨迹，测试效率低；
从端上直接测试引擎，不符合分层测试思想，较难发现深层次问题。
三、开展三部曲
熟悉被测模块
无论是做自动化测试也好，集成测试也罢，都需要对待测模块有一定程度的了解，对于单元测试这种需要深入代码逻辑的测试来讲，更是如此。在开展测试之前，主要从几个方面对待测模块进行分析：代码逻辑、圈复杂度、代码深度、扇入、扇出以及代码行等，如下图所示：

图可测性分析
可以看到，该模块有些接口的圈复杂度达到了，而业内设计较好的代码圈复杂度在左右，对这类接口，不建议做，最好的方法是让开发进行优化，降低函数的圈复杂度。
选用合适的测试框架
工欲善其事必先利其器，对而言也是如此。的历史已经非常悠久了，开源框架也是非常多，其中公司出品的和就是做单测的必备神器。
目前该测试框架可以支持、以及 平台。
结合实际情况，整合和框架至测试分支，如下图所示：

图代码组织结构
这里的是嵌入到开发工程里的，做为开发源码中的一个，该和之前的的区别在于，其是基于 的 工程，运行环境是 ，类似于下的可执行文件，而自动化的运行环境都是基于或者是 系统，这些差别所带来的影响会在第节中详细说明。
设计单测
环境部署好了，剩下的就是根据之前的接口分析来设计单测了。这里举一个简单的例子来进行说明，被测接口是，代码逻辑比较简单，如下图所示：

图被测接口
如何设计呢？对这种既有入参，又有返回值的函数，相对是比较好设计并进行结果验证的，我们重点关注入参在不同取值的情况下，函数返回结果是否符合预期。测试代码的编写如下图：

图测试用例
这样的是不是很简单，但在写单测的过程中，我们所面对的测试对象往往复杂的超出你的想象。
四、遇到的问题与解决方案
类的、函数，外部测试类无法调用
开发在设计类时，对于不想让外部类访问的属性以及方法都可以定义为私有的，这并没有什么设计上的问题，但对于测试而言，就要突破这种访问限制，做到和非接口都可以在测试类中被访问到，对这个问题，最简洁快速的方法是：在测试类中将、关键字重定义为，之后在测试类中就可以访问到被测函数的所有方法以及属性。代码如下图：

图可访问
对回调函数的测试
对于中的异步回调，可以采用异步变同步的方法，保证该调的时候可以正常的调用。
以及非虚函数，无法使用现有的框架进行
为什么无法 类型的函数
在 的官方“常见问题”的回答中，是这样的：        即如果你需要一个静态函数，那说明你的程序模块过于“紧耦合”了并且灵活性不够、重用性不够、可测试性不够，你最好是定义一个小接口，通过这个接口来调用那个函数，然后就容易了。
为什么无法非虚函数？
                。允许用基类的指针来调用子类的函数，举个例子，就很容易明白了，如图：

图基类指针调子类函数
非虚函数不具备这样的特性，无法很方便的使用。在实际开发过程中，我们不可能将所有的接口都定义为虚函数，那这个问题如何解呢？
方案一
见 官方手册，                ，即依赖注入。该方案的原理是通过模板类的方式来实现，在开发代码中通过传入实际对象来调用真实接口，在测试代码中通过传入对象来调用出来的接口。官方提供的一个例子，如图：

图 依赖注入
方案二
重新定义一个类，该类并不继承被测类，但是在类中，需要实现和中同样的函数接口，除了待的接口。即被测类和类之间没有任何关系，类中同样实现了被测类中的大部分接口，在测试代码中，通过声明类的对象，来达到测试目的。
上述两种方案都可以解决不能非虚函数的问题，但是都并不完美，均有其缺点：方案一最大的问题是需要修改开发源码，这对于老工程来讲，几乎是不可能的，除非赶上开发重构代码；方案二虽然不会修改开发源码，但是需要维护一套开发代码，当开发代码有变更时，的类需要进行同步修改，无疑加大了测试的维护成本。
如何解决？——
提到，就不得不提百度在年开源的，其提供了平台下程序的功能 可以解决只能虚函数的限制。上的和上的原理差不多，操作基本上是对目标函数进行劫持，替换成自己的函数，然后在自己的函数中进行一些用户预期的操作，比如修改函数返回值等。对原理比较感兴趣的可以拜读下源码：
看起来似乎可以解决我们的问题了，但是不幸的是，目前该技术仅支持了平台，而我们的测试框架是在 系统下搭建的， 是系统，无法在下使用。综合考虑后，决定在系统进行导航引擎的单测。百度以及公司内部都基于以及，对进行了二次封装，形成了自己的单元测试框架和。
和
这两个测试框架的部署，也是废了一番周折这两个测试框架都依赖的底层系统库二进制文件描述库和程序调试，归档等。
Ø：须安装特定版本的以及对应版本的。
 版本不对
所有的以及源码编译没有问题，但是在运行的时候会出现如下图所示的：

图版本错误引起的
版本不对
版本在编译源码库时，会出现链接错误：    ` 上给的解释是：
Ø：仍需要特定版本的系统以及版本。
虚拟机
该虚拟机上安装的也只有相应的和文件，没有的源码，直接运行自带的，运行完好，没有相应的。
注：实际运行过程中对版本也有要求及以上版本，否则会出现：=__   。
虚拟机
上整个测试框架运行没有问题，但是毕竟该版本的系统太老了，官方已经停止维护了，各种软件包都没法通过来安装，这也给后续配置开发环境带来了一定程度的麻烦，所以，就想着能否用高版本的来试下是否能运行，结果是不行的，同样会崩到系统库中。
总结，这两个测试框架都是基于系统的技术，将和完美结合，但是都依赖于系统的底层库，需要特定版本的系统库。虽然有了或者，可以很方便的接口，但方便的同时，我们就不会再去思考如何对复杂接口进行解耦和了。
有些函数扇出太高，可测性太低
有些历史接口，其扇出达到了，代码行也有，圈复杂度更是达到了，对这样的一类接口，几乎不具可测性，如果这类接口又是业务中很重要的接口，建议开发一起从可测性角度出发重新设计，达到可测性后再来开展单元测试。 
五、和测试的差异
测试的对象是公开的，这些有详细的接口说明文档。的测试对象是内部函数，这些函数没有任何文档，需要测试通过或者找开发咨询去了解。
测试可能只需要了解某个被设计来干什么，对其内部如何设计关心的并不多。不单需要知道被测函数的功能是什么，还要了解其是如何设计的，实现原理是什么，要求比测试要高。
测试除了要保证接口本身的功能外，更多的还要关心第三方使用者会如何用，即调用场景。不需要关心外部如何调，更加聚焦函数本身。
数据构造，深入到函数内部，构造的数据不仅仅包含函数入参，还包含函数内部用到的一些数据。
如果代码发生了重构，的历史大多数情况下也得跟着重新设计，测试后期的维护成本也很高。
获取更多测试干货，关注微信公众号：腾讯移动品质中心
版权所属，禁止转载。作者 |熊训德

熊训德英文名：，年毕业于四川大学大学并加入腾讯。目前在腾讯云从事  生态相关的云存储和计算等后台开发，喜欢并专注于研究大数据、虚拟化和人工智能等相关技术。

核心原理
 配置说明了使用哪个类来作为  的  实现类。
 这个默认配置实现就是

其中  的类图如下：
 
最重要的几个成员在类图中列出来了，
 类在  中有一个  类型的引用，即是 ， 以这个引用来控制集群的复制；
 类在复制和管理方面比较重要的几个类是：， 和 。
其中  主要管理 ，包括线程池的初始化、结束，以及通过  管理  的加入和可能的异常。在  中比较重要类的是 ，这个类是实际的  执行者，在  对  初始化时即被启动，会一直去扫描其在  中对应的  文件，有新的记录就往   中传输，并记录到达了的对应  相应传输点。
 主要用于跟踪  中  中  的状态， 的  是通过  来协助完成的， 中有记录每个  文件传输的 ，以及当某个  挂了后也需要  来协助把原来  中负责传输的  分配到另一个  上去。默认的实现类是 。
 是用于记录  过程中的参数状态传输队列长度，时延等，通过一个线程池定时的获取这些状态来实现，可以通过  以  方式获得或者在  的对应 中也能查看。用于监控  。
 的初始化是在初始化完成，开始向   的过程中开始：它在  中有  引用。在 方法中调用  实例化和初始化  。在初始化过程中，包括  以及对应的监控线程池， 和  都要进行初始化。而且实例还会被注册为 ，当  时会回调对应方法。
在写  也注册了 ，但是  并未做传输的动作。很可能是考虑到了性能方面的影响， 的 方案是异步传输。具体做法是初始化后  中对应的  实例会去扫描  文件去传输：

上图是  端  时， 的时序图。
 把  提交到  后封装成  写到 ，成功后即返回。
这时  中有一个异步的后台  线程会异步的去扫描 包括正在写的和已经滚动了的 ，把新增的  以  调用的方式发送到对应的   。
写成功后会到  上更新日志对应成功的  。
图中红色框中的即是  线程所在类。 即是  的  ， 是  的  。
复制的核心过程
这里重点解析  类，与之相关的重点类图如下：

在  过程有两个关键的 ：
第一个在  和  都有的一个引用 ，这个用于控制整个  的复制队列 。具体实现类是 ，因为  可能会有多个   而且复制过程很可能会挂掉，所以  通过  的协助来完成  以及  过程。与  相关  有如下结构：
 
其根  是 {} 图中是默认值 ，在其子节点中有相关的  的状态以及分配的  ，另一块子节点记录了不同的各个  上所传输的  队列以及对应的  。
 
这个  的在三种情况下，在对应的  的  子  下会添加文件：
 时， 启动时把相应  文件名
 时，把新滚动的  添加上
 时，把挂了的  的  文件名和  移动到相应  上
另一个  是在  中用   来代表具体的  的  。具体作用是记录  的，通过这个类打开  读取  。
其实现类是 ，这个类首先是线程安全类，其实是基于数组堆的优先队列。所含对象的排序不是  而是依据对象的自然排序顺序或者是构造函数的  决定的顺序。在其构造函数中的  是  。
 
这个  并不复杂，就是基于开始时间实现了  接口的类，这样使用这个优先队列时间最早小  的排在最前面。
其中最开始时间用 方法从   名字中获得。即是把   的名字以“”点号划分，然后最后一段就是开始时间一个时间戳，比如一个    是这样的

对应  的名字是：
对应  开始时间戳即是：
 
这个  增加有三种情况：



在   被源源不断的写数据过程中，其  文件的文件名被加到  对应的  下，对应为，与此同时对应  的  则被加载到内存中对应为 。持有这两个队列的引用，在其中不断的对这些传输到配置的不同的 中，具体  的时序图如下：

 的异步线程从内存的队列中取出当前需要处理的  的  并打开它。这时候
以  为单位，从上次标记的  开始  中记录扫描这个 ，和写  时类似把  和  重新封装成 ，每个封装后的  按照  中顺序组成一个。扫描过程一直到出现了下面几种情况才会终止：
 的数量超过了配置 ，默认是
所有  的总大小超过了配置 ，默认是
碰到了包括  在内的等各种异常
如果是前两种情况会调用  开始往   发送，如果碰到了异常，如果是  异常则也会发送，如果是其他的异常会  后等待下一次唤醒。
在  方法中，会调用  默认实现类  的  方法，在这个方法中实际操作  一队 。
 有一个流量控制的配置，受两方面影响一个是流量，另一个是周期；流量的控制通过计算一段时间内发送的总的  大小来判断， 通过上一次发送时间和当前时间来对比。通过这两个参数确定当前是否需要  的间隔。过了这个间隔后即被唤醒。可配置不开启流量控制。
为了节省内存及时的 ，重新封装 成  作为发送给   的单元。
随机选择一个   的  作为本次发送的目的端如果    监测的变更使用上一次的 ，选择的规则是根据配置 ，默认是，这个配置表示  集群从  集群中选择  发送的比例，可以调节  集群的写压力。
通过  的  接口把这批  发送到选定的  上。发送的具体：把  根据不同的表分开再使用  接口发送到  中，这里是有重试机制，所以在  前使用  和  的  作为  ，防止重发。
设置  新的  或者清理旧的  
全部  发送成功后，更新相应的监控数据，包括本批次数据的传输时延 ，本批次返回的时间戳，最后一个传输的时间代当前时间 中最后一个  插入  的时间。
 过程
 的  主要是通过  协助实现的。
如果是   的某个  挂了， 在 中有重试，包括在 、 和  都是有重试的，当重试超过一定次数后，把异常一直抛到  这层后会把这个  加入到  中，后续在上一步 选择  时不会再选择这个 。
如果是   的某个  挂了，其他的  中  都有会  到，它们会去  住挂了的  的 ，因为是排他的，只有一个  能够抢到并把这些未处理完的  放到自己的  目录下依序处理。
比如最开始是这样子的，然后给挂了

那么 就会被  住，然后再把其下  都拷贝到自己  目录下，并把原来的  给删了，然后会去根据其  所在  开始去  给对应  集群：
 
其具体的时序图如下：

所有  中  的  都会去跟踪注册 目录下节点的  事件，因为这个目录的先对应  都是临时的，一旦某个  挂了对于会话就会关闭， 也会被删除，那么注册在这个  上的  的  的  将被调用。这个回调最终会在  中启动一个线程独立去完成  任务。
如上所述，方法即是：
先  住 对应  下的目录，其他的  发现已经被  后就会直接退出线程。
把原来的目录拷到自己  的 目录下，并改其  的名字，改名规则是： 名称原来  名称。改名的原因是可以让  处理时分辨出是  后的  的 ，会优先迅速的处理掉。
把原来的  目录删除。
因为保存在  中的  有保存相应的 ，所以即是挂了，新的  也可以从上次  的  开始往  集群中发送数据。
附： 生命周期
   发到 
 把相应的请求写到 
假如改变的  对应的   的范围有在  中支持到  ，这个   将增加到  对应的  中。这个加的过程是异步的，先在  中 ， 即是一个 ，在后面扫描中才加入像中所叙述。
 _ { = _ _ = }  
在一个独立的线程中，作为批处理的一部分， 从  读取。
 加上主集群的 重新封装，然后加入到一个 ？。当这个  满了或者  到达了文件的底部，  会发送给一个  集群随机的一个 。
 顺序读取  并把  分离到各个 中，每一个表一个  。这个  和中  一样？是一样在所有的  都被  后，每一个  会使用 进行 。为了防止循环复制  集群的  和  集群的  消耗了数据后就会保存了这些 。
在  集群中， 的当前复制的  将被保存在  中。
前三部的插入步骤都是一样的
又在一个单独的线程中， 读取、过滤和编辑 用相同的方式就像上面一样。  不回应调用。
 集群将  和尝试一个可配置的次数。
如果  集群的  仍然不可用，集群将选择一个新的  并且重新发送  的  。
与此同事， 的回滚日志也将加入  的  对应队列。日志将归档到各自的  中，方式是通过移动  文件目录到一个集中的日志目录。日志将在内存中更新它们的目录在  的线程中。
当  集群最终可用时， 集群中的  将用同样的方式处理。 集群会将积压的日志都复制到停机期间的  集群。个人介绍， 在前端摸爬滚打的码农一枚，对技术充满热情的菜鸟，致力为手的建设添砖加瓦。

格式的历史
     原义是“图像互换格式”，是  公司在年开发出的图像文件格式，可以说是互联网界的老古董了。
 格式可以存储多幅彩色图像，如果将这些图像连续播放出来，就能够组成最简单的动画。所以常被用来存储“动态图片”，通常时间短，体积小，内容简单，成像相对清晰，适于在早起的慢速互联网上传播。
本来，随着网络带宽的拓展和视频技术的进步，这种图像已经渐渐失去了市场。可是，近年来流行的表情包文化，让老古董  图有了新的用武之地。


表情包通常来源于手绘图像，或是视频截取，目前有很多方便制作表情包的小工具。
这类图片通常具有文件体积小，内容简单，兼容性好无需解码工具即可在各类平台上查看，对画质要求不高的特点，刚好符合  图的特性。
所以，老古董  图有了新的应用场景。
本文的应用场景
新的应用场景带来新的需求，本文所探究的问题来自于某个业务场景下——为用户批量推送表情包。
一批图像大约有张，以缩略图列表的形式展示在客户端。
根据我们使用测试数据进行的统计  图表情包的尺寸大部分在之间，批量推送的一个重要问题就是数据量太大，因此，我们希望能够在列表里展示体积较小的缩略图，用户点击后，再单独拉取原图。
传统的  缩略图是静态的，通常是提取第一帧，但在表情包的情形下，这种方式不足以表达出图片中信息。比如下面的例子


第一帧完全看不出重点啊！
所以，我们希望缩略图也是动态的，并尽可能和原图相似。
对于传统图片来说，文件大小一般和图片分辨率尺寸正相关，所以，生成缩略图最直观的思路就是缩小尺寸，大法。
但是在  图的场合，这个方式不再高效，因为  图的文件大小还受到一个重要的因素制约——帧数
以这张柴犬表情为例，原图宽度，尺寸，等比缩放到之后，尺寸还是，等比缩放到，相当于尺寸变为原来的四分之一，体积还是



可见，大法的压缩率并不理想，收效甚微。
而且，我们所得到的大部分表情图素材，分辨率已经很小了，为了保证客户端展示效果，不能够过度减少尺寸，不然图片会变得模糊。
所以，想要对图进行压缩，只能从别的方向入手。
探寻格式的存储
想要压缩一个文件，首先要了解它是如何存储的。毕竟，编程的事，万变不离其宗嘛。

作为一种古老的格式，的存储规则也相对简单，容易理解，一个文件主要由以下几部分组成。

文件头
图像帧信息
注释

下面我们来分别探究每个部分。
文件头
格式文件头和一般文件头差别不大，也包含有：

格式声明
逻辑屏幕描述块
全局调色盘

格式声明

 为“” 个字符； 为“”或“” 个字符。
逻辑屏幕描述块

前两字节为像素单位的宽、高，用以标识图片的视觉尺寸。
里是调色盘信息，分别来看：
   为全局颜色表标志，即为时表明全局颜色表有定义。
  代表颜色表中每种基色位长需要，为时，每个颜色用表示，即我们熟悉的表示法，一个颜色三字节。
  表示是否对颜色表里的颜色进行优先度排序，把常用的排在前面，这个主要是为了适应一些颜色解析度低的早期渲染器，现在已经很少使用了。
   表示颜色表的长度，计算规则是值作为的幂，得到的数字就是颜色表的项数，取最大值时，项数=，也就是说格式最多支持色的位图，再乘以 算出的字节数，就是调色盘的总长度。
这四个字段一起定义了调色盘的信息。
   定义了图像透明区域的背景色在调色盘里的索引。
   定义了像素宽高比，一般为。
什么是调色盘？我们先考虑最直观的图像存储方式，一张分辨率×的图像，本质是一张点阵，如果采用最常见的三色方式存储，每个颜色用表示，那么一个点就可以由三个字节 = 表达，比如可以表示一个白色像素点，表示一个黑色像素点。
如果我们采用最原始的存储方式，把每个点的颜色值写进文件，那么我们的图像信息就要占据就是××字节，这是静态图的情况，如果一张图里有帧，点阵信息就是×××。
下面这张兔子的表情有帧，分辨率是×，如果用上述方式计算，文件尺寸至少要。

但实际文件尺寸只有，它一定经历过什么……
我们可以使用命令行图片处理工具来看看它的信息。
    
我们得到下面的文本
  
  
   
 
 
 
     
   
     
   

可以看到，   就是它的调色盘，长度。
为了确认，我们再用二进制查看器查看一下它的文件头。

可以看到里的字段的确符合我们的描述。
在实际情况中，图具有下面的特征
一张图像最多只会包含个值。
在一张连续动态里，每一帧之间信息差异不大，颜色是被大量重复使用的。
在存储时，我们用一个公共的索引表，把图片中用到的颜色提取出来，组成一个调色盘，这样，在存储真正的图片点阵时，只需要存储每个点在调色盘里的索引值。
如果调色盘放在文件头，作为所有帧公用的信息，就是公共全局调色盘，如果放在每一帧的帧信息中，就是局部调色盘。格式允许两种调色盘同时存在，在没有局部调色盘的情况下，使用公共调色盘来渲染。

这样，我们可以用调色盘里的索引来代表实际的颜色值。
一个色的调色盘，的颜色只需要用就可以表达了。
调色盘还可以进一步减少，色，色，，相应的压缩率就会越来越大……
还是以兔子为例，我们还可以尝试指定它的调色盘大小，对它进行重压缩
 =   
 =   
 =   
 =   

依然使用工具，参数就是调色盘的长度，得到的结果




注意到了的时候，图像已经变成了黑白二值图。
居然还能看出是个兔子……
所以我们得出结论——如果可以接受牺牲图像的部分视觉效果，就可以通过减色来对图像做进一步压缩。
文件头所包含的对我们有用的信息就是这些了，我们继续往后看。
帧信息描述
帧信息描述就是每一帧的图像信息和相关标志位，在逐项了解它之前，我们首先探究一下帧的存储方式。
我们已经知道调色盘相关的定义，除了全局调色盘，每一帧可以拥有自己的局部调色盘，渲染顺序更优先，它的定义方式和全局调色盘一致，只是作用范围不同。
直观地说，帧信息应该由一系列的点阵数据组成，点阵中存储着一系列的颜色值。点阵数据本身的存储也是可以进行压缩的，图所采用的是压缩算法。
这样的压缩和图像本身性质无关，是字节层面的，文本信息也可以采用比如常见的，就是和哈夫曼树的一个实现。
基于表查询的无损压缩是如何进行的？基本思路是，对于原始数据，将每个第一次出现的串放在一个串表中，用索引来表示串，后续遇到同样的串，简化为索引来存储串表压缩法。
举一个简单的例子来说明算法的核心思路。
有原始数据：
可以看出，原始数据里只包括个字符四个字符可以用的索引来表示，。
原始字符串存在重复字符，比如，，都重复出现过。用代表，代表，上面的字符串可以替代表示为
这样就完成了压缩，串长度从缩减到。对原始信息来说，压缩是无损的。
除了采用之外，帧信息存储过程中还采取了一些和图像相关的优化手段，以减小文件的体积，直观表述就是——公共区域排除、透明区域叠加
这是官方范例里的一张图。

根据直观感受，这张图片的每一帧应该是这样的。

但实际上，进行过压缩优化的图片，每一帧是这样的。

首先，对于各帧之间没有变化的区域进行了排除，避免存储重复的信息。其次，对于需要存储的区域做了透明化处理，只存储有变化的像素，没变化的像素只存储一个透明值。
这样的优化在表情包中也是很常见的举个栗子

上面这个表情的文件大小是，帧数是我们试着用工具将它逐帧拆开，这里使用另一个命令行图像处理工具
   _

可以看出，除了第一帧之外，后面的帧都做了不同程度的处理，文件体积也比第一帧小。
这样的压缩处理也是无损的，带来的压缩比和原始图像的具体情况有关，重复区域越多，压缩效果越好，但相应地，也需要存储一些额外的信息，来告诉引擎如何渲染，具体包括：

帧数据长宽分辨率，相对整图的偏移位置

透明彩色索引——填充透明点所用的颜色

 ——定义该帧对于上一帧的叠加方式

 ——定义该帧播放时的停留时间


其中值得额外说明的是 ，它定义的是帧之间的叠加关系，给定一个帧序列，我们用怎样的方式把它们渲染成起来。
详细参数定义，可以参考该网站的范例：
 和透明颜色一起，定义了帧之间的叠加关系。在实际使用中，我们通常把第一帧当做基帧，其余帧向前一帧对齐的方式来渲染，这里不再赘述。
理解了上面的内容，我们再来看帧信息的具体定义，主要包括：

帧分隔符
帧数据说明
点阵数据它存储的不是颜色值，而是颜色索引
帧数据扩展只有标准支持

和比较直观，第二部分和第四部分则是一系列的标志位，定义了对于“帧”需要说明的内容。
帧数据说明。

除了上面说过的字段之外，还多了一个 ，表示帧点阵的存储方式，有两种，顺序和隔行交错，为  时表示图像数据是以隔行方式存放的。最初  标准设置此标志的目的是考虑到通信设备间传输速度不理想情况下，用这种方式存放和显示图像，就可以在图像显示完成之前看到这幅图像的概貌，慢慢的变清晰，而不觉得显示时间过长。
帧数据扩展是标准增加的，主要包括四个部分。
、程序扩展结构 主要定义了生成该的程序相关信息

、注释扩展结构 一般用来储存图片作者的签名信息

、图形控制扩展结构  这部分对图片的渲染比较重要

除了前面说过的 、、 之外， 用来定义是否接受用户输入后再播放下一帧，需要图像解码器对应的配合，可以用来实现一些特殊的交互效果。
、平滑文本扩展结构   

标准允许我们将图片上的文字信息额外储存在扩展区域里，但实际渲染时依赖解码器的字体环境，所以实际情况中很少使用。
以上扩展块都是可选的，只有置位的情况下，解码器才会去渲染
需求场景——给表情包减负
说完了基本原理，来分析一下我们的实际问题。
给大量表情包生成缩略图，在不损耗原画质的前提下，尽可能减少图片体积，节省用户流量。
之前说过，单纯依靠大法不能满足我们的要求，没办法，只能损耗画质了，主要有两个思路，减少颜色和减少帧数。

减少颜色——图片情况各异，标准难以控制，而且会造成缩略图和原图视觉差异比较明显

减少帧数——通过提取一些间隔帧，比如对于一张帧的动画，提取其中的提取帧。来减少图片的整体体积，似乎更可行。


先看一个成果，就拿文章开头的图做栗子吧


看上去连贯性不如以前，但是差别不大，作为缩略图的视觉效果可以接受，由于帧数减小，体积也可以得到明显的优化。体积从缩到了
但是，在开发初期，我们尝试暴力间隔提取帧，把帧重新连接压成新的图，这时，会得到这样的图片。

主要有两个问题。
、帧数过快；
、能看到明显的残留噪点。
分析我们上面的原理，不难找到原因，正是因为大部分存储时采用了公共区域排除和透明区域叠加的优化，如果我们直接间隔抽帧，再拼起来，就破坏了原来的叠加规则，不该露出来的帧露出来了，所以才会产生噪点。
所以，我们首先要把原始信息恢复出来。
两个命令行工具，和都提供这样的命令。
    _
    

还原之后抽帧，重建新的，就可以解决问题了。
注意重建的时候，可以应用工具再进行对透明度和公共区域的优化压缩。
至于问题，也是因为我们没有对帧延迟参数 做处理，直接取原帧的参数，帧数减少了，速度一定会加快。
所以，我们需要把抽去的连续帧的总延时加起来，作为新的延迟数据，这样可以保持缩略图和原图频率一致，看起来不会太过鬼畜，也不会太过迟缓。
提取出每一帧的信息，也可以通过工具提供的命令来提取。
   
  
在实际应用中，抽帧的间隔是根据总帧数求出的
 =
 =
 =
 =
 =
值的计算还做了归一化处理，如果新生成缩略图的帧间隔平均值大于，则统一加速到均值，同时保持原有节奏，这样可以避免极端情况下，缩略图过于迟缓。
具体实现
本文介绍的算法主要应用于手热图功能的后台管理系统，使用编写。是一个较为常用的图像处理工具，除了还可以处理各类图像文件，有封装的版本可以使用。只有可执行版本，在服务器上重新编译源码后，采用调起子进程的方式实现。
对于图片信息的解析较为方便，可以直接得到结构化信息。支持命令管道级联，处理图片速度较快。实际生产过程中，同时采用了两个工具。
 {} = _

  = 
    = {
    {
            ：
          
    }
     _ = \     
      = _

      = 
      = 
    ={
           
            =       {
             = \   
            =
          }
                 {
             = 
            =
          }
    }{
             =       {
             = 
            =
          }
    }
      = _
    判断是否速度过慢，需要进行归一加速处理
    {
            =
             =       {
             =   
          }
    }

     =
    =
    
    

      = 
       =    _   {
          =={
            
            
            =
          }
       = 
    }
    =
    
    
      {   }
}
测试时，采用该算法随机选择张图进行压缩，原尺寸被压缩到，压缩比，不过由于该算法的压缩比率和具体图片质量、帧数、图像特征有关，测试数据仅供参考。
本文到这里就结束了，原来看似简单的表情包，也有不少文章可做。
谢谢观看，希望文中介绍的知识和研究方法对你有所启发。

相关推荐
高性能图片架构与设计谷歌开源图片压缩算法实测体验报告关于图片资源瘦身的奇思妙想作者：胡涛 

使用工具来更好的调试我们的工程中新开发或者修改过的模块的内存状况。
 设备性能越来越好，  也相应的变得越来越庞大，代码的量级也在快速的增长，开发一个小的模块在工程中调试变的越来越难，通常我们是通过观察的内存变化高低，或者内存分配快照对比来寻找泄漏的情况，但这几乎是一个让人抓狂的调试方法，尤其在非常复杂的项目中，一个模块的推入与推出在上的变化微乎其微，而且受制于项目的复杂度，各种你所未知的对象的创建与销毁带来的图形高度的影响，对于观察的分配图像的高低变化来说，能够参考的意义就变的非常有限。
通过过去参与过的复杂大型的项目开发经验，开发新的模块的时候，总结出了一套完整的内存自测的方法，通过来逐步跟踪检测我们创建和主动销毁的对象是否真的销毁了。
在演示之前，需要强调一件事情就是，以文件夹目录作为你的空间命名很重要，请遵循开发新模块的时候使用你的模块的命名作为前缀。因为没有命名空间这个东西，通常为了保证不冲突，我们都是以项目前缀＋空间命名来保证文件的独立性，空间名就是目录和模块的名字了。这个在我们使用进行内存检测的时候是非常重要的，接下来的使用过程就可以证实这一良好的命名习惯所带来的巨大好处，不只是优雅，更重要的是帮助。
除了命名，还有一件很重要的事情就是，你需要对你的模块在各种操作或者事件发生过程的情况下，对你的对象分配过程要非常非常清楚，因为这样，你才能看出相应的变化，哪些对象是应该存在的，哪些对象在某个动作结束后是必定会销毁的，这个应该很容易，你应该纯天然的就知道，因为你开发的整个逻辑。
最近在开发一个新的模块，正好需要在内存方面做一个完整的自测，既要确保效率，也要确保内存的正确分配与释放。
重要：以下教程开始所有示例图片，请自行点击图片看大图，看的倍儿清楚！

首先，我先上图，看一下我的命名组织结构，遵循的就是模块化的命名，因为手的跨部门合作，所以用部门标记作为前缀。代码首先是要让人来看的，是人在维护程序，所以可读性非常重要，在开发完这些功能后，我对于所有对象在运行过程中的创建与销毁是很清楚的。

接下来我要进入来进行内存测试，运行就了，就会进入下面看到的界面，详细讲解一下都是什么吧，这些对对象怎么分配内存的很重要。

然后我就需要操作模拟器来进入我所开发的功能模块，会看到非常复杂的对象分配情况，所以这一步非常关键，我只需要在搜索框搜索模块的前缀就可以只显示当前模块所涉及的对象分配与销毁情况，如下图，进入了的模块视图：

接下来我执行一个环境查询的命令，再看一下执行之后的内存分配情况。

我的逻辑是这样的，点击一次创建一个命令，通过这个命令初始化并执行一个任务，任务结束后就销毁这个任务对象，相应的命令也作为任务的成员一起被销毁。所以，在动作执行完后我们应该可以在已销毁对象中找到这个实例，运行截图如下：

我看到任务是已经被销毁了的，可是用来初始化的命令对象为什么没有被销毁，我需要深挖一下这个命令对象的引用计数到底怎么发生变化的，就需要用到下面的步骤了，按照图解去深挖它：

我挖到命令对象的内部，一路挖到底，我发现命令对象最终的引用计数是，证明它还在内存中活着，截图是这样的：

所以，我就看看，任务对象销毁了，那任务对象到底发生了什么事 截图是这样的：

我就是不死心，我就是要看到，到底是不是真的呢，为了进一步佐证命令对象在内存中，我在对象内部观察了一个内存检测的通知，收到通知后弹一个出来，如果对象被销毁了，它肯定收不到这个通知，如下面截图所示的工作：

因为这是我自己写的逻辑，我很清楚对象在哪里分配内存，然后我就去查代码，命令对象到底经历了什么，从开始到结束的执行过程是什么样的：

看完上面的截图，再去看命令对象的引用计数变化就知道为什么了：
当然，我也看出了为什么引用计数没有归零，所以，我在下面进行了修复：
再次  然后我再做一次查询任务，看看这次命令对象的引用计数变化，命令对象被释放了！：

总结：

保持你的模块拥有一个良好的命名空间

请深刻并且清楚的知道，触发什么事件，执行动作之后，你的对象分配会是什么样的，谁此刻应该存在内存中，谁应该被销毁，然后利用上面的原理去查看，它是不是被销毁了，如果没有被销毁，那么你应该去查你的代码，到底在执行过程中，哪里没有平衡引用计数。

此方法在和的情况都是适用的，目标是观察具体哪个实例对象没有被销毁，然后根据引用计数变化跳转到代码中去确认哪里出现了内存问题。


文章来源于公众号：小时光茶社 

相关推荐性能监控，拒绝用户流失快速定位手游内存占用过高问题前言
本文算是一篇娱乐型的文章吧，并没有牵扯到太多技术性的东西。
本文主要写的是如何扭曲你的数据，在不影响结果和其他属性的情况下，使得你数据画出来的图更加好看。
本文以“兔子”数据为例。
下文分享链接密码均为 
正文
经常有这样的情况，你用数据画出图像有看起来会很丑，如何让你的图像变得好看一点呢？需要修改点一点。 且这个修改是不能在数据的属性基础上进行修改。在现实生活中该方法的用处在于在做一些数据报表的时候可以令你的报表变得更加清晰好看明了。或者是开发相关数据绘图软件，对数据画出的图进行优化。

上图为“兔子”数据优化后的示例
一、软件介绍思路
这是它们的官网
本文的思路来源于
主要是做出计算和图表，致力于让结果更加人性化

左：的四张图表
右：非结构化的四张图
两边数据集是相同的，但最终的图像明显存在根本结构和视觉区别。
如今数据的可视化重要性越来越高且越来越流行
在他们的官网上你可以下载到“恐龙”的数据集
下面也给出了“恐龙”数据

数据库集。 虽然形状不同，但每个数据集具有相同的小数点后两位的统计信息平均值，标准偏差和相关指数

对左侧的数据集进行一些小的更改，同时保持相同的统计属性小数点后两位

将随机的点转换为圆，同时保证数据具有相同的特征

创建数据集。 输入是左侧的“恐龙”数据集，中间是一组目标形状。 最终数据集显示在右侧。 所有数据集和动画的所有帧具有相同的统计其中  = ，  = ，  = ，  = ，  = 。
下图为最终整合在一起的结果

好了，其它更多的你们可以去它的官网看
开始写代码本文使用语言
先说说想法
将的数据和数据之比稍微修改少量，以确保数据的准确性
下文对数据修改称为扰动
_=_ _
{
 _
   ___  

   ___  
}


_=
{

   {
   _=_  
    __ 
      
   }


   {
   _=_  
    __ 
      
   }

=_ =_
}
我们需要改动的数据点，在下面称为扰动点
然后需要计算扰动点与目标点位置之间的距离。 对于每个扰动点，需要找到目标中最近的邻居并计算距离。 这可以在中使用 一种数据结构完成，当然还有一个语言的相关包，，这样做在函数中实现。 下面代码尝试了最小化距离之和，还有另一种方法是最小化平均距离：
_=
{

   {
   _=_
   _= _ =
    _  _
      {
      _  _
      _
      }
   }
}
现在它就变成了一个循环迭代次数的问题，如果距离低于某个限制标准，则存在
_=_ _
{
_  _ _ =
_=_
   
   {
   _=__
   _=_
    _  
      _
   }
_
}
此代码处理单个属性。 上面的开发者利用原始模型在实施该过程中花费了一个多小时的时间，同时处理多个属性，并使用模拟退火算法来防止死循环在本地的最小值中。
下面是例子，原始点位黄色

对图像进行修理一下就可以变得很好看
相关下载
这是“恐龙”数据
这是“兔子”数据
这是“本文代码”
说明
这个方法对于那些对数据精度要求很高的系统是不能使用的
理由很简单
作者：赖博先
导语： 本人最近系统的看了推荐相关的论文，觉得非常有收获，所以整理小文以飨读者；“它山之石可以攻玉” ，希望可以给大家带来帮助和启发。

是全球最大的视频分享平台，用户量高达亿，每天上传的和都是百万级别。那么问题就来了，他们是如何让用户在这么多的视频中快速的发现自己感兴趣的内容呢？大家可能会想到搜索，确实搜索是一个必不可少的工具，但有一个前提条件是用户必须知道视频的关键词，通过搜索关键词才能找到对应的视频，并且用户很多时候其实并不是很知道自己需要什么样的内容，逛纯粹为了打发时间。为了很好的解决用户快速发现可能感兴趣的视频这个问题，推荐系统绝对是搜索的一个很好的补充。
本文主要介绍 年推荐系统相关的算法和策略变迁。
笔者从网上找到了三篇介绍推荐系统相关的文章，一篇是年发表的《            》；一篇是年发表的《____》还有一篇是年发表的《      》，这三篇文章介绍都了推荐系统以及内部算法架构，通过这些文章我们可以窥伺其在不同时期，基于不同资源和技术对系统的进化过程，对于想在自己场景中使用推荐技术的同学有非常好的借鉴意义；
年发表的那篇相对于后面两篇来说技术上差别还是蛮大的，作者把推荐问题建立在一个的图上，对于某个，作者定义了他可能感兴趣的  需要满足的条件：
、到的路径是最短的
、到有尽可能多的路径
、到要避开热门的影响热门可以根据度来判断
根据上述三个标准，可以给图上每个用户推荐适合的；那如何实现呢？文章里作者提出了一种叫做的学习框架，这个框架目标是解决少量有标注数据集，来预估大的无标注数据集的问题。作者使用多种方法在这个算法框架上比如、 、 ，并且给出了很多概念定义和算法描述，实验结果也是非常吸引人；对于图模型， 是一定会想到的解决方案，其逻辑是将每个顶点的发送到相关联的邻居上，在每次传递结束后，对顶点的进行归一化。对应到视频推荐是我们够建观看当然可以是其他行为：转评赞等的关系图，把用户喜欢看的视频当作，然后进行随机游走，将推广到其他视频上。这个算法试验结果很好，但是文章也是是给出了漂亮的结果，对里面实现一笔带过，我理解对于这么大的数据量级使用这种迭代算法，计算代价是非常高的，所以应用到实际场景，系统工程要求也是非常高。
  相比于年文章，年发表在的文章，不管是行文风格，还是算法架构都发生了非常大的变化，年文章充满了学术气息，长篇大论，但是如何应用到实际业务中并没有提到很多；年的文章很短，页，非常简单明了的介绍了推荐系统的方方面面，同时还介绍了很多实际业务中需要使用的，比如如何解决相关推荐带来的兴趣狭窄问题，引入  去除不相关视频等，在实际业务中非常有借鉴意义。这篇文章介绍的推荐场景是主页，场景的目的是给用户提供个性化的内容以此提升用户使用网站的互动性和娱乐性。文章介绍的核心算法其实就是算法，然后根据用户在网站上的历史行为给其生成一个个性化的视频列表：

文章作者也提到，他们把这个问题定义成推荐问题，而不是点击预估问题，需要完整地考虑内容的新鲜度、精确度、多样性以及用户近期行为。另外认真的同学会发现推荐列表中，每个视频封面图片下面有系列的介绍，标题、视频发表时间、观看次数、   ；里面推荐理由也是非常重要的，让用户知道为什么会给他推荐这个视频，而且列表前四个  都不同，说明是经过了策略的调整。
回到文章核心算法，要根据用户历史行为推荐相关视频，一个核心问题是计算视频与视频的相关度，作者文章中说是使用了  的技术来解决，其实是使用来计算视频之间的相似度：

公式里面分子  表示视频  和视频  在一个时间窗口文章用天里面的次数，分母  是一个规范化函数 ，来避免热门视频带来的影响，文章中列举了一个简单的函数：  =  ·  ，当然实际业务中可以根据业务知识自定义这个规范函数；如果是使用  =  · ，那么 其实就是关联规则置信度的计算公司，对于种子视频，要找到最相似的视频， 是不影响排序，而  直接打压了热门视频的影响，一定程度上提升了多样性，并且对于小曝光视频有扶持作用。上述计算相关性的公式，只是一个简单抽象，文章提到实际业务中还考虑了很多因素，比如播放时间戳、播放序列、  等。有了视频之间的相关性，就可以将每个视频作为节点，视频之间的相关性作为边的权值构建一个有向的  ，接下来根据这个图为每个用户  来产生推荐候选集合，然后将推荐集合传入进入排序层生成推荐列表，大概逻辑如下：

种子视频生成是根据用户历史正向行为获取的，比如用户收藏、赞、加入播放列表、评分等。有了   和种子视频，根据    算法就可以跟每个用户生成一个个性化的推荐候选池，但是作者认为这种传统做法会让用户的兴趣越来越窄，于是他们在搜索最近邻居的基础上加以扩展，搜索多阶的最近邻居，公式如下：


生成完候选之后，下一步是从几百个视频中，挑选几个到十几个视频展示给用户，那必须需要有一个排序算法，文章中提到了三类型的因素用于最终的打分：

  视频质量

  用户的切合程度

  多样性


视频质量主要是根据用户反馈信息来得到，比如收看数目、总被观看时长、评分、评论、赞、分享等，同时还有视频的上传时间之类的信息
用户切合度是取决于用户对种子视频的喜欢程度，以及视频之间的相似程度，同时加强近期行为。多样性主要是通过分类数目来衡量；然后把这三方面的因素作线性加权得到候选集合的权重注：如果用树模型或者  模型应该可以取得更好的成绩，排序得到推荐列表。
推荐系统实现方面分为三个方面：、数据收集；、推荐候选生成；、线上推荐服务；系统主要使用了  和  实现
年的论文用到的技术相对于年有了非常大的改变，所用到的数据源也不仅仅只有用户显性行为，但是主框架还是候选生成排序模型的模式，只是这两层架构都是使用了深度模型四层，其实不深下图是年论文中提到的架构图：

主架构通过  候选生成模块，从百万 所有推荐候选池找出几百个与用户相关的待推荐视频；然后排序模块将候选模块产生的推荐列表中在选择十几个视频展示给用户。这篇文章比较有开创性的是，在这两个模块中都使用了深度学习，合理的将不同特征和不同数据源融合在一起，并取得非常不错的效果。下图是候选生成模型框架：

文章将推荐问题转换为极多分类问题  ，公式如下：

表示在时刻 ，用户上下文信息在视频库中精准的预测出视频  的类别每个具体的视频视为一个类别， 即为一个类别的概率。上面的公式是一个明显的  多分类器的形式；其中  和 ，分别是用户的  向量和视频的  向量，具体怎么来的呢？对于视频向量，文章采用了   的方式计算出每个视频的  向量原文：                           ；而  则是通过输入用户信息和上下文信息给上面模型架构训练得到。
整个模型由包含三个隐层组成，输入层输入的的信息有，用户播放历史和搜索历史向量分别取，再加入用户基础画像年龄、性别等其余特征：视频质量、视频等特征成向量输入；从上图可以看出，输出分为和两个部分。部分输出层是层，也就是上面提到的那个公式表示的概率值，线上部分通过向量和向量得出用户相关视频注：是指线上推荐服务；是离线训练模型；下同。
 模型框架：

 层从架构上跟候选生成层基本一致，不同是的最后输出层是一个  ，而阶段激活函数是；层针对视频播放时长进行建模并不是一个单纯的预估模型，文章指出，单纯根据  来进行推荐，会出现“”，也就是助长标题党，封面党；这样并不能带来用户停留时长的提升，以有没有点击来划分正负样本，正样本根据播放时长进行加权，正样本的权重是播放时长 ，负样本权重是，而最后一层模型是  ；那么学到的为：

其中  是总的样本数量， 是正样本数量， 是第正样本的观看时长。 相对  比较小，因此上式的  可以转换成，其中  是点击率，点击率一般很小，这样 接近于，即期望观看时长。因此在线上  的  阶段，我们采用  作为激励函数，就是近似的估计期望的观看时长。
另外文章也花了很大篇幅将特征工程相关的工作这与深度学习自动提取特征有点不符，哈哈作者说虽然深度学习可以缓解人工构造特征的负担，但是原始数据也是无法直接喂给前馈神经网络，所以特征工程依旧非常重要；
在架构上整个推荐系统是建立在   上面，使用  进行建模。
本文通过对  不同时期发表的文章，可以看到其技术的变迁，年的推荐技术的积累，有很多东西可以值得我们去学习的。
参考文献：
                                   
                       
 ， ，               作者 | 况鹰编辑 | 迷鹿

况鹰，腾讯高级工程师，目前主要负责手个性化增值及企鹅电竞助手业务开发与性能优化，在和端都有丰富的经验，闲暇之余比较爱折腾和研究各种新技术。

接上一篇《源码分析第一篇踏石留印》简单介绍了的由来和工程构成，这一篇我将剖析一下二代的代码内部，就不来文艺气息了，直接上猛料。本文将按照数据源的获取、渲染、推送的直播流程来让大家深入了解一下。
、直播源数据获取
在启动时会优先加载  核心库，这个库初始化  很多内容，包括 模块、、性能监控等。初始化后会加载多个  下可以理解为，一般而言一个  对应一个功能特性，每个  加载时会初始化一些静态函数地址用于处理特性。
特性通过  来区分，如主播插入图片时，会调用  为“_”的 函数来处理，并相应的增加一个对应的  对象。

对于外部调用接口而言，所有  的数据函数名称基本一致对于不同 略做调整，比如  类型的直播源数据对外接口长下面这样：

这样做的好处是有利于第三方贡献者接入，如果想加入一个新的直播源类型，只需要仿照已有  增加类似的特性处理函数而不用更改主程序框架。当然如果不习惯  语言，也可以切换为  用成员函数地址代替静态函数地址，其它语言依次类推。
、直播源数据管理
对于直播源数据， 首先会建立其一个场景  的概念，过程类似于开演唱会搭舞台。舞台场景中有很多部件 _ ，主播在直播时可以根据需要择时删除、隐藏、添加场景中的部件，管理非常便捷。基本数据结构如下：

 除了支持单个场景，也支持同时搭建多个场景，主播可以在场景间过渡切换，不过直播难度也会增加。对于观众而言观看直播犹如观看了一场演唱会，可以发弹幕尖叫呐喊。
、直播源数据渲染
在初始化时会根据直播源类型对数据做一个分类，每一类数据对应相应的，如  对应的  为 ，麦克风对应的  为，目前默认配置了 个通道，分别用于  、桌面音响、麦克风，最大可拓展为个：

 在初始化时会开启一个  和  线程用于定时更新数据，以 为例，对于每一个预览界面，首先会  一个  对象用于关联 函数和  线程，直播时  线程定时更新会调用  函数，触发场景和  的绘制与刷新。大概流程如下：

黄色代表线程，蓝色代表对象
最终渲染会传递到每个_，每个_会绑定一个 ， 对应的便是主播看见的直播画面，在调用  之前会先调用  或  更新这个  。 绘制的顺序跟_的顺序有关，_以链表的形式串联起来，采用尾部插入的方式置入新直播源，外在展现便是越晚置入的直播源数据越在上层，主播调整直播源数据的顺序也就是调整链表的顺序。
、直播源数据推流
有了直播源数据，主播端可以看见渲染的直播缓慢。但这还不够，只有推送到后台才能展现给更多的观看用户。在直播源推送时会首先创建推流  和  的  对象，并创建  对象管理  对象，绑定  对象与  、 数据源最后使用  或者  推流，关系如下：

对于目前常见的  推流过程，主要分为三个步骤：

创建线程连接服务器，初始化模块；

连接服务器成功后创建线程并开启数据；

线程根据信号量来控制是否发送数据，信号量在时会重置；


其中  数据的过程可以理解为关联数据采集和数据发送，如下图所示：

黄色代表线程，蓝色代表对象
 和  对象都会绑定回调函数，当  与  线程检测到内容有更新时，会根据是否需要编码触发不同的回调函数对数据进行处理，最后序列化后通过  打包发送到后台。
总结：
的整个开播过程都是围绕数据源展开的，代码核心部分由语言编写，层则用的。数据更新回调较多，除了的和的通信机制，也有一部分是作者自己的，看代码时全局关联会比较容易懂，如果对有兴趣的同学可以一起学习交流。

相关推荐
 点对点直播直播应用的后台服务器性能测试实践作者：高苡新
团队：腾讯移动品质中心

背景
测试的是浏览器内核的渲染能力。通常会选取一些业界常用的测试页面作为测试用例，例如：
图测试页面截图
测试从列入腾讯浏览服务上线前性能测试以来，就一直存在测试数据不稳定问题。初期采用购置小风扇、增加冷却时间、编写重测页面等方法解决问题，效果并不理想。时不时还是会出现测试结果发现性能落后，但开发跟进分析后发现是测试数据波动导致的误报的情况。这种情况对测试和开发同学的工作效率都造成影响。
问题定位
腾讯浏览服务英文缩写的上线前性能测试再次测得落后。用例落后上一版本帧。但经过开发定位问题，发现依然是数据波动导致的误报。
图性能测试结果
这次，开发同学和测试同学决定刨根问底找到影响数据波动的根本原因。
通过性能监控工具，我们发现发热导致的降频和关闭是影响测试结果的主要原因。
图开发定位问题邮件内容
解决办法
为此，测试组专门购置了性能优越的笔记本散热风扇来给测试手机降温。
图笔记本散热风扇
初步验证发现效果良好下面一段文字为邮件内容节选：
“本周 性能日常监控结果：
数据基本稳定。在增加了散热器与小风扇辅助散热之后，三部手机的测试结果均接近、月份结果且多多少少有所提升，无重测项。”
优化效果
日常监控历史记录可以看到优化前后的效果：
、个用例的波动范围都不同程度缩小。其中 __的波动从帧缩小为帧。
图优化前后数据波动范围对比
、之前经常要重测的用例，如今不再需要重测。目前重测概率为。
图优化前后重测记录
注：当监控数据和上一次相差帧或以上时需要重测。
规范“有效落后”门限值
注：达到该门限值才认为是有效落后，开发跟进分析。
个用例当中， __的波动最大。所以我们对 __进行了次测试每次组测试值验证数据波动范围：
图优化后数据波动情况
图优化后数据波动情况
结论：
、单次测试组数据的最大最小值偏差月帧；
、多次测试组数据的平均值波动在帧左右；
、多次测试所有数据的最大最小值偏差帧。
基于以上测试结果，制定不同用例的“有效落后”门限值如下：
图根据数据波动验证结果制定“有效落后”门限值
搜索微信公众号：腾讯移动品质中心，获取更多测试干货！月日，一种名为“”的新型勒索病毒席卷了欧洲，乌克兰等国家，多家运营商、银行、机、公司、机场等均受到影响，包括政府大楼的电脑甚至于乌克兰副总理的电脑都遭到感染，出现问题；另有消息称前切尔诺贝利核电厂的防控系统也受到影响，导致基于系统的传感器失灵，科学家不得不手动监测辐射水平。
同时，在号点左右，腾讯云联合电脑管家发现相关样本在国内出现，腾讯云已第一时间启动用户防护引导，到目前为止，云上用户尚无感染案例，但建议没打补丁用户尽快打补丁避免感染风险。
经云鼎实验室确认，这是一种类似于“”的勒索病毒新变种，传播方式与“”类似，利用了永恒之蓝进行传播，同时还具备局域网传播手法。
腾讯云主机防护产品云镜已第一时间检测该蠕虫，云鼎实验室将持续关注该事件和病毒动态，第一时间更新相关信息，请及时关注，修复相关漏洞，避免遭受损失。
技术分析
通过对勒索病毒进行分析，我们发现主要是以一个文件的形式存在，通过投放手段远程侵入目标主机，一旦受到感染，那么病毒将执行加密和内网传播操作，主要有：

将自身投递到\目录下，然后通过进行启动
一旦病毒启动功，将会进行文件加密，同时在系统中添加定时任务，系统将在一小时后重新启动，在系统重启后将看到以下的画面
在这过程中，病毒还会利用工具提取内存中的密码
病毒在获取密码后会扫描内网中的机器，对远程机器的、端口进行连接，尝试将自身和副本复制到远程机器的文件夹，然后通过通过和执行命令远程调用进行启动，以此进行传播
除此之外，病毒还会利用永恒之蓝 和 永恒浪漫进行传播

事件响应
在监测到事件后，腾讯云团队启动响应机制，个小时内进行多维度的预警和防御：

确认腾讯云安全组对相关利用端口的封堵
封堵病毒使用的相关域名和
普查云上机器对病毒使用漏洞补丁的更新情况，提前做好防御预警
将相关样本入库检测
通知合作伙伴相关情报

在拿到相关病毒样本后，我们第一时间对云镜后台检测策略进行了升级，对腾讯云上已经安装过云镜的用户进行了检测，未发现受本次病毒影响的用户。
云镜是腾讯云官网为用户提供的一款主机安全加固产品，可以帮助云上用户实时发现黑客入侵行为和漏洞风险，降低因黑客入侵导致的数据泄露风险。主要包括密码破解拦截、异地登录提醒、木马文件查杀、高危漏洞检测等安全功能，解决当前服务器面临的主要网络安全风险，帮助企业构建服务器安全防护体系。
目前，云鼎实验室与电脑管家依然通过全网布控监测病毒相关疫情，通过“云端”的联动形成立体防御体系。
相关推荐
主机安全云镜
 勒索病毒来袭，腾讯云用户安全指引
 新型勒索病毒的加密原理分析
 勒索软件新变种详细分析报告想起来说这事是因为偶然发现腾讯云监控的界面可以选择过去的精确时间段来展现监控曲线了，比如下面这个图展现的是某个产品月日晚上到之间的外网出入带宽曲线。

从曲线可以看到，在晚上十点半左右，流量瞬间从飙升到，然后缓缓回落。中间发生了什么呢？
这其实是一个做运营的新同学策划的一个活动，整个活动部署在腾讯云上，上线前的开发阶段只申请了一台单核的服务器，开通了的带宽用作开发。
氮素，开发和在线运营是完完全全不一样的两回事啊 
在月号周五晚上十点多，技术同学几乎都下班去过周末的时候，运营同学觉得是时候让产品亮相了，对外推送了消息，带宽当然在瞬间打满了。说时迟那时快，运营同学一看到活动页面打不开已经意识到出了什么问题，立刻做了一个重要的动作：
他把主机切换为按流量付费模式，然后直接把带宽拉到的上限。这个操作直接打开了系统的带宽瓶颈，如一开始的流量图所示，流量直接冲高到的上限后开始回落，活动得以照常进行。
的带宽得多贵？应该要花不少钱吧？实际上这个操作最后还退回了一点儿钱：

因为当时账上只有几百块钱了，直接扩带宽肯定余额不足，要联系充值也来不及了，而因为主机原来是按照带宽预付费的，直接切换成按照流量付费，不再需要占用固定带宽了，所以带宽费用反而退回了。
即使是不太精通技术的运营同学，平时掌握云服务的特点和基础操作，在关键时刻也可以一秒钟丫鬟变格格，所以平常学习一点云知识是多么有用！
最后，到底这是个什么活动呢？晒一下我的活动体验图吧：
在活动下线前你可以扫描下面的二维码来体验一下：

相关推荐
我是怎么让全国最大的儿童失踪预警平台流量掉底的导语
物联网  ，是指将物与物的信息交互也接入到互联网中来，通过对具体事物进行标识、感知、信息传递和智能处理，在无需人工干预的条件下实现智能化识别、定位、跟踪、监测控制和管理，为人们提供智慧和简约的服务，在移动互联网时代，我们已经实现了人与人之间的无障碍信息传递，而借助于物联网技术，则可以真正实现万物互联，因此，物联网也被称为下一代互联网技术。然而即使是到了年的今天，虽然距物联网概念的提出已经过去了十几年的时间，物联网的发展仍然没有进入大规模产业化的阶段，甚至于连行业的标准制定都还没能统一，可以说物联网的发展仍是任重道远。
目前物联网的连接技术理念主要存在有两个发展方向，一个是短距离无线网络方案，包含 、蓝牙、、、 等多种技术，其中以蓝牙  的呼声最高。另一个则是低功耗广域网络技术，就是专为低带宽、低功耗、远距离、大量连接的物联网应用而设计，包含多种技术，如 、、、 等。其中  是  推出的标准技术，经过多次讨论、已成为了目前被全球广泛接受的全新窄带物联网技术标准，可谓是技术演进和市场竞争的综合产物。
一 蓝牙 
 蓝牙  技术是由蓝牙技术联盟   年  月  日正式发布， 组织是蓝牙技术的官方组织，它是由全球超过三万家公司加盟的非盈利机构，也是蓝牙商标的所有者。它以制定蓝牙标准、推动该技术的普及和发展为宗旨。

 蓝牙技术本身并不是什么新技术，蓝牙技术适用于无需额外无线基础设施的智能手机和平板电脑，可提供短距离、点对点连接，同时本身功耗也很低。各种蓝牙产品也随处可见，举凡移动设备、耳机、车机等各式消费或专业电子设备都能发现蓝牙的踪迹。然而却正是由于蓝牙  的发布，才使得蓝牙技术进入物联网行业的视野。这主要是由于蓝牙  相比于上一版本，有了以下特性的改变。

 倍传输速度的提升，  在之前  的  基础之上，增加了一个可选的  的 。
 倍通讯距离的提升，在降低带宽提升通讯距离同时保持功耗不变允许的最大输出功率从之前的  提升至 。使得蓝牙发射和接受设备之间的理论有效工作距离增至  米。
 倍广播数据容量提升，从  的  字节提升至  字节，并且可以将原来的  个广播通道扩展到  个广播通道，增加通道选择算法同时允许无需配对接受信标的数据，比如广告、、位置信息等。

基于蓝牙  的技术，使得蓝牙信号覆盖范围更广，传输速度更快，连接更加稳定可靠。蓝牙  还有支持室内定位和导航的功能，结合  可实现精确度小于  米的室内定位，并且蓝牙  还针对物联网的应用做了很多底层优化。
然而仅靠以上这些新特性，蓝牙  还不能说是物联网技术的完美解决方案，因为它没能很好的解决联网问题，各个蓝牙设备仍然是独立的个体，且无法直接接入因特网。于是在  年  月  日，蓝牙技术联盟正式推出   标准，蓝牙技术开始全面支持  网络。随着   标准的发布，可以说是补齐了蓝牙  技术在物联网应用上的最后一块短板，利用这项技术，可以实现设备的自组网连接，通过接入节点即可实现跟互联网相连，大大减少组网成本。

 组网示意 网络可以使蓝牙设备直接或间接传输信息到接受信息所需的设备，这种网络架构相对稳定，整个系统不会由于单个设备的失效而无法顺利运行。由于蓝牙网状网络采用泛洪法从网络中的一个设备传输信息到所有的各个设备，与路由传输方法相比，这种方法需要较少的存储和较低的处理能耗，故而更节能。
二  
 年  月，在  组__的研究项目中，主要有  项技术被提出，分别是拓展覆盖  技术、 技术和  技术。其中  由华为、高通和  联合提出， 由爱立信、中兴、诺基亚等厂家联合提出。最终，在  年  月的  次全会上协商统一为  技术。

 技术演进从接入网络技术来看， 是在  基础上发展起来的， 其主要采用了  的相关技术，并针对自身特点做了相应的修改。 当  与  并存部署时，下行链路上  和  可以 做到互不影响。 可直接部署于已有的  或  网络中，即可复用现有基站以降低部署成本，实现平滑升级。 是可运营的电信网络，这是  区别于 、 等技术的关键。
 具备四大特点：
一是广覆盖，将提供改进的室内覆盖，在同样的频段下， 比现有的网络增益 ，覆盖面积扩大  倍；
二是具备支撑海量连接的能力， 一个扇区能够支持  万个连接，支持低延时敏感度、超低的设备成本、低设备功耗和优化的网络架构；
三是更低功耗， 终端模块的待机时间可长达  年；
四是更低的模块成本，企业预期的单个接连模块不超过  美元。
 网络部署因为  自身具备的低功耗、广覆盖、低成本、大容量等优势，使其可以广泛应用于多种垂直行业，如远程抄表、资产跟踪、智能停车、智慧农业、公共监测、企业安防等。 
 的部署方式较为快捷、灵活，也可以部署在  网络。 单扇区支持  万个连接，比现有网络连接数高  倍，目前全球有约  万个物理站点，假设全球有约  万个物理站点，所有站点全部部署 ，每站点三扇区共计可接入终端数将达  亿个。 
三  
无线射频识别技术   是一种非接触式的自动识别技术，它通过射频信号自动识别目标对象并获取相关数据。 技术广泛应用于各行各业，日常生活中常见的门禁、食品、安防设备、交通系统都有  技术的应用。
 系统的基本组成包括：
①读写器：读取有时还可以写入标签信息的设备，可设计为手持式或固定式；
②天线：在标签和读写器间传递射频信号；
③标签：由耦合元件及芯片组成，每个标签具有惟一的电子编码，附着在物体上标识目标对象；
每个标签都有一个全球惟一的  号码 ， 是在制作芯片时放在  中的，无法修改，标签根据其工作方式分为有源标签和无源标签两种。读写器对标签的操作有三类：识别，读取 ；读取，读取用户数据；写入，写入用户数据。

 系统工作原理 的工作频率分为低频和高频两类，低频系统工作频率通 常 小 于 ，典 型 工 作频 段 为 、、 等。低频电子标签成本较低，标签内保存的数据量较小，读写距离较短，外形多样，读写天线方向性不强；高频 系 统 工 作 频 率 通 常 大 于 ， 典 型 工 作 频 段 为 、、、 等。高频系统标签内保存的数据量较大，读写距离较远可达几米至十几米，能适应物体高速运动，外形一般为卡状，读写天线及电子标签天线均有较强的方向性，但成本较高。
 技术借助无线电原理，读写器可以无接触的跟电子标签进行数据通讯，同时还具备防水、防磁、耐高温、使用寿命长、读取距离大、数据可以加密、存储信息更改自如等优点，也可识别高速运动物体并可同时识别多个标签，操作方便、快捷。
后语
物联网发展到今天，各种技术方案呈现出百家争鸣，百花齐放的状态，短距离无线网络技术方案，重点在于解决室内定位和室内联网问题，是物联网通讯最后一公里的解决方案，瞄准的是智能家居，智能穿戴、智能商场、室内照明、智能工厂、智慧医疗等领域。在这一领域，除了上述的蓝牙和  技术，还有  技术也是一大分支，不过  发展到如今，各大厂商的设备各自为营的情况比较严重，不同产商设备间互通性并不是很好，随着  规范的发布，或许会给这一状况带来改善。而以  为代表的低功耗广域网络技术则每个设备个体都能独立联网，典型的应用场景是无人介入，而又需要定期获取数据的情形，在建筑监测、智能表计、水域监测、科学测量、共享单车领域有很大的应用空间。
物联网终将会走入千家万户，囊括人类生活的方方面面，不管是当下还是将来，大一统的局面是很难出现的，物联网应用面对的是复杂的网络环境，必定是各种技术互补发展，通过低功耗广域网络和局域网络之间的互补效应才能带来最好的物联网体验。一、写在前面的话
、关注的问题
大数据时代的冲击，导致各种业务的对数据的依赖不断加大，要求存储的数据格式更加复杂和趋于个性化，而要求保留的时间也越来越长，对数据库存储的压力随之不断提升。
由于数据的重要性和价值不断提升，对历史数据的利用率也愈发提高，冷热数据的界定也逐渐模糊，对于全量数据的查询处理速度的要求也越来越高。
、怎样应对
数据量大？格式复杂？
自身的文档型特性很好的解决了格式灵活设置，在同一个库中支持不同格式的求，而在中存储引擎引入了压缩功能，出色的压缩了海量数据的存储空间。
 快速查询大量数据，开销如何？
建立索引将大量提高数据的查找和处理效率本文着重关注索引的开销，关于索引的效率将在性能分析中呈现，但在海量数据中建立索引的开销过大时间、空间一直是一个棘手的问题。很好的优化了建立索引的机制，对于海量数据，能够很好的缩短建立时间和压缩占用空间。
二、压缩
、概念
压缩原理
使用 存储引擎，支持压缩一个新的存储引擎。 使用页面管理磁盘  。每个页面都包含很多文件。页面被写入磁盘时就被默认压缩，当在磁盘中被读入高速缓存时它们就被解压。

支持对所有集合和索引进行压缩和前缀压缩如果数据库启用了，文件一样会压缩。这为广大使用者们带来了又一福音，因为之前版本的都是因为存储引擎消耗了过多的磁盘空间而不得已进行扩容。其中压缩为数据库的默认压缩方式，用户可以根据业务需求选择适合的压缩方式。理论上来说，压缩速度快，压缩率，而压缩率高，消耗多且速度稍慢。当然，只要选择使用压缩，肯定会占用更多的使用率，但是考虑到本身并不是十分耗，所以启用压缩完全是值得的。
集合压缩
①无压缩
②默认启用
③
索引压缩
①无压缩
②前缀默认启用
、使用
适用不适用的场景
①随机数据不能压缩；
②已经压缩过的数据可能是二进制数据不能压缩；
③文本压缩效果特别好；
④对于文件中的字段名压缩效果特别好尤其是短字段名。
如何开启
 中的默认是存储引擎，故其默认对集合和索引启用压缩。在使用之前版本的时，你还需要指定–选择使用再利用压缩功能。为了在启动时明确设置副本的压缩，可以在配置文件中的进行相应设置。使用命令行选项–。
    要指定压缩特定的集合，你需要使用 命令中的并传入相应参数项来覆盖默认值。例如，使用压缩库创建一个名为的集合：
    “”  {   {  {   ‘_=’ } } } 
、实战
场景介绍
 ①   数据结构

 ②集合大小
_  万
_  万
_  亿
_  亿
_  亿
测试结果



的 存储引擎在数据压缩主要是文本数据的能力出色，基本上能达到压缩左右的存储空间，极大程度上提升了磁盘空间的使用率。

的 存储引擎压缩从小规模数据的压缩到海量数据的压缩其性能保持稳定，压缩率均在。可以说明数据量的增大不会成为其压缩功能的瓶颈。

三、索引


、概念
 提供了多样性的索引支持，索引信息被保存在 中，且默认总是为_创建索引，它的索引使用基本和 等关系型数据库一样。其实可以这样说说，索引是凌驾于数据存储系统之上的另一层系统，所以各种结构迥异的存储都有相同或相似的索引实现及使用接口并不足为奇。
、使用
创建索引
 ①普通索引
 {}{}{}
注意：将键的索引命名为，默认情况下建立的单个索引均为普通索引非唯一索引，且在后台进行创建，不会阻塞其他操作。
 ②复合索引
                  { }
注意：数字表示键的索引按升序存储，表示键的索引按照降序方式存储。
 ③唯一索引
   {}{}
  {}{}
注意：单个索引和复合索引均可设置为唯一索引，只需保证插入数据的唯一性即可。
查看索引
 
删除索引
 {}
、实战
  场景介绍      
 ①   唯一索引

 ②   普通索引

 ③   复合索引

 测试结果
①空间开销
 
 

测试集合为_亿数据，压缩后存储空间约为，其中索引唯一索引、普通索引、复合索引所占空间约为，占存储总空间的。

在三种不同的索引中，


唯一索引_   占  ，
复合索引_占，
普通索引占。
说明建立唯一索引是主要是影响索引空间开销的主要因素，而复合索引所占空间小于其分别建立单个普通索引。
②时间开销


随着数据量的增大，建立索引的时间开销将不断增大，故数据集合最初的设计极为重要，在海量数据生成后中建立索引，有一定的时间开销。

在建立索引的时间开销上：普通索引  复合索引个 唯一索引。


在一亿数据的集合中，
普通索引时间开销：约分钟
 复合索引时间开销：约分钟
唯一索引时间开销：约分钟
《  第一期 ：集群搭建 》《  第三期：托管  存储服务 》的索引是其一大特色，本文从原理层面讲述索引中的索引的实现。
 索引的创建与使用
通过 {} {} 来创建一个索引，索引的精度通过来指定，越大，索引的精度就越高。更大的带来的插入的可以忽略不计。
通过
{ 
      
      
      
      
         
     |}
来查询一个索引，其中：| 表示应该如何理解创建的索引，表示将索引理解为平面索引，表示将索引理解为球面经纬度索引。这一点比较有意思，一个索引可以表达两种含义，而不同的含义是在查询时被理解的，而不是在索引创建时。
索引的理论
 使用一种叫做的技术来构建索引，但是的并没有使用国际通用的每一层级个的描述方式见 。而是使用平面四叉树的形式。
如下图：

很显然的，一个的精度能把平面分为个，一个的精度能把平面分为个。索引的默认精度是长宽各为，索引把地球分为块，每一块的边长估算为
 =  米
的官网上说的的精度就是这么估算出来的
                                 

索引在中的存储
上面我们讲到使用平面四叉树的方式计算。事实上，平面四叉树仅存在于运算的过程中，在实际存储中并不会被使用到。
插入
对于一个经纬度坐标，计算出该坐标在平面内的编号，该编号为是一个的类型，该类型被用作的，因此实际数据是按照 {}的方式被插入到中的。
查询
对于索引的查询，常用的有和两种。查找距离某个点最近的个点的坐标并返回，该需求可以说是构成了服务的基础陌陌，滴滴，摩拜， 是查询一个多边形内的所有点并返回。我们着重介绍使用最广泛的查询。
的查询过程
的查询语句如下：

   {
        
              
               
      {   }   
             
   }

可以理解为一个从起始点开始的不断向外扩散的环形搜索过程。如下图所示：

由于圆自身的性质，外环的任意点到圆心的距离一定大于内环任意点到圆心的距离，所以以圆环进行扩张迭代的好处是：
减少需要排序比较的点的个数能够尽早发现满足条件的点从而返回，避免不必要的搜索
点集密度估算
那么，如何确定初始迭代步长呢，认为初始迭代步长和点集密度相关。
 会根据点集的密度来确定迭代的初始步长。估算步骤如下：
从最小步长默认为向外以矩形范围搜索，如果范围内有至少一个点，则停止搜索，转否则转 步长倍增，继续步骤以矩形对角线长度的三倍作为初始迭代步长。

圆环覆盖与索引前缀原理
上面我们说过，每一次的搜索都是以圆环为单位进行的，但是真实存入中的是{}，计算出与圆环相交的所有边长的格子的的值并在中搜素绝对是一个非常愚蠢的做法，因为如果圆环的面积很大，光是枚举所有的就有上百万个。
但是换个角度来看，其实以地球为一个整体去看待存储的点，绝对是稀疏的。这个稀疏的性质使得我们可以粗略的以平面四叉树的角度自上而下的找出与圆环相交的四叉树中间节点。
整个平面与圆环必然是相交的，于是将平面一分为四，剔除不相交的部分，对于每个留下来的子平面，继续一分为四，剔除不相交的部分，经过多轮迭代，留下来的子平面的都是该子平面中所有的索引前缀，如下面四幅图所示：

上面四幅图中，分别为整个平面被四叉树划分次后与圆环的相交情况，如果继续往下细分，所形成的图形就越来越逼近整个圆环。中使用参数来限制最多逼近到多少个子平面与圆环相交，默认为。
我们注意到，上述平面划分过程为四叉树的分裂过程，每一次分裂都使得递归搜索的子平面与父平面有相同的前缀这里需要思考为什么，可能不太明显，因此每一个子平面可以对应于中一段连续的这里又是为什么？，也正因此，该参数越大，会使得需要搜索的子平面越少，但是会使得的搜索更趋向于随机化搜索，导致更多的。我们知道更适合于做搜索，所以对该参数的调整需要慎重。
展望
原生的接口是国内各大应用的主流选择。腾讯云的专家经过测试发现，在点集稠密的情况下，原生的接口效率会急剧下降，单机甚至不到。腾讯云对此进行了持续的优化，在不影响效果的前提下，的效率有倍以上的提升，建议大家选择腾讯云作为应用的存储方案。

推荐阅读

复制集原理
基于用户画像大数据的电商防刷架构需求分析
有需求才有动力！
最近有不少服务器，但是管理起来还需要输入密码，而且有的还不一样，太麻烦了，所以就利用配置免密码登录服务器。
流程
生成秘钥
首先在自己的电脑上生成秘钥。
 –  –
直接回车生成秘钥对。
可以看到在  目录找到一个  的目录，有两个文件。
_ 和 _ 其中一个是私钥，一个是公钥。
服务器上利用同样的方法创建，保证有一个  目录。
复制秘钥
登录服务器后，在  目录新建一个文件，名字叫做 _
将刚才自己电脑上生成的公钥内容复制进去，保存。
然后进行权限设置
   _
如此一来，配置就完成了。
验证
断开服务器，重新连接，发现就可以直接进入了。前言
在你的工程中，是否有一些文件代码具有配置化，模板化的特点，这些代码不再有逻辑上的变动，只是随着业务的发展，重复的堆叠。当你在这个文件中新增一行配置时，内心是否心生抗拒，思考过这行配置是否可以不用人工来添加，让你从机械重复的劳动中解放出来呢？
本文通过介绍腾讯视频项目中，创建的例子，向大家介绍，如何通过自定义注解处理器自动生成代码，以及如何调试自定义注解处理器。首先，介绍一下我们工程中，是如何创建的。
方法中，将传递给的静态方法，返回指定的。

      {
     
     =   
      
}
在我们的工程中，频道页上所有的，都是通过这个工具类创建出来的。
类：
       {
    
      
}
这里省略了一些细节。
方法：
        {
         {
              =  {
                  {
                     _
                          
                     _
                          
                        此处省略了很多条
                          
                     _
                          
                     _
                          
                 }
            }
      } {

       }
}
那么，当我们新增一种的时候，套路已经清晰了。当我们新增一种时，要经历以下几个步骤：

定义 常量__。
新建 文件，编写代码。
在文件的方法中新增一条配置。

现在，我们就开始说明，如何自动化的在中新增配置。当然，你可能觉得，每次在中手动新增一条配置也没花多少时间。确实，我这里只是拿来举例子，配合讲明白这篇文章的主题。并且本文将通过新工程的方式讲解，而不是基于腾讯视频的工程。
首先，介绍一下需要用到的基础知识。

是 中一款用来辅助处理编译时注解的插件。不知注解为何物的同学可以先下去补补课。上非常著名的、、等优秀开源库都使用了这个插件，它们都是基于编译时注解实现的框架。
  
   是之后提供的用于编译期处理注解的组件，简称。主要包括两大部分：、用于模型化 程序语言结构的模型化，包括包下的 ，包下的  及其他辅助工具类。
、包下用于编写注解处理器的注解处理。
 和 
代表源文件中的程序构建元素，例如包、类、方法等。接口有个子类。




包程序元素





类、接口、注解、枚举元素



方法参数、成员变量、局部变量、枚举常量、异常参数



方法、构造函数、静态代码块


    类、接口、方法、或构造方法的泛型参数



 用于描述程序中元素的信息，即 的元信息。通过接口可以获取的。接口的继承结构相对比较复杂：

一些已知的的释意：




原始数据类型， 





引用类型



数组类型



声明的类型，例如类、接口、枚举、注解类型



注解类型



类类型



枚举类型



接口类型



类型变量类型



 类型



通配符类型



当是或者时，可以转化成
  = 

是一组用来生成 文件的 。正如其名，当你创建文件时，你将不用再处理代码换行、缩进、引用导入等枯燥而又容易出错的工作，这一切都将能够很好地为你完成，你的工作将变得富有诗意。
、、、、都是提供的用于描述一个源文件元素的类。代表了一个接口、类、注解、枚举的定义，代表一个成员变量、函数参数的定义，代表了方法的定义，用于描述一段代码块，表示源文件本身。一个文件正式通过以上几种类型的嵌套、组合，最终描述成一个完整的源文件。为每种元素，都提供了相应的类。
提供了一套自定义的字符串格式化规则。常用的有、、、：



格式化规则
表示





字面量



字符串



类、接口



变量



介绍完基础知识，下面我们通过新建工程的方式，一步步讲解：
新建工程
 新建工程。 新建 ，选择 ，该中，提供注解的定义：


   {
       
}
 新建_ ，选择 ，该 中新建类，该类需继承类。
在_  的中，添加如下配置：
 {
        
     
     
}

 = 
 = 
现在，你的工程结构应该如下图所示：

在中编写注解处理的代码：

{}
     {

      
        __ = 
        _ = 
      

    
            {
        
            = 
          = 
         ==  || {
             
        }
         = __
         ==  || {
                   
             
        }
        解析参数  ①
          = 
          = _
         {
             =   {
                 = 
            }
        }  {
                  
               
        }
          = 
        

          = 
         {
             = 
                 
        }  {
                  
              =  
            
             
        }
          = 
          = 
        构建类
          = 
                 
                         
          =  
          =  
        构建方法       
          = 
                  
                
                
                
        如果指定了，则如果创建发生异常时，返回
         = {
             
        }
        构建{
                    }
        代码块
          =  
        循环遍历所有被注解元素，每项元素都会对应生成一条 语句
            {
              = 
             == {
                
            }
            
              = 
              = 
             =      =   
             \     
        }
        没有匹配到的情况下，返回
        \   
        
        
         =  {
              
                
            
        }
        构建文件
          =  
        写文件
         
         
    }
方法通过遍历所有被注解的，生成一个由指定的文件，该文件中包含一个静态方法       的方法 ，该方法体由一个语句根具的值创建并返回不同类型的。 
提供了、、三个注解分别用来注明该文件支持的注解类型，支持的版本，和支持的输入参数。你也可以通过覆写的，，方法来指定。可以看到，我们通过注解描述了需要处理的注解类是 ，该注解处理器需要指定的输入参数有和，指定了生成文件的名称，指定了当创建发生异常时，需要返回一个默认，在模式下，这很有用，比如，你在上看到了一个，表明该位置创建失败了。
在  方法中，为了方便我们向控制台输出日志，我们将保存起来。工具初始化时，会回调方法， 是向传递的编译环境参数，向提供了访问编译环境的工具集，比如，通过可以获得向控制台报告错误、警告、提示的工具，通过可以获得创建源文件的工具。
接下来，我们来看方法。方法可能会被工具多次调用，，初始化的时候，会调用一次方法。在第一次调用时，编译器会将整个工程作为输入，收集到所有被注解的元素，然后同过方法的参数传递给方法处理。如果在某轮处理中，生成了新的文件，则编译器会将新生成的文件作为输入，然后收集到新的被注解的元素，直到不再产生新的文件后，循环调用结束。注意，当没有新的文件生成后，还会被再调用一次，此次输入是空的。











整个项目














在代码①处，我们解析输入参数_，如过_被指定，则会尝试通过这个类的方法，这个方法接受一个字符串，返回一个 ，完整的描述了代表的类名称、包名称等信息。如果格式不合法，会抛出。
下面看这两行代码：
      = 
    
 通过的方法获取操作程序元素的工具类，并通过方法返回由指定的 元素。会校验这个元素是否合法，如果不合法，会抛出异常，终止处理。
        {
         = {
                   
        }

        {
                  
        }
        {
                  
        }
    }
 所接受的元素必须是类，而且必须继承自，并且必需相对生成的文件可见，也就是生成的文件必须对所表示的类具有访问权限。
元素是否继承自
        {
         {
              = 
             == {
                 
            }
              =  
            {
                 
            }
             = 
        }
    }
元素是否可见：
       {
          = 
          =  == 
          = 
          {
             
        }
        {
             
        }
        {
             
        }
         
    }
返回包裹的最里层元素，如果该元素恰巧是一个类，那么就是一个内部类。返回该元素的访问权限修饰符，是反射包中提供的类，定义了，等常量，分别对应、修饰符。如果是一个内部类，则其必须是一个静态类。其次，如果是一个类，则可以访问，否则，看是否和指定的文件是否在同一个包下。
、、、、都是提供的用于描述一个源文件元素的类。代表了一个接口、类、注解、枚举的定义，代表一个成员变量、函数参数的定义，代表了方法的定义，用于描述一段代码块，表示源文件本身。一个文件正式通过以上几种类型的嵌套、组合，最终描述成一个完整的源文件。为每种元素，都提供了相应的类。
          =  
         
当构建好后，则通过方法，生成源文件。
          {
         {
              = 
              =
             {
                
            } {
                 {
                    
                }  {
                    
                }
            }
        }  {
                   
        }
    }
通过会返回一个接口，的方法可以创建文件对象，这样，我们用可以将生成的字符串写到文件中去了。为什么这里需要通过提供的接口来写文件呢，我们完全可以通过自己 的方式创建文件呀？答案是确实可以，但是这样，就无法感知有新的源文件创建了。
注册处理器
文件代码编写完后，还有一件非常重要的事情，就是注册，这样编译器才能在编译的时候找到正确的注解处理器处理注解。

在 的 下新建目录
在下继续新建文件


 在文件中新增一下语句：

以上配置过程也可通过引入插件自动完成。是提供已一款可以自动生成包配置的插件。首先在 文件下，添加如下红框中依赖：

然后再上新增如下注解：

应用
现在，我们来编写我们的主工程，来测试我们的_处理器。工程结构如下所示：

定义如下：
__
     {
       {
          
    }

         {
          
    }

           {
          
        
    }

       {
        吴涛
        
        __ 
        
    }

}

     {

       {
        
    }

         {
         
    }

           {
          
    }
}
 ：
  
    引入插件

 {
  

}

 {
     {
           注解处理器生成的文件名
               指定异常
    }
}

 {
    
    
      
     _
}
编译后，成功在目录下生成文件：
 

 
 
 
 
 


            
    {
          {
     {
       {
         
            
        
           
      }
    }   {
        
    }
  }
}
现在，我们可以在中引用该类了：
     {

    
        {
        
        _
          =  __
          = 
        
    }
}
如何调试？
也许在我们开发注解处理器的时候，还需要单步调试，以便我们寻找注解处理器的漏洞。下面就向大家介绍，如何调试我们刚才开发的注解处理器。
、在方法中的合适位置下断点：

下断点的方法与平常调试代码并无区别。
、在项目的根目录下的文件中，新增如下配置：
===_===
=
、新建 ：


注意新建的名称一定要是 。
、 

现在，我们看到断点已经生效：

、执行任务，命中断点：

结语
本文通过中使用工具类创建的例子，一步一步讲解了如何通过自定义注解处理器，如何使用提供的，以及如何使用插件，以自动化的方式来生成工具类文件代码，从而提高编码效率。另外，本文还讲解了如何配置虚拟机参数，来调试逻辑稍复杂的自定义注解处理器。
现在有越来越多的开源项目在使用，的强大之处可见一斑，因此作为一个开发者，我们有必要去了解这门技术。“早上，犹豫了半天，金拱门还是开封菜。想了想最近长肉厉害，忍痛喝了杯白毛女……”
看懂张泉灵发的黑话了么？不管看没看懂，点开这篇推送，指数君恭喜你加入本周炸裂舆论场的娱乐爆款事件——麦当劳改名金拱门！

腾讯指数监测显示，麦当劳改名金拱门的相关传播消息从月日时起出现，迅速掀起传播高峰。
憋太久的段子手们释放洪荒之力，素材“金拱门”充分发挥“尬聊尬聊”的土气，打开人们解构、娱乐各大国际品牌的大门，将事件推上舆论风口。

来源网络
媒体消息掀起浪花，段子手们推波助澜
据公开信息可知，麦当劳在今年月起酝酿改名，月日公司完成改名，当时并未引起关注。媒体的发现和挖掘，引发第一波关注。
微博成为此次事件的主要传播渠道，从日到今天时，总量超过万条。传播路径：
媒体引发关注——段子手推波助澜——各大品牌蹭热点——达到高峰
从微博传播内容看，是转载，原创内容占比。网友转载各种段子，大部分配以“哈哈哈哈哈”等无意义内容，充分展现了此次事件的娱乐围观性质。

部分热传段子，来源微博
金拱门的热传首先为竞对开封菜加一血，星爸爸、必胜客等也沾光，微博曝光频率得到增加。
最会蹭热点的杜蕾斯，当然没有错过这场盛宴，发布了新版海报，虽然新版海报赶不上段子手为其取的新名——拦精灵。

腾讯指数监测显示，近两天以上品牌的微博曝光量，都超过了从前。
从关注该事件的网民画像来看，后最关注“金拱门”，岁以下的网民占比近成。而更喜欢吃零食的妹子们，对金拱门的关注度不如男生，占比。简单说更关注金拱门的是：

男！青壮年！
来源：腾讯指数
金拱门？神棍来了……
为什么麦当劳改名“金拱门”，所有麦当劳餐厅未来真的就叫金拱门了？
。麦当劳发布声明，变更主要在证照层面，麦当劳餐厅名称、食品安全标准、营运流程等保持不变。
虽然从感知上来说，并没有过多变化，但微博网友继续娱乐，而知乎网友和媒体开始刨根问底，寻求改名原因。
最神棍的解释

来源知乎
最情怀的来源

来源知乎
最励志的解释

来源媒体
那些尬名的国际大牌们
麦当劳公司改名、餐厅不改名的做法正符合舆论心意。腾讯指数监测显示，本地化的有所克制，使这次改名反而助推“麦当劳”或“金拱门”品牌知名度。无论请哪位明星代言，恐怕也不会有如此广泛的舆论效应，让网友有如此高的参与热情。
反观，亦有说要本地化结果却失败“尬名”的品牌，比如爱彼迎 、美斯恩。

腾讯指数监测显示，“爱彼迎”近日声量不及“”一半
需要看到的是，这场网络狂欢的背后，有着年轻人对“麦当劳”怀旧情怀的推波助澜。

年内地第一家麦当劳深圳东门店的昨天和今天。 微信公众号“南方视觉”
对于许多后、后来说，麦当劳是一顿奢侈的大餐，是小朋友艳羡的生日会，是手办玩具的收集处……年来，这个连锁品牌或多或少承载着我们记忆的一部分。随意尬名，可是会造舆论抵制的。

于是，看完舆情报告的你，要不要来一份怀旧的“金拱门”？

本文来自微信公众号 腾讯指数服务号作者：张艳

导读
在，任何产品、任何项目的代码，在没有经过有效的代码审查 前是不能提交到代码库里的，这也是程序如此优秀的最重要原因之一。恩，这就是所谓别人家的公司，不过， 的重要性，可见一斑。说起 ，通常会被认为是开发的事情，其实不然，作为测试人员，尤其是“测试左移”越来越成为趋势的情况下，势必要提高代码能力，而 就是一个很好的切入点。不仅可以学习开发的技术，还可以完善测分、提前发现、降低质量风险和测试成本，好处不言而喻。笔者作为 的新手，经过一番学习和实践，总结了一点点“潜规则”，希望可以抛砖引玉。
资源泄漏篇
试想，如果申请的资源未进行释放，那势必会资源泄漏，尤其是对于长时间运行的程序来说，会导致系统中可用的资源越来越少，严重的，系统会因为资源耗尽而崩溃。因此，资源泄漏的问题需要得到重视，除了提测后的资源挂机测试之外，在前期 阶段更加需要注意，以便尽快尽早发现问题，降低成本和风险。
对于这类问题，笔者总结了如下需要注意的地方：
慧眼识珠：资源获取和资源释放函数需要成对使用

成对使用的资源获取和释放函数太多，这里就不一一列举啦，总之，看到资源获取语句，必查资源释放语句，反之，亦然。
异常处理篇
优雅编程需要在一开始就考虑异常事件的处理，不仅需要保证在正常情况下程序可以稳定运行，而且在发生错误和出现“意外事件”时仍然能继续可靠运行。因此，需要尽可能多的预见所有这些异常事件。异常处理代码也是的高发区域，不仅在设计用例阶段需要考虑全面， 的时候也需要特别关注。

慧眼识珠：异常处理
 任何可能出错的函数调用语句，必须加异常处理，这些函数调用，包括但不限于
网络交互：是否有超时、是否考虑负载均衡、重试机制等
数据库交互：是否连接成功、超时、重试、判断返回值等
读取请求数据包：是否判断返回值，防止读到脏数据等
文件系统操作：  等，判断各种正常异常情况
边界值考虑是否周全
 对于异常处理，务必注意如下：
异常判断一定要有异常判断的时机、条件一定要正确异常判断的分支一定要完整异常处理一定要充分边界考虑周全
数组越界篇
访问数组时，如果访问了数组定义之外的范围，即下标落在区间 之外，会导致程序运行错误，而中数组下标越界，编译器是不会检查出这种错误的，但后果可能会比想象中严重，甚至程序崩溃。因此，这类看似不起眼的小问题，也需要得到重视。下图就是一个缺少下标判断的例子。

慧眼识珠：对于用到数组的地方，一定注意如下几点：
 记住数组循环操作的代码模板  =     
 记住数组下标判断的代码模板    ||  = 
 错误区间
或者
  =     
 正确区间
 看到下标操作，必查下标判断
下标判断一定要有，且出现在正确的地方即判断要及时，并注意判断条件要正确
多线程问题篇
多线程编程很容易遇上诸如丢失更新、脏读、死锁等线程冲突问题。多线程的问题一旦发生便很难定位和解决，所以要在编程的初始阶段就要注意避免多线程程序常见的错误。多线程同时读写同一资源，例如变量，文件，同一缓冲区等，一旦出现竞争条件，很容易导致程序运行结果出错。这类的用户反馈问题也有很多，首先列举下导致多线程问题的原因：
 资源的读写和更新没有加锁此处经常会有用户反馈
 资源的获取和访问之间有时间间隔
 加锁范围太小
 使用了线程不安全函数
慧眼识珠：多线程问题
 识别全局资源
 开头的变量，_，_利用，如 ，将鼠标移到变量上面，会显示变量类型
 看到资源的读写和更新，必查加锁
若该资源会被同时读写，则检查此变量的所有读写操作，确保正确加锁。
 看到加锁操作，必查加锁范围
加锁太小，程序出错；加锁太大，降低性能；需要根据具体情况权衡。
 看到资源的获取和访问之间有时间间隔，必查资源是否会被更新
 识别线程不安全函数：
返回缓冲区的函数，例如_，建议分别使用__，_代替会记录函数状态的函数，例如基础库的初始化函数，例如_ __
除零错误篇
虽然  加入了异常机制来处理很多运行时错误 但是异常机制的功效非常受限 很多错误还没办法用原生异常手段捕捉，例如这里所说的除零错误，而这个错误也经常导致程序崩溃，因此 时需特别注意。
慧眼识珠：除零错误
 除法或者取模操作，必加除数为零的判断
 浮点转整型会丢失小数部分，特别需要关注变成的情况
 对于影响程序稳定性和健壮性的输入，必做检查
缓冲区溢出篇
通过往程序的缓冲区写超出其长度的内容，造成缓冲区的溢出，从而破坏程序的堆栈，造成程序崩溃或使程序转而执行其它指令。造成缓冲区溢出的原因是程序中没有仔细检查用户输入的参数。
慧眼识珠：缓冲区溢出问题
 识别缓冲区溢出高风险函数，慎用或者干脆不使用缓冲区溢出高风险函数
不保证补\的函数，例如系列函数有可能溢出，需要排查一遍是否存在这些的使用参数中不带目标缓冲区长度的字符串处理函数，例如，，，，等等最好使用安全版本
 看到缓冲区溢出高风险函数，必查溢出
 看到可写缓冲区当参数，必查缓冲区长度
业务逻辑篇
除了上述和业务无关的较为通用的具体代码问题外，业务逻辑错误，也需要关注，当然这就需要在深入理解业务需求的基础上了。
慧眼识珠：业务逻辑错误
 前提：深入了解被测业务、需求，即深入需求分析、采用测试建模
 找开发了解架构设计、代码结构，事半功倍
 可以分阶段进行：
阶段一总览：看到一块代码，不急于研究细节，而是首先根据上下文，函数原型，以及对代码结构的快速扫描，简单得出代码与业务需求的映射；
阶段二深入：根据代码结构深入，可以从核心功能或者感兴趣的部分入手，深入浅出
阶段三回顾：再回头总结思考一下：这个代码块的作用是什么？有何影响？是否正确按照预期实现了业务需求？
 识别逻辑错误，需要测试人员在做时候，能够经常地从代码中“跳”出来，使用测试思维而不是开发思维，来思考上面的问题、或者跟开发人员沟通。一些逻辑错误，确实可以在思考、沟通的时候自然而然暴露出来。
 规则提取篇
以上介绍了一些常用的技巧，那么在一定程度上是否也可实现自动化呢，答案是：。由于业界的静态代码扫描工具如 等，只专注于不存在误报的、能够普遍使用的规则，规则有限且是基础校验，于是管家测试组的振宇大牛开发了一套灵活自定义规则的缺陷规则代码扫描工具，规则来源于、分析、用户反馈分析等。缺陷规则代码扫描专注于静态扫描存在误报的规则以及只有在特定运行时态会的代码规则，可以说补齐了静态代码扫描的短板并实现了一定程度的自动化。
应用管理测试组的测试童鞋，从月至今贡献了条扫描规则条已实现自动化，条作为经验，这些规则每天都在跑，并且会随业务增量添加哦。据不完全统计，发现有效 ，有效解决率。该自动化扫描目前还会存在一些误报的情况，，还需要人工过滤。下图显示的是某次的扫描结果，还需要人工。待将来优化到零误报，则可以节省掉这一部分工作。

综上所述，作为新手的测试人员，笔者只是罗列了一些简单的技巧，当然，主要是抛砖引玉，期待大家更多的分享交流，相信哦。最后，希望大家都能慧眼识珠⊙⊙，一秒发现噢。

相关推荐【腾讯】和开发一起写代码，让测试左移起来【腾讯】不会做分析？套路走起作者： 崔杰

导语
目前互联网大量的应用层协议从迁移到了，已经在越来越多的场合替换协议。近期由于业务需要，我们通过对的请求进行了一次抓包分析，同时也了解了更多相关知识，整理出来和大家一起学习。 
一、概述
到底什么是呢？简单而言，是使用加密的协议。协议通过明文进行信息传输，存在信息窃听、信息篡改和身份冒充的风险，而协议具有信息加密、完整性校验和身份验证的功能，可以避免此类问题。
全称为：安全传输层协议  ，是介于和之间的一层安全协议，不影响原有的协议和协议，所以使用基本上不需要对页面进行太多的改造。
注：大多数人将和  联系起来，是公司在年代中期发明的。随着时间的推移这种说法就渐渐变得不准确了。由于失去了市场份额，它将的维护工作移交给因特网工程任务组。第一个后版本被重新命名为安全传输层协议，是在年月份发布的。由于诞生都年了， 所以真正的“”传输其实是几乎见不到
二、看握手
下面是我们抓包数据中的一次请求的建立过程：

很明显，前条消息对应的是通信的三次握手的过程。需要说明的是，根据，一旦出现“”就意味着需要连接目标端的号端口
 
从这条消息开始，开始协议的握手过程

我们可以在 消息中，看到两个信息，根据它们分别是：第一处表示本次通信使用的版本为；第二处表示客户端期望使用的版本为。注：版本协商，客户端会提供它能支持的最高的版本，由服务端确认最终使用的版本

前面的四个字节是当前时间，它的格式是时间戳。跟随其后是字节的随机数，它将在后面过程中使用。
 
在这里它是空值或者是。如果在几秒前连接过该服务，它就可能继续使用之前的会话，不需要重新执行整个“握手”过程。在我们的抓包内容中，由于是第一次连接，所以 长度为。
 
它是请求发送端所支持的密码算法的一个列表。这里看到请求发起方提供了个可供选择的选项。关于的解释，我们在后面篇章会有更详细的介绍。
： 
这个字段包含了我们请求要发往的服务器的域名信息，它作用有些类似协议中的“”，这样就允许了公司出于成本的考虑将上百个网站绑定在同一 地址上。


其中有服务端对 回应的一些关键信息：

同 类似，它返回了服务端的当前时间，以及服务端产生的一个字节随机数

服务端确认通信使用的版本：
 
服务端选择的通信使用的加密协议套件：
_______
 
建立的会话标识，有了它，随后重连服务器就不需要再执行一个完整的握手过程了。
    
在同一条消息中包含了：服务端返回证书，交换公钥以及“ ”结束三部分内容。客户端收到服务证书后，会先验证证书的合法性，如果验证通过才会进行后续通信。
    、  
这里三条客户端发送的消息：交换公钥，编码改变通知 和 握手结束消息。   、  
这是握手过程的最后一条消息，内容为：服务端编码改变通知 和 握手结束消息。至此，通信的整个握手过程已经完成。
要注意，在消息中包含两部分信息，标识和校验信息。但是无论客户端还是服务端，在  之后的内容都已经通过加密方式传输了，所以中具体内容已经无法通过直接查看。       通信过程可以总结为

客户端将可支持版本、加密套件列表、随机数等，通过 结构体传给服务端服务端将选定的版本、使用的加密套件和服务端产生的随机数通过结构体回传给客户端。同时也会把证书传给客户端，证书里面同时带有公钥客户端验证证书后，会计算产生随机数字 并用证书公钥加密后发给服务器，同时通过计算获得协商密钥服务端使用私钥解密出 ，并通过计算获得协商密钥 最后双方使用对称加密的密钥进行加解密传输
三、的介绍
在基本了解的通信过程之后，我们再来了解一下的概念。每一个都是个算法类型的组合：
个 认证算法个加密算法个   消息认证码 简称算法个 密钥交换算法显然，这个算法是用于实现信息加密、完整性校验 和 身份验证的功能
从我们的抓包内容中可以看到：服务端最终选择的加密套件为：
_______
对应到算法类型后：
算法类型    示例中对应算法    常见算法名称认证算法        主流加密算法    __ ，加密模式  
和不推荐，已淘汰
算法          密钥交换算法        注：关于 中各算法的流行趋势，感兴趣的同学可以自行检索
关于协商过程：消息内容是通过来指定过程中使用的算法的服务端大多数情况下，会从客户端 中按排列顺序从上往下进行选择，因为排列靠前意味着安全性越高算法的选择会一定程度上影响连接的性能，在某些场景下服务端可以综合考虑安全性和效率问题，选择更加合适的算法组合。
四、一些数学相关的知识
对称加密 和 非对称加密
对称密码编码技术，它的特点是文件加密和解密使用相同的密钥，即加密密钥也可以用作解密密钥，这种方法在密码学中叫做对称加密算法。相应的非对称加密算法中加密和解密使用两种不同的密钥，其中，公钥是公开的，私钥由个人持有，必须保密。
 的通信过程中只在握手阶段使用了非对称加密，后面的通信过程均使用的对称加密。尽管非对称加密相比对称加密更加安全，但也存在两个明显缺点：
 计算资源消耗大。一次完全  握手，密钥交换时的非对称解密计算量占整个握手过程的  以上，如果应用层数据也使用非对称加解密，性能开销太大，无法承受。 非对称加密算法对加密内容的长度有限制，不能超过公钥长度。比如现在常用的公钥长度是位，意味着待加密内容不能超过字节。所以非对称加密目前只能用来作密钥交换或者内容签名，不适合用来做应用层传输内容的加解密。非对称密钥交换算法是整个  得以安全的基石，充分理解非对称密钥交换算法是理解  协议和功能的关键。下面我们选取其中常见的两种非对称算法进行介绍：
算法简介
年，三位数学家、 和  设计了一种算法，可以实现非对称加密。这种算法用他们三个人的名字命名，叫做算法。从那时直到现在，算法一直是最广为使用的非对称加密算法。
公钥与密钥的产生
假设想要通过一个不可靠的媒体接收的一条私人讯息。她可以用以下的方式来产生一个公钥和一个私钥：
随意选择两个大的质数和，不等于，计算=。
根据欧拉函数，求得 =φ=φφ= 
选择一个小于  的整数 ，求得  关于模  的模反元素，命名为。模反元素存在，当且仅当与互质
将  和  的记录销毁。
是公钥，是私钥。将她的公钥传给，而将她的私钥藏起来。
加密消息
假设想给送一个消息，他知道产生的和。他使用起先与约好的格式将转换为一个小于，且与互质的整数，比如他可以将每一个字转换为这个字的码，然后将这些数字连在一起组成一个数字。假如他的信息非常长的话，他可以将这个信息分为几段，然后将每一段转换为。用下面这个公式他可以将加密为： ≡   
计算并不复杂。算出后就可以将它传递给。
解密消息
得到的消息后就可以利用她的密钥来解码。她可以用以下这个公式来将转换为：
 ≡   
得到后，她可以将原来的信息重新复原。
解码的原理是
 ≡ · 
已知· ≡   ，即· = φ。由欧拉定理可得：
 · =  φ=·φ≡ ≡   
签名消息
也可以用来为一个消息署名。假如想给传递一个署名的消息的话，那么她可以为她的消息计算一个散列值 ，然后用她的私钥加密这个散列值并将这个“署名”加在消息的后面。这个消息只有用她的公钥才能被解密。获得这个消息后可以用的公钥解密这个散列值，然后将这个数据与他自己为这个消息计算的散列值相比较。假如两者相符的话，那么他就可以知道发信人持有甲的密钥，以及这个消息在传播路径上没有被篡改过。
通过一次简单实践更好的了解

假设 = ， = ，都是素数即可，则 =  = ；
得到： =  =  = ；
根据模反元素公式，可以得出，· ≡   即· =  为正整数；
假设=，则· = ，且、为正整数，并且与互质，则 = ， = ；
获得公钥和密钥：公钥为  =  ，密钥为  =  ；
假设要传输的数字为，通过公钥加密后为：  = ；
通过密钥解密：  =   = ，即获得结果；

目前大部分  流量是使用 进行密钥交换。
在介绍之前，先来看一下，它其实是使用椭圆曲线加密技术的 密钥交换算法。密钥交换算法，可以让交换双方在不共享任何秘密的情况下协商出一个密钥。则是建立在基于椭圆曲线的离散对数问题上的密码体制，在相同的密钥长度下，其安全性比更高。
而则是的 ，它会为每次握手过程分配一个不同的 ，从而提供前向安全性。实际上，在中允许使用的 必须采用具有前向安全性的密钥交换算法。
五、总结
实际就是在层与层之间加入了来解决安全问题的。
在进行应用数据传输之前，需要通过握手过程来协商安全通信所需的相关参数。
整个通信过程中主要用到散列、对称加密、非对称加密和证书等相关技术，来解决客户端与服务器数据传输中各种安全风险问题，从而达到保证整个通信过程的安全。
六、参考链接



___

相关推荐与前端性能浅析与原理导语

作者介绍：曾楚伟，来自广州的微信事业群，基础平台组高级工程师。

主要分享内容：

设计；
基于的存储案例。



本演讲整理来自“腾讯大讲堂”。引言
此次我们谈论的中间件，针对前端和  的  和  开发而言。对于严格意义上的中间件平台与应用之间的通用服务，例如用于缓解后台高访问量的消息中间件，本篇不会去叙述，因为不是本篇的论述意图。
言归正传，当我们在编写业务代码时候，我们无法避免有些业务逻辑复杂而导致业务代码写得又长又乱，如果再加上时间紧凑情况下写出来的代码估计会更让人抓狂。以至于我们一直在寻求更好的架构设计和更好的代码设计，这是一个没有终点的求知之路，但是在这条路上会越走越好。
 
 意为面向切面编程，是在  的  框架的重点内容，其作用如下图所示：

根据上图，整个响应  过程可以看做是一条串联的管道，对于每个  请求我们都想插入相同的逻辑例如数据过滤、日志统计的目的，为了不和业务逻辑混淆一块，提高代码复用率， 提倡从横向切面思路向管道某个位置插入一段代码逻辑，这样就实现在任何业务逻辑前后都有相同代码逻辑段，开发者只需专注写业务逻辑，既不影响整个响应  过程，而且隔离了业务逻辑，实现高内聚低耦合原则。
可以说  对  进行了一个补充， 是对做同一件事情的业务逻辑封装成一个对象，但是做一件事情过程中又想做别的事情对  来说难以解决。就像上图所示，当系统在响应用户修改信息的请求时，系统在业务处理之前对用户提交的数据做了安全过滤，业务处理之后还要做日志统计。相反如果把所有逻辑都柔合在一起，每次写业务都需重复编写数据过滤和日志统计的代码，违反了单一职责，高内聚低耦合的原则，并且降低代码复用率。
在前端，我们可以借用这种思想通过  和  函数来实现，我们看下代码实现：
 = {函数处理前执行
    = 
    {
     
      
   }
}
 = {函数处理后执行
    = 
    {
      
     
   }
}
实现思路是对被处理的函数通过闭包封装在新的函数里，在新的函数内部按照顺序执行传入的参数和被处理的函数。
举个栗子：
用户提交表单数据之前需要用户行为统计，代码应该是这样写：
 {
   上报数据
}
 {
   提交数据
}
 提交之前执行
结果： 上报数据
      提交数据
从代码可以看出已经把统计和数据提交业务隔离起来，互不影响。
但是如果提交数据之前，需要数据验证并且依据验证结果判断是否能提交，怎么做？这里要改动函数，看下代码：
 = {函数处理后执行
    = 
    {
       = 
     返回成功则执行函数
        
   }
}
 {
   上报数据
    
}
 {
   验证不通过
    
}
 {
   提交数据
}


结果： 
 验证不通过 
 {
   上报数据
    
}
 {
   验证通过
    
}
 {
   提交数据
}


结果： 
 验证通过
 上报数据
 提交数据
思想在前端分解隔离业务已经做到位了，但是却有了一串长长的链式出来，如果处理不当很容易让维护者看晕，例如下面这样：
提交数据前，验证数据，然后上报，在提交之后做返回首页的跳转
 {
   上报数据
    
}
 {
   验证通过
    
}
 {
   提交数据
}
 {
   返回首页
}

结果： 
 验证通过
 上报数据
 提交数据
栗子可能并没有那么晕，但是也得仔细看才能看懂整个流程，实际开发中估计会有更麻烦情况出现，另外，如果  或 的参数  是一个异步操作的话，又需要做些 ，显然还是有些不足的，那么还有没有其他解决办法呢，既能隔离业务，又能方便清爽地使用～我们可以先看看其他框架的中间件解决方案。
  与 的中间件
 和  本身都是非常轻量的框架， 是集合路由和其他几个中间件合成的  开发框架， 是  原班人马重新打造一个更轻量的框架，所以  已经被剥离所有中间件，甚至连  中间件也被抽离出来，任由用户自行添加第三方中间件。 和  中间件原理一样，我们就抽  来讲。
我们先看下中间件写法：
  = 
  = 

   {
  数据统计
  执行权利传递给
}

   {
  日志统计
  
}

    {
   
}


整个请求处理过程就是先数据统计、日志统计，最后返回一个 ！
上图运作流程图如下：

从上图来看，每一个“管道”都是一个中间件，每个中间件通过方法传递执行权给下一个中间件，就是一个收集并调用各种中间件的容器。
中间件就是一个函数，通过  的  方法接收中间件，每个中间件有  传入的  ，  和  参数。如果要把请求传递给下一个中间件必须使用 方法。当调用方法则此次请求结束， 直接返回请求给客户，但是若在方法之后调用  方法，整个中间件链式调用还会往下执行，因为当前   所处的函数也是一块中间件，而  只是一个方法用于返回请求。
 借用中间件
我们可以借用中间件思想来分解我们的前端业务逻辑，通过  方法层层传递给下一个业务。做到这几点首先必须有个管理中间件的对象，我们先创建一个名为  的对象：
 {
    = 
}
通过数组缓存中间件。下面是和方法：

 = {
    == {
         
  }
  
   
}

 = {
       {
      = 
     
  }
}
 = {执行请求
   = {复制
     
  }
  
}
我们用简单使用一下：
  =  
{}
{}
{}
{}

输出结果： 




没有出来是因为上一层中间件没有调用方法，我们升级一下高级使用
  =  
{
  结束
}
{
   结束
}
{
   结束
}
{
   结束
}

输出结果： 



结束
结束
结束
上面代码的流程图：
可以看出：每一个中间件执行权利传递给下一个中间件并等待其结束以后又回到当前并做别的事情，方法非常巧妙，有这特性读者可以玩转中间件。
 实际应用

   验证的数据
   

  {
   验证
  通过验证
}


   发送的数据
   

  {
   {模拟异步
      已发送数据
     
    } 
}
  {
    跳转
}
 和  函数都需要数据参数，目前  只传 ，需要传递  数据才能顺利执行下去，然而每个中间件需要的数据不一定都一致就像  与、。
我们需要引入一个  对象来包裹这一串逻辑需要的数据，每个中间件在  内提取自己所需的数据，这样就能满足所有中间件， 函数做相应调整：
 {
   = 
   = 缓存
}

 = {
    == {
         
  }
  
   
}

 = {

       {
      = 
      传入与
  }
}

   数据的入口
   

 = {
   = {复制
     
  }
   = 缓存数据
  
}
业务逻辑做相应修改：
  {
   
  通过验证
}
  {
   {模拟异步
      
      = 设置跳转的
     
    } 
}
 {
     
}

  =  

{{  }}
结果：
   {   }

   {   }
  


{{  }}触发第二次，改变数据内容

结果：
   {   }

   {   }
  
以上代码大功告成。
 总结
通过以上代码，实现了业务隔离，满足每个业务所需的数据，又能很好控制业务下发执行的权利，所以“中间件”模式算是一种不错的设计。从代码阅读和代码编写的角度来说难度并不大，只要维护人员拥有该方面的知识，问题就不大了。
我的知乎原文：

相关推荐
最佳实践之连接示例如何搭建高质量、高效率的前端工程体系页面结构继承云已经渗透到对我们生活的方方面面，所以，对于云，逃也没用，躲也没用，时代总会来临。果断拥抱，理性选择，踏实落地，即是未来。
导语：云计算是一种模型，它可以实现随时随地、便捷地、随需应变地从可配置计算资源共享池中获取所需的资源例如网络、服务器、存储、应用及服务，资源能够快速供应并释放，使管理资源的工作量和与服务提供商的交互减小到最低限度。
发布版本，看上去就没有不能支持的东西，私有云的春天真的来了吗？红得发紫，与之对应的和持续高温。但是对于不少企业尤其是传统企业，云仍在天边，对于云仍感觉云里雾里。上云还是不上云，上什么云，这是个问题。我们试着用最通俗的比喻，理清云服务中最基本的那些事儿。
什么是云？
历史上已经有不下于一百种的定义，影响力较大的是美国国家标准与技术研究院的定义：云计算是一种模型，它可以实现随时随地、便捷地、随需应变地从可配置计算资源共享池中获取所需的资源例如网络、服务器、存储、应用及服务，资源能够快速供应并释放，使管理资源的工作量和与服务提供商的交互减小到最低限度。显然，对一般的用户来说，这并不好理解，翻译成人话大概是：让计算、存储、网络、数据、算法、应用等软硬件资源像电一样，随时随地、即插即用。这种定义，比较像张三眼中的云，我们称其为广义云计算。
什么是虚拟化和分布式？
虚拟化和分布式在共同解决一个问题，就是物理资源重新配置形成为逻辑资源在领域称为解耦，也就是你用的东西跟实际物理的东西是两码事，一如李四和王五的午饭其实是在张三家解决的。其中虚拟化做的是造一个资源池，而分布式做的是用一个资源池。
虚拟化包括计算虚拟化、网络虚拟化和存储虚拟化。计算虚拟化通常做的是一虚多，即一台物理机虚拟出多台虚拟机，以“榨干”实际的物理资源，其包括全虚拟化、超虚拟化、硬件辅助虚拟化、半虚拟化和操作系统虚拟化。类似于计算虚拟化，网络虚拟化同样解决的是网络资源占用率不高、手动配置安全策略过于麻烦的问题，采用的思路同样是把物理的网络资源抽象成一个资源池，然后动态获取，网络虚拟化目前有控制转发分离、控制面开放、虚拟逻辑网络和网络功能虚拟化等不同的思想路线。存储虚拟化通常做的是多虚一，除了解决弹性、扩展问题外，还解决备份的问题。
公有云、私有云、混合云和社区云是什么东东？
私有云是为某个特定用户机构建立的，只能实现小范围内的资源优化，因此并不完全符合云的本质——社会分工，所以等开源软件带来的私有云繁荣可能只是暂时的，会有越来越多的客户发现廉价的硬件和免费的软件并不是打造私有云的充分条件，精细的管理、×运维所耗去的总成本不比公有云低，而且随着公有云厂商运营能力的进步，这种趋势会越来越明显。托管型私有云在一定程度上实现了社会分工，但是仍无法解决大规模范围内物理资源利用效率的问题。
公有云是为大众建的，所有入驻用户都称租户，不仅同时有很多租户，而且一个租户离开，其资源可以马上释放给下一个租户，一如饭店里一桌顾客走了马上迎来下一桌顾客。公有云是最彻底的社会分工，能够在大范围内实现资源优化，因此，不管道路如何曲折，前途总是光明的。当然公有云尤其是底层公有云构建，不是一般人能玩的了的，就像开个三五桌的饭店谁都能行，开个三五万桌的饭店就要看资金和本事了。很多客户担心公有云的安全问题，敏感行业、大型客户可以考虑，但一般的中小型客户，不管是数据泄露的风险，还是停止服务的风险，公有云都远远小于自己架设机房。
社区云是介于公有、私有之间的一个形式，每个客户自身都不大，但自身又处于敏感行业，上公有云在政策和管理上都有限制和风险，所以就多家联合做一个云平台。
混合云是以上几种的任意混合，这种混合可以是计算的、存储的，也可以两者兼而有之。在公有云尚不完全成熟、而私有云存在运维难、部署实践长、动态扩展难的现阶段，混合云是一种较为理想的平滑过渡方式，短时间内的市场占比将会大幅上升。并且，不混合是相对的，混合是绝对的。在未来，即使不是自家的私有云和公有云做混合，也需要内部的数据与服务与外部的数据与服务进行不断的调用级混合。并且还有可能，一个大型客户把业务放在不同的公有云上，相当于把鸡蛋放在不同篮子里，不同篮子里的鸡蛋自然需要统一管理，这也算广义的混合。

、和又是什么？
，   ，基础设施即服务；，   ，平台即服务；，   ，软件即服务。云计算同样会向着高度分工的方向进化。还有同学问，存储到底算是哪一层呢？这就相当于你觉得能灌溉能和面还能直接喝的水是哪一层呢？自然是出现在不同场景时对应不同层：常说的块存储、对象存储一般是指层，而网盘一般是指层。
提供的一般是通用计算、存储和网络三大基础资源，前面提到的虚拟化、分布式等大多集中在本层，少量“流亡”于层。一般认为，始于亚马逊的和两款产品。近两年，我们说的云计算快速落地，其实主要指的迅速落地，因为原来的公有云确实不稳定，而客户也都在观望。当然，有公司提出自己是“企业级”，这就有点噱头了，试问，哪个不是冲着企业级这一目标去的？给开发者玩儿的吗？
定义比较复杂，早年提供的是部署了数据库和开发环境的平台，被称为：企业名首字母；： ，常用于个人建站，商用程度并不高，在中国尤其如此，后来要么转型要么解体了；后来转为提供某种细分能力，如图像识别、语音识别、推送、通信等，常以或进行交付；近两年风生水起，成为新秀。此时回头看原来的各种定义，都不太恰当了，因此比较准确的描述应是：提供除计算、存储和网络三大基础资源之外的其他能力如通用开发能力，细分能力，业务交付能力，但并不对终端用户提供成熟产品。
涵盖的就广了，邮箱是、网盘是、几乎常见的网站都是！但一般所谓的是指：具有一定复杂度的，通常应该在架构下主要通过端完成的软件服务，在架构下完成了。当然这个复杂度，在不同的时期有不同的定义，十几年前，邮箱可能都算复杂了，而现在随着技术的成熟，大部分的操作都可以在浏览器完成。当然，放企业级市场里，比较好界定，指以云的方式取代了的原来企业软件系统的服务。始于上世纪九十年代末等公司，随着移动互联网和的发展而蓬勃发展，强调的是瘦终端。但是，到底多瘦才算瘦，各种应用不再用而以微信小程序的形式出现算瘦吗？或许，的终极进化是纯“裸机”，也就是“桌面云”，当然这只是一种理想，因为不仅关乎软硬件技术，还关乎用户习惯。须知，到现在还有不少用户喜欢把电影放到移动硬盘里，抽屉里一塞，那感觉，踏实！
最接近于终端用户，是一个巨大的市场。但是，是对软件开发水平和服务水平的综合考验，拼得往往不仅是技术本身，还包括对用户的理解、以及设计水平和创意。如果原来就是卖不出去的软件，没有任何改进包装一下放到云上改为服务也不会有人买单，原来最起码还不用对宕机这种事情负责呢，放云上只是增加了服务商自身的风险。所以，绝不是单机软件到云上的简单迁移，而是自始至终都应贯穿服务的思想和云的思想，比如多屏同步、多人协同等。也所以，我们虽然看好整体市场，但是并不看好很多领域一堆堆的无价值企业，资本寒冬，最先倒下的往往是他们。
云计算有什么价值？
成本更低、运维成本更低、服务更好、弹性扩展、部署更快、不用采购硬件，云计算的好处总能说出一大堆。但，这些点往往只反映云计算的一个侧面，有的还不完全正确：比如成本低，客户会发现，如果租用高性能云主机且保证的可用服务时，成本往往并不比自建机房低，在需要的主机物理机或虚机量比较大时，尤其明显。其实，云计算的本质就是社会分工，社会分工所产生的价值云计算都能产生，比如规模化、精细化所产生的成本降低与效率提高等；而社会分工中产生的问题，云计算也都会面对，比如节省下来的成本到底是买家受益还是卖家受益，再比如垄断。还是拿蒸馒头举例子，在城市中，大多数家庭不自己蒸馒头而去馒头房买，这是社会分工，节省了社会总体成本，但是买馒头并不比自己蒸更便宜，说明节省了的成本进入了卖家而非买家的腰包。再比如，当一个城市只剩一家馒头房而大多数家庭又丧失了蒸馒头的能力时，馒头房便有可能提价，这就是垄断。
理解了云计算是一次社会分工的本质，便不会过分夸大其优点，更不会对之回避认为其只不过是一时风潮。从狩猎到农耕、再到工业社会，从一只羊换两把斧子到贝壳、金属货币、纸币、虚拟货币，从生产方式到价值交换方式，你会发现，人们所做的一切都是在朝着社会分工或促进社会分工的方向发展。

参考：《年中国企业云服务行业报告》艾瑞咨询分析师王巍令大家都能看懂的云计算

人人都是网络工程师
领取元腾讯云新用户专属礼包前言
命令是我们日常工作中比较常用的命令。全面的掌握这个命令可以使很多操作达到事半功倍的效果。如果对命令有以下这些疑惑，本文都能帮你解决：

命令的格式是什么？
参数中出现或号是什么意思？比如   与   什么区别？
   “”   {} \和   “”   {} 有啥区别？
参数为什么要以“\”结尾，而不是只写“”？

命令基础
命令大家都比较熟悉，反倒想讲的有特色比较困难。那干脆我们怎么平淡怎么来好了。我们一般用的命令格式很简单，一般分成三个部分：
   
格式如上，第一段命令。第二段，要搜索的路径。这一段目录可以写多个，如：
     
第三段，表达式。我们例子中用的是 “”这个表达式，指定条件为找到文件名是的文件。对于命令，最需要学习的是表达式这一段。表达式决定了我们要找的文件是什么属性的文件，还可以指定一些“动作”，比如将匹配某种条件的文件删除。所以，命令的核心就是表达式的指定方法。
命令中的表达式有四种类型，分别是：

：就是我们最常用的指定查找文件的条件。
：对找到的文件可以做的操作。
 ：全局属性用来限制一些查找的条件，比如常见的目录层次深度的限制。
 ：位置属性用来指定一些查找的位置条件。

这其中最重要的就是和，他们是命令的核心。另外还有可以将多个表达式连接起来的操作符，他们可以表达多个表达式之间的逻辑关系和运算优先顺序，叫做。
下面我们就来分类看一下这些个分类的功能。

命令是通过文件属性查找文件的。所以，表达式的都是文件的属性条件，比如文件的各种时间，文件权限等。很多参数中会出现指定一个数字，一般会出现三种写法：
：表示大于。
：表示小于。
：表示等于。
根据时间查找
比较常用数字方式来指定的参数是针对时间的查找，比如 ：查找文件修改时间，单位是天，就是小时。举个例子说：
      
我们为了方便看到结果，在这个命令中使用了参数，具体细节后面会详细解释。再此我们只需要知道这个参数可以将符合条件的文件的相关属性显示出来即可。那么我们就可以通过这个命令看到查找到的文件的修改时间了。
      |
                             月    
                              月    
                              月    
                              月    

我们会发现，时间都集中在月号，而今天是：
  
年 月 日 星期三  
实际上，当我们在后面指定的是的时候，实际上是找到了距离现在个小时之前修改过的文件。如果我们在考究一下细节的话，可以使用这个命令再将找到的文件用时间排下顺序：
         {} \
此命令用到了参数，后面会详细说明。我们会发现，找到的文件实际上是集中在月日的到月日的这个范围内的。就是说，实际上，指定天的意思是说，找到文件修改时间范围属于距离当前时间个小时到个小时之间的文件，这是不加任何符号的的含义。如果是 呢？
         {} \
你会发现找到的文件是从现在开始到个小时范围内的文件。但是不包括个小时到个小时的时间范围。那么 也应该好理解了。这就是指定时间的含义。类似的参数还有：
：以天为单位通过 查找文件。
：以天为单位通过 查找文件。
：以分钟为单位通过 查找文件。
：以分钟为单位通过 查找文件。
：以分钟单位通过 查找文件。
这些参数都是指定一个时间数字，数字的意义跟完全一样，只是时间的单位和查找的时间不一样。
除了指定时间以外，还可以通过对比某一个文件的相关时间找到符合条件的文件，比如 。
     
这样可以在目录下找到文件的 比的 更新的所有文件。类似的参数还有：
：比较文件的 。
：比较文件的 。
还有一种特殊用法，可以用来做各种时间之间的比较。比如，我想找到文件修改时间比文件的 更新的文件：
     
这个用法的原型是：   。其中表示的是跟后面的什么时间比较，而表示使用查找文件什么时间进行比较。就是拿文件的 时间跟的 进行比较。和可以使用的字母为：
：文件 。：文件 。：文件 。
在某些支持记录文件的创建时间的文件系统上，可以使用来表示文件创建时间。系列文件系统并不支持记录这个时间。
根据用户查找
 ：文件的所属用户为。
 ：文件的所属用户为。
 ：文件的所属组为。
 ：所属组为的文件。
：没有所属组的文件。
：没有所属用户的文件。
根据权限查找
：文件可执行。
：文件可读。
：文件可写。
 ：查找权限为的文件，的写法可以是数字，也可以是=的方式如：
      
这个写法跟：
     === 
是等效的。
另外要注意，指定的是完全符合这个权限的文件，如：
     == 
                              月    
没描述的权限就相当于指定了没有这个权限。
还可以使用或作为前缀进行描述。如果指定了，就表示没指定的权限是忽略的，就是说，权限中只要包涵相关权限即可。如：
      
这是找到所有只有———权限的文件，而就表示只要是包括了的其他位任意的文件。加前缀表示的是，指定的权限只要某一位复合条件就可以，其他位跟一样忽略，就是说 还可以找到————或者———这样权限的文件。老版本的前缀是用表示的，新版本的意境不支持前加前缀了。
根据路径查找
 ：文件名为指定字符串的文件。注意如果中包括等特殊符号的时候，需要加””。
：的忽略大小写版本。
 ：查找符号连接文件名为的文件。
：的忽略大小写版本。
 ：根据完整路径查找文件名为的文件，如：
     | 






：的忽略大小写版本。
 ：用正则表达式匹配文件名。
：的忽略大小写版本。
其他状态查找
：文件为空而且是一个普通文件或者目录。
 ：指定文件长度查找文件。单位选择位：
：字节单位。
：块为单位，块大小为字节，这个是默认单位。
：以为单位，表示两个字节。
：以字节为单位。
：以字节为单位。
：以字节温单位。
的数字指定也可以使用号作为前缀。意义跟时间类似，表示找到小于指定长度的文件或者大于指定长度的文件。
：根据文件的编号查找。
 ：根据文件连接数查找。
 ：找到跟指定的文件完全一样的文件，就是说两个文件是硬连接关系。
 ：以文件类型查找文件：
可以选择的类型为：
：块设备
：字符设备
：目录
：命名管道
：普通文件
：符号连接
：

表达式中的类型参数主要是用来对找到的文件进行操作的参数。在上面的例子中，我们已经看到可以使用参数对找到的文件进行长格式显示，这就是一个类型的参数。类似的参数还有。
 ：跟功能一样，区别是将信息写入指定的文件，而不是显示在屏幕上。
：将找到的文件显示在屏幕上，实际上默认命令就会将文件打印出来显示。
：参数会将每个文件用换行分割，而这个参数适用分割。有时候在脚本编程时可能会用上。
 ：参数的写入文件版本。将内容写到文件中，而不是显示在屏幕上。
 ：的写入文件版本。
：可以将找到的文件直接删除。
：格式化输出方式打印。如：
        
   
显示文件名，并以空格分隔。代表文件名。其他信息可以参见 。
：如果复合条件的是一个目录，则不进入目录进行查找。例子：
   
   
      





     






我们先创建了一个的目录，然后在这个目录下创建了一个叫的文件。之后先用带的看到，能显示出目录，但是目录中的文件并没有显示，说明这个参数让命令没有进入这个目录查找。而后一个不带参数的显示出了目录下的。
：找到符合条件的文件后立即退出。
中执行命令

命令的是一个非常好用的参数，当然其可能造成的破坏也可能非常大。在学习它之前，我先要提醒大家，使用之前千万要确定自己在做什么。
这个参数的常见格式是：
  
注意后面的分号。它是用来给做标记用的。在解析命令的时候，要区分给定的参数是要传给自己的还是要传给命令的。所以以分号作为要执行命令所有参数的结束标记。命令返回值为则返回。在参数指定的执行命令中，可以使用{}符号表示当前找到的文件名。比如：
        {} \



上面的命令表示，找到目录下文件名为的文件，并其文件名。注意再使用分号的时候前面要加转移字符\，因为分号也是的特殊字符，所以会先解释它。前面加上\就可以让直接将其船体给命令，这个分号由解释，而不是。其实这个用的比较废话，毕竟本身就会找到相关条件的文件并显示其文件名。但是试想如果我们将换成或者，是不是就有意义的多？比如：
        {} \
请不要执行这个命令！！
或者：
        {} {} \
这个命令可以将符合条件的文件都加个后缀备份一份。于是我们可以执行删除了：
      



        {} \
     
当然，删除前还是要确认清楚你要删的文件一定是对的。

和有一些差别，主要是在执行指定的命令时，那个相关命令是在那个工作目录下执行的差别。是在所指定的起始目录，而是文件所在目录。对比一下就明白了：
        {} \



        {} \



一个命令打印出来的路径都是开头，另一个显示的都是当前目录下的某某文件。
的方式要比安全一些，因为这种执行方式避免了在解析文件名时所产生的竞争条件。
出了上述两种比较典型的执行命令的方法以外，还对这两个参数提供了另一种形式的命令执行格式：
  {} 
  {} 
我们还是先用例子来看一下这个格式和以分号结束的方式的差别：
        {} \



        {} \
  
光这样看可能还不是很明显，我们可以这样在描述一遍他们的执行过程：
 
 
 
和
   
其实就是说，对于 {} 格式来说，每找到一个文件就执行一遍相关命令，而 {} 格式的意思是说，先执行，找到所有符合条件的文件之后，将每个文件作为命令的一个参数传给命令执行，指定的命令实际上只被执行了一次。这样用的限制也是不言而喻的：{}只能出现一次。
            {} \
上面这个命令将符合条件的文件全部到了目录中，当然如果文件有重名的情况下，会被覆盖掉。从这个命令中我们学习一下{} 格式的使用注意事项，它不能写成：
        {}  \
所以只能使用参数改变命令的参数顺序来指定相关的动作。
无论如何，直接使用和是很危险的，因为他们会直接对找到的文件调用相关命令，并且没有任何确认。所以我们不得不在进行相关操作前再三确认，以防止误操作。当然，命令也给了更安全的参数，它们就是：


它们的作用跟和一样，区别只是在做任何操作之前，会让用户确认是不是？如：
            {} \
     
于是，每一次你都要确认是不是要这么做。只要你输入的是或者以开头的任何字符串，都是确认。其他的字符串是否认。另外，这两个参数不支持{} 的格式。

的操作符实际上是用来连接多个表达式和确定其逻辑关系用的。如：
       





这个命令中使用了两个表达式，他们之间没有任何分隔，这是实际上表达的含义是，找到两个条件都符合的文件。实际上就是表达式的逻辑与关系，这跟参数连接或者参数一样：
        





        





除了逻辑与关系以外，还有逻辑或关系：
        

        
表示两个条件只要符合其中一个都可以。
在条件表达式前面加表示对表达式取非。同样的也可以用参数。另外如果表达式很多，可以使用  确定优先级，如：
    \      \  \      \
这里表示的是： “”   和 “”   是或关系。
最后
中还可能常用的其他参数比如：
：制定了这个参数后，遇到目录先进入目录操作目录中的文件，最后再操作目录本身。
：目录最大深度限制。
：目录最小深度限制。
还有一些其他相关参数大家可以在 中自行补充，就不在这更多废话了。希望本篇可以对大家深入的掌握命令有所帮助。
如果有相关问题，可以在我的微博、微信或者博客上联系我。

大家好，我是！
如果你喜欢本文，欢迎在微博上搜索“”关注我，地址是：
大家也可以在微信上搜索：系统技术 关注我的公众号。
我的所有文章都会沉淀在我的个人博客上，地址是：。
欢迎使用以上各种方式一起探讨学习，共同进步。个人介绍：腾讯架构平台部平台开发中心基础研发组，组长为专家工程师，专注于为数据中心提供高效的异构加速云解决方案。目前，已在腾讯海量图片处理以及检测领域已规模上线。

接上篇：深入理解  和异构计算芯片  上
 计算能力分析
这里  计算能力用  的  架构进行分析，架构上计算单元有个 ，每个可以对数据在一个时钟周期中做一次乘运算和一次加运算，所以对应单精度浮点计算能力为：    乘和加 =   ，即每个时钟周期可以做个单精度浮点计算。
峰值浮点计算性能 = 核数  频率  每周期执行的浮点操作数。已的型号来计算峰值计算能力为 = 核数  频率     =   即每秒峰值浮点计算能力。
芯片结构是否可以充分发挥浮点计算能力？的指令执行过程是：取指令 指令译码 指令执行，只有在指令执行的时候，计算单元才发挥作用，这样取指令和指令译码的两段时间，计算单元是不在工作的，如图所示。
图：指令执行流程
为了提高指令执行的效率，在当前指令执行过程的时候，预先读取后面几条指令，使得指令流水处理，提高指令执行效率，如图所示。指令预先读取并流水执行的前提是指令之间不具有相关性，不能一个指令的如何执行需要等到前面一个指令执行完的结果才可以获知。
图：指令流水执行 
作为通用处理器，兼顾计算和控制，晶体管用来构建 还有一部分控制单元，用来处理复杂逻辑和提高指令的执行效率，如图所示，所以导致计算通用性强，可以处理计算复杂度高，但计算性能一般。
图：结构
通过计算性能分析，直接提高计算性能方向为：增加核数、提高频率、修改架构增加计算单元 个数。这个方向中，直接增加核数对于计算能力提升最高，但是带来芯片功耗和价格的增加，因为每个物理核中只有的晶体管是计算单元。提高频率，提升的空间有限，而且频率太高会导致芯片出现功耗过大和过热的问题，因此英特尔等芯片制造商目前走多核化的路线，即限制单个微处理器的主频，通过集成多个处理器内核来提高处理性能。修改架构增加计算单元个数，目前英特尔按照“”二年一个周期进行架构调整，从年开始放缓至三年，更新迭代周期较长。
 计算能力分析
主要擅长做类似图像处理的并行计算，所谓的“粗粒度并行 ”。图形处理计算的特征表现为高密度的计算而计算需要的数据之间较少存在相关性， 提供大量的计算单元多达几千个计算单元和大量的高速内存，可以同时对很多像素进行并行处理。
图是的设计结构。的设计出发点在于更适用于计算强度高、多并行的计算。因此，把晶体管更多用于计算单元，而不像用于数据和流程控制器。这样的设计是因为并行计算时每个数据单元执行相同程序，不需要繁琐的流程控制而更需要高计算能力，因此也不需要大的容量。
图：结构
中一个逻辑控制单元对应多个计算单元，同时要想计算单元充分并行起来，逻辑控制必然不会太复杂，太复杂的逻辑控制无法发挥计算单元的并行度，例如过多的… … … 分支计算就无法提高计算单元的并行度，所以在中逻辑控制单元也就不需要能够快速处理复杂控制。
这里计算能力用的 进行分析，包含个流处理器 ，流处理器就是的计算单元。每个流处理器包含一个单精度浮点乘和加单元，即每个时钟周期可以做个单精度浮点计算。峰值浮点计算性能 = 流处理器个数  频率  每周期执行的浮点操作数。以为例，峰值浮点计算性能= 流处理器    乘和加 =  即每秒峰值浮点计算能力。
芯片结构是否可以充分发挥浮点计算能力？同一样也是指令执行过程：取指令 指令译码 指令执行，只有在指令执行的时候，计算单元才发挥作用。的逻辑控制单元相比简单，所以要想做到指令流水处理，提高指令执行效率，必然要求处理的算法本身复杂度低，处理的数据之间相互独立，所以算法本身的串行处理会导致浮点计算能力的显著降低。
 计算能力分析
作为一种高性能、低功耗的可编程芯片，可以根据客户定制来做针对性的算法设计。所以在处理海量数据的时候， 相比于 和，优势在于：计算效率更高，更接近。
不采用指令和软件，是软硬件合一的器件。对进行编程要使用硬件描述语言，硬件描述语言描述的逻辑可以直接被编译为晶体管电路的组合。所以实际上直接用晶体管电路实现用户的算法，没有通过指令系统的翻译。
的英文缩写名翻译过来，全称是现场可编程逻辑门阵列，这个名称已经揭示了的功能，它就是一堆逻辑门电路的组合，可以编程，还可以重复编程。图展示了可编程的内部原理图。
图：内部结构图
这里计算能力用的进行分析，包含个  ，就是的计算单元。每个可以在每个时钟周期可以做个单精度浮点计算乘和加。峰值浮点计算性能 = 个数  频率  每周期执行的浮点操作数。运行频率已来计算，峰值浮点计算性能 = 个数    乘和加= 即每秒峰值浮点计算能力。
芯片结构是否可以充分发挥浮点计算能力？由于算法是定制的，所以没有和的取指令和指令译码过程，数据流直接根据定制的算法进行固定操作，计算单元在每个时钟周期上都可以执行，所以可以充分发挥浮点计算能力，计算效率高于和。
 计算能力分析
是一种专用芯片，与传统的通用芯片有一定的差异。是为了某种特定的需求而专门定制的芯片。芯片的计算能力和计算效率都可以根据算法需要进行定制，所以与通用芯片相比，具有以下几个方面的优越性：体积小、功耗低、计算性能高、计算效率高、芯片出货量越大成本越低。但是缺点也很明显：算法是固定的，一旦算法变化就可能无法使用。目前人工智能属于大爆发时期，大量的算法不断涌出，远没有到算法平稳期，专用芯片如何做到适应各种算法是个最大的问题，如果以目前和架构来适应各种算法，那专用芯片就变成了同、一样的通用芯片，在性能和功耗上就没有优势了。
我们来看看 和  的区别。基本原理是在芯片内集成大量的数字电路基本门电路以及存储器，而用户可以通过烧入  配置文件来来定义这些门电路以及存储器之间的连线。这种烧入不是一次性的，即用户今天可以把  配置成一个微控制器 ，明天可以编辑配置文件把同一个  配置成一个音频编解码器。 则是专用集成电路，一旦设计制造完成后电路就固定了，无法再改变。
比较  和  就像比较乐高积木和模型。举例来说，如果你发现最近星球大战里面  大师很火，想要做一个  大师的玩具卖，你要怎么办呢？
有两种办法，一种是用乐高积木搭，还有一种是找工厂开模定制。用乐高积木搭的话，只要设计完玩具外形后去买一套乐高积木即可。而找工厂开模的话在设计完玩具外形外你还需要做很多事情，比如玩具的材质是否会散发气味，玩具在高温下是否会融化等等，所以用乐高积木来做玩具需要的前期工作比起找工厂开模制作来说要少得多，从设计完成到能够上市所需要的时间用乐高也要快很多。
 和  也是一样，使用  只要写完  代码就可以用  厂商提供的工具实现硬件加速器了，而要设计  则还需要做很多验证和物理设计 ， 等等，需要更多的时间。如果要针对特殊场合如军事和工业等对于可靠性要求很高的应用， 则需要更多时间进行特别设计以满足需求，但是用  的话可以直接买军工级的高稳定性  完全不影响开发时间。但是，虽然设计时间比较短，但是乐高积木做出来的玩具比起工厂定制的玩具要粗糙性能差一些下图，毕竟工厂开模是量身定制。

另外，如果出货量大的话，工厂大规模生产玩具的成本会比用乐高积木做便宜许多。 和  也是如此，在同一时间点上用最好的工艺实现的  的加速器的速度会比用同样工艺  做的加速器速度快  倍，而且一旦量产后  的成本会远远低于  方案。
 上市速度快  上市速度慢，需要大量时间开发，而且一次性成本光刻掩模制作成本远高于 ，但是性能高于  且量产后平均成本低于 。目标市场方面， 成本较高，所以适合对价格不是很敏感的地方，比如企业应用，军事和工业电子等等在这些领域可重配置真的需要。而  由于低成本则适合消费电子类应用，而且在消费电子中可配置是否是一个伪需求还有待商榷。
我们看到的市场现状也是如此：使用  做深度学习加速的多是企业用户，百度、微软、 等公司都有专门做  的团队为服务器加速，而做  方案的初创公司  的目标市场也是服务器。而  则主要瞄准消费电子，如 。由于移动终端属于消费电子领域，所以未来使用的方案应当是以  为主。

平台性能和功耗比较
由于不同的芯片生产工艺，对芯片的功耗和性能都有影响，这里用相同工艺或者接近工艺下进行对比，芯片还没有商用的芯片出现，的也只是自己使用没有对外提供信息，这里芯片用在学术论文发表的《       》作为代表。

从上面的对比来看，能耗比方面：      ，产生这样结果的根本原因：对于计算密集型算法，数据的搬移和运算效率越高的能耗比就越高。和都是更接近底层，所以计算效率高和数据搬移高，但是有冗余晶体管和连线，运行频率低，所以没有能耗比高。和都是属于通用处理器，都需要进行取指令、指令译码、指令执行的过程，通过这种方式屏蔽了底层的处理，使得软硬件解耦，但带来数据的搬移和运算无法达到更高效率，所以没有、能耗比高。和之间的能耗比的差距，主要在于中晶体管有大部分用在和控制逻辑单元，所以相比来说，对于计算密集同时计算复杂度低的算法，有冗余的晶体管无法发挥作用，能耗比上低于。
 总结与展望
处理器芯片各自长期发展的过程中，形成了一些使用和市场上鲜明的特点。领域存在大量的开源软件和应用软件，任何新的技术首先会用实现算法，因此编程的资源丰富而且容易获得，开发成本低而开发周期。的实现采用等底层硬件描述语言实现，需要开发者对的芯片特性有较为深入的了解，但其高并行性的特性往往可以使业务性能得到量级的提升；同时是动态可重配的，当在数据中心部署之后，可以根据业务形态来配置不同的逻辑实现不同的硬件加速功能；举例来讲，当前服务器上的板卡部署的是图片压缩逻辑，服务于业务；而此时广告实时预估需要扩容获得更多的计算资源，通过简单的重配流程，板卡即可以变身成“新”硬件来服务广告实时预估，非常适合批量部署。芯片可以获得最优的性能，即面积利用率高、速度快、功耗低；但是开发风险极大，需要有足够大的市场来保证成本价格，而且从研发到市场的时间周期很长，不适合例如深度学习等算法正在快速迭代的领域。
讲了这么多，当遇到业务瓶颈的需要异构计算芯片的时候，你是否能够根据业务特性和芯片特性选择出合适的芯片呢？
分析完各类芯片特性，接下来，重点来了！
 
当今的有很大的性能潜力，支持深度可变的流水线结构，提供大量的并行计算资源，一个时钟周期内就可以完成非常复杂的功能。的可编程能力保证了这种器件能够满足应用软件的特殊需求，不存在设计定制协处理器的成本或者延迟问题。是重新可编程的，它可以在一个芯片中为多种应用提供非常灵活的定制协处理功能。拥有了，业务就拥有无限可能。同样的半导体技术，既能把处理器的性能发挥到极限，也能使从简单的胶合逻辑控制器，发展到性能很高的可编程架构。完全能够满足市场的“”需求。
的内置存储器也有很大的性能优势。例如，片内存储器意味着协处理器逻辑的存储器访问带宽不会受到器件引脚数量的限制。而且，存储器和运算逻辑紧密结合，不再需要采用外部高速存储器缓冲。这样，也避免了大功耗的缓冲访问和一致性问题。使用内部存储器还意味着协处理器不需要其他的引脚来提高其可访问存储器容量，从而简化了设计。
很多人由于的开发难度大以及开发周期较长而对其持有怀疑态度，好消息是以及语言越来越完善，很多应用直接使用这两种高级语言就可以取得较大性能提升。
业界成功案例

为了更好地满足对计算性能的要求，全球的很多大型企业都在的加速硬件上进行了布局和实践。

决定以亿美元收购生产商。预计到年，以上的服务器芯片将配备一个协处理器。
：
和联合宣布开展一项多年战略协作，在 系统上运用 加速工作负载处理技术，以打造更高性能、更高能效的数据中心应用。
微软：
早在年，就将 运用在其搜索的业务中，使的搜索处理量提升了一倍，搜索时间缩短了。年，微软进一步将运用于深度学习领域。年，微软体系结构顶级会议上发表的《   》显示了其在数据中心体系架构上的勃勃野心。现在，进入微软数据中心的每一个服务器上均带有一块板卡，其基本的架构如下：

论文中涉及到的应用场景包括：
网络加速例如网络数据包加解密
本地应用加速加速、延时敏感性业务加速
支持之间通信，计算资源池化，提供的概念，将和服务器解耦。
：
年，也宣称要同合作用平台进行数据中心的建设。
百度：
国内百度也推出了版本的百度大脑，运用到线上服务；版百度大脑已运用于包括语音识别、广告点击率预估模型、序列检测以及无人车等业务中。据了解，应用了该版本百度大脑后，语音在线服务、广告点击率预估模型等的计算性能皆提升了倍。

相关推荐认识多种处理芯片的特性和实战上篇认识多种处理芯片的特性和实战下篇精细化容量管理的设备成本优化之路浏览器中打开 登录腾讯云，用微信 号注册一个腾讯云账户。在导航栏中选择云产品计算服务器，或者输入 进入云主机的选购页面。选择“包年包月”，可用区选“广州二区”。下一步，选择镜像，根据你的常用服务器类型选择 或者 【敲重点】公网带宽选择这里记得选【按使用流量】，不要选【按带宽计费】，否则元代金券不够买一台云主机。输入自定义的密码或者选择“自动生成密码”，之后到腾讯云的站内信去查收密码。核对信息这一步勾选【兑换代金券】，输入腾讯云开发者运营提供的代金券兑换码验证码，即可获得一张元的代金券。或者如果是发放到你的号的方式，你可以直接勾选【使用代金券】。完成支付后，稍等几分钟，你就会收到一台生成的腾讯云主机啦。
相关阅读：云服务器官方文档 如何在腾讯云快速构建一个个人站点微信个人订阅号后台搭建入门教程在分布式环境当中，总是会遇到诸如 主机宕机 或 网络故障 等各种影响系统可用性的情况发生。轻则会导致投诉，重则导致企业核心数据的丢失，影响企业业绩和商誉。而如何确保分布式系统运行正常，应对各种故障场景，保证系统始终处于高可用状态是每个企业研究的方向之一。
腾讯云数据库技术专家，赵海明在  中国技术大会上，以 腾讯分布式数据库  的可靠性系统为例，为大家分享了保障分布式系统可靠性的一些基本思路。
，腾讯自研全功能分布式关系数据库
 是腾讯在开源的分布式数据库简称基础上，研发的一款全功能分布式关系数据库系统，相较于， 通过在内核中创造性的引入  的概念，提出双  分布策略，有效的解决了数据倾斜的问题；同时，根据数据的时间戳，将数据分为冷数据和热数据，分别存储与不同的存储设备中，有效的解决了存储成本的问题。本文主要以举例，自上而下向读者深度剖析保障 可靠性的两大系统：灾备系统 和 冷备系统 。图   架构
分布式系统容灾中的“脑裂”情况
分布式系统，通常是由若干台物理服务器通过网络搭建而成的，与单机系统不同的是，分布式系统通常由多台设备组成。主机物理服务器宕机 或者 网络故障 是大概率事件，而 脑裂 场景则是分布式系统中的常见问题如下图。
图   灾备系统——脑裂故障场景
当系统出现节点异常后，为避免脑裂，我们通常需要一个全局的调度集群，出现故障时，通过全局调度集群锁住原节点，并通过内部选举，提升某最优节点为。到原有故障恢复后，在将其降级为重新加入集群，使得系统仍然是一主两备，保障系统始终处于一个高可用的状态。图   灾备系统——灾备目标
深入到分布式系统调度内部过程，又需要去解决孤岛检测和角色校验两个问题。

孤岛检测： 解决由于   网络故障恢复后，导致   脑裂的问题。
角色校验： 解决由于   主机宕机重启后，导致   脑裂的问题。

图   灾备方案——  故障
 分布式系统的某一主机网络故障时，某一个节点就行是没有通讯的孤岛，因此孤岛检测很形象的比喻这种脑裂场景。因此分布式系统通常将孤岛检测拆分为以下几个步骤检测孤岛：分布式系统通过部署于每个节点的，向集群所有主机发送网络心跳，实时检测连通性。若无法连通，意味着自己成为网络孤岛。杀死实例： 发现自己成为网络孤岛后，会主动发起请求杀死本机所有实例。容灾切换： 监听到集群   异常或无法连通时，主动容灾切换，以恢复数据库服务。由于原 已被杀死，整个系统只有新   提供读写服务，因此系统没有   脑裂。恢复主备：孤岛主机网络恢复后，正常连通后，会向该主机上的  发起做备指令，让原   降级成为一个全新的  ，以恢复系统一主两备的高可用模式。通过  的 孤岛检测 机制， 在任意   网络故障情况下，都能保证系统一直处于高可用的状态。图  灾备方案——孤岛检测当发生 主机宕机 后，分布式系统就需要 通过 角色校验 机制来解决系统 的脑裂问题，如下图所示，仍然以举例：宕机切换：当   所在主机发生宕机后，发起状态仲裁，生成容灾指令，对该主机上的   执行容灾切换，容灾切换后， 系统中的每组  节点都只有唯一的一个   对外提供读写服务。角色校验：当故障主机宕机重启后， 和  会通过心跳包对  所监控的节点执行一次 主备角色校验。由于宕机后， 对故障主机上的原   执行了容灾切换，因此  认为该主机上的该  节点角色为  ，但是在容灾切换的过程中，由于原   主机因为宕机，无法接收容灾指令，因此宕机重启后，该主机上的  认为该  节点角色仍然为  ，此时  和  发生角色校验失败，杀死实例：角色校验失败后， 会杀死本机所有  节点，以防止主机宕机重启后，原   和新   并存而出现系统脑裂。恢复主备：在  由于角色校验失败将  杀死后， 会向原   所在的  发起做备指令，将原   降级成为新的  ，以恢复系统一主两备的高可用模式。通过  和  的 角色校验 机制， 在任意  主机宕机重启的情况下，也能保证系统一直处于高可用的状态。
图   灾备方案——角色校验
两地三中心容灾方案
解决了脑裂问题后，面向分布式系统的另外一个问题是出现机房级故障怎么办？ 目前应用于微信支付系统，因此的在设计时就考虑了两地三中心的架构如下图所示。简单来说，通过让数据 节点实现，同城节点强同步，异地节点异步同步的节点部署架构实现高可用。同时，让每台主机部署，负责采集各个节点运行状态，上报给所有 ，同时负责执行  下发的各种操作指令。负责状态汇总，并将状态信息写入  集群；单监听各个节点的运行状态，异常时发起仲裁流程，根据仲裁结果，发起容灾切换流程。当然，也支持接收外部用户操作指令，生成分布式指令计划，下发给  执行，并监控  的执行状态；图  灾备方案——两地三中心
分布式系统容灾中的调度节点容灾问题
前文阐述了通过 脑裂，两地三中心方案， 为了解决分布式系统中的节点故障的问题，系统引入了两个组件 、，作为调度模块。而如果在运行过程中，、 本身也会出现主机宕机、网络故障等异常场景呢？我们梳理了分布式的调度系统中常见的故障：故障一： 宕机：在执行容灾过程当中， 主机发生宕机，导致容灾流程中途失败？故障二：状态误判： 系统本身运行正常，但由于  和  之间的网络故障， 对  所监控的  状态发生误判，导致  在  系统正常运行的情况下，发出错误的容灾倒换指令？故障三：指令超时： 向  发送的指令都是通过网络包进行发送，会出现指令丢失或者指令超时？故障四：指令乱序： 在执行指令的过程中，会向  反馈自身的执行状态，由于各种原因，当  回复的指令出现了乱序怎么办？
针对上述故障场景， 容灾系统提出了如下解决方案：

任务接管：引入主备 ，用于解决  在容灾流程中发生宕机或者网络故障等问题。
状态仲裁：引入  集群，保证所有节点状态的一致性，避免  状态误判，发起误容灾。
超时重试：通过超时重试机制，解决 、 网络通信过程中，出现的网络超时的问题。
指令 ：对每条指令分配全局唯一  号进行编码，解决 、 网络通信过程中，出现指令乱序的问题。

图   灾备方案——、 故障
通过 状态仲裁 和 任务接管 解决误容灾和  容灾过程中发生宕机的问题，如下图图所示，分布式系统可以做如下操作：节点异常：当  节点异常后， 采集节点状态信息，将异常状态上报给所有 。状态仲裁：当   收到节点状态异常后，不会立即发起容灾流程，而是向所有   发起状态仲裁请求。状态获取：  收到状态请求后，向  拉取节点状态，并回复给  。启动容灾：当超过多半   认定该节点异常后，  发起容灾流程。执行容灾：  生成容灾指令计划，并向各个  发起容灾指令，并监听  的指令执行状态，同时将容灾日志持久化到配置库。 宕机：在容灾过程中，如果   发生宕机， 会发起选主流程，从   中选择一个新的  。任务接管：新的   选定后，会从配置库中拉取容灾日志，重新生成容灾指令计划，继续向  发送容灾指令，完成剩余容灾流程。 重启：原   宕机重启后，从  获取自身角色，发现已经被降级成 ，不再恢复容灾流程，自动转换成新的   运行，保证系统不会出现  脑裂。通过 状态仲裁 保证 状态的一致性，避免因对状态的误判，发起误容灾；通过 任务接管 确保在  宕机 等故障场景下，容灾仍然能够继续执行；通过  选主，保证系统在任何时刻都只能够存在唯一的一个  ，避免出现  脑裂。

图   灾备方案——状态仲裁  任务接管
引入 超时重试 和 指令  解决 、 网络消息超时和消息乱序的问题，如上图所示，具体流程如下：超时重试： 发送指令给  后，会监听指令的执行状态，超过一定时间没有收到  的回复，执行指令重试。指令 ： 在下发每一条指令的时候，会对指令进行编码，赋予一个全局递增的唯一  号，一起下发给 ， 在回复  执行状态时，必须将原来的指令  一起回复给 。 递增：当  收到  回复后，根据需要选择继续监听，还是下发下一个指令，如果下发下一个指令， 首先将指令  递增，然后再下发指令。消息过滤：递增 ，一方面表示 ， 更新了本身的任务状态，另一方面表示，针对  回复的消息，如果  小于 当前的  号，则  不予处理，直接过滤即可。通过 超时重试 确保在网络抖动等异常情况下， 仍然能够正常发送指令计划；通过 指令  确保  能够时时更新自身的任务状态，忽略  反馈的过期消息，防止由于网络问题导致  回复的消息出现指令乱序。图   灾备方案——超时重试  指令 
分布式系统的冷备系统
当然，还有一种极少见但仍然会存在的异常情况，即整个数据库集群彻底故障。此时，为了进一步保障分布式系统的数据可靠性，建议在现有高可用容灾的基础上，仍然部署冷备系统。而 基于特性开发了自动冷备系统，在  运行过程中，定期将存量数据和增量数据备份到 。这样，在诸如磁盘不可修复损坏等极端场景下，  仍然能够执行数据恢复。而为了提升冷备效率，同时降低冷备对业务资源的占用， 的将冷备流程下放到数据节点的备机执行，同时对冷备的上传机制进行了优化，实现  的冷备和增备不落盘透写 ，以减少本地磁盘 压力，同时还能做到对网络资源灵活控制，进一步降低系统负载。
图   冷备系统
最后再说一句
目前， 已经支持在专有云私有化中部署，且很好的兼容协议，解决了存储成本、数据倾斜、在线扩容、分布式事务、跨节点等敏感问题，目前已经在微信支付、电子政务大厅、公安等系统上稳定运行。源码为   版本， 上对应的   为 本文将对  的调度算法原理和执行过程进行分析，重点介绍  算法中预选和优选的相关内容。
 的基本功能
  的作用是根据特定的调度算法将调度到指定的工作节点上，这一过程也叫绑定。 的输入为需要调度的  和可以被调度的节点的信息，输出为调度算法选择的 ，并将该   到这个  。

 中调度算法分为两个阶段：预选  根据配置的  默认为  中定义的    集合过滤掉那些不满足的的，剩下的作为优选的输入。
优选  根据配置的  默认为  中定义的    集合给预选后的进行打分排名，得分最高的即作为最适合的，该就到这个。

预选规则详细说明
预先规则主要用于过滤出不符合规则的节点，剩下的节点作为优选的输入。在版本中预选规则包括：

详细的规则说明：
   检查在此主机上是否存在卷冲突。如果这个主机已经挂载了卷，其它使用这个卷的不能调度到这个主机上。 、  和   使用的规则如下 

 允许同时挂载多个卷，只要这些卷都是只读的。
  不允许不同的  挂载同一个卷。
  不允许任何两个  分享相同的 ，  和 。注： 与  一样，在卷都是只读的情况下，允许挂载两个  相同的卷。

   检查在给定的  限制前提下，检查在此主机上部署  是否存在卷冲突，目前指对  资源进行检查对象函数。
   确保已挂载的  存储卷不超过设置的最大值。默认值是。它会检查直接使用的存储卷，和间接使用这种类型存储的  。计算不同卷的总目，如果新的  部署上去后卷的数目会超过设置的最大值，那么  就不能调度到这个主机上。
   确保已挂载的  存储卷不超过设置的最大值。默认值是。规则同。
   确保已挂载的存储卷不超过设置的最大值。默认值是。规则同。
   判断节点是否已经进入到内存压力状态，如果是则只允许调度内存为标记的 。
    判断节点是否已经进入到磁盘压力状态，如果是则不调度新的。
     是否满足节点容忍的一些条件。
     节点亲和性筛选。
     包含一些基本的筛选规则、、、。
   检查节点上的空闲资源、、资源是否满足  的需求。
    检查  内每一个容器所需的  是否已被其它容器占用。如果有所需的不满足要求，那么  不能调度到这个主机上。
 检查主机名称是不是  指定的 。
 检查主机的标签是否满足  的  属性需求。
优选规则详细说明
优选规则对符合需求的主机列表进行打分，最终选择一个分值最高的主机部署 。 用一组优先级函数处理每一个待选的主机。每一个优先级函数会返回一个的分数，分数越高表示主机越“好”，同时每一个函数也会对应一个表示权重的值。最终主机的得分用以下公式计算得出：
 =         …    

详细的规则说明：   对于属于同一个 、  的 ，尽量分散在不同的主机上。如果指定了区域，则会尽量把  分散在不同区域的不同主机上。调度一个  的时候，先查找  对于的 或者  ，然后查找  或   中已存在的 ，主机上运行的已存在的  越少，主机的打分越高。
    如果新的  要分配一个节点，这个节点的优先级就由节点空闲的那部分与总容量的比值总容量节点上的容量总和新的容量总容量来决定。 和  权重相当，比值最大的节点的得分最高。需要注意的是，这个优先级函数起到了按照资源消耗来跨节点分配  的作用。计算公式如下： –        –       
    尽量选择在部署  后各项资源更均衡的机器。 不能单独使用，而且必须和  同时使用，它分别计算主机上的  和  的比重，主机的分值由  比重和  比重的“距离”决定。计算公式如下： =  – 
      调度中的亲和性机制。 调度时将  限定在指定节点上，支持多种操作符、 、 、、 、 ，而不限于对节点  的精确匹配。另外， 支持两种类型的选择器，一种是 “ ” 选择器，它保证所选的主机满足所有对主机的规则要求。这种选择器更像是之前的 ，在  的基础上增加了更合适的表现语法。另一种 “ ” 选择器，它作为对调度器的提示，调度器会尽量但不保证满足  的所有要求。
    通过迭代  的元素计算和，并且如果对该节点满足相应的，则将 “” 加到和中，具有最高和的节点是最优选的。
  权重  如果  的  没有设置    = ，则该  对该  的得分就是分，加上权重，那么该对该的得分至少分。如果的设置了， =  ，如果该  对应的  是  或 ，则该  对该  的得分就是分。
   使用  中  与  节点  进行匹配，配对成功的项越多，则得分越低。
另外在优选的调度规则中，有几个未被默认使用的规则：
   据主机上是否已具备  运行的环境来打分。 会判断主机上是否已存在  运行所需的镜像，根据已有镜像的大小返回一个的打分。如果主机上不存在  所需的镜像，返回；如果主机上存在部分所需镜像，则根据这些镜像的大小来决定分值，镜像越大，打分就越高。
    是一个优先级函数，它给予所有节点一个相等的权重。
   作用与  相同，已经被  替换。
   在  中，替换 ，给使用多资源的节点，更高的优先级。计算公式为：            以下简称是的四大组件之一，提供类似数据库增删查改的数据操作方式，同时还支持跨进程。在跨进程调用的场景中，作为数据提供的进程称作进程，请求数据的进程称作进程。当我们享受它在跨进程场景下带来的便利时，可能未曾想到进程存在被杀的隐患。
一、日志分析
               
               
                     
这是进程被以下简称杀死的行关键日志：

第一行，的进程没有启动，所以会先启动它；
第二行，进程启动后，某些原因实际场景可能是死掉了；
第三行，因为的进程死了，所以杀死了的进程。

那么是什么样的工作原理，使得无辜的进程会被杀死呢？这需要结合源代码进行分析。
二、清理已死进程的
首先，我们深入到源码下文基于版本，从” ”的日志来看对于已经死亡的进程会做什么善后工作。
       
          {
              
      ==    =  
             ==  {
          =  == 
          = 
          {
                   
                      
                       
             = 
        }  {
                           
                
             = 
             = 
        }
        __   
         _ _
                            
          
          {
            
        }
          {
            
        }
    }    =  {
               
                  
                           
        __   
    }   _ {
        _       
                 
    }
}
在的方法中，找到了” ”日志的打印输出。然后，代码会运行到方法。
    
            {
      = 
      =    
}

    
              {
              
       {
         = 
    }
}

     {
               
                 
                 
      
      = 
       =     =   {
          = 
          ==  {
                  {
                 = 
            }  {
                  
            }
        }
    }
     
}

    
            {
       =     =   {
          = 
          {
                       
                       
                      
                {
                
            }
        }
                 
          = 
         = 
                 
            {
                = 
                      = 
                      = _ {

                        
                   
                         
                                =     
                              =        
            }
        }    =    =  {
        }
    }
}
经过一层一层的方法调用链条：      ，终于找到了进程被杀死了的地方，并且打印输出的日志也完全吻合。
不过，即使在最终的  方法里面，要走到杀死进程的代码，也是要经过一层层的条件判断。其中最关键的是，  。那么，以下简称的什么时候增，什么时候减？
三、的计数增加
的增加在的方法。在中，方法调用链是    ：
  
               {
      =  {
          =   {
              = 
              ==  {
                  {
                        
                    
                    
                }
            }
        }
          =   
          {
                               
             = 
             = 
        }
        
        
    }
}

   
                {
     {
          =  =    =   
          {
             =    
        }

          {
             =    
        }
          
    }
}


   
                {
         
}
方法会在以下简称里面被调用到。
   
                {
     {
         = 
                   
    }    {
         
    }
     
}
方法会在里面被调用。
       {
       
       

     
                  {
        
         = 
         = 
    }

    
          {
         
                
                 
    }
}

    
               
              {
          
     =    
}


   {
     
}
正是应用开发经常打交道的的实现类。在它的构造方法中，会实例化一个，用于方法调用的时候返回，而这个方法是我们使用的时候，一定会用到的。
的类型是以下简称，它是以下简称的实现类。在实现的方法，直接返回的是。方法在方法中会被调用：
     {
     _ {
         
    }
       = 
      =  {
                  
          
    }
     
}
的每一个增删查改的方法里面，方法和方法都是成对出现的。
       
               {
      = 
     {
    }    {
    }  {
        
    }
}

         
           {
      = 
     {
    }    {
    }  {
        
    }
}

        
             
             
           {
     {
         {
             =   
                       
        }    {
             = 
        }
    }    {
               
               
         
    }  {
          =  {
            
        }
    }
}
四、的计数减少
方法的调用很有可能会使得的计数减少，下面我们要继续追踪代码来作证明。方法是直接调用了方法。
       {
    
        {
          
    }
}
果然，在方法里面，被减了。
       {
      {
          {
             = 
        }
    }
}
至此，我们已经了解，杀死的进程的工作原理：的方法调用过程中，进程死了，那么在清理进程的时候，对于  的的进程会被掉。
五、另一种杀死进程的场景
方法里，如果发现的进程未启动，会调用启动进程。然后调用方法，增加的计数。当进程启动，会调用方法。我们主要关注它里面个逻辑：

发送一个延迟秒的____的消息给；
调用；


   
                {
     {
          =  =    =   
          {
                       
             
              =  {
                 {
                      = 
                              
                      =    =    {
                    }  {
                         = 
                                    
                                 
                                           
                    }
                }
            }
             
             =    
        }
    }
}

    
          {
      =    {
          = ____
         = 
         ___
    }
     {
          =  ==   
                     
           
                  
                 
                 
                 ||  
                  
                
                
    }
}
____消息的处理，会调用  。后者这个方法，前文介绍过了，当判断  ，会杀死进程。
     {
       {
          
    }

    
        {
          {
         ____ {
              = 
              {
                
            }
        } 
        }
    }
}

     {
     
          
}
只有秒钟的倒计时，我们看看如何救赎。方法会发送一个_的消息个。
     {
          
               
               
             
               
               
                 
                   {
        _ 
    }
}
的处理消息，会调用方法。

             _
                
                
  ，后者方法里面，有处我们需要关注的：

调用了；
它调用了方法；

    {
     {
          {
              {
                 
            }
        }
    }
}

  
            {
               =
         

         {
          =   
                     
          =  {
             = 
            
        }
    }

     {
        
             
    }    {
         
    }
}

   
           
              {
      = 
     
      ==  ||  ==  {
         {
                
             
        }
    }
}
我们看方法，会调用到方法，这是一个抽象方法。当我们自定义实现的时候，需要实现这个方法。
      {
      
}

        {
     = 

    
                  
            
     
      ==  {
        
    }
}

   
在方法，终于找到了拆解定时炸弹的钥匙。____被了！
    
          {
      {
           = 
           =      {
              =  {
                  {
                ____ 
                }
            }
        }
    }
}
所以，留了秒钟，给的进程启动和做准备工作其中包括了，否则进程避免不了被杀的命运。
六、总结
我们选择作为跨进程通信的方案时，要把进程被杀死的情况考虑在内，因为这看似不可完全避免。
七、参考
理解原理 引用计数 __
八、源码
导语：最近特别火的狼人杀和最近特别火的   会擦出什么样的火花呢？本文和您一同探讨  性能优化的现实场景。

项目简介

狼人杀游戏是多人实时性游戏，对流畅度等性能都有要求。作为大型游戏，无论从代码规模和迭代速度来看，手  的安装包和版本迭代速度都无法用  来承载这样的游戏。从而   成为了比较好的选择。
手    简介
在手  目前使用的   版本是  版本。下面的数据分析都是基于手  版本进行的分析数据。
问题分析

开发过   的同学，大体都对白屏界面有所了解。作为  原生自带功能，基本上每个使用  的业务都在优化这一阶段。通过对狼人杀的测试来看，首次从  启动到渲染，耗时基本有  左右。而这些耗时数据还是在  中测试得出，可想低端局的情况可能会更加糟糕。
分析性能

工欲善其事必先利其器，要分析其耗时。还得从源头着手，根据常规做法，都会将   打包的  拆分成   和业务 。从上图，  加载流程来看，加载  与业务  的耗时是可以有优化空间的。

优化的方案和大多数人的思路一样，只需在业务启动前预加载  与业务  即可达到优化时间的效果。
目前所遇到的瓶颈


在优化的开始，我们可能一直把精力放在  中，认为  是  的公共库，体积肯定不小。但是从数据来看，我们的狼人杀业务  已经是 纯  代码，不包括资源文件而  只有 ，已经是两倍的体量。现在还只是狼人杀业务的初期，随着业务的快速迭代，业务  只会更快的增加。而过大的业务  所导致的加载时间也会加长。
可能有同学会说，这不是有预加载嘛。我承认，预加载确实解决了绝大部分业务  的加载耗时。但是，并不是每次预加载都可以刚刚好预加载好业务 。虽然业务  加载耗时变长，预加载好的几率就会慢慢变低。
而这不是最关键的行为，最关键的是内存的消耗，我们来看一张图。

从上图就可以看出，仅仅是 ，仅仅只是在内存中展开，还没有到运行。这个时候内存消耗已经达到了 。而整个狼人杀  渲染起来，则消耗了  以上的内存。而这还没有包括业务使用的内存。在手  中，内存的消耗是巨大的，而留给狼人杀使用的内存其实已经很少了。从这里可以看出，内存的优化好像更加迫在眉睫。
  按需加载

  的思路是在业务运行之前，将所有  代码在  中展开。这个逻辑本身没有什么问题。但是，我们需要改造成按需加载。按需加载的本质就是将不是关键路径的业务  拆分开，变成插件中的插件。当业务触发到此逻辑的时候，再去将  代码动态展开。达到动态执行的目的。
而我们想要达成按需加载的效果，可能会面临着三个挑战。
 在动态运行的时候，代码注入的问题。
 模块与模块之间相互引用的问题。
打包工具改造的问题。我们来依次看下这三个问题。
动态注入


从  层面分析，想要达到  代码的动态注入。必须要和运行的  在相同运用域下面。我们通过分析打包后的  代码得知，必须要在_ 模块名称作用域下面。

从  层面分析，想要达到  代码的动态注入。则必须要拿到  中的 。


   
                                  
                          
    {
       =        

      
      _     {
        
        

          {
          
          
        }

          
        _ 
                                    
                                 
                                     
         {
            _ {
              
              
           }

             

           
         }
      }
    }
 而上述函数则是比较关键的执行函数，需将此函数从  内核中暴露出来。
模块相互引用
如果要实现按需加载，则主逻辑  中包含的其他插件  代码，则不能在主逻辑  展开的时候运行。我们想要实现这样的效果，则有两个方案可以实施二选一即可。
跟进  动态执行的原理，我们可以将主业务   中引用插件  的实现函数使用空方法_ 业务名{空} 代替。然后等到运行时，再注入相同的方法_ 业务名{真实方法} 。等业务触发了插件  逻辑的时候，真正运行的是刚刚注入的  真实方法。
懒 
我们平常的业务代码基本是这样引入另外一个模块的
   
   
   
   
   
 {}  
 最终打包工具会把他打包成这样的
 _ = 
                
 _ = __
 _ = 
                
 _ = _ 
                _
 _ = 
                
 _ = _ 
                _
 _ = 
                
 _ = _ 
                _
而这些在业务函数体中，会在编译的时候去找寻此文件是否存在。而这样会报错。
 正确的做法是在业务逻辑中，再去  其模块。
  === _ {
                  = 
                _
                 
                        
                                ={_}
                         
                 
}
在打包工具中展示则是这样的效果。
  === __ {
              = 
            _
             
                 _ {
                  _
            }
}
这样就实现了  的懒加载。实现了先运行主业务，再动态运行插件业务。
打包工具改造
 = {
     
     
         = {
             
            
             
        }
         = 
         =  
         = 
            
            
            
            
            
            
        
}
打包工具的改造，重要的是将业务  拆分成不同的插件。这个可以仿照以前  与业务  拆分的做法。
按需加载小结
 按需加载，只是一个思路。当业务逐渐庞大的时候，相信大家都会面临这个问题。不过，安卓则比较幸运一点。 有一个原生的  命令可以将业务  以每个业务一个  文件。不过  命令不能打出  平台的，解释是因为  上面对小文件有  性能的瓶颈。不过，这里我就没有亲自测试过了。不过个人感觉，真正做到按需加载，就得根据业务做不同的打包，不易过大，也不易过小。平衡才是王道。
后续
大家从上文耗时表可以了解到，预加载和按需加载，只是优化了启动耗时的一部分。而  在执行  到  展示出，中间还有  的耗时。这部分目前来看，不管是狼人杀大型业务的启动，还是  业务的启动，都会有这  的耗时，应该与业务大小无关。从时间表来看，是  在大量绘制 。所以，这部分应该也有优化的空间。后续有进展再和大家分享。
后面会分享更多有关   相关的内容，希望和大家共同学习，成长。前言
自微信版本开始，小程序正式跟大家见面了。最近利用业余时间做了个小程序，命名“养车记账本”。作为狗，经历了从注册开发者资质开始到正式上线的全过程，微信小程序官方 文档 、 快速构建具备弹性伸缩能力的微信小程序 等不在此次叙述之列。本实例所用资源为腾讯云购买的微信小程序解决方案，选的其中的环境。废话不多说，下面是关于这个小程序的一些分享可以扫描二维码体验。
 
准备工作
因为涉及的东西比较多，所以需要准备的东西也比较杂。当然，你得首先知道自己要做什么，毕竟这一切准备和将来的劳动都将为这个产品服务。
开发者资质、服务器、数据库、域名需要预留至少天备案时间、证书等可以通过申请、购买获得，工具及操作环境如下：

工具： 、、、、微信开发者工具、 、 
操作环境：微信公众平台、腾讯云、业务服务器 、    、会话管理服务器、微信小程序数据库　　整个过程会产生一些费用，根据自己选择，大概几百元的样子。不过别担心，腾讯云可以满足所有需求，其中的微信小程序解决方案，就是专门针对小程序量身定制的。
申请资源
目前小程序的开放注册范围仅限于企业、政府、媒体和其他组织，是不开放对个人注册的，所以首先你需要给自己一个合法的身份，我是找了个朋友的企业注册的。申请小程序的开发权限，请移步微信公众平台。吐槽一句，现在开发者也流行缴纳“入会费”，这里需要元。

其次是腾讯云注册，这里可以获得小程序用到的一切资源，包括域名、证书、服务器、数据库等。小程序毕竟是腾讯的产品，服务器支持肯定自家的兼容更好些，腾讯云官网为广大开发者提供了微信解决方案服务器。首次购买半年需要元，后期续费每月元。

见到下面这个界面，就申请成功了。

域名申请、解析、备案
腾讯云可以申请域名，域名一般需要元左右，审核过程会持续个工作日，之后需要解析域名，在腾讯云管理中心可以直接操作登录腾讯云管理中心云产品域名服务云解析。域名备案比较耗时，要在指定背景下拍照。如果你距离指定地点比较近，可以到指定地点拍照，基本各省都有拍照点，见拍照点地图。

如果不方便，可以申请邮寄给你个背景幕布，按照要求拍照，见办理拍照指南，备案材料提交管局审核，需要大概个工作日你得习惯这工作效率，所以最好提前申请域名，给备案预留出时间。

另外，域名实名认证也需要天。
创建微信小程序服务器
在腾讯云购买小程序解决方案时需要选后台语言，决定了分配给你的是什么系统及环境的服务器有、、、四种选择，后期可更改、重装系统。云端小程序构建完成后会得到三个服务器：业务服务器、会话管理服务器、数据库服务器，之后以短信形式发送分配的服务器登录密码，用户名统一是。
在腾讯云登录服务器后可以在弹出的黑色命令窗口输入命令，见下图：

之后输入用户名和密码即登录成功。这个登录窗口是用做的，不能拖动滚动条查看一屏以外的东西，相当憋屈。所以还得有个称手的工具，现在可以登场了。

运行之后输入公网地址，点击，之后输入用户名密码，就可以执行各种命令了。

至于上传下载文件，为了安全起见，默认安装的镜像  不支持，官方推荐用，这两个都可以支持，操作跟  类似。
这里不得不说下关于三个服务器需要注意的点，或者说是坑。系统虽然可以重装，不过需谨慎，因为有些配置重装后并不能恢复成最初分配时的状态。下图是业务服务器重装界面再次提醒：重装需谨慎：

关于业务服务器：我选的是环境服务器，购买后默认并不支持，需要自己安装。下面是关于环境业务服务器升级支持扩展方法：


      
   
 =   
 =   
  
以上四行，从上到下按次序执行或保存为一文件，如_见附件， 然后执行
  _
 再执行
_
 即可
业务服务器配置参考这里，修改  文件。业务服务器的文件存放路径
关于会话服务器：首先查看《腾讯云小程序会话管理服务器修复与升级方案》见附件，然后如果你也重装了会话服务器，你可能还会发现一个问题，官方给出的三木聊天室链接失败。问题解决参考这里 。
执行
 _
 
 记下配置里的和_值，之后退出。
执行
 
 之后按照参考，本应执行
        其中、、、是在步骤中查看到的具体信息
但因为重装系统默认提供的和密码不正确，需要在微信小程序数据库账号管理里为_重置密码，见下图：

然后用内网和新密码执行如下命令：
      _ 新密码
或直接用账号登录，执行：
       密码
  为微信小程序数据库内网地址，用户名和密码为登录数据库服务器的账号密码，注意参数后没有空格
登录微信公众号打开开发设置，记下小程序和小程序密钥
执行命令行后带设置字段值不用引号，退出命令行直接输入回车：
 
    = 这里是 =这里是 
为会话服务器云主机安全组添加默认安全组放通全部端口，并更改优先级在前面
更新_ 内容为以下：

 = 数据库内网地址
 = 
_ = _
_ = 新密码
_= 
 或

 = 数据库内网地址
 = 
_ = 
_ = 密码
_= 
会话服务器文件存放路径
关于数据库服务器：如果有数据表格需要导入，如果你要导入的文件大于，可以压缩成，一般可以压缩到原来的，压缩比率还是很可观的。
腾讯云实名认证
腾讯云实名认证后可以获得腾讯云的代金券，还可以更好的保障你的号安全，认证后你的腾讯云号也是独一无二的。具体见实名认证指引，大约个工作日。

证书
为了保护小程序应用安全，微信官方的需求文档要求每个微信小程序必须事先设置一个域名，并通过请求进行网络通信，不满足条件的域名和协议无法请求。所以需要购买或申请证书。目前正规渠道购买证书还是很贵的，不过如果您选的是微信小程序方案，这个证书是免费的大约需要个工作日审核下发颁发后会获得一个压缩包，内含安全证书。安装证书参考这里把证书压缩包内下的证书拷贝至下
至此，环境算搭好了，剩下的就专注于你的小程序开发了。
小程序策划
我最初是想做一个车友会之类的小程序，但涉及车友互动发文之类，需要有互联网电子公告服务许可证， 总之各种条条框框。反正我是练手，还是绕过这个限制，改做记账本之类的小工具了，鉴于目前小程序只能匹配全名，只在个别关键词开启了模糊匹配，经过查验，“养车”和“记账”两个词都可以模糊搜索，所以名字就叫“养车记账本”了，可以给车主提供个专门记录养车所产生的费用的统计工具。从用户开始访问小程序开始，大概流程图如下：

主要涉及以下几个功能：增加记账、账单列表、账单筛选、修改账目、删除账目、账单统计、车型选择、分类设置等。
增加记账和修改账目可以共用同一个界面，根据实际需要，要用到账单分类、账单产生日期，再就是额度。记账页面操作简单，见后面设计图。
账单列表页和账单统计作为一个展示模块，需要能够通过设置筛选条件比如时间段、类别勾选来展示指定账目，展示方式为按时间列表，统计方式为饼图。
用户可以设置车型，可以不填。如果用户有不止一辆车，这个必须为必填，不过第一版先不考虑多辆车这个维度，后期再加。
至于分类，我大概归纳了一下用车、养车过程可能产生费用的方面，大概包括停车费、加油费、养护、保险、罚款、高速、维修、购车、年检、改装、赔偿等，如果不够用可以在分类设置里增加分类，如果用不到的可以关闭，避免干扰。
再就是象征性的来个建议反馈、关于之类的。
小程序设计
小程序有推荐的设计规范，见微信小程序设计指南，为方便设计师进行设计，微信提供一套可供设计和小程序使用的基础控件库；同时提供方便开发者调用的资源。设计小程序推荐以的尺寸为标准，即。

其中图标我用的钢笔工具，选择的像素路径描边，无填充色。一共分两种状态：选中状态和未选中状态。未选中状态描边色 ，背景色 ；选中状态描边色，背景色  。
 
小程序开发
开始码代码了，开发分前端和后台。
小程序在前端上的贡献不得不点赞，在的基础上扩展了 单位，换算为屏幕宽度，换算为屏幕宽度。这样就可以根据屏幕宽度进行自适应，让前端开发可以解放出来不用过多考虑兼容问题。使用规定屏幕宽为，比如在  上，屏幕宽度为，共有个物理像素，则 =  = 物理像素， =  = 物理像素。是 微信 的一套标签语言，结合基础组件、事件系统，可以构建出页面的结构。开发工具不大好用遇到次闪退，有个好的保存习惯还是不错的；还有就是调试时候如果需要点开非默认页面，有时候不能刷出结构，重启开发工具可以解决，但毕竟不是一天两天打造完美的，相信微信团队一定能做更好。如果不习惯也可以用你喜欢的工具。我的页面结构如下：
  
    
    
    
    
    
    
    
    
    
    
  
如果问你，小程序放开的用户数据够吗？你一定说不够。那我们能做的就是物尽其用吧！如果你的接口涉及当中的 ，接口的明文内容将不包含这些敏感数据。如果需要获取敏感数据，需要对接口返回的加密数据  进行对称解密。可参考微信小程序客户端腾讯云增强 。
在微信登录，解密后，可以在里可以看到用户信息

在登录后做了这些工作：获取用户信息，对照数据库，如果库里有该用户，将车型和类别设置存储到本地，以供其他页面调用；如果没有则保存该用户。如果库里有该用户且设备信息有变化则更新设备信息，如果没有则追加设备信息。如果用户拒绝获取用户信息，授权失败，显示重新授权教程。篇幅有限，只截取部分代码展示。代码如下：

 用户登录
{
      = 
      方法和  方法使用是一致的，不过如果用户已经登录的情况下，会把用户的会话信息带给服务器，服务器可以跟踪用户
    {
           要请求的地址
           请求之前是否登录，如果该项指定为 ，会在请求之前进行登录
         {
             
              = 
            {
                 
            }
             
             用户登录如果库里有该用户，将车型和类别设置存储到本地，如果没有则保存该用户
            {
                  这里不是真实地址
                 {
                     
                     
                     
                     
                     
                     
                     
                }
                  {
                    {
                         
                         
                          登录成功后为该用户格式化表单
                    }
                }
            }
             用户设备信息采集
            {
                  {
                     返回网络类型 有效值：下不常见的网络类型无网络
                      = 
                    {
                          {
                             如果库里有该用户且设备信息有变则更新设备信息，如果没有则追加设备信息
                            {
                                  这里不是真实地址
                                 {
                                     
                                     
                                     
                                     
                                     
                                     
                                     
                                     
                                     
                                     
                                }
                            }
                        }
                    }
                }
            }
        }
         {
            {
                 提示
                 未授权不可使用，请删除后重新获取养车记账本。
                 
                 查看教程
                 
                  {
                      {
                        {
                             
                        }
                    }
                }
            }
        }
    }
}
前端开发过程中遇到的问题顺便提一句，、、等组件使用原生渲染，如果需要弹层交互的话它们会挡住弹层，解决办法就是在弹层后将这些组件属性设置为，弹层消失时重置为。另外还有个问题：我想把里的数据保存成对象格式的，如果追加值的话，不支持这样追加，只能{}，但前者可以更直观的表示某一组赋值是给一个特定对象的，尤其有时候不能确定你要追加的值就限于你指定的那几个的时候，但并不支持这种做法，不知是出于何种考虑，如果没有特殊原因还是希望能改进下。再有就是不支持标签名选择器，也是目前支持标签比较单一，所以要想美化某个组件，必须给它实实在在赋个样式，略显臃肿。
后台开发语言我选的是，主要是网上资料多，函数方法齐全。关于对的增删改查操作网上很容易找到。在同事的指点下，采取了一些措施，防止注入与攻击，主要是过滤文本，做了字符串转换、格式化等操作。在账单查询页面，通过联合查询列出用户表和账单表信息，对查询结果装入数组，之后进行格式化输出供小程序使用，代码如下：
 = 
 = 
 = 
 = 
  {
     =  将传来的时间使用“”分割成数组
     =  获取年份
     =  获取月份 
     =  获取日期
     =  =  =  默认时分秒均为
     =  将时间转换成时间戳
     =  获取星期值
     = 星期日星期一星期二星期三星期四星期五星期六 
      
}
 = ___{
        =  {
         =  
             = 
             = 
        
         = 
         = 
    }
     =  
         = 
         = 
         = 日 
         = 
         = 
         = _
    
     = 
     = 
     = 
}
 =  
     = 
     = 

 = 
 == {  如果没有结果
     =  返回空数组
}
 = _ 将数组转化为格式的字符串
 
针对自己的项目，需要设计合理的数据库表以满足记账的需要。关于账单表字段设置如下：
  `_` 
  ``      指针
  ``     用户
  ``      类别
  ``         金额
  ``     添加日期
 =  = =账目表
此外还有用户表、设备表、类别表、车型表。除了车型表独立存在之外，其他几个表都是以字段相互关联的，以实现相互间的互查。
小程序测试、发布、监测
开发者工具 集成了开发调试、代码编辑及程序发布等功能，其中模拟器模拟微信小程序在客户端真实的逻辑表现，对于绝大部分的  均能在模拟器上呈现出正确的状态。自带的调试工具分为  大功能模块：、、、、、，平时开发的时候及时纠错，问题不大。马上就要车展了，鉴于时间关系，第一版就这样匆匆提交了。不过比较幸运，首次提交就通过审核了。

提交审核需要填一些简单的信息，有利于用户快速搜索出你的信息。之后可以在微信公众平台查看数据分析，其中的自定义分析功能强大不过目前正在内测中，暂时只支持开发者测试数据上报；及以上微信版本支持用户数据上报，用户微信版本更新以前无法收集数据。新版本覆盖全量用户前，数据可能有缺失，可以从不同角度分析访问者信息，为你进一步挖掘用户信息做足准备。

结语
随着小程序不断增长，越来越多的小程序渗透到网友生活、工作的方方面面。弱水三千只取一瓢。本着满足客户某项需求的前提下尽量做一个小而美的工具。
问题是养车记账本目前只具雏形，限于时间和个人能力，班门弄斧，只完成了基础功能，还有很多细节需要调整，功能也不太完善，比如筛选交互逻辑还需要进一步优化，每个网友现在也只能为一辆车记录账单，账单统计还可以列出筛选具体额度以及增加趣味评价，甚至可以考虑增加位置定位等功能……也恳请大家提出宝贵意见，未来一个月比较忙，等车展过后继续！
最后，感谢、给出的好点子，感谢给出的服务器升级、部署方面的指导，感谢在开发方面的帮助。微校开放平台概述
腾讯微校是专注高校领域的公众号第三方平台，目前已接入公众号超过万个，精准覆盖大学生超过万。通过微校开放平台，开发者可以轻松的直接向上千万大学生提供服务，公众号运营者也可以通过本文档来帮助拓展开发。

微校开放平台主要用于指导开发者如何借助微校提供的开放能力对已授权腾讯微校的公众号提供服务能力。具体公众平台接口调用规范和标准，请参照微信公众平台开发者文档。

需要向运营者提供应用配置页的应用，应在运营者开启应用时，将页面链接返回微校具体可参见应用开启请求说明，微校会以的形式加载到应用管理页面，无应用配置页的应用，微校会直接展示默认应用管理页面。

微校会为优秀的开发者提供一定奖励，同时，开发者也可以向微校申请技术优化指导、免费服务器等方面的支持。


服务器环境
腾讯云主机   
下面开始
、登录微校开发平台，创建一个新的应用。

、比如我们像上面那样，弄一个消息回复类应用。

、填写相关信息，上传几张测试用图。

、设置关键字 我这里以“测试”为例，并且开启了模糊匹配。
填写地址，填写测试平台的原始 如果不知道，可以看后面。

、在填写完确认提交后，就可以看到上面这些信息，其中和 下面要用。

、如上图修改中的，修改中的和。


、修改完参数后，点击接口测试，如上图时就成功了。否则请检查你的参数是否修改，然后点击下面的应用测试地址，去开启应用。

、如上图，依次点击开启应用和确认开启。



、当看到如上图所示的时候，都和我的一样，那么下面就可以去公众号测试了。下面我们去公众号掌上江大和测试。
 



至此，此次任务全部完成。下面讲解核心代码：

用于来自微校的应用开启验证核心代码如下：
 _ ==  {
 =   _
  =      {
 = 响应地址
=    设置
 {




_
{
_
_{
微校应用测试

}
}
}
}
}

【用于响应用户发送的关键字】核心代码如下
接收文本消息
  
{
_=公众号原始
=_
=    公众号的名称
 
{
          测试文字
              = 这是个文本消息
             
     其他的类似
         
              =  \技术支持 
             
     }
     _{
          {
              =  
         }  {
              =  
         }
     }{
          =  
     }
      
 }

微校获取公众号信息，签名算法等函数
  _{      根据原始_获取公众号信息 返回的是数组
=    应用
_ =  应用_
=
=
_=
  _=_
  _=
  =
  _=
   
  =___
 =______=__==_==
 = _
 
}
  =  {        生成位随机字符
 = 
 = 
  =      {
 =  _    
}
 
}
 ___ {    校验信息
 = __
 _
_ = 
    {
_ = {}={_}
}
 =  _  =  _
 
}


在使用中，我们可以使用将公众号信息等数据存放到数据中，以便下次调用。欢迎大家共同探讨！

相关推荐如何利用腾讯云搭建个人网盘如何在腾讯云上搭建一个自动播放的服务器当前浏览器不能支持视频播放，请采用或以上浏览器
今天，我们来了解一下负载均衡的几种类型，来帮助我们更好的使用腾讯云负载均衡。

腾讯云负载均衡从大类上来分，有两个大类，分别是公网负载均衡实例和内网负载均衡实例。其中公网实例又分为公网有固定负载均衡实例和公网无固定负载均衡实例。公网实例用于链接互联网外网的负载均衡和请求分发，内网实例用于内网的负载均衡和请求分发。
公网型负载均衡实例通过  从客户端获取请求，并向绑定监听器的后端服务器分发这些请求。
内网负载均衡只能在腾讯云内部访问，不能通过  访问没有公网域名或公网 。内网负载均衡通过对应的  将内网客户端对服务器端的请求合理地分配到服务器集群上。内网负载均衡一般用于内网服务集群的请求处理。
公网有固定  型负载均衡实例均会被分配固定的  公网 ，支持接收客户端的 、、、 等请求转发。同时支持会话保持、健康检查等所有腾讯云负载均衡提供的服务。
公网有固定型负载均衡实例的主要应用场景就是当对公网提供服务的是服务器群集，需要提供统一的入口，并将公网用户请求合理地分配到服务器集群时；要对服务器集群做故障容错和故障恢复时；以及为不同运营商的用户提供就近接入，做网络提速时；

而公网无固定  类型的负载均衡实例不会被分配固定的公网 ，但腾讯云会为每个公网无固定  负载均衡实例提供一个 二级域名。公网无固定  类型的负载均衡实例 仅支持  协议七层转发功能不支持  记录，不支持 绑定，意味着用户只能向一个腾讯云提供的域名发送请求。
如果你要使用你自己的域名来承载请求，是不能使用无固定型的负载均衡器。

公网无固定负载均衡实例的应用场景是比较窄的。主要应用于当用户需要大量域名时；当对公网提供服务的是服务器群集，需要提供统一的入口，并将公网用户请求合理地分配到服务器集群时；希望对服务器集群做故障容错和故障恢复时；公司内部的系统到系统之间的跳转，企业内部的局域网业务等；为不同运营商的用户提供就近接入，做网络提速时；不过，我们依然建议大家使用公网有固定类型的负载均衡，自由度更高，可以更好的去服务业务。

拓展阅读
公网负载均衡实例：内网负载均衡实例：固定型快速入门：公网应用型快速入门：

相关推荐
【腾讯云的种玩法】十分钟轻松搞定云架构 · 负载均衡的最佳实践【腾讯云的种玩法】十分钟搞定云架构 · 什么是、什么是什么是 
对象存储服务是腾讯云提供的面向企业和个人开发者提供的高可用，高稳定，强安全的云端存储服务。您可以将任意数量和形式的非结构化数据放入，并在其中实现数据的管理和处理。支持标准的 接口，您可以快速上手使用，按实际使用量计费，无最低使用限制。
如何在  上使用 
安装
执行  命令安装拓展
  
然后在  中的  中添加
\\
执行   将自动在 目录下生成  文件，修改配置文件中的对应选项
配置完成后，在需要使用的文件中使用
 \\
然后使用静态方法调用比如

来调用，执行操作。

相关推荐
利用腾讯云云对象存储定时远程备份网站
反向代理腾讯云的一个坑商业转载请联系腾讯获得授权，非商业转载请注明出处。原文链接：

北京时间月日凌晨点， 周年，在 乔布斯剧院，苹果发布了三款新。全面屏 来袭，这款被定义为未来的智能手机黑科技满满：全面屏，无线充电、面部识别“ ”以及跟踪你脸部动作的。和往年的苹果秋季发布会一样，发布会在开始之前就获得了极高的关注，苹果官网也会承受极大的并发压力，看看往年的情况：
年的 预购的情况：
年月日下午三点，香港各个公司的办公平台都在不断的刷新苹果官网，当天苹果官网无法承载用户压力导致无法访问，网页通过多国文字显示“我们将很快恢复服务”。
时隔一年，的预约情况：月日，距离 开始预约不到两小时，尝试打开苹果官网浏览，结果显示无法访问。不光是苹果中国官网，美国以及中国香港、中国台湾等地均出现了类似故障。
今年，苹果官网早早的在发布会前小时就开始维护，而今年，苹果官网没有再出现官网崩溃的情况。
网站的访问速度是企业必须要做好的事情。谷歌和一些网站的研究表明，用户们只愿意访问那些打开速度最快、性能最好的网站。一个网站每慢一秒钟，就会丢失许多访客，甚至其中很多访客永远不会再次光顾这个网站，对于来说，也是同理。
众多电商公司开始磨拳擦掌开始做和的活动了，不过这里必须要问自己一句，你的活动页面准备好了吗？
活动前的压力测试，是做预约抢购活动必须经历的一个测试环节。
制定压测目标
对活动页面进行压力测试的根本目的，是要实现活动页面上线时能够正常运行。不过在压力测试前，需要对“用户访问页面”的逻辑有清晰的认识。
这里举个例子：中午去“海底捞”吃饭。 “海底捞”就是你的活动页面。客人去吃饭，就是用户对这个活动页面发起请求，对这个页面造成了一定的负载。客人越多，这个页面负载就越大。几个桌子的客人一起开始点菜，就是对你的活动页面产生了并发。同时，其他桌有的在吃菜，有的在等菜，这些都是并发进行的事务。所以，一个请求会有多个事务产生，比如：点菜，下单，上菜，买单等步骤。
那么如何衡量这个饭店的承载能力好坏呢？
、先看客人能不能一起进来，饭店能同时容纳多少人进来，就是并发量、客人进入饭店，发起下单的请求后，饭店要花多长时间上菜，我们称之为响应时间、饭店每秒可以给多少客人上菜，我们称之为每秒处理事务数
了解了这些指标之后，就基本可以很清晰的制定压测的目标了。
用户可以根据自己活动页面的实际需求，给这些指标设置具体的数值。例如，这边以某个压测大师的合作产品为例，指标要求设置如下：●  ：次●  响应时间：●  并发量：
创建测试
在制定完压测的目标之后，需要选择一个合适的压测工具，这边以压测大师为例：、进入腾讯官网，、选择“性能测试”下的“服务器性能”
、进入项目如果没有创建过项目，点击“创建新项目”
、进入项目后，点击压测产品首页中的创建测试按钮，选择测试。
、填写名称和用例备注，确定压测的机器人配置。根据活动页面的承载要求，并发人数为，因此测试的起始人数就可以设置为，每隔秒增加人，最大人数为，代表页面上线后便产生了的并发人数，并持续了秒。 秒可增加，代表并发的持续时间
、新建客户端请求，确认要压测的地址和客户端请求方式。客户端请求包括，和接口等多种形式，方法选择可选和在客户机和服务器之间进行请求响应时，两种最常被用到的方法是： 和 。  从指定的资源请求数据；  向指定的资源提交要被处理的数据，协议可以选择“”和“”。
客户端请求截图，图中填写了的测试地址
、确认压力源，外部服务器选择“腾讯云”即可。
、编辑测试模型，根据实际要求，如果只有一个压测场景，把的压力都放在该场景上。
、开始测试。点击“立即执行”，开始测试。
结果查看与分析
点击“立即执行”之后，测试会马上进入排队系统，如果压力源系统内有空闲资源将马上执行测试。
在测试过程中，测试报告页面会实时显示“人数趋势”和“收发包率”，用户可以实时查看接口的压测情况。
总体概况
压测结果可以首先查看总体的情况，了解本次压测的结果。
再来回顾一下活动页面主要关注的三个指标：●   ：次●  响应时间：●  并发量：
压测大师测试报告页面会显示总体的数据概况，用户可以通过这些数据了解压测的基本结果。在服务器优化前后我们分别选取了两份不同的测试报告，内容如下：测试报告一：响应时间超出，  次低于次的要求，这次测试结果不符合活动要求。
测试报告二：经过优化后，活动页面的响应时间和均满足要求，服务器优化很成功
具体数据情况
在测试过程中，可以通过“事务数据“查看测试过程中的问题详情。
观察下图右侧“请求统计”中成功、失败、错误和超时的比例情况，了解此次压测收发包的精确结果。
下图右侧的“耗时统计”获取各类具体的耗时情况。测试报告一：此份报告可以看出最高才达到了左右，不满足测试需求
而看”响应时间“的统计图，可以发现从刚开始的并发，服务器的响应时间就到了。
测试报告二：此份报告可以看出最低的便达到了次，满足测试需求；
通过对活动页面反复的调试和压力测试，开发者可以迅速的发现服务器性能的瓶颈，并加以修复，保证页面在活动当天可以承载足够的压力，完成一个成功的活动。

压测大师旨在降低开发者在服务器性能测试方面的门槛，迅速发现服务器端的性能瓶颈，进行针对性的性能调优，降低服务器采购和维护成本，提高用户留存和转化率。目前主要优势如下：●  一分钟发起测试，无需编写脚本●   无需配置压力机，随开随用，轻松发起十万压力●  支持、等协议，覆盖，，，游戏等主流场景●  实时查看测试报告，多维度报告对比，迅速定位性能瓶
目前压测大师已经正式对外开放：体验地址：一、 介绍
监控系统是整个运维环节，乃至整个产品生命周期中最重要的一环，事前及时预警发现故障，事后提供翔实的数据用于追查定位问题。监控系统作为一个成熟的运维产品，业界有很多开源的实现可供选择。当公司刚刚起步，业务规模较小，运维团队也刚刚建立的初期，选择一款开源的监控系统，是一个省时省力，效率最高的方案。之后，随着业务规模的持续快速增长，监控的对象也越来越多，越来越复杂，监控系统的使用对象也从最初少数的几个，扩大为更多的，。这时候，监控系统的容量和用户的“使用效率”成了最为突出的问题。
监控系统业界有很多杰出的开源监控系统。我们在早期，一直在用，不过随着业务的快速发展，以及互联网公司特有的一些需求，现有的开源的监控系统在性能、扩展性、和用户的使用效率方面，已经无法支撑了。
因此，我们在过去的一年里，从互联网公司的一些需求出发，从各位、、的使用经验和反馈出发，结合业界的一些大的互联网公司做监控，用监控的一些思考出发，设计开发了小米的监控系统：。
二、 特点
、强大灵活的数据采集：自动发现，支持、、支持用户主动、用户自定义插件支持、   、、、 、水平扩展能力：支持每个周期上亿次的数据采集、告警判定、历史数据存储和查询、高效率的告警策略管理：高效的、支持策略模板、模板继承和覆盖、多种告警方式、支持调用、人性化的告警设置：最大告警次数、告警级别、告警恢复通知、告警暂停、不同时段不同阈值、支持维护周期、高效率的组件：单机支撑万的上报、归档、存储周期为分钟、高效的历史数据组件：采用的数据归档策略，秒级返回上百个一年的历史数据、：多维度的数据展示，用户自定义、高可用：整个系统无核心单点，易运维，易部署，可水平扩展、开发语言： 整个系统的后端，全部编写，和使用编写。
三、 架构

每台服务器，都有安装，是一个开发的程序，用于自发现的采集单机的各种数据和指标，这些指标包括不限于以下几个方面，共计多项指标。

相关
磁盘相关


内存相关
网络相关
端口存活、进程存活
 插件
某个进程资源消耗插件
、 等相关统计项采集
机器内核配置参数

只要安装了的机器，就会自动开始采集各项指标，主动上报，不需要用户在做任何配置这和有很大的不同，这样做的好处，就是用户维护方便，覆盖率高。当然这样做也会端造成较大的压力，不过的服务端组件单机性能足够高，同时都可以水平扩展，所以自动多采集足够多的数据，反而是一件好事情，对于和来讲，事后追查问题，不再是难题。
另外，提供了一个，用户可以方便的通过接口，数据到本机的，会帮忙高效率的转发到端。
四、 数据模型
 是否强大，是否灵活，对于监控系统用户的“使用效率”至关重要。比如以为例，上报的数据为或者、，那么用户添加告警策略、管理告警策略的时候，就只能以这两个维度进行。举一个最常见的场景：的磁盘空间，小于，就告警。一般的服务器上，都会有两个主要的分区，根分区和分区，在里面，就得加两条规则；如果是的机器，一般还会有十几块的数据盘，还得再加多条规则，这样就会痛苦，不幸福，不利于自动化当然可以通过配置一些自动发现策略来搞定这个，不过比较麻烦。
五、 数据收集
，接收客户端发送的数据，做一些数据规整，检查之后，转发到多个后端系统去处理。在转发到每个后端业务系统的时候，会根据一致性算法，进行数据分片，来达到后端业务系统的水平扩展。
 提供接口和接口两种方式，自身是无状态的，挂掉一台或者多台不会有任何影响，同时性能很高，每分钟可以转发超过万条数据。
目前支持的业务后端，有三种，、、。是我们开发的高性能告警判定组件，是我们开发的高性能数据存储、归档、查询组件，是开源的时间序列数据存储服务。可以通过的配置文件来开启。
的数据来源，一般有三种：、采集的基础监控数据、执行用户自定义的插件返回的数据、 ：线上的业务系统，都嵌入使用了统一的，对于业务系统中每个接口的、都会主动采集并上报说明：上面这三种数据，都会先发送给本机的，再由转发给。
基础监控是指只要是个机器或容器就能加的监控，比如    等，这些监控采集的方式固定，不需要配置，也不需要用户提供额外参数指定，只要跑起来就可以直接采集上报上去； 非基础监控则相反，比如端口监控，你不给我端口号就不行，不然我上报所有个端口的监听状态你也用不了，这类监控需要用户配置后才会开始采集上报的监控包括类似于端口监控的配置触发类监控，以及类似于的插件脚本类监控，一般就不算基础监控的范畴了。
六、 报警
报警判定，是由组件来完成。用户在 来配置相关的报警策略，存储在中。  会定期加载中的内容。也会定期和 保持沟通，来获取相关的报警策略。
 不仅仅是单纯的加载中的内容，根据模板继承、模板项覆盖、报警动作覆盖、模板和绑定，计算出最终关联到每个的告警策略，提供给组件来使用。
转发到的每条数据，都会触发相关策略的判定，来决定是否满足报警条件，如果满足条件，则会发送给，再以邮件、短信、米聊等形式通知相关用户，也可以执行用户预先配置好的地址。
用户可以很灵活的来配置告警判定策略，比如连续次都满足条件、连续次的最大值满足条件、不同的时间段不同的阈值、如果处于维护周期内则忽略 等等。另外也支持突升突降类的判定和告警。
七、 
到这里，数据已经成功的存储在了里。如何快速的读出来呢，读过去小时的，过去天的，过去一月的，过去一年的，都需要在秒之内返回。
这些都是靠和组件来实现的，会将数据往组件转发一份，收到数据以后，会以的数据归档方式来存储，同时提供查询接口。
面向终端用户，收到查询请求后，会去多个里面，查询不同的数据，汇总后统一返回给用户。
八、 面板
九、 存储
对于监控系统来讲，历史数据的存储和高效率查询，永远是个很难的问题！数据量大：目前我们的监控系统，每个周期，大概有万次数据上报上报周期为分钟和分钟两种，各占，一天小时里，从来不会有业务低峰，不管是白天和黑夜，每个周期，总会有那么多的数据要更新。
写操作多：一般的业务系统，通常都是读多写少，可以方便的使用各种缓存技术，再者各类数据库，对于查询操作的处理效率远远高于写操作。而监控系统恰恰相反，写操作远远高于读。每个周期几千万次的更新操作，对于常用数据库、、都是无法完成的。
高效率的查：我们说监控系统读操作少，是说相对写入来讲。监控系统本身对于读的要求很高，用户经常会有查询上百个，在过去一天、一周、一月、一年的数据。如何在秒内返回给用户并绘图，这是一个不小的挑战。
在这块，投入了较大的精力。我们把数据按照用途分成两类，一类是用来绘图的，一类是用户做数据挖掘的。
对于绘图的数据来讲，查询要快是关键，同时不能丢失信息量。对于用户要查询个，在过去一年里的数据时，数据量本身就在那里了，很难秒之类能返回，另外就算返回了，前端也无法渲染这么多的数据，还得采样，造成很多无谓的消耗和浪费。我们参考的理念，在数据每次存入的时候，会自动进行采样、归档。我们的归档策略如下，历史数据保存年。同时为了不丢失信息量，数据归档的时候，会按照平均值采样、最大值采样、最小值采样存三份。
运维架构服务监控感谢阅读腾讯 微信号第五篇文章，我们将深度解析机器学习领域顶会的热门研究。第一部分解析了五大热门研究领域的重点文章，包括强化学习、随机优化、连续非凸优化、分布式机器学习及递归神经网络等。第二部分简介本届，第三部分为腾讯 机器学习团队的首次公开亮相。


欢迎转载，请在文章开头注明来自腾讯 微信_

腾讯 去年四月成立，今年是首次参加，共计四篇文章被录取，位居国内企业前列。此次团队由机器学习和大数据领域的专家、腾讯 主任张潼博士带领到场交流学习，张潼博士还担任了本届领域主席。在本次人的主席团队中，华人不超过位，内地仅有腾讯 、清华大学和微软研究院三家机构。

图：本届领域主席、腾讯 主任张潼博士现场发表演讲

图：腾讯 机器学习团队

图：展台前络绎不绝的学者
以下为腾讯 机器学习团队在会后对五大研究领域的回顾与独家解析。
所提及论文下载地址：
强化学习
 
强化学习是机器学习的重要分支，通过试错或模仿专家的方式学习可靠策略，解决序列决策问题。其应用领域包括视频游戏、无人驾驶、机器人控制、物流管理和仓储调度等。粗略统计，本届有余篇强化学习相关论文，涵盖了收敛性分析、连续控制、搜索与探索、多智能体与博弈论、模仿学习与转导、端到端深度强化学习等多个方面。
这次会议的研究中体现出三大特点：一、深度学习范式被广为采用，研究者将对问题的理解和先验知识做成了复杂网络模型的子模块，并采用端到端的方式训练；二、来自机器人领域的学者持续影响连续控制方面的研究；三、团队配合多智能体方面的研究吸引了越来越多的注意力。另外，「视频游戏与机器学习」研讨会环节发布了新的强化学习模拟器平台。我们重点关注了以下文章：
      
本文由 发表。策略网络被划分为两个模块：管理者和工作者。管理者模块在低时间分辨率工作，产生中长期子目标；工作者模块在高时间分辨率工作，从管理者模块拿到子目标，并上原始的环境观测一起输出当前时刻的决策动作。本文这种精巧设计的网络结构能自动「发现」子目标，并自动学出相应的「子策略」，而之前的工作都采用了手调子目标的方式，在灵活性和通用性不如本文所提出的算法。

本文的管理者工作者网络结构
实验表明该方法确实能够成功的自动发现「子目标」并学出「子策略」。下图展示了该方法在「蒙特祖玛的复仇」游戏环境上的结果。该游戏特点是有多幕切换，奖励信号稀疏且延迟很长，例如在某一幕拿到了剑要再回到前两幕斩杀某个骷髅怪。

              
本文由卡内基梅隆大学发表。假设输出的连续控制信号从分布中采样，本文通过一个深度神经网络直接学习、预测分布的两个参数。在连续控制的文献中，以往工作多采用高斯分布假设并直接学习和预测高斯分布的均值和方差。但高斯分布在数值上是无界的，对一些需要安全策略的场合这种性质极不合理。例如，自动驾驶中，左右打盘的角度无论如何不能太大。而分布刚好满足左右有界这一性质如下图。

本文方法的实现非常简单但又十分有效，在机器人控制模拟环境的多个任务中取得的结果超过了基于高斯分布的连续控制方法如下图。

    
本文由加州理工大学、迪斯尼研究院和公司该公司有大量体育比赛的各类实际数据联合发表，通过模仿学习方式学出多智能体控制模型。本文收集了大量英超足球比赛数据，使用结构学习方式自动学出智能体和实际数据的合理对应关系。这里的对应关系是指，比如当前智能体在某个具体位置到底是更适合学习前锋、前卫还是中场的行为。
通过动态构造对应关系，本文算法绕开了多智能体模仿学习中对应关系可能存在模糊或不确定性这一难题，例如边后卫助攻到前场后，到底该表现得更像后卫还是更像前锋。实验表明该方法学出的控制策略与专家数据来自实际的英超比赛更为接近，见下左图中的白圈，而定量结果可见下图右。

其他话题
在「视频游戏与机器学习」研讨会环节，暴雪公司宣布开源并发布《星际争霸》的编程接口，开发者通过其可获得游戏内部状态、操纵游戏单位执行指定动作等。其还公布了几十万一对一比赛回放文件，记录了匿名玩家的操作序列。暴雪还与 合作，推出了相应的版本接口。

 效果现场演示

接口，访问特征图层
另外，  发布了新的强化学习框架，其特点为支持多种环境执行器的并发模型一对一，多对一、一对多，多对多，这会为现代强化学习算法的实现，如模特卡罗树搜索和自我对战 ，带来极大便利。
随机优化
 
随机优化算法是指每次只随机采样一个或少量几个训练样本对模型更新的优化方法。因其有低内存消耗、低单次迭代计算复杂度等特点，被广泛应用于大规模机器学习模型训练中，包括绝大多数深度学习模型的训练。粗略统计，本届有余篇随机优化相关论文，大致可分为一阶随机优化、二阶随机优化和非凸随机优化三个大方向。
本次会议的相关论文中体现出两大特点：二阶随机优化算法被更多研究者所关注；非凸随机优化，特别是针对深度学习的非凸随机优化算法成为一个新的研究热点。我们重点关注了以下几篇论文：
      
本文由香港科技大学发表。在深度学习中，参数以及数据分布都会随着迭代进行不断变化，这使得深度学习模型的训练一直是一个具有挑战性的问题。针对这一问题，本文提出了全新的算法，具有更快收敛速度。与已有优化算法如不同的是，本文的算法迭代中，越新样本具有越大权重，这使算法更能适应数据分布变化，有更快收敛速度。多个数据集上深度学习模型训练实验结果显示，比其他已有算法收敛更快。

模型训练实验结果
        
本文由微软研究院发表。随机梯度下降和梯度下降是当前求解非凸机器学习模型的常用方法，本文借用方差下降随机优化算法的关键思路，并对目标函数的强非凸性做更细致的分析，提出了针对于非凸随机优化问题的新算法，比目前标准算法更高效。作者的创新之处，是提出了一套针对强非凸函数更细致的分析方法，并在此基础上设计了针对非凸优化问题更精细的随机算法，能有效利用强非凸函数的结构信息。理论分析结果显示，在强非凸参数大于某个常数时，本文所提出的算法具有更低的计算复杂度。

计算复杂度对比结果
         
本文由上海交通大学和北京大学联合发表。近似牛顿算法，如和，是一类高效的二阶随机优化算法，因其单次迭代计算复杂度较低、收敛速度快等特点受到广泛关注。但已有理论的分析结果和其在实际应用中的性能表现在很多方面并不一致。本文为二阶随机优化算法提出了一套新的分析工具，解决了多个理论及应用中表现不一致的问题。
在创新点上，作者将多种近似牛顿算法统一到同一个算法框架中，对其局部收敛性质做统一分析，解决了多个理论分析结果和实际应用性能不一致的问题，并为新算法设计提供了新的思路。本文从理论上证明了：一、近似牛顿算法的线性收敛速度不需要矩阵满足连续，但是算法平方收敛速度需要此连续。二、矩阵的条件数和的性能不相关。 

连续非凸优化
 
连续非凸优化在机器学习中起着举足轻重的作用，大部分机器学习问题均可建模成某一类连续非凸优化问题。粗略统计，本届大概有篇连续优化的论文，其中半数以上为非凸连续优化内容。另外，由于深度学习的流行，一阶优化算法相关论文也占有相当大的比重。我们将重点介绍以下三个研究：
          
这篇论文由腾讯 、中山大学和香港中文大学合作完成，提出了新的求解多块非光滑复合凸优化问题的算子分裂算法。该算法采用迭代及算子分裂的技巧处理不可分的非光滑正则项。通过用单调算子理论，文中给出多块非光滑复合凸优化问题最优解集以及算法的等价刻画，并利用该等价刻画来巧妙的建立了所提算法的全局收敛性。最后本文以实验证实了该算法的有效性。

        
这篇论文由芝加哥大学和微软研究院共同完成，提出两类新的原对偶一阶算法来求解经验风险最小化的凸优化问题。通过自适应地利用样本数据中暗含的强凸性质，文中证明了这两类新算法的线性收敛速率。另外，通过利用的技巧，文中将算法中距离下的邻近算子替换为距离下的邻近算子，从而得到两类原对偶算法变体。最后实验证明该算法的有效性。

           
这篇论文由罗格斯大学和南京信息工程大学共同完成，作者首次建立了有稀疏约束的极小化问题对偶理论。基于此，本文提出了求解具有稀疏约束的极小化问题的对偶硬阈值 算法及其随机版本的变体，并在无需采样算子满足限制同构性质的条件下建立了算法收敛性。这篇论文从实验上说明了该算法在具有稀疏约束的极小化问题上效果为目前最佳。

分布式机器学习
  
分布式机器学习旨在研究如何以平行、分布式方式来设计算法和系统，实现对大规模海量数据的高效处理。其研究涉及算法和系统两个方面，本届的相关研究主要以算法设计为主。依照分布式类型，主要有中心化分布式和去中心化分布式两种。
粗略统计，本届有篇分布式机器学习相关论文。其中篇为传统分布式机器学习算法优化算法设计，中心化分布式和去中心化分布式各占篇；此外，篇论文讨论了中心化分布式场景下，如何利用数据稀疏性降低通信消耗；篇讨论了通信限制条件下的中心化分布式算法设计；另外几篇则涉及高斯过程、汤普森采样和聚类算法等的中心化分布式算法设计。
从研究上本届有三大研究趋势：一、去中心化的分布式机器学习得到了越来越多关注；二、异步通信仍是分布式机器学习关注的重要方向；三、在贝叶斯优化、高斯过程、聚类算法等具体领域，开始有更多分布式研究。我们重点关注了以下几篇文章：
      
本文由清华大学计算机系与腾讯 联合发表，首次提出了免投影的分布式在线学习算法，并给出了它的悔界上界 。后者依赖于网络大小和拓扑结构，随网络增大而增大，随网络拓扑连接性能提升而减小。相较于传统的有投影分布式在线算法，本文的算法计算复杂度明显降低，能高效处理分布式在线数据流，克服了传统有投影算法需复杂投影计算的问题。

       
本文由中国科技大学与微软亚洲研究院联合发表，提出了延迟补偿的异步随机梯度下降算法。传统异步随机梯度下降算法直接使用延迟的梯度，而该文则给出了一种补偿延迟梯度的算法。补偿方法利用梯度函数的一阶近似，即损失函数的二阶近似来估计延迟的梯度，使算法能取得优于异步随机梯度算法的效果。从创新点上，该文首次提出了对延迟梯度的估计思路，并应用在实际的深度学习训练当中。

             
本文由剑桥大学和联合发表。汤普森采样算法是贝叶斯优化领域的经典算法，可对搜索空间做高效探索，但当前算法无法实现大规模并行化。本文提出了分布式的汤普森采样算法，并在具有大规模搜索空间的化学实验中验证了该算法的有效性。

递归神经网络
  
递归神经网络，尤其是和，已经在时序性数据 建模与生成都取得了显著的效果。研究已是深度学习一个重要研究方向。去年的，所有深度学习相关论文、至少三个都提及了神经网络与深度学习。而今年的中，有个专门介绍最近的进展，包括一些新的模型，如  ，和一些在音乐、音频和视频数据上的应用。这说明主流学术界与工业界近期对有很大关注度。我们也重点关注了以下几篇研究：
   本文由苏黎世联邦理工学院及卢加诺大学的实验室联合完成。    是对框架的一种扩展。 之间的变换深度  为，而允许该深度高于，因而进一步学习信号间的复杂关系。在一些语言建模任务上，显示了更强大的能力，如在 数据集上 的从降到了。

   
本文由北卡罗来纳大学和印度科学研究院共同完成。    可学习一个近似的动态表示空间用于极小样本学习。在极小样本学习公开数据集合上，错误率降低为，可以说是在这个人物的公开测评库上，超过了人类的识别水平。这个工作主要模拟人类比较两个图像相似度的行为，用一个网络协调整个过程，采用相应注意力模型让两幅图像交替比对。在每一个 ，结合图像局部区域信息和的前一个时刻状态，产生当前时刻状态。的最终状态可推导出两副图像的相关性表示 。
在极小样本应用上有两种处理方式：一是采用朴素的模型，将给定测试图像与数据集合的所有图像比对，返回最相似的图像对应的所属类别；第二种方式成为  ，在采用朴素的将测试图像与数据集合的图像比对后，得到相应的相关性表示。这一步学习了局部的两两之间比对关系，基于相关性表示，进而使用双向学习全局的比对信息。朴素模型和  模型在数据集上都取得了超过人类的识别能力；另外，前者在数据集上的测试结果也超越了 等模型。

       
本文由谷歌大脑、和密歇根大学联合发表，文中介绍了一个层次方法预测长时视频未来帧。模型先估计输入视频帧的高阶结构信息，再预测此信息如何在未来视频帧进化，最终给定一个单帧图像和预测得到的高阶结构信息，来重构未来视频帧像素级别的信息。文中提出的模型使用预测视频结构信息，和一个  产生未来视频帧。其预测性能在和  数据集上均取得了很好结果。

       
本文由苏黎世联邦理工学院、苏黎世大学和三星综合技术院等机构共同发布。神经网络的激活模式 一般呈现出稳定输出，为进一步处理这样的自然信号，该论文提出了一个 ，其中每个神经元只在其激活值超越一个阈值时传输相应的信号。虽然一个朴素的 在内存使用和计算量上有一定程度提升，但是其能在训练阶段以较快时间得到较高准确度。在    数据集上提高了倍训练效率，而准确度基本无损失。在另一个自动驾驶数据集上，使用一个端到端的网络来完成  ，训练效率显著提高了倍。在的语音识别数据集上， 可在不损失精度的情况下，提高倍训练效率。
   
本文由卡内基梅隆大学发表，文中提出了一个没有门操作的单元，即   ，可保证   来学习序列信号的长时依存特性。结构简单，没有相应门操作，跟的参数量比较一致。在合成数据上，相较于，可学习多尺度循环统计特性  。而且在学习一维信号的长时依赖，其性能也优于。具体说来，在数据集分类、多声部音乐 建模、一维天气数据建模等任务上性能优于或。
      
该论文由西门子公司与德国慕尼黑大学联合发表，通过 的方式分解矩阵，以处理中高维度的输入信号，如视频建模 任务。现阶段对视频类高维度的输入信号，都通过操作将视频每一帧表示为一个特征向量，降低相应维度，后使用建模时序信息。在等现有视频数据集上，该方法取得了与当前最优方法匹敌的结果，但是其计算复杂度远低于朴素的。本文提出的 可构建一个 替换的大矩阵，还可与共同用端对端训练方式完成训练。

除了上述的模型创新外，应用于时序数据，尤其是音频、音乐、语音等数据，也取得了显著的进展。比如研究的进展、音频合成工作和巴赫音乐的产生等。相关论文为：     ；         ；        
腾讯 
机器学习团队首度亮相
腾讯 成立于年月，专注于机器学习、计算机视觉、语音识别和自然语言理解四个领域「基础研究」，及内容、游戏、社交和平台工具型四大「应用探索」，提升的决策、理解及创造力，向「  」的愿景迈进。
腾讯 主任及第一负责人是机器学习和大数据专家张潼博士详情可点链接，副主任及西雅图实验室负责人是语音识别及深度学习专家俞栋博士。目前团队共有余位科学家及多位应用工程师。
机器学习团队团队是实验室最早组建的研究团队之一，目前有十多位基础研究科学家，涉及该领域的总监和研究专家包括刘威、黄俊洲和刘晗等博士，由张潼博士直接领导。
在基础和前沿研究方向上，机器学习团队着重研究前沿的机器学习理论及算法，研发和部署大规模机器学习深度学习系统。在大数据和互联网背景下，探索其在社交网络、广告推荐、行业大数据、智能游戏，及基于感知和决策的等方向的应用。
正在进行的项目研究项目包括机器学习理论、优化算法、大规模分布式计算、异构平台，及创新监督、半监督和增强机器学习算法等诸多有既有实际应用需求，也有学术前沿期许的项目，吸引了海内外众多优秀人才参与。
腾讯 四篇论文被接收
论文一：           本文提出了第一个能在模型训练开始前，同时检测和去除稀疏支持向量机中不活跃样本和特征的筛选算法，并从理论和实验中证明其能不损失任何精度地把模型训练效率提升数个量级。
论文二：          本文提出了求解多块非光滑复合凸优化问题的算子分裂新算法，该算法采用迭代以及算子分裂的技巧处理不可分的非光滑正则项，并以实验证实了该算法的有效性。
论文三：    本文提出了一个高维大数据中能更有效学习稀疏线性模型的分布式算法。在单个机器训练样本足够多时，该算法只需一轮通信就能学习出统计最优误差模型；即使单个机器样本不足，学习统计最优误差模型的通信代价只随机器数量对数曲线上升，而不依赖于其他条件数。
论文四：     本文提出了去中心化的分布式在线条件梯度算法。该算法将条件梯度的免投影特性推广到分布式在线场景，解决了传统算法需要复杂的投影操作问题，能高效处理去中心化的流式数据。

文章来自：腾讯 微信_作者： 

一 背景
是谷歌官方出的一个用于大量数据展示的新控件，可以用来代替传统的，更加强大和灵活。
最近，自己负责的业务，也遇到这样的一个问题，关于是否要将替换为？
秉承着实事求是的作风，弄清楚是否有足够的吸引力替换掉，我从性能这一角度出发，研究和二者的缓存机制，并得到了一些较有益的结论，待我慢慢道来。
同时也希望能通过本文，让大家快速了解与在缓存机制上的一些区别，在使用上也更加得心应手吧。
：相关知识：与缓存机制原理大致相似，如下图所示：

滑动过程中，离屏的即被回收至缓存，入屏的则会优先从缓存中获取，只是与的实现细节有差异这只是缓存使用的其中一个场景，还有如刷新等
：本文不贴出详细代码，结合源码食用更佳！
二 正文
 缓存机制对比
 层级不同：比多两级缓存，支持多个离缓存，支持开发者自定义缓存处理逻辑，支持所有共用同一个缓存池。
具体来说：两级缓存：

四级缓存：

和缓存机制基本一致：
 和功能相似，意义在于快速重用屏幕上可见的列表项，而不需要重新和； 和  功能相似，意义在于缓存离开屏幕的，目的是让即将进入屏幕的重用 的优势在于的使用，可以做到屏幕外的列表项进入屏幕内时也无须快速重用；可以供多个共同使用，在特定场景下，如多个列表页下有优势客观来说，在特定场景下对的缓存机制做了补强和完善。
 缓存不同：
 缓存，抽象可理解为：  避免每次时调用  标识状态； 缓存。
缓存不同，二者在缓存的使用上也略有差别，具体来说：获取缓存的流程：

获取缓存的流程：

 中屏幕外获取缓存时，是通过匹配获取目标位置的缓存，这样做的好处是，当数据源数据不变的情况下，无须重新：

而同样是离屏缓存，从根据获取相应的缓存，但是并没有直接使用，而是重新即必定会重新，相关代码如下：
源码：
        通过匹配从中获取缓存
           = 
        无论是否成功都直接调用导致必定会调用
           =   
          =  {
              =  {
                 
            }  {
                
            }
        }
 中通过获取的是，即；中通过获取的是，即  ，，；从流程图中可以看出，标志的作用是判断是否需要重新，这也是实现局部刷新的一个核心。
 局部刷新
由上文可知，的缓存机制确实更加完善，但还不算质的变化，更大的亮点在于提供了局部刷新的接口，通过局部刷新，就能避免调用许多无用的。

和添加，移除效果对比
结合的缓存机制，看看局部刷新是如何实现的：以中为例，最终会调用，使整个重新绘制，过程为：
其中，为重点，分为三步：：记录刷新前列表项的各种信息，如，用于动画的相关计算；：真正测量布局大小，位置，核心函数为；：计算布局前后各个的状态，如，，，等，如有必要执行相应的动画
其中，流程图：


当调用时，会对屏幕内做预处理，修改相应的以及流程图中红色部分：

当调用中时，通过对和的预处理，使得只调用一次
需要指出，和最大的区别在于数据源改变时的缓存的处理逻辑，是一锅端，将所有的都移入了二级缓存，而则是更加灵活地对每个修改标志位，区分是否重新。
三结论
、在一些场景下，如界面初始化，滑动等，和都能很好地工作，两者并没有很大的差异：
文章的开头便抛出了这样一个问题，微信客户端卡券模块，大部分都是以列表页的形式展示，实现方式为，是否有必要将其替换成呢？

答案是否定的，从性能上看，并没有带来显著的提升，不需要频繁更新，暂不支持用动画，意味着优势也不太明显，没有太大的吸引力，已经能很好地满足业务需求。
、数据源频繁更新的场景，如弹幕： 等的优势会非常明显；
进一步来讲，结论是：列表页展示界面，需要支持动画，或者频繁更新，局部刷新，建议使用，更加强大完善，易扩展；其它情况如微信卡包列表页两者都，但在使用上会更加方便，快捷。
：仅从一个角度做了对比，盲人摸象，有误跪求指正。
四参考资料
  源码  工作原理解析，带你从源码的角度彻底理解：_ 自己动手写学习其原理：
  源码 剖析：_ 剖析：_ 

本文来源于： 微信公众号一、概念理解
 同步  异步
首先理解操作需要调用系统服务，那么：
同步，每个请求逐一处理，用户发起请求后需要等待或者轮询内核，直到操作完成继续执行；
异步，多个请求并发执行，用户发起请求后仍然继续执行，当内核完成后通知用户线程。
 阻塞  非阻塞
阻塞，请求发出后，若条件不满足，线程；
非阻塞，请求发出后，若条件不满足返回标志信息，告知条件不满足，线程仍然。
个人理解：
以上两个概念，在某些场景下其实是没有什么区别的，因为通常异步不会阻塞。但是如果严格去探讨，两者是不等价的，同步可以实现非阻塞，异步也可以阻塞。理解上有点绕，我认为同步和异步表述的是线程间的协作关系，即之前的任务需要等先来的完成之后才进行比如需要拿到上一次的返回值，而阻塞非阻塞强调的是发起一个请求是否立即返回结果严格来说也可以是，理解为返回空。
二、   多线程
下面回归正题，的网络线程采用了原生实现模型，此时服务端一个线程可以同时处理客户端请求，如果放到的模型去理解，这就是大名鼎鼎的多路复用！其实传统多线程也并非一无是处，如果考虑只是处理并发量不大的长连接，用这种模式实现可能更加简便，性能上也不会有多大差别。但是如果是应对高并发场景，多路复用势在必行。
在理解上可以参照本系列上一节的两张附图，注意和最大的两点区别是：

从面向流改为面向缓冲区；

引入选择器，允许一个单独的线程同时监视多个通道。即：通过调用方法由一个用户态线程负责轮询多个，直到某个阶段的数据就绪，再通知相应的用户线程当前线程执行操作，以此实现非阻塞和模拟异步化。


 进一步考虑，上述实现是否还存在不足呢？
答案是肯定的，

尽管一个线程可同时监控多个请求，但是所有读写请求以及对新连接请求的处理都在同一个线程中处理，无法充分利用多的优势，同时读写操作也会阻塞对新连接请求的处理，因此需要将线程和业务线程解耦。

单局限性，可引入了多，也即一个主负责监控所有的连接请求，多个负责监控并处理读写请求，减轻了主的压力，降低了主压力太大而造成的延迟，同时具有一定的容错性。并且每个子分别属于一个独立的线程，每个成功连接后的的所有操作由同一个线程处理。这样保证了同一请求的所有状态和上下文在同一个线程中，避免了不必要的上下文切换，同时也方便了监控请求响应状态。另外，在选择进行注册时可以通过轮询的方式达到一定的均衡。


这里贴一个简易实现代码，方便阅读：
：
   {
     
           = 
         {
      = 
      = 
    
     
     _
      = 
      =  
       =      {
       =  
    }
      = 
        {
        = 
           {
        
          {
            =  
            = 
          
             {} 
            =    
          
          
        }
      }
    }
  }
}
类：
   {

       = 
       =
        
    
      {
     = 
    
  }
        {
     _
  }
     {
    
  }
     {
      {
        {
          =  {
          
        }
          = 
          = 
          {
            = 
          
            {
              = 
              =  
              = 
                {
              
              
              {}\   
              
            }    ==  {
              {}\     
              
            }  {
              {}\   {}   
            }
          }
        }
      }
    }
  }
}
三、线程模型
现在终于到了正题，理解了上面的问题，再来看的线程模型就很容易理解了，其设计思路基本如上，并无二异。
源码的线程模型部分相关类图如下：

其中，即为线程，就是负责启动多个线程并分发事件，代码实现上采用 方式； 
为业务线程池，将解码后和创建一个任务放进去跑，实现了线程和业务线程的解耦。
中核心代码如下：

    管理多个
 
   
{
     
    {
         
    }

     = 
        
    {
        
    }
}

轮询
   
{
       
}


  
{
    
    {
         
        {
            
            
              = 
             
            {
                  = 
                

                   

                 {
                         
                      = 
                                {
                        
                    }

                       
                    

                }    {
                     
                }
            }
            
        }
    }   
    {
         = 
        
    }
}
当然从类图中也可以看出，具体实现上还考虑了很多其他的问题和优化方案，如：过载保护等，这些留待下节说明。
感谢阅读，有错误之处还请不吝赐教。

致谢，在的学习上要感谢实习中毛哥和导师的指导，让我少走了不少弯路，特别是思考问题的方式上，受到了极大的启发； 还有组里像浩哥，哥、哥，菠菜、 等所有小伙伴给予热情的解答和帮助。腾讯云商业智能分析产品由北京永洪商智科技有限公司提供，永洪一站式大数据分析平台

产品中过滤条件设置
在数据分析中常会对一些数据进行筛选，如不同权限的用户看到的数据信息不同，可以通过行过滤器设置；同一报表中不同组件显示的数据不不同，可以通过给组件添加过滤器来实现。用户可使用过滤器来实现对数据的筛选。在展示数据的组件上均可实现对数据的过滤，对已绑定数据的组件才能设置过滤条件。这里介绍一下常见过滤器的设置。
一、过滤器的类别
产品中在创建数据集处行过滤器、列过滤器如图所示，这两个过滤器主要是用于对数据级别权限进行设置，行过滤器也可以限制数据集数据行数。

图
编辑报告处设置组件上的过滤器，该过滤器主要是限制组件展示的数据。
注：列过滤器与行过滤器和组件上过滤器有所不同，列过滤器是限制用户不能查看哪些字段，而行过滤器和组件上的过滤器是限制数据集数据条数。
二、行过滤和组件上过滤器常见设置
、新建过滤器
行过滤器：在创建数据集处元数据编辑区左上角点击行过滤器，进入到行过滤器编辑界面，如图所示。点击编辑行过滤器进入行过滤器编辑界面。

图
组件上过滤器：组件上右击，选择过滤器，进入过滤器编辑界面，如图所示。

图
、增加过滤条件
在过滤器编辑界面，点击增加过滤条件，即编辑过滤条件，分别在过滤字段、条件设定及设置值处输入选择或输入对应的内容即可，如图所示。

图
在过滤条件的设定中，不同数据类型的数据字段包含的筛选条件不同，具体如图所示。

图
其中日期，时间，时间戳类型的数据会显示日历按钮。
“ 之间 ” 会弹出两个输入框，用于输入初始值和终止值。“ 其中一个 ”、 “ 包含其中一个 ” 可添加多个值，可以通过 “ 添加 ” 和 “ 删除 ” 按钮对所添加的值进行编辑。“ 在圆形内 ” 需要添加  个参数值并且必须按照顺序依次添加，需要添加的参数值为：经度值、纬度值、半径 米。“ 在矩形内 ” 需要添加  个参数值并且必须按照顺序依次添加，需要添加的参数值为：经度值、纬度值、宽 米、高 米。只有长整型数据 比如：表示经度和纬度的位置列 才有 “ 在圆形内 ” 和 “ 在矩形内 ” 的过滤条件。
注：包含对应于语句中的，包含其中一个对应于语句中的 ，都可以进行模糊查询。其中一个对应于语句中的语句。
过滤条件的值还支持一些系统参数，  上只显示出 ， ， ， ，例如：当被筛选的组件中含有空值，并且是空字符串而不是  时，过滤条件应当是  等于{}，如图所示。

图
产品中内置参数的具体含义，如图所示。

图
、编辑过滤条件
在编辑好的过滤条件上双击即可编辑设置好的过滤条件。
、过滤条件相关设置
产品中过滤条件之间有与、或、非的设置，可以设置子过滤条件，也可以删除已有过滤条件。
添加子过滤条件，在已存在的过滤条件上右击，可以选择在该条件上方或下方插入过滤条件来设置子过滤器或并列过滤器，如图所示。也可以在过滤编辑界面上方的工具按钮插入过滤条件。

图
过滤条件中的与、或、非设置。若过滤条件存在两个及以上时，在并列的过滤条件，空白处右击，可选转化为与或，如图所示。

图
过滤条件中非设置是在编辑过滤条件时选择是或不是，不是表示非。
删除过滤条件
选中已有的过滤条件，在过滤编辑界面上方的工具删除按钮删除过滤条件，也可以右击删除。
注： 在移除已经设置过滤器的组件后，相应的过滤器也会被删除，但清除所有绑定的数据后，过滤器不会消失，仍然工作。
倘若过滤条件中需要设定参数，参数的书写格式为 {} 问号必须是英文状态下输入的。
三、列过滤器
列过滤器主要功能是实现数据级别的权限设置，在创建数据集处可设置列过滤器来设置哪些用户不能看某些字段。如图所示，点击编辑进入列过滤器设置界面。

图
列过滤器设置界面如图所示，可以将可选列表中的用户、角色、组添加到已选列表中，已选列表中的用户不能看到数据字段的内容。

图导语
随便说说，其一，项目的原名是“移动交互应用的前后台框架”，为了高大上，起了个“云计算”；其二，这是动手写的第一篇，不过在规划里面第二篇，第一篇项目概述没想好；这篇文章主要来之的一篇文章，是算法实现方案的指导性综述。
 概述
 定义
头部姿态估计  ，：利用计算机视觉和模式识别的方法在数字图像中判断人头部的朝向问题；头部姿态估计是一个空间坐标系内识别头部的姿态方向参数也就是，头部位置参数 和方向角度参数。
按照估计结果的不同，分为离散的粗糙头部姿态估计单张图像、连续的精细头部姿态估计视频。

 应用
近年来，主要应用有：
智能人机交互 

取代鼠标：头部姿态和注视跟踪
识别人的注意力角点
疲劳驾驶检测
人的行为的理解和分析

人脸身份识别

姿态正则化
基于模型的面部识别

游戏和娱乐

头部运动驱动的游戏
虚拟社交换脸
用户测试分析注意力


 头部姿态估计的方法
基于视觉的头部姿态跟踪和识别技术不仅是一个重要的理论问题，还有着显著的应用前景，因此吸引了国内外众多研究机构的重视。国际上开展头部姿态跟踪研究的有麻省理工学院人工智能实验室、卡内基梅隆大学机器人研究所、瑞士洛桑联邦理工学院 计算机视觉实验室、微软  研究院等著名的研究单位。国内也有许多高校和科研机构开展了头部跟踪的相关研究，比如北京大学视觉与听觉信息处理国家重点实验室、清华大学人机交互与媒体集成研究所、中科院自动化所模式识别实验室、上海交通大学系统控制与信息处理教育部重点实验室、南京大学计算机科学与技术系、东南大学学习科学研究中心情感信息处理实验、西安交通大学人工智能与机器人研究所等单位、浙江大学计算机学院等。
经过近  年的研究，已经出现了多种基于视觉的头部姿态估计方法。按照判断头部姿态技术的不同可以分为八种类型                    。

 模板匹配方法  

模板匹配的头部姿态估计，具体来说就是选择一些标注了头部姿态的图像作为样本集，如图所示。识别时，把当前图像与样本集中的图像进行对比，找到与当前图像最接近的样本，
并把该样本的姿态作为当前图像的头部姿态。
基于模板匹配的技术与其它方法相比具有实现简单的优点，可以随着使用环境和人员的不同随时对样本库进行扩展。只要采集一些包含头部信息的图像并标注每个图像的头部姿态就可以生成样本库，不需要采集反样本图像，也不需要识别人脸特征点。基于模板匹配的技术同时适合高分辨率和低分辨率图像的识别。
基于模板匹配的技术也有很多不足。首先，头部姿态参数的精度受到模板个数的影响，如果模板个数较少，姿态参数的精度会比较低，如果模板的个数较多，又会带来较大的计算量。当样本集里有很多人的样本时，模板匹配会受到不同头部姿态和不同人脸的双重影响，导致姿态参数的误差较大。
 多分类器方法 

针对不同姿态的人脸训练相应的识别器，然后把多个识别器同时使用，选择匹配程度最高的识别器对应的姿态作为当前图像的头部姿态。和基于模板匹配的方法一样，基于多个分类器的方法也是直接对图像进行处理。
与基于模板匹配方法相比，基于多个分类器的方法具有多个优点。通过采用多个训练样本，可以克服人脸外观的局部变化对头部姿态识别的影响，并且同时适合高精度和低精度的人脸图像。另外不需要单独的头部检测和定位即可完成对头部姿态的估计。其不足之处是需要训练大量的分类器才能识别较多的头部姿态，此外还要提供大量不包含人脸的图像作为反样本，这会增加分类器的训练时间。如果分类器的数量较多的话，对某个识别器的正样本很可能成为另一个识别器的反样本，影响姿态识别的结果。同时具有人脸检测和姿态识别的功能，使训练过程包含很多重复。
 非线性回归方法  

非线性回归方法通过学习从图像空间到一个或者多个姿态方向的非线性函数映射来估计头部姿态。
非线性回归方法神经网络方法的有点很多，这些系统非常快只需要提供一组标注了姿态参数的人脸图像就可以方便的完成训练，在近场和远场图像中工作很好在实践中精度也相对最精确。
这类方法的主要缺点是他们容易出现头部不稳定的错误。
 歧管嵌入方法  

歧管嵌入方法寻找模型头部姿势连续变化的低维歧管。新图像可嵌入到这些歧管中，然后用于嵌入模板匹配或回归。
上述的歧管嵌入技术都是线性或非线性方法。线性技术具有嵌入可以通过矩阵乘法执行的优点，但是它们缺乏非线性技术的表示能力。作为这些方法的结合，全局头部在台歧管可以由一组局部线性歧管近似。这已经用于 ， 和  的头部姿态估计。
 柔性模型方法  

柔性模型将非刚性模型与图像平面中个人的面部结构相结合。从特征级比较或模型参数的实例中估计头部姿势。
   是一种典型的柔性模型。使用  通过迭代逐步接近人脸图像，所以能较好的克服头部检测误差的影响，获得准确的头部姿态。 的主要问题是训练过程中对所有的训练图像都要标注人脸特征，这限制了该方法对大范围头部旋转的支持，因为此时人脸图像的很多特征点已变的不可见。另外， 也不能跟踪分辨率较低的远景人脸图像。
 几何关系方法 

几何方法使用诸如眼睛，嘴巴和鼻尖等特征的位置来确定其相对配置的姿势。
此类方法过程简单，使用几个特征点就可以得到头部姿态检测结果，但检测过程中不能出现特征点的丢失和遮挡，同时获得的姿态参数的精度也比较低。远场图像是有问题的，因为分辨率可能使得难以或不可能精确地确定特征位置。
 跟踪方法 

跟踪方法从观察到的视频帧之间的移动中恢复头部的全局姿态变化。
跟踪方法的主要优点是通过发现视频帧之间的小姿态位移，能够以高精度跟踪头部。在这种跟踪配置中，这些方法始终优于其他头姿态估计方法。通过基于模型的跟踪的另一个优点是能够动态地构建个人头部的个性化原型，避免外观变化的不利影响。
跟踪方法的难度在于准确地初始化位置和姿势，以生成新模型或调整现有模型。没有单独的定位和头部姿态估计步骤，这些方法只能用于发现帧之间的相对变换。在这种操作模式下，这些方法不是绝对意义上估计头部姿势，而是跟踪头部的运动。然而，对于某些应用，仅需要相对运动。一些例子包括使用手动初始化的圆柱模型和递归最小二乘优化跟踪头部，或通过可变  模型进行跟踪。只要头部姿态估计值接近原始视图，跟踪方法可以自动初始化，使用动态模板重新创建模型。
 混合方法 

混合方法组合了上述一种或多种方法来克服任何单一方法中固有的限制。
混合方法可以使用两种或更多种独立技术，并将每个系统的估计值融合为单一结果。在这种情况下，系统从多个提示获得信息，从而提高估计精度。具体示例包括外观模板与几何匹配也包括粒子滤波以及通过弹性图形匹配进行改进的歧管嵌入方法。
相关推荐：《基于云计算的  移动交互应用研究：交互云计算》接系列文章：
《 海量之道系列文章之弱联网优化 》一《 海量之道系列文章之弱联网优化 》二
首先，可以在我们自己内将各种路由交换设备的设定小于或等于字节，并积极参与三次握手时的协商过程，期望达到自动控制服务器收发数据报文大小不超过路径最小从而避免分片。这个方案的问题是如果路由路径上其它设备不积极参与协商活动，而它的或设置值又比较，那就白干了。这就好比国家制定了一个高速沿途隧道限高公示通告标准，但是某些地方政府就是不告诉你，没辙。
其次，可以在业务服务中控制应用数据请求响应的大小在字节以下注：也无法根本避免前述方案中间路由 的问题，在应用层数据写入时就避免往返数据包大小超过协商确定的。但是，归根到底，在出发前就把数据拆分为多个数据报文，同分片机制本质是相同的，交互响应开销增加是必然的。考虑到人在江湖，安全第一，本方案从源头上控制，显得更实际一些。
当然，最靠谱的还是做简法，控制传输数据的欲望，用曼妙的身姿腾挪有致，相关的内容放到轻往复章节探讨。
对应到前面的快乐运猪案例，就是要么在生猪装车之前咱们按照这条路上的最低限高来装车问题是怎么能知道整个路上的最低限高是多少，要么按照国家标准规定允许的最小限高来装车，到这里，肥猪们终于可以愉快的上路了，风和日丽，通行无阻，嗯，真的吗？
②　放大拥塞窗口
把拥塞窗口初始值设为，这也是目前 中协议栈的缺省值。放大拥塞窗口是一项有理有据的重要优化措施，对移动网络尤其重要，我们同样从一些基本理论开始逐步深入理解它。
是个传输控制协议，体现控制的两个关键机制分别是基于滑动窗口的端到端之间的流量控制和基于测算的端到网络之间的拥塞控制。
流量控制目标是为了避免数据发送太快对端应用层处理不过来造成缓存溢出，就像一次发了车肥猪，买家那边来不及处理，然后临时囤货的猪圈又已客满，只好拒收抛弃，相关概念和细节我们不展开了，有兴趣可以研读《详解 卷一：协议》。
拥塞控制目标是在拥塞发生时能及时发现并通过减少数据报文进入网络的速率和数量，达到防止网络拥塞的目的，这种机制可以确保网络大部分时间是可用的。拥塞控制的前提在于能发现有网络拥塞的迹象，协议栈的算法是通过分组丢失来判断网络上某处可能有拥塞情况发生，评判的具体指标为分组发送超时和收到对端对某个分组的重复。在有线网络时代，丢包发生确实能比较确定的表明网络中某个交换设备故障或因为网络端口流量过大，路由设备转发处理不及时造成本地缓存溢出而丢弃数据报文，但在移动网络中，丢包的情况就变得非常复杂，其它因素影响和干扰造成丢包的概率远远大于中间路由交换设备的故障或过载。比如短时间的信号干扰、进入一个信号屏蔽的区域、从空闲基站切换到繁忙基站或者移动网络类型切换等等。网络中增加了这么多不确定的影响因素，这在拥塞控制算法最初设计时，是无法预见的，同时，我们也确信未来会有更完善的解决方案。这是题外话，如有兴趣可以找些资料深入研究。
拥塞控制是协议栈最经典的和最复杂的设计之一，互联网自我牺牲的利他精神表露无遗，设计者认为，在拥塞发生时，我们应该减少数据报文进入网络的速率和数量，主动让出道路，令网络能尽快调整恢复至正常水平。
拥塞控制机制包括四个部分：
         慢启动；
         拥塞避免；
         拥塞发生时的快速重传；
         快速恢复；
话题太大，我们聚焦到与本主题相关的【慢启动】上。
慢启动这项措施的缘起是，当新链接上的数据报文进入一个拥塞状况不可预知的网络时，贸然过快的数据发送可能会加重网络负担，就像养猪场每天都会向很多买家发车送肥猪，但是出发前并不了解各条高速路上的拥堵情况，如果按照订单一口气全部发出去，会遇到两种情况，一是高速很顺畅，很快到达此时流量控制可能要干预了；二是高速本身就有些拥堵，大批卡车上路加剧了拥堵，并且肥猪们堵在路上，缺衣少食饿瘦了买家不干，风餐露宿冻死了卖家吃亏，重新发货还耽误时间，并且，用于重新发货的货车加入高速则进一步加重了拥堵的情况。作为一个充满社会良知精神的养猪场，我们肯定不愿意贸然增加高速的负担。
下面进入简单的理论知识介绍部分，如觉枯燥，敬请谅解。
是一个可靠传输协议，基础是发送应答式确认机制，就好比肥猪运到目的地买家签收以后，要给卡车司机一个回执带回去交差，猪场老板一看回执，大喜过望，马上继续装车发运，如此往复。如【图九 链接建立、传输和关闭示意】，可以了解这种发送应答式工作的基本流程，如果再结合流量控制、拥塞控制和超时重传等机制，会有很多变种，整个协议栈因而显得比较复杂。
但，万变不离其宗，老子说“是以圣人抱一为天下式”，真经典。

【图九 链接建立、传输和关闭示意】
慢启动顾名思义，就是把网络链路数据报文传输启动的速度放慢一些。方法其实也挺简单，发送方维护了两个参数用于控制这个过程，它们分别是拥塞窗口， 和慢启动门限，  ，具体算法如下：
        链接建立好以后，初始化，单位是链接建立过程中协商好的对端，代表一次可以发送  个字节。初始化为，单位是字节；
        每当收到一个， ，呈线性上升，发送方此时输出数据量不能超过和接收方通告的窗口这个概念我们在后面的章节中会介绍大小；
        每当经过一个  ，网络往返时间， =   ，呈指数让升，同样发送方此时输出数据量不能超过和接收方通告的窗口大小；
          是一个上限，当 = 时，就进入“拥塞避免”算法；
广告时间，插播简单介绍一下，它是  网络往返时间的简写，简单的理解就是一个数据报文从发送出去到接收到对端确认的时间这样描述其实不够严谨，因为我们没有展开数据报文发送和对端确认的各种复杂。是超时重传机制的基础，也是拥塞控制的关键参数，准确的估算出具有伟大的现实意义，同时也是一项相当艰巨复杂的任务。计算机科学先辈们在持续完善的计算方法，从最初中描述的经典算法，到  算法，最后发展到今天在使用的  算法，如有兴趣可自行以深入研究。
通过【图十 慢启动过程示意】，可以更直观的理解慢启动的过程，经过两个，已经由初始值演化为：即在接收方通告窗口大小允许的情况下，可以连续发送个数据报文，然后继续指数增长，这么看来，慢启动一点都不慢。

【图十 慢启动过程示意】
注：示意图中三个大括弧逐渐变大不是因为数值变大，而是要      示意包含的数据报文变多；
猪场老板来解读一下这个算法，我们对一个买家同时维护两个账单数字，一是起运数量设为，单位是卡车，二是最大同时发货数量设为，以肥猪头数为单位，描述如下：
        同买家订单协商确定后，初始化，把符合通往买家的高速路上限高要求的一辆卡车最大装载肥猪头数设为，代表一次可以发送  头肥猪。初始化为，单位是头；
        每当收到一个买家回执， ，呈线性上升，猪场老板此时发货数量不能超过和买家通告的临时囤货的猪圈大小；
        每当经过一个送货往返， =   ，呈指数让升，同样猪场老板此时发货数量不能超过和买家通告的临时囤货的猪圈大小；
        是一个上限，当 = 时，为了避免可能带来的高速拥堵，就要进入“拥塞避免”算法；
这里，需要提到的一篇论文《    ’   》暨。 从开始采用了这篇论文的建议把 初始化为个，而在此之前， 采用了的规定，是根据的值来动态变化的。的这篇论文值得研究一下，理论分析和实践检验都有。
简单来说，初始化为，就是为了允许在慢启动通过往复“慢慢”提升拥塞窗口前，可以在第一个网络传输回合中就发送或接收       的数据。这对于和来讲是非常重要的，因为它给了更多的空间在网络交互初始阶段的数据报文中填充应用协议数据。
对于移动，大部分网络交互都是并发短链接小数据量传输的形式，如果服务器端有 的数据返回，采用过去的慢启动机制时，效率会低一些，大概需要个才能完成数据传输，反应到用户体验层面就是慢，而把拥塞窗口初始值提升到后，在大多数情况下都能在个的周期内完成应用数据的传输，这在移动网络这样的高时延、不稳定、易丢包的场景下，显得尤其意义重大。
一次就发卡车肥猪，让慢启动歇一会，别问为什么，有钱，任性。
③　调大读写缓冲区
把的读缓冲区亦可称为发送缓冲区和写缓冲区亦可称为接收缓冲区大小设置为。在平台上，可以通过  函数设置_和_选项来分别调整读缓冲区和写缓冲区的大小。
这两个缓冲区跟我们的协议栈到底有怎么样的关联呢。我们回忆一下【图六 数据报格式及首部中的各字段】，里面有个位窗口大小，还有我们前面提到的流量控制机制和滑动窗口的概念，大幕徐徐拉开，主角纷纷粉墨登场。在正式详细介绍之前，按照传统，我们还是先站在猪场老板的角度看一下，读缓冲区就好比买家用来囤货的临时猪圈，如果货到了买家使用部门来不及处理，就先在这里临时囤着，写缓冲区就好比养猪场根据订单装好车准备发货，如果买家说我现在可以收货便可速度发出，有点明白了吧。下面详细展开探讨：
         【窗口】
整个协议体系是经典的分层设计，层与应用层之间衔接的部分，就是操作系统内核为每个链路维护的两个缓冲区，一个是读缓冲一个是写缓冲。从数据结构角度讲，这两个缓冲区是环形缓冲区。
读缓冲肩负的使命是把接收到并已确认过的报文中的数据缓存下来，由应用层通过系统接口读取消费。就好比买家内部会分原料采购部门和产品加工部门，采购部门收到肥猪后先送到临时猪圈好吃好喝供着，加工部门需要的时候就会拎着屠刀过来提猪。
写缓冲肩负的重任是缓存应用层通过系统接口写入的要发送的数据，然后由协议栈根据、、和对端通告的窗口等参数，择机把数据分报文段发往对端读缓冲。想要在拥塞控制等相关参数都允许的条件下连续发送数据报文，尚需对端通告的窗口大小能够容纳它们。就好比猪场老板根据买家订单发货，先调配若干辆卡车，根据高速的限高要求装上肥猪，然后再考虑高速的顺畅情况来分批发货，货可以陆续上路，但还有一个重要前提是发货前买家通告的临时猪圈空间是足够容纳这些肥猪的。
窗口是用于在接收端和发送端之间动态反映接收端读缓冲大小的变化，它的初始值就是读缓冲区设定的值，单位是字节，这个数字在包头的位窗口大小字段中传递，最大字节，如果嫌不够大，在选项中还有一个窗口扩大的选项可供选择。
为什么叫窗口，一窗一风景，英文世界很现实，境界也就到级了，这与中华文明一沙一世界，一花一天堂的差距甚大。再直观一些的类比就是你拿着一个放大镜，在的军用地图上顺着一条路苦苦寻找东莞某镇，放大镜的范围就是我们说的窗口。
概括而言，窗口的作用是量化接收端的处理能力，调控发送端的传输节奏，通过窗口的伸缩，可以自如的调节发送端的数据发送速率，从而达到对接收端流量控制的目的。
师傅三藏曾经对悟空说：你想要啊？你想要说清楚不就行了吗？你想要的话我会给你的，你想要我当然不会不给你啦！不可能你说要我不给你，你说不要我却偏要给你，大家讲道理嘛！现在我数三下，你要说清楚你要不要，嗯，说清楚最重要。
         滑动窗口
客户端和服务器在链接建立的三次握手过程中，会根据各自接收缓冲区大小通告对方窗口大小，接收方根据自己接收缓冲区大小初始自己的“接收窗口”，发送方根据对端通告的窗口值初始化一个对应的“发送窗口”，接收窗口在此端的接收缓冲区上滑动，发送窗口在彼端的发送缓冲区上滑动。因为客户端和服务器是全双工，同时可收可发，故我们有两对这样的窗口在同时工作。
既然是滑动窗口，就意味着可以滑动、伸缩，【图十一 窗口边沿移动】展示了这些情况，注意协议栈规定窗口左边沿只能向右滑动，且的确认模式也在机制上禁止了窗口左边沿向左移动。与窗口滑动相关术语有三个：
        窗口左边沿向右边沿靠近称为窗口合拢，发生在数据被发送和确认 时。如果左右边沿重合时，则形成一个零窗口，此时发送方不能再发送任何数据；
        窗口右边沿向右移动称为窗口张开，也有点类似窗口向右侧横向滑动。这种现象发生在接收方应用层已经读取了已确认过的数据并释放了接收缓冲区时；
        窗口右边沿向左移动称为窗口收缩，强烈建议避免使用这种方式；

【图十一 窗口边沿移动】
我们再来看看滑动窗口与缓冲区如何结合使用。假设一个客户端设置了个单位的读缓冲区，编号是  ，服务器也相应的设置了个单位的写缓冲区，编号是  。在链接建立的时候，客户端会把自己的读缓冲大小通告给服务器，此时在客户端和服务器就维护了一对收发窗口。在【图十二 服务器发送窗口示意】展示了服务端发送缓冲区和其上的滑动窗口，其中大的黑色边框就是著名的滑动窗口。

【图十二 服务器发送窗口示意】
发送缓冲和发送窗口一共区隔出四个部分：
        已发送并收到确认的数据即已成功到达客户端，单元格边框以粉色标识；
        已发送还未收到确认的数据即发送但尚未能确认已被客户端成功收到，单元格边框以蓝色标识；
        处于发送窗口中还未发出的数据即对端接收窗口通告还可容纳的部分，单元格边框以绿色标识；
        处于发送窗口以外还未发出的数据即对端接收窗口通告无法容纳的部分，单元格边框以黄色标识；
为了更好的理解滑动窗口的变化过程，可以观察【图十三 滑动窗口变迁示例】，它向我们展示了一个服务器向客户端发送数据时读写窗口的变化过程：

【图十三 滑动窗口变迁示例】
        客户端通告了一个字节的窗口并在自己的读缓冲区初始化该窗口，服务器在它的写缓冲区初始化了这个窗口；
        服务器发送字节到客户端，服务器发送窗口此时包括了两部分，字节为等待确认的数据、字节为等待发送的数据，窗口大小为字节不变；
        客户端收到字节数据，放入接收缓冲区，此时应用层马上读取了头字节，接收窗口因此调整为    字节，接收窗口先合拢，然后张开。客户端回复确认收到字节数据，并且通告接收窗口调整为字节；
        服务器收到客户端的确认，发送窗口也先发生合拢，随后根据客户端通告的新接收窗口大小，重新调整发送窗口，此时发送窗口又张开至字节；
        服务器发送字节到客户端，服务器发送窗口此时包括了两部分，字节为等待确认和字节等待发送的数据，窗口大小为字节不变；
        客户端收到字节数据，放入接收缓冲区，此时应用层又读取了头字节，接收窗口因此调整为    ，接收窗口先合拢，然后张开。客户端回复确认收到字节数据，并且通告接收窗口调整为字节；
        服务器收到客户端的确认，发送窗口也先发生合拢，随后根据客户端通告的新接收窗口大小，重新调整发送窗口，此时发送窗口又张开至字节；
        服务器发送字节到客户端，服务器发送窗口此时仅包括一部分，即字节等待确认的数据；
        客户端收到字节数据，放入接收缓冲区，接收窗口因此调整为  ，接收窗口合拢为。客户端回复确认收到字节数据，并且通告接收窗口调整为字节；
     服务器收到客户端的确认，发送窗口也发生合拢，随后根据客户端通告的新接收窗口大小，重新调整发送窗口，此时因为接收窗口为，发送窗口保持合拢状态；
提升吞吐量，最佳状态是在流量控制机制的调控下，使得发送端总是能发送足够的数据报文填满发送端和接收端之间的逻辑管道和缓冲区。其中逻辑管道的容量有专门的学名叫  ，带宽时延乘积， = 链路带宽  ，在一个高带宽低时延的网络中，包头中的位窗口大小可能就不够用了，需要用到窗口缩放选项，在中定义，有兴趣可以研究一下。
猪场老板解读：滑动窗口是从养猪场到买家临时猪圈的出入闸门，猪场养殖场这道出闸门叫发送窗口，买家临时猪圈那道入闸门叫接收窗口，为了不让买家的临时猪圈爆满溢出无法签收新来的肥猪们，进而导致猪场白送一趟货，猪场老板必须要等买家通告自己空闲槽位数量后才可进行生猪发货操作，这个槽位数量就是窗口大小，槽位减少或增加，受到猪场发货速率和买家屠宰部门提货速率的共同影响，表现出类似窗口合拢或张开的滑动状态。我们期待的最佳状态就是高速路上跑满欢快的车队，临时猪圈住满幸福的肥猪。
三藏对小牛精说：所以说做妖就像做人，要有仁慈的心，有了仁慈的心，就不再是妖，是人妖。哎，他明白了，你明白了没有？
④　调大 初始值
将 初始值设为。
为每一个报文段都设定了一个定时器，称为重传定时器，当超时且该报文段还没有收到接收端的确认，此时就会对该报文段进行重传。当链路发生超时时，意味着很可能某个报文段在网络路由路径的某处丢失了，也因此判断此时网络出现拥塞的可能性变得很大，会积极反应，马上启动拥塞控制机制。
初始值设为，这也是目前 版本中协议栈的缺省值，在链路传输过程中，协议栈会根据动态重新计算，以适应当前网络的状况。有很多的网络调优方案建议把这个值尽量调小，但是，我们开篇介绍移动网络的特点之一是高时延，这也意味着在一个比较大的网络上传输数据时，如果初始值过小，很可能发生不必要的重传，并且还会因为这个事件引起协议栈的过激反应，大炮一响，拥塞控制闪亮登场。
猪场老板的态度是什么样的呢：曾经有一份按时发货的合同摆在我的面前，我没有去注意，等到重新发了货才追悔莫及，尘世间最痛苦的事莫过于此，如果上天能给我一个再来一次的机会，我希望对甲方说耐心点，如果非要给这个耐心加一个期限的话，我希望是一万年。
⑤　禁用快速回收
快速回收是一种链接资源快速回收和重用的机制，当链接进入到_状态时，通常需要等待的时长，但是一旦启用快速回收，则只需等待一个重传时间后就能够快速的释放这个链接，以被重新使用。 的协议栈提供了一组控制参数用于配置端口的快速回收重用，当把它们的值设置为时表示启用该选项：
        __ = 
        __ = 
        _ = __启用时必须同时启用本项，反之则不然，用于计算，在报文头部的可选项中传输，包括两个参数，分别为发送方发送报文时的时间戳和接收方收到报文响应时的时间戳。系统和移动设备上的、都缺省开启了此选项，建议不要随意关闭
以上参数中是_的缩写，_与层的链接关闭状态机相关。下面我们看看_是谁，从哪里来，往哪里去。
接 《 海量之道系列文章之弱联网优化 四 》常见支持开发  的第三方语言

 语言         

 语言

 语言 


怎么用  开发  程序
 其实我们最主要解决的就是下面几件事情：

在   中安装  解释器

搭建  和  通信的桥梁

如何配置工程并开发


在   中安装  解释器

 开源了一个可以嵌入到  工程中的  编译脚本，具体位置在这：

默认是使用   编译 _、、、、 共  个版本，然后打成一个臃肿包，可选  或者
如果真的要用于生产环境的话，只要把  中的
=_    
修改 = 
我们只需要支持  和  即可， 可以兼容 所以可以让包小一些。
 解释器编译
 到  目录，设置编译参数，直接编译。我们这只需要  版本，所以直接   即可。

 解释器
如果编译出问题，可以直接下载编译好的版本：


搭建  和  通信的桥梁
 是一个连接  和  的桥梁。
首先，我们需要安装一下：
打开  终端运行下面命令   
 
 写  语法 
调用  的方式和以前  直接的写法很像
方法名不使用，而是使用_   如： 代码：   
 代码：_ 
不能使用 ， 里面使用  代替 如： = _   

 可支持  插件功能
、 内嵌   可实现  下发插件能力。
、 内嵌  可实现  下发插件能力。
、 如果内嵌  解释器与  通信框架，利用   同样可以下发  文件来实现下发插件能力。
 开发  总结
、没有  语法高亮  的支持 ， 系统库方法名较长开发者必须熟记各名方法名，这无疑给开发增加难度。
、 解释器过大生成的只有  和  的  就已经有  了；相比较而言， 的解释器就只有 。
、技术支持  没有任何官方文档；开者过程出现一些  框架自身的 ，无人解决。 
一个可以编译执行的 
运行结果如下：年月，腾讯正式于全平台上线了《龙之谷》手游，次日冲到了 畅销排行第二的位置，并维持到了现在。上线当日百度指数超过万，微信游戏平台数据显示预约数多万，而据内部人员透露当日新进用户，这就是《龙之谷》手游在安卓平台上所取得的成绩。
较高的市场期待让腾讯测试团队对《龙之谷》手游的测试倾尽全力，面对“经典”和盛大游戏一贯口碑，腾讯测试团队对游戏服务器进行了严格的压力测试，上线后服务器稳定的表现也证明了测试团队的用心没有白费。
本文记录了《龙之谷》手游压测过程中的点点滴滴，希望给其他手游的压测提供思路、方法和工具的借鉴。
一、项目背景
测试需求产生
《龙之谷》手游初期性能并不好，无法同时支持大量玩家同时进行游戏，存在卡顿、无法登录、掉线等一系列性能问题。无论从玩家流失率的降低，还是游戏体验的提升，针对该游戏的性能测试迫在眉睫。
技术难点
为了产生足够的服务器压力，《龙之谷》手游测试团队选择与 腾讯合作，使用了其服务器性能测试专家模式的代码开发，产生与客户端行为相似的机器人对游戏服务器产生压力，并且有针对性的配置机器人的行为用于测试容易产生问题的场景，可视化的获取性能数据后进行分析。
由于机器人侧需要模拟客户端的逻辑向服务器进行发包，所以必须理解其游戏协议并融入腾讯测试框架中，在腾讯专家的帮助下，使用针对 协议的代码模板自动化生成工具，成功实现模拟客户端的机器人开发，并产生最高每秒并发上万的压力。
另一方面，由于游戏比较重度，压测的场景选择与用户的行为分析也成为难题。在专家的建议下，通过分析删档测试时服务器各协议频率数据，分别按协议比率的多少、处理时间长短、筛选出待测的场景与重点协议。主要针对登录、好友、交易所、主城、语音、单人、英雄战场、赛马、世界、在线副本以及数据库等进行了重点调试及压力测试。
二、实现方案
测试的目标
容量测试：
√  单服并发用户数：人
√  各协议响应时间：秒
√  事务成功率：
稳定性测试：
综合场景压测小时无问题，关注各系统资源稳定性
关键场景压力测试：
√  登录、主城、世界等
√  各协议响应时间：秒
√  事务成功率：
测试前的分析

一般压测模型由三部分组成，机器人、服务器和数据库，游戏服务器主要是优化热点游戏逻辑、协议栈参数、系统网络参数、同步机制等。数据库是优化语句，优化索引，优化数据存储等。机器人部分由平台自动分配压力机，如未产生明显，无需进行调优。
在架构分析之后，需要构建机器人模型，模型构建方法一般是根据研发打点数据，统计在一段时间内，删档服各单个协议总数与耗时并计算压力值与百分比：

示例数据如下：


 删档服不同时间点各单个协议总数与耗时并计算压力值与百分比示例
需要注意的是，除了关注占比靠前的协议进行调试，另外需关注平均耗时较长的协议中逻辑是否存在优化空间，因此该类耗时较长的协议也在测试范围之内。
在获取模型并开发完机器人之后，可以通过腾讯服务器性能测试产生压力，通过其提供的网卡性能图中包量和流量的分析来判断压力机器人模型是否有效反应了真实玩家的行为。


主要的测试功能
● 登录、创建角色、进主城、新手引导压测
● 主城移动、聊天、做任务、装备升级压测
● 好友操作、技能升级、副本战斗、世界压测
● 、、天空竞技场、活动压测
● 组队、购买物品、抽宠物、交易所、公会压测
● 针对以上场景的综合压测
测试中遇到的问题
类型一：单协议场景支持并发过低，该类场景集中触发时，会发生同服玩家卡顿、无法登录游戏、掉线等问题。如登录、技能升级、装备强化等。
类型二：部分热点场景如主城、世界支持人数不足，易发生玩家集体卡顿、掉线等问题。
类型三：其他在高并发长时间运行下容易出现的问题：缓冲区不足、进程崩溃、内存泄露等。
优化的方法
类型一：单场景问题排查
在机器人开发完毕后，可以通过腾讯服务器性能测试专家模式中的单场景测试，逐步增加场景压力，若发生：服务器进程资源耗尽、回复消息过慢、回复消息失败，则表示服务器到达瓶颈，此时一般可通过系统工具、、、等排查热点逻辑，查看是否存在优化空间，或从逻辑机制上解决。

热点逻辑排查业务名已隐去
图中展示了简单场景中，请求无法满足并发量的要求，遇到这种情况，一般可以使用排查服务器热点逻辑进行优化。

类型二：容量测试问题排查
综合场景一般包括之前筛选出的所有场景，将所有玩家按照一定比例比如在主城，在副本战斗，该比例一般可以通过不同场景下的心跳包频率比例看出。
主要会遇到的问题为：游戏卡顿、玩家掉线等，该类问题一般为客户端或服务器各进程资源遇到瓶颈所致。排查方法与单场景类似，不再过多描述。
__
各场景的数据表现事务名已隐去
类型三：稳定性测试问题排查
稳定性测试中易出现服务器宕机、内存泄露等情况，针对服务器宕机，一般通过分析文件，并结合所测场景的机器人行为进行分析宕机原因。

通过查看稳定性测试中的内存变化曲线，可以判断服务器内存是否稳定或泄露，若发生泄露，一般可通过内存检测工具，如等对服务器进程进行排查。

三、最终效果
测试效果
解决各种宕机、卡顿、掉线问题：
测试期间共发现并修复各类卡顿、宕机、掉线、无法进行游戏等问题余个，同时准确估算了线上玩家所产生的压力，为最终服务器的部署及稳定运行提供了性能保障与数据支撑。
解决需要多人参与、团战等场景的测试问题：
机器人程序可以用于需要大量用户参与的测试场景，进行自动化测试及验证该类场景是否可以在一定压力下稳定运行：如世界战，公会战、跨服擂台赛等。
录像效果
主城移动测试：
世界测试：
英雄战场多人对战测试：
“外网问题无小事”，所幸这次《龙之谷》手游上线过程中没有出现常见的面对开服压力而服务器崩溃的事件，在这次的手游测试过程中也可以感受到游戏发行、渠道和对服务器承压情况越来越重视。
然而目前市场上还没有针对游戏的服务器性能检测工具，无论是开源还是商业软件都不能很好的满足游戏的专项测试需求，与此同时受限于开发周期短以及人力的问题，中小型往往采取编写模拟机器人进行简单的压测，测试的覆盖面窄，无法保证并发请求，造成潜伏的问题遗漏到线上。
此次腾讯测试团队正是利用腾讯的服务器性能测试功能实现模拟机器人的协议配置，最终实现了《龙之谷》手游的平稳上线。
目前腾讯的服务器性能测试功能已经开放对外，通过基于真实业务场景和用户行为进行压力测试，帮助游戏开发者发现服务器端的性能瓶颈，进行针对性的性能调优，降低服务器采购和维护成本，提高用户留存和转化率。
 体验地址：
如果对使用当中有任何疑问，欢迎联系腾讯企业：
商业转载请联系 腾讯获得授权，非商业转载请注明出处。原文链接：

相关推荐腾讯手游如何提早揭露游戏外挂风险？服务器压力测试的一次优化历程直播应用的后台服务器性能测试实践作者：陈帅
团队：腾讯移动品质中心
一、背景介绍
流畅度测试，是笔者设计整个框架的最初的痛点，前述的耗电、内存等属于框架拓展功能。
在本框架之前，部门一直使用工具来获取流畅度数据，并使用量化模型一种收集丢帧，并通过合适算法得到最终分数的评估模型评估流畅度，使用页面驱动的自动化来编写用例。但执行了多轮测试后，发现存在一些问题：
、原方案测试流畅度依赖于手机，如果需要对某款手机做专门评测，存在局限；
、由于是借助方案收集数据，驱动中需要先拉起被测应用，以确保拿到被测应用的，然后拉起工具开始收集数据，再拉起被测应用开始测试。这样的流程将被重复多次，导致进行一轮性能测试的周期在小时以上；
、方案为页面驱动方案，特点是以用户点击为分界点，将流畅度数据拆分成不同页面的数据；
、驱动方案主要是点击文本，在自动化中，点击是需要经过查找、点击，这样会导致每次点击的间隔并不一致。流畅度数据建立在大样本之上才更为准确反复执行被测场景，但该框架对这种用例逻辑的支持力度不够。
二、原理分析
工具是腾讯开源的用于测试各类性能数据的工具，分析下它收集流畅度数据的原理。如下图，所做的工作有部分：
、将系统丢帧告警的阈值从修改为。这个只能在手机上才操作有效；
、：收集系统中打出的丢帧日志，并过滤掉非被测应用的日志，将被测应用的丢帧到一个  中；
、：控制时间间隔为，将丢帧数分配到各个秒中去，统计出各秒的值。如果出现某一秒的值超过，需要做前序值修正；
、输出值序列到文件或中。

图一输出数据原理
简而言之，在流畅度上，其实就是将丢帧换算成值给到测试人员了。至于为什么要用手机才能测试，是因为系统为了减少无必要的日志，将___值默认设置为。导致线程时，只要丢帧不高于帧，就不会通过告警。

图二 源码
三、数据收集
借用工具，既限制了测试场景，又将测试操作复杂化了，那是不是可以不借用工具，收集到数据呢？答案是肯定的。
使用收集丢帧数据。
命令：    
日志行示意如下，其中包括信息：
该丢帧信息属于哪一秒；
该丢帧信息属于哪一个进程；
本次丢帧具体数值为。
=                 。
这些信息有什么用呢？
知道了丢帧属于哪一秒，我们可以摒弃自己来控制时间间隔，再丢帧数据的方案。换成新方案：直接将手机系统吹按的不同秒的丢帧数据到一起，方法更为简单；
该丢帧数据的进程信息，只统计被测程序的流畅度；
被测应用插桩替代手机方案。
执行命令是从系统全局上将的___修改为。而使用如下图的反射方式，可以将直接将被测应用的___修改为。

图三反射修改___
需要注意的是，方案收集到的日志行可能是如下图四的序列。有以下三种情况：
时刻的丢帧是：   = ，所以值为；
时刻无丢帧，所以值为；
时刻的丢帧是：，但同一秒内最多丢帧个，所以需要对前序时刻的值做修正，得到时刻为，时刻为。

图四丢帧日志序列
根据上述三种情况的逻辑，可以得到如下图五，计算值的核心逻辑。至于如何从日志行中取出时间、、 值，无非是正则表达式，不再赘述。

图五值计算核心逻辑
四、自动化用例
本篇需要特意提一下自动化的逻辑，需要注意两个点：
、主路径循环执行多次，保证收集到的场景性能数据有较大样本，避免数据波动；
、如下图六，__的逻辑是，第一次点击时保存该按钮的绝对坐标信息，后续点击都使用绝对坐标进行点击。使用非坐标点击，由于需要进行查找，和手机通信，所以操作间隔 = 用例逻辑时长  查找控件时长  通信耗时。而使用坐标点击，就可以做到自己控制操作间隔，尽量做到每次测试的流畅区间卡顿区间波动较小，数据更加稳定。

图六用例逻辑
五、数据使用算法
拿到较大样本的数据后，可以有多种方案体现在报告中。
、表格体现
如下值大的范围占比越高，代表流畅度性能越好。

图七表格示意
、柱状图体现
优点在于更为直观，可以看到上部的深蓝色和绿色区间越长，代表流畅度越好。

图八图形示意
上述数据处理的算法，可以直接使用的公式来搞，也可以使用如下图的代码处理。

图九获取测试报告结果的算法
、打分评估
首先需要介绍两个概念：流畅区间、卡顿区间。用户使用一个，对于静态页面，一般流程是看一个页面，然后点击某处，等待响应，再接着看，以此循环。在此过程中，只有“点击某处”会触发新的线程操作，有可能导致卡顿，这个卡顿的时间区域，可称之为卡顿区间。而没有用户操作的区间则称之为流畅区间。
加入获取到的流畅度数据样本中有秒的数据，其中可能只有秒的卡顿区间数据。如果直接将组数据取平均值，会发现秒卡顿完全被组流畅抹平。为了提高卡顿区间占比，可以加快操作速率，但这就不是真实的用户场景了。可以从另一个方向思考——算法：为了弱化流畅区间的数据，执行算法以下三步：
每五秒取一个最小值，获取一个最小值序列；
将最小值序列中的每个值，使用抛物线函数将值对应到分值 分，这是为了让丢帧多的值打分低，从而突出丢帧高的点；
最后取分数平均值。

图十换算评分方程曲线
最终得到的报告：

图十一评分对比
算法代码：

图十二换算评分算法代码
总结，流畅度测试三要素：
驱动需要严格控制流畅区间、卡顿区间的占比，取决于用户操作密度；
数据收集，样本要足够；
报告使用的算法或图表，要更为科学些，不能直接用平均值了事。
搜索微信公众号：腾讯移动品质中心，获取更多测试干货！作者：闫燕飞

背景
是基础架构部开发的高性能、高可用消息中间件，其主要用于消息传输、网站活动追踪、运营监控、日志聚合、流式处理、事件追踪、提交日志等等需要高性能的场景，目前已经上线腾讯云。完全兼容现有的协议，使现有用户可以零成本迁入。基于现有的进行了扩展开发和优化，为了方便用户理解本文也将对的实现原理进行较为详细的介绍。
原理
    诞生背景
是一种高吞吐量的采用发布订阅模式的分布式消息系统，最初由采用语言开发，用作的活动流追踪和运营系统数据处理管道的基础。现已成为开源项目，其主要的设计目标如下

以时间复杂度为的方式提供消息持久化能力，即使对级以上的数据也能保证常数时间复杂度的访问性能。注其实对于写的确保证了的常数时间性能。但对于读，是分片级别对数时间复杂度。
高吞吐率。力争即使在非常廉价的商用机上也能做到单机支持的消息传输能力。
支持 间的消息分区，及分布式消费，同时保证每个内的消息顺序传输。注其实本身实现逻辑并不做该保证，主要的算法是集中在消费者端，由消费者的分配算法保证，详情下面会介绍。
同时支持离线数据处理和实时数据处理。
支持在线水平扩展，的水平扩展主要来源于其分区的设计理念。

    主流消息队列对比












模式
发布订阅
发布订阅
传统发布订阅
发布订阅


同步算法

同步双写




分布式扩展
否
支持
支持
支持


堆积能力
磁盘容量
磁盘容量
磁盘水平扩展
磁盘水平扩展


性能
中
高
高
很高


可靠性
一般
一般
极高
一般


持久化
内存硬盘
磁盘
磁盘
磁盘



    架构
    整体架构图
 
    相关概念介绍
    集群
系统强依赖的组件。其存储了核心原数据 如信息配置、信息、 消费分组等等，相当于充当了的配置管理中心 。 的选举如选举、选举、 选举等等，同样也会借助于。
    
协调器模块主要用来管理消费分组和消费充当中介管理消费者并从消费分组中选举出一个消费者作为然后将消费分组中所有消费者信息发往该由该负责分配。该模块为 版本新加入的新的模块集群中可以存在多个协调器分别管不同的消费分组，提高整个系统的扩展能力，主要用于解决之前消费者 消费者都需要通过与连接进行相关的选举，导致压力大、惊群及脑裂问题。
    
模块主要负责 选举、监听创建及删除事件然后下发到指定进行处理等功能，整个集群中只能有一个，利用的临时节点特性来进行选举。
    
消息缓存代理，集群包含一个或多个服务器，这些服务器被称为，负责消息的存储于转发，作为代理对外提供生产和消费服务。
    
消息主题类别，逻辑上的概念，特指处理的消息源的不同分类，用户可以根据自己的业务形态将不同业务类别的消息分别存储到不同。用户生产和消费时只需指定所关注的即可，不用关注该的数据存放的具体位置。
    
物理上的分组，在创建时可以指定分区的数量，每个是一个有序的队列，按生产顺序存储着每条消息，而且每条消息都会分配一个的自增长的有序相当于消息。是整个可以平行扩展的关键因素。
    
副本，级别的配置，可以理解为消息的副本数。 版本加入的概念，主要目的就是提高系统的可用性。防止意外崩溃导致部分不可以服务。
    
  ，用来维护跟上数据的列表当崩溃后，优先从该列中选举
    
 生产者，采用方式进行消息发布生产。可以通过与连接获取信息 信息等等元数据，然后再与交互进行消息发布。在此过程中相当于一个配置管理中心类似于 提供相关的路由信息。采用直接向暴露信息存在以下两个非常大的弊端：

属于整个系统的核心结构，其性能直接影响了整个集群的规模，故当暴露给生产者过多的生产者会导致性能下降最终影响整个集群的规模和稳定性。
存储着的核心数据，若公开暴露出去则容易受到恶意用户的攻击，最终导致集群不可服务，故非常不建议服务提供方向使用者暴露信息。

正因为存在上面的问题，也提供了 ，通过该生产者可以获取到信息、信息以及下的信息，然后生产者在访问指定的进行消息生产，从而对生产者隐藏了信息使的整个系统更加安全、稳定、高效。
    
消费者，采用方式，从端拉取消息并进行处理。当采用订阅方式一般通过使用   或 来进行订阅订阅感兴趣的时，必须属于一个消费分组，而且保证同一个的一条消息只能被同一个消费分组中的一个消费，但多个消费分组可以同时消费这一条消息。
其实本身不对这个同一个的一条消息只能被同一个消费分组中一个消费者消费做任何保证，尤其是在版本之前 根本都没有消费分组的概念也没有消费概念，只是提供 供使用者去拉取消息，至于是谁来取取多少次其根本不关心，该保证是由消费者内部的算法自己完成。
在版本之前消费分组只是消费者端的概念，同一个消费分组的所有消费者都通过与连接注册，然后自主选择一个一个消费分组一个，再通过该进行分配分配算法默认是也可以配置成 甚至自己实现一个算法非常的灵活。所有消费者都按照约定访问分配给自己的，并且可以选择将消费保持在或自己存。该方式会暴露从而导致存在和暴露给一样的问题并且因为任何一个消费者退出都会触发事件，然后重新进行从而导致压力非常大、而且还存在惊群及无法解决的脑裂问题，针对这个问题版本含之后 添加了协调器模块。
但模块也未进行任何分配算法相关的处理，只是替换了的一些功能，充当了中介将之前消费者都要通过自己选择 变成统一和通信，然后由选择，然后将同一个消费分组中的消费者都发送给消费者，由负责分配。另一个方面就是当前多了管理的功能，消费者可以选择将提交给然后由进行保存当前默认情况下会将信息保存在一个特殊的默认名称__中，从而减少的压力。消费分组中的分配具体可以看下一个小结中消费分组的相关说明。
     
消费分组，消费者标签，用于将消费者分类。可以简单的理解为队列，当一个消费分组订阅了一个则相当于为这个创建了一个队列，当多个消费分组订阅同一个则相当于创建多个队列，也变相的达到了广播的目的，而且该广播只用存储一份数据。 为了方便理解，通过下面的图片对消费分组相关概念进行讲解。
 

一个消费分组可以订阅多个，同理一个可以被多个消费分组订阅
中的只会分配给同一个消费分组中的一个消费者，基于这种分配策略，若在生产消息时采用按照消息进行将同一个用户的消息分配到同一则可以保证消息的先进先出。正是基于这种分配策略实现了消息的先进先出。
同一个消费分组中，不同的消费者订阅的可能不一样，但的分配策略保证在同一个消费分组的只会分配给订阅了该的消费者，即消费分组中会按照再划分一个维度。以上图为例 中和同时订阅了 所以将下面的  四个均分给和。同样 中只有订阅了故中的两个只分配给了未分配给。

    
消息，是通信和存储的最小单位。其包含一个变长头部，一个变长，和一个变长。其中和是用户自己指定，对用户来说是不透明的。的详细格式下面会有介绍，这里先不展开说明。
下一篇：《高性能消息队列  核心原理介绍下》目前  产品是基于应用层面的负载均衡，所以要实现业务感知并自动切换  还得使用弹性网卡这一个特性来进行支持，我们需要一些特殊的手段来支持当然后续弹性网卡特性会陆续支持。
由于之前的文章都传递了一个错误的观念就是使用  作为高可用群集的 ，这里正式给大家道歉，当然这是属于我个人名义发布的博客，在做个人实验研究出错是时长的事儿，借助这个事儿也发现  弹性网卡  不支持  切换这事儿，并且跟对应的   好好聊了一个下午，最终使需求落地，将在近期内进行更改，，我们先来看看在原有架构上增加这个  机后到底实现了什么，如下图所示：

但是需要强调的是，本身      就属于高可用群集，其检测机制非常完善，可以实现无感知迁移：
、由于加了  机，判断阈值为 次，所以低于 级别的故障还是有有所影响，那么做  群集的高可用作用就会大打折扣。
、由于加了前端  机， 机作为逻辑判断的机器节点，理论上并不会有很大的故障几率，但是仅仅是单一的  作为支撑，这里存在单点故障风险。
所以，综上所述，若要将此文所涉及的架构用于生产环境，还需要考虑将脚本扩展及考虑容灾，其次目前该脚本只支持两个节点，所以节点的环境需要定制当然对于有  运维环境的朋友这个改造几乎轻而易举。
下面让我们来看看如何实现吧：
、    首先我们要准备好几个脚本已上传到  ，地址为：  ，分别是：
 
、    先根据官网指引给单独的机器槽点部署好  环境建议使用   ：
、    使用前请记得修改公共加密、 两个脚本都需要修改，公共加密方式可参考：
 
、     是用来判断当前弹性  在哪个网卡上，可以传参数进行测试，方法：

、    而  是用来执行迁移  ，而需要改动的就是  ：
以下为脚本内容：
 
    
        =    
         这里为群集 == 
             
                   
        
             
                   
    
         
               
         
 ____ == ____
    =这里为群集 
      == 
        =这里为第一个节点网卡实例
          == 
            =  对应 群集 第一个节点网卡实例第二个节点网卡实例 
             ° _  
        
            = 对应 群集 第二个节点网卡实例第一个节点网卡实例 
             ° _  

以下为检测需要设置的：
    =数据库端口
     
      == 
        =这里为第一个节点网卡实例 
          == 
            = 对应 群集 第一个节点网卡实例第二个节点网卡实例 
             ° _  
        
            = 对应 群集 第二个节点网卡实例第一个节点网卡实例 
             ° _  
、该脚本为第一版，也是抛砖引玉，考虑到   弹性网卡自动切换机制为公有云必然实现之路，这里的脚本只作为过渡用，目前仅支持个节点如需要多个节点判断可以自行修改使用冒泡排序，设置完成后，需要在  服务器上运行一个常驻脚本来调用两个  脚本来进行轮训，实测 切换一次，丢包低于个：

自此自动巡检完成：
 
切换  群集  丢包测试，切换次，丢包三个：
 
切换群集  丢包测试，切换次，丢包零个：

、    使用  连接  实例完成，检查状态：


相关推荐数据库的高可用性分析【腾讯云的种玩法】在的  下搭建一个适用于个人的  环境今天这个教程给大家带来邮件服务器的搭建，可以创建自己的域名邮件帐号，来发送和接受邮件，希望大家喜欢。
一、前期准备：
、域名：我的是
、腾讯云服务器一台：地址是，   数据中心版。
、邮件服务器搭建软件包下载地址：
其中包含：

  功能强大，而且是免费的；

     、、集成的服务器环境；

   用于在界面上收发邮件用写成的；

  __ 系统支撑环境有的可以不用安装。
 、前期配置准备我这里用的是腾讯云域名解析服务：
首先使用域名解析服务，添加一条记录，主机记录为，记录值为；再添加一条记录，主机记录为记录值为；再添加两条记录，主机记录分别是、，记录值都为。 要用其它邮箱给这个发，必须要配置
二、开始安装
、首先安装__做为系统支撑环境。
、安装。一路就可以了，不用修改数据。这个软件安装好后可以修改语言为中文，还要切换至在线状态。
、安装
在第三个界面有两个选项询问你是要使用内置的数据库还是要使用外置的数据库，如图所示我们点击第二个选项选择，外置的数据库就可以了。内置的也可以，但是这样不好使用

设置你的的服务密码自己随便写，但是要记住，登录的时候用

我这里设置为，然后继续安装。
设置数据库

我们选择创建一个新的数据库，不要默认的。

数据库种类选择这里面自带的数据库是；

填写数据库的配置信息：由于是在本机上安装的数据库，就填，不是的话就填数据库的地址，端口号默认即可，然后填写数据库名称，这里填写的一定要是数据库没有的名称，不然会有冲突导致数据库创建失败，最后配置数据库的用户名和密码新建的数据库没有密码的可以不填。

选择附加服务如果安装了__ ，就选这个，没有安装的选择上图所示的

在这里安装会报错，说缺少的驱动库，我们需要在的安装目录下复制到上述的目录下。 不知到的请百度。找不到的也百度。
接下来就可以安装完成了。
打开我们刚安装完的软件，到如图所示的界面

选中上面的信息点击连接并输入我们刚开始安装的密码

如图所示我们就登录到了管理界面里面了全是英文的英文不好的可以选择汉化
首先点击域名添加添加一个域名

域名添加好以后，就开始添加我们需要的邮件帐号了。

可以设置自己需要的内容，其它的选项也可以试这设置一下，看看是什么效果，这里我就不多说了。
下来安装邮件服务器的网页管理界面。

首先复制到我们的的目录下 这个目录在我们刚才安装的邮件服务器目录中
然后开始配置目录下的文件。
首先重名名为，修改
_ = _ = 其中地址为你服务器的地址，修改语言为中文，然后保存。
这样我们输入我们的域名地址\ 就可以访问我们的网页界面了。
、搭建收发邮件的网页版界面
将我们网页版的客户端 直接复制到的目录下，结果如图所示

然后开始安装我们的客户端
在浏览器下输入 开始按照提示一步一步安装

输入我们数据库的配置信息，然后在界面上测试安装完成后继续安装

会提示我们要删除以前的的安装目录防止别人破坏。到这里就说明安装完成了
安装完后我们就可以登录到
首先修改一下系统配置主要是修改系统语言，然后就可以用创建的用户收发邮件了这里是系统的管理员界面，用户是密码是安装时候设置的。
三、测试
配置完以后就可以开始登录 这个地址进入邮箱里开始收发邮件了，大家赶快感受一下吧

如图是我用我的邮箱给我一开使新建的邮箱帐号发送的测试邮件。

如图是我用我的邮箱给我邮箱发送的测试邮件。
大家是不是很喜欢尼，如果喜欢就赶快注册个服务器，域名来感受下吧，如果有什么问题可以向我提问，我会第一时间回复的。

相关推荐
【腾讯云的种玩法】发送邮件设置
如何搭建一台服务器
高性能高稳定的弹性伸缩计算服务作者：薛梁

   现场可编程门阵列，作为  领域中的一种半定制电路而出现已有  年的历史了，它既解决了定制电路的无法改变功能的不足，又克服了原有可编程器件门电路数有限的缺点，可应用的场景也很广泛。
就在  年  月  日，腾讯云推出国内首款高性能异构计算基础设施——  云服务，利用云服务的方式将只有大型公司才能长期支付使用的  服务推广到了更多企业。企业可以通过  云服务器进行  硬件编程，可将性能提升至通用  服务器的  倍以上。同时，与已经深入人心的高性能计算的代表  相比， 具有硬件可编程、低功耗、低延时的特性，代表了高性能计算的未来发展趋势。
而在火热的深度学习领域，企业同样可以将  用于深度学习的检测阶段，与主要用于训练阶段的  互为补充， 还可应用于金融分析、图像视频处理、基因组学等需要高性能计算的领域，是这类对效率要求高的行业应用的最佳选择。
基于此， 采访了由腾讯云基础产品中心、腾讯架构平台部组成的腾讯云  联合团队，向读者介绍  的基本原理和设计初衷，应用场景以及它给行业带来的价值。
腾讯云  的开发历史及背后的团队力量
随着芯片制程逼近理论极限，可以预见通用处理器性能提升空间越来越有限。而腾讯自己的业务随着移动互联网的快速增长，数据体量的急剧膨胀，伴随着对这些数据的计算需求也在迅猛上涨。腾讯在  年开始考虑如何解决计算需求的增长，而  作为一种可编程的加速硬件彼时进入了大家的视野。有了解决计算需求的想法后，需要通过实践验证  实际的能力。
腾讯的 、微信业务，用户每天产生的图片数量都是数亿级别，常用的图片格式有  格式、 格式等， 图片格式比  图片格式存储空间小。为节省存储空间，降低传输流量，提升用户的图片下载体验，通常采用  格式进行存储及传输分发，而图片转码所带来的计算消耗需要上万台  机器支撑。自然  开发落地的第一个切入点就是图片转码：将  图片格式转成  图片格式。
在图片转码的实践中， 联合团队取得了  处理延时相比  降低  倍， 处理性能是  机器的  倍，验证了  能进行计算加速的能力，同时也增强了  联合团队的自信心。
图图片转码中  和  延时对比
图图片转码中  和  吞吐率对比
图片转码项目完成后，深度学习映入了  联合团队的眼帘，一方面深度学习需要密集的计算，另一方面深度学习在未来应用上有着巨大的商业价值。深度学习基于深度神经网络理论，用在图片分类的神经网络是其中的一个分支：卷积神经网络。团队使用  对  计算进行加速，增强违规图片检测能力，最终在深度学习的实践中取得了  处理性能是  机器  倍的战绩。
腾讯云  项目实践的结果，见证了  在数据中心里可以提供强大的计算能力和足够的灵活性，来应对数据中心对硬件加速的挑战。经过之前的  实践， 联合团队获得了在数据中心使用  的经验，未来也将在数据中心的计算、网络、存储三个方向进一步探索，重构数据中心基础架构。
云端的数据中心业务日新月异，更需要一种高性能、高灵活的底层硬件结构，所以  联合团队通过云端开放  计算服务，从硬件层面加速云计算在各个场景中的应用，降低企业的使用门槛和成本。
的特点解析
 年  月，英特尔宣布正式停用「」处理器研发模式，未来研发周期将从两年向三年转变。至此，摩尔定律对英特尔几近失效。一方面处理器性能再无法按照摩尔定律进行增长，另一方面数据增长对计算性能要求超过了按「摩尔定律」增长的速度。
 本身无法满足高性能计算应用软件的性能需求，导致需求和性能之间出现了缺口。在新的芯片材料等基础技术没有取得突破前，一种有效的解决方法就是采用专用协处理器的异构计算方式来提升处理性能。现有的协处理器主要有 ， 和 ， 由于其独特的架构拥有其他处理器无法比拟的优势。
   现场可编程门阵列，可以通过软件重新配置芯片内部的资源形成不同功能硬件，就像用乐高积木可以搭出航空母舰或变形金刚一样。因此， 不仅有了软件的可编程性和灵活性，同时又有  高吞吐和低延时的特性。而且，由于有丰富的 ， 还非常适合用作协议和接口转换的芯片。
 在数据中心最大的特点就在高吞吐的同时能做到低延时。 内部的资源都是可以重配置的，因此它可以很容易进行数据并行和流水并行，且易于在数据并行和流水并行之间平衡。而  几乎只能做数据并行。
与  相比， 的可编程性体现出很大的优势。现在数据中心的各种算法每时每刻都在更新变化，没有足够稳定的时间让  完成长周期的开发。比如在一种神经网络模型出来之后开始把它做成 ，也许还未投片生产，这个神经网络模型已经被另一种神经网络模型所替代。不同的是， 可以在不同的业务需求之间做平衡。比如说白天用于为搜索业务排序的机器；在晚上请求很少的情况下，可以将这些  重新配置成离线数据分析的功能，提供对离线数据进行分析的服务。
另外由于  有高速  等丰富的接口，而且能灵活控制实现的粒度和操作数据，因此非常适合进行协议处理和数据格式的转换。比如说  可以很方便的接入以太网数据，并对以太网包进行包过滤等处理。
和 、、 在设计上的区别
图处理器芯片对比
 属于冯·诺依曼结构，任务执行需要经历取指、译码、执行、访存以及写回等过程。 为达到足够高的通用性，其指令流的控制逻辑相当复杂。 使用  单指令多数据流并行等方式进行计算加速。
 在使用时硬件功能模块已固定，无需分支判断等复杂控制逻辑，同时大大降低了访存次数。因此在能效上可以比  高出  到  个数量级。
 是一种专用的芯片，是为了某种特定的需求而专门定制的芯片。 与通用芯片相比，体积小、功耗低、计算效率高、芯片出货量越大成本越低。但是缺点也很明显：开发周期很长，算法是固定的，一旦算法变化就可能无法重用。
而  则是“软硬件一体”的架构，软件就是硬件。 基本原理是在芯片内集成大量的数字门电路以及存储器，用户可以通过烧入  配置文件来来定义这些门电路以及存储器之间的连线，进而得到不同的硬件功能。
就开发难度而言，      。目前主流的  开发语言是硬件描述 ，需要开发者具备一定的相关技能。随着业界 、 等类  高级语言的推进， 的开发难度和周期也会有所改善。
 部署在哪里？与  之间如何通信？
腾讯云的  主要部署在数据中心的服务器中。腾讯云将  芯片加上  内存、外围电路和散热片，设计成  板卡。这种  板卡被安装在服务器的主板上，用户通过网络远程访问服务器，开发调试 ，并用其加速特定业务。
 与  之间是通过  链路通信的。 内部集成了  内存控制器和  控制器。在  芯片内部也用可编程逻辑资源实现了  控制器、 控制器和  控制器。一般通讯分三种情况：
指令通道
 向  芯片写入指令，读取状态。 直接通过  访问到  芯片内挂载的存储器或内部总线。
数据通道
 读写  板卡上  的数据时， 通过  配置  芯片内的  控制器，输入数据的源物理地址和目的物理地址。 控制器控制  卡上的  控制器和  控制器，在  卡上的  内存和  连接的  内存之间传输数据。
通知通道
 通过  向  发送中断请求， 收到中断请求后保存当前工作现场，然后转入中断处理程序执行，必要时会关闭中断执行中断处理程序。 执行完中断处理程序后，会重新打开中断，然后重载到之前的工作现场继续执行。
目前行业面临的问题
在行业内，微软在数据中心使用  架构， 也推出了  的计算实例，那么是不是说明整个行业对  的使用比较广泛呢？实际上， 是个硬件芯片，它本身不能直接使用，也缺乏类似操作系统这样的系统软件支持。长期以来， 行业在数据计算加速方向可以分为以下几个参与方：

芯片原厂： 和 已被  收购提供  的芯片，直供或者给代理商分销。

 提供商：提供各种功能的 ，比如访问  内存的 ，支持  设备的 ，图片编解码的 。一些共同的通用  由芯片原厂提供。

集成商：集成商提供硬件和软件的支持。由于直接用户缺乏硬件设计和制造能力，往往希望集成商提供成熟完善的硬件，并完成的集成，提供驱动和使用方式，方便最终用户的使用。

用户：最终使用者。在数据中心领域，用户一般目的是希望使用  对计算进行加速。


在  行业，芯片原厂并不提供直接使用的硬件板卡，这个工作由集成商完成。由于硬件板卡使用量小和分担设计、生产成本，硬件板卡价格往往高于芯片价格，甚至达到十倍之多。
 提供商因为担心产权泄露，通常不会迅速提供可用的可执行文件网表文件给用户，而是需要签署一系列的协议和法律文件，甚至有的  提供商根本不提供给用户测试的机会。这样就造成最终用户很难得到可用的硬件板卡，更难以及时获得使用最新工艺芯片的硬件板卡，造成用户无法快速对不同进行验证，从而挑选适合自身业务的。另外， 的开发使用硬件描述语言，缺乏软件领域非常广泛使用的框架概念，导致开发周期漫长。一般来说， 开发周期是软件开发的三倍左右。
综上所述的这些问题，决定了云对  行业的颠覆和革命。
腾讯云  平台具体能解决哪些问题
腾讯云  平台解决的是  整个行业的一些问题。 用户比较少，属于一个相对封闭的圈子， 开发门槛高、开源的优质  比较缺乏、芯片价格昂贵等问题一直为大家所诟病。
针对开发者，腾讯云  平台提供了  的底层硬件支撑平台，类似操作系统的部分功能，简化了开发者对底层通用设备的访问，比如  和  这些通用设备，可以使开发者更聚焦到业务功能的开发。
 行业内的  提供者和使用者缺乏一个公开的交易平台和信用保证机制， 交易环节冗长，价格不透明，很难达成交易，获取  后还需要搭建硬件平台来验证  性能，这些都严重影响产品上市进程，经常耗时几个月之久。腾讯云提供了   商店， 开发者和  提供商可以通过   商店为其他客户无偿或有偿地提供   和对应的测试程序。这些  都是基于腾讯云  的标准硬件来开发定制的， 的验证和测试可以很方便地在云平台上完成，一个  的交易可以由几个月缩短到一天之内，提高交易效率，也使得  交易变得更加透明。
针对一些希望使用低延时的高质量计算服务的小型公司而言，可以使用  云计算加速服务，不用耗费大量人力进行高性能计算方面的开发，很简单地就可以把高性能的云计算服务集成到自己的网络平台，达到提升用户体验的目的。比如：低延时的图片格式转换、基于深度学习的图片分类等服务，类似的服务后续还会进一步丰富。
对于学校的  教学而言，以前学校需要为每个学生购买一个开发板卡，有了腾讯云平台之后可以节省学校购买开发板的成本，现在只需要给每个学生申请一个  云平台的账户即可，学生登录上去直接可以根据  进行学习开发即可。腾讯云平台同时会为用户提供便于学习的操作指导和实验课程方案，用户学习的东西更接近企业的实际应用场景，可以很好地跟将来的工作需要对接起来。
此外，大容量的  芯片价格比较昂贵， 一个很重要的原因是  芯片缺少量大的爆款产品，而腾讯云  平台可以聚集大量的客户来使用腾讯的标准  硬件设备，这样会增大该  芯片的供应量，同时也便于芯片厂商降低成本，逐渐缓解  芯片昂贵的问题。
从这些可以看出  云化意义重大，可以推动整个  行业的发展，给  产业链的各方带来收益。
 在互联网业务中的应用优势

图片转码

随着移动互联网的发展，用户每天上传的图片量越来越庞大，公司目前用于图片转码的业务主要有  相册、微信等，而业务中使用的图片格式大都为  格式、 格式等，而图片转码所带来的计算消耗需要上万台  机器支撑。所以  在互联网业务中第一个应用场景就是图片转码： 图片格式转成  图片格式。项目取得了  处理延时相比  降低了倍， 处理性能是  机器的  倍。
为了更进一步提升图片的压缩率，同时随着  高性能编码标准的发展， 的  帧图片压缩率和之前的  等编码标准有了很大的提升， 的  帧图片压缩率和  相比提高  左右，和  相比提高更多，平均能到  左右，因此，无论从下载带宽节省还是后台存储成本降低，以及用户下载图片体验等角度来看， 标准都有很大优势。而采用  的问题在于  的帧压缩计算复杂度非常高，采用  进行转码成本很高，导致很难在业务中全面推广。为了增强图片转码能力，腾讯继续使用  对图片转码进行加速。
经测试，完成  格式图片转成  格式图片，测试图片大小为 ， 处理延时相比  降低  倍， 处理性能是  机器的  倍， 机型单位成本是  机型的 。




图片分类

深度学习近年来在语音识别、图片分类和识别、推荐算法等领域发挥了越来越大的作用。在移动互联时代，为了增强图片检测的处理能力，降低图片检测成本，腾讯使用  对  计算进行加速。
研发团队使用  完成  算法的  模型， 处理性能是  机器的  倍， 机型单位成本是  机型的 。

能让开发者团队更「任性」
对于外部开发者和开发团队来说，首先，腾讯云  提供统一的硬件平台。开发者无需关注  基础设施，免去了重复开发硬件平台面临的问题和挑战，快捷部署，几分钟就可以部署完毕一台全新的  平台。 芯片丰富的逻辑资源可以为开发者「任性」实现功能提供保障。统一的平台也便于开发团队快速弹性扩展硬件平台，从而提高业务容灾可靠性。
其次，腾讯云  提供完备的开发环境，不需要专门人员开发驱动环境。开发语言多样性，，， 满足不同类别的开发人员需求，降低学习开发门槛，简单易用。
再者，腾讯云  提供丰富的  功能，不仅有大量免费  和有偿的  服务，而且交易流程透明、安全、可靠。加速开发者开发进度的同时也为开发团队提供一个将自己开发的  进行交易的平台。
最后，腾讯云  提供专业安全防护。部署到云上，将享受与云服务器同等的云安全基础防护和高防服务。免去传统  数据存储和传输安全所带来的困扰。
可以看到，传统的  开发面临的硬件平台稳定性、开发语言门槛高、调试周期长、驱动软件联合调试等问题都将得到改观，开发者和开发团队能够从繁杂和重复的工作中快速释放出来，有更多的时间和精力投入到创新的工作中去，这将为整个技术研发的氛围增加更多的创新因子，创造更多的价值。
未来， 的行业价值
当前  火爆，得益于  的高密度计算能力以及低功耗的特性， 率先在深度学习在线预测方向广告推荐、图片识别、语音识别等得到了较大规模的部署。用户也常常将  与  进行对比， 的易编程性、高吞吐与  的低功耗、易部署等特性也各有千秋。相较于  以及 ， 的低延时以及可编程性也是其核心竞争能力。
对于行业来说，云是一种共享服务的思想，用户不以占有的方式使用硬件和软件，而是共享复用，因此大大降低了使用成本，提升了资源的使用效率。 云服务，可以让行业参与方都获得价值：

芯片原厂：不需要经过层层代理，增加成本，而是可以通过云提供硬件板卡复用的服务。因为硬件统一采购和维护，也大大提升了稳定性和可靠性。

 提供商：可以把放到云平台的市场中去，最终用户使用时，云平台完成部署和交付，用户不需要接触可执行文件网表文件，因此不存在产权泄露的风险。这将鼓励提供商的服务方式，可以提供按时长计费，买断计费，乃至试用版免费等方式，用户也可以迅速验证。

设计和开发：云提供框架方式，封装了常用的系统级操作 内存的访问、、 设备控制等，可以支持硬件描述语言，也支持  以及类似  的高级语言。提供通用的驱动和调用库，不需要用户编程。对高阶用户而言，也可以使用  或者硬件描述语言实现自己的功能。


 最初的应用场景是在通信行业，那么其高通信带宽以及实时性处理能力可以为数据中心基础架构带来什么改变呢？当前， 可以在  大显神威的地方，例如低延时网络架构、网络虚拟化、高性能存储以及网络安全等等。可喜的是，我们看到微软以及亚马逊等同行已经使用  在其公有云网络中进行了诸多积极尝试，腾讯云当前也在多个方向进行积极的探索和实践。
可以预见的是，借助于 ，我们的数据中心会更加的绿色高效。

相关推荐【腾讯云的种玩法】利用云服务器资源进行网络服务分享技巧：降维用户偏好分析
在广告算法大赛中，在对用户点击之后的转化情况预估时，笔者主要需要考虑两方面情况：
用户对点击的偏好；
具体点击场景与用户的匹配情况。
其中又可分为：①具体用户对的偏好；②用户的属性对的偏好。这两点大致可理解为：我喜欢，所以我下载，或者虽然我以前没接触过这类，但这类对我这类人群具有天然的吸引力，所以我也下载了。这里主要分析①中用户偏好。
根据比赛提供的数据，用户偏好可以从以下三个方面寻找：①用户近期的流水安装；②用户的历史安装；③用户近期的点击情况。这三点中，重要性程度：①②③，但是①的数据量只有部分，约占到全部数据量的，②的数据量约，③就更稀疏，训练数据中万，去重的有万，每个用户的平均记录只有条，想要找到对应该用户在前面几天点击该的记录很困难，只对部分用户有效。
虽然在中，但过多的缺失会导致重要的特征变得不重要，因此我们在进行时只采用历史安装数据，保证数据的标准性，不需要再进行其他规范化处理。
用户安装历史数据统计如下：

这里我把未知类型的当作一类来看待，现在看来，未知种类的在考虑偏好时，应该去掉不予考虑。
用户偏好可从用户历史安装数据出发，近期用户安装流水数据作为近期用户偏好在这里不进入分析实际上，近期的偏好更能反映用户点击时的转化情况，用户历史安装数据中种类较多，远多于我们分析的种，因此在时，只统计用户每小类安装的数目，用户安装之后打开的几率较大。流程如下：

统计每个用户历史安装的各小类数目，生成维数据表，为用户，为种类数；

对生成的数据进行转换；

利用流形对数据集降维至维；

将降维后的数据入点击流水记录进行训练。


统计用户的安装使用情况，共有大类，小类，多个，因为这个中在训练数据中出现的只有个，且如果采用大类数目统计，这些大类安装数目很容易占到非常大的特征权重，因此这里只按小类目进行统计。
统计出转化与未转化的分布如下图，其实转化与未转化之间并没有分开，只是可以看见转化了的分布较集中，越靠近中间的簇，是不是就转化率越高，暂时还不清楚，笔者用之后的特征与时间窗特征，单模型，可以跑到的分数。

主要工具：
中的_，中的，这个模块只能用来实验，对于样本数超出时，基本无能为力，因此这里给大家提供一个额外的计算程序，实际上这个程序也好不了多少，笔者能力有限，是用完成的这部分处理，有经验的同学，程序可以轻松的转为程序。
是由衍生出的一种算法，最早出现在年，它改变了和中基于距离不变的思想，将高维映射到低维的同时，尽量保证相互之间的分布概率不变，将高维和低维中的样本分布都看作高斯分布，而将低维中的坐标当做分布，这样做的好处是为了让距离大的簇之间距离拉大，从而解决了拥挤问题。
算法原理：_的实现：_作者：郭华

一、
简介
 是一款协议调试代理工具，它能够抓取记录本机所有请求，通过设置断点等方法我们可以任意修改进出的数据完成测试。其原理如下图，我们仅需要修改中收到的数据就可以模拟客户端和服务器的交互，完成一系列测试。

关于的安装、配置方法上教程很多，这里就不再介绍。
抓包
如果需要抓取本机请求，只需要启动程序并确保左下角为状态即可。

如果需要抓取移动端请求，则需要在移动终端上指定代理服务器为所在主机需要处于同一网络，端口默认

配置

中网络配置如果需要抓取请求，需要在中勾选菜单栏选项

勾选如下选项：

导出证书并安装

移动终端可以在浏览器中访问来安装证书。
如果不安装证书的话只能抓取请求。
修改数据
提供修改数据的方法有很多，常用的如下命令行设置断点

  
后面将在实例中为大家介绍各个方法的具体使用方法。
二、测试实例
 需求介绍
如图所示，中的一个页面向用户展示天气信息，具体规则如下：

拉取时机：进入页面后刷新天气信息数据源：  接口显示数据：温度信息、天气、出行提示、风速、能见度……
从测试角度看这个功能的测试难度不大，问题是如何快速的将全部天气信息匹配的和出行提示验证完毕。
测试前分析
通过分析接口和客户端代码了解到，客户端向服务器请求指定城市天气信息，在服务器返回的天气信息中各类天气状况由值表示对应关系如图，数值对应的天气图标如图

图

图因此在测试中我们只需要让客户端接收到指定值的天气数据就可以完成全部验证，所以先用抓包看下接口的返回数据。
方法如前文：首先上开启，其次在手机中配置代理，接下来我们还要在手机浏览器中访问来安装证书本例中接口为请求，最后客户端触发下请求就了。

可以看出，红框内圈出的这一部分就是我们需要修改的数据啦。下面我们就采用各种手段来吧。
修改数据

如果在工作中需要对某一个请求进行操作，最简单的方法莫过于使用的这个功能。

默认情况下状态为，根据需要我们可以选择开启不同的断点
 ：向服务器发起请求前打中断，用以修改请求内的数据。
  在服务器返回数据后中断，用以修改响应数据。
我们的用例中需要修改客户端收到的数据，因此勾选 即可。
注意：使用此功能需要正确使用，否则抓到的所有请求的会发生中断。

所有的设置都打开后就可以进行测试了，在抓到返回数据后发生中断时我们手动将所有天气信息值更改为龙卷风

修改完毕后点击   向客户端返回数据。接下来就是检查结果了。

结果符合预期，页面中的所有天气均为龙卷风通标。
以上便是自动打断点的使用方法，唯一不足的地方是当你需要查看其它请求的时候，已配置的可能导致它们无法展示在中，不过没关系，看看下面这种方法。
命令行设置断点

为了方便用户使用，还提供了一个命令行接口，通过一系列内置命令可以大大的提高使用效率，这里我们只关注断点相关的几个常用命令，其他的内容可以通过查询。

本例中我们关闭并使用进行中断

键入断点后进入天气也触发天气信息拉取

这样一条熟悉的中断请求就出现在我们面前了，后面的操作跟之前一样，修改数据返回即可。
注：清除断点输入断点命令符不接参数即可，如：对于熟悉的同学这种方法更灵活，可以快速的对需要监控的数据打点操作。
这个功能基本原理就是替换线上文档，例如一个请求，我们可以设置规则将返回的文件替换成本地文件。使用方法也很是简单，只需要在插件内添加规则即可。

在我们这个测试用例中，只需要创建规则匹配指定字符串，然后将修改好的响应文件添加进去，同时勾选上方三个复选框即可。一切搞定之后，当客户端发起请求后会将本地构造的文件如图作为返回给客户端完成测试

这种方法操作简单，一劳永逸，对于数据量改动比较大的场景较为适用。
 前面的方法对于数据来讲尽管够用，但总感觉有所些欠缺：人工介入太多，不能自动替换数据也无法通过数据驱动来进行测试。幸好，提供了这样一个插件，通过它可以编辑脚本文件实现自定义规则的实现。
使用语言不是需要单独安装后才可以使用

=
安装：

安装完毕后重启点击【 】即可

可以看到，脚本中已经预先设置好了这些接口，我们只需要在其中定义自己需要的规则就可以了。
 第一种方法我们可以向下面这样将直接替换数据中的字符串来进行测试

再次发送请求后收到的数据将自动修改之前的 =”” 变更为=”” =””

 第二种方法也可以向下面这样，当收到服务器响应时弹出提示框动手动输入数据


第三种方法当然最建议的一种方式还是搞成数据驱动：
①   创建一个文件按行存储测试用例

②   脚本里读取文件信息，此处的方法是自己实现的，功能就是计算出第一个未标注“”的数据作为当前需要替换的数据，并在结束时做上标记。这样一来，系统中所有的请求信息将按照预先设计好的顺序

③ 测试同学按照预先设计好的用例检查结果就可以了。
这是一个很小的例子，但足以说明它强大的扩展性。对于测试工作而言更像是一种粘合剂，它可以把手机、测试数据、执行脚本等测试中参与的一切粘合在一起，让测试更便捷，让自动化测试更强大。
三、小结
除以上介绍的这些数据的功能外还有很多其他用途，如域名的重定向、的测试，这里就不一一列举。但根据我们以往的经验，如果能结合我们在其他领域的研究和探索，肯定还能有更深更广的应用。

 原文链接：__


相关推荐【腾讯】从到：打造移动端性能测试平台【腾讯】移动自动化测试框架对比导语
作为一个开源的数据库，有着广泛的应用。本文主要讲述了复制的原理，以及异步复制，同步复制和并行复制。
、复制的原理
有两种复制原理：基于行的复制和基于语句的复制。最早出现的是基于语句的复制，而基于行的复制方式在版本中才被引入。这两种方式都是通过在主库上记录二进制日志、在备库上重放日志的方式来实现异步的数据复制。这意味着、在同一时间点备库上的数据可能和主库不一致，并且无法保证主库备库之间的延迟。
  、基于语句的复制
基于语句的复制模式下，主库会记录那些造成数据更改的查询，当备库读取并重放这些事件时，实际上只把主库上执行过的再执行一遍。
优点：
最明显的好处是实现相当简单。理论上讲，简单地记录和执行这些语句，能够让备库保持同步。另外好处是日志里的事件更加紧凑，所以相对而言，基于语句的模式不会使用太多带宽。一条更新好几兆数据的语句在二进制日志里可能只占用几十字节。
缺点：
有些数据更新语句，可能依赖其他因素。例如，同一条在主库和备库上执行的时间可能稍微或很不相同，因此在传输的日志中，除了查询语句，还包括一些元数据信息，如当前的时间戳。即便如此，还存在着一些无法被正确复制的，例如，使用_函数语句。存储过程和触发器在使用基于语句的复制模式时也可能存在问题。另外一个问题是更新必须是串行的。这需要更多的锁。并且不是所有的存储引擎都支持这种复制模式。
、基于行的复制
开始支持基于行的复制，这种方式会将实际数据记录在二进制日志中，跟其他数据库的实现比较相像。
优点：
最大的好处是可以正确的复制每一行，一些语句可以呗更加有效地复制。由于无需重放更新主库数据的查询，使用基于行的复制模式能够更高效地复制数据。重放一些查询的代价会很高。例如，下面有一个查询将数据从一个大表中汇总到小表

   __

            _   
缺点：
但是另外一方面，下面这条语句使用基于语句的复制方式代价会小很多：
  _   = 
由于这条语句做了全表更行，使用基于行的复制开销会大很多，因为每一行的数据都会呗记录到二进制日志中，这使得二进制日志时间非常庞大。另外由于语句并没有在日志里记录，因此无法判断执行了哪些除了需要知道行的变化外，这在很多情况下很重要。执行基于行的过程像一个黑盒子，你无法知道服务器正在做什么。 
由于没有哪一种模式对所有情况都是完善的，能够在这两种复制模式间动态切换。默认情况下使用的是基于语句的复制方式，但如果发现语句无法呗正确地复制，就切换基于行的复制模式。还可以根据需要来设置会话级别的变量_控制二进制日志格式。
、异步复制过程
总体来说，复制有个步骤：
、主服务器把数据更改记录到二进制日志中。这叫做二进制日志事件
、从服务器把主服务器的二进制日志拷贝到自己的中继日志中。
、从服务器重放中继日志中的事件，把更改应用到自己的数据上。
这只是概述，每一个步骤都很复杂。下图更清晰描述了复制的过程。

第一步、在主服务器上记录二进制日志。在每个更新数据的事务完成之前，主服务器都会将数据更改记录到二进制日志中。即使事务在执行期间是交错的，也会串行地将事务写入到二进制日志中。在把事件写入二进制日志之后，主服务器告诉存储引擎提交事务。
第二步、从服务器把主服务器的二进制日志拷贝到自己的硬盘上，进入所谓的“中继日志”中。首先，它启动一个工作线程，叫线程，这个线程开启一个普通的客户端连接，然后启动一个特殊的二进制日志转储进程它没有相应的命令。这个转储进程从主服务器的二进制日志中读取数据。它不会对事件进行轮询。如果跟上了主服务器，就会进入休眠状态并等待有新的事件发生时主服务器发出的信号。线程把数据写入从服务器的中继日志中。
第三步、线程读取中继日志，并且重放其中的事件，然后更新从服务器的数据。由于这个线程能跟上线程，中继日志通常在操作系统的缓存中，所以中继日志的开销很低。线程执行事件也可以被写入从服务器自己的二进制日志中，它对于有些场景很实用。
、半同步复制
一般情况下，异步复制就已经足够应付了，但由于是异步复制，备库极有可能是落后于主库，特别是极端情况下，我们无法保证主备数据是严格一致的。比如，当用户发起命令时，并不关心的执行状态，执行成功后，立即返回给用户。试想下，若一个事务提交后，成功返回给用户后，这个事务的还没来得及传递到，那么相对于而言就少了一个事务，此时主备就不一致了。对于要求强一致的业务是不可以接受的，半同步复制就是为了解决数据一致性而产生的。
为什么叫半同步复制？先说说同步复制，所谓同步复制就是一个事务在和都执行后，才返回给用户执行成功。这里核心是说和要么都执行，要么都不执行，涉及到  。而只实现了本地和的，但并没有实现和的，所以不是严格意义上的同步复制。而半同步复制不要求执行，而仅仅是接收到日志后，就通知可以返回了。这里关键点是接受日志后是否执行，若执行后才通知则是同步复制，若仅仅是接受日志成功，则是半同步复制。对于而言，我们谈到的日志都是，对于其他的关系型数据库可能是 或其他日志。 
半同步复制如何实现？半同步复制实现的关键点是对于事务提交过程特殊处理。目前实现半同步复制主要有两种模式，_模式和_模式。两种方式的主要区别在于是否在存储引擎提交后等待的。先来看看_模式，如下图，和分别表示用户发起命令和返回给用户的时间点，中间部分就是整个过程和做的事情。

提交时，会首先将该事务的 刷入磁盘，然后将事务的刷入磁盘这里其实还涉及到两阶段提交的问题，这里不展开讲，然后进入 流程，这个步骤主要是释放锁，标记事务为提交状态其他用户可以看到该事务的更新，这个过程完成后，等待发送的消息，等到的响应后，才成功返回给用户。看到图中红色虚线部分，这段是和的同步逻辑，是一致性的保证。
半同步复制是否能保证不丢数据？我们通过几种场景来简单分析下。第一种情况：假设第，步执行成功后，还没来得及传递给，此时挂了，作为新提供服务，那么备库比主库要少一个事务因为主库的 和已经落盘，但是不影响用户，对于用户而言，这个事务没有成功返回，那么提交与否，用户都可以接受，用户一定会进行异常捕获而重试。第二种情况，假设第步 执行成功后，还没来得及传递给，此时挂了，此时与第一种情况一样，备库比主库少一个事务，但是其他用户在执行完后，可以看到该事务的更新，而切换到备库后，却发现再次读这个更新又没了，这个就发生了“幻读”，如果其他事务依赖于这个更新，则会对业务逻辑产生影响。当然这仅仅是极端情况。
对于第二种情况产生的影响，_模式可以解决这一问题。与_相比，在_模式下， 后，就开始等待同步。那么在进行第步后，即其它事务能看到该事务的更新时，已经成功接收到，即使发生切换，拥有与同样的数据，不会发生“幻读”现象。但是对于上面描述的第一种情况，结果是一样的。
所以，在极端情况下，半同步复制的会有一个事务不一致，但是对于用户而言，由于这个事务并没有成功返回给用户，所以无论事务提交与否都是可以接受的，用户有必要进行查询或重试，判读是否更新成功。或者我们想想，对于单机而言，若事务执行成功后，返回给用户时，网络断了，用户也是面临一样的问题，所以，这不是半同步复制的问题。对于提交返回成功的事务，版同步复制保证一定是一致的，从这个角度来看，半同步复制不会丢数据，可以保证的强一致性。下图是_模式，事务提交过程。

、并行复制
半同步复制解决了的强一致问题，那么性能问题呢？从图中可以看到参与复制的主要有两个线程：线程和线程，分别用于拉取和回放。对于而言，所有拉取和解析的动作都是串行的，相对于并发处理用户请求，在高负载下， 若产生的速度超过消费的速度，导致出现延迟。如下图，可以看到，和之间的管道远远大于和之间的管道。

那么如何并行化，并行线程，还是并行线程？其实两方面都可以并行，但是并行线程的收益更大，因为线程做的事情更多解析，执行。并行线程，可以将从拉取和写 分为两个线程；并行线程则可以根据需要做到库级并行，表级并行，事务级并行。库级并行在官方版本已经实现。如下图，并行复制框架实际包含了一个协调线程和若干个工作线程，协调线程负责分发和解决冲突，工作线程只负责执行。图中，，和的事务就可以并发执行，提高了复制的性能。有时候库级并发可能不够，需要做表级并发，或更细粒度的事务级并发。

并行复制如何处理冲突？并发的世界是美好的，但不能乱并发，否则数据就乱了。上面通过锁机制来保证并发的事务有序进行，那么并行复制呢？必需保证回放的顺序与上事务执行顺序一致，因此只要做到顺序读取，将不冲突的事务并发执行即可。对于库级并发而言，协调线程要保证执行同一个库的事务放在一个工作线程串行执行；对于表级并发而言，协调线程要保证同一个表的事务串行执行；对于事务级而言，则是保证操作同一行的事务串行执行。
是否粒度越细，性能越好？这个并不是一定的。相对于串行复制而言，并行复制多了一个协调线程。协调线程一个重要作用是解决冲突，粒度越细的并发，可能会有更多的冲突，最终可能也是串行执行的，但消耗了大量的冲突检测代价。
外部引用  《高性能》作者 | 石仕海编辑 | 京露

石仕海，年校招入职腾讯互娱运营部运营开发岗位，参与腾讯游戏营销活动开发和营销平台建设，年开发经验。

  

是一个异步、并行、高性能的网络通信引擎，使用纯语言编写，提供了语言的异步多线程服务器。内置了服务器端和客户端，服务器端，支持类似语言的协程，可以使用同步代码实现一步程序。

采用多路复用异步阻塞的模型，采用多线程多线程实现异步。基于，每个可以处理无数个连接请求，因而可以轻松处理高并发。
模式下，作为前端接入层转发机，作为应用服务器构建高并发服务。

 请求转发配置
{
   
  _  
   {
     
     _{
      _ 
    }
  }
}
是服务器监听的端口。设置为静态文件目录。如果请求静态文件则直接处理，当请求动态文件时，则发送给服务器来进行处理。
  
是一个中立的技术标准，是语言的进程管理器。
的模式有很多缺点，每接收一个请求就要一个进程处理，只能接收一个请求做出一个响应；每一个请求都必须重新解析文件，重新载入全部扩展并初始化全部数据结构。
会事先启动起来，解析文件，载入扩展，初始化数据结构都只会在启动时完成，作为一个管理服务器存在，使用进程线程池预先启动一系列的子进程来等待处理。然后服务器发过来请求，一旦接收到请求就交给子进程处理，不需要在接收到请求后启动，会快很多。服务器通过一个长连接请求进程管理器。
进程像是一个常驻，在请求到达时，进程管理器选择并连接一个解释器去接收服务器发送过来的环境变量和标准输入，请求处理完成后将标准输出或错误从同一连接返回给服务器，该解释器子进程等待处理来自进程管理器的下一个连接。

 进程参数配置
_ 
__  
测试服务器环境为核，配置参数_为，充分利用性能；同时__参数设为和是为了把个进程绑定到个上，减少多核切换造成的寄存器等现场重建带来的性能消耗。
 请求转发配置
 \{
   
  _ 
  _ 
  _ _ __
   _
}
是_监听的端口，当有请求过来时，服务器会把请求转发到进程管理器，收到请求后就会交给一个子进程处理该请求。
  _
_模式运行，意味着是作为的一个模块来启动。只有在启动的时候会读取配置文件并加载扩展模块，在运行期间是不会再去读取和加载扩展模块的。出于稳定性和安全性考虑，通常使用默认的模式运行程序。在模式下，一个单独的控制进程负责产生子进程，这些子进程用于监听请求并作出应答。

总是试图保持一些备用或空闲的子进程用于迎接即将到来的请求，这样客户端无需在得到服务前等候子进程的产生。但是，一旦连接数多了，必须要生成更多的进程来响应请求，对于进程的切换就很频繁，很耗事件和资源，导致性能下降；同时，在同步阻塞模型下，遍历多个连接句柄才能知道句柄是否有事件通知，因此效率非常低。

使用命令 可以查看是运行在模式还是在模式，查看结果如下：
  


_
_
可见当前服务器上配置的使用模式运行，模式的运行参数如下：
 
 
 
 
 
 
 

服务器性能对比测试
运行环境说明：  ，使用 开启核内存虚拟机，操作系统
  个  ，个 ，静态请求直接处理，动态请求转发处理；版本为，版本为。
  个  ，个 ，静态请求直接处理，动态请求转发处理；版本为，版本为。
  _个进程，静态和动态请求都由处理；版本为，_版本为。
压测参数：并发请求参数为，压测请求总数为，使用作为压测工具；压测指令为
     
每个压测指令执行次，取次  值的平均值作为最后的统计数据。
纯文本输出
代码

       
数据库访问
代码

   = 
   = 
   = 
   = 
   = _
   =  
   =    
   = 
   = _{
     \
  }
  
斐波那契数列计算
代码

   _{
    {
       
    }
     = 
    ==
    =={
      =
    }
     
  }
  _

静态文件读取
静态文件内容：，公司的某个产品组件，文件大小

分析总结
在前三组动态请求处理程序中，在纯文本输出的压测样例里，和比性能差别不大。在数据库访问和斐波那契数列计算中，加入了访问的操作和相对复杂的逻辑运算，压测结果表明的性能要优于。这是因为在中，客户端连接请求，访问都是异步处理，比阻塞的要高效。
在上述三组动态请求中，实验结果表明和都要比_要高效。这主要是因为服务器，服务器在处理请求时都是异步非阻塞机制，相对而言的同步阻塞机制要低效许多。
最后一组测试——静态文件读取，非常明显的展示出在操作方面，比要高效很多，性能是的倍以上。的采用事件通知机制实现了异步非阻塞的模型，用户进程注册了事件监听之后马上返回，直到内核进程通知事件完成后用户进程再继续执行。
 更新
补充下异步访问的代码。

 =  __
{
  =  _
  = 
  =
  =
  =
 =_
 =

  {
    === {
        __ _
        
   }
    =    
   _   {
        _ =  \                 
        
         _
        _
   }
}     
}

该代码通过浏览器访问时没有问题，能够正常返回；但是在用压测时会出现报错” ___    = =”，后续解决了会提供压测数据。如您有解决方案，也可留言提供。

相关推荐
设计思路学习与总结
腾讯云极速配置运行环境我们管理服务器的时候经常需要远程登录服务器。直接已经比较少人用了，大家比较广泛的使用，再配合上证书或者高强度的密码登录，这样虽然安全了很多，但是把端口暴露在外网仍然会召来黑客的探测和攻击，但是不开放接口的话自己都上不去了？
很多年前看一部流行的网络小说《我是一个黑客》，里面作者介绍了一个黑客们的小技巧：

但是要和其他系统通讯，端口肯定是必须要的。这个有经验的人用端口扫描一扫，一般也能看出多了一个端口。或者系统本来没有开的服务怎么开了等？ 对付这种技术，曾经废了我很一段脑筋。 但是最后我还是想出一个办法。成功的解决了这个问题。 其实端口扫描就是和对方建立一个连接，如果连接成功，说明端口开发，否则就是没有开发的。 由于普通的网络程序，采用的都是的标准，所以当然你开了端口，程序都能连接。 但是我的后门，我拦截了连接函数。并且拦截了数据包。如果数据包不是我特殊的数据。我就知道是普通的扫描软件。我就不响应。于是对方就认为没有开发这个端口。 如果是我的程序的话，我是有特殊数据标识的。我的程序就会响应。

类似这样的手段其实在多年前就已经不只是黑客手段，而成为了一种很好的安全手段了，还有了个很酷的名字：   介绍   中文介绍。网站上收集了数十个 的实现，其中有像小说一样通过包的端口来实现的，更多的是通过依次一系列的端口号来实现的。假如每个端口号可以有种可能性，那么连续个端口号就相当于一把的密钥，已经具备相当的安全性了。
其中的一个实现就叫敲门，项目开源在上 ，需要各种操作系统版本的工具可以在主页 下载到注意和下的工具都是命令行工具，不要直接点击运行，要在或者窗口里面执行。
什么是
敲门指的是我们从自己的客户端设备、笔记本或者手机向服务器发送一系列实现约好的暗号，而服务器上需要相应的安装接收暗号的服务，它在接收到正确的暗号的时候，会临时性的为敲门者开一段时间的门并随后关上当然也能够配置成一直开着，我们要在这几秒钟里面登录成功并且保持连接，如果不小心断了连接就要重新敲门。
动作的实质就是连续的向指定的的约定的端口连续的发送多个或者包，比如我们可以通过 服务器地址 端口号 命令来发送包，也可以直接在浏览器地址栏里面用 服务器地址端口号 的方式来让浏览器发出与服务器指定端口握手的包。但是最好用的还是直接下载工具版、版，用  服务器地址 端口号 的方式来实现敲门

这里使用了 参数来显示敲门过程
什么是
如果说是敲门的来宾，就是应门的门童。下的守护进程  常用来命名，比如的守护进程，就是的守护进程，所以服务器只有安装了，才能正确的相应客户端的暗号。
安装前的准备
下载
项目的主页在  我们可以从官网找到最新版的下载链接。不过为了避免可能遇到的之类的问题，我们下载了一个版本放在腾讯云上，所以你可以通过执行下面这个命令，从腾讯云上下载到服务器上以下操作假设你在当前用户的的目录下操作：
 
安装
上一步下载到的是的文件，接下来我们要编译，就需要使用到命令。
  
但是因为系统默认不带这个工具的，你会看到一个错误提示，那么我们就需要先用命令吧这个工具安装上去。
   
安装 
安装好了工具以后，我们再次尝试安装：
  
这次很可能提示变成了了“  ”，因为默认也不带这个工具。那么一样的，我们可以用命令把它安装好：
   
安装 
安装好了工具以后，我们再次尝试安装：
  
这次我们会看到一系列的自检，最后出现了这样的一些检测失败：

  _      _      _               

这说明，现在系统里面还缺一个编译器，我们用来装一个：
   
编译
现在，我们终于可以编译  了：
  
安装
执行以下指令安装工具：
  _
配置和验证
修改日志文件位置
一般我们会把的日志记录到文件中，这一步你可以自己编辑文件，把改成  = 
如果不熟悉工具的话也可以直接执行这个命令
   = \\\\\\ 
修改敲门暗号
和上一步一样，你可以在 中编辑进去自己的敲门暗号，当然也可以直接用默认的暗号，但是因为默认暗号都是一样的，所以太容易被猜到了。
为了方便，这里我们也可以用三行命令来完成对暗号的修改
   =  
   =  
  __ =            
第一行：在这里我们使用的暗号是：连续通过、和这三个端口通过协议各敲一次门。你也可以编辑自己的暗号。
第二行：我们只接受的握手包作为敲门信号。
第三行：我们把原来默认的规则的修改方式从附加到最后面改成插入到最前面
启动服务
现在我们可以启动  服务来侦听我们设置的暗号了，运行一下指令：
 
也可以打开计划任务，这样系统重启的时候也能自动启动了
  
然后我们可以检查一下是否如期望启动了：
 
如果看到  就说明运行良好，如果看到  的话就要检查一下日志文件在前面的步骤中我们指定了文件的错误记录了。
本地敲门测试
现在已经开始监听敲门声了，我们首先可以在服务器上就地运行一次敲门：
  {}     
这样会依次用协议从本服务器的公网接口向自己的、、端口发送三个数据包作为敲门暗号。
本地敲门验证
然后我们检查文件。在日志文件中，如果第一个暗号被接受了，会记录下来：

    

随后依次接收到后面的暗号会触发 、，之后接着会执行文件中的段里面的 _指令，并在日志文件中记录：

            

这条命令会在本机的中的链上增加一条规则，允许发出正确敲门暗号的来源通过端口访问服务器。
在经过秒在配置文件的_中可以修改后，会接着执行  _ 。所以秒后，再打开日志文件，会多看到两条：

   
             

这条命令会把秒前临时打开的后门又重新关掉。所以我们必须要在敲门成功后的秒内通过登录上服务器。
下载工具
你可以在的主页的 段那里下载到工具的各种版本。比如假如你是是电脑可以下载   ，如果是当然就下载 了。
下载下来的压缩包里面可能有各种源码，不要管它，在 包里面直接解压出来\\\这个文件放到一个控制台容易访问的位置，比如 \\下面。 如果是 的话解压出来就只有一个文件，把它放在容易调用的路径比如就可以了。
真实远程敲门测试
从安装了工具的的台式机或者笔记本上执行：
       
然后再检查确认一次 文件中， 是否出现了新的从  到  的敲门记录和随后的  记录。
因为敲门是通过发送包实现的即使我们选择了协议，敲门过程实际上也并不会真的建立任何连接，只是和本身成为暗号的一部分而已，所以包到达服务器的时间有可能是乱序的，这回导致敲门失败，如果遇到只看到  或者  ，看不到  的情况，可以多试几次，或者手工依次执行：
    
    
    
如果仍然不行，有可能部分端口被禁止了，可以换端口试试看；也有可能网络不通假如服务器开启了协议的话可以   看看链路是否有问题
开始隐身吧
隐身前的准备
到现在，敲门策略已经生效，我们可以通过自己定制好的暗号来让执行特定的任务临时增加一条了，那现在我们可以披上隐身斗篷了。接下来的操作要非常小心，如果操作错误，有可能这台服务器从此就真的隐身了，我们再也登录不上去了。
首先，非常重要的一条，先执行这个命令：
            
这个命令会允许已经建立的连接不会被我们下一步增加的规则封堵，这里使用参数来确保这条规则被放在最上面。为了确保策略生效，我们需要运行这个命令： 
 
如果看到
   
                               
                                      
这个信息，就说明规则添加成功了。
放一颗后悔药非必须
为了防止万一误操作导致服务器穿上隐身衣以后再也找不到了，我们可以先放好一颗后悔药：
           |     
这条计划任务会在分钟后把我们的下一条指令添加的规则清除掉，你可以通过命令来查看它是否成功计划了。
这样如果在后面一切操作都顺利的话，我们可以用 

命令查到这个计划任务的编号，然后用 
 编号
命令吧这条计划任务删除。
留一个后门
在开始隐身之前，还可以把当前的登录加到白名单中以防万一。我们可以从命令中找到  的登录记录看到自己的登录来加到里面，或者也可以用这样一行代码来完成：
| |  \\\\\\\      \       |
如果登录用户不是的话需要对命令做相应的修改。一样的，我们需要检查确认生效：
 
开始隐身
现在我们要在中添加一条规则，除了已经建立好的连接和白名单之外，不允许任何人再建立新的连接
        
如果前面的每一步都做对了，那么这一步我们的服务器连接还是持续的，如果万一服务器成功隐身了并且服务器和主机失去联系了了，，如果是你自己购买的主机，你可以通过控制台上的“登录”功能，用登录服务器来删除刚刚添加的规则。或者你也可以等上一步操作埋下的后悔药自动生效，把刚刚添加的规则删除掉。
在控制台上删除指令是  
        
敲门登录
现在直接通过我们的笔记本、台式机进行登录的行为已经被规则给掉了，所以新建的会话根本登录不上去。以后如果需要登录的话我们可以这样做：
        
 
或者在中登录服务器前先在控制台执行一次：
       
然后马上登录。
至此，我们成功的用工具把随时端口隐藏起来了。如果有需要，我们还过配置  文件来隐藏其他端口或者让服务器根据暗号执行其他任务。
万一网络不稳定怎么办
有的时候网络不稳定，难以保证敲门序列依次到达服务器，我们可以用命令来控制每个包发出的时间，从而尽量确保包到达次序：
=
              
这里的第一行要修改成自己的服务器域名或者，后面的每个都是秒，可以根据具体网络情况做调整。
设置开机启动
我们前面已经通过    命令设置了开机启动。但是这样每次服务器重启的时候我们设置的设置都会丢失。为了在重启的过程保存和恢复设置，我们可以在命令中增加相应的操作：
在中添加保存设置在中恢复设置
我们可以通过这样一行命令把这两行添加到文件中：
     { {\    \\\    { {\    \\\ 
这样应该算是标准做法，但是这样做有一个风险就是，如果一个人刚好进来，中刚好保存了他的白名单，那么这个白名单就会被永久保存下去了。如果要回避这个风险，也可以直接只在中添加我们的两条规则，像这样：
   { {\   \  \  \\  \  \\  \ \   \  \  \\  \    前言
上一篇《引擎资源管理代码分析    》讲解了引擎资源管理代码的类型设计架构和接口的实现。感兴趣的同学推荐先点击链接阅读上一篇文章。本文将继续讲解对象实例化、销毁和资源释放接口的代码实现。
       
上一小节我们讲解了引擎的函数是如何实现资源加载的，但众所周知，该函数返回的是不能直接使用在游戏中的，想让它出现在场景树中必须再调用函数对这份资源进行实例化。但奇怪的是，函数返回的对象类型和传入的资源类型是完全相同的，而常见的引擎设计一般是传入一个之类的资源对象，返回一个或之类的引用这份资源的实体对象。从这个角度看，函数不像是个“纯资源”到“对象实例”实例化函数，而更像是个进行对象复制的函数。那么在引擎内部，返回的和后的对象有什么区别呢？
在解释资源和实例的区别之前我们先来关注一个有趣的接口：


    
    

   
                                 

这个的说明指出它可以用来判断一个是一个，还是说一个运行时对象在场景中或运行时创建的对象。经测试当我们将的返回值直接作为参数传入到该函数中进行调用，函数返回值为。而当我们讲的返回值作为参数传入时，返回值是。也就是说这个就是资源，而所谓的对象就是实例。那么接下来我们分析下在引擎中这个函数是如何实现的。
这个接口对应的函数为__，它所做的工作是根据传入的在一个类包含的中查找对应的类对象。这个类包含两个类型的成员变量：和，分别记录包含该对象的序列化文件和该对象在文件中的局部索引。如果能在这个中找到对应的文件标识符，函数则返回，否则返回。显而易见，所有从文件中加载的肯定是能查到记录的。
那函数本身又是如何实现的呢？其实它内部的实现函数___就是在执行操作，且这个操作只会为新生成的产生对应的，但并不会在类的中加入新对象到的映射条目，自然也就不是的对象了。
在对象树的时候引擎不同于传统的递归深拷贝克隆方式，而是先将需要复制的对象树中的所有对象都创建出一个新的副本，但先不复制其内容。这样的好处是可以集中创建新对象，避免长时间锁定的全局表，提高多线程访问效率。
创建完所有的新对象后，会通过一个继承于基类的序列化读写器来进行对象数据的复制操作。这个序列化读写器类主要负责实现数据流的操作，它有多个子类，例如：、、、、等等，它们的接口统一，但实现不同，可以用来进行两进制文件内存数据读写、脚本读写、对象指针的重映射浅拷贝等不同的工作。
而如何通过类复制对象数据的过程我们可以用如下的伪代码说明：
    
{
    创建数据写入器
     
    

    将源对象的数据写入缓存
    

    创建数据读取器，从先前写入器的缓存读取数据。
     
    

    从缓存中读取数据到目标对象
    
}

    
{

      
    {
        写入读取成员变量的数据
        _
    }


        _
}
从上面的代码中可以看出，虽然数据的操作由对象实现，但哪些成员需要序列化、如何序列化，仍由具体的子类所负责。这样在实现例如类的代码时，即可只复制对相同对象的引用，让两个组件引用同一个对象，而无需完全复制一份相同资源数据，从而节省了内存开销。

、

上文讲到无论是从文件中加载的资源还是实例化出来的对象其基类都是，那么对应的对象删除接口理应就是和这两个函数了。而这两个函数有什么区别呢？它们又真的能释放掉资源吗？
在的说明文档里是这么解释这两个函数的：

       = 

     
                                                                       

       = 





   





        





            
                                                                                

从函数说明文档来看，它们的主要区别在于是在当帧的操作执行完毕后再延迟删除对象，而是在调用时立即删除对象。且这两个函数都可以自动判断传入的对象类型，如果是还会自动删除其下挂接的子节点和组件。
在的函数说明中还特别强调了只在编辑器的代码中调用它，游戏中应使用。因为如果在编辑器中使用的话延迟销毁对象的调用是不会进行的。注意这里指的是在实现编辑器扩展功能的代码中调用它，而不是指在编辑器中执行的游戏运行时代码。至于第二个的参数我们稍后再谈。
接下来让我们看看这两个函数在引擎代码中的实现：
的调用的引擎内部函数叫，这个函数一开头就先进行了两个判断和报警返回：
 
{
                                
    
}

  
{
                          
    
}
第一个判断的函数在游戏运行时会返回，否则返回。也就是说在编辑器代码中调用是会直接返回的。警告中也指明应调用替代。
第二个判断是，其内部逻辑正是我们前文中提到的，用来判断该对象在中是否存在对应的序列化文件。也就是说如果我们在调用时传入的对象是使用加载的返回值，而不是出来的实例，这个函数是不会作任何处理的。也就是说用函数是无法卸载掉加载的对象的。
在进行完判断后，函数将延迟销毁对象的回调函数注册到了一个叫的类中，该类负责在每帧的后统一执行这些回调。而函数的实现则是简单调用了这个函数。
那函数的体现在哪里呢？它其实是一个递归的对象销毁函数，也就说当我们把根级传进去的时候，它会自动把其下挂接的所有子节点和组件都删除掉。除此之外它还会做一些安全处理，例如是否重复销毁，对象是否还在被物理引擎使用中等等。
接下来让我们看看函数的实现。它内部其实调用的是下面这个函数：
    
{
        
    {
                             
        
    }

    
}
这个函数中首先进行了一个判断，如果传入的对象是的资源对象，且未指定参数为则直接报错返回。再接下来它和函数调用了同样的函数，只不过这次没通过是立即调用的。
那么我们是不是只要将参数设为就可以在游戏运行时用它来卸载加载的对象呢？答案是否。原因有二：

这个函数是在调用返回前就把删除掉了，而未等待当帧的结束。在游戏运行时状态有很多处理操作是异步执行的，这样很可能造成逻辑的漏洞，不安全。

当的标志为时，这个函数不但会把内存中的删除掉，还会把中保存的文件关联信息也删除掉。在编辑器中运行时甚至还会把文件中的资源数据也一并删除掉。这样的后果是我们再也无法重复加载该资源。


所以最终的结论很遗憾，在游戏运行时的代码中，我们只能使用来销毁通过函数实例化的对象。

那我们再来看看这个函数的实现。它的引擎内部函数如下：
  
{
     == 
        

    
    {
                
        
    }

      = 
    
    {
                            
        
    }

    
}
首先这个函数只接受的，否则直接返回。之后它调用了这个函数用来判断的类型是否可卸载，如果不符合要求也是直接返回。而函数的实现如下：
   
{
        
         

        
         

          
         

        
         

     
}
坑爹呢这是！连和类型的对象都不给卸载么！换句话说我们只能用它来卸载诸如、、、等继承自基类的纯资源对象。再仔细跟下最终调用的卸载函数，这个函数的确也没有任何的递归卸载处理代码，它只是一个在函数的递归调用代码中用来删除单个对象的函数。
   
文章读到这里，想必各位读者跟我一样也是非常的失望。如此高大上的一个引擎竟然连一个好用的手动卸载单个资源的接口都没有。人类最后的希望就落到了这个接口身上。
接口的引擎内部函数是__，这个函数本质上是一个异步处理函数，调用它后其实只是创建了一个叫的异步操作处理对象，并将其加入到了的队列中，然后就直接返回了。
这里需要先解释下这个的工作原理。这个类有一个类型的成员变量，其中存储的是所有异步操作的基类，它有两个重要的虚函数，一个是、另一个是。初始化后会在主线程外新启动一个线程运行一个循环的函数，这个函数会不断地从队列中取出尚未执行完成的对象，并调用它的虚函数执行异步工作。当执行完毕返回后，如果对象被标记为需要通知主线程，则这个对象的指针会被记录在一个可跨线程访问的_的成员变量中，游戏的主线程则会在主循环中调用这个_的虚函数。
 类就是继承自异步操作基类的对象之一。但它的函数实现是空的，只有函数内调用了下函数。顺带一提，还有负责场景异步加载的、负责异步创建的等类也是继承自。
是引擎底层真正实现无用对象回收的函数，它的实现逻辑是：

遍历对象到指针的全局表，收集仍未销毁的对象到资源回收表中。

在资源回收表中查找所有仍挂接在场景中的根节点对象，并递归遍历其下引用的所有对象，将其标记为被引用对象。

遍历资源回收表，卸载表中所有不存在任何引用的对象。
如上所述，这是一个典型的被动型垃圾回收机制，而且实现方法非常暴力，其中涉及到多次对全局对象表的遍历操作。在一般的游戏场景中，对象可能动辄几千或者上万，一次函数的调用可能会耗时几百毫秒，造成非常严重的卡顿。但同时它也是唯一能自动递归卸载节点树下所有资源的接口，真是让人又爱又恨。简介

是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的  机器上。简单说，让整个运维环境标准化，真正实现构建、部署、  ，无差异的在任何环境中运行应用。
在游戏领域的应用模式
通过与母机共享内核，具有轻量级、启动速度快、支持在线升降配内存等特点，并且基于镜像可以非常快速的构建一致性环境用于业务的集成发布、扩缩容、故障处理等场景中。我们看到很多业务已经开始体验给业务带来的优势，从整体架构上来说，目前在游戏上的应用主要分为两种形式：
 虚拟机模式
虚拟机模式是应用上最基础、最简单的模式，也是应用最多的模式。不管是新业务，还是老业务都能够通过快速的替换实现对的利用，基本上可以无门槛接入。业务也只是把容器作为一台虚拟机使用，像在虚拟机上一样部署自己的业务，包括，监控，周边系统，业务进程等等。
那么这里的优势主要体现在，可以在业务无感知的情况下进行在线升降配。比如：对于分区分服的游戏来说，往往大区的在线分布很不均衡，为了减少日常维护的复杂度，业务基本上都会维护一致的区服架构，这样对于在线比较低的大区，低负载就会比较严重。而如果业务使用的话，就可以在业务无感知的情况下快速的在线降配，及时的释放资源，降低业务的运营成本，甚至可以进一步结合业务的在线数据直接做到自动升降配，无需人为的干预。但这里需要注意的是，如果大区在线比较稳定的话，单纯降配是没有问题的，但如果只是波动，就需要考虑到业务在升配的时候，资源申请问题因为有可能释放的资源已经被其他业务给使用了。

：这里我们也看到在虚拟机的应用模式下，业务的运维模式其实变化不大，这其中既有业务运维本身对的理解有限，同时也被业务现有的架构流程所局限难以施展。

 集群模式
集群模式在对更深的理解之上构建的业务形态，推崇在一个容器上只部署一个进程，通过、等来管理整个容器集群。业务在集群模式下，已经没有了机器的概念，可以充分利用镜像、容器、仓库所带来的持续集成发布、故障处理、以及扩缩容上的巨大优势。比如发布流程：通过持续集成，开发可以直接交付镜像给到运维，镜像按照模块区分，通过标识不同的版本，提交发布后系统可以直接拉取最新的镜像重启容器，也可以依赖做滚动的升级。通过镜像的方式，业务大部分的配置也可以直接打包到镜像，不再需要依赖复杂的配置管理工具。


：类似这种颠覆式的改变，需要运维从业务立项就开始介入，与开发、同事一同搭建整个集群生态系统。当然也会有一些新的挑战，比如：在集群模式下的网络架构、业务监控、容器日志集中处理、风险控制等等。

 的应用
从上面我们也看到集群模式是可以更好的发挥的优势，但是接入改造是一个漫长的系统过程，也有待于周边平台的完善。在虚拟机模式下，利用 其实也可以在弹性扩缩容、容量管理、故障处理方面给业务带来很大的优势。但我们也知道在游戏业务中，不管是扩缩容，还是故障处理都有很高的时效要求，运维是不可能手动一步步去处理的。所以这里在环境一致性和交付效率上也遇到一些新的挑战，比如：
 标准化问题
为了让业务申请的容器环境尽量跟外网保持一致，减少后续的配置变更，通过对业务指定的镜像机进行，实现包括：策略，策略，卷目录大小的一致，针对目录还可以进一步指定相关的目录，并且优化了和周边系统的同步刷新。而镜像版本的一致性由运维通过独立的接口进行配置维护。默认业务申请容器的时候是拉取最新的镜像，特殊情况下业务也可以通过指定来拉取特定的镜像。
 交付效率
通过分析发现，在容器的交付过程中最耗时的两步是：
 创建容器时从镜像仓库拉取镜像
  容器创建完成后，还经过流转到业务自己的配置管理模块下
为了提高交付的效率，通过联合资源同事搭建了独立的集群，通过镜像预先部署的方式来避免每次从镜像仓库拉取，配置管理系统目前也在跟周边同事一起优化，目前已实现秒级的容器创建，可在分钟内完成资源交付使用。
 周边系统同步效率
业务扩缩容或者故障处理，运维在拿到交付的容器后，往往还需要同步周边系统的权限，比如：、、安全等。现阶段来看在镜像资源交付已经秒级的情况下，相比而言周边平台处理还是比较耗时的，通过分析把部分步骤并行，部分步骤前置可以一定程度上解决这个问题，但也还需要进一步推动相关的系统平台进行优化改造。

所以在解决了这些问题之后，即便是虚拟机模式下，业务也能在下列场景上发挥出 带来的优势：

 弹性扩缩容

业务扩容一方面可以通过已预部署镜像的集群快速申请容器资源，申请到的环境跟外网的基本一致，运维只需要更新周边权限和拉起进程就可以快速的上线提供服务，也可以通过在线升配来快速满足业务紧急扩容的需求。同样业务缩容一方面可以走正常的容器回收下线流程，也可以直接在线降配。需要强调的是，在线升降配作为弹性伸缩的一种，操作起来固然很简单，但游戏有时需要考虑同屏人数、游戏活跃度，从运营策略上考虑可能并不是很适合。


容量管理

根据以往的经验，业务为了应对在线的波动，实际的建设容量都会偏高一些。在利用镜像以后，业务可以在秒级获取到跟外网版本一致的容器，通过简单的配置更新拉起，即可给业务快速的扩容，再加上在线的升降配能力可以使业务具备极强的伸缩能力，运维也可以根据实际情况来降低业务建设容量，降低运营成本。
但需要注意的是：为了提升整个资源的规模利用效率，集群容量是共享的，业务需要提前根据实际情况申请配额，然后由资源交付同事进行集群的建设维护。比如：为满足业务故障替换、快速扩容等紧急情况而搭建的特定集群，一般不支持业务的常规替换、搬迁等时效比较低，并且资源流转也比较慢的需求。

故障处理

利用 做故障恢复，主要优势体现在：
流程优化：过去机器故障，一般是优先重启机器恢复，如果机器重启失败，则再走机器替换流程。可以看到不管 是机器重启还是机器替换都比较耗时。而拥有镜像容器之后，业务在机器故障时，则可以直接走镜像容器的创建和替换，直接在新容器上进行业务恢复，不再等待故障机器的重启和恢复。流程相对简单，也比较容易实现自动化，或者跟现有的故障自愈流程结合。
效率提升： 通过恢复故障，除了流程上的简单高效外，还存在并发优势，因为容器或者虚拟机都依赖母机硬件，所以会出现多台机器同时异常的情况。而 在申请容器方便，并发优势明显，经测目前不到分钟即可交付上百台容器资源，大幅提高了处理效率。
成本节约： 走快速 替换，业务不再需要维护机器，有利于资源盘活，降低成本。
简单总结下业务使用前后的优势对比：

四，总结
在基础运维工作已经自动化的今天，容器技术进一步颠覆了传统的资源管理和业务运维方式。从镜像的构建到容器的编排管理，容器作为计算资源的提供者，使得运维不再关心具体的机器，甚至也不再需要额外的配置管理，一个个镜像就是一个个独立的业务模块，可随时根据需要调度生成指定数量的容器来提供服务。并且通过跟周边系统的打通，运维日常的发布、扩缩容、故障处理也都可以自动实现。
在容器化运维的新时代，尽管一切还在摸索中，但我们已经可以看到新趋势下容器技术给业务运维带来了前所未有的优势和挑战。这一阶段，运维作为连接用户和业务的纽带，也更加需要深入到基础平台的构建和业务的发展规划中去，只有这样才能不被时代所抛弃，也才能不断的给业务创造更大的价值。一、简介
是一种高吞吐量、分布式、基于发布订阅的消息系统，最初由公司开发，使用语言编写，目前是的开源项目。
跟、等目前流行的开源消息中间件相比，具有高吞吐、低延迟等特点，在大数据、日志收集等应用场景下被广泛使用。
本文主要简单介绍的设计原理。
二、架构

基本概念：

：服务器，负责消息存储和转发
：消息类别，按照来分类消息
：的分区，一个可以包含多个，消息保存在各个上
：消息在日志中的位置，可以理解是消息在上的偏移量，也是代表该消息的唯一序号
：消息生产者
：消息消费者
 ：消费者分组，每个必须属于一个
：保存着集群、、等数据；另外，还负责故障发现， 选举，负载均衡等功能

三、设计原理
 数据存储设计
以文件形式存储在文件系统，目录命名规则：__，例如，名为的，其有个，则数据目录中有个目录：  ，分别存储相应的数据。
的数据文件
中的每条包含了以下三个属性：





其中表示在这个中的偏移量，不是该在数据文件中的实际存储位置，而是逻辑上一个值，它唯一确定了中的一条，可以认为是中的；表示消息内容的大小；为的具体内容。
的数据文件由以上格式的组成，按由小到大排列在一起。如果一个只有一个数据文件：

新数据是添加在文件末尾，不论文件数据文件有多大，这个操作永远都是的。
查找某个的是顺序查找的。因此，如果数据文件很大的话，查找的效率就低。

通过分段和索引来提高查找效率。
数据文件分段
物理上由多个文件组成，每个大小相等，顺序读写。每个数据文件以该段中最小的命名，文件扩展名为。这样在查找指定的的时候，用二分查找就可以定位到该在哪个数据文件中。
数据文件索引
数据文件分段使得可以在一个较小的数据文件中查找对应的了，但是这依然需要顺序扫描才能找到对应的。为了进一步提高查找的效率，为每个分段后的数据文件建立了索引文件，文件名与数据文件的名字是一样的，只是文件扩展名为。

索引文件中包含若干个索引条目，每个条目表示数据文件中一条的索引。索引包含两个部分，分别为相对和。

相对：因为数据文件分段以后，每个数据文件的起始不为，相对表示这条相对于其所属数据文件中最小的的大小。举例，分段后的一个数据文件的是从开始，那么为的在文件中的相对就是 = 。存储相对可以减小索引文件占用的空间。
，表示该条在数据文件中的绝对位置。只要打开文件并移动文件指针到这个就可以读取对应的了。文件中并没有为数据文件中的每条建立索引，而是采用了稀疏存储的方式，每隔一定字节的数据建立一条索引。这样避免了索引文件占用过多的空间，从而可以将索引文件保留在内存中。但缺点是没有建立索引的也不能一次定位到其在数据文件的位置，从而需要做一次顺序扫描，但是这次顺序扫描的范围就很小了。


总结
查找某个的消息，先二分法找出消息所在的文件因为每个的命名都是以该文件中消息最小的值命名；然后，加载对应的索引文件到内存，同样二分法找出小于等于给定的最大的那个记录相对，；最后，根据到文件中，顺序查找出等于给定值的消息。
由于消息在的数据文件中是顺序读写的，且消息消费后不会删除删除策略是针对过期的文件，这种顺序磁盘存储设计是高性能很重要的原因。
 生产者设计


负载均衡：由于消息由多个组成，且会均衡分布到不同上，因此，为了有效利用集群的性能，提高消息的吞吐量，可以通过随机或者等方式，将消息平均发送到多个上，以实现负载均衡。
批量发送：是提高消息吞吐量重要的方式，端可以在内存中合并多条消息后，以一次请求的方式发送了批量的消息给，从而大大减少存储消息的操作次数。但也一定程度上影响了消息的实时性，相当于以时延代价，换取更好的吞吐量。

 消费者设计


任何必须属于一个 
同一 中的多个实例，不同时消费同一个，等效于队列模式。如图，  的三个实例分别消费不同的的消息，即，、、。
不同 的实例可以同时消费同一个，等效于发布订阅模式。如图，  的和  的，同时消费的消息。
内消息是有序的，通过方式消费消息。
不删除已消费的消息

队列模式
队列模式，指每条消息只会有一个消费到。保证同一 中只有一个会消费某条消息。

在 稳定状态下，每一个实例只会消费某一个或多个特定的数据，而某个的数据只会被某一个特定的实例所消费，也就是说对消息的分配是以为单位分配的，而非以每一条消息作为分配单元；
同一 中，如果实例数量少于数量，则至少有一个会消费多个的数据；如果的数量与数量相同，则正好一个消费一个的数据；而如果的数量多于的数量时，会有部分无法消费该下任何一条消息；
设计的优势是：每个不用都跟大量的通信，减少通信开销，同时也降低了分配难度，实现也更简单；可以保证每个里的数据可以被有序消费。
设计的劣势是：无法保证同一个 里的均匀消费数据，且在实例多于个数时导致有些会饿死。

如果有或者的增减，为了保证均衡消费，需要实现 ，分配算法如下：

对设计原理：

对于每个 ，选举出一个作为版本以上，由它 ，从而监控判断是否有或者的增减，然后生成命令，按照以上算法重新分配。
当 第一次被初始化时，通常会读取每个的最早或最近的记录，然后顺序地读取每个 的消息，在读取过程中，它会提交已经成功处理的消息的由记录。
当一个被重新分配给 中的其他，新的消费的初始位置会设置为原来最近提交的。


如图，  指最近一次提交的消费记录， 是当前消费的位置， 是成功拷贝到的所有副本节点的所有节点，下文介绍的最近消息的，  是写入中最后一条消息的。
从的角度来看，最多只能读取到 的位置，后面的消息对消费者不可见，因为未完全复制的数据还没可靠存储，有丢失可能。
发布订阅模式
发布订阅模式，又指广播模式，保证的每条消息会被所有 消费到，而对于同一个 ，还是保证只有一个实例消费到这条消息。
 设计
作为消息中间件，数据的可靠性以及系统的可用性，必然依赖数据副本的设计。
的副本单元是的，一个的数量不能超过的数量，因为一个最多只会存储这个的一个副本。所有消息生产、消费请求都是由的 来处理，其他 负责从复制数据进行备份。
均匀分布到整个集群，的算法如下：

将所有假设共个和待分配的排序
将第个分配到第  个上
将第个的第个分配到第    个上


如图，有三个：、、，每个的数等于一个是，另一个是，按照以上算法会均匀落到三个上。
对管理：选举出一个作为，由它 ，负责的的集群分配，以及切换选举等流程。

分布式系统在处理节点故障时，需要预先明确节点的””和””的定义。对于节点，判断是””有以下两个条件：

节点必须和保持心跳连接
如果节点是，必须从节点上复制数据来备份，而且备份的数据相比而言，不能落后太多。

将满足以上条件的节点认为是” ”同步中，称为。
的维护了每个的信息，理想情况下，包含了的所有所在的节点信息，而当某些节点不满足以上条件时，可能只包含部分。例如，上图中的的列表可能是，也可能是和。
数据可靠性
如何保证数据可靠性？首先看下，生产一条消息，该消息被认为是””即认为消息已经可靠存储的过程：

消息所在的 会定时异步从上批量复制数据
当所有 都返回，告诉该消息已经写成功后，认为该消息，并告诉生产成功。这里和以上””条件的第二点是不矛盾的，因为有超时机制，等的复制数据，如果一定时间不返回可能数据复制进度落后太多，则将该 从中剔除。
消息之后，才能消费到。




机制下的数据复制，既不是完全的同步复制，也不是单纯的异步复制，这是高吞吐很重要的机制。同步复制要求所有能工作的都复制完，这条消息才会被认为，这种复制方式极大的影响了吞吐量。而异步复制方式下，异步的从复制数据，数据只要被写入就被认为已经，这种情况下如果都复制完都落后于，而如果突然宕机，则会丢失数据。而的这种使用的方式则很好的均衡了确保数据不丢失以及吞吐量，可以批量的从复制数据，数据复制到内存即返回，这样极大的提高复制性能，当然数据仍然是有丢失风险的。
本身定位于高性能的，更多注重消息吞吐量，在此基础上结合的机制去尽量保证消息的可靠性，但不是绝对可靠的。
服务可用性
所有收发消息请求都由节点处理，由以上数据可靠性设计可知，当的 故障后，会及时地从列表中把它剔除掉，并不影响服务可用性，那么当故障后会怎样呢？如何选举新的？
选举

在存储的信息，并且能动态调整列表的成员，只有里的成员才会被选为，并且所有的都有可能成为；
节点宕机后，能监控发现，并由的节点从中选举出新的，并通知内的所有节点。


因此，可以看出，只要中至少有一个，就能保证服务的可用性但不保证网络分区下的可用性。
容灾和数据一致性
分布式系统的容灾能力，跟其本身针对数据一致性考虑所选择的算法有关，例如，的算法，算法等。的机制和这些 算法对比如下：

机制能容忍更多的节点失败。假如节点有个，每个最多能容忍个失败，且不丢失消息数据；但相对 选举算法，只能最多容忍个失败。
在消息持久化上，需要等个节点返回，但 只需等个节点返回，且不依赖处理最慢的节点，因此 有优势
机制能节省更多节点数。例如，要保证个节点可用，方式至少要个节点，而 至少需要个节点。

如果所有都宕机了，有两种方式恢复服务：

等任一节点恢复，并选举为；
选择第一个恢复的节点不一定是中的节点为

第一种方式消息不会丢失只能说这种方式最有可能不丢而已，第二种方式可能会丢消息，但能尽快恢复服务可用。这是可用性和一致性场景的两种考虑，默认选择第二种，用户也可以自主配置。
大部分考虑的分布式系统假设个节点，为了保证数据一致性，最多只能容忍个节点的失败，而为了兼顾可用性，允许最多个节点失败，因此是无法保证数据强一致的。

如图所示，一开始数量等于，正常同步数据，红色部分开始，发现其他两个复制进度太慢或者其他原因网络分区、节点故障等，将其从剔除后，单节点存储数据；然后，宕机，触发重新选举第二节点为，重新开始同步数据，但红色部分的数据在新上是没有的；最后原节点恢复服务后，重新从新上复制数据，而红色部分的数据已经消费不到了。
因此，为了减少数据丢失的概率，可以设置的最小数，低于该值后直接返回不可用，当然是以牺牲一定可用性和吞吐量为前提了。
重复消息
消息传输有三种方式：

  ：消息可能会丢失，但不会重复传输
  ：消息不会丢失，但可能重复传输
 ：消息保证会被传输一次且仅传输一次

实现了第二种方式，即，可能存在重复消息，需要业务自己保证消息幂等性处理。
 高吞吐设计

对于，顺序读写磁盘数据，以时间复杂度方式提供消息持久化能力。
批量向写数据
批量从拉数据
日志压缩
分多个，提高并发
零拷贝 ，使用系统调用，将数据直接从 发送到上
可配置是否等待消息。如果生产消息，每次都必须等存储后才返回，时延会很高，进而影响整体消息的吞吐量。为了解决这个问题，一方面可以配置减少的副本数，例如，大小为；另一方面，在不太关注消息可靠存储的场景下，可以通过配置选择是否等待消息，如下：





持久性等级
返回响应时机
写延时





高
全部成员返回
高



中
中任一成员返回
中



低
不等待成员返回
低



这是用户在消息吞吐量和持久化之间做的权衡选择，持久化等级越高，生产消息吞吐量越小，反之，持久化等级越低，吞吐量越高。
 基本原理
 
集群信息由维护，并选举出一个。所有的选举都由决定，将的变更直接通过方式通知需要为此做出响应的；也负责增删以及 的重新分配。
在上注册，一旦有宕机，其对应在的临时节点自动被删除，对宕机上的所有重新分配新；如果宕机，其他通过选举出新的，然后同样对宕机上的所有重新分配新。
 
 所在的宕机，如上所述， 根据动态维护的，会重新在剩下的机器中选出里面的一个成员成为新的。如果中至少有一个，则可以确保已经的数据不丢失；否则选择任意一个作为，该场景可能会有潜在的数据丢失；如果所有的都宕机了，就无法保证数据不丢失了，有两种恢复方案，上文已介绍过。
四、推广
腾讯云即将推出高性能的消息队列服务，完全兼容开源 版本。服务端完全托管在腾讯云上，用户无需自己维护和搭建，使用开源 客户端即可访问实例，大大降低了用户使用的门槛，欢迎体验：
参考
一个 论坛在腾讯云已经良好工作了很久，不久前突然随机出现以下错误：

从字面意思上看，就是数据表“_”满了写不进去，最可能的就是磁盘满了。不过这个论坛使用的是云数据库，所以也可能是云数据库的容量用完了。登陆上去查一下使用情况：

的空间还只用了，远远没有满呢，那是出了什么问题呢？
其实  论坛多年前设计的时候，把一些临时性的需要频繁读写的数据表设计为了内存表，这样避免在读写这些表的时候会产生磁盘  操作，从而提高了系统的性能。这在那个软硬件性能相比今天非常弱的时代无疑是一个巨大的优化。
但是这样需要确保数据库有足够多的内存来创建内存表。其实在现在的云数据库  中，  性能瓶颈已经被极大的打开了，内存表起到的优化作用很有限，相反很容易带来内存不足导致的    问题。
比较容易的解决方案是把满掉的内存表清空，但是这样会带来一些非核心数据的损失，而且治标不治本，智能临时性的缓解问题：
  _；
更好的选择是把内存表变成表：
  _ =
变更后问题迎刃而解。这样只要放弃一点点看不到影响的性能，就可以比较长久的化解这个问题。
如果有时间可以顺手把其他内存表也都变为，避免在其他表上再次发生类似的悲剧。

相关推荐
基于的云数据库搬迁实例解析简介
近年来，在国内取得了突飞猛进的发展，很多门户网站开始提供解决方案。是一款开源的高性能服务器和反向代理服务器，同时支持代理服务。由俄罗斯设计师在年开发，年发布第一个版本。以其高性能，高可用，丰富的功能模块，简单明了的配置文档以及占用较低系统资源而著称。其采用最新的网络模型，支持高达个并发连接。
 是一个安装非常的简单、配置文件非常简洁、非常少的服务器。 启动容易，并且几乎可以做到不间断运行，即使运行数个月也不需要重新启动。在不间断服务的情况下还可以进行软件版本的升级。
 同时也是一个非常优秀的邮件代理服务器最早开发这个产品的目的之一也是作为邮件代理服务器， 描述了成功并且美妙的使用经验。
软件的安装及指令
软件包使用源码编译安装。需要提前将其依赖包进行安装。

安装依赖包          

源码包编译安装，在官网下载          解包
  
  __            配置
                                           编译
                                    安装

将程序做个软连接，方便执行       连接


软件包采用的是模块化的设计，模块分为内置模块和第三方模块。
服务器安装好之后，程序的主目录在下，该目录下分别为主配置文件目录，网页根目录，日志文件目录，主程序目录。默认无执行脚本，需要手动输入命令来管理。常用的命令如下：

启动主程序 

关闭主程序   

重载配置   


配置文件解析
主配置文件为，配置文件包括全局，，，设置。主要用来定义工作模式，提供功能，用来设置虚拟主机，必须位于内部，一个配置文件可以由多个，一个表示一个虚拟主机。虚拟主机包括三种类型：基于域名的虚拟主机，基于的虚拟主机，基于端口的虚拟主机。
  
                                            设置用户和组
    _            启动子进程，通过   |  
    _                    错误日志文件，以及日志级别
    _                        
    _    

                                      进程号
     {                              工作模式，每个进程可以处理的连接数
        _                               
    }

     {                                                 
                                          为文件类型定义文件
            _           默认文件类型   

            _    _  _
            _                         创建访问日志
             __ _ 
            __ ___

            _    

                    
            _     

            _                               
            _                                 
            保持连接的超时时间  

                                                        
            是否启用压缩功能

             {                                             定义虚拟主机
                                                        监听端口
                    _                        主机名

                 

                _    

                      {                                      
                    对进行匹配，支持正则
                           
                           
                        }

                _                           
                设置错误代码对应的错误页面

                         
                
                    _        
                     =  {
                       
                    }

                         
                
                  \ {                                
                若用户访问的是动态页面，则找主机的端口，即交给处理，
                通过_实现代理功能
                    _   
                }

                        
                
                
                  \ {
                               
                    _   
                    _  
                _ _ __
                            _
                }

                         
                    
                
                  \ {
                      
                }
        }
                     
              
            
             {                                              
            定义另一个虚拟主机
                       
                       
                _      
                  {
                       
                       
                }
         }
         
        
         {                                              
        定义安全网页
                    
            _  
            _      
            __  

            __    
            __  

            _  
            ___  

              {
                   
                   
            }
        }
    }
基本应用

搭建服务器
配置用户认证登陆网页
配置加密网站
虚拟站点

高级应用
 反向代理实现集群负载均衡
除了可以作为后端服务器之外，还是一个高效的反向代理服务器。在负载均衡的架构中，可以为我们提供非常稳定且高效的基于七层的负载均衡解决方案。可以根据轮询，哈希，哈希的方式调度后端真实服务器，也支持对后端服务器的健康检查功能。
 地址重写规则
地址重写的概念：—获得一个来访的请求，然后改写成服务器可以处理的另一个过程语法：   选项优势：—缩短，隐藏实际路径提高安全性—易于用户认证和键入—易于被搜索引擎收录用途：—当网站文件移动或者文件目录名称发生改变时，出于搜索引擎优化需要，你需要保持旧的。—网站改版，或者网站导航和连接发生改变，为了持续持有源连接带来的流量，需要保持旧的。
基本应用实例
 搭建服务器
在地址为的主机上安装部署服务。
方案：使用台虚拟机，其中一台作为服务器、另外一台作为测试用的客户机，如图所示。

操作：配置文件无需更改，直接启动服务。
                                             启动服务  
                                     重载配置
客户端访问：
  
访问结果如图

 配置网站用户认证访问
操作：在配置文件里添加用户认证模块，操作如下：
  
                                                    
        支持中文字符
        _       ：   提示信息
        ___                           
                帐号密码文件
                                       重载配置
     
生成密码文件   
  
   
          输入两遍密码
客户端访问：
  
访问结果如图

虚拟主机
要求：配置基于域名的虚拟主机
操作：操作如下：
搭建一个服务器
                      安装软件包
                               修改主配置文件
 {
         
}

  {                                            域
         
         
}

  {                                            域
         
         
}
                                 
检查语法错误，无错误，无输出
       
                                                复制一个 在去修改
       
                                                复制一个 在去修改
                       
                                        修改域的地址库文件，增加下面的代码
                      
                      
                     
                        
                                        修改域的地址库文件，增加下面的代码
                      
                      
                     
                 检查语法错误
    

                            重启服务
客户端配置服务器：
  
                                      
指定为本机的域名解析服务器
客户端测试解析：
  
   
  
   
修改配置文件，添加第二个虚拟主机，操作如下：
  
 {
               
        _  

          {
               
               
                    }
        }
                     
创建的网页根目录
    制作主页
      制作主页
客户端测试：
  

  

加密网站部署
要求：配置加密网站
操作：操作如下：
  
  {
                                              监听的端口
       _  

       _                            证书
       __                        私钥
         {
              
              
       }
    }
   
客户端去访问：
                     访问时输入
访问结果如下：点击我已充分了解可能的风险最终结果如下：
高级应用实例
反向代理实现负载均衡要求：配置反向代理实现服务器负载均衡。—后端服务器两台，可以使用实现—采用轮询的方式调用后端服务器—两台服务器的权重要求设置为不同的值—最大失败次数为，失败超时时间为秒
方案：反向代理负载均衡拓扑结构如图：操作：操作如下：

准备两个后端的服务器，提供服务。的地址为，的地址为。配置的服务操作如下：                                装包
              配置主页  
                            启服务
   |                          检查监听端口

的配置如下：                                装包
              配置主页  
                            启服务
   |                          检查监听端口

在代理服务器上配置反向代理服务器，操作如下：  

 {
           {                                    定义集群
               = _= _=
                _= _=    
         最大失败数，失败超时时间，权重为  
         }
                {                                  网页根目录
                            
                         _            指定为代理服务器
                            
             }
}
                             重载配置
客户端测试反向代理负载均衡，效果如图：

地址重写规则案例

操作如下：  
                                加在里
    
   
客户端访问  
结果如下：访问跳转到操作如下：  
                       加在里
   
客户端访问  
结果如下：

根据用户不同的浏览器，访问相同页面，返回不同的结果      返回          返回操作如下：
  
__  {
                  
        }                                            加在里
__  {
                  
        } 
  {}  创建目录
   部署主页
    
   
客户端访问
  

  

如果文件不存在，则调转到首页操作如下：
  
 _{
                  
        }                                            加在里
   
客户端访问：客户端访问
         随便输入文件名
结果如下：
语法选项详解：   选项选项：      —：停止执行其他的重写规则，完成本次请求—：停止执行其他重写规则，根据继续搜索其他，地址栏不改变— 临时重定向，地址栏改变，爬虫不更新—永久重定向，地址栏改变，爬虫更新
总结
是一个轻量级的服务器，同样起 服务，比 占用更少的内存及资源，功能很强大，应用也很广泛。高度模块化的设计，编写模块相对简单。目前越来越受到人们的喜爱。

相关推荐
  搭建文件上传下载服务 封锁恶意 ，并且定时取消的两种脚本作者 | 幸山编辑 | 京露

幸山，腾讯云助理工程师，目前就职于腾讯，负责腾讯云内容分发网络和动态加速网络的测试工作，全心全意为开发者提供最优质的网络加速服务。

简介
全称为    是一个在和以及中的前端软件包管理器。基于包管理，能够从指定的服务器自动下载包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软体包，无须繁琐地一次次下载、安装。提供了查找、安装、删除某一个、一组甚至全部软件包的命令，而且命令简洁而又好记。
 的命令形式一般是如下：
    
其中的是可选的，选项包括帮助，当安装过程提示选择全部为，不显示安装的过程等等。为所要进行的操作， 是操作的对象。
 可通过命令查看已安装的 ：
  | 

的配置文件
的配置文件分为两部分，主配置文件和源配置文件：
主配置文件：，通常在路径下，定义了的全局配置，应该只有一个主配置文件。
源配置文件：，通常在路径下，定义了源服务器的地址，顾名思义，就是安装包获取的源路径，可以包含多个，必须是文件后缀，名称可以自定义，安装更新时，根据主配置文件决定获取哪个包来安装。
主配置文件
打开可以查看配置文件：
 


=
      缓存的目录， 在此存储下载的 包和数据库，默认设置为
=
     安装完成后是否保留软件包，为不保留默认为，为保留
=
      信息输出等级，范围为，缺省为
=
      日志文件位置。用户可以到 文件去查询过去所做的更新。
=
     包的策略。一共有两个选项， 和，这个作用是如果你设置了多个，而同一软件在不同的 中同时存在， 应该安装哪一个，如果是，则 会安装最新的那个版本。如果是，则 会将服务器 以字母表排序，并选择最后的那个服务器上的软件安装。一般都是选。
=
     有和两个选项，设置为，则 只会安装和系统架构匹配的软件包，例如， 不会将的软件包安装在适合的系统中。默认为。
=
      的一个参数，具体请参阅官方文档，简单的说就是相当于，允许更新陈旧的包。
=
     是否检查  ，一种密钥方式签名。有和两个选择，分别代表是否进行校验，以确定 包的来源是有效和安全的。这个选项如果设置在部分，则对每个 都有效。默认值为。
=
     是否启用插件，默认为允许，表示不允许。我们一般会用这个插件。
_=
     允许保留多少个内核包。
=
     指定一个软件包， 会根据这个包判断你的发行版本，默认是，也可以是安装的任何针对自己发行版的 包。
=
     网络连接发生错误后的重试次数，如果设为，则会无限重试。默认值为。
=
     排除某些软件在安装升级名单之外，可以用通配符，列表中各个项目要用空格隔开，这个对于安装了诸如美化包，中文补丁的朋友特别有用。
源配置文件
源配置文件定义了软件仓库， 安装更新的软件包都是从配置的软件仓库获取的，在目录下后缀文件均是可用配置。
源配置文件的一般格式如下：

=    
=

 是用于区别各个不同的，必须有一个独一无二的名称；

 是对 的描述，支持像 这样的变量；

 是服务器设置中最重要的部分，只有设置正确，才能从上面获取软件。它的格式是：


=
　　　　 
　　　　 
其中 支持的协议有    三种。 后可以跟多个，你可以自己改为速度比较快的镜像站，但 只能有一个，也就是说不能像如下格式：
=
=
=
 之后可以加上多个选项，如、、 等，比如：

=       
=
　　　　 
　　　　 
=
     决定这个配置是否可用，默认为，可用，设置为时该配置无效
=
     有和两个值，与中相同，即是否需要对获取的软件包进行校验
=
     同
=
      有两个选项 和，意思分别是有多个可供选择时， 选择的次序， 是随机选择，如果连接失败则使用下一个，依次循环， 则根据 的次序从第一个开始，默认是。
===
     指定一个镜像服务器的地址列表，通俗的讲，是从后面的获取资源，而是将多个放在网上，从多个中获取最快的链接来获取资源，和配置最好只开启一个
=
     定义用于校验的密钥，就是数位签章的公钥档所在位置！
源配置文件还支持、、等参数，用于构造：
：发行版的版本，去主版本号，即取，取，从部分的获取，如果没有，则根据包进行判断，查看的方法： 或者  
：体系，如，等，通过命令“” 或者“ ”查看
：的基本体系组，例如，和机器都具有的基本架构，和机器具有_的基本架构。通过命令“ ”查看。
这个地方有个怪异的事情就是，的值是的版本好，在主配置文件中配置为“”，这三个从名称上看根本没有一点联系，完全违背编程规范。
遇到的问题解决
想在机器上查看的安装情况，通过命令“  ”，提示镜像：

 直接镜像也是不通的：

查看源配置文件可以看到镜像的构造情况：

对应到，即是，是_，于是手动查看这两个参数的值：

 不过通过“  ”查看版本居然提示未安装：

与镜像并不一致，即获取的是错的，于是用刚才命令获取的参数组装进行，成功：

即之前是错误获取了参数，于是将里的参数全部置换为，问题解决：

深层次的原因，即为何获取的是，而不是出来的，就与未安装有关，既然提示未安装，那么就尝试安装：  ，得到错误提示：

即，即将安装的与已经安装的冲突，不能安装，而的版本正好是：

就是说读的是的版本号，这就是错误根因，即系统运行的是腾讯自身的系统，读取的就出现了错误另外一个运行良好的系统装的是普通的，不过考虑到将删掉，重新安装可能会出现更多难以预料的问题，因此只将配置文件修改就停止了。
相关推荐
系统安装环境前言
“在一次正常的活动促销之后，客服开始陆续反馈有用户反应在抢标的时候打不开网页或者 ，在打开的时候标的就已经被抢光了。
刚开始没有特别的上心，觉得抢标不就是这样吗，抢小米手机的时候不也是这样吗？
随着活动继续推进，有更多的用户强烈抗议，用户领了加息券或者抵现券之后抢不上标的，认为是平台作假故意不让他们使用以达到节省资源。
分析过程
以前也会有陆续的用户反馈不减少的情况，给客户以小米抢手机为例子解释就过去了，这次用户反馈太过强烈，才让我们重视了起来。
我们前端一共有三款产品：、官网和 ，其中  使用量最大，官网其次， 平时使用量极少但是做活动期间流量会暴增活动一般都是  游戏居多， 也便于推广营销。
前端的三款产品都是分别使用  负载到后端的两台  服务器中如下图，这次用户反馈基本在  和  端，所以重点观察这四台服务器。

首先怀疑网络带宽是否被涌满，找到网络工程师通过工具来监控，在抢标的时候带宽最高使用率只有  左右，随排除之。
再次怀疑  服务器是否抗不住了，使用  命令查看官网负载的两台服务器，在抢标的瞬间会飙到  左右，抢标后也慢慢的恢复了正常， 两台服务器高峰到 ，随后也恢复正常。
跟踪  服务器业务日志，发现在数据库更新层报请求不到新的数据库连接或者数据库连接已经用完，认为是数据库的最大连接数太小，于是调整  数据库最大连接数为以往的  倍。
下次抢标的时候继续观察业务日志，发现已经不报数据库连接的相关错误了，但还是很多用户反馈抢标时候打不开页面。
继续跟踪  服务器，在抢标时使用命令 | | 查看  的连接数有  左右，随机查看  配置文件中设置的最大连接数为  默认的最大连接数为 。
原来抢标期间连接数已经到达最大连接数，很多用户在抢标的过程中已经获取不到  连接导致页面无响应或者  一直在等待中。于是调整  配置文件中的最大连接数为 。
在抢标过程中继续观察， 的连接数在抢标的时候仍然可以飙到  之间，根据客服反馈，仍然有很多用户反馈抢标的问题，但比之前稍微好一点，但是有零星的用户反馈已经抢到标的，最后又给回退了。
然后继续观察数据库服务器，使用  命令和   查看  主库和从库的各项负载吓一跳如下图， 服务器主库的各项指标均已经达到峰值，而从库几乎没有太大压力。

跟踪代码发现，三端的业务代码全部连接主库，从库只有后台的查询业务在使用，于是立刻启动改造。
将除在抢标过程中的查询外，其他页面或者业务的所有查询改造为查询从库，改造之后观察，发现主库的压力明显减少，从库的压力开始上来了。如下图：

根据客服的反馈，改造之后抢到标回退的问题几乎没有了，抢标过程中页面打不开或者打开慢的问题有一定的缓解但仍有部分用户反馈此问题。
根据上面各项目分析得出结果：

负载的两台服务器均已经达到处理的极限，需要配置更多的服务器来负载。
 主库的压力明显减少，但是从库的压力却上去了，需要将现在的一主一从一从改为一主多从的模式。
彻底解决这些问题，需要综合考虑平台的整体优化，如：业务优化去掉业务中热点、增加缓存、部分页面静态化可以使用雅虎和谷歌的前端优化规则，网上也有很多的测试网站可以评测等等。

当时根据这些情况写了一份优化的报告，见下文：
优化报告
背景
随着公司业务不断发展，业务量和用户量的激增，官网  也从最初的  到现在的 ， 活跃用户更是大幅增加。
因此对平台目前的技术架构提出了更大的挑战，特别是近期平台标源紧张的情况下，满标的时间更是越来越短，服务器的压力也越来越大。因此需要升级目前的系统架构，以支持更大的用户量和业务量。

用户访问示意图
目前平台面向用户的有三款产品面：平台官网、平台  和平台小网页，其中平台官网和平台  的压力比较大。
存在的问题
用户抢标的时候问题集中在以下几个方面：

网页或者  打不开。
网站或者  打开慢。
抢标过程中转账成功后，因为服务器负责压力大更新失败，再次退款。
数据库连接数用完，导致满标后添加投资记录失败，回退标的进度。

分析
通过对近期的服务器参数、并发量，以及系统日志等进行深入的分析得出：

平台官网、平台  抢标过程中服务器压力巨大，平台  问题更加突出，抢标高峰期间单台  服务器  最大连接数已经接近 ，接近  最大的处理能力。
数据库服务器压力巨大。

数据库压力主要在两个时期比较突出：

当平台做活动的时候，官网、小网页、 访问量巨增，导致数据查询量跟着巨增，当到达数据库处理极限时，就会表现出网站打开慢等问题。
当用户抢标的时候，用户抢标的压力又分为两个阶段：抢标前和抢标中。抢标前，因为满标速度很快，用户提前打开抢标页面不断刷新，这样数据库的查询压力会不断增大，如果抢标的用户量非常大，会导致在抢标之前将数据库连接数用完。抢标中，单次购买大概会涉及  张左右表进行更改查询，每个标的份额  万大概每次会有  人左右购买完成满标，以中间值  人计算，在几秒的时间内需要对数据更新  次仅仅是更新，不包括查询 ，产生大量并发，可能会导致更新失败或者连接超时，从而影响到用户投标和系统正常满标。

解决方案
 服务器解决方案
单个用户访问  服务的示意图，如下：

目前网站和平台  均是采用了两台服务来做均衡负载，每台服务器中安装了  来做服务端接受处理，每台  最大可以处理大约  条连接。因此理论上目前网站或者  可以处理大于  个用户请求。
如果要支持同时  的请求，则需要  台  服务器来支持因此目前缺少  台  服务器。
升级服务器后的访问示意图，如下：

数据库解决方案
当前数据库的部署方案，如下图：


主从分离解决主库  的查询压力。目前平台官网、 均连接  主库导致主库压力倍增，把服务中的查询全部迁移到从数据库可以大量减轻主库的压力。
增加缓存服务器。当从库查询到达峰值的时候，也会影响主从的同步，从而影响交易，因此对用户经常使用的查询进行缓存以达到减少数据库的请求压力，需要新增三台缓存服务器搭建  集群。


其他优化

官网首页静态化，从  统计来分析，首页占比网站的整体访问量的  左右，对于首页不经常变动的数据通过静态化来处理，提升官网打开的流畅度。
 服务器的优化，开启  压缩，配置合理的链接数等。
去掉投资过程中的更新热点：标的进度表。每次投标成功或者失败都需要对标的进度表进行更新，多线程更新的时候就会出现乐观锁等问题。去掉过程中的更新，只在满标后将标的进度信息保存在标的进度表，优化投资过程中对数据库的压力。

服务器升级方案
平台最大的压力来自于数据库，需要将现在的一主一从，改为一主四从。官网小网页产生的大量查询，由虚  分发到三台从库，后台管理查询走另外的一个从库。
数据库需要新增三台服务器，数据库升级后的示意图如下：

通过增加缓存可以减少数据库的压力，除了需要新增两台大内存的缓存服务器，还需要新增三台  服务器分解用户访问请求。

 需要新增两台服务器
在抢标过程中  服务器压力最大，需要新增两台服务器，配置完成后的示意图如下：

官网需要新增一台服务器
官网在抢标过程也有一定的压力，需要新增一条服务器，完成后示意图如下：

总合计之后需要购置  台服务器，其中有两台要求有大内存 以上，所有优化方案投产后，问题解决，抢标无忧！

作者：张强纯洁的微笑，曾经先后在互联网金融、第三方支付公司担任高级  工程师、架构师、技术经理、技术负责人等职务。在互联网金融工作期间，从零参与公司技术平台建设，组织平台进行过四次大架构升级。目前在一家第三方支付公司做架构师，负责支付公司大数据平台建设。
编辑：陶家龙、孙淑娟出处： 技术栈 微信公众号 、前言
在上一篇打造黑苹果一组装硬件的选择与组装 中，我们已经给大家在硬件上有了一个建议。如果你已经购买了硬件了，或者你原来的硬件就已经满足了黑的需求，那么，下面就要开始安装黑系统了。
如果你不愿意折腾，建议在仓库盘上先安装一个的操作系统，然后上淘宝，找一个黑系统安装的店家，花上百十块钱，就可以安装好了，省的自己研究。

在仓库盘上安装是因为我们要在固态硬盘上安装 系统，安装好了之后，你可以选择保留仓库盘的或者格式化掉，随便你咯在仓库盘格式化的时候，不推荐使用硬盘分区格式，原生不支持。


推荐一个商家 你自己去找。他们的技术实力不错，我自己在黑苹果的过程中遇到一些问题，他们给予了有效的解答。我第一次黑苹果，也是他们帮忙安装的。不过店家是做服务的，所以很忙，因此有时候回复慢一些，还需要等一下。
另外，淘宝上的店家虽然都说是安装的原版，但实际上都是懒人版。懒人版使用上基本没问题。
本章节的内容你可以查看  网站的   频道。当然是英文的。如果你英文牛逼，就以原版为参照，我的博文辅助，如果英文不好，那就以我的为主，那边的为参照。
第一步，准备一台电脑
这一步，比较坑。因为它要求你先有一台电脑。看管可能要愤怒了，我不就是因为没有菜黑的吗？这是一个先有鸡还是先有蛋的坑爹问题。解决方法有三：

找朋友借一台。可行性 ★★★。苹果电脑的保有量实在比较小，如果是一线城市，或者大学生，应该是可以解决的。
买一台。可行性 ★ 。虽然这个解决方法有点可笑，但我就是这样的呀，我本来就有，黑主要是为了避免和的快捷键不一致导致我总是混乱在到底按什么按键上，否则我是不会黑的。
找上面的淘宝店家先给自己黑一个，然后你就有电脑啦。可行性 ★★★★★ 。

当然，你要说了，我已经找淘宝卖家黑好了系统，我为毛还要再制作一个安装盘呢？其实道理很简单，难道，你就不会重新安装系统了？你每次黑苹果都去淘宝上花钱黑？
最重要的是，淘宝上黑的系统是升级不了的因为懒人版分区的原因。如果系统升级了，那不是干瞪眼
当然，有钱，另说！
先不管你怎么找一台电脑了，反正言尽于此。
另外，在黑的时候，最好是两个人两台电脑，方便互相提醒研究，以及查阅资料。
第二步，相关准备工作

在  注册一个账户。点击 这里 注册。
注册完成后，到  频道下载  和  两个软件，找最新的下载。当前最新为   和    
准备一个  以上的盘，质量要好一点的。
备份你原来的资料

 是制作启动盘的工具。 是系统引导，以及安装驱动的工具。
第三步，下载  原版系统

打开苹果电脑的   ，并登陆你的  。
下载   系统。

  是目前最新的苹果系统。


这个系统文件是很大的，下载过程也是比较久的，要看你的网速。经过漫长的等待，就下载好了。
最后在  里面就会出现一个   
下载好了之后，放在这里就可以了。啥也不用动
第四步，格式化你的盘
下面，图片我使用的是 的图片。是英文的，如果你不能准确理解英文与中文的关系，建议你将  系统调整到英文，然后再进行下面的操作。系统偏好设置中，语言与地区，将拖动到简体中文的上面，然后重启系统就可以了。

插入你准备好的 盘
打开 磁盘工具  ，路径  
在左侧栏，选中你插入的盘



点击上方的  按钮 中文版为 抹掉 
 在弹出来的对话框中，名字后面输入
第二个，选择    
 第三个，选择   


如上图所示，然后再点击  按钮。

如上图，执行完成之后，我们点击  按钮，中文版应该为 完成这里，需要注意的是，有可能执行一次会失败，如果失败了，就再来一次，一般就成功了。
好了，到这一步，我们的盘就准备好了，下面我们要开始制作了。
第五步，用  创建一个可以启动的 盘

解压并打开我们上面下载的  工具
点击     。一路下来，有没有下面一路的畅爽感？呵呵。



到了如上图的这一步，我们点击右侧的 上面的图标，选择我们的盘，然后点击  按钮。

然后在    这一步选择  然后点击   按钮，这一步没有截图。但是应该算表述得清楚。




在    这一步，选择    这个，然后点击   按钮。如上图所示。
在   这一步，需要选择你的显卡类型。如果你是用的集成显卡，就什么都不用选，直接点击  按钮，如果你是用的  或者其他 黑支持的英伟达显卡，那么，这里就要点选 英伟达 的显卡驱动 ，绿色的眼睛图标，这里不放了。然后再点击  按钮



然后就到了这一步了，如果你是用的集成显卡，就和上面的图片一模一样，如果你点选了 英伟达 的显卡图标，那么这里就有个图标。一切准备好后，我们点击   按钮 ，就会到下面的图片


正在复制文件。
因为文件比较大，需要的时间比较长，大概分钟到分钟的时间，需要耐心等待一下。中间别手贱，到处乱搞。
最后，在盘制作完成之后，将我们下载的  压缩包解压，得到一个文件夹，里面有一个叫  的软件，复制到我们的盘当中。然后我们的黑系统安装盘就算制作完成了。
本文由原创，部分内容以及图片参考与  网站，允许转载，但转载必须附注首发链接。谢谢。
首发地址：
原文链接：作者 | 王拥军

王拥军，毕业于天津大学计算机系，拥有从计算机硬件到操作系统安全、从后台服务器到客户端的全平台工作经历。目前在腾讯自选股从事互联网证券软件研发管理。对上市公司及创业团队的产品、文化、经营等具有独到的见解。
个人公众号“水滴的声音”，专注企业文化、团队管理。

前言
最近大家都在讨论岁的问题。笔者前几天从公司管理角度写了一篇《从华为大龄员工看员工激励、股权激励的问题》，今天从员工自身发展角度再讨论一下。
观点

工资的高低跟年龄的大小无关，只跟个人的产出有关；

工资的高低跟岗位的高下无关，只跟行业的供需有关；

没有持续火爆的行业，也没有彻底消失的行业；

岁的出路有三种：蜕变、吃老本、转行。


软件工程师就像妓女
昨天去超市，门口贴着一个招聘广告，其中有两个地方吸引了我：
、岁以下；
、月薪。
不知道各位敲键盘码代码的软件工程师作何感想。
岁，不是今天才有这个问题的。只不过，之前轮不到后的最广大一波人群，所以没有太多人关注。
现在，年，年出生的也已经岁了。难怪，岁的问题开始引起了大家的关注。
体力劳动密集型行业，岁一直都是个坎儿。后坐在办公室里敲电脑，以为自己不是靠体力，是靠的脑力，所以很少有人考虑过这个问题。
其实，早就有人提出过：软件工程师就像妓女，吃青春饭。只不过，当时大家只是把这句话当做玩笑，没人当真。
没想到，这么快就应验了！
岁的变化
有几个问题值得探究：
、许多行业，许多工种，尽管坐在办公室里，真的不属于体力密集型岗位么？
 、岁，是否是人类体力、脑力的转折点？
“码农”这个词是软件工程师对自己的自嘲，没想到竟然一语成谶。
我不知道生理学家的研究是否表明岁人类的体力与脑力都有下滑，但是从个人的感受，确实，岁跟岁时候的精力真的是无法相比。
无论是对新知识的学习速度，还是敲代码的速度，岁的我确实比岁的我下降不少。
工地上的农民工岁的时候可能跟岁差不多，然而整天憋在办公室缺乏体力运动的“码农”，岁的体力跟岁相比完全不在同一个层次。
那么，作为码农，岁的我真的要被早早地淘汰了么？未来的道路又在哪里呢？
体力、技术、技艺
我冥思苦想自己的出路，对比岁的我与岁的我，看看年龄除了带走“精力充沛”这个优势之外，是否同时给我带来某些伴随着岁月而成长的优势，甚至于：未来当我岁、岁的时候，我何以立足在这个世上？
我非常明确目前的社会，尽管我被淘汰，走下坡路，也绝对有饭吃、饿不死。然而，仅仅是“有饭吃饿不死”，这绝非我的愿望。
如果有某些优势是伴随着年龄和经历而成长的，那么，这种优势，我显然要尽力提升、发挥，这样，不仅仅岁的我会比岁更有价值，而且在未来岁、岁的时候，会更加比现在的时候具有价值。
经过观察，我发现，医生这个行业，越老越吃香；还有教师、律师、会计师等等。
那么，这些行业跟工地上的建筑工有何区别呢？
经过对比我发现：
工地上的建筑工，岁跟岁，做的事情都类似，效果差别不大；
医生和老师就不同了，岁的医生明显比岁的医生要靠谱，岁的老师讲课的水平也绝非岁能够媲美。
当然了，如果不努力，岁也有比较差劲的医生和老师，但只要自己肯努力，十年时间，自己的看病经验、讲课风格，确实会有本质的区别。
为什么会这样？
因为工地上大部分的工作都比较简单、单调，两只手出力气即可；而看病和教书，经验太重要了，遇到过的病情越复杂，碰到过的学生越调皮，经验积累的越丰富。
 其实，如果拿工作“复杂度”来讲，体力劳动也有很多复杂度较高，讲究经验的工种，比如说：焊工、木工、等等。
比如说：焊工，用电焊还是气焊？多高的温度？多大的焊条？焊过之后是否够结实？消耗了多少材料？
难怪总有新闻报道：许多工厂严重缺乏高级技工。
“技工”，是“技术工人”，这说明工人虽多，但懂技术的不多，尤其是技术好的就更少了。
据说某些工程上的焊接工作，全国也就屈指可数那么几个焊工可以搞得定！这就不仅仅是“技术”了，而称得上“技艺”，即：将技术发挥到了艺术的地步。
出自“技艺”之手的，就不叫工业品了，而叫“艺术品”。比如：瑞士手表、紫砂壶。
三大核心竞争力
曾经有人讲过这么个故事：一台发动机坏了，一大堆工人修不好，请来个专家，专家听了听声音，在发动机某个位置划了根线，说“把这里的线圈重新绕一下”，果然，问题就解决了。老板说：划这根线值块钱，绕线圈的体力活只值块钱。
软件工程师也好，码农也好，如果一直只会干绕线圈的这种谁都能很快学会的活儿，显然是没有太大价值的，就相当于工地上只会搬砖一样。
那么，软件行业的“技艺”体现在何处呢？
、时刻关注新知识新技术的发展，保持自己在行业内不至于落后。
对于新知识，年轻人往往有两个优势：容易接受、学习速度快。
岁，学习速度慢，这是自然的，但最可怕的，并不是速度，而是：对新知识的接受意愿不强，甚至排斥，认为自己的知识足够了。
这个弊病，不仅仅软件工程师有，医生、教师、律师、建筑师，也都有！自以为有了十多年的经验，哪里还有什么自己摆不平的问题，于是对于新知识完全排斥，甚至对于业界有何新的变动毫不知情！
软件工程师抱怨软件行业两三年一小变，五六年一大变，那么，医疗、教育、法律、建筑，难道不是么？最新的流行病、手术方式、教育理念、法律条文、建筑标准，这些，哪一个不是年年在变？
、努力解决自己项目中的疑难问题，提升自己“划线”的能力。
绕线圈绕的快，也算是能力的提升。但终归没有“划线”的价值高。
代码写的再快，显然要比一眼就能定位到软件缺陷差那么点意思。
或者，干脆，用完全颠覆性的方案，几何级的提升代码的速度和质量。
、时刻关注自己从事的事务中，有哪些地方可以改进。
如果说“划线”仅仅是发现问题、解决问题，那么，比这个层次更高的，则是：提出问题。
也就是说：发动机没有故障的状况下，如何提升发动机的性能，如何降低发动机的成本，等等。
岁的工程师，除非是惰性十足的，许多都能够做到“划线”解决问题的地步，然而正是因为“所有问题都能够解决了”，逐渐失去了上升的可能。
然而，学无止境，技无止境，艺无止境。
供需变化与吃老本
当然，划线有划线的价值，绕线圈有绕线圈的价值，工地上有很多多岁甚至多岁的农民工，软件行业自然也缺不了码代码的人，只是价值的差异而已。
其实，即便是人人都能干的搬砖，工资也在不断提升，十年之间提升了十倍以上，比软件工程师的提升都高。
不同职位工资的差异，主要是由供需情况决定的。
工地上工资之所以上涨，是因为没有多少年轻人愿意去工地上干苦力活儿，年轻人宁愿拿块的工资坐在办公室里，也不愿意风吹日晒挣那甚至上万。
十年来，各个大学最为热门的那些专业，为社会提供了源源不断的人力供应，其中，包括软件。
信息时代的来临，也确实需要如此之多的软件工程师，然而，终有一天，供需的天平发生逆转，那么，个人的价值不再取决于自己的行业，而完全取决于自己的技艺水平。
凭什么敲两行代码就要比搬两块砖值钱？如果这个世界上所有人都会敲代码，没有人愿意搬砖，那么，搬砖绝对会比敲代码更赚钱！
由于信息时代的继续发展，各行各业的信息化需求依然未能得到满足，岁哪怕只会敲代码的码农，也有钱可以赚，就如同工地上别说岁了，连岁的农民工也多得是。今天，餐饮服务行业大多是岁以下的姑娘，未来，会有更多阿姨在为大家点菜。
所以，即便是技术没有本质提升的软件工程师，也不见得马上就会完全失业，顶多就是变相降薪。
其实降薪这个事情很正常，前几年钢铁行业火爆，钢厂工人收入稳步提升，这两年钢铁需求量萎缩，相关人员收入也下降不少。
只是，习惯了一路上升的世纪宠儿，突然面临转折，终归需要一段时间适应。
被动换行
以上无论技术高也好，低也罢，终归还是能够依靠已有的技术生存下去的。然而，最最糟糕的，是被动换行。
纺织行业伴随着机械化的进展，许多中年工人下岗。软件行业，就一定会长盛不衰么？或者，规模一直会持续暴涨么？
软件，也属于一种基础设施。
电脑硬件经历十多年的飞速发展，革新的速度已经逐渐慢了下来。跟过去十年从到的量级飞跃不同，近几年，一直在的级别。
同样的，软件也一样。大部分行业的软件，某一天，一定会发展到不需要大幅改进的地步。
也就是说：软件的需求依然存在，但需求量已经没有那么巨大了。
比如说：通讯软件、社交软件、视频软件、办公软件，等等。和，不知道还有多少人在用，不知道还有多少人在用。
导致软件工程师需求减少的，不仅仅是软件的需求，只怕生产率的提升带来的从业人数的减少威力更为强大。
做一个网站，十年前所需要的人力，跟今天所需要的人力，完全不同。
这是因为软件的生产工具得到了大幅的改善。这种改善不仅仅导致工作量的减少，而且导致软件行业的入门门槛更低，甚至导致非专业人士都足以短时间内完成应用软件的开发。
机器能够做得事情很多，所以软件的需求量巨大；机器能够做得事情很多，连软件也能够由机器完成，所以软件工程师的需求量会变小。
某一天，有很多软件工程师需要转行，这没有什么好奇怪的。农民工都是农民转行做了工人，越是生存状态不佳的人越是喜欢换行，反倒是生存状态好的人换起行来显得被动。
那又能怎样呢？二十多年前，那么多人同时下岗。未来，软件工程师即便要下岗，也不是一次性的，因为企业经营的效率得到了提升，大家不会等到迫不得已才一起裁员。这样也好，再就业的竞争稍微小一点。
结论
人无远虑必有近忧。要么，把自己单一的技能做到极致，哪怕只有一个软件工程师的岗位，那也是你的；要么，多掌握几种本领。

以上内容来自作者本人公众号【水滴的声音】关注企业文化、团队管理。