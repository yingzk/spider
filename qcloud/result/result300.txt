Dubbo 发布了恢复维护后的第一个版本 2.5.4，主要是解决 issues 和依赖升级。
dubbo-2.5.4
Fixed issues

不能优雅停机的问题
MonitorFilter监控统计功能阻塞rpc流程
动态配置：设置指定的consumer不生效，provider端动态配置删除后仍起作用
路由规则解析错误，导致路由规则不生效
异步配置意外透传
并发执行限流不准确
社区反馈的一些小修复

   
依赖升级

一些插件、测试依赖升级待整理


代码格式化
优化端找不到时的提示信息

升级的   已到最新版。

视频教程项目实战 我们在做微信公众号的开发时，都需要一个开发的环境，我们平常叫做开发空间，常用的空间我们在新浪和百度可以申请，但是，如果我们有一台腾讯云服务器，我们便可以利用它来作为我们微信公众号的开发环境，下面我给大家详细介绍几种配置腾讯云服务器环境的方法和开发模式的接入。
    准备条件：腾讯云服务器一台，客户端软件，，。
配置
登陆后打开服务器管理界面，点击服务器管理图标，进入服务器管理界面。
在服务器管理器中找到角色并点击，然后在旁边点击 添加服务器角色，在弹出的窗口中选择 。点击“下一步”按钮，选中选项，
设置完成后，点击按钮，完成安装。
在本地浏览器中通过服务器公网查看服务器是否正常，如果画面出现图片，说明安装配置成功。
接下来，安装
下载的安装包。下载地址选择对应版本安装包。
下载完成后，安装，选择服务时，点击 选项，然后等待安装完成。安装完成后在服务器网站根目录下 目录下创建一个格式代码检验是否成功。
最后，安装。
到官网 下载软件，选择对应电脑版本。
下载完成后，解压文件，运行安装文件，安装过程不懂的话默认安装。
安装成功后运行，在命令行到安装目录，输入命令    按下回车键，会出现默认用户名，用户密码为空，最好修改为自己的密码。
这样。就完成了的环境配置。
最后，我们在本地电脑安装客户端软件，将微信公众号开发的代码上传到服务器目录下。然后填好公众号平台的开发者模式就行了。具体的步骤和服务器服务的安装这里不介绍了
上面的这种配置步骤一般看起来就让人觉得头晕，其实，我们也可以利用快速搭建环境。
在服务器中下载软件，点击安装，安装过程我就不说了，实在不懂就百度一下啊。安装成功后，我们在服务器的右下角右击运行图标，将软件的状态切换为在线，然后在本地电脑浏览器上登陆服务器检验是否安装成功，出现的信息画面表明安装成功了。
接下来，就是在设置数据库的密码就了。不过对于微信公众开发环境来说，这步可以省略，如果你想建一个个人博客或论坛，这就必须要设置了，我们只需要将我们的微信公众号开发代码上传到 的目录下就行了。
利用搭建开发环境，这就更简单多了。
对于上面的两种方法，利用显得更加的简单，我们在服务器中下载好安装包时，点击安装，会出现命令窗口，根据提示选择安装的版本和版本，然后等待安装，在最后出现的用户名和密码设置中设置完成后，就完成我们开发所需的环境了，同样，将我们的微信公众号开发代码上传到网站文件下就可以了。
以上是本人在入门微信公众号开发时摸索过的方法，文章中有错误的地方希望多多见谅和指出修改，当然这只是微信公众号开发环境的配置，想能够到开发模式，还要完善其他的配置步骤，这里不说了。希望能帮助大家，谢谢。

相关推荐
【腾讯云的种玩法】云中漫步，做个公众号方便生活、取悦自己
利用腾讯云服务器进行微校开放平台开发
微信小程序 扶持计划个人介绍：腾讯后台工程师，专注图片压缩及存储系统一百年不动摇，并致力于做一名相关前沿技术的人话翻译家。

这两天笔者的朋友圈被开源编码器刷屏，“图片大小减小”、“质量不变”这样的字眼刺激了我们的肾上腺，的同学也为我们带来了第一手的测试资料——谷歌开源图片压缩算法实测体验报告。
如果这样的神器真的如此神，那还有啥事儿呢。于是我们抱着强烈的好奇心实地考察了这个连名字都不知道怎么念的新鲜事物。
结论是：

在基于相同客观质量以为评价标准的条件下观察主观视觉效果的优势是有效改善了传统在低质量条件下“振铃效应”产生的伪影；劣势是编码出的图片在质量较低时=有一定的“钝化效应”，对于图片中细节精细的部分，丢掉了较多的信息。

同样基于相同客观质量条件下并不以填的参数为标准，为什么不以它为标准参见“原理解析”小节图片大小与传统相比并无明显优势。组大概比传统的编码结果减小了，组和传统基本持平，组反而大出了。

延时方面，编码器对于主流的非高清图规格如 的处理延时在秒级或秒级，业务主流压缩工具对于相同规格的处理延时均在以内


原理解析：
基于同样来源于的图片视觉差异评价工具。的评价体系基于三个传统方法没有考虑的原则：

人眼对强黄色光附近蓝光变化是不敏感的，因此黄光区域附近的蓝光可以用更少的来编码

人眼对蓝光有着较低的空间分辨率，视网膜中用于分辨高清细节的区域没有蓝色光的受体，故高频区域的蓝色光部分可以用更粗的粒度编码。

将图像中的噪声区域分辨出来进行粗粒度的编码。


基于这三点，主要从两方面下手来进行：

对全局量化表进行微调，这一步和我们调整质量参数本质上是一样的

对系数的高频部分进行有选择的丢弃。


第二步就比较了。通常在我们使用例如等工具压缩图片时降低质量参数本质上就是在量化步骤按照一定规则丢弃高频信息，最终反映在的中。相当于绕开了制定好的量化规则降低了质量而且不告诉用户，让用户以为仍然保持了质量怎么感觉也有了一点流氓气质呢，。所以在后续测试中我们发现，在相同条件下，传统的质量参数可以比编码出来的低大约个点。原因主要就在这里。
总的处理流程是尝试多种量化表及系数两个方面的可能性，然后分别将尝试的结果放到评测工具中评分，最后选择一张它认为最好的结果返回给用户。所以它的处理时延特别长。用参数打开的可以发现，平均一张图大概它将尝试接近次的迭代。
测试样本：
分别选取，  三种分辨率的格式图片各张本来还选取了的照片分辨率图片做测试，但是由于时间有限，这部分待后续进行。三种分辨率的图片在选取的过程中综合考虑主色调的不同、明暗灰度的不同、场景的不同人工合成的图片还是自然风景照以考察该编码是否尽可能多的适用于不同场景。
测试场景及指标：
该编码器有参数可以指定，注释掉对于必须大于部分的代码之后可以设置任意值，经过第一轮初步测试发现， 以下的时候其实编码出的图片已经没有变化为什么还需要进一步研究，故实际选取      为测试对象。从编码时延、同指标下图片的对比以及视觉效果还有内存消耗四个方面进行评估。
测试环境及工具：
机型：     
测试工具：、编码器、视频质量评价工具集
测试结果：
时延、内存消耗、带宽节省

检测
检测方法是首先分别用和分别用的参数进行重新解码和编码，然后对每个质量的结果图与原图分别解码成源数据格式，最后用视频质量评测工具集中的工具进行评测，框架图可表示为：
 
当我们设定了以=为标准时候反过来再观察两种编码工具各自设定的值。经过统计发现，传统的质量比的质量平均大约小。举个例子也就是说，传统的质量和编码器的质量在客观质量评价体系当中是等价的。
同下图片大小对比：

应用场景的思考
编码器本质上弱化了参数在编码流程中的作用，可以比喻为编码界的“小米”，其效果类似于加强版的七牛图片“瘦身”功能。
因此对于图片细节要求不高且对图片质量不甚了解的用户或者当面对一个业务因为需要节省流量同时又不希望图片质量受太大影响而对质量参数选择困难时，是一个不错的入门选择。从流程方面看，多次的迭代以及新的评价工具的加入是延时过长的主要原因，也许利用并行化会是一个不错的优化方向。

相关推荐：图片流量节省大杀器：基于的自适应图片技术实践【腾讯云的种玩法】  整合万向优图图片管理能力，打造高效图片处理服务一、 引言
本文源于一个简单的想法 “在服务器进程中，加载搭建的场景，并驱动在客户端的行为”，这个想法引发了一系列的思考：

物理引擎的选择
如何从导出场景
如何用加载场景，并验证其正确性
如何驱动寻路
等等

带着上面的问题，作者花了大概两周的时间完成了组件选型、搭建、测试验证的工作，也整理完了这篇文章，分享给有相同疑问的同事。 因此，本文主要侧重于工作流的介绍和工具的使用，原理的介绍只会在必须的情况下提及，更多的原理需要大家去自行查阅，比如的使用、的应用、库的使用等，可以详读最后一节的参考文献。
下面开始，会逐步解决上面的问题，另外，列举一下文中用到的组件列表，方便大家提前查阅。


  


  


首先是物理引擎的选择，这里选择了，主要有两个原因：

开源，支持\\
有很多成功的游戏，已经成为腾讯内部的主流技术选型

下一节开始，会开始介绍环境下环境的搭建。
二、 环境搭建
 下载
下载，首先需要申请加入，进入官网，找到下载页，然后按步骤操作就好，系统会自动审核，大概分钟就可以搞定了。
得到授权后，可以进入主页下载版本，地址如下：
 编译
的编译十分简单，上写的也很清楚，开发机是环境，所以直接进入_文件夹，输入执行即可，编译成功会生成一系列的静态和动态库。
 _   





































 _   
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
提供和库，使用库编译可以连接进行调试，另外，因为执行时需要动态链接，所以也需要把动态库的路径添加到配置中，完成配置后执行刷新，同时也可以执行 进行检查是否添加成功。
 _  
 

_
 测试
这里选择的是_进行测试，首先需要修改代码中的为，不然编译时会找不到函数。同时编写，这里的链接顺序不要错了，内容如下
 =   

_=           \
          \
        _ \
        _ \
        _ \
        _  \
        _ \
        _ \
        _ \
          \
         \
         \
          \
          \
          \
          \
        _ \
        _ \
        _ \
        _ \
          \
         \
         \
         \
          

_ =           \
          \
        _ \
        _ \
        _ \
        _  \
        _ \
        _ \
        _ \
          \
         \
         \
          \
          \
          \
          \
        _ \
        _ \
        _ \
        _ \
          \
         \
         \
         \
          




          _
这里只编译测试，执行 即可，生成，执行测试是否成功。
三、 调试
上一小节，已经完成了在服务器端的编译，下面我们开始测试和服务器进程的连通调试。
首先介绍一下的工作原理，启动后会监听端口，服务器上启动的进程，需要连接上进行，连通后界面上会出现服务器创建的场景。
 安装
安装十分简单，进入官方下载页，下载安装即可，启动后可以看到的主界面，同时在当前机器上，  可以连通，说明正常启动，并监听端口成功。
下面是连接的示例代码：
     = __  

     = 
      = _  
       ==   {
          \
    }
      = 
      \ 
 搭建反向隧道
当前公司的开发机无法直接连上办公区的开发机，这里需要建立反向隧道。这里的反向隧道是把开发机上的请求，转到办公区的开发机上，这里才能实现和的连通。
开发机上建反向隧道比较简单，执行       就可以，其中是开发机。
开发机相对麻烦一些，作者先用的测试，启动后进程没有常驻，最后用解决了，的配置如下所示：

配置完成后，点击，登陆完成后，就可以连接上了。
这时可以在开发机上  端口，如果可以连通，就说明反向隧道已经建立成功。
 连通测试
在开发机上执行，可以在上看到服务器进程创建的场景，下图中的测试场景是从一个测试场景导出的。

下面开始介绍如何从一个测试场景导出在中可以加载的场景。
 场景导出
进入= ，下载，并按照说明操作，可以导出一份文件，需要注意的是，要把场景加到中，导出文件如下所示：
 = 
       
     
         
         
         
    
     
         
         
         
         
         
         
    
服务器端的加载配置并添加到场景中的代码如下：
     
     
       =        
      ==  {
         \
        
    }

     
     
     =   
     = 
        = 
        = 
     = 
    
四、 从场景导出
从场景导出的方法，查到的资料主要有两种方法，这两种方法都是基于库。
方法一是使用库，安装插件到中，项目地址在__ ，项目主页上介绍的方法比较简单，但依赖于地形数据，比较耗性能，网上还有一篇采用_选项导出的方法，尝试多次后没有成功，所以放弃了这一方法。
方法二是直接使用库，这里主要介绍下这种方法的导出过程。
在线手册 ，有兴趣的同学可以研究下。
 导出场景描述的文件
从上的源码，生成两个文件和=
把两个文件放到当前项目文件夹下，然后选择一个网格对象，在  菜单中根据需要选择导出为  文件，文件将被保存在项目目录中，扩展名为的文件。

 安装库
首先要从主页下载项目，。
下载完后，根据主页上的说明，下载，放到下，通过命令行，生成依赖的编译文件，的使用方法这里不再介绍，执行的命令如下： —= 
然后需要下载库，进入 ，下载即可，下载完成后放到目录下，如下图所示：

用打开项目，执行编译如果出现了连接错误，可以尝试将项目——项目属性——配置属性——连接器——清单文件——嵌入清单 “是”改为“否”，编译成功后，可以在目录下找到文件，双击打开即可。中提供了两个测试场景，在中选择其中一个进行加载，关于的使用，这里不再详述
 
 导入场景文件，导出文件
把上面导出的文件放到下，然后选择目标文件，执行，即可完成的构建，如下图所示：

右侧支持调整参数，调整完成后点击可以再次生成，确认后点击即可生成服务器可以使用的文件。
五、 服务器加载文件
 环境，环境搭建
服务器加载文件，需要用到中的库，所以，首先需要在开发环境，搞完编译问题。
把之前下载的，在下解压，并在的目录下创建，库没有任何外部的依赖，所以编译比较简单，编译生成一个静态库。
 =   
=       

 = 



           


            


           
编译成功后，在之前的编译的中，加下对库的链接。
 =      




          _ 
 加载文件
加载文件，需要用到中的类，类提供了接口，但是使用导出的文件，不能直接用使用接口打开，因为这里用到了自定义的头部结构，头部结构定义在_中，如下所示：
 
{
     
     
     
     
}

 
{
     
     
}
生成的文件头部是结构，而不是，这里官方没有一个很好的说明，详细可以看下面的加载代码
      =  
       

      
     
    _  =    
      = 
    {
        
         
    }
      = _
    {
        
         
    }
      = _
    {
        
         
    }

      = 
     
    {
        
         
    }
      = 
     
    {
        
         
    }
初始化成功后，就可以读取所有的
      
       =     
    {
         
         =    
          = 
        {
            
             
        }

          || 
            

           =   __
          
          
         =    
          = 
        {
            
             
        }

          ___  
    }

     = 
      {
            \
         
    }

      _ = 
     =  _
      {
            \
         
    }
到此，结构已经构建完成，对象也完成初始化，下一步可以用对象进行寻路。
关于坐标系
在寻路测试中，碰到一个很奇怪的问题，在寻路控制一个角色移动时，发现角色会穿墙，对比了中的测试路径和中的移动轨迹发现二者是镜像关系，这才发现原来是坐标系的问题。
采用的是左手坐标系，中可选左手\右手，当然这里设置的是左手，而中采用的是右手坐标系。

实测发现，里的坐标点和中的坐标点，只有坐标是反的。 也就是说中的  ，对应中应该是  。 所以这里在调用 的时候，坐标系的坐标需要乘上转换为右手坐标系，得到的路径点座标结果，也需要再乘上，还原为左手坐标系。
这里建议大家把坐标转换封装起来，对上层调用的人来说，就不需要关注坐标的问题了。
 寻路测试
下面，我们来测试下服务器的寻路，这里的测试方法是，在中选择一个路径，在服务器上输出起始点，在上观察角色移动的路径，是否和中一致。
首先我们在中选择一个测试路径：

起点在   终点在  
在服务器上输出起始点，因为坐标系的原因，这里的是取反的，另外，因为轴没有变化，所以暂不输出坐标。
  
  
_ _
_ = 
__
  
  
  
  
  
  
  
  
  
测试一共经过个点后，到达目标。
在上，可以看到实际的模拟情况，这里抽取了几个截图。

测试结果显示，服务器的寻路结果和中是一致的。
六、 总结
回头我们最初的问题，如何从“中，导出物理场景给服务器使用，同时借助实现在场景中的角色导路”，借助于上面的工具，这个问题已经实现，最后我们再总结下具体的工作流。
工作流启动于中的场景修改后，需要依次执行以下步子骤：

使用生成加载的配置，同步到服务器，现在的格式是文件。
导出场景描述文件，采用生成文件，同步到服务器，现在是二进制的文件。
连接，检查步骤生成的配置是否；测试几次寻路点，检查步骤生成的文件是否。

最后附上参考资料和手册。
七、 参考资料

 手册

 手册
 
使用生成 
导出场景描述文件 生成原理高斯模糊英语： ，也叫高斯平滑，是在 、以及等图像处理软件中广泛使用的处理效果，通常用它来减少图像噪声以及降低细节层次。
简介
高斯模糊 是美国图像软件公司开发的一个图像处理软件 系列中的一个滤镜，具体的位置在：滤镜—模糊——高斯模糊！高斯模糊的原理中，它是根据高斯曲线调节像素色值，它是有选择地模糊图像。说得直白一点，就是高斯模糊能够把某一点周围的像素色值按高斯曲线统计起来，采用数学上加权平均的计算方法得到这条曲线的色值，最后能够留下人物的轮廓，即曲线．是指当   将加权平均应用于像素时生成的钟形曲线。在中间，你应该知道所有的颜色不过都是数字，各种模糊不过都是算法。把要模糊的像素色值统计，用数学上加权平均的计算方法高斯函数得到色值，对范围、半径等进行模糊，大致就是高斯模糊。
原理
周边像素的平均值
所谓模糊，可以理解成每一个像素都取周边像素的平均值。


上图中，是中间点，周边点都是。中间点取周围点的平均值，就会变成。在数值上，这是一种平滑化。在图形上，就相当于产生模糊效果，中间点失去细节。显然，计算平均值时，取值范围越大，模糊效果越强烈。
下图分别是原图、模糊半径像素、模糊半径像素的效果。模糊半径越大，图像就越模糊。从数值角度看，就是数值越平滑。

接下来的问题就是，既然每个点都要取周边像素的平均值，那么应该如何分配权重呢？如果使用简单平均，显然不是很合理，因为图像都是连续的，越靠近的点关系越密切，越远离的点关系越疏远。因此，加权平均更合理，距离越近的点权重越大，距离越远的点权重越小。
正态分布的权重

正态分布显然是一种可取的权重分配模式。在图形上，正态分布是一种钟形曲线，越接近中心，取值越大，越远离中心，取值越小。计算平均值的时候，我们只需要将中心点作为原点，其他点按照其在正态曲线上的位置，分配权重，就可以得到一个加权平均值。
高斯函数
上面的正态分布是一维的，图像都是二维的，所以我们需要二维的正态分布。

正态分布的密度函数叫做高斯函数 。它的一维形式是：

其中，μ是的均值，σ是的方差。因为计算平均值的时候，中心点就是原点，所以μ等于。据一维高斯函数，可以推导得到二维形式


有了这个函数 ，就可以计算每个点的权重了
权重矩阵
假定中心点的坐标是，那么距离它最近的个点的坐标如下：



更远的点以此类推。
为了计算权重矩阵，需要设定σ的值。假定σ=，则模糊半径为的权重矩阵如下：这个点的权重总和等于，如果只计算这个点的加权平均，还必须让它们的权重之和等于，因此上面个值还要分别除以，得到最终的权重矩阵。
计算高斯模糊
有了权重矩阵，就可以计算高斯模糊的值了。假设现有个像素点，灰度值如下：



每个点乘以自己的权重值：得到将这个值加起来，就是中心点的高斯模糊的值。对所有点重复这个过程，就得到了高斯模糊后的图像。如果原图是彩色图片，可以对三个通道分别做高斯模糊。
高斯模糊矩阵示例表
这是一个计算 σ =  的高斯分布生成的示例矩阵。注意中心元素  处有最大值，随着距离中心越远数值对称地减小。

注意中心处的  比 σ 外的  大  倍。
源码实现
 

 
 
 
 

 

　简单高斯模糊算法

　　
　　　参数说明

　　　返回类型说明
　　　违例类型　违例说明
　　类、类方法、类成员

   {
           {
          =   将这个图片拷贝到你项目根目录下
        
          = 
          = 
          =  
          =  
           =     
               =      {
                   
                 
                  
            }
           
    }

               {
          =   
          =   
          = 
           =       
               =        {
                  = 
                    {
                     = 

                }    =  {
                     = 
                }
                  = 
                    {
                     = 
                }    =  {
                     = 
                }
                 =  

            }
    }

           {
          = 
           =      {
              = 
               =      {
                 = 
            }
        }
    }

         {
          = 
          = 
          = 
           =      {
              = 
               =      {
                  ==  {
                    
                }
                  =  
                 = 
                 = 
                 = 
            }
        }
                  

    }
}
运行结果
原图片

高斯模糊化后的图片

附：程序源码下载“凡人皆有一死。”当你进入权力的游戏，成不了赢家，就只有死路一条，马丁大神不会给你任何回旋的余地。
最近，权游剧迷 用机器学习算法量化并预测出了《权力的游戏》剧中每一位角色的命运，结果显示，就连三龙在手、一向顺风顺水的龙之母——丹妮莉丝·塔格利安女王也要步入死生之地了。
并且，龙妈之死的确信度还蛮高的。

 是中欧大学网络科学中心的计算机科学家。基于他从《权力的游戏》字幕中所提取的数据，建立了一个“权力的游戏的社交网络”，其中主要是该剧近个场景中的角色互动频率，这些数据被算法提取成了下图中的社交图谱：

这张图谱的量化数据能够清楚地说明：谁有最强的社会背景，谁的“人脉最广”，谁与其他角色有最强的关系——相互欺骗或缔结盟约……在这利益纷争犬牙交错的冰火乱局中，毫无悬念，狼家和狮子家的主要人物牢牢占据着社交图谱的中心位置。
通过社交关系计算出每个角色的重要程度后，将角色在剧中的生死同他们在社交网络中的位置关联起来：

在他研究的个角色中，有人已经死亡。角色互动数据所给出的特征集，很好地描绘了死亡角色在剧情中重要程度及其社会地位，据此，可以大致推测剧中角色的命运，正如他在论文中所描述的：

基于这里的数据，我们可以学到某种有根据的推测，并判断出哪个角色更有可能在今后上映的剧集中领便当。推测的逻辑是，仍然活着的这些人物中，有哪人的特征跟已经领便当的最为相似。

当机器学习算法学过这里的各种数据后，所研究的个角色，有四分之三的人的命运都被该模型准确预测到了。相比剧评师们种种不靠谱的猜测，机器算法的表现可谓是可圈可点。

不过，在预测错误的角色中，有人早已被丧心病狂的编剧杀死，但该模型仍旧预测他们还活着。比如大名鼎鼎的“小玫瑰”——玛格丽·提利尔，她在剧中死于圣贝勒大教堂的野火爆炸，该幕剧情一同死掉的还有在场“百花骑士”、“大麻雀”等数百人。
对此，表示，加入更多的信息可以提高模型预测的准确性，如角色性别、家族人数等等。关于他的研究详情，可以参考这里：




看看前几季纷纷领便当的角色，剧中剩下的人物，极有可能死掉的都有谁呢？
在的模型所预测出来的结果中，最能惊掉你下巴的就是龙之母了：在接下来的剧情中，丹妮莉丝·坦格利安有的死亡几率，该预测的错误率仅为。
，你确定你这算法没有在逗我们所有剧迷们？
我们知道，丹妮女王登陆龙石岛后，她的三条龙、万多斯拉克骑兵、无垢者死士已经是整个维斯特洛大陆最强大的势力。铁王座果真就那么难坐吗？
女王命运扑朔迷离，就连女王座下的无垢者指挥官也要搭进去：灰虫子接下来的死亡几率为，错误率同样，排名第三。

可意外的是，女王铁卫乔拉·莫尔蒙的死亡概率只有％，根据剧情，大熊的灰鳞病已经病入膏肓，被关在学城的地下室就剩下等死了。
不过，根据今天最新的剧情，大熊的病的确已被“异鬼杀手”山姆治好了。山姆到学城原本是寻找消灭异鬼的办法，他是在一本老书里发现了治愈灰鳞病的方子，然后冒死从大熊身上剥离出感染他的爬行动物与皮肤脓疱的鳞屑。

另一个意外是，本应遭报应的狼家养子席恩·葛雷乔伊，却跟大熊一样，是死亡几率最低的一个角色。这个背叛狼家、被小剥皮折磨成臭佬、被叔叔“鸦眼”追杀至天涯海角的小海怪，在上一集遭遇“鸦眼”伏击时，眼睁睁看着姐姐被俘、“大沙蛇”被杀而逃命，求生的本能果然又让他在最新的剧情中幸存了下来。

然而，被“鸦眼”俘虏到君临城的“小沙蛇”特蕾妮·沙德就没有那么幸运了，为女报仇心切的瑟熙·兰尼斯特女王可不会让她好受。作为“红毒蛇”的私生女，在上一季谋杀瑟熙的独生女后，“小沙蛇”的死亡几率早已高居机器预测的榜首，达到，预测出错率则低至。

至于她在最新剧情中的命运，这里就不再具体展开。

下表中每个人物所对应的概率，则是的机器学习模型所预测的最终结果：

参考链接：

文章来源：科技大本营周小军，腾讯高级运维工程师，目前就职于腾讯社交网络事业部，负责社交产品分布式存储的运维及团队管理工作。对互联网网站架构、数据中心、云计算及自动化运维等领域有深入研究和理解。

一、活动背景

运维有三座大山：大活动、大变更、大故障。这几个运维场景是最消耗运维人力的。特别是大活动，非常考验弹性能力，对运维自动化挑战很大。
我今天所分享的主题就是深入百亿次红包大活动的背后，解析腾讯运维的方法体系，了解织云平台如何帮助运维实现大活动高效运维，如何减少运维人海战术。
过年大家都刷过微信红包和  红包， 红包的业务主要有几种产品形态：刷一刷红包、拼手气红包、红包和空间红包等。年跨年除夕这天有亿的在线用户刷了亿次的红包。这么大的体量给整个架构体系带来的冲击是非常大的。
今天将从”刷一刷红包”的业务架构、活动背景、计划扩容、压测和演习、运维策略及活动现场这几个方面来分享我们的活动型背后的运维支撑工作，希望给大家在产品大活动时提供参考和帮助。
挑战

大活动前的二个月，产品会给研发和运维提供详细的产品运营指标，今年春节前”刷一刷”红包所规划的产品指标预估为峰值每秒万，同时活动及节假日也带来相关消息量和空间说说量倍的上涨。
根据运营指标，运维按历史性能数据、容量模型和业务架构，评估出春节活动需要万台虚拟机和千台数据库服务器扩容支撑。
节前恰好遇到厂商内存供货问题，服务器供应非常紧张，采购比原计划延期了一个多月。甚至有个别型号的服务器到春节封网前一天才到货。紧张的设备供给运维增加了扩容压力。
二、活动计划
 日历表

运维有个月时间来准备和实施红包活动，上图是活动日程表。在确定产品策略和活动方案后，月进入资源采购流程，元旦前后进入扩容部署。
业务扩容有两周时间，到月的中旬，也就是离春节还有周的时间开始进行业务和模块压测，以及活动演习及预案，大年三十我们开始进入活动现场。
在活动现场，产品、开发和运维全部在第一线保障红包，一直坚守到大年初一的凌晨一两点钟。
活动梳理

由于活动涉及业务多，模块核心链条关系错踪复杂，运维在前期的活动梳理中，要做好基础能力、外部服务压力和支撑等复杂的评估准备工作。
支撑工作梳理包括内网专线穿越流量梳理，因为业务均为多地部署深圳、天津和上海，同城也有几个大的核心，业务不仅有同城跨 部署，也有跨城异地部署，评估同城、跨城的专线容量是容量评估重点之一，如果超出阈值有什么应急方案，跨城调度与容灾怎么做，柔性与过载保护策略等，这些都是运维要考虑的核心保障工作。
三、扩容
 刷一刷红包架构
在分享扩容之前，我先从刷一刷红包的系统架构开始，先让大家对业务进一步的了解。

业务架构由抽奖系统、消息系统和支付系统三个核心架构组成。

接入层统一接入：手自身系统与客户端唯一连接。

抽奖主逻辑：含抽奖相关逻辑、数据上报等、排行榜、订单管理等。路由采用自研内部路由系统简称的一致性功能，保证同一个用户的不同请求会落到同一台机器。

存储：中奖记录和奖品等信息统一存储。统一使用公共组件自研分布式存储系统进行存储。

礼包发货：现金外的其他奖品发货，包括公司内外业务的礼券。

公众号消息：负责用户中奖以及发货通知。

支付系统：现金和奖品发货，还包括后端的银行接口等。

 资源：用于奖品图片信息等资源下载。 


根据这三个层，架构分成无状态层和有状态层，无状态层为接入层和逻辑层；有状态层即数据存储层，数据持久化存储。
扩容包括无状态层和有状态层的设备扩容。

上图是系统的架构图
 无状态服务自动扩容
 传统扩容流程
下面讲一下怎么做无状态的扩容，这是传统的扩容流程，传统运维的扩容流程一般是通过脚本来部署。我们把流程拆解下，可以看到它主要由以下核心步骤组成，包括部署操作系统、服务部署、配置下发、业务模块关联、业务代码包发布、业务权限管理、启动服务、模块测试、服务上线和加入监控告警。
蓝色圆圈是流程执行的时间消耗，这里一台设备约消耗半小时。如果扩容一千台机器需要两个人月。如果用脚本或开源运维工具批量的扩容，一个模块按一人一天，这样的工作量还是非常繁琐的，非常依赖人海。
 全自动扩容

在我们强大的织云自动化运维平台支撑下，我们的业务模块都是一键式扩容模式，也称一键上云。一个模块下的上百台设备，整个扩容流程跑完只消耗分钟时间。
我们来看一下我们这边是怎么做的，这是我们基于的全自动扩容， 是我们非常核心的扩容系统，包括资产、模块、业务对象、软件包、配置等等的数据信息都在这里面。
新部署服务器从  获取属性以后，会进入到服务包的部署，之后到告警屏蔽，下面有发布自检，会检测装的包是否正常的。然后到业务测试，灰度上线，体检报告。整个流程效率比较高，一般来讲部署一台设备或一个模块也就分钟，因为它是并发来做扩容的。织云已经把运维操作抽象成几百个流程。
整个春节期间走了多次扩容流程，每天都有上百个业务模块并行，春节我们扩容了多个模块，平均一个模块是多台设备。

上图是织云的一键上云页面，左边是管理列表，右边是服务器属性。包括它属于哪个模块，是多少，什么机型，运营状态，操作系统，监控等等。
当我们点击”新增设备”按纽，下面就是扩容流程，就会弹出一个界面，会显示出要扩什么样的机型，系统支持、虚拟机等等五种类型。下面就是设备责任人，等等。点击发布完，就会根据参考自动化把扩容批量走完整个流程。

刚刚说到我们扩容的最后流程是变更体检报告，变更体检报告是变更系统和监控系统的融合，依赖于变更系统的变更日志和监控系统的监控数据和监控告警。变更系统需要把每次现网变更记录下来，变更体检报告根据这个记录，取得变更设备和变更对象列表，然后分析这些变更对象的监控数据，得出最终结果。
体检报告的检测结果为正常，需关注，异常。正常表示本次变更正常；需关注表示此次变更中有一些监控指标波动比较大，需要相关人员关注下，对业务本身没有造成重要影响；异常表示本次变更造成了现网故障，需要立即回滚。正常的体检报告不发送任何通知，需关注的体检报告发送邮件通知，异常的体检报告既发送邮件也发送短信通知。
检查项大体可分为两类：基础特性检查项，业务检查项。

基础特性检查项是指与机器相关的监控项，如，流量，包量等。

业务检查项则是与业务相关的服务间调用简称模调，自动化测试等。


体检周期为、、、分钟。
个检查特性包括、网外卡流量、内外网卡包量、超过的设备数、自动化测试告警、模调告警等，并分别进行评分。评分为则正常，小于一定值则需要关注，总分大于一定值为异常。
上图里面，变更分钟，告警数，容量告警、 告警都是零，第分钟也是这个告警，到了第分钟出现四条模调告警，就触发一条告警信息给运维，运维通过邮件把这个发给业务负责人。保证这个变更是闭环，从设备的申请到发布自检到报告都是一个闭环的流程，这个运维是非常高效的。

刚才说过的传统的扩容跟织云扩容的对比，传统扩容基于用  或  来管理业务信息和资源信息，稍进步一点的用数据库来管理。运维要登录跳板机或总控台，在总控台用命令行或页面跑各种安装脚本，脚本之间需要人工确认。
比如说装一个 ，安装完成以后要手工把、端口等信息粘贴到下一个脚本或流程来由运维继续执行，脚本间没有全流程概念，需要人工去更新信息。一个业务工程师同时只能做一个模块的变更或扩容，如果并发同时做多个变更，极易出错出现故障。
织云高效的实践是，它是以运维标准化为基石，以  为核心的自动化运维平台。通过  界面的一键式上云，基于业务原子任务和流程引擎，形成一个完整的运维流程，最后并行执行。一个模块一个人到分钟就可以做完所有操作。
高效扩容的背后是基于一套标准化的理念。包括分层标准化、可运维规范、软件标准化，并且标准化以  落地。
我们以  为核心，把资产配置、硬件配置、软件配置、运营配置，比如说这个是在哪个地方部署的，因为我们有容灾，还有权限的管理，我们模组之间有管理，把这些配置都打包到  里面，通过引擎实现自动化发布机制。到线上服务以后，后面还会有监控告警、一致性、变更体检等等闭环的服务。从  到线上服务，整个流程都是闭环的。

这是运维标准化的实践。把架构、配置、监控、软件包、工具等等先实现标准化，然后落实到  配置中心，通过工具或流程快速交付。标准化是要落地，如果没有这些跟  的实践，标准化就是一个纸面的东西，是没有办法实现的，这四步缺一不可。
 有状态层的自动扩容

刚才讲到无状态的扩容，现在是讲有状态的数据层扩容。通常来讲，数据层扩容是  工作中工作量最大、最易出故障的变更。但在我们这边，数据层扩容已经实现了与无状态层一样的灵活性。
我们的数据层分两层架构，上层是无状态接入机，负责数据路由配置，下层是存储机，负责数据存储。
接入机扩容跟无状态层的扩容方法类似。
存储层通过数据搬迁，同时并行修改接入机路由表来实现扩容。

存储层扩容的原理是，我们首先把记录   万到桶，桶再分配到存储机的存储单元，通常是  一个内存存储单元，一台  内存的存储机有个存储单元。
桶是搬迁最小单元，通过桶搬迁方式来实现记录的扩缩容，整个桶搬迁是全自动化，运维只要指定一台或一批目标存储机，桶和记录就会自动搬迁分布到目标存储机之上，搬迁过程中代理机的路由表是实时更新的，因此搬迁过程中业务的访问不受任何影响，只是搬迁过程中的不能删除，但这个过程只有数秒时间，业务基本无感知。

上图是数据层的架构，存储层分内存存储和固态盘存储二级，数据可以自动根据冷热规则在内存和存储之间分布，以节省内存成本。目前我们共有万多台 ，人均管理两千多台 ，存储机扩容的效率很高，但由于数据搬迁速度较慢，通常是一台  内存的内存存储机在生产环境下需要小时完成搬迁，因此千台  花了两三周时间来完成扩容。
四、压测和演习
运维摆脱了设备扩容的人海战术后，就像特种部队一样，把精力聚焦到有价值的工作中，譬如业务架构评审、资源评估和规划，压测及演习、应急预案、监控等等和业务相关的事情这是业务运维应该更关注的地方。

 红包容量评估
如何评估活动容量？我们会根据四个维度来评估容量。首先是 的容量，像电力、机柜、专线的容量等等。以服务器为维度，会关注四个核心指标，、网络的磁盘、网卡流量、网卡包量，判断这个设备的整体容量水平。这是基础的维度。

业务这边，我们会有业务维度的评估，譬如红包业务的每秒红包容量。根据设备的能力来推导出业务容量的水平，譬如模块单机能抗千个 ，假设模块下有一百台设备，那么该模块的  就能支撑万 ，并且这个容量负载必须是线性的增长。
 红包压测
容量完成扩容前后，我们会多次对模块和业务进行压测，来评估容量基准值，扩容之后的水位能否支持到业务高峰。
我们通过演习的方式来模拟实际的用户请求。
我们的业务是多地部署的，譬如  是分布到深圳、上海和天津三地。那么，我们把全国流量调度到其中一地，譬如深圳，观察容量、延迟等指标，因为我们业务关键链路会有几十个模块，在这个过程中，有些模块如果有问题会出现异常或告警，比如说有些模块  会过热，会上到  的高水位，或者失败率开始增加。业务会根据这些模块的容量，根据高负荷的模块做一些性能的优化或扩容。保证这些模块负载都是合理范围。

第二部分是线上灰度，我们会逐渐放开抢红包的活动，譬如对华南区域的用户放开”刷一刷红包”的入口，用户有提示先去刷，刷的时候发现这个产品的测试是否符合预期，关键模块的容量是不是达到我们的标准。我们会有灰度逐步放量，最后全部放量。还有一个小年夜的多时段，比如说在晚上定点来分别放开”刷一刷”这个活动的流量。
这是有一个压测出问题的例子，我们在压测的时候发现有一些存储机的网卡流量被压爆了，这是一台网卡流量的巅峰，平时是  的水平，到了压测的时候压满  的带宽。我们分析发现，这个是存储器上有热 ，然后我们根据压测出的情况继续推动各种优化。
 红包演习

上图是红包演习的范例，我们把手的深圳   万用户调到天津去，以模拟深圳的挂后天津的压力。运维日常以及节假日前会通过各种调度来做各种演习。
五、运维策略
 业务错峰部署
业务策略多变，之前评估供给的设备不一定能满足实际产品指标，因此我们还做了业务错峰部署，在一批服务器上同时部署了红包和空间的服务，一台机器会部署两套服务。在红包活动时这些设备用于红包活动，红包活动结束后，通过调度快速把机器调度到空间服务进程上，这样错峰来重用服务器计算资源。

大家可能会觉得这种切换风险比较高，后来经过我们的验证，我们的调度能力还是确保这些多设备的复用达到我们的预期。我们通过技术的方式来做，即可以做到业务错峰，也可以进行扩容。
 柔性保护
在活动过程中还有很多服务故障，我们还需要对服务的柔性做一些测验。我把我们”刷一刷红包”分层，针对每个层出现的问题做一切特殊的过载保护。比如说用户，如果点准点开放给用户，同时会有亿的用户涌入这个架构，系统的峰值会非常高。

在用户层我们做了错峰的开放，譬如在：到分把用户随机放进来，把请求随机分布在秒区间。
如果接入层这边出现容量和负载过高，我们会在这里随机丢弃一些请求，根据用户的进行随机丢包。
如果是银行这边的接口出现瓶颈，我们会降低现金的的派发速度等等。消息系统出现瓶颈，我们会设置一定比例的用户不发送消息。每一个层都会跟研发一起考虑这个容量出现问题的时候怎么做柔性保护

这是我们运维这边一键下发属性的界面见，我们可以选择不同的模块，然后选择柔性的配置表，通过一键下发的方式将柔性策略实时下发，并实时生效。
六、活动现场
 看监控

前面的扩容、压测和应急预案等已经做完了，到了春节活动现场，运维主要有三类工作，一是看现场视图，二是扩容过热模块，三是处理热。
有些业务模块，通过压测手段是没有办法模拟现网的，在现网情况下会出现容量超过阈值的情况。运维会通过视图或告警快速发现，经过简单评估后从备用资源池中紧急提取设备，对模块进行扩容，把容量负载降到正常水位。
这是大年运维部门的现场见，大家都在看视图和快速扩容模块，这是我们运维主要做的事情。

上力量是织云的运维核心视图见，可以看到集成了各业务核心视图，包括红包大盘、红包相关模块告警， 核心模块容量，红包视图等等，运维主要是看这些视图，看告警来保证活动是正常的。
 现场挑战热

数据存储在活动高峰面临的挑战之一是热 。即某一些热点记录的访问量过大，高峰期甚至上涨百倍。
我们有几种常用方法来处理热。首先是拆记录，比如说这个记录的访问量非常大，每秒有十几万，我们会把  的  分拆成多份，分布到不同的表实例。
其二是限制记录的长度，有些  的  很长，在热点访问时会给存储机内存拷贝、网卡造成压力。我们会查找出过长的 ，让业务通过字段压缩、删除冗余字段等方式来减少记录长度。
第三是把千兆的存储机换成万兆的存储机，让网卡流量突破限制，在现网万兆存储机能跑到  的水平。
第四是记录打散，快速通过搬迁方式，把集中的热点  分布到十几台存储机来支撑。
最后，业务在前端可能会有几十台逻辑设备，业务可在逻辑设备上用内存做前端缓存，减少对后端存储机的访问。
七、回顾


回顾整个红包的活动策略，万台级设备扩容仅用了天时间，极大解救了运维。运维从扩缩容的工作量中解脱出来后，可以把更多的时间和精力更深入理解业务，为业务在质量、成本和速度几个方面给用户提供更多的价值，为业务保驾护航。
相关推荐
 解决方案 自动化运维程序员转型、机器学习需要学多久？年？年？这是绝大多数考虑转型的人，从一开始就要认真思考的问题。
光说不练在这里没用，咱们还是要看真实的故事，来看看黑人小哥 的转型之路。他是多伦多的一位软件工程师，在月份打算转型机器学习，并公布了一项为期个月的学习计划。
如今计划期满，他完成得怎么样呢？转型之路有何心得？我们先听听这位小哥自己的说法。

作者 |  翻译 | 科技大本营参与 | _，波波
这其实就是线性代数，不是什么高深的学问。
我做了什么？怎么做到的？
这里，我就不再介绍原先的学习计划以及随后在上的跟进讨论了。如果你不怕冗繁的细节，可以重新去看原文：

学习计划：跟进讨论：

长话短说：我学完了，现在退出，开始找工作。
想马上知道接下来的事情吗？且听我说。我并没有完全照着一开始的计划，按部就班地学习，而更像是一段长达个月的、挤满额外内容的学习经历。现在，我马上就要完成这段职业生涯的转型经历了，所以想和你们分享一下我的体会。
先分享一下我最终版的学习日程，然后再跟您们讨论这中间的变动以及我这样做的原因，最后是给初学者的一些建议。
顺便说一句，文章开篇这句“这其实就是线性代数，不是什么高深学问”，意味的是机器学习或深度学习并不简单。
我的学习日程
这段时间，我一直全身心的投入在学习上，每天学习小时。我每天都努力完成时间安排，并且没有放下健身房和午餐的休息时间。大部分时候都可以正常完成，有时候也会熬到凌晨点或点再睡觉，但也有几天什么事情也没完成。有时候是因为我的懒惰夏天实在容易变懒，其他时候是因为太累了。
这里还要提一下我学这些的背景—教育基础，我有一个软件工程学位和优达学城纳米级数据分析师的认证。除了工作经验，还是一名开发者和分析师。
第个月
深度学习  第部分开始 尝试竞赛  分享经验：中级参加本地研讨会一般讨论
第个月
深度学习  第部分完成 从头开始构建深度学习框架 对抗挑战使用面试项目进行实践 数据科学家与，职业培训营：开始分享经验：中级参加本地研讨会讲座和小组讨论
第个月
深度学习  第部分开始暂停数据科学家与，职业培训营：完成 吴恩达的机器学习：已完成分享经验：中级更多本地研讨会：和 
第个月
深度学习，第部分开始：构建和部署端到端深度学习产品开始分享经验：中级
杂项
就像一个笔记，每个课程或程序都有很多阅读材料——博客文章，斯坦福大学在线课程，学术论文等——和往常一样，终究要花功夫学习额外的知识。我虽然做了大量的“额外”阅读，但肯定有一些地方跳了过去或者没有兴趣继续了解下去。我目前已经学习到第四个月到月中旬实际上是个月，我提前了，但是打算不久之后就开始找工作，不会一整个月都拿来学习。
细节
我对原来的时间表做了个比较大的改动：

数据科学家与 
吴恩达的机器学习 
项目端到端深入学习项目

在开始深度学习的第部分之后，我决定参加举办的数据科学家与培训营。要多从实践的角度思考所学的内容，因为我目前的角色并不能简单的划分成单纯的深度学习或单纯的经典机器学习。所以尽管动手实践深度学习的经历很棒，但如果在接受采访时，我不了解和算法之间的区别，仍将会十分尴尬。
另外，尽管提供了快速程序，但它并不教授，而的职业生涯训练营则有许多在数据挖掘和操作方面的课程。
由于我之前已经完成了优达学城的数据分析课程， 所以的项目对我来说，更多的像是复习当然也有一些新的提示和技巧，但这正是我需要的。
总结起来就是：

项目适合进行深入的学习，且涵盖范围广泛。它这种让你一行一行实践代码的方式非常棒！
优达学城的项目为每个机器学习算法提供了非常多的细节，方便你了解如何使用它们并构建优秀的大型项目。

斯坦福大学机器学习课程，由吴恩达在上教授的可能是互联网上最著名的机器学习课程。这差不多是我想学它的主要原因。另外，我也从朋友那里听说这是一个很棒的课程。
我学这门课的目标是为了强化自己的知识基础。虽然在之前我已经学习过优达学城和的课程，这两个课程都涉及机器学习  从不同的角度讲述，但我认为再多学习一门这个领域中最好的课程绝对有利无害。
这门课非常有意思，有趣且具有挑战性。像其他一切一样，有一些我完全理解的部分，也有一些我还没有完全搞清楚的部分。
我不认为会在任何新项目里帮到我，但对于完成几次作业来说，这个软件并不难上手。虽然这门课是一个很棒的经历，但我仍然相信的数据分析师纳米学位有更实际的用处。
最后一件帮助我完成学习目标的事，是的端到端深度学习项目。数据科学或机器深度学习不仅仅是关于理论，算法，研究和出版论文！对于我来说，我一直想要构建产品，做一个实践者，做一些事情。
在我的项目中，我将定义一个问题、潜在的解决方案、源数据、构建和测试模型、生成模型、实现、前端并部署到“生产”上。本质上，我将要建立一个端到端的深入学习管道，从而打造一个直播产品。
或者至少，这是一个计划。
我对初学者的建议
开始学习。你没有什么好的借口可以不去学习，哪怕是换了职业。
学几门数学课程，但几门也就够了。

边注：据我所知，实际的机器和深度学习不涉及计算编码、求导、反向传播、等的亲自实现，甚至中都没有函数库  尽管我相信一些面试官不这样认为也就是不使用函数而分割这个字符串，因为在生产中我们不使用库，这让你明白我们一般如何处理这种商业案例。

但我还是要偏一句题，这不是说你不需要数学，而是说你只需要了解术语代表什么意思，如何解释它们，以及如何根据他们的信息来修正模型或参数即可。但在实际实施机器学习和深度学习的世界中，并不需要博士学位：
这其实就是线性代数，不是什么高深学问。
但是，现在并不建议你开始着手一个大的项目，因为它将占满你的学习时间。尝试做一些实际动手的工作，使用真实的数据进行练习，你需要它们来增长经验和参加面试，而不是马上就开始处理你开始新的职业生涯之后才会遇到的，更重要的现实世界的问题。
我觉得我的脑子里已经充满了机器学习和深度学习的“东西”，总是有一篇要去读的新论文或发表的文章。但还是得慢慢来，我很确定我还没有达到我想要的程度。
综上所述，我建议你学习的课程包括：

数据科学家与
数据分析师纳米学位
 的机器学习
深度学习快速
进行个人项目或参加竞赛进行练习在进行步骤的时候

另附：这里还有我正在更新的一些“阅读清单”，以记录我在学习过程中做的更重要的事情。你可以在我的博客上找到它们：
课程

                   
      
      

视频

  
    

书、论文、文章及博客

  
       
       
  
   
   _
   _
  _
      
  
    
            
     
       
       
     
  _

我接下来的计划
找工作。我的最后一件事当然是恢复工作。我会尝试尽可能有选择地去找工作，不是说我以前没有这样做，而是我认为这是一个职业变化，认真审视这个过程的每一方面都是很好的。
到目前为止，我一直在被动地审查公司，调查他们在机器学习和深度学习领域中究竟做了什么。所谓的“机器学习工程师”在深度学习方面做的很少，而其他“数据工程师”则需要很多或的知识以及和 等的技术。
到目前为止，我学到的两件事或者说还没学到？

没有真正的“深度学习工程师”角色，它只是被附加到了的描述中，所以得记得仔细阅读工作责任部分。

数据科学家，数据工程师甚至数据分析师的角色可能因公司和工作职责而异。这个可以细分成企业需求和创业公司的需求。


对于我个人来说，根据我的兴趣，我将寻找一个职位，让我能够扩展我在深度学习中的专长它本身就是一个大领域，同时还能使用一些“经典”的机器学习技术。如果他们能丢给我一些开发工作，甚至会更好
那么，了解完我的这段经历，你认为，任何人都有机会能成为全栈机器学习工程师吗？
原文地址：

文章来源：科技大本营容量管理从本质来讲，主要需要解决的问题是系统“亚健康有病，但还不影响生活和工作”的情况下，我们能够及时知道，并做出对应策略，确保系统恢复到正常顺畅；本方案主要是讲的第一部分，“我们如何及时知道、并告警预警”，不涉及到“容量处理策略”。
一主要问题场景：
实时系统：
能提供服务，但是速度较慢；
随着业务的逐渐发展，一路上升都提供良好，但是离悬崖慢慢靠近用一个举重运动员的话说，在压一块金牌在杠铃上，就倒了；
 业务突发增长，导致短时间内，系统资源耗尽，服务质量严重下降；
离线系统：
 随着业务的发展，在约定时间内逐渐无法完成任务例如：个小时跑一次的数据统计，随着业务增长，无法在个小时内完成；
依据以上问题场景，数据容量系统定义以下目标，并以此目标为验收标准；
二数据容量系统的目标：
核心目标：
 容量实时监控；
 容量按天日报，了解到目前系统在资源和业务方面的容量百分比，处理取于高负载的设备或者是模块；
附加目标：
成本控制，通过对低负载模块的展现，整合机器利用率，有效控制成本；
三容量管理方案
针对实时系统，主要采用一下三种方式来达到要求：
自动化测试监控添加测速和时耗告警；满足场景一、告警时间分钟
针对外网服务，自动化测试监控平台提供模拟用户角度从外网访问网页目前主要是针对、积分、、四个外部网站，并且对时耗做了收集和告警；
针对后台服务，自动化测试监控平台提供模拟客户端从内网访问服务端，针对所有实时系统都添加了核心功能的自动化测试，并且对时耗也做了收集和告警；
针对基础资源的实时告警满足场景三、告警时间分钟
针对基础资源的实时监控，主要有以下几种：

部门默认在平台上统一配置的告警策略：
单机使用率：使用率大于等于，连续分钟，短信告警；单机负载： 负载大于等于，连续分钟，短信告警；单机应用内存使用率：使用率连续分钟，短信告警；
单机外网流量告警： 当前流量=上周同天同点，连续出现分钟，则短信告警 当前流量上周同天同点连续出现分钟，则短信告警
单机硬盘使用率： 使用率，直接上报 使用率 预警发短信

针对层面，自行脚本资源配置
使用量：单个进程，超过 最大限定值的，则短信邮件告警机器负责人； 
内存使用量：单个进程，物理内存使用量超过  |   |  { } 的，则短信邮件告警机器负责人；
使用量：一台设备，若使用率超过则短信邮件告警机器负责人；
共享内存使用量：一台设备，若共享内存个数使用超过    |    最大限定的，则短信邮件告警机器负责人；
信号量使用量：一台设备，若信号量使用超过    |    最大限定的，则短信邮件告警机器负责人；
消息队列使用量：一台设备，若消息队列使用超过    |    最大限定的，则短信邮件告警机器负责人；
消息队列未处理量：一个消息队列，若未处理消息数个，则短信邮件告警机器负责人；
连接数数_状态一台机器连接数_状态数量超过 的最大限定值的，则短信邮件告警机器负责人；


采集容量数据，按天计算容量百分比，并预警已经取于高负载的模块和设备满足场景二，预警时间天

容量采集数据以及方式：
硬件相关的基础资源：均可通过网管后台获取采样值。关键指标：使用率、负载、外网入流量，外网出流量、应用内存使用率、磁盘利用率
相关的基础资源设备从本机作为特性上报到公司网管，容量从网管后台取得采样值；关键指标：、连接数、连接数
业务特性：设备从本机作为特性上报到公司网管，容量从网管后台取得采样值；关键指标：请求量数、平均时耗、占用计算资源、失败率

计算每日负载值：

输出物：设备负载日报高负载管理、低负载管理业务模块负载日报


针对离线系统，主要采用以下方式要求：
 离线任务执行时耗超过最大值，直接告警满足场景五、告警时间分钟；预警时间天；
采用收集离线任务开始时间、结束时间、执行时间标准；
采用公共工具部署在每台服务器上，各自任务自行上报开始时间点，结束时间点。
四结束语
本方案仅仅涉及到“容量问题告警、预警”的内容，部门在这一块才刚刚起步，特别是问题出现之后的定位、处理还没有定论和统一解决方案，另外，容量管理系统的端非常多，如何简单有效的管理这些端也是个挑战。还希望大家能够有好的想法、建议，可以和这边交流，让容量管理在“减少故障发生、降低故障影响”等方面发挥大作用。

相关推荐精细化容量管理的设备成本优化之路如何依托腾讯云完成海量数据的存储和备份 是面向对象与函数编程语言，最终编译成  字节码，运行在  上。如果要比较，最多的是和  对比， 相对而言补全了  的许多弱点。例如： 里接口与继承，在  里的是特质，弥补  中接口的尴尬之处，特质里的方法可实现也可不实现。
在数据集操作方面，感觉和其他所有语言相比具有压倒性的优势个人观点，悄悄的毫无征兆的实现了很多方法。例如： 实现的隐式转换，替换原有函数功能，如等操作符，等操作符在  都是函数，当然自己就可以改变这些函数并运用下去。
同时还有在并发编程方面也有不错的竞争手段， 将并发结果变得更加可控，同时模式匹配、提取器这些数据集操作都给操作带来了很大的方便，笔者是  新手，这只是一些粗糙的理解如发现错误欢迎留言，会立马更正，因为技术所以不能马虎。
本文使用了  、、数据集、、 的一些相关操作，从而特意选做了一个功能主题：提取淘宝目录分类名，流程为：获取  目录 取得  下所有的子分类写入数据库。不多 ，看代码：
=========================================================================================================
 
 
 { }
 
 
 { }
 
 
 
 
 _
 _
 
 
 { }
   = {
      =    用来存目录名称与目录 
      {
        =    模式匹配失败
        
        =  模式匹配成功
         = 
    }
      设置并发线程数
      =  
        {
        所有的并发对象存入 
    }
      = 
      =   阻塞主线程等待所有  完成， 将是每个  返回 的列表
        {
         = 
        = 
          {
          =  获取 ，也就是最后一级目录
         {
             = {
              =     
              =     
            {}  {} {} {}
              =    {}{}{}{}
            
            
          }
        }
      }
    }
  }
    提取 只需几行代码
        = {
      = 
   =\\ = {  =  =   }
     返回
  }

=======================================================================================================
 { }
 
  {
     = = 淘宝接口
            =   = {
              =   声明 ，使  操作更强更敏捷
              =   
            
            
        }
        隐式转换如：， 被隐式转成  了
            = 
        隐式转换如：
            =    
            = 
            隐式转换如：
            = 
}
贴上接口数据图片， 为最后一级目录名
贴上  内容
 =     

 =     

 =     

 =   _  

 =     最近一段时间使用做媒资数据的接入，简单介绍一下的特性和语法。
、特点
是一个基于分布式文件存储的数据库。由  语言编写。是非关系数据库当中功能最丰富，最像关系数据库的。它将数据存储为一个文档，数据结构由键值=对组成。 文档类似于  对象。字段值可以包含其他文档，数组及文档数组。
具有自动分片、支持完全索引、支持复制、自动故障处理、高效存储二进制大对象 比如照片和视频的特点。查询方式更多样，可以查询文档中内嵌的对象及数组。支持，但必须使用语法，从而导致一个实例只能运行一个线程。支持多种语言。
、缺点
不支持事务。
不支持，如果有的需求，请重新设计你的或者采用。
、语法
连接：默认没有密码。
创建数据库： __，如果不存在这个数据库则创建，存在则切换到这个数据库
查看所有数据库： 
删除数据库：
创建表并插入文档：__，_是一条记录
查询数据表记录：_，查询一条记录：_
删除表：_，删除表里的所有记录：_{}
查询条数：_
添加索引：_{__}，给__字段添加索引
和：_{_}
排序：_{}，按排序，是升序，是降序
条件查询语句大于小于：_{__{   }}，过滤__在某个时间段内
条件查询语句：_{__ _}，多个字段间用逗号隔开
条件查询语句_{{__ }{_ }}
、其他
大小写敏感
一般我在需要定时调度批量语句时通过把语句写在中通过调用发表者简介： 周蔚， 腾讯专家工程师，即通产品部，平台开发组组长 

导语
年，借着公众号“动态消息”的东风我们把沉寂多年的应用开发框架开发代号移植到了全平台中。基于新框架带来的能力，我们可以将服务以页卡的形式嵌入到消息流中，使用户在多个平台下获得一致的产品体验。中因此诞生了新形态的“轻应用”。此后我们持续在完善框架的应用开发能力。期望基于构建一个开放的场景化“轻应用”平台，并探索未来新的互联网服务形式。
“轻应用”展示：



　
　
　
　

















 “轻应用”暂没有正式的名称。团队内部基于习惯把这种内嵌在中的应用称为“轻应用”，蕴含应用轻小，使用轻便之意。有时候我们也把“轻应用”称为“轻”或“应用”。和中承载的大量全屏体验的应用不同，“轻应用”更多是以碎片化的方式内嵌在中。
支撑“轻应用”的开发代号是我们自研的框架。基于使用脚本语言开发带来的优势，“轻应用”可以像应用一样动态更新，无需随版本发布。且具备多平台、、体验一致性，一次开发，多平台运行   。
“轻应用”的技术特点：
动态更新
动态更新是“轻应用”最基本的技术能力。“轻应用”既可基于包的形式整体更新，也可基于视图局部更新。虽然以技术为代表的方案也可以使应用获得动态运营能力，但主要应用在全屏场景下，而“轻应用”将这一能力拓展到了消息流等新的嵌入式场景。



　
　
　
　











运动基于“轻应用”提供的动态运营能力无需发布新版本即可切换模版风格
轻量
对比其他技术方案、 等，“轻应用”在加载速度和内存占用方面有明显优势。所以“轻应用”可以在不影响基础体验的情况下内嵌在消息流中使用，同时打开数十个甚至上百个视图实例。

运动打开前后内存变化 
为了达成上述轻量化的目标，我们在技术方案选型和实现上都向“轻”的方向有所倾斜。首先我们选择了作为第一个支持的开发语言。的 非常小，充分保证了初始化时间和内存开销的可控。而其基于寄存器的实现也使得脚本程序在性能方面表现优异。另外在部分，中没有提供控件库，只是提供构建的原子能力。开发者可以在上层通过模板装配出可复用的控件。这使核心的部分非常简约。而在工程实现部分，我们在开发时尽可能的复用了各个操作系统提供的差异化的源生能力。虽然这导致了框架的工程实现部分会更繁琐如增加一些中间层的设计，同样的基础模块实现多份等，但在体积控制上具备明显的优势。

可交互
消息流中的图文消息主要用于呈现静态的文字和图片内容。集成后，消息内容具备了更丰富的互动能力。从而使消息流从服务入口的容器升级为了服务本身的容器，嵌入在消息里中的服务可以更短路径被用户使用。
 
基于“轻应用”实现的时钟计算器小游戏，可直接在消息流中完成交互
为了实现上述能力升级，提供了丰富的基础能力供开发者使用。同时也将部分的平台能力进行了封装，使“轻应用”可以更好的融入中。



　
　




界面
文本、图像、画布、输入框、布局器、控制器、模板


网络
、、


多媒体
音频播放、视频播放、动图、


设备
罗盘、加速度、位置



登录、获取用户信息、分享、打开网页应用、扫码



随着应用开发能力的逐步完善，部分团队已经开始尝试基于开发更复杂的全屏“轻应用”。
 
全屏方式打开的腾讯地图“轻应用”
“轻应用”升级场景化应用：
移动互联网时代，手机携带的便利性促使了场景化应用的出现和普及。无处不在的二维码以及诸多基于微信公众号的服务都很好的诠释了场景化应用的价值。基于二维码打开的应用小程序用户在吃饭、唱、看电影等诸多场景中都能非常方便的用上相关的互联网服务。场景化应用的普及进一步促进了互联网融入用户的现实生活，极大提升了用户获取使用服务的效率。基于场景化应用的价值和潜力，我们期望能基于“轻应用”构建场景化应用的平台来充分发挥它的价值。但需要注意到，中并不存在如微信公众号一样强大的开放生态，同时用户看到二维码也不会条件反射般的选择扫码。所以关于中如何建设场景化应用平台需要我们选择和微信不同的切入点和发展思路。
我们当前选择的产品方向是根据用户行为狭义来说就是对话语义和用户属性识别场景，匹配场景化的服务嵌入消息流使用。作出这种选择主要基于两方面因素：首先是对用户的价值。消息流是人与人沟通的核心载体。如果服务能自然的融合到消息流中，所有以沟通为起点的服务都能最短路径获取和使用。其次是技术实现上的考虑。消息流中的对话内容很多时候也正是当前用户所处场景相关的语言表达，有助于平台识别用户所处场景。

中现有的场景化应用主要通过两种被动方式触发：

识别用户输入内容触发应用入口，点击后在键盘区展示。

识别聊天内容在消息流中插入应用入口，点击后在消息流中展示。





　
　
　
　











地图 



　
　
　
　











音乐、自选股、动漫、天气 
基于被动方式场景作为切入点有两个原因：一是客观上现有的语义分析技术能力不足出于对用户隐私的尊重无法使用更成熟的服务器方案，手机设备的资源有限使技术选择有较大局限性，被动方式触发对召回率的要求没有主动搜索那么高。二是主观上策略选择，基于消息流内容的被动触发可以为服务提供方带来增量的流量。为了获得被动触发的机会，需要“轻应用”主动的标注所具备的能力。而主动标注再结合模式识别、自然语言理解等技术手段，用户行为、用户画像、服务三者均转化为可计算的数据。基于计算使用户行为动态关联到个性化的服务，这正是我们建设场景化“轻应用”平台的基础。
注：导流量是把双刃剑，过度的导流必然会伤害用户体验。所以这需要平台团队有更强的克制力。被动场景的“轻应用”接入需要尽量规避带有推荐广告性质的服务，更多局限在和场景有直接关联偏工具属性的服务上。
除了用户行为被动触发“轻应用”所需的应用能力标注以外，我们也期望所有“轻应用”的输出都能是统一的标准化语义化的元数据。结合知识图谱，所有的“轻应用”能聚合成一个有机的整体，使用户从任意场景切入使用“轻应用”，都能伴随着使用“轻应用”的行为自然的切换到下一个场景继续使用其他“轻应用”。


场景化应用并不局限于单个用户到服务的单向连接，基于平台自身的分享能力，可以实现多人和服务的连接关系。群投票、聚餐时点菜、买单、点歌等等都是生活中经常发生的多人共同使用服务场景。而基于消息流内嵌“轻应用”来实现，沟通、服务交互、信息反馈都直接在消息流中完成，使用服务的整体体验更流畅更直观。
 
基于“轻应用”实现的游戏组队，消息流中可实时更新组队状态和组队人数
“轻应用”的未来：
数年前，使用互联网还是局限在特定地点家、公司、网吧使用特定设备上网。在移动互联网时代智能手机的普及打破了时空的桎梏，使人们可以随时随地的使用互联网，淡化了“上网”概念。未来随着物联网等基础设施的完善，穿戴式设备眼镜、汽车、家用电器电视、冰箱、家居设备等都会成为接入互联网的节点。现实世界和虚拟网络世界之间的边界会逐渐模糊。而场景化应用正是促进现实生活和互联网服务融合的重要桥梁。
基于以上判断，“轻应用”未来发展的大方向也可以基本确定。首先在表现层面，我们期望基于“轻应用”能构建标准化的容器，可在手机之外的其他设备中展示，帮助服务以碎片化的方式更方便的嵌入到各种场景中使用。其次是数据层面，我们期望能把“轻应用”标准化语义化的元数据标注拓展到设备层面，使设备能力融合到“轻应用”的服务网络中，构成完整的服务闭环提供给用户使用。



　
　
　










除此之外，和技术的结合同样也是“轻应用”未来需要努力的方向。可以充当现实世界和互联网服务之间的翻译，提升用户使用服务的效率。同时也可以承担数据过滤器的角色，解决信息过载问题。对场景化“轻应用”平台来说，技术的价值具体可以体现在以下几个方面：

挖掘更多数据生成精确的场景描述，给用户更个性化的服务界面。

改善人机交互方式，使用户可以更高效的使用服务。

辅助用户在使用服务时更高效的做决策。


“连接一切”是公司未来发展的大战略。“轻应用”的发展方向和这个大战略也是一致的。我们期望 “轻应用”在未来能更好的扮演连接器的角色，连接用户和服务。能让用户拥有更加便捷高效的生活。本文由  编译，腾讯云技术社区经授权转载。
译者按  的语法非常简单，然而如何加快镜像构建速度，如何减少  镜像的大小却不是那么直观，需要积累实践经验。这篇博客可以帮助你快速掌握编写  的技巧。
为了保证可读性，本文采用意译而非直译。另外，本文版权归原作者所有，翻译仅用于学习。
我已经使用  有一段时间了，其中编写  是非常重要的一部分工作。在这篇博客中，我打算分享一些建议，帮助大家编写更好的 。
目标

更快的构建速度
更小的  镜像大小
更少的  镜像层
充分利用镜像缓存
增加  可读性
让  容器使用起来更简单

总结

编写 文件
容器只运行单个应用
将多个  指令合并为一个
基础镜像的标签不要用 
每个  指令后删除多余文件
选择合适的基础镜像 版本最好
设置  和 
使用  可选
在  脚本中使用 
 与  优先使用前者
合理调整  与  的顺序
设置默认的环境变量，映射端口和数据卷
使用  设置镜像元数据
添加 

示例
示例  犯了几乎所有的错当然我是故意的。接下来，我会一步步优化它。假设我们需要使用  运行一个  应用，下面就是它的  指令太复杂了，所以我简化了，它是错误的，仅供参考。
 

  

    

     

        

     

        

        

     

      
构建镜像
    
 编写 文件
构建镜像时， 需要先准备  ，将所有需要的文件收集到进程中。默认的  包含  目录中的所有文件，但是实际上，我们并不需要 目录，_ 目录等内容。
 的作用和语法类似于 ，可以忽略一些不需要的文件，这样可以有效加快镜像构建时间，同时减少  镜像的大小。示例如下


_
 容器只运行单个应用
从技术角度讲，你可以在  容器中运行多个进程。你可以将数据库，前端，后端，， 都运行在同一个  容器中。但是，这会让你非常痛苦

非常长的构建时间修改前端之后，整个后端也需要重新构建
非常大的镜像大小
多个应用的日志难以处理不能直接使用 ，否则多个应用的日志会混合到一起
横向扩展时非常浪费资源不同的应用需要运行的容器数并不相同
僵尸进程问题  你需要选择合适的  进程

因此，我建议大家为每个应用构建单独的  镜像，然后使用   运行多个  容器。
现在，我从  中删除一些不需要的安装包，另外， 可以用   替代。示例如下：
 

  

    

   

        

     

          

     

  
 将多个  指令合并为一个
 镜像是分层的，下面这些知识点非常重要

 中的每个指令都会创建一个新的镜像层。
镜像层将被缓存和复用
当  的指令修改了，复制的文件变化了，或者构建镜像时指定的变量不同了，对应的镜像层缓存就会失效
某一层的镜像缓存失效之后，它之后的镜像层缓存都会失效
镜像层是不可变的，如果我们再某一层中添加一个文件，然后在下一层中删除它，则镜像中依然会包含该文件只是这个文件在  容器中不可见了。

 镜像类似于洋葱。它们都有很多层。为了修改内层，则需要将外面的层都删掉。记住这一点的话，其他内容就很好理解了。
现在，我们将所有的  指令合并为一个。同时把   删除，因为它会使得镜像构建非常不确定我们只需要依赖基础镜像的更新就好了
 

  

   \  

         \

       \

      

  
记住一点，我们只能将变化频率一样的指令合并在一起。将  安装与  模块安装放在一起的话，则每次修改源代码，都需要重新安装 ，这显然不合适。因此，正确的写法是这样的
 

         

    

     

  
 基础镜像的标签不要用 
当镜像没有指定标签时，将默认使用  标签。因此，   指令等同于  。当时，当镜像更新时， 标签会指向不同的镜像，这时构建镜像有可能失败。如果你的确需要使用最新版的基础镜像，可以使用  标签，否则的话，最好指定确定的镜像标签。
示例  应该使用  作为标签。
      

         

    

     

  
 每个  指令后删除多余文件
假设我们更新了  源，下载，解压并安装了一些软件包，它们都保存在 目录中。但是，运行应用时  镜像中并不需要这些文件。我们最好将它们删除，因为它会使  镜像变大。
示例  中，我们可以删除  目录中的文件它们是由   生成的。
 

   \  

         \

      

       

    

     

  
 选择合适的基础镜像 版本最好
在示例中，我们选择了  作为基础镜像。但是我们只需要运行  程序，有必要使用一个通用的基础镜像吗？ 镜像应该是更好的选择。
 

    

       

    

     

  
更好的选择是  版本的  镜像。 是一个极小化的  发行版，只有 ，这让它非常适合作为基础镜像。
 

    

     

  
 是  的包管理工具。它与  有些不同，但是非常容易上手。另外，它还有一些非常有用的特性，比如  和  选项，它们都可以帮助我们减少镜像的大小。
设置  和 
 指令可以设置默认目录，也就是运行     指令的地方。
 指令可以设置容器创建是执行的默认命令。另外，你应该讲命令写在一个数组中，数组中每个元素为命令的每个单词参考  官方文档。
 

   

    

  

  
 使用  可选
 指令并不是必须的，因为它会增加复杂度。 是一个脚本，它会默认执行，并且将指定的命令错误其参数。它通常用于构建可执行的  镜像。 如下
 

      

       

    

=

    

   

     

     _=

       

    

   

               

              

      _  

     _=

      

    

    

                

       _     

      {}

    


示例 
 

   

    

  

   

 
可以使用如下命令运行该镜像
 运行开发版本

    

 运行生产版本

    

 运行

    
 在  脚本中使用   在  脚本中使用 
在前文的  脚本中，我使用了  命令运行  应用。不使用  的话，我们则不能顺利地关闭容器，因为  信号会被  脚本进程吞没。 命令启动的进程可以取代脚本进程，因此所有的信号都会正常工作。
  与  优先使用前者
 指令非常简单，仅用于将文件拷贝到镜像中。 相对来讲复杂一些，可以用于下载远程文件以及解压压缩包参考  官方文档。
 

 

    

  

   

 
 合理调整  与  的顺序
我们应该把变化最少的部分放在  的前面，这样可以充分利用镜像缓存。
示例中，源代码会经常变化，则每次构建镜像时都需要重新安装  模块，这显然不是我们希望看到的。因此我们可以先拷贝 ，然后安装  模块，最后才拷贝其余的源代码。这样的话，即使源代码变化，也不需要重新安装  模块。
 

 

    

    

  

   

 
 设置默认的环境变量，映射端口和数据卷
运行  容器时很可能需要一些环境变量。在  设置默认的环境变量是一种很好的方式。另外，我们应该在  中设置映射端口和数据卷。示例如下
 

 _=

 _

  _  

    

  _

 _= \  

    _= \

    _=

 _  

 _

   

 
 指令指定的环境变量在容器中可以使用。如果你只是需要指定构建镜像时的变量，你可以使用  指令。
 使用  设置镜像元数据  使用  设置镜像元数据
使用  指令，可以为镜像设置元数据，例如镜像创建者或者镜像说明。旧版的  语法使用  指令指定镜像创建者，但是它已经被弃用了。有时，一些外部程序需要用到镜像的元数据，例如  需要用到 。示例如下
   

    


 添加 
运行容器时，可以指定   选项。这样的话，容器崩溃时， 守护进程  会重启容器。对于需要长时间运行的容器，这个选项非常有用。但是，如果容器的确在运行，但是不可陷入死循环，配置错误 用怎么办？使用  指令可以让  周期性的检查容器的健康状况。我们只需要指定一个命令，如果一切正常的话返回 ，否则返回 。对  感兴趣的话，可以参考  这篇博客。示例如下
   

  

 _=  

 _

  _  

    

  _

 _= \  

    _= \

    _=

 _  

 _  

    _ ||  

   

 
当请求失败时，  命令返回非  状态。

原文     译者 译文原地址：一、简介
 和  一样都是基于  开发的，是比  和  更轻量级的运维自动化工具。无服务器端，使用时直接运行命令即可，不需要在被管控主机上安装任何客户端，所以任何一台机器只要安装了  就可以管控其他主机。基于模块工作，可使用任意语言开发模块。也可使用  语言定制剧本 ；基于工作；可实现多级指挥。
二、安装配置
、准备工作
准备三台机器 _，这两台机器都关闭 ，清空  规则并保存。  

：

：

：


、编辑  文件
两台都设置，若机器太多，可以通过搭建 ，则不用在每台机器上设置这个

  

  

  


、设置 
在  上
   
    =

在  上
   
    =
、安装
      
     
、密钥配置
在服务端生成密钥，并且复制公钥到节点中。
        一路回车下去
   _  _

使用命令来复制公钥到节点中
         输入和密码
         输入和密码
、配置
   
    
    
    
    
三、 实例
、远程执行命令
       
     |  | = 
                 
                                       
                           
                            
                             

     |  | = 
                 
                                       
                            
                             

     |  | = 
                 
                                       
                                       
                           
                             
                           
注意： 指定模块名， 指定相应命令，这样就可以批量执行命令。这里的  为之前自定义的主机组名。当然我们也可以直接写一个 ，针对某一台机器来执行命令。如下：
       
     |  | = 
                 
                                       
                            
                             
、远程执行脚本
        创建一个脚本
    
     ``  _
       = = =        把脚本分发到各远程机
             批量执行脚本
        |          注意： 模块，还支持远程执行命令并且带管道
、拷贝文件和目录
       = = = = =       拷贝文件
       = = = = =      拷贝目录
、添加计划任务
       =_ =   = =
注意：其他的时间表示：分钟 ，小时 ，日期 ，月份 。
、删除任务计划
若要删除该  只需要加一个字段 =
       =_ =
、安装
这里用安装工具
       =
、服务管理
       = = =       开启  服务，并关闭开机启动。
、文档使用
列出所有的模块
       
查看指定模块的文档
                           
       

相关推荐
  如何接入腾讯云  的  【腾讯云的种玩法】云服务器搭建环境作者： 倩倩

最近鹿晗爆出了与关晓彤的恋情天时间这条宣布恋情的微博光点赞就有万！一瞬间微博和娱乐圈都炸了

 
两人恋情公布后，由于瞬间流量过大，导致微博服务器崩溃，一些用户的客户端无法正常刷新和评论，为此微博紧急租用了台服务器来面对这突如其来的流量高峰。
两人的恋情也让一位名为丁振凯的程序员火了，他是微博搜索的工程师，当天正好是他大婚的日子。服务器崩溃时他正在山西侯马举行婚礼，为了处理紧急情况，他不得不从酒席上离开，处理微博异常后才又返回继续婚礼……
而这条微博的点赞率也高达万，也算是条大流量博了。
在这个星光熠熠的时代，明星的一举一动无不牵动着粉丝的点。
粉丝，作为这个时代社交网络的中坚力量，在引爆话题、带动消费等各方面均展现出巨大的能量。你或许身居其中，也可能超然其外。
这些当今最火的明星们，不论你站哪一队，不论你粉谁，相信你都从未停止对他们的好奇！
别着急！来看看腾讯社交洞察联手腾讯用户研究与体验设计中心发布的《流量明星受众分析报告》，你会了解到：
品牌主最关心的位明星的广告价值迪丽热巴和杨颖的受众消费兴趣图谱和鹿晗的话题图谱明星们的粉丝兴趣大观察废话不多说  我们开始吧！

当之无愧人气小鲜肉
自带话题属性哪家强

迪丽热巴加入《奔跑吧》之后，话题也在蹭蹭蹭的上涨，关注度超过杨颖和杨幂，成为今夏话题“黑马，网络受众讨论规模居首位，有近万条讨论。
杨颖虽然由于怀孕生产，活动都已暂停，但也丝毫不影响自身的话题热度，位居第二位。

小鲜肉当道，鹿晗、分列话题榜单第一第二，热度不相上下。李易峰、吴亦凡、杨洋人气持续高涨。
而鹿晗可谓是一举一动都能成为话题将近万条讨论，网络受众讨论规模居首位，如果加上这两天恋情曝光后的数据，可能这个数字会更大！不过人红是非多正面评论率占最低，仅占。
女性粉丝偏爱小鲜肉
后撑起粉丝圈半壁江山

同为热门明星，但追捧人群各不一样！迪丽热巴受到超男生追捧，荣获“宅男女神”称号！
—岁中小学生却偏爱杨颖；刘诗诗更招同龄人喜欢；杨幂及郑爽受众群体基本相似，平均年龄为岁。

这是一个看脸的时代！男星受众的特征基本一致，男女比例对半开，年轻人占据主流，且城市分布差异化不大。
有个有趣的点是，岁以上的粉丝喜欢的是年纪最小的们！年龄算什么？该追的星还是要追的！
“有车一族”“有房一族”
“单身粉丝”“成家男女”

在女星中，迪丽热巴受众可能拥有车辆人群占比较高，而刘诗诗的受众中则为有房一族较多。单身男女偏爱杨颖、迪丽热巴；成家男女则追捧刘诗诗、杨幂、郑爽。
以后相亲问对方有无车房可以换个含蓄的方式了：“或许，你喜欢迪丽热巴或者刘诗诗吗？”

那哪位男星会更受有车有房一族的青睐呢？
受众属有车一族在五位男星中的可能性最高，鹿晗的受众属有房一族的可能性最高。
情感方面，吴亦凡的单身受众比例最高，可能大家更喜欢所以无惧单身吧；而李易峰、鹿晗更受情侣的欢迎；杨洋则被新婚人群所青睐。
这年头，读的书打的游戏越多
就越喜欢追星！

女星受众兴趣各不同，迪丽热巴、杨幂、杨颖的受众均为游戏爱好者；郑爽受众爱宅在家中看剧打游戏。
而刘诗诗的受众则表示世界那么大，我想出去走一走。

男星受众兴趣多与音乐有关，其中关键词中国民谣、中国摇滚更是被多次提起。
而粉丝喜欢的歌手也大致接近，纷纷对周杰伦、张杰、林俊杰、薛之谦、汪苏泷、杨宗纬和陈奕迅等男歌星感兴趣。
粉丝消费兴趣大揭秘
不仅爱追星还更爱享受生活

粉丝的消费兴趣标签已经成为精准化定义的重要指标。
杨幂受众更爱吃喝玩乐，尤为关注快消娱乐品；刘诗诗受众因年龄关系，则对教育、金融、汽车、家电等低频消费更感兴趣。综合来看女星受众比一般人群在消费领域更为突出。

男星受众消费兴趣相较与女星受众消费兴趣较为一致，在游戏、婚恋交友、教育、数码、动漫小说和美容方面消费高于一般人群。
其中李易峰和杨洋受众兴趣更加广泛，且李易峰受众更偏爱数码、服饰、美容。
报告数据来源声明：引用腾讯社交大数据、腾讯指数。

本文来自： 腾讯大数据 公众号作者｜商户运营开放团队编辑｜顾乡

移动支付时代，越来越多的人习惯于不带现金出门，许多支付场景只需要掏出手机就能完成。正因为如此，收银系统的可用性问题也越来越重要。如何打造移动支付时代的高可用收银系统？这是微信支付团队的经验，仅供参考。

一、为什么强调收银系统的可用性？
随着移动支付高速发展，用户已养成出门消费不带钱包的习惯， 频繁的日常消费对商户收银系统高可用提出了极高的要求，收银系统一点小小的故障如“付不了钱、重复支付、付款超时”等都会給用户和商户带来诸多的不适和不利，引发用户愤怒、投诉、纠纷，最终导致商户的用户流失。所以对于商户来说如何打造高可用的收银系统就变得十分的重要。
如何打造高可用收银系统？看完本文，相信您将有所启发。
二、高可用收银系统设计方案
通过对市面上的收银系统进行分析研究，发现普遍存在以下风险：
服务时延不稳定：

跨城调用、配置不当，导致网络不稳定；

系统可用性考虑不周：

多个支付渠道支付宝、微信等部署在一起，相互影响；

业务逻辑服务和数据服务部署在一起，相互影响；

无异地容灾、自动切换能力；


数据容灾恢复不及时：

单点、主备切换依赖人工、故障恢复时间不可控；

为了帮助商户提升服务质量，尽可能降低以上风险，微信支付团队提出一套高可用收银系统的设计方案，其系统架构图如下所示：
接下来从三个层面分别阐述：
降低服务时延：
收银系统线下门店遍布全国、网络复杂包含电信、联通、铁通、移动等，对系统时延提出更高挑战。
针对这个问题，一些云服务商支持“网络访问跨地域实时切换”的能力，通过冗余网络出口部署，实现跨区域网络间灵活切换调度，为网络出口灾备提供了保障。
另外腾讯云联合微信支付推出支付加速方案，部署在腾讯云上的服务可以直接将发往微信支付的公网请求解析为内网访问，将延时率减少，提升用户支付体验。
同时，微信支付官方还提供了和两个域名，供服务商系统自行探测服务质量，优先选择速度更快的域名进行访问。
注：双域名探测择优有如下注意点：

并发探测，谁先回来谁先被采用，从而提升效率；
建立探测重试机制、控制探测频率，减少不必要的探测；
建议的探测时机：系统开启时发起探测，或请求超时发起探测；

云助力，低成本提升可用性：
文章开头提到，在移动支付时代，用户对收银系统的可用性有更高的要求，这就迫使服务商做系统设计需要考虑更多因素。
由于这些因素实现成本比较高，纯粹自己实现的话不太现实，所以这里笔者将结合比较熟悉的腾讯云提供的能力来进行阐述，建议身处云时代的服务商多了解这些能力，低成本解决高可用问题。
 因素一、多地部署、多点接入：
利用腾讯云在全球多个数据中心的基础设施，很容易实现多地部署和多点接入，在架构层的高可用设计可以最大限度容忍单个地域网络运营商故障和网络抖动带来的不稳定因素，并为全球各地的业务伙伴提供最优质的接入条件。
当网络出现故障时，腾讯云全球内网互联互通，及时调度业务流量至其他区域可以保证用户体验不受影响。
 因素二、防攻击：
攻击将真正的用户挡在门外，现在云服务商也会提供防御此类攻击的服务。比如腾讯云大禹高防系统提供防护带宽和道线路，可以动态调度网络流量，帮助用户有效抵御攻击。
 因素三、负载均衡、故障屏蔽：
为了提升系统的稳定性和容灾能力，业界比较成熟的解决方案是基于“无状态的应用层服务设计”，做到能够“实时监控服务器节点可用状态、自动转移失败任务到其他可用节点、将集中请求分摊到集群各个机器节点的能力”。
身处云时代服务商可以借助腾讯云的负载均衡能力来低成本解决这个问题。腾讯云的负载均衡具备健康检查能力，可允许用户自定义健康检查频率，以确保后端云服务器在出现故障时第一时间感知到并且及时切走业务流量，保证前端应用的高可用和无感知。
 单集群台物理服务器组成，最大并发连接数超过亿，可处理峰值的流量，每秒处理包量为万。只有一台实例可用的极端情况下，仍可支撑万以上的并发连接，确保后端正常提供服务，高扩展和低成本的优势最大限度节省成本。
 因素四、过载保护：
移动支付目前处于高速增长期，各种营销活动会带来业务高峰。
一方面需要及时扩容，预留冗余服务能力；另一方面当实际业务流量远超过系统的最大正常服务水平时进行自我保护，快速拒绝掉部分请求，保证正常的服务水平，而不是被拖垮影响全部服务；
建议采用云服务商提供的消息队列，通过云上的分布式消息队列提供可靠的异步通信，有效提升系统吞吐量，确保消息的可靠传递，减少后端系统压力，防止系统雪崩。
另外腾讯云服务器具备弹性伸缩 能力，只需配置简单的伸缩规则，集群即可在高负载时自动扩容缩容，确保业务平稳度过高峰。按量计费能力可以最大限度节省成本。
 “跳单”，实现数据层秒级自动容灾切换能力：
收银系统的数据分成两类，一类是订单信息主要包括订单表和退款表，特点是数据量大且多读多写；另一类是基础信息主要包含门店、设备、商户等信息，特点是数据量少且多读少写。这里介绍的数据库高效容灾实践是基于订单信息Ｂ，以为例。
容灾策略普遍依赖“半同步，主备切换”，通过自动或者人工切换业务恢复时间在分钟到几十分钟之间。这对于交易量稍大的场景来讲，故障恢复时间还是太长。如何在更短的时间内达到恢复业务，我们设计了“跳单”的数据层容灾解决方案。
核心思路：
在数据访问层封装一个“跳单”组件“自动避开有故障的存储”，让订单数据数据可以随意落到各个容器。
下面详细介绍“跳单”的整体流程：为了实现跳单逻辑，我们先将数据库水平划分为若干组，每组一主两备、读写分离，主用来写，从用于读，主从同步由半同步机制来保证。
使用订单号保存分组标记，如原先单号为，可以在最后一位加分组标识，如组，则变成
在这样的前提下：
创建订单请求：
收银终端的一个创建订单请求过来，先调用选择器随机选择一组，然后查询计数器，看该组失败次数是否超出阈值，超限则跳过重选，否则通过探测器发送一条语句，探测是否可用。如失败则需重选，成功则把分组标记写到单号，把订单插入改组。
更新或查询请求：
直接解析单号的分组标记，然后操作对应。“跳单”保证新交易是正常的，优先把支付做成。某组发生故障时，订单查询和撤销等操作需等主备切换恢复才能进行。
这里的注意事项：

计数器需要设置周期，比如一分钟，以便设备故障恢复自动启用。

调用的时候需要设置超时时间，比如秒，避免某一组故障，拖死上层服务。

探测使用语句，这是因为如果死机恢复了之后有可能是只读状态，如果发送来探测就无法保证是可写的。


三、做了“跳单“后的日常演练
为检测系统是否真正高可用，需要做定期演练，以下是我们的日常演练计划：

每周做一次单组故障的常规演练。

每季度做一次多组故障演练。


从下图演练时的监控可见，当某组故障时请求会掉底发生跳单，但整体曲线平滑，业务运行正常，无影响。
四、做了“跳单”后的扩容和缩容
扩容步骤：

部署新的订单，给它分配编号；

将新库信息配置到选择组件；

新库接入业务流量；

观察监控有无异常；


缩容步骤：

将撤掉的库编号按收缩之后剩余数取模：例如原来有组，收缩到组，计划撤掉库，则先把库模得到。

把数据迁移到库，修改配置，关闭库流量。新的订单不会再进入库，而历史查询则通过取模访问库即可。

监控无异常之后正式撤掉库。


五、做了“跳单”后的商户维度查询
多组容灾方案有一个通用难题就是“商户维度列表查询效率问题”。订单分散在不同的，若查询量小则可直接采用全库扫描，通过上层并发调用来解决效率问题。如果变成高频操作，则需考虑额外搭建一套数据库，以商户纬度进行数据存储，这两套数据库之间的数据同步采用可靠消息队列来进行同步。具体推荐了解下腾讯云上面的和组件。
虽然因为“跳单”而带来了列表查询的效率问题，但是对收银系统来说，核心设计理念还是“尽可能把支付做成”！不要因为列表查询问题而影响到核心支付的可用性。
六、收银系统安全性考虑
系统安全性也是衡量一个收银系统可用性的关键指标，通过调研发现线下收银系统有可能存在以下安全风险：

收银终端软件被非法安装；

整台机被盗；

中间人攻击；

正常交易订单被非法退款；


为了应对上述风险，我们提供以下策略供大家参考：

机注册激活机制，即解决收银终端软件被非法安装的问题，又可以在机被盗时直接屏蔽掉；

请求及响应参数签名机制，防止客户端伪造，及请求篡改；

走协议，且限制合法根证书，防止中间人抓包、监听、请求重放；

限制当天内的订单可以在当时交易的机上发起退款，超过一天的只能通过微信支付商户系统进行退款，解决恶意退款问题。另外微信支付官方安全团队也在微信支付的开发者文档里面加入了“最佳安全实践”，大家可以自行前往查看。


七、推荐使用微信支付网络监控工具
为了更好的监控商户服务器与微信支付服务器之间的网络质量，微信支付的运维团队提供了一套网络监控工具，通过将监控数据上报到微信支付的运维系统，方便运维人员帮助商户优化链路质量。
该工具的详细使用说明可以看微信支付开发者文档中的说明。
八、写在最后
综上所述，从无到有搭建一套高可用收银系统要考虑的问题点很多。全部自建成本不低，建议多关注云服务商提供的一些基础能力高防、网络访问跨地域实时切换、分布式消息队列、负载均衡、弹性伸缩、、“云支付”等，尽可能站在云时代的基础设施上来进行高效研发才是更加明智的选择。
再次强调，我们追求的是 “尽可能把支付做成”！
微信支付团队会继续保持对“高可用收银系统”的技术研究，希望可以持续给整个行业输送经验，帮行业提升服务质量，最终让用户享用到更好的移动支付服务。
文字略多，感谢您的耐心阅读！
本文作者：郭润增、唐川鹏、黄东庆、苗俊磊、邵然关于商户运营开发组：我们致力于用技术帮微信支付合作伙伴赋能！
本文转载自公众号本文来自：
编辑：霍丙乾
源码地址：

导语
本文通过  以及  两种方式对   项目进行构建，提供了详细的从  源码编译、到   项目的编译及运行的方法，以及该过程中遇到的问题和解决方案，涉及两处对编译器的修改也已经提交 。
最近因为  上线的原因，一直没顾上对   进行体验，现在   预览版发布一周了，我来给大家较为详细地介绍一下它的一些相关内容。
、  是什么
  不是  的概念，它不仅仅是要与底层代码比如 、 交互，而且还要绕过  直接编译成机器码供系统运行。也就是说， 准备丢掉  这根拐杖了！
其实我第一次看到  这个名字的时候很自然的想到了 ， 跑在  上面，使用  与底层代码交互是一件再正常不过的事情了，至于搞这么大动静么，不过等我进行了一番了解之后才发现， 项目组的野心真是不小， 诞生这么多年了，也没有做过编译成除  虚拟机字节码以外的字节码的事情， 才出来多久啊，果然具有革命性。
所以以后有人再问你，什么是 ，你要回答， 是一门很牛逼的静态语言而不是之前经常说的  是一门运行在 、、 上的静态语言了，反正你能想到的， 项目组都想干
、如何编写   程序
现在   刚刚处在技术预览阶段，离商用目测还需要至少一年的时间小小地激动一下，年会不会发布正式版呢，性能优化、标准库、反射等等功能现在尚处于早期的状态，所以大家也没必要强求。下面我给大家介绍下怎么编译出一个  工程。
 准备编译器
编译器目前有 、 两个版本，可以编出运行在 树莓派、 以及   和  系统上的程序 真可怜。。，下面的演示运行在     上，与  的小伙伴可能稍微一些差异。
编译器官方有现成可用的版本，下载地址如下：

  

  树莓派 


不过呢，也建议小伙伴们直接  编译器源码编译，没有复杂的编译步骤，两行命令即可搞定编译。
  
代码拖下来之后，保证网络畅通，运行：
  
这一步是下载依赖，官方源码使用了，所以如果你本地没有   的话也会自动去下载。这一步就是下载下载下载，所以一定要注意，出错的话基本上就是网络问题。运行完成之后，你就会在  目录下面看到下载的各种依赖了。

接着就可以编译了：
 
编译时间不长，如果出现错误，可以  多试几次。。编译完之后我们就可以得到编译器一份啦。

  版 
下面我们先在  中创建一个普通的  工程，创建好之后，修改  文件，改成下面这样：


 {
     {
        
         {
              
        }
    }

     {
         
    }
}

  

 {
     {
            的配置文件
            头文件目录，可以传入多个
            头文件编译后映射为  的包名，这个有问题，后面我们再说
    }
}

 {
     {
           代码配置，项目入口  需要定义在这里
          使用前面的  配置
         _ 自己编译的  字节格式的依赖
           编译的目标平台
    }
}
我们可以看到， 就是用来编译  为  代码的插件， 配置我们的项目， 主要用来配置  调用  的接口。有关插件的配置，可以参考官方文档：_。
配置好之后，我们还要创建一个  文件，加入下面的配置：
 配置编译器 ，要配置为  目录的 
 例如：=你的  源码路径
=你的编译器路径
当然，这个配置可以不加，那样的话，你编译的时候会首先下载一个编译器放到你本地。
接着我们创建一个  文件，用来配置  源码到  的映射关系：

=_
下面准备我们的源码，在工程目录下面创建  目录，在  目录下面创建下面的文件：
_
 __
 __

 

  

 __
_
 _
 

 {
    \
}

  {
      \ 
     ==   
         
}
我们定义了两个函数，一个用来打印 “”，一个用来计算阶乘。
接着在  目录下面，用命令行编译：
 =  _  _ 
如果提示找不到  命令，可以去编译器的  目录中找。
截止到现在，我们已经编译好  源码了。接着我们创建  源码：

 

   {
    
    
}
好了，这时候我们可以运行  的  任务了：
    

 

 
 

 
        
        


 

   
     
编译完成之后，在 目录中会生成一个  文件，命令行运行它：
 

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  





好，我们的程序已经运行起来了，我们看到了  当中的  输出以及阶乘求解的过程，大功告成。
当然，你还可以编写更多好玩的代码，编译的结果就是  再也不需要  了，你说激动不激动？
 命令行版 
除了  构建外，我们也可以直接使用命令行编译  ，具体步骤也比较类似，首先准备好源码，跟  中一致。
接着编写  或者 ，官方采用了  脚本的方式来构建，那么我下面给出类似的 ：
   
         _  

   
        

  _ _
      
     =   _  _ 


        
这样只需要在命令行执行先把编译器  加入 ，之后执行 ，编译完成之后就可以在 下面找到了。
 几个重要的坑
  插件指定包名的问题
  插件配置中， 有一行可以配置  代码映射到  的包名：
 {
     {
        
           生成的  代码标识符中含有 “” 倒是无法编译
    }
}
如果这样配置，那么生成的 文件就会出现下面的情形：
 
 _

_ __ _  {
     _ 
}
__ 显然这不是一个合法的  标识符。因此目前这个地方还是有问题的。
这个问题我已经提了 ，参见：    
解决方案也比较简单，我发现这段儿  代码生成的时候，编译器企图对包名中的特殊字符进行替换，只不过替换的是 ““ 而不是 “”：

        
           {
               == 
              _   _  _  
              _   _  _  
          }
  的  函数不能有包名
细心的读者应该会发现，我们前面写的  函数所在文件是没有  的，如果你给这个文件制定一个 ，那么编译器就无法找到入口函数，进而导致编译链接错误。
    _
  _  
      __  
      _
         
     
     
  文件的路径
如果你使用前面的  进行编译， 调用时传入的  文件的路径一定不能写成下面这样
    
 必须使用 的形式，否则编译器在编译时出遇到类似下面的问题：
     = =     
       
    
           
         
         
         
         
以上用  替换了编译的路径。
这个问题是因为  最终会调用  去编译一个动态生成的  文件，而调用时传入的  是  文件的父目录，如果我们传入  文件时写了形如 “ ” 这样的参数，那么得到的父目录就是  了，于是就出现了各种找不到文件的情况。
当然我们可以对编译器源码稍作修改就可以解决这个问题：

        =   
           =   
     
这个问题我也在  提了 ，大家可以参考：         “ ”。
、展望
嗯，这题目看上去真有点儿让我想起毕业论文来呢。不过这个展望比起论文的展望要踏实得多。
  支持
通过前面两节对   项目的构建和运行，我们发现  官方对于开发体验非常关注，尽管目前  对此的支持还基本为零，不过  插件的支持已经非常令人满意了。相信随着   项目的迭代， 对其的支持也会趋于完善，彼时我们开发   的程序简直会  到飞起。
当然，我们也看到前面的构建过程中，对于  源码的构建支持几乎为零，我们仍然需要手动对  文件进行编译，不过这个并不复杂，所以极有可能出现的情形是  专门为  搞一个  的版本哇塞，整合  以及现有   的功能，一键编译  以及   源码也未可知呀。
 支持更多平台
  技术预览版还不支持 ，这可苦了没有  机器的小伙伴们嗯，虚拟机可以拯救你们，不过这只是暂时的，前期也没必要在很多平台上投入精力，一旦   在  机器上火起来，届时  版的动力岂不是更大么，哈哈。
比起对  版的支持，我觉得对  的支持才是杀手级的。毕竟现在写桌面程序的人要少一些了，而  程序也大多用微软全家桶，所以赶紧支持  吧，哈哈哈。
 再见，
从学知道  的一开始，就尝试着写过几个小程序，结果毋庸置疑，除了蛋疼就是蛋疼， 支持也困难得不要不要的。后来开始写 ，也基本上对  是敬而远之。
说起来我们公司项目有大量的  代码用  编写，在  和  上有相应的移植版本，开发完成后再打包移植到  以及  上。当然，我并不在这些项目组，我只是觉得搞这些开发的同事特别是负责移植到  的同事的实在太优秀了，像我这种  脑残粉，离了  智能提示的话，一行代码都写不下去。。。
 的出现很有希望终结  的痛苦现状，  也将为我们这些  打开一扇窗户，让我们几乎零成本进入底层代码的编写。
那个什么，以后别说自己是  了，说自己是  吧，也欢迎大家经常光顾 。
 大一统
如果我想写个牛逼一点儿的程序，我会选择 ，原因是我对它最熟；
如果我想写一个工具脚本，我会选择 ，尽管  有时候还真是挺坑的，不过用着还算不错；
如果我想写个网站，我会选择 ，因为开发方便，资料也多
嗯，自打一开始学编程，我就发现这坑可踩大发了。尽管用  可以写出  能写出的任何程序， 也一样，不过每一门语言终究因其自身的特点而擅长于不同的使用场景。
前不久跟一个资深开发聊天，他问我  能做什么，我说能做这个，能做那个，结果他听了之后来了一句： 能写的  都能写是呗？没错，他说得是对的，只是这能和能做好之间可就差了十万八千里了。
请问，如果你想要写一个小工具，你用  写的话，是不是工程还没有配好，别人用  就已经调试完了？如果你用  写  应用，是不是工程还没配好，别人用  已经开始跟客户端联调了？这么说也许夸张了一些，但不得不承认的是，每一门语言都有其擅长的场景，“能干的也能干” 这样的句式简直让人有种 “你行你上啊” 来批驳的冲动。
那么  的出现究竟能给我们带来什么呢？试想一下，写小工具，我们可以用  ；所有  擅长的  都擅长，而且写起来还比  简洁不少；你甚至可以用  来开发前端程序来替代 ，尽管这个目前看来还没有很多人用到。而现在呢，我们还可以把  直接编译成  一样的机器码来运行，这样一来， 将来还可以直接应用于嵌入式等对性能要求比较高的场景，这可真是上的了云端，下的了桌面，写的了网页，嵌的了冰箱啊。
一句话， 从  起家，现正在向着各种应用场景用功，各个场景的表现也不错，俨然成为一门擅长多个领域的语言了。
当然，程序员们也是萝卜青菜各有所爱，真正实现大一统显然也不太现实，但我们至少拥有了这样的途径和机会是不是？

如果你有兴趣加入我们，请直接关注公众号 。关闭不需要的服务。列出需要启动的的服务、、、、  启用  服务既可以提升性能，又可以降低能耗。
 是  系统日志服务。关闭  ， ，将=改为。
脚本如下：

系统优化脚本，关闭除了、、之外其它不常用的服务。
   ` `

=` |  `
 
  
 |  | _ |  |  |  |  |  
     
  

      
      
    
  



对网络参数进行调整
调整网络参数，可以增强 的能力，命令如下
 _=
执行 立即生效

修改  命令的  记录个数
 
将=改成
 立即生效
定时校正系统时间
   
添加计划任务
        

调整  的最大文件打开数
在文件中添加  

关闭写磁盘功能
如果有多个小文件，通常就没有必要记录文件的访问时间，这样就可以减小写磁盘的。打开文件，然后在包含大量小文件的分区中使用和这两个命令
   ，  


相关推荐
扩容文件系统 下相关知识总结导语
通过信息技术改造传统媒体的作业模式，是媒体行业发展的基础动力。为了更好地应对信息化对媒体行业带来的冲击，并抓住云化变革所带来的新机遇，金融时报与海云捷迅一起，打造出超融合一体化云平台项目，为报社及全媒体新闻生产业务提供了有力的基础支撑和承载环境。媒体迎来新时代。
《金融时报》是以金融为特色的综合类财经报纸，自年月日创刊以来，便成为党和国家在金融领域的重要舆论阵地和传播金融政策和信息的重要渠道；是中国人民银行和国家外汇管理局授权公布金融统计资料的核心媒体，是银监会、证监会、保监会指定的重要信息披露媒体。
随着虚拟化、云计算、物联网以及大数据等新技术的兴起，由云计算技术推动的信息化变革正在走向现实。新信息化工作模式正逐渐成为企事业单位竞争力的重要支撑。“十三五”期间，新技术引导的信息化能力提升将成为企事业单位信息化建设的中心内容。
从报业信息化浪潮以来，金融时报的绝大部分业务系统目前都实现了信息及流程的数字化处理，建立了两大类不同的管理信息系统，专业类应用及通用类应用，专业类应用，指和报社日常生产业务非常相关的专业信息系统应用，比如采编、排版、广告、资料库、考核和财务等。通用类应用，指和报社生产业务流程不太相关的比较通用的周边辅助类应用系统，比如电子邮件、公司内网论坛、系统和即时通讯等。
由于历史和技术发展的原因，报社内大部分管理信息系统都呈现分散配置的特点，各个业务系统之间，各业务系统内各个服务之间，都各自独立，并各有各自的专用硬件和软件平台，且独自分别维护，形成一种“烟囱式”垂直体系结构的配置模式。
云时代面临的新问题
新技术的出现，激发新的需求应用；新的需求应用的产生，又催生出新的业务形态。电子信息技术颠覆了报纸传统的铅排出版方式，而互联网时代的到来又改变了媒体，发布、阅读、传播的途径。整个报业都在这种内外环境的剧烈变化下，面临全新的挑战。
首先，不能及时响应新业务形态快速变化。、微博、微信、直播等新媒体平台的不断涌现，促使着传统报社媒体必须快速响应不断变化的新业务形态。业务的快速上线、下线成为常态。而目前报社架构无法支撑这种快速变化。从服务器采购、环境搭建、软件部署，到最后系统上线，通常需要个月的时间。
其次，异构应用多，资源整合困难，不能满足媒体融合的要求。从十八届三中全会提出推动媒体融合发展的重大目标以来，各级报社都从不同的角度对媒体融合进行了各自的实践。媒体融合，是新媒体与传统媒体业务的融合，是不同体制与人员的融合，是内外资源的融合，是新闻创作方式、是新闻传播形式的融合。从基础架构层面，要求打破原来报社业务系统之间各自独立的现状，实现对不同厂商、不同应用的异构整合，资源统一池化，实现资源整合。
第三，生产安全要求高，业务系统众多且复杂。新闻业务是时效性要求很高的业务，承载新闻生产业务的业务系统如果出现故障，就可能延误出报，导致重大的生产事故。而要完成报社全部生产流程，又需要不同厂商的不同系统之间相互协作。涉及系统众多且复杂，就容易出现问题。因此，作为业务支撑的基础平台，必须能够全面管理并监控所有资源和系统的运行状态，一旦出现问题能够及时告警；需要平台具备高可用性，出现问题平台自动自愈，并支持虚拟机自动漂移，从而不影响上层业务系统的运行，保障生产安全。
第四，系统利用率低，运维成本高，报社业务有明显的周期性特征，出报前系统负荷大；出报后资源又闲置严重。而且，报社不同的业务系统，高峰时间不同。但在传统的烟囱式架构下，各应用系统独占各自的资源，不能相互利用空闲的硬件资源，各业务系统资源只能按自身峰值需求配置，各级系统管理各自为政，没有形成统一的资源调度策略，缺少高效管理，无法支撑精细化运营，系统维护成本高，大量资源闲置和浪费。
“超融合一体化云平台”解决方案
金融时报社超融合一体化云平台项目为报社全媒体新闻生产业务提供基础支撑和承载的环境，是报社全媒体新闻采编核心业务上云的核心组成部分。面对金融时报所面对的问题，海云捷迅提出了一套基于超融合一体机的云平台解决方案。
通过海云捷迅超融合一体机，软硬件集成交付，拆箱即用，为金融时报社快速提供层基础支撑平台。平台通过计算存储融合，软件定义技术的综合应用，可以非常容易的与报社现有架构无缝集成，使得报社能够以最小的初始成本快速实现基础设施的“云化”，让业务快速分步上云。同时，随着报社规模的发展、自身业务的增长，支持“积木堆叠式”快速弹性扩容，按需升级，从而满足报社业务快速、灵活变化的需要。

积木式建设，线性高速扩容，满足业务快速灵活变化的需要
同时，采用融合软硬件架构，资源统一调度，为媒体业务融合提供支撑。海云捷迅超融合一体机，在硬件上，采用业界一流的模块化设计的组件，根据报社使用场景，提供计算，存储，网络垂直整合的融合架构硬件平台。在软件上，通过采用开放的框架，融合计算虚拟化、存储虚拟化、网络虚拟化等技术，为上层媒体业务融合提供支撑。同时所有资源集中统一管理调配，实现基础架构资源的按需供应、弹性支撑，从而满足媒体融合环境下不同应用灵活的性能需求。

采用融合软硬件架构，资源统一调度，为媒体业务融合提供支撑
该平台拥有完善的监控告警，系统高可用性，确保生产安全。平台的监控告警功能可以为整个云计算管理平台、私有云环境提供可靠的运行保障，系统可对物理机、虚拟机、存储、数据库、中间件、常用服务等提供细粒度监控支持实时监控，报社也可结合自身全媒体采编系统的关键特性，自定义监控项和告警阈值，设置以短信或邮件等多种告警形式，充分保证整个云计算管理平台的可靠性。
同时整个平台通过高可用性功能实时监控各主机状态，一旦发生异常，则自动切换到云端备机上，由备机继续提供服务，自动完成虚拟机的漂移，保证上层采编业务服务不中断，最大限度保障生产安全。

完善的监控告警，系统高可用性，确保生产安全
改变，创造新价值
海云捷迅提供的超融合一体化云平台项目方案，从金融时报本身存在的问题出发，解决了金融时报存在的问题，也为后续其他业务系统的陆续逐步上云打下坚实的基础。同时也为以后，在如何更加深入的进行新闻业务融合和创新等方面进行了积极的探索。
就目前而言，该方案简化了生产流程，提高了资源应用率，在未来金融时报如需增加新业务，只需向系统提交申请，系统能够妙级提供资源，帮助快速灵活上线。通过云平台的部署，打破原来各业务系统资源之间各自独立的现状，借助统一、弹性的资源池架构，实现不同应用在不同时间、不同访问压力情况下的资源自动调配，提高了系统资源的利用效率。
与此同时，超融合一体机的实时监控及统一管理功能，保证了平台高效、可靠的运行。一旦发生异常，自动切换备机，从而保证业务服务不中断，同时，超融合一体机实现应用集中更新、统一发布；将应用的升级、变更、维护等工作交由后台统一管理和运行。
海云捷迅作为国内首批云服务企业，在云计算领域，为报业、教育、金融、电力、医疗等行业提供专业服务。海云捷迅针对每个行业开发出有针对性的整体云安全解决方案，帮助客户维护系统安全，提升业务效率，解除用户在云化之路上的后顾之忧。在以后，海云捷迅将继续为企业客户竭诚服务，针对不同客户，提供高效可靠的方案，助力各行业云化落地。概述
应用日志的收集，在未出现前，常用做法是将日志写到主机的某个文件，当需要查看日志时先登录到主机然后去查看相关的日志文件，主机上的日志只要不特意删除会一直存在；随着和容器编排技术的出现，容器的销毁和重新创建被看成是一种常态，如果用原来的方式将应用日志写到容器的文件系统里，那么当容器销毁时日志就会丢失，这种情况下，一种有效的解决方法是引入集中式的日志管理系统，将容器的日志通过发送给日志系统进行统一存储。
目前主流的分布式日志系统有，，，等，本文利用腾讯云容器服务搭建系统收集的访问日志 ，搭建过程中共搭建如下个服务，每个服务的功能如下：

服务：该服务提供日志集中存储和查询

服务：以的形式提供日志的可视化展现和查询界面

登录鉴权服务：如果直接放到公网上，因为本身没有鉴权机制，如果被端口扫描工具扫出来，很容易出现他人查看操作日志的行为，为避免该情况，在前面加个服务，利用的认证来做鉴权。

应用服务：创建该服务的目的是为了验证是否可以将应用日志采集到里。该服务用的访问日志做日志源，浏览器每访问一次服务，就会生成一条日志，和该服务在一起的容器会将新产生的日志发到里。


在开始搭建日志系统之前，了解容器日志的输出方式和的相关配置是非常必要的，因此下文先简单介绍这两个方面的内容，然后再进行具体的搭建步骤说明，最后对搭建过程中碰到的问题进行总结。
下面的搭建方法采用的方式是一个应用容器绑定一个采集日志容器的做法，如果一台主机上有很多服务的日志需要采集，建议先提前规划好日志目录，用一台主机放一个日志采集容器的方法。
容器日志输出方式
容器日志常见输出形式主要有以下两种：

标准输出，当 的 使用默认设置时，用  命令看到的日志输出采用的就是这种方式。如果要收集标准输出的日志，常用方式是设置 的 ，目前 支持的  如下表所示，但是目前的 定义中还不包括 的字段，一种解决方式是修改 的 默认配置。




日志驱动名称
描述





不输出任何内容



日志以的格式保存成文件，这是默认的日志输出驱动



将日志输出到



将日志输出到



将日志输出到支持   格式的日志采集系统如和



将日志输出到



将日志输出到  



将日志输出到



将日志输出到的事件系统，这个驱动只有对下的生效



将日志输出到的日志系统中




日志文件输出，像、，等应用都是将日志写到文件。这种形式的日志输出常用的收集方式有两种：

每个应用容器单独再配一个日志采集容器如或等，在中应用容器和日志采集容器可以做成一个，然后他们之间共享一个。这种方式的缺点是应用容器越多，日志采集容器也会变多，会增加系统的资源消耗。
在主机上放一个日志采集容器，将某个主机目录映射到容器内，同时将该主机目录映射到每个应用容器的日志输出目录，这种方式的优点是每台主机上只有一个日志采集容器，缺点是要对每个应用的日志输出目录做本地磁盘映射，同时要提前规划好各个应用的日志文件名称和目录，避免出现不同应用生成相同的日志文件或日志目录。



简介和配置简介
是由、和三个项目共同组成的日志系统，其中：

简称是日志搜索引擎语言开发提供日志存储、聚合、搜索和查询等功能支持插件
是日志采集模块语言开发支持的日志输入源包括、、、等，日志输出端支持、、和等，有丰富的插件。
是日志分析和展现模块可以通过配置和对接，支持自定义界面展示。

在系统中采集端如果用，因为是写的，对系统资源占用相对较多，因此生态中出现了轻量级的采集端家族，目前家族的成员如下：

：采集文件中的日志到。
：采集主机的、内存、文件系统、磁盘和网络等信息到
：对网络包进行采集，将采集数据发到
：采集系统的 到
：对服务进行健康检查，将检查结果发给

配置
的配置文件采用文件格式



配置项名称
含义





集群名称



节点名称



是否允许该节点成为



是否允许该节点成为数据节点



存储日志的目录



存储数据的目录



的主机地址



集群中主机之间相互发现时使用该字段，指定集群内的所有主机，格式如  


__
成为的时候，集群中至少需要多少个节点



配置
的配置文件包含三部分：、部分，指定数据源，可以同时指定多个数据源，可以使，标准输出，等
、部分，数据处理部分，可以对输入的数据做格式解析，提取新字段等。
、部分 指定数据输出到哪里，可以同时指定多个输出源，可以是标准输出，，和等。
配置
的配置文件也是采用格式



配置项名称
含义





的服务端口，默认为



指定的



是否启用



证书



日志输出的地址



控制是否输出日志



使用腾讯云容器服务搭建
下面的搭建步骤基于腾讯云容器服务来搭建，容器服务集群中包括两台机器，配置是核的系统。搭建步骤如下：

创建 服务，该服务包含一个容器
创建服务，该服务包含一个容器，和 之间以服务的方式连接。
搭建的鉴权服务，该服务使用容器，放在前面，避免在公网上被随机登录使用。
创建应用服务，该服务包括两个容器，一个还有一个是，和容器之间共享数据目录采集的访问日志文件并将新生成的日志发给。

搭建过程中使用的镜像是上的的、和的镜像，版本为
在搭建之前，参考的安装文档，需要对容器主机做相关设置：

使用命令确保主机至少有的可用内存，因为 的镜像中的配置参数是
在每台容器主机上执行  __=。默认使用     目录来存储索引。 默认操作系统对计数的限制太低，可能引发内存不足的异常。

创建服务
启动的 命令如下：
          = __=
对应腾讯容器服务控制台创建的参数配置如下：



配置项名称
配置值




服务名称



限制
核


内存限制



镜像



镜像版本



实例个数



运行命令



运行参数
= __=


网络参数
网络方式选仅在集群内访问协议选容器端口服务端口


数据卷
选择本地磁盘，选择一个主机目录，取名为


挂载点
选择数据卷，映射到容器目录为



另外为了避免容器还在运行状态但是进程异常导致服务不可用，可以考虑给服务配置健康检查参数。
创建服务
启动的  命令如下：
         
对应腾讯容器服务控制台创建该服务的参数如下：



配置项名称
配置值




服务名称



核数
核


内存



实例个数



镜像



镜像版本



网络方式
提供集群内访问方式，不在公网上直接暴露的端口



创建认证服务
第一步在主机上用生成包含用户名和密码的文件，具体的使用方式如下：
  
在两台主机上将生成的帐号密码文件放到该目录放到目录下
第二步在两台主机的目录下创建的配置文件内容如下：
  
_  

_   
        


 {
    _  
}

 {
           
    _  

    _    _  _ _  
                       __ _ 
                      __ ___

    _    

            
    _     

    _  

      
     {
           
    _  

     
    _    

      {
        _  
        ___ 
         
        _   
        __  _

    }
  }
}
第三步，创建认证服务，配置参数如下：



配置项名称
配置值




服务名称



镜像



数据卷
使用本地硬盘，名称用，对应的主机目录 



数据卷
使用本地磁盘，名称用，对应的主机目录


网络方式
提供公网访问，容器端口用，服务端口用


挂载点
使用 ，容器内目录，放的配置文件


挂载点
使用 ，容器内目录，放 的用户密码文件



第四步在外网访问服务，输入正确的用户名和密码后，可以看到的界面，表示这一步配置成功。

输入正确的用户名和密码后，如果可以看到的如下界面，表示搭建成功：
创建应用服务
第一步，先在两台主机上放好的配置文件，配置文件的内容如下，配置文件放到主机的需要映射到容器的目录为。该配置文件同时抓取和两个日志文件到。
    {
      {
      = 
      = __
     _ = 
    }
      {
      = 
      = __
     _ = 
    }
   }
    {
      {  =  }
   }
第二步，创建两个数据卷



数据卷名称
对应的本机目录
用途





不填主机上临时分配
在该目录下产生日志，读取该目录的日志




存放的启动配置文件



第三步， 创建容器



配置项名称
配置值




实例个数



镜像



镜像版本



核数



内存



运行命令



运行参数
 注意在界面上填的时候， 和要放两行


挂载点
挂载卷 ，容器目录，存放生成的日志文件


挂载点
挂载卷，容器目录，存放的配置文件



第四步， 创建容器



配置项名称
配置值




实例个数



镜像



内存



核数



挂载点
挂载卷 ，容器目录，存放生成的日志文件



第五步，将的端口映射到外部端口
第六步：等服务创建完成，通过网页访问服务，检查界面上是否可以看到的访问日志，正常的访问日志如下：

搭建过程问题总结
在使用腾讯云容器服务搭建系统的过程中碰到如下问题：

容器主机上用 运行没有跑起来，原因是对内存要求较高，申请的主机如果只有的内存，容器会自动退出原因为配置的都是的内存，配置文件在目录，建议使用以上的主机；另外需要对主机执行  __=。运行之前需要做的系统配置在

对于 命令可以正常运行的 ，相同的参数使用容器服务运行失败。原因是容器服务默认做了内存限制，大小为，因为镜像中的默认配置是，先通过看可用内存是否有，如果没有的的话就用    _ 释放一部分内存出来，如果该参数设置为刚刚好还是会报错，建议用。

用默认设置启动不了，原因是镜像中配置的 选项最小堆栈是，最大为；通过将的内存调到。

数据采集端如果采集的是主机某个目录的日志，碰上这种情况需要容器服务支持的功能，指定对应的采集在某些的主机上运行，还有如果可以支持自定义配置文件的定义和下发，让容器可以引用到下发的配置文件，就不用预先在所有的主机上预先放置配置文件了。这两个需求点待容器服务推出和配置管理功能后就能很好地解决。

如果需要重新搭建一套环境，通过目前界面上的操作比较繁琐，希望能够支持从已经部署完的服务中导出配置文件，支持从文件导入创建服务。这个需求点，目前容器服务团队已经在做应用模版的开发工作，推出应用模版后可以解决该问题。

本文档的部署方式只用一个容器，当容器所在的主机异常时，如果在另外一台机器上启动了，原先的数据就看不到了，针对这种情况，就需要容器服务支持网络存储如 等。商业转载请联系腾讯获得授权，非商业转载请注明出处。原文链接：

热点来的太快就像龙卷风，明星的八卦总能作为事件引发热点。
月日，鹿晗与关晓彤恋情公布，瞬间上了热搜，粉丝炸了，微博的服务器也跟着瘫痪了。
微博瘫痪，让一位微博工程师在结婚的当口放下酒杯，开始扩容服务器，真是哭笑不得。更有网友吐槽，鹿晗其实是个老黑客，让众码农汗颜。
虽然微博这次瘫痪防不胜防，毕竟明星公布恋情如何预警？然而服务器准备不足也是一点。看看这条微博：顶级流量，可怕的传播层级，如下图所示
聊完八卦，回归主题：服务器压力。所以你家的服务器还好么？虽不是所有产品都能像微博拥有亿万量级，但在产品预期范围内出现问题，那即便再精美的产品也无法留住用户的心。
一、先谈谈服务器相关的性能指标，有很多，但不可能全看，那么有哪些核心呢？
、响应时间
是指所有用户的响应时间由小到大进行排序，第的响应时间，是用来评估系统容量的重要指标之一。
、性能，关注服务器的服务能力
每秒系统处理事务通过、失败以及停止的数量。通过它可以确定系统在任何给定时刻的时间事务负载。
、支持的最大在线人数
指同时登录站点的最大人数或者服务器同时接收下载的最大数量。
、服务器自身压测过程总、内存等的变化情况
利用率是指：执行非系统空闲进程的时间总的执行时间；内存占用率指的是此进程所开销的内存。
、事务成功率
事务成功率=成功处理的事务所有事务，是检测服务器处理事务成功几率的重要指标。
二、市面上有哪些服务器压测方法
为了能够帮助用户更快捷的获得服务器的核心数据，市场产生了诸多各式各样的压测方法，但也存在各式各样的问题：
、现网数据预估
根据压力测试过程中的部分数据，对未来大量用户访问的情况机型预估。
存在问题：只适合简单的服务器拟合，复杂服务器数据就不太准确。
、真人压测
通过邀请一定数量的真实用户来玩游戏，从而对服务器达到一个测试效果。
存在问题：暴露出的性能问题有限，封测人数通常还是太少，虽然有几百或者几千用户在玩，但是并发并不够，不足以暴露服务端性能问题；另外不适合调优，真人无法完全重复相同行为，服务器就难以进行回归调优。
、接口测试
选择一些具有代表性的功能，通过以小见大的方式，来评估整套服务器性能。
存在问题：无法遍历整个服务器的接口，难以避免一些微小的问题。
、录制回放
通过抓取数据包的方式，来获取游戏时的协议，再把这些捕获的协议重新发送给服务端，通过工具放大协议量级达到性能测试的目的。
存在问题：面对复杂的协议交互，单纯的放大数据包，无法产生足够压力。
、机器人模拟
 通过高还原真实玩家的用户行为，模拟高并发场景，从而得到类似很多人同时游戏的测试效果。
这些方法各有优劣，腾讯内部普遍使用“机器人模拟”的方法进行压测，而“机器人模拟”的压测方法需要充足的测试时间和很大的人力投入，为此腾讯制定了一个较为通用的测试流程，用以提升压测效率。
三、腾讯内部服务器性能的测试流程介绍
根据腾讯内部游戏和产品的使用需求，腾讯团队首先针对与协议的页面，梳理了一个通用的压测流程。
、 确定压测场景，比如登录，获取信息列表等
测试人员第一步要做的就是测试方案的确认，主要就是提前模拟实际业务中涉及的场景以及场景中用户的使用行为，通常需要确认这样几点：
 确认用户的登录状态，用户的登录态是否会不断变化
 用户登录后的访问路径之间的上下文关系
 访问路径之间的参数传递关系
、 测试人员编写测试用例
编写测试用例就是将上述模拟场景具体化的过程，包括确认压测的人数，人数递增逻辑，具体需要压的接口，接口之间的参数传递等。
、 启动机器人进行测试，渐进增加机器人数量
在确认了测试方案后，这一步就是执行的过程，根据测试方案中预估的压力人数，渐进的增加压力的人数。
、 记录分析数据及事务处理情况，查看服务器负载的变化以及服务器的当前承载能力。
上一步提到了要渐进增加机器人，那么为什么要渐进增加机器人？因为在服务器并发增加的过程中需要不断监控上文服务器的核心数据，不断挑战服务器处理能力的极限，避免上来就使用一个过高的并发数直接超过了服务器处理能力的极限，从而无法起到性能优化的目的。
一般来说，在机器人增加的过程中，的突然跑满以及响应时间瞬间变长，都可能是服务器产生了瓶颈。因此压测人员需要实时监控压测上升过程中的服务器情况变化，从而定位问题所在。
、 调整配置，迭代测试，预估服务器的承载能力以及可能存在的性能瓶颈
在发现基本的测试问题后，测试人员需要通过不断的调试来定位问题，然后重新发起压测，知道实现最终的测试目的。
根据这个测试流程，腾讯内部也总结了一些压测产品所需要具备的特点。
    简单易上手
产品的业务场景是多变的，但是好的压测产品应该让这个场景配置过程变得简单易用，用户在简单输入需要压测的即可进行各个接口的测试，大部分测试配置建议提供一个默认值，用户对功能更加了解之后可以自由配置这些参数。
    进阶功能完善
除了简单易用之外，也要给用户提供一些进阶的功能，在简单输入的基础上，可以支持用户自定义变量，从文件读取变量，甚至从其他的返回值获取变量的值，可以比较真实模拟真实场景，避免请求变量单一。
    提供分布式压力机进行压测
由于单机的局限性，压测产品可以使用分布式压测的框架，根据用户配置的机器人数量动态分配多个压测机，极大提升压力上限。
    详细的测试数据统计
压测大师会记录测试过程中的多项数据，包括在线人数变化、变化、响应时间、收发包流量、服务器内存状态、压力机硬件负载、测试结果统计等，可以快速定位服务器的容量以及瓶颈。
基于这些需求，腾讯团队开发了专注服务器压测的产品“压测大师”，简化了压测配置过程，用户可以在线上部署，线上调试，线上查看报告，帮助用户成为最高效的“压测大师”。

 压测大师旨在降低开发者在服务器性能测试方面的门槛，迅速发现服务器端的性能瓶颈，进行针对性的性能调优，降低服务器采购和维护成本，提高用户留存和转化率。目前主要优势如下：
Ø  一分钟发起测试，无需编写脚本
Ø  无需配置压力机，随开随用，轻松发起十万压力
Ø  支持、等协议，覆盖，，，游戏等主流场景
Ø  实时查看测试报告，多维度报告对比，迅速定位性能瓶
目前压测大师已经正式对外开放，点击链接：  即可使用。
如果对使用当中有任何疑问，欢迎联系腾讯企业：有一种日志，叫做慢查询日志，主要就是用来记录一些耗时的查询操作。通过这个日志我们就可以分析出哪些的操作是影响性能的，我们需要对其进行一些优化措施。
查看开启状态

上面的截图是我在  下安装的  版本，我们可以发现，这个版本是开启了慢查询的。我在  下采用  的方式安装的  默认没有开启慢查询日志。不管默认有没有给我们开启，我们是需要了解慢查询日志是如何开启的，开启的方式也非常简单。找到  的配置文件， 下是 ， 下的是 。进行如下配置就可以了。
=


___=


__=
第一行是指定开启慢查询日志
第二行是指定慢查询日志的路径
第三行是指定查询时间大于多少的才进行记录，但是是毫秒，也就是操作大于  的操作都会被记录。
配置完毕之后要重启  生效。
下面来看看慢查询日志的内容
\ \\  \\   
    
     
 
 
      
_  _  _  _   
 =
        
 
      
_  _  _  _   =
        
 
      
_  _  _  _   =
        
 
      
_  _  _  _   =
        
我们可以看到在  日，有多个慢查询产生。单独抽取一组，如下
 
      
_  _  _  _   
 =
        
_ 表示的是耗时时间
下面是一些操作，这的主要操作就是一个 
这就是慢查询日志。原文【  ——    】

推广你的项目
当你建立一个项目之后，没有说你一定要去推广他，即使是这个项目并不是很流行，仍然可以找到很多理由让你在这个项目上花时间。但是如果你希望别人能发现并且使用你的项目，那么这个时候您就需要把你辛苦工作的成果告知世人！
找出你的卖点
在你开始推广你的项目之前，你应该能够解释你的项目是做什么的，为什么大家需要他
是什么让你的项目变得不同或者有趣，在自己心中问这些问题会让你更容易说服别人。
牢记一件事情，别人之所以使用你的项目，甚至是为你的项目做贡献，是因为你的项目解决了他们的问题。所以你要找出他们需要什么，然后把他当成你项目的卖点或者说价值所在。
举个例子，用代码实例来清晰的阐述为什么他的项目是有用的。

如果你想深入了解如何挖掘项目的“卖点”，看一下的“  ”，练习如何建立用户的形象。
帮助人们发现然后关注你的项目

你最好有一个唯一的“主页”链接用来推广，引导人们关注你的项目。你不需要找一个炫酷的模板或者域名，但是你的项目确实需要一个入口。
—      “       ”

通过引导他们到一个唯一的地址来帮助人们发现和记住你的项目。
要有一个推广的主阵地。一个账号，链接，或者频道是引导人们查看你们项目的一个简单的方式。这些方式也给你日益增长的社区一个讨论的好地方。
如果你目前还不想给你的项目搞这么多乱七八糟的东西，而且还要在有机会的时候推广你的账户和账户。举个例子，如果你某一个讨论会或者活动上发言要保证在你的简历或者幻灯片上包含这些信息。只有这样人们才会知道怎么找到你或者关注你的工作。

我之前犯过的一个错误就是没有给项目开一个账户。是一个让人们知晓项目进展的好渠道，也可以让人们持续的接触到你的项目。
—  “      ”

考虑给你的项目做一个网站 。一个网站可以让你的项目更加友好，而且更加容易浏览，更重要的是附上清晰的文档和教程。这也是象征着你的项目还是活跃的，这会让你的用户使用你项目的时候感觉更放心。可以用一些例子告诉人们如何使用的项目。
 的协作者说，我们给做的网站可以说是“在早期开发的时候做的最好的一件事情了”。
如果你的项目是托管在上的，你可以用 简单的创建一个网站。    是一些优秀的内容详尽的网站的例子

现在你的项目有了“卖点”，和让人们很容易发现你项目的渠道，接下来我们谈谈如何和你的用户交流吧！
到你项目的受众在的地方去线上
网上拓展是分享和快速宣传项目的一个好方法。借助一些网上的渠道，你有可能找到一大批受众。
利用好已有的线上社区和平台去找你的受众。如果你的开源项目是一个软件项目，你可能会在     或者。找到你觉得人们会最有可能从你的项目中受益或者对你项目感兴趣的渠道。

每个程序都会有那么一些方法只有一部分人才会用到，所以不要想着去打扰每一个人，把你的力气用在可能会从你项目受益的社区就好。
—  “    ”

来看看下面的一些方法吧，也许推广你的项目的时候用得着。

快找找有没有相关的开源项目和社区。有时候，你不需要直接的推广你的项目。如果你的项目对使用的数据科学家来说是无可挑剔的，那么就去找数据科学的社区。等他们知道你的项目之后，很自然的就会谈论然后分享你的工作成果。

如果你项目尝试解决某些问题，那么找到会遇到这些问题的人。想象你的项目受众会在哪些论坛，然后搜索这些论坛，回答他们的问题，然后找一个合适的实际，向他们建议使用你的项目来作为一种解决方案。

寻求反馈。给一个可能会用到你项目的人介绍你自己和你做的工作。对哪些人会从你的项目受益要很明确。尝试完善一下下面这句话：“我觉得我的项目能够帮助，那些尝试做的人”。听取和回复别人的反馈，而不是简单的推广。


一般来说，在你索取什么回报之前先把精力放在帮助别人上。因为在网上推广一个项目对任何人都是一个不难的事情，所以有很多人和坐着一样的事。告诉人们你是谁，而不是你想要什么，这样才能从众多推广者中脱颖而出。
如果没有人对你的推广感兴趣，不要灰心！大部分的项目的开展都是一个要花费数月和数年的反复过程。如果你第一次没收到反应，尝试换一种策略，或者找办法给别人的项目做做贡献。这都是些需要时间和奉献精神的事情。
到你项目受众在的地方去线下

线下活动是一个推广项目流行的方式。这是一个接触某个忠实听众和建立深层次的联系的好方式，特别是如果你对到场的开发者感兴趣的话。
如果你还是个公中演讲的新手，从寻找一个和你项目使用的语言或者生态系统相关的当地的聚会开始吧。

我去的时候非常紧张。我要发表一个演讲，在那儿我就认识几个人，还在那儿呆了整个周。但是其实我不应该焦虑的。真是太他妈吊了！每个人都是超级友好外向，以至于我没有找到时间和人们讲话。
—  “        ”

如果你从来没在公共场合讲过话，感觉紧张那就太正常啦！记住你的听众就在哪儿，因为他们都是真正的想听你介绍你的项目。
当你在写你的演讲稿的时候，把重点放在你的听众会感兴趣而且能获取价值的事情上。保证你的语言要友好和和蔼可亲。笑一笑，深呼吸，幽默一点儿。

当你开始写你的演讲稿的时候，不管你的主题是什么，如果你能把你的演讲当成是给别人讲故事的话，效果会更更好。
—   “        ”

等你准备好了，考虑一下在某个会议上发言的时候推广你的项目研讨会可以帮助你接触更多人，有时候是来自全世界各地的人。

我非常认真的给的人写了一封信，然后求他们给我一点时间让我上展示我的项目。同时我又非常担心，这个项目我做了六个月，要是大家不认可怎么办。那时候我就一直在想，我的天，我他妈在这里是干吗？
—  “  ” 

建立声望
除了上面提到的策略之外，邀请人们分享和支持你的项目的最好办法就是分享和支持他们的项目。
帮助新手，分享资源，给别人的项目认真的做贡献会帮助你建立起良好的声誉。然后他们就很有可能知道你的项目而且更有可能关注和分享你在做的事情。
有时候，这些关系还会进一步发展成更广阔的生态系统中的官方合作伙伴意思即使你有可能成为那些有名社区的成员

之所以是现在最流行的第三方库的唯一原因就是大家都需要它。
—  “       ”

种一棵树最好的时候是十年前，其次是现在。所以啥时候开始建立你的声望都不晚。即使是你早就已经建立了自己的项目，还是要继续找办法帮助别人。建立用户群没有一蹴而就的方法。获取别人的新人和尊重需要时间，同样，建立声望的过程也永远不会停止。

公开第一个版本的时候实在年初。我也就是用一些常规的方法来推广：发，写博客告诉别人可以用它来做什么，在各种各样的聚会上我都提到过它。当年他已经广为人知的时候。我才开始做关于它的演讲。
—  “ ”

一如既往的坚持！
有时候，让人么注意你的开源项目会话费很多事件。但是关系！现在很多流行的项目都是花了很多年才有今天的活跃度。把重点放在建立声望上而不是企图一夜成名。耐心一点，一如既往的和那些可能会从中受益的人们分享你的项目。这是十分钟成为   系列的第二篇文章，让大家可以无门槛参与大型开源项目，感谢社区为  带来的贡献，也希望参与   能为你的生活带来更多有意义的时刻。
为了加速表达式计算速度，最近我们对表达式的计算框架进行了重构，这篇教程为大家分享如何利用新的计算框架为  重写或新增  函数。对于部分背景知识请参考这篇文章，本文将首先介绍利用新的表达式计算框架重构  函数实现的流程，然后以一个函数作为示例进行详细说明，最后介绍重构前后表达式计算框架的区别。
重构  函数整体流程

在  源码  目录下选择任一感兴趣的函数，假设函数名为 

重写  方法该方法参照  规则，根据  函数的参数类型推导函数的返回值类型根据参数的个数、类型、以及函数的返回值类型生成不同的函数签名，关于函数签名的详细介绍见文末附录

实现该  函数对应的所有函数签名的  方法，此处  表示该函数签名的返回值类型

添加测试：在  目录下，完善已有的  方法中关于该函数实现的测试在  目录下，添加  层面的测试

运行  ，确保所有的   都能跑过


示例
这里以重写  函数的  为例，进行详细说明
首先看 _：
实现  方法
该方法主要完成两方面工作：

参照  规则推导  的返回值类型
根据  函数的参数个数、类型及返回值类型生成函数签名。由于  的参数个数、类型及返回值类型只存在确定的一种情况，因此此处没有定义新的函数签名类型，而是修改已有的 ，使其组合了 表示该函数签名返回值类型为 

   {
    
}

         {
     参照  规则，对  函数返回值类型进行推导
     = 
     = 
    

     根据参数个数、类型及返回值类型生成对应的函数签名，注意此处与重构前不同，使用的是  方法，而非  方法
      的函数声明中， 表示函数的参数， 表示函数的返回值类型， 表示该函数签名中所有参数对应的正确类型
     因为  的参数个数为，参数类型为 ，返回值类型为 ，因此此处传入  表示函数的返回值类型，传入  用来标识参数的正确类型。对于多个参数的函数，调用  时，需要传入所有参数的正确类型
      =    
      =  {
          
    }
     = {{}}
      
}

 实现  方法
        {
     对于函数签名 ，其参数类型已确定为  类型，因此直接调用  方法计算参数
       =  
      ||  =  {
           
    }
       
}

然后看 __，对已有的  方法进行完善：
     {
       监测  泄漏的工具，可以直接照搬
        的测试用例对  方法实现进行测试
     此处注意，除了正常  之外，最好能添加一些异常的 ，如输入值为 ，或者是多种类型的参数
     =  {
             {}
         
            
           
    }{
        {   }
        {你好   }
        {   }
        
    }
     _  =   {
          =   {}{}
         
         以下对  函数的返回值类型进行测试
         = 
          
          
          
          
          
         以下对  函数的计算结果进行测试
          = 
          {
             
        }  {
             
              {
                  
            }  {
                  
            }
        }
    }
     以下测试函数是否是具有确定性
      = {} 
     
     
}

最后看 _，对  的实现进行  层面的测试：
 关于   函数的测试可以在这个方法中添加
     {
      {
        
        
    }
     =  
     

      
     此处的测试最好也能覆盖多种不同的情况
        
                 
    `         `
     =          
          
}

重构前的表达式计算框架
 通过  接口在  文件中定义对表达式进行抽象，并定义  方法对表达式进行计算：
  {
    
       
    
}

实现  接口的表达式包括：

 ：标量函数表达式
：列表达式
：常量表达式

下面以一个例子说明重构前的表达式计算框架。
例如：
   
     
     
     


           “” 

对于上述  语句  条件中的表达式：在编译阶段， 将构建出如下图所示的表达式树

在执行阶段，调用根节点的  方法，通过后续遍历表达式树对表达式进行计算。
对于表达式 ‘’，计算时需要考虑两个参数的类型，并根据一定的规则，将两个参数的值转化为所需的数据类型后进行计算。上图表达式树中的 ‘’，其参数类型分别为  和 ，根据  的计算规则，此时需要使用浮点类型的计算规则对两个参数进行比较，因此需要将参数 “” 转化为  类型，而后再进行计算。
同样的，对于上图表达式树中的表达式 ，计算前需要将其参数分别转化为  类型；对于表达式 ‘’，计算前需要将其参数分别转化为  类型。
因此，在重构前的表达式计算框架中，对于参与运算的每一组数据，计算时都需要大量的判断分支重复地对参数的数据类型进行判断，若参数类型不符合表达式的运算规则，则需要将其转换为对应的数据类型。
此外，由  方法定义可知，在运算过程中，需要通过  结构不断地对中间结果进行包装和解包，由此也会带来一定的时间和空间开销。
为了解决这两点问题，我们对表达式计算框架进行重构。
重构后的表达式计算框架重构后的表达式计算框架，一方面，在编译阶段利用已有的表达式类型信息，生成参数类型“符合运算规则”的表达式，从而保证在运算阶段中无需再对类型增加分支判断；另一方面，运算过程中只涉及原始类型数据，从而避免  带来的时间和空间开销。
继续以上文提到的查询为例，在编译阶段，生成的表达式树如下图所示，对于不符合函数参数类型的表达式，为其加上一层  函数进行类型转换；

这样，在执行阶段，对于每一个 ，可以保证其所有的参数类型一定是符合该表达式运算规则的数据类型，无需在执行过程中再对参数类型进行检查和转换。
附录

对于一个  函数，由于其参数个数、类型以及返回值类型的不同，可能会生成多个函数签名分别用来处理不同的情况。对于大多数  函数，其每个参数类型及返回值类型均确定，此时只需要生成一个函数签名。
对于较为复杂的返回值类型推导规则，可以参考  函数的实现和测试。可以利用  工具运行查询语句     观察  的  函数在传入不同参数时的返回值数据类型。
在  表达式的运算过程中，只涉及  种运算类型目前正在实现对  类型的支持，分别是

 

 




 通过  方法可以将一个表达式转换为对应的类型。

对于一个函数签名，其返回值类型已经确定，所以定义时需要组合与该类型对应的 ，并实现  方法。 不超过上述  种类型的范围


 我是  的分割线 
回顾三月启动的《十分钟成为   系列 | 添加內建函数》活动，在短短的时间内，我们收到了来自社区贡献的超过  条新建內建函数，这之中有很多是来自大型互联网公司的资深数据库工程师，也不乏在学校或是刚毕业在刻苦钻研分布式系统和分布式数据库的学生。
   将大家聚集起来，我们互相分享、讨论，一起成长。
感谢你的参与和贡献，在开源的道路上我们将义无反顾地走下去，和你一起。
成为   赠送限量版马克杯的活动还在继续中，任何一个新加入集体的小伙伴都将收到我们充满了诚意的礼物，很荣幸能够认识你，也很高兴能和你一起坚定地走得更远。
成为   获赠限量版马克杯，马克杯获取流程如下：

提交 
提交之后，请耐心等待维护者进行 。目前一般在一到两个工作日内都会进行 ，如果当前的  堆积数量较多可能回复会比较慢。代码提交后  会执行我们内部的测试，你需要保证所有的单元测试是可以通过的。期间可能有其它的提交会与当前  冲突，这时需要修复冲突。维护者在  过程中可能会提出一些修改意见。修改完成之后如果  认为没问题了，你会收到     的回复。当收到两个及以上的  后，该  将会被合并。
合并  后自动成为 ，会收到来自   的感谢邮件，请查收邮件并填写领取表单，表单填写地址：

后台  核查   及资料信息，确认无误后随即便快递寄出属于你的限量版马克杯

期待你分享自己参与开源项目的感想和经验，   将和你一起分享开源的力量

了解更多关于  的资料请登陆我们的官方网站：
加入    请添加我们的  微信，微信号：
 作者：徐怀宇，  。 徐鹏

本篇文章主要介绍  是如何使用分布式一致性验证框架  进行一致性验证的。
什么是 
 是由   采用函数式编程语言  编写的验证分布式系统一致性的测试框架，作者使用它对许多著名的分布式系统 进行了“攻击”一致性验证，并且帮助其中的部分系统找到了 。这里一系列的博客展示了作者的验证过程以及对于一致性验证的许多思考。
 如何工作
 验证系统由  个节点组成，一个控制节点 ，五个被控制节点默认为     ，控制节点将所有指令发送到某些或全部被控制节点，这些指令包括底层的  命令到上层的  语句等等。 提供了几个核心  用于验证分布式系统：


   封装了所验证的分布式系统下载、部署、启动和关闭命令，核心函数由  和  组成，在  的  测试中， 负责下载  并且依次启动  、 和 ； 负责关闭整个  系统并且删除日志。


   封装了每一个测试所需要提供的客户，每个  提供两个接口： 和 ， 负责对  进行连接，而  则包含了测试中  对  调用的  语句，具体语句依测试而定。


   用于对测试生成的历史进行验证，判断测试结果是否符合预期，历史的格式如下图所示：
 


   用于对系统引入故障，比如常见的网络分区、网络延时、节点宕机，在  的测试中，有以下几种 ：
  ：网络分区
  ：每个节点都看到不同的 
  ：对某些节点进行 
  ：对某些节点进行 
  下图展示了   引入测试中后某些语句执行时出现了  的错误。
 


   是  中的事件发生器，它将  和  的操作交织在一起，为整个测试生成具体的执行语句。


 中的  测试
 中的  测试有  个，分别是 、 和  测试。
 
银行测试用于验证快照隔离。这个测试模拟了一个银行系统中的各种转账，每个银行系统的初始可以是这样的：
 
 
 
 
 
 分别代表账户名称，而  代表账户余额。测试会随机生成转账信息：
  
代表将金额  从账户  转入账户  这个操作。与此同时，测试会随机读取所有账户的存款信息，例如某一时刻账户的存款信息可能是这样的：
    
下面是测试进行中的某次截图：

在快照隔离下，所有的转账都必须保证每一时刻所有账户的总金额是相同的。 在即使引入了各种  的情况下仍旧顺利地通过了测试。
 
这个测试从不同节点并发的将不同的数插入一张表中，并且进行一次最终的表读取操作，用于验证所有返回成功的插入值一定会出现在表中，然后所有返回失败的插入值一定不在表中，同时，因为  的引入，对于那些返回  的插入值，它们可能出现也可能不会出现在表中，这属于正常情况。
下面是测试进行中的某次截图：

同样， 通过了测试。
 
这个测试很好理解，建一个表，然后插入一条值，然后我们把这个值看做是一个寄存器，然后在测试中并发地从各个节点对其进行 、 和  操作。

然后利用  产生的一系列操作历史如上图进行  一致性验证。这个算法是  的核心，也是  被业界所熟知的原因之一，所以花时间去深入学习了下，我会在另一篇文章具体介绍这个算法。
写在最后
每次  更新代码，我们都会内部触发  来执行 ，通过  来保证  的数据一致性。如果你对分布式测试，一致性验证感兴趣，欢迎参与开发。
 ：导语：情感情绪检测是自然语言理解的关键要素。最近，我们将原来的项目迁移到了新的集成系统上，该系统基于麻省理工学院媒体实验室推出的模型搭建而成。

情感情绪检测是自然语言理解的关键要素。最近，我们将原来的项目迁移到了新的集成系统上，该系统基于麻省理工学院媒体实验室推出的模型搭建而成。
代码已经开源了！详见： 
该模型最初的设计使用了、和，接着我们将其移植到了上。与相比，能让我们更自由地开发和测试各种定制化的神经网络模块，并使用易于阅读的风格来编写代码。在这篇文章中，我将详细说明在移植过程中出现的几个有趣的问题：

如何使用自定义激活功能定制 
对象的工作原理及其构建
如何将关注层从转换成
如何在中加载数据：和 
如何在中实现的权重初始化

首先，我们来看看的模型。它是一个相当标准而强大的人工语言处理神经网络，具有两个双层，其后是关注层和分类器：

模型
如何构建一个定制化的 模块
有一个很不错的特点： 及其协作者能够在一个拥有亿条记录的海量数据集上训练该模型。因此，预先训练的模型在此训练集中具有非常丰富的情感和情绪表征，我们可以很方便地使用这个训练过的模型。
该模型是使用针对的回归内核的默认激活函数 训练的，而是基于的库建模的，这样，可获得原生支持的加速与标准的回归激活函数：

默认的和默认的因此，我写了一个具有 回归激活函数的自定义层：
   _ _ _= _=
    
                  
    
      = 
     =  _ _   _ _

        =  

     = _
     = _
     = 
     = _

     =       
     =   

      

 _
    
         
      
    
     =     
     =   
     =   
 
这个单元必须集成在一个完整的模块中，这样才可以使用所有的功能。这个集成相关的代码很长，建议直接引用到中的相关源代码。
和中的关注层
模型的关注层是一个有趣的模块，我们可以分别在和的代码中进行比较：
 
    
               
    
     ____ _ _=
            
         
            _     
            _           
                                 
        
         ____
        _ = _
        _ = _
        _ = _

     ____
         = {}{_}  ={_}
         =________ ____

       _
          
         
                 
            _     
         
                  _  
        
         = _
        _ =   

                  
           
        _ = _
         =  _ =_
         _
             = 
         =   _

               
        _ = _  
        _ = _= =     
         = __

           
         =  _

                 
         = =

    _  
 
    
             
                 
    

     ____ _= 
         = 
        _ = 
        _ = _
         ____ 

      _
        _ = =
         _ == 

         = _=_ 
                                 ={}_
                                 =
        _ = 
         _

       =
               
              
                
           
         =  
        _ = 
         =  _ _
         =    = =

             
            
             =  
             =   
        _ =    = =
        _ =   __
         = _ =
         _
              _
         

     ___ _
         ___

     __ _
        _ = _
         _
             _ _ _ _
         _ _

     _  _=
         _ 
               _
        
 
如你所见，主要的算法大致相同，但代码中的大部分都是注释，而则需要编写几个附加函数并进行调用。
在编写和调试自定义模块和层时，是一个更快的选择；而对于快速训练和测试由标准层构建的模型时，显然更加合适。
对象的工作原理
有一个不错的掩码功能可以用来处理可变长度序列。那么在中又该如何处理这个呢？可以使用！ 文档中有关的介绍并不是很详细，所以这里会详细描述它的细节。

一个拥有个序列个令牌的典型批次
假设我们有一批可变长度的序列在应用中通常就是这样的。为了在上并行计算这样一个批次，我们希望：

尽可能多地并行处理这个序列，因为隐藏状态依赖于每个序列的前一个时间步长，以及
以正确的时间步长每个序列的结尾停止每个序列的计算。

这可以通过使用中的类来实现。我们首先通过减少长度来对序列进行排序，并将它们放到在张量中。然后对张量和序列长度列表调用__函数
 _                   
_ = __

        
_ = _       _
_ _ = _ =
_ = __ _

    
_ = ___ _ _=
对象包括：

一个对象：一个令牌的总数，每个令牌的维度，在这个简单的例子中有五个令牌序列用整数表示：，
一个_对象：每个时间步长的令牌数列表，在这个例子中为：，，，，

用__函数来构造这个对象非常的简单：

如何构造一个对象_ = 
对象有一个很不错的特性，就是我们无需对序列解包这一步操作非常慢即可直接在数据变量上执行许多操作。特别是我们可以对令牌执行任何操作即对令牌的顺序上下文不敏感。当然，我们也可以使用接受作为输入的任何一个模块 。
例如，在我们的模型中，我们可以在对对象不解包的情况下连接两个模块的输出，并在此对象上应用。我们还可以在不解包的情况下执行关注层的一些操作。
中的智能数据加载：和
在中，数据加载和批处理通常隐藏在_函数中。重申一遍，如果你想要快速地测试模型，很好用，但这也意味着我们不能完全控制模型中的重要部分。
在中，我们将使用三个类来完成这个任务：

一个类，用于保存、预处理和索引数据集
一个类，用于控制样本如何批量收集
一个类，负责将这些批次提供给模型

我们的类非常简单：
 
        
     
        _     
        _     

     ____ 
         
    
     ____ _ _
                  
          _ 
            _ = __
          _ 
            _ = __

        _ = _  =
        _ = _  =

     ____
         _

     ____ 
         _ _
我们则更有趣。
我们有几个小的数据集，用于微调情感情绪检测模型。这些数据集有着不同的长度和某些不平衡的种类，所以我们想设计这么一个批量采样器：

在预先定义的样本数中收集批次，这样我们的训练过程就可以不依赖于批次的长度
能够从不平衡的数据集中以平衡的方式进行采样。

在中，是一个可以迭代生成批次的类，的每个批处理都包含一个列表，其中包含要在中选择的样本的索引。
因此，我们可以定义一个用数据集类标签向量来初始化的对象，以构建满足我们需求的批次列表：
 
              
          
     
        _    
        _  
        _      
                  
                
            
     ____ 
                
    

     ____ _ _ _  
        _ = _
        _ = _
         = 

        

         
                    
             _ == 
             = _ == 
             = _ == 
             _   == 
            __ = _  
        
             = _

          
                   
            _ =  _ =
        
                   
            _ =  __ =
            _ =  __ =
            _ = _ _ =

                    
                
             = _
            _ = _

            _ = __
            _  
            _  

     ____
            _
           __
             =   _
             =   _ _
             _

     ____
                
 _  _    _
从到：不要忘记初始化
将代码移植到的过程中，最后需要注意的事情是对权重的初始化。
在开发速度方面的另一个强大特点是层的默认初始化。
相反，并没有初始化权重，而是由开发者自己来决定。为了在微调权重时获得一致的结果，我们将像如下代码那样复制默认的权重初始化：
 _
    
              
    
     =      _  _  
     =      _  _  
     =      _    
     = =
       
        _
       
        
       
         
结论
当我们针对一个模型比较和这两个框架时，我们可以感觉到它们有着不同的哲学和目标。
根据我的经验来看：

非常适合于快速测试在给定任务上组合标准神经网络块的各种方法；
非常适合于快速开发和测试自定义的神经网络模块，因为它有着很大的自由度和易于阅读的风格的代码。很多网站在注册界面经常要获取验证码需求。获取验证码都会出现一个验证码倒计时，一般都是秒倒计时，要是等待过了这个秒的倒计时，又可以重新发送验证码。今天就来说说用如何才能实现倒计时！有需求的伙伴们可以看看！
首先我们来看看效果图：

点击获取验证码后出现秒的重发倒计时

当倒计时结束后，出现重发的按钮，以此循环
实现的代码：
由于是项目中的页面，所以只能截取重要的部分代码，谅解：
实现发送验证码的倒计时代码
 样式你们自己美化就 ，这里就不一一展示；
代码：

设置倒计时的秒数从多少开始，然后依次递减，当倒计时为时候，按钮中的文字就变为“重发”然后重置倒计时秒数为初始的秒！倒计时不为的时候就依次递减，定义了一个定时器在循环！最近大家都在讨论苹果封杀热更新，觉得苹果手又痒痒了，为了赚钱，无所不用其极。
大家担心一堆游戏要玩不了了，甚至担心微信小程序要完蛋了，更奇葩的还有担心  也不能用了。
作为软件工程师，笔者尝试揣测一下苹果封杀热更新的初衷，以及对行业可能的影响。
我们首先从“”和“更新”这两个东东来说，业内人士请直接跳到第  段开始。
——
，即  的缩写，中文翻译为应用程序。苹果手机上的应用，属于面向用户的终端应用，属于一种计算机应用程序软件。
板砖机时代，手机里也有程序，比如俄罗斯方块，这个程序是定死的，不可改变，甚至关机之后，连自己的游戏积分也没了。这就像是小商小贩使用的计算器，功能是定死的，而且无法保存任何历史数据。
这种程序定死的设备，除了早期的板砖机、计算器、游戏机、还有 、、 播放器等等。
小霸王游戏机，想玩什么游戏，必须要买游戏卡，游戏软件是固化在游戏卡里边的。
、、，程序软件是定死的，有些能解码 ，有些能解码 ，但要解码的音视频内容则存储在碟片上。
小霸王游戏机的主机，相当于计算机硬件系统处理器、内存等；
包含有多种游戏的游戏卡，相当于计算机的软件程序，电脑上用软盘、硬盘、光盘存储，游戏机上用游戏卡存储；
包含有音视频内容的碟片，相当于需要处理的各种数据。
这里我们划分了三个角色：看得见摸得着的硬件设备、完成不同任务的软件程序、数据。
 的硬件和软件都是定死的，唯一可以更换的就是数据碟片或内存内容，除了看电影，我们不能指望  干别的。
游戏机还好，可以通过更改游戏卡玩不同的游戏，只不过，特定游戏卡里的游戏是定死的，不能改变。
——
再来说更新的问题。
相比  和游戏机，电脑的功能更强大，可以安装不同的应用程序。
在互联网普及之前，如果我们需要购买新的应用程序，就必须要通过购买对应的软盘、光盘，或者优盘。
互联网普及后，我们可以在网络上下载应用程序，比如说 。
最开始的时候， 各个版本的更新，都需要我们手动从  网站下载，然后手动安装更新。
后来，为了解决版本更新的问题，几乎所有软件都提供了自动下载、自动更新的功能。
刚开始的时候，应用软件将自己整体更新，后来，随着应用软件越来越复杂，体量越来越大，逐渐采取“部分更新”的策略，即：将自己的一部分功能更新。
——
回头来看苹果手机上的软件更新。
苹果商店有个设置，可以自动更新应用程序，比如微信有了新版本，苹果手机会在晚上的时候帮我们自动下载更新到最新版本的微信。
这个更新动作，是由苹果手机做出的，而不是微信做出的。
尽管最近几年的苹果系统都是默认自动更新，但是，依然有不少用户停用自动更新，选择手动更新应用软件。更何况，整个应用软件的更新，耗费流量比较大，时间也比较长，尤其是动辄几百兆的手机游戏。
问题来了：微信要做一个新的广告，某个游戏要更新一个游戏场景，如果采用更新整个应用程序的方案，代价太高。
于是，软件供应商微信或游戏开始采用电脑上常用的“部分更新”策略，自己对自己进行一部分功能的更新，不更新整个应用程序。
从更新方式上，显然，苹果商店的自动更新，所有应用软件依然来自于苹果商店，都是经过苹果审核后的应用软件，因此，这种方式肯定是苹果自己主推的。
——
热更新的风险
应用软件自己对自己的热更新，无论整体还是部分，既然电脑上可以，苹果手机上为什么就不允许呢？
应用软件自己对自己的热更新，虽然具有很大的便利性，但对用户来讲，具有巨大的“未知风险”。
首先，静默安装导致的用户知情权和控制权风险。比如电脑上，安装一个软件之后，过不多久，就会发现这个软件越来越大，甚至默默的替我们安装了一大堆别的软件。
其次，从好的方面讲，苹果的审核策略保证了所有苹果手机上的软件能够按照苹果设定的用户体验发展，否则的话，真不知道手机的左上角右上角会多出多少小图标，没准时不时的右下角弹出个广告框。
再次，未经审核的软件，是否具有安全风险也未可知。尽管苹果的审核解决不了所有的安全问题，但至少能够解决大部分的安全问题。
还有，未经审核的软件，自己偷偷增加了赚钱的功能，竟然不给苹果分享，当然苹果不乐意了。
所以，无论是从用户体验还是从商业利益的角度，苹果都有很强的欲望禁止应用程序的热更新。
——
热更新的必要性
然而，如同上边所述的案例，微信要换个广告，游戏要更新个场景，这个需求是存在的。
于是，在保证应用软件的体验、安全、利益的前提下，提供软件的更新，就成为苹果审核的诉求。
所以，以下几种热更新，显然是苹果允许的。
、数据更新。比如说  更新一下全国的铁路客车时刻表，这只是对数据的更新，应用软件本身的功能并没有发生更改。
、配置的更新。比如说某些  通过更新图片、颜色来更新外观界面，甚至更新各个按钮的位置。
、脚本此处的脚本有歧义的更新。比如游戏里增加一个故事脚本。
以上这些更新，并没有扩大整个应用程序的功能范围，尽管某些界面的更新会导致用户体验的问题，但不会对安全性、商业利益造成冲击，所以，苹果不会限制。
——
典型的热更新
以下几种典型的热更新，是否能够通过审核，完全取决于实现的方式，而不是外在的功能。
、广告更新。
如果仅仅是更新广告内容，显然只是对数据进行更新，并没有对软件功能进行更新，因此是允许的。
如果更改了广告的展现方式，则要区分是用何种技术手段实现的。如果多种广告方式是提前代码里规划好的，只是通过更新配置来更新广告方式，则是允许的。
、微信小程序
最近微信小程序的功能扩展的非常频繁，从微信推送的说明来看，显然，微信小程序能够调用到的功能和接口都是微信提前定死的，小程序必须通过微信来调用操作系统功能，而无法调用微信不提供的功能。
这就相当于：浏览器里边的  页面，无论如何，都是需要通过浏览器来间接调用系统功能的，而无法直接获取到系统接口权限。
因此，微信小程序是安全的，也是苹果允许的。
、游戏
游戏是个重灾区。
举个例子来说：要在游戏里搭建一个崭新的城市。
如果游戏引擎中搭建城市的方式是通过配置文件的更改，那么，这些游戏基本上问题不大。
如果游戏引擎中搭建城市的方式是通过一段软件程序直接搭建，那么，风险就比较高了。
如果游戏引擎本身提供的间接接口有限，为了扩展的便利性而提供了直接访问底层系统接口的能力，那么，这种风险就非常高了。
——
封杀的矛头是什么？
从苹果发送给各个开发者的邮件可以看出，封杀针对的是那些提供系统底层接口访问能力的“热更新框架”，而不是针对“热更新”这个行为。
换句话说：苹果封杀的不是热更新，封杀的是不受控制的底层接口访问。
比如：、_，这两个方法，提供了访问任何底层接口的能力。审核的时候，应用程序不通过这些方法访问某些敏感性的接口，而审核通过之后，应用程序通过热更新来调用某些对安全有风险的敏感接口。
那么，为什么许多热更新框架要提供这个能力呢？
热更新的目的，当然是为了更改软件的某些数据、配置甚至某些流程、逻辑。
然而，作为一个框架，如果要通过中间件的方式比如微信对小程序，浏览器对 完美支持所有软件的功能需求，显然要做大量的工作，几乎要将所有苹果允许的系统接口全都封装一遍，这几乎是不可能实现的。
于是，就有了两种结果：要么瞄准某些行业，提供远小于系统完整功能的局部功能；要么，干脆提供一种穿透中间件直达任何系统底层接口的能力。
前一种方案，当然会导致此类框架的应用范围受到极大限制。
后一种方案，虽然满足了所有行业软件开发商的需要，但必然会导致软件功能在审核之后的完全不可控。包括影响系统及用户数据的安全，以及规避苹果对收费提成的诉求。所以，自然会遭到苹果竭尽全力的封杀。
——
通过上述分析，可以得出一个结论：
如果软件对系统接口的调用在审核期间是完备的，不存在审核之后新增系统接口的可能，那么，无论是否存在热更新，都是允许的。
如果软件对系统接口的调用，尤其是某些敏感接口的调用，在审核之后动态加载，这种方式一定是会被否决的。
同样的，如果软件使用了具备上述能力的框架、 等第三方代码或组件，尽管自己没有调用敏感接口，但由于存在“调用敏感接口的可行性”，因此也是会被否决的。
对于游戏引擎来说，过于通用化的游戏引擎，风险是比较高的，因为游戏引擎开发商为了通用性极有可能会提供不受控制的直达系统接口的访问能力。
从工作量上来说，实现同样的热更新，如果客户端软件做的事情越多，那么，可控的范围越高；客户端软件做的事情越少，那么，为了扩展性，不受控制的范围就越广，风险也就越高。
说句不太好听的话：有什么大不了的功能更新，不能提前在客户端布局好的？非要用这种完全扩展能力的热更新框架？
“没准哪一天我们需要新增大的功能呢？”
苹果审核现在已经够快的了，这么重大的功能，连三天的提前量都预留不出来么？
“突然出了  怎么解决？”
出了 ，难道没有什么策略能够提前避免或者规避出现这么严重的  么？非要通过热更新？如果连热更新自己都挂了，又该怎么办？
软件工程师是喜欢自由的，不希望受到太多约束。
然而，既然是“工程师”，就要明白：所有“工程”都是有标准有流程的。
一个上万零器件的机器，的零件都是标准化的。而且，从机器开始正式使用之前，所有的故障预案都已经做好了。
不能等着软件出现故障了才寻找解决方案，而是在软件分发出去之前，就要有出故障之后的预案。
甚至，一个标准的软件，一大半的代码是在规避故障，以及收集信息以供出现故障之后迅速定位、解决。
除了故障的预防、定位和解决，任何工程的扩展性，尤其是软件的扩展性和延续性，也是一个软件架构是否足够成熟的标志。
相对于面向大型机构的商业软件，苹果手机上面向普通用户的大部分终端软件，还有很多地方值得改进。一、背景
近日，腾讯云鼎实验室的合作伙伴于年月日点开始，监测到一次大面积网络攻击活动，本次活动呈现的最明显特点是参与攻击的源地址覆盖度超级广泛，几乎在全国所有省市运营商的骨干网络上均有明显活动。据公司的统计，在线内网攻击地址数百万左右。
据监测，目前攻击呈现出三个阶段：

月日点全国大量真实地址开始攻击地址，一直持续到至日凌晨点结束；
月日早晨点左右开始攻击地址，
月日攻击呈现多样化。

经过对攻击源机器进行分析，腾讯云云鼎实验室工程师在机器中发现暗云Ⅲ的变种暂时命名为暗云Ⅳ，通过对流量、内存数据等内容进行分析，基本确定本次超大规模攻击由“暗云”黑客团伙发起。
二、详细分析
“暗云”是一个迄今为止最复杂的木马之一，全网普查显示，感染了数以百万的计算机，暗云木马使用了很多复杂的、新颖的技术来实现长期地潜伏在用户的计算机系统中，关于暗云的分析详见
我们在对目标机器排查中，发现了中可疑，在对内容进行分析，我们发现肉鸡机器的与暗云 中 与  的相对位置相同，而且病毒均存储在 的个扇区中。


与此同时我们在对另外一台机器进行分析的时候，在内容里发现域名内容，机器启动时候会访问的端口，这与腾讯电脑管家关于分暗云Ⅲ的木马在层用连接访问的端口获取”的行为相符。进一步通过获取到肉鸡机器的流量信息，我们发现机器每隔分钟会去访问

通过对该域名进行访问可以发现配置信息，并且存在一个文件的下载链接。

基于域名的访问对机器的流量抓包，发现发起请求的进程为进程，并且确认父进程为。

进一步捕获的内存数据进行分析，也发现了相关域名的请求信息。

暗云木马集成了引擎，自身相当于一个下载者，通过对 访问下载 进行解析执行，实行具体的攻击行为。

通过对进行解密，可以发现明显的攻击功能。
暗云木马的发现和清理将进一步净化网络环境，腾讯安全团队将持续为国内互联网基础设施安全保驾护航。腾讯云主机安全应用——云镜系统和腾讯电脑管家已经可以在服务器和用户个人终端实现对该木马全面查杀。
三、相关样本及域名
相关恶意域名如下，厂商可在网关设备上进行拦截。









四、参考链接

“暗云”木马详细技术分析

暗云Ⅱ木马分析

暗云Ⅲ  木马分析

暗云Ⅲ木马专杀工具
_

五、致谢
本次事件响应中得到各合作伙伴的大力支持，特别感谢，排名不分先后：

重庆巴南区网信办
烽火台威胁情报联盟

立普威陆重庆科技有限公司
哈工大网络安全响应组
其他不愿意透漏名字的安全伙伴作者：杨升军

官网购买地址
购买流程：管理中心产品服务云服务器云主机新建
选择需要的配置，提交订单支付即可备注：查看机器初始密码：管理中心消息中心
更具实际需求选择购买地区和服务器配置

相关推荐
从购买服务器到建站，从打造自己的网络领地。
云服务器管理常见问题第届中国数据库学术会议 已于年月日至日在浙江大学举办。本次会议，腾讯云带着其分布式数据库内部代号亮相大会，向全国余名数据库技术的研究者、教师、同学和开发者展示了腾讯云的数据库技术。
浙江是中国电子商务大省，腾讯分布式数据库内部代号恰好是解决类似于电商、的订单交易、购买支付场景的利器。
为什么说适用于电商、等业务呢？众所周知，电商等互联网模式和碎片化的行为，无异给核心交易数据库带来巨大的挑战。即使是某些银行高大上的业务系统，其平均约在，常规峰值约倍；而在互联网场景中，任何智能设备都是交易终端，加上电商等经常出现限时抢购、秒杀等运营活动，无论哪种活动，从数据库角度就都意味着短时间并发和请求总量都远高于正常水平若不做好措施，结果就是花钱推广，反而砸掉自己招牌。通过总结，互联网场景的交易系统数据库可能经常遭遇以下情况：峰值超过正常值数倍的业务请求。秒杀等场景将带来大量的线程影响性能。故障是常态，如何确保故障数据不错不丢，且不影响全局。性价比是业务重要考量点。
峰值超过正常值倍以上的请求洪峰：以腾讯米大师对接了腾讯内外十余万业务的支付交易，这些业务会不定期发布营销运营活动，如电商大促、春节红包、国庆献礼、游戏推广等。在全年出现了多次均值倍的请求洪峰， 有次甚至超倍。下图为近期某业务做午间大促，导致整个平台请求量猛增倍蓝线是上一日对比数据，红线是当日数据。

类似问题也是电商等业务常见场景，而米大师的经验是，除了通过架构将支付系统按场景、业务、流量进行解耦，利用云的弹性和云的冗余资源池，在活动时快速自动的部署业务服务器。并区分业务单元域部署，前置调度，做分流和异常隔离和缓存外，采用支持水平拆分的分布式架构的数据库。
因为数据库本身无法像逻辑层一样做隔离请求，而将几张大表水平拆分分表。能够让数据库可以随时横向扩展，因此平时只需要在性能方面预留一定冗余，确保偶发性小峰值并不影响整个数据库性能。如果遇到可预见的超高峰值，例如年度大促、春节活动等，由业务部门决定是否进行水平扩容。当然，分布式数据库的原来使得水平扩容十分简单，而且通过自动再均衡方案，扩容可以仅影响集群中的少数节点，而其他节点可以在扩容时仍然正常运行不会受到影响。

热点更新技术，从容应对秒杀等场景： “秒杀”场景下，大量的用户在极短的时间内请求少量商品。在数据库中，一个商品是一行存储，所以秒杀会导致大量的线程来竞争行锁，当并发度越高时等待的线程也会越多，导致下降上升。这会导致什么问题呢？要么秒杀时，抢购一个商品但整个平台出故障；要么就出现个库存卖出去个等各类异常。当然，业内也有一些从数据库层面的解决方案，例如：把热点商品放到单独的热点库中；通过缓存系统如消息队列等缓存热点请求；或让业务层将修改的多条合并减少。而腾讯热点更新功能，是通过一个全局表存储有请求的热点对象，制定热点请求过来时，先查找表中有无对应的热点对象，有就获取，会被阻塞；没有该热点对象，那么创建该热点对象的方式进行。这种方案通过简单扩展语法和参数，使得业务不改变架构，仅需修改几行的情况下，便可以快速应对秒杀等场景原理如下图。当然，配合缓存使用，可以进一步为业务提高性能，减少击穿的概率
根据测试，我们发现应用和不应用的热点更新技术会的效果差异非常明显测试数据如下图。

故障是常态，重要的是如何应对故障：    如果您的业务是规模比较大，那么无论是网络、硬件、软件或人为的故障都是难以避免。因此，数据库系统必须做到以下几点，才能尽可能小的影响业务

只有保障数据强一致了才能保证故障切换的时候数据不错不丢。
故障能不能影响全局，且尽量做到业务无感知。
支持同城双活、两地三中心等架构
立体组合的监控系统，能快速判断故障，定位问题。
必须要有风险控制策略等措施保证数据安全

而腾讯分布式数据库发展了年，早已默认数据强同步复制，任何节点故障，只要是已应答均可保证数据不错不丢。也可设置多种同步方案，不同的业务数据库采用不同复制策略以求在业务逻辑和数据一致性之间平衡。
分布式架构，也使得任意节点故障，并不会影响全局，且每个从节点都可用做只读访问。在某些仅软件故障的场景， 的保持连接技术，可用软件故障，确保逻辑层和数据库连接不断开，且自动重发失败请求。此时业务是来说，感受就是某个请求时间稍长；即使是数据库事务，或自动回滚，或直接报错，数据不会错乱的。
由于的设计之初就是应用于腾讯内部金融支付类业务，因此同城双活、年底三中心对其来说早已成熟，常用方案如下图：
通过对系统从硬到软、从模块到流程、从系统升级到常规运维的立体化监控，并结合 “自愈”能力，可让常见故障自动解决，仅的故障需要人工干预，自动化的流程极大提高了故障修复响应效率。
当然，也是腾讯首个将完整的信息安全要求和风控体系做到整个数据库系统中的产品之一。包括业务和运维系统，我们提供恶意打击、稽核、实时风控等能力；在数据库层面，也提供了安全审核平台，数据库防火墙等一系列安全能力。

此外，成本控制是互联网企业成功的要素之一，如果是采用商业数据库，先互联网这种体量成本将是天价。而采用基于开源协议的分布式数据架构和腾讯云服务，按需使用且无高昂的费用，将极大的节省业务使用数据库成本。
目前，作为支撑了腾讯内外超过亿以账户，亿以上的交易流水和海量的虚拟交易的数据库，腾讯云分布式数据库已经广泛应用在银行、保险、理财、电商、等核心系统中。导语
跨越全国省、城市，名犯罪嫌疑人被捕，其包含  攻击黑色产业链中的各类角色：发单人、攻击实施人、肉鸡商、出量人、担保人、黑客攻击软件作者等，人民网、中新网、凤凰网等多家媒体对此事进行了相关报道。
腾讯“守护者计划”与腾讯云安全团队正是本次警方抓捕行动的幕后重要协助者。上周追击实录一 我们曝光了黑产集团运作模式，但想必看得意犹未尽，那上述被捕角色如何在组织详细的“分工协作”呢？请看本篇追击实录二带来的详解。

案件回顾

  黑产全链条遭斩断

近年来， 攻击   事件频发，即黑客组织通过控制服务器、肉鸡等资源，发动对包括国家骨干网络、重要网络设施、政企或个人网站在内的互联网上任一目标的攻击，致使目标服务器断网，最终停止提供服务。据外媒报道，  服务供应商  公司发布的二季度互联网安全报告显示，年全球  攻击的次数上升了。 攻击对全球网络安全构成了极大威胁，对于威胁行为者而言，  攻击是从受害者处敲诈金钱、窃取数据、同行恶意竞争的首选武器，甚至为了进一步黑客主义意图，还可以随时发起大规模网络战争。
年月初，江苏省某网络公司服务器频繁遭到  流量攻击，导致挂载在服务器上的多个网站无法正常运营，损失严重。据了解，此次  攻击是网站经营者的业务同行恶意竞争打压，雇佣黑客实施  攻击网络的犯罪行为。随后，在腾讯“守护者计划”与腾讯云安全团队的共同协助下，江苏省徐州市公安局网安支队根据网络攻击溯源寻踪，开展  黑产打击行动，于近期打掉了这个  攻击黑产团伙，抓获分布于全国省城市的犯罪嫌疑人人，包括发单人、攻击实施人、肉鸡商、出量人、担保人、黑客攻击软件作者等  黑产链条中的各类角色，对该类型的攻击犯罪形成了有力震慑。

图： 警方抓获犯罪嫌疑人图

 黑产团伙“分工协作”详解据腾讯“守护者计划”安全专家介绍， 攻击犯罪已经进入产业化时代——从以往的需要专业黑客实施全部攻击过程的行为，发展成由发单人、攻击实施人、肉鸡商、出量人、黑客攻击软件作者、担保人等多个犯罪个体共同参与实施的产业化犯罪行为。此次江苏某网络公司  流量攻击案件，便是  攻击产业链化的典型例子。

那么，在这个黑色产业链中，这些角色如何“分工协作”呢？
发单人
在  攻击黑色产业链中，链条顶端的角色为“发单人”，也就是出资并发出对具体网站或服务器的攻击需求的人。常见的“发单人”通常是非法网站如色情、赌博、彩票、游戏私服等网站的经营者，为了打压竞争对手而雇佣黑客对其他同类网站进行攻击。
攻击实施人
接到“发单人”指令并执行攻击的人，称为“攻击实施人”。实施攻击的方式有两种：
一种是利用软件、工具操纵肉鸡被入侵利用做攻击工具的个人计算机模拟访问，占用目标的服务器资源，导致正常用户无法访问；
另一种是发送大量流量攻击目标服务器，导致服务器无法访问网络。软件或工具多数购买自“黑客软件作者”。而有的“攻击实施人”由于不懂攻击服务器搭建，于是从“肉鸡商”和“出量人”手中购买已经搭建好的“肉鸡集群”和“流量平台网页端的服务”。
肉鸡商
“肉鸡商”是侵入计算机信息系统的实施人，或者买卖被侵入计算机系统权限的中间商。他们利用后门程序绕过安全性控制而获取对程序或系统访问权的程序方法配合各种各样的安全漏洞，获得个人计算机和服务器的控制权限，植入木马，使得这些计算机变成能实施攻击的“肉鸡”。
出量人
“出量人”是拥有服务器控制权限和网络流量的人。他们有一定技术能力，能够租用专属服务器并自行配置攻击软件从而获取流量。
担保人
在发单、购买肉鸡、购买流量等各个交易环节中，因为交易的双方往往并不认识，于是他们会找到业内“信誉”较高的黑客作为“担保人”，负责买卖双方的资金中转，担保人可从中抽取一定的好处费。
黑客攻击软件作者
负责编写  软件，用其实现多种攻击方式，降低黑客攻击门槛，并售卖软件盈利。

图： 黑产集团运作模式图解

网络空间安全与纯净 腾讯云协警共同努力 

随着  攻击的产业化和僵尸网络构建工具包和所谓的“”、“”以及其他  出租服务的广泛运用，不仅增加了  攻击的打击难度，还降低了  攻击的实施门槛。如今，不再仅仅是国家支持的黑客和组织能够使用  基础架构，就连普通的网络犯罪分子和脚本小子也能够轻松发起一场  攻击。因此，积极打击  攻击，铲除  攻击黑色产业链，是保障网络空间的安全和纯净的重要行动。
今年以来，腾讯“守护者计划”安全团队陆续协助多地警方，破获多起  攻击案件。除上述的月江苏某网络公司  流量攻击案件以外，还有月重庆某区局部网络  攻击等。
同时，腾讯云联合腾讯电脑管家已率先布署云端防御。腾讯云大禹系统专业抗 抵抗  攻击布局防御云端服务器安全，腾讯电脑管家保障用户终端电脑安全，构建“云端”的立体化防御体系，帮助用户避免遭受大规模  攻击。此外，腾讯云还联合途隆云、唯一网络、睿伟网络、帝恩思四家企业共同成立  防护联盟，未来将在  领域深度合作，共建安全的网络空间。
相关推荐
  解决方案前言
日本著名棋手藤泽秀行说过一句话：“棋道一百，我只知七。”
围棋被称为世界上最复杂的游戏。想成为一位顶级棋手，往往需要过人的天赋和多年不懈的努力。
但是的出现颠覆了很多传统的下法，打开了围棋世界的一扇大门。年初，腾讯推出了围棋软件“绝艺”，在网络上以绝对优势击败各国顶尖棋手，其后又赴日本参加了杯世界计算机围棋大赛并夺冠。
月日，一部记录了腾讯“绝艺”诞生和夺冠全程的记录片《》在香港恒生管理学院首次试映。该片由曾蝉联第届、届金马奖最佳纪录片奖导演周浩执导，深度访谈了柯洁、古力、武宫正树、大竹英雄等多位世界顶级棋手，讨论与人类的关系。
著名科幻作家、南方科技大学教授吴岩参加了首映会，并与周浩就之后人与机器的关系展开了深入的讨论，碰撞出无数火花。


周浩第、届金马奖最佳纪录片奖导演

研究人工智能，是用 不熟知的方法抵达秘境
以前我们拍纪录片还是拍一些跟人有关的东西，我一直觉得纪录片是研究人和人之间的关系。当科技发展到今天的时候，我发现好像仅仅研究人与人之间的关系还不够。所以说我想研究一下和人的关系。我认为这还是在研究人和人之间的关系，这是人和人之间的关系的一种拓展。
我第一次去腾讯的时候认识了“绝艺”的研发团队。这个团队大概有十多个人，大多数是岁左右的程序员，而且是典型的程序员，特别木讷。中午请我吃饭，除了他们的领导，其他人基本上不说话，连简单的寒喧都不会。我知道他们花了不到一年的时间设计软件，“绝艺”那时候已经不断地在跟柯洁下棋了，柯洁是很难赢一盘的。
我就想不通一个问题，柯洁成为世界第一，一方面是因为他有天赋，另一方面是因为他自己不懈的努力。从几岁开始学棋，最后变成世界第一，需要运气，需要努力。
但是另外一群人，就像扫地僧一样，花了不到一年的时间研发出一台会下围棋的机器，就超越了柯洁，这中间到底发生了什么事情？
我发现我们常规的认知方式应该被不断地打破。就像两个星球之间有一百万光年，按照传统的思维方式，我们以最快的速度也得一百万年才能抵达。实际上这种思维方式，现在已经越来越不准确了。比如说有虫洞，有另外一种方法可以抵达。人类对未来的认知、对世界的认知是非常非常局限的。世界的发展，社会的发展也许有另外一种方式可以走下去的。所以我觉得研究人工智能，实际上就是用一种以前我们不大熟知的方法去抵达另外的秘境。
对于所有围棋选手，的出现，是喜悦大于悲哀的事情
对我们的影响已经越来越大了，我发现另外一个问题，就是这帮围棋选手也许是人类第一批生活和职业受到严重影响的人，当出现以后，他们怎么面对的出现？他们是一种什么样的心态？
藤泽秀行，这是日本的一位已逝的、非常有名的棋圣，他曾经说过：“棋道一百，我只知其”。后来我也访问过很多围棋高手，我问柯洁：”你大概知道多少？”柯洁说：“大概、吧。”
现在一般人认为围棋应该已经是围棋上帝了，但很多棋手并不认为已经穷尽了围棋的道理。我们自以为很了解世界，其实也许人类对世界的了解连都不到，世界上最聪明的人，他们认为对围棋的了解只有，何况我们这些平凡人？
目前为止，当出现的时候，围棋选手们的喜悦甚至会大于悲哀。只有一个人对我说“来得太早了”，这个人是柯洁，一个岁不到的年轻人。当他是世界第一的时候，突然间有一个机器下得比他厉害，可以想象他的失落感。他问，“为什么不晚出现几年？”
但在另一个层面看，他也特别欣慰。当你成为世界第一的时候，突然冒出一个老师，这个老师可以很快碾压你，其实这种感觉对一个心智健全的人来说，是一件非常欣慰的事情。因为知道自己的短处在哪里，可以进步了，这种感觉是非常微妙的。
围棋胜负是很重要的事情，但是棋手会冷静地看待胜负，比如古力。其实对大多数棋手而言，围棋是一种修行，是让你在围棋中感悟人生。我采访日本一个非常有名的棋手，他感叹老天爷发明了这么一种完美的游戏，你不能穷尽它的变化，这种感觉是职业棋手才能体会的。
所以围棋给他们带来的乐趣，已经远远超过了胜负。当出现以后，全世界下围棋的人数增加，围棋在欧美的普及度也得到了提高。围棋之所以在欧美普及不开，是因为欧美没有很厉害的高手，高手都在东方。当围棋软件出现以后，一个欧洲人如果不断跟世界最高水平下棋的话，他的棋艺会提高得非常快。所以围棋界是非常高兴的，他们觉得既然来了就接受它。
 

吴岩著名科幻作家南方科技大学教授

人工智能可能导致失业，但解放出来的人将创造新工作
我看到这个片子以后特别高兴，因为我是搞心理学出身，年的时候有一篇文章名为《》，讲人类认知的极限就是，只是个左右的组块就可以处理这些问题。这可能已经到了人类认知的极限，但是计算机现在能帮助人类，那么下一步机器和人确实是站在一个起跑线上。
当大量的人工智能出现时，失业就会普遍产生。在内地，我们讨论得最多的问题就是下一步谁会失业。比如说高校里面，翻译专业可能最早失业，因为翻译是比较容易做的。老师也快失业了，因为教师的这套东西基本上人工智能也是可以处理的。
今天人工智能确实正在影响着我们的生活，而且是最普通人的生活。但另一方面，人工智能近期对职业的发展，特别是对创业特别有好处。比如有个识花的软件，只要对着花拍一张照片，它就能告诉你这是什么品种，产自哪里。还有一个看云的软件，通过对云的观察，自动预测小时之后的天气。
从人类发展的历史看，科技的进步是在不断解放人类，人工智能可能替代掉很多工作，而解放出来的人将会创造出新的工作方式和职业。

当天的讨论实在太精彩，影片正式放映前，主持人特意留了出时间给现场的观众提问。
：如果什么都能做，我们可以快乐消费，可以娱乐，可以，或者是进行文化方面的创作。人会不会被废掉？人类再继续往前走的动力在哪里？
周浩：我并不认为是机器战胜了人类，我更愿意认为是一个人或者一群人设计了一个机器，战胜了另外一个人或一群人。
我觉得未来人工智能对人类的影响，可能反而不是在人工智能本身，因为人工智能还是一种工具，危险一定是来自于那些使用这个工具的人。就是当人的恶和这个机器进行完美结合，也许人类的某种灾难会降临。所以我觉得最终应该控制的，应该用道德去规范的，还是人本身。因为人的恶，也许远远超过我们的想象，机器有时候反而是可控的。
吴岩：周导提得很有道理，因为他一直在提一个作品是《黑晶》，这里面有大量的关于人的恶。但是我觉得后人类时代，这个问题也很严重。摆在所有人面前的现状是，不单要处理人文的问题，还要处理后人的问题。今天不是说没事儿了，而是要考虑的问题更多了。
：现在好像有一种趋势，总是在谈人工智能将会取代人类，这对教育来说是有很大影响的，因为我们通过教育去培训学生，用机器去教育学生可行吗？从人文角度来说，我们应该如何相信人工智能呢？
周浩：以我的观点，我觉得现有的人工智能是无法代替人脑的，比如说关于爱，关于爱情，我不知道两个机器怎么交配，怎么会有性生活。我觉得人是一个非常复杂的组合体，而围棋软件就是一种算法，说下棋的时候，哪一步棋的胜率高就下哪一步棋，在它的整个程序里面只有胜负，这是决定它认识世界的唯一方法。
而人类有趣的东西，恰恰是那些混沌的、模糊的、说不清道不明白的感觉。比如柯洁就谈到过这样的问题，他说下一步棋的时候，一定会受上一步棋的情绪的影响，跟今天吃了一顿饭、见了什么人，都有非常大的关系。但是对机器而言，它永远只有胜负。
所以人类的感觉超越了胜负，胜负只是一个手段。就围棋这个游戏而言，我并不认为胜负是人类要的结果。围棋在中国国语里面有一种说法叫做“手谈”，就是两个人不说话，用手在进行交流，这种感觉是很多棋手要找的感觉。
人跟人在一起的感觉，和人跟机器在一起的感觉是不一样的，也许我不会那么悲观吧。
吴岩：我同意现在的人工智能，基于深度学习的人工智能还是比较“傻”的人工智能，虽然已经可以解决很多问题了，但还是很简单的。下一代的人工智能，比如说模拟人脑的那些算法，一旦突破了，比较复杂的人工智能出现的时候，很难讲不会取代今天的一些事情。
现在大家总是在说人工智能情绪做不了，个性做不了，自我意志做不了。但事实上，情绪这些东西早晚都是可以做出来的，因为情绪就是伴随着认知的一种东西，你喜欢和不喜欢，这些都可以还原成某种生理的信号。只要把这些信号转换成代码，人工智能模拟情绪是没有问题的。至于说自我意识，这些也很可能早晚有一天是可以做的。所以我觉得，并不能说人工智能不可怕。
关于现在的教育，我非常同意现在我们就要做出很多应对的方式，来给我们的下一代人做准备，让他们努力面对这个新的一面。其实现在做可能都已经晚了，过去的科幻小说是说未来在远方，今天我们说未来昨天晚上已经到了。面对这个情况，学生没有办法面对，我们也没有办法面对，现在所有事情都比想象中出现得快。
本文经腾云编辑整理发布一、 技术介绍
  工作原理
  是    的简写，意即  虚拟服务器，是一个开源的负载均衡流量调度器。 集群采用  负载均衡技术和基于内容请求分发技术，将用户请求按照一定策略分发到后端的  上，从而将一组服务器构成一个高性能的、高可用的虚拟服务器。在特定的场景下，整个服务器集群的结构对客户是透明的，而且无需修改客户端和服务器端的程序。

如图所示，前端调度器虚拟出  监听和接收请求，真正提供服务的是后端的 亦称为  或者 ，数个  组成一个 ， 的请求分发到  上，并在  当中的  之间按一定策略分发轮询。 与    不同之处在于， 没有  的概念，也没有 ，并且只提供  层的负载均衡。  
 调度模式
   
 除了支持传统的 、、 模式之外，  内核，支持一种新的负载均衡模式：。 区分于传统  模式的地方在于数据包经过调度器的时候，源目  和端口都被转换了，后端  看到的数据包来源是调度器的  。

采用  模式的优点是可以更加灵活的适应不同的网络环境，对网络架构的改动需求最小，而且支持跨集群调度。缺点在于如果后端服务器需要获知真实的客户端  地址，需要打内核补丁。当调度器与后端服务器建立  连接的时候，三次握手包的包头中会携带写入真实客户端  地址的     信息，只有后端服务器打了补丁才能获取到客户端 。
  
在网络环境许可的情况下，采用  模式可以带来 左右的性能提升，并且不需要配置  ，由于   需要与内网互联网段 与内网核心互联地址段在同一子网内，使用  模式能够减少  地址占用。

 内网负载均衡 
 支持内网负载均衡功能。在实际应用场景中，可能会遇到在内网当中的服务器也需要负载均衡的情况，比如中间件层调用存储、前端调用数据库等等。内网负载均衡需要网络环境支持，在内网核心上将地址段路由下一跳指向  的  。需要注意的是，内网负载均衡必须是  模式，内网负载均衡不支持  模式。

 
传统的  不具备  功能，当使用  模式进行负载均衡的时候，后端服务器正常的公网访问需求仍然需要通过额外的设备解决。 可以合并 ，提供了  模式，使用中需要将内网核心的默认网关指向  的  。所有数据包在流入  的时候都会在  表中检查一遍，不存在会话的数据包根据策略路由从   池中选取  作为源地址转发出去
 会话保持
 的   状态默认  超时， 秒内没有数据传输就断开连接。在  层负载均衡场景下， 默认启用会话保持功能，同一个   转发到同一个后端服务器， 秒无数据传输后过期，不同的   或者会话过期则按调度算法重新分派。在  层负载均衡场景下，默认不启用会话保持。可以开启插入  会话保持功能，默认过期时间  秒。   层负载均衡  可以使用  或  提供  层负载均衡功能。
二、 组网模式
 并行旁挂

在已有成熟的网络架构中部署 ，采用并行旁挂的方式不需要网络有太多的变动，而且相比  模式需要在  配置  地址不同， 模式的只需要单独的一个 ，就能够进行负载均衡。并行旁挂模式分为单臂和直挂两种。单臂的情况下，对链路的压力很大，当流量高峰期容易导致链路跑满，因此一般采用直挂的方式，将  分别直挂在  出口和内网核心。所有需要负载均衡的数据流量经由  出口转发给  服务器，其它流量不受影响。
 串行路由

串行组网架构是应用最为广泛的负载均衡组网架构。只有在串行组网架构当中，才可以使用  的  模式。使用  模式可以做到对后端服务器完全透明，并且调度性能和网络吞吐也比并行旁挂模式要好。
数据的访问流向均先经过  交换机，通过  交换机路由到  上，根据  配置的负载均衡策略对流量进行负载均衡，再经由内网核心交换机和机柜接入交换机到达相应的服务器，返回的数据流亦然。  
串行组网架构整体网络结构比较单一整齐，业务数据流走向清晰可见，易于设计、部署实施，及后续的维护、管理，相关故障的排查。不过由于  位于出访流量的必经之路，除非有相应的路由策略，否则所有的对公网访问流量也需要经过 ，因此需要与  的  配合使用。
三、 高可用性
 主播模式
在冗余方面， 分别支持主备模式和集群模式。在主备模式下， 可采用成熟的开源软件  实现冗余功能。在  主备方案实施当中，一台为主机正常提供服务，另外一台提供热备份。当主机离线时，备机会自动接管所有 ，接替主机承担负载均衡的职责。      参照了  协议实现故障切换。 的   与  的   在概念上并不相同。 不需要像  那样为每台设备的每个网段配置  ，再配置一个不同于   的   对外提供服务。在  中，  直接对外提供服务， 模式下还拥有不会随主备切换的  。在正常情况下，主机对外宣告  ，备机没有配置 ，保持静默。如果主机发生故障，备机会在一秒钟内检测到，产生故障切换事件，通过发送免费  宣告自己拥有  ，引发流量切换。

 可以指定某个网络接口运行  实例，为了避免  影响现有网络，可以采用单独的心跳线传输  流量。备机通过监听  通告确认主机是否存活，如果主备机因为意外同时 ，会导致严重的网络故障，并且需要人为干预才能恢复。为了避免单根链路故障而导致的意外故障切换，建议心跳线采用两根链路捆绑，可以大大降低故障几率。 支持人为的进行主备机倒换，但是并不具备  的会话镜像功能，因此在主备机倒换和故障切换之后，所有会话的连接性都会丢失。
 集群模式
集群模式采用了   方案，利用开源的软路由软件 ，对  接入交换机宣告  的主机路由信息，通过  等价路由的特性可以提供最多八台   的集群服务。在集群模式下， 可以横向扩展，自由伸缩，但是会增加网络的复杂性。

单  区域， 只能使用  模式，与内网核心使用  连接，在每一个服务  宣告 ，并且所有后端服务器必须配置  为网关，对网络的要求和后端服务器的变动需求非常大。如果要使用  模式，需要  与内网核心也建立  邻居关系，将   同时宣告给内网核心。受限于  调度算法，集群模式有可能无法提供无感知的伸缩特性。如果三层设备不支持  调度一致性 ，那么当某台  离线的时候，所有长连接都会丢失。目前只有  设备支持一致性  算法。
 监控检查
 可以对  后端服务器做健康检查。当某个  服务不可用， 会自动将其从  中剔除。 目前支持的健康检查方式有 、、。
四、 网卡配置
 系统拥有以下几种接口类型，在实施设计阶段要予以考虑。业务接口可根据网络架构和应用场景行衡量。



端口名称
端口用途
端口类型
端口数量





主备故障切换心跳线
电口




内网业务流量接
电口\光口




外网业务流量接口
电口\光口




业务流量接口采用多千兆电口捆绑的方式，需要注意对端三层设备的链路聚合负载均衡模式的选择，以防聚合中单根链路跑满的情况发生。心跳线的作用是备机探测主机是否存活的关键，一旦这条链路丢失， 系统就会出现双  的情况，所以使用两根心跳线捆绑的方式可以让出现心跳线物理损坏的几率大大降低。接 调研与 上


应用场景
按理说，应该不算，而应该算。那为什么会放在这里说，其实主要有两个原因：一是并不是很简单的，因为它提供了大量的配套管理服务，虽然这些服务大多数都是通过 的形式提供，但确实是可以编程来调用的；二是本身也一个很有特色的“可编程”服务：服务。这个服务是可以嵌入在它提供的各种服务中，提供用户自定义控制这些配套服务的能力，所以让这些服务看起来更像平台，而脱离单纯的。从嵌入的角度来看，比更加的激进，而不是遵循传统的服务存在，因此能被更广泛的互联网业务所使用，而不仅仅是互联网电商客户。据说最近一些在上很火的新游戏，都有用到的服务，包括。
开发支持
因为核心是围绕其服务器来设计的，所以并没有所谓的开发框架。而更多是针对提供的各种透明的、基于网络的优化功能。比如，就是基于使用时间、负载情况，对实例进行伸缩，这里补充一点，的虚拟机也是支持技术的，所以能比较方便的启动、迁移。而另外一个叫的服务，则是比较传统的类似的负载均衡器。
能够真正对“编程”的，就是他们的服务。你可以多种语言来编程，包括  ，来编写一些触发器产生的事件处理回调。在的各种服务中，有很多服务都支持，如，这些服务在收到请求，或者发生状态变化的时候，都会触发很多不同种类的事件，从而调用用户自定义的这些代码。比如对象存储收到数据的时候，就会触发代码。这个功能就能很方便的用来做游戏的存档和读档。又或者数据库服务在对数据进行或者操作的时候，也可以触发你的代码。当然，像这种流式计算服务，本身就是需要用户代码来做离线的统计或数据处理的。

把用户代码嵌入到服务当中，而不是提供一个用户代码的服务容器，这个设计也许是需要服务而产生的。但这种灵活的设计，也把使用者从“标准开发框架”中解放出来，作为服务提供者，也无需像那样提供各种语言和五花八门的编程框架。由于游戏服务器端一般的通信模型和相去很远，有大量的主动通知，以及在线数据反馈的需求，所以使用那套框架肯定是不能满足需求的，但好像这种，游戏客户就可以自己写一个简单功能的，比如只做简单的广播服务，而其他的存储功能，都以的方式把游戏逻辑和存储服务结合起来，比较的省事。
运维管理
由于主要目标是卖虚拟机，所以拥有很多更“通用”的运维管理工具。其中一个就是，这是一个一个应用部署工具，通过集成来拉取和存储你的软件。对于仅仅是需要部署应用的客户来说，非常方便。而另外一个工具叫，这个是更通用的运维部署工具，看起来非常像，你可以用它来部署任何软件。这类工具都是通过先在你的虚拟机部署目标机器上，安装一个代理程序，然后这个代理程序就可以从一个集中的软件部署任务服务器上，接受各种部署或配置的任务。用户可以集中在一个界面上去部署软件，修改配置，而且可以通过格式的数据表，记录各服务器相同或者不同的配置，通过工具或自定义的脚本，自动化的在目标机器上做任何的部署操作。

把对于虚拟机的弹性部署，按负载自动伸缩能力，也应用在计费上。所以有一个叫的服务，其实就是按需付费的功能。这对于各种还在推广开发期的业务特别友好，国外有很多独立游戏或者创业项目，都直接在上开发测试。同时也提供了所谓的工具，其实是一种持续集成工具，但部署部分就默认结合在上。虽然也有各种开发工具，但直接以持续集成的面貌来提供服务，并且结合云服务，还是非常值得点赞的。毕竟现在在持续集成方面，大家都还是比较繁琐的去设置各种服务器环境，结合上运维系统，才能真正的“自动化集成”。而使用，开发者可以直接一键就把代码部署到虚拟机上，中间还经过自动化测试等等集成任务。这样就又省了折腾持续集成软件的工夫了。

最后说说服务，这和的服务有一种重要不同，就是他主要面向的虚拟机的数据，而不是具体的服务。这个系统另外一个特色，就是可以从日志生成、搜集、监控、告警、报表一体化。可以说是一个通用的日志分析系统。用户可以向发送自定义的指标，然后设置监控阈值，这样不但会在你设置的范围内进行监控报警，而且还会存储所有的这些日志，并用以生成统计报表和图形。

所有的这些服务，给我的感觉，就是虽说服务看起来没有那么“有技术含量”，但由于其高度注重易用性，所以非常容易吸引人去使用。就是不管你是什么平台或者架构，似乎都能用的上它的某几个服务。而且所有的这些服务界面，都是统一接口模型、统一界面风格，让人可以触类旁通，学习起来一点不费劲。当然这里也有可能因为本身没有提供太过复杂的功能
关联配套
由于的主力产品是的虚拟机，所以其在线计算的云服务几乎是没有的。但是有丰富的其他配套服务，一点不比逊色。它们大体来看分为两类：
存储产品

：对象存储服务，以二进制块的方式直接存放。一些游戏开发商直接用来存用户存档数据。
：和古老的标准兼容的分布式文件系统。
：具备全球节点的服务。国内用户是比较熟悉的，但的优势在于其全球的机房和带宽优势。
：这一块就是“关系型数据库”的服务类，包括了 \  \   \  \ 这些数据库服务器。这个服务就非常典型的是平台同的类型，但是同样也提供。而且最后这个数据库，是自己研发的，兼容的产品，据他自己说比快很多。
：一种数据库，属于，也就是无需预建数据结构的。可以使用搜索大概是等于号匹配，也可以使用搜索大概是大于和小于号匹配，这一点是很多都不具备的。
：类似这样的缓存服务器集群。这里直接提供集群功能，就不需要自己去想办法搭集群了。这也是比较典型的服务商会提供的服务。
：分布式消息队列服务。这个服务很特别，一般来说消息队列服务，是用于比较大规模的服务器系统，需要把计算任务分布放在多个硬件虚拟机上运行，而彼此之间又需要互相通讯，所以需要这种消息队列服务。如开源的有或这种，但直接做成分布式的，还是比较少见的。这样不用自己维护消息队列服务集群，只需要使劲买来添加计算节点，还是比较爽的。问题是这个服务的接口是的，也就是说基于协议的，所以其延迟性应该是一个问题。如果在游戏里面使用，估计只有一些不太在乎延迟的，触发量较少的操作，会适合用这个服务，比如用户从游戏大厅进入到游戏房间这种。

离线计算产品

：用来分析所有提供的服务的日志。是一个强大的日志统计分析系统。
：一种流式计算，类似 这种系统。值得注意的是，它同样是可以直接调用所有的服务生成的日志。这是离线计算产品的一个通用特征，就是“本系统”类的服务，都可以直接调用，无需用户自己去做各种接口或格式的转换。
 ：著名的机器学习服务，同样可以从全线服务的日志中作为学习、测试数据集。秉承的易用性设计目标，这个服务内置了大量的学习模型，很多功能都不需要使用者去自己编写各种学习公式。而只是需要开发者使用其交互式视觉工具，就可以完成对机器学习任务的配置和运行。
：级别的数据仓库，属于列式存储系统一般大容量的数据库都是这种


总结
作为一个“云”时代非常重要的概念，在实际的业务中应用却远没有和的广泛。究其原因，我觉得无非是其灵活性受限导致的。比如这种教科书式的平台，尽管提供了各种管理服务和多种语言框架，但最后还是受一个大的服务的框框所约束。而且后台关联服务和服务存于一个沙箱中，虽然提供了很好的自动化运维的能力，但也造成了很多不便。除了一些很简单的、典型的互联网业务，很多其他的服务，都多多少少可能需要突破这些限制。——不过话说回来，这种对于标准的服务，确实是非常的方便，几乎完全不需要自己去运维。
而以为代表的，这种不太纯正的，提供了大量的运维工具，实际上还是需要用户自己去做很多运维的工作。但这样也提供了极大的灵活性：你可以用的模式去使用。同时也提供了很多的配套管理服务，使用者同样可以不去自己部署、配置这些服务。可以说同时的灵活性，和的强大功能。不过也不是天衣无缝，其中服务，就不属于通用的业界标准，如果你把很多业务代码用的方式来实现，那么你就无法切换到别的云服务商上去了。加上服务大部分都是 ，所以网络造成的延迟和带宽占用，都不适合大量交互的在线服务——网络游戏。
最后展望一下的发展，个人觉得通用型应该是没前途的。因为业务模型千差万别，模型上的通用必然带来功能上的限制，以及易用性上的确实。所以还是应该按不同的业务领域具体细分下去。现在互联网业务比较大的业务领域有三类：一是电子商务类，二是游戏类，三是资源社区类如站、今日头条、各种、云音乐等。这三类业务都有其非常明显的模式和需求差异。
比如电商类服务，一般所谓的“业务流”是一个重要需求，而且对于存储安全性非常重视，但对于延迟要求就很低；而游戏类则无法接受单向的协议，而且多数都要和游戏客户端引擎什么的结合，对于延迟的要求非常高，大多数不能忍受超过，存储只要可以无限扩容，安全性无需达到金融级都可以；社区类则对于大量的文件存储很分发是硬需求，需要更广的部署地点，但业务逻辑一般不会过于复杂。
因此我们很难通过简单原始的一个 应用框架，就把这三个方面的业务需求都框进去，而且除了处理请求，还有大量的业务通用功能，是可以作为服务做出来卖钱的，比如电商的订单系统、游戏的同步服务、社区的基础社区功能等等。
最后的总结，就是服务必须要立足业务领域，面向业务中的通用逻辑，才能真正的做好一个云。
无耻的小广告，腾讯游戏服务，专为游戏开发服务： 【声明】以上广告本人没有一分钱广告费

本文来源于 韩大微信公众号翻译  科技大本营参与   、周翔



当前  序列到序列学习惯用的方法是，借助 循环神经网络将输入序列转变为变长输出序列   ，而    则提出了一种完全基于  卷积神经网络的架构。相比循环模型，其训练过程中所有元素的计算都可以完全并行化， 硬件的性能可以得到更好的利用；而且，由于非线性的数量是固定的并且不受输入长度支配，优化起来也更加容易。

 使用门控线性单元  ，缓和了梯度传播，还在每个解码器层上都装了一个独立的注意力模块。在机器翻译比赛  中， 的架构的“英语德语”和“英语法语”翻译的准确度超过了  等人 的深度  架构，而且在  和  上的运行速度也有数量级的提升。
科技大本营对论文进行了简要翻译。
 引言
使用  学习在很多任务中已经有成功的应用，例如机器翻译、语音识别和文本摘要等。目前最常用的方法是使用一系列的双向  对输入序列进行编码，再用一系列的解码器  生成一个变长输出序列，输入和输出序列通过一种软注意力机制联系在一起。试验证明，在机器翻译任务中，这个架构的表现要比传统的基于短语的模型好得多。
尽管  独具优势，用它来进行序列建模却不是很常见。相比循环层，卷积层可以生成的是固定大小的上下文的表征，但是，只要在彼此顶部叠加几层卷积层，就可以增加网络的有效上下文大小。这样就可以准确控制要建模的依赖关系的最大长度。卷积网络不依赖于对上一时步 的计算，因此序列中每个元素的计算都可以平行化，而  则必须维持先前所有时间步长的隐藏状态，这阻止了序列内的平行计算。
多层卷积神经网络生成层级式表征，较近的输入元素在较低的层相互作用，而较远的元素则在较高的层相互作用。相比循环网络建模的链结构，层级式结构提供了一种较短的路径来捕获词之间远程的依赖关系，例如获取一个可以捕捉  个单词一个窗口之间关系的特征表达，卷积核宽度为  的卷积网络只需进行  次卷积操作，相比之下，循环神经网络则需进行  次操作。在输入数据时，卷积网络进行恒定次数的卷积核操作和非线性计算，而循环网络则是对第一个单词进行  次操作和非线性计算，对最后一个单词只进行单次操作集合。此外，固定对输入进行非线性计算的次数也可以简化学习过程。
在最近的一些研究中，卷积神经网络已被用于进行序列建模，如  等人的研究提出在一连串卷积层之间进行循环 ； 等人的研究尝试不借助注意力机制处理神经网络翻译任务。但是这些方法在大型基准数据集上的成绩都没有超过当前最优成绩。 等人在  年曾探讨过利用   完成机器翻译任务，但是他们评估的对象只限于一个小数据集，而且用的还是一种与传统的基于计数的模型协作的模型。这种部分卷积的架构在处理较大的任务时表现优异，但是他们的解码器仍然是循环网络 等人 。
在本文中，我们提出了一种用于  建模任务的纯卷积架构。我们的模型配有门控线性单元和残差连接 。我们还在每个解码器层使用了注意力机制，每个注意力层只添加数量足以忽略不计的 。借助以上组合，我们可以处理大型任务。
我们在几个大数据集上对用这种方法完成机器翻译和文本摘要任务进行了评估，并将评估结果与当前的最佳架构进行了比较。在 ’ 的“英语—罗马尼亚语”翻译中，我们以   的优势超越了先前的最佳成绩。在 ’ 的“英语—德语”翻译中，我们以   的优势超越了  等人提出的  系统。在 ’ 的“英语—法语”翻译中，我们以   的优势超越了 等人 提出的概率训练系统  。另外在即时翻译语句时，我们的模型在  和  硬件上的运行速度要比  等人提出的系统 要快一个数量级。
 循环序列到序列学习
序列到序列建模已成为基于循环神经网络的编码器—解码器结构 等人   等人 的同义词。编码器  处理元素数量为  的输入序列  =      ，返回状态表征  =      。解码器  代入 ，然后从左到右生成输入序列  =      ，每次生成一个元素。在生成第  个输出元素时，解码器根据先前的状态  计算出一个新的隐藏状态 ，一个先前目标语言单词  的内嵌 ，以及从解码器输出  中提取出的一个条件输入 。基于这种方式，学界提出了很多种不同的编码器—解码器架构，这些架构的不同之处主要在于条件输入和  类型的不同。
未使用注意力机制的模型只考虑最终编码器的状态 ，方法是对所有  进行  =  的设置；或者用  初始化第一个解码器的状态，不使用 。使用注意力机制的架构在每个时步 将  计算为       的一个加权总和。总和的权重被称为注意力分数 ，它可以使网络在生成输出序列时考虑输入序列的不同组成部分。计算注意力分数，根本上就是将每个编码器状态  和先前解码器状态  和最终预测  的组合进行比较；计算结果进行正则化，最终形式为在输入元素上的分布。
编码器—解码器模型中的循环网络常为长短期记忆网络以及门控循环单元。这两种网络都是通过一个门控机制对   进行的延伸。门控机制可以使网络能记忆先前时步 中的信息，对长期依赖 进行建模。最近提出的方法也是依靠双向编码器来为先前的上下文和之后的上下文构建表征。层数很多的模型通常依赖于  连接或  连接。
 卷积架构
接下来，我们提出了一个处理序列到序列建模任务的纯卷积架构。我们使用  来计算中间编码器状态  和解码器状态 ，而不是使用 。
 位置嵌入 
首先，我们在分布式空间中嵌入输入元素  =      ，并将其表示为  =     ，其中

是嵌入矩阵

中的一列。我们还嵌入了输入元素       的绝对位置，其中

这样，我们就可以得出输入元素表征  =         。我们对解码器网络生成的输出元素进行类似的操作，将得出的输出元素表征输入到解码器网络  =       中。位置嵌入在我们的架构是很有用的，因为它可以使我们的模型感知到现在处理的是输入序列或输出序列的哪一部分。
 卷积块架构  
编码器网络和解码器网络用的都是同一种块结构，这种结构根据恒定数量的输入元素来计算中间状态。我们将解码器网络的第  个块结构的输出表示为 =      ，将编码器的第  个卷积的输出表示为 =      ；本文中的“卷积块”和“卷积层”可以互换。每个卷积块都包含一个后跟一个非线性的一维卷积。对于只有一个卷积块且卷积核宽度为  的解码器网络，每个输出状态  都包含  个输入元素的信息。在每个卷积块顶部叠加几个卷积块，这样就可以增加每个状态代表的输入元素的数量。例如，设定  = ，叠加  个卷积块，那么我们可以得到一个由  个元素组成的输入字段 ，即每个输出依赖于  个输入。非线性可以使网络利用整个输入字段，或者在需要时只用考虑更少的元素。
每个卷积核都参数化为

和

并作为输入
，
它是嵌入在  个维度中的由  个输入元素组成的一个字符串。这些元素被映射至一个输出元素

这个输出元素的维数是输入元素维数的两倍；后面的卷积层处理前面卷积层的  个输出元素。我们选择门控线性单元作为非线性，用它对卷积的输出执行一个简单的门控机制

 等人的研究中也提出了类似的非线性，他们对  进行了  计算，但是  等人的研究表明  在语言建模任务中的表现更好。
为了构建深度卷积网络，我们将每个卷积的输入的   添加到卷积块的输出中。

在编码器网络中，我们在每个卷积层填充输入，确保卷积层的输出与输入长度相匹配。但是，在解码器网络中，我们必须确保解码器没有更多信息。
我们还在大小为  的嵌入和大小为  的卷积输出之间的映射中添加了线性映射。最后，我们计算了  个可能的下一目标元素  的分布：
 多步注意力 
我们提出了一种在每个解码器层上应用的独立注意力机制。为了计算该注意力机制，我们将当前的解码器状态  与先前的目标元素  合并在一起：

图 训练过程中的  示图。我们对英语源语句进行了编码顶部，并同时计算了四个德语目标单词中部的所有值。我们的正是解码器上下文标准底部左侧和编码器表征之间的点积。我们将中部右侧计算的条件输入加到解码器状态中，预测目标单词底部右侧。形框和乘法运算框表示的是门控线性单元。
对于解码器层 ，状态 的 和源元素  计算为解码器状态摘要  和最后一个编码器卷积块  的每个输出  之间的点积。

当前解码器层的条件输入  是编码器输出以及输入元素嵌入  图，右侧中部加权总和：

总的来说，我们的注意力机制可以考虑之前注意到哪些单词，并在每个时步上执行多个注意力‘’。
与  相比，我们的卷积架构还允许将序列的所有元素的注意力计算图，中间进行批处理，我们分别对每个解码器层的计算进行批处理。
 归一化策略 
我们谨慎地对权重进行了初始化，以稳定学习过程，同时我们还对网络的各部分进行了  操作，以确保网络的  不会发生较大的变化。特别地，我们缩放了残差卷积层的输出以及，以维持激活函数的 。我们将输入和一个残差卷积块的输出的总和乘以√ ，以将总和的  减少一半。假设被加数有相同的 ，该假设不一定正确，但是在实践中却有效。
 初始化
在加入不同层的输出时，如  ，正则化激活需要进行谨慎的权重初始化。初始化的目的与正则化的目的相同：在整个前向和后向传递过程中维持激活函数的偏差。均值为 、标准差为  的正态分布的所有嵌入都经过初始化。对于输出不直接转递到门控线性单元的层，我们从

开始对权重进行初始化，其中  是每个神经元的输入连接的数量，这样可以确保正态分布的输入的  保持不变。
对于正好在  激活之前的层，通过调整       中的衍生方法，我们提出了一种权重初始化方法。如果  输入的分布函数均值为 ，并且  足够小，我们就可以使用输入  的四分之一近似估计输出 。因此，我们对权重进行了初始化，这样  激活函数的输入偏差就是输入层偏差的倍。实现方法是从

中提出初始值。当构建好网络后，将  全部设为 。
我们在一些层的输入中执行了 ，这样输入的概率值就始终为 。这还可以看作为乘以一个  随机变量，代入概率  计算  值，不涵盖 为  的情况。 的应用可以使偏差缩放  倍。我们的目的是使用较大的权重初始化各层，以恢复输入的偏差。具体的做法是，对输出由  处理的层使用

对于其他层，则使用

结论

表：与以前的工作相比，我们的模型在任务上的准确率。 和  的结果是多次测试之后的平均值。
我们针对  第一次引入了全卷积模型，该算法在非常大的基准数据集上的表现，超过了 。与  相比，我们使用的卷积方法更容易发现序列中的组成结构，因为表征实际上是分层构建的。我们的模型依赖于 门控，并需要之执行多重  步骤。
我们引入了序列学习的第一个完全卷积模型，该算法在非常大的基准数据集上以超过一个数量级的速度超越强反复模型。与循环网络相比，我们的卷积方法允许更容易地发现序列中的组成结构，因为表示是分层构建的。我们的模型依赖于门控，并执行多重注意的步骤。
我们在几个公开的翻译基准数据集上都取得了目前最好的成绩。在“ 英语  罗马尼亚语”的任务中，我们超出目前最佳成绩  。相比   年的  模型，在“ 英文  法文”翻译任务中，我们进步了  ，而在“ 英语  德语”翻译任务中，我们进步了  。
在未来的工作中，我们希望将卷积架构应用到其他的  学习问题中去，而这些问题也很可能从学习分层表征中受益。
源代码和模型获取地址：

文章来源于  科技大本营 微信公众号 是什么？
按照  官网的描述  是一个可用于诊断、调试和教学的  用户空间跟踪器。我们用它来监控用户空间进程和内核的交互，比如系统调用、信号传递、进程状态变更等。
 底层使用内核的  特性来实现其功能。
在运维的日常工作中，故障处理和问题诊断是个主要的内容，也是必备的技能。 作为一种动态跟踪工具，能够帮助运维高效地定位进程和服务故障。它像是一个侦探，通过系统调用的蛛丝马迹，告诉你异常的真相。
 能做什么？
运维工程师都是实践派的人，我们还是先来个例子吧。
我们从别的机器  了个叫做 _ 的软件包过来，开发说直接启动就行，啥都不用改。可是尝试启动时却报错，根本起不来！
启动命令
_ _
输出：
    
  
为什么起不来呢？从日志看，似乎是初始化日志文件失败，真相到底怎样呢？我们用  来看看。
    _ _
输出
 _ _ _     = 
  =      
                   = 
此处省略去一些无关输出
 __  =       
 __ _|_|_|_  =       
           
 = 
    \   
 = 
 _           = 
     
我们注意到，在输出   错误的前一行，有个  系统调用：
 __ _|_|_|_  =       
它尝试打开文件__来写不存在则创建，可是却出错了，返回码是 系统错误号为。 查下系统调用的手册页
  
搜索  这个错误号  的解释
 _                           
这里说得比较清楚，因为我们例子中的  选项指定了 _ 选项，这里  为  的原因是日志路径中某个部分不存在或者是一个失效的符号链接。我们来一级一级看下路径中的哪部分不存在：
  _
   _     
  _
 
        
        
原来是  子目录不存在！上层目录都是存在的。手工创建  子目录后，服务就能正常启动了。
回过头来，  究竟能做什么呢？它能够打开应用进程的这个黑盒，通过系统调用的线索，告诉你进程大概在干嘛。
 怎么用？
既然  是用来跟踪用户空间进程的系统调用和信号的，在进入  使用的主题之前，我们的先理解什么是系统调用。
系统调用
按维基百科中的解释，在计算机中，系统调用英语： ，又称为系统呼叫，指运行在用户空间的程序向操作系统内核请求需要更高权限运行的服务。系统调用提供用户程序与操作系统之间的接口。
操作系统的进程空间分为用户空间和内核空间。操作系统内核直接运行在硬件上，提供设备管理、内存管理、任务调度等功能。用户空间通过请求内核空间的服务来完成其功能——内核提供给用户空间的这些  就是系统调用。
在系统上，应用代码通过库封装的函数，间接使用系统调用。
 内核目前有多个系统调用，详细的列表可以通过手册页查看。这些系统调用主要分为几类：

文件和设备访问类 比如  等
进程管理类   等
信号类  等
内存管理  等
进程间通信   信号量，共享内存，消息队列等
网络通信  等
其他

熟悉  系统调用系统编程，能够让我们在使用  时得心应手。不过，对于运维的问题定位来说，知道  这个工具，会查系统调用手册，就差不多够了。想要深入了解的同学，建议阅读《  系统编程》 《  环境高级编程》等书籍。
我们回到的使用上来，有两种运行模式。

一种是通过它启动要跟踪的进程。 用法很简单，在原本的命令前加上  即可。

比如我们要跟踪  这个命令的执行，可以这样：   

另外一种运行模式，是跟踪已经在运行的进程，在不中断进程执行的情况下，理解它在干嘛。 这种情况，给  传递个   选项即可。比如，有个在运行的 _ 服务，第一步，查看：

 _                      

得到其  然后就可以用  跟踪其执行  完成跟踪时，按    结束  即可。
 有一些选项可以调整其行为，我们这里介绍下其中几个比较常用的，然后通过示例讲解其实际应用效果。
常用选项
从一个示例命令来看      =      

 在每行输出的前面，显示毫秒级别的时间
 显示每次系统调用所花费的时间
 对于某些相关调用，把完整的环境变量，文件结构等打出来。
 跟踪目标进程，以及目标进程创建的所有子进程
 控制要跟踪的事件和跟踪行为比如指定要跟踪的系统调用名称
 把的输出单独写到指定的文件
 当系统调用的某个参数是字符串时，最多输出指定长度的内容，默认是个字节
 指定要跟踪的进程 要同时跟踪多个 重复多次选项即可。

实例 跟踪   看其启动时都访问了哪些文件     =     
部分输出
        =  
   _ =  
   _|_ =  
  _ _|_ =        
  _  =        
   _|_ =  
   _|_|_  =  
   _ =  
   _ =  
输出中，第一列显示的是进程的 接着是毫秒级别的时间，这个是  选项的效果。 每一行的最后一列，显示了该调用所花的时间，是选项的结果。
这里的输出只显示和文件访问有关的内容，这是因为我们通过  = 选项指定了。 
 问题定位案例
 定位进程异常退出
问题：机器上有个叫做  的常驻脚本，运行一分钟后会死掉。需要查出死因。
定位：进程还在运行时，通过  命令获取其   假设我们得到的  是
     
查看   我们在最后行看到如下内容：
    
     
这里可以看出，进程是被其他进程用信号杀死的。实际上，通过分析，我们发现机器上别的服务有个监控脚本，它监控一个也叫做  的进程，当发现  进程数大于时，就会把它杀死重启。结果导致我们这个  脚本被误杀。
进程被杀退出时， 会输出      代表发送给进程的信号等，那么，进程自己退出时会输出什么呢？这里有个叫做 _ 的程序，其代码如下：
 
 

     {
        
}
我们看下它退出时上能看到什么痕迹。   =  _说明：  = 表示只跟踪和进程管理相关的系统调用。
输出：
 _ _     = 
 ___  = 
 _           = 
     
可以看出，进程自己退出时调用函数，或者从函数返回 最终调用的是_系统调用， 并且会输出  为退出码。可能有人会疑惑，代码里面明明调用的是 怎么显示为_ 这是因为这里的函数不是系统调用，而是库提供的一个函数，函数的调用最终会转化为_系统调用，它会退出当前进程的所有线程。实际上，有一个叫做_的系统调用注意前面的下划线 线程退出时最终会调用它。
 定位共享内存异常
有个服务启动时报错：
    
   
错误日志大概告诉我们是获取共享内存出错，通过看下：
    = __ __
输出：
    = 
             = 
  
    =    
    
   
这里，我们通过 = 选项，让只跟踪和进程通信相关的系统调用。
从输出，我们知道是系统调用出错了，是。同样， 查询下手册页，搜索的错误码的说明：
                                       
翻译下，设置错误码的原因为下列之一：
要创建的共享内存段比 小 一般是个字节要创建的共享内存段比  大 内核参数配置指定的共享内存段已存在，其大小和调用时传递的值不同。
从输出看，我们要连的共享内存  指定的大小是字节，明显与第，种情况不匹配。那只剩下第三种情况。使用看下是否真的是大小不匹配：
   |  
                                         
                       
可以看到，已经这个已经存在，并且其大小为字节，和我们调用参数中的不匹配，于是产生了这个错误。 
在我们这个案例里面，导致共享内存大小不一致的原因，是一组程序中，其中一个编译为位，另外一个编译为位代码里面使用了这个变长数据类型。 把两个程序都编译为解决了这个问题。
这里特别说下的 选项。要跟踪某个具体的系统调用， =即可。但有时候我们要跟踪一类系统调用，比如所有和文件名有关的调用、所有和内存分配有关的调用。如果人工输入每一个具体的系统调用名称，可能容易遗漏。于是提供了几类常用的系统调用组合名字。

 =     跟踪和文件访问相关的调用参数中有文件名
 =  和进程管理相关的调用，比如_
 =  和网络通信相关的调用，比如
 =    信号发送和处理相关，比如
 =  和文件描述符相关，比如等
 = 进程见同学相关，比如等

绝大多数情况，我们使用上面的组合名字就够了。实在需要跟踪具体的系统调用时，可能需要注意库实现的差异。比如我们知道创建进程使用的是系统调用，但在里面，的调用实际上映射到了更底层的系统调用。使用时，得指定 = 指定 =什么也匹配不上。
性能分析
假如有个需求，统计  版本内核中的代码行数包含汇编和代码。这里提供两个脚本实现：
_

_=
   
    =   |  { }
     _ =  
        \         \ 
   _

_

     \         \  \
|     |   
两段代码实现的目的是一样的。 我们通过的选项来分别统计两种版本的系统调用情况和其所花的时间使用同时统计子进程的情况。
 

从两个输出可以看出，_ 只需要秒就可以得到结果：行。它大部分的调用开销是文件操作等，统计代码行数本来就是干这些事情。 而_完成同样的任务则花了秒。它大部分的调用开销都在进程和内存管理上。 实际上，从两个图中系统调用的次数我们可以看出_只需要启动个进程。 而_完成整个任务居然启动了个进程！而进程创建和销毁的代价是相当高的，性能不差才怪。
总结
当发现进程或服务异常时，我们可以通过  来跟踪其系统调用，“看看它在干啥”，进而找到异常的原因。熟悉常用系统调用，能够更好地理解和使用 。
当然，万能的  也不是真正的万能。当目标进程卡死在用户态时， 就没有输出了。 这个时候我们需要其他的跟踪手段，比如  等。安装容器 以及 初始化化本地项目
 是腾讯云内部封装的一个框架，它主要解决及公共库的版本管理、进程线程管理、公共抽离、日志搜集等功能，简洁来说，主要完成三部分功能：

类似的进程管理
在框架层集成通用服务通用数据接口、日志搜集等中间件服务
依赖版本管理及公共库

这些功能如果分开开发以及分开应用的话，个人觉得效果会更好一些。
如何安装
提供了 安装方法 和 安装方法，嗯，完美的避开了环境的安装。
可以通过以下的方式手动安装：

下载代码：  
运行  ，它完成了两个工作：

构建代码和
建立本地链接


运行  
修改文件，并且建立全局软链

把第一行代码改成 
建立全局软链：   ，需要替换成你本地的的地址。



自此，命令就可以在你的本地正常运行了。
如何初始化本地项目的依赖
以 _项为例，我们来讲讲如何安装它的本地依赖。


下载代码：   _
安装依赖： 
安装本地包依赖，分别是相关的和前端相关的组件库。
下载，然后找到运行 ，然后在_中运行  
下载_，然后在项目中运行 ，然后在_中运行  



使用启动本地
前面准备好了和项目，接下来，我们看看如何将和项目连接起来。
如何利用运行本地
理论上来说，本地项目应该跑一个    之类的命令即可运行。但是前面提过，本质上是一个框架，它将一些通用服务统一管理之后，我们的本地开发就再也离不开它了。
提供了   ，可以读取本地的配置文件启动。
那么如何提供本地的配置文件呢？
新建文件，指向对应项的配置文件。
  {
     {
         
         同样，指向你本地项目的配置文件即可
         _
    }
}
到此，你已经在某个端口启动了你的项目，你访问  能够在控制台看到对应的日志。是的，启动并监听了本地。而这，也才是第一步而已。
使用代理进行本地开发
前面启动的，你通过  访问就会遇到第一个问题：登录状态保持。
使用转发，解决同步问题
腾讯云有统一的单点登录页面，我们访问本地项目的时候，会自动跳转到登录页面，那么如何同步，保持登录状态呢？最简单的就是使用转发请求，我们安装并且修改  如下：

图： 配置 
这时，你可以通过对应的访问咱们本地的项目，也就是说，我们已经把相关的东西给串起来了。
紧接着，咱们再来把前端资源给串起来，整个项目就算能够正常运行了。
使用转发，解决等资源的代理问题
前面虽然把相关的东西成功运行起来，但是你如果通过 查看里面的等静态资源，你会发现，他们都是线上的文件而并非本地的代码，也就是说，你改了本地的文件并不会生效到页面上。因此，我们需要将这些资源文件也代理到本地，这儿我们通过来解决这个问题。
  = 
  = __ 
  = __ 

 = {
     \\\\\\
      
  }
  {
     \\\\\\
      
  }
  {
     \\\\\\
      
  }
  {
     \\
      
  }
  {
     \\
     
  }

然后通过运行    启动代理服务器。有了代理之后，我们还需要配置浏览器，将浏览器的请求打到我们的代理服务器上

图：浏览器配置 
而其中的开发模式，指向的就是代理服务器。到此为止，我们就将等静态资源映射到了本地，本地开发环境的大致样貌出来了。
使用构建代码
构建工具的引入是为了让本地开发更加高效：更高效的组织代码、运用更优秀的特性、完成自动化任务。
如何安装

安装：    
运行构建命令：  ，它会监听下的目录，然后构建输出。


图：构建输出 
是一款构建工具，它能够静态分析代码从而解析模块间的依赖并且输出一份入口文件，而入口文件中就包含相应的依赖关系。
有几个实际中遇到的问题分享一下：
首先，如果你发现的 中有报错提示找不到某些模块，很有可能是需要运行  去同步新的入口文件。
其次，如果你的代码有服务端渲染，需要在中配置，并且运行 去进行服务端渲染的编译。
最后，如果你发现配置文件报错，请第一时间联系相关开发人员寻求帮助，因为无论是还是，目前都有一些改动，可能配置项已然发生了变化。
总结说点啥
本文较为浅显的梳理了运行一个项目所需的所有步骤

安装、、组件库
对应项目，并且建立它和、组件库之间的关系
项目提供配置给，然后运行 模式，启动并监听实例
配置代理解决的同步问题
运行 ，监听代码并构建输出
配置代理，将等资源映射到本地环境
如有需要，运行  更新入口文件的依赖，配置支持服务端渲染。

整体来说，要为一个项目搭建本地开发环境还是略微有点困难，这当然有多方面的原因，其中也有一些历史的包袱。这儿抛出一些思路和想法，或许考虑不太全面，大家可以随意讨论。
将拆分？
本质上是为了统一管理实例，并且管理业务相关的一些通用服务，比如登录服务、日志统计等。
但是从一个系统的设计来说，尽量和业务解耦或许更便于维护和使用。
那么我们是否可以将至少拆分成两部分：

进程管理这一部分类似的功能本地运行的时候，读取本地项目的配置文件，应避免配置到项目中

通用服务基础库可以将部分业务相关的封装到一个基础库中，被其他项目引用可以将部分中间件服务抽离出来封装到基础库中，比如日志统计、性能统计等，被其他项目引用


最终设计成一个  ，分别负责进程管理和底层通用服务的封装，本地开发过程中，只需要引入即可。
本地尽量脱离？
本地应该尽量脱离，从而减轻本地开发环境的搭建成本。最终设计成运行     就可以让项目成功的跑起来。
这个需求很依赖前面的拆分，只要将拆分出来，作为依赖引入到本地中，那么我们的就可以独立运行而不依赖。
资源能否脱离代理配置？
现在的资源代理更多算是一种手段，各种切换代理还是会影响开发的效率。之所以需要资源代理主要有三方面的原因：

当初设计的方案是按需加载加强版，通过来实现按需加载。
模块都在线上进行管理，可以做到一次上线，全量紧急修复。
等资源来源比较复杂，可能是线上地址测试地址地址等

线上打包还是本地打包，这是一个相对的问题，本地打包可以解决频繁代理切换的问题，并且能够对本地代码有更好的掌控性。

本地打包也可以解决按需加载的问题。
对于通用业务，也可以做到全量修复，对于业务代码，不全量也更安全。
那对于不同来源的，可以继续利用的方式加载。可通过配置不同开发环境下的便于开发。

规范并精简项目结构及代码？
目前目录结构略显冗余，主要存在几个问题：

基本上是按页面拆分逻辑，会导致代码复用性不是特别方便
部分目录结构略显冗余，且模板代码较多，可考虑适当精简，采用类似的封装
目录结构的就近原则可以进一步加强，通用无业务组件抽离到公共中去，通用业务相关的组件可以考虑抽离成另一个级别的组件库，用管理。

由于对项目的历史原因并不深入了解，加之对代码的熟悉也不够深入，所以以上只是一些粗略的想法，也并没有具体深入到实现方案上，肯定有不少疏漏之处，欢迎大家拍砖！也欢迎大家讨论！
初衷就是希望本地开发能够更方便一些，代码和目录结构能够更加规范更加轻量一些。一、测试说明
使用  五种数据类型分别存储  万条数据，数据为‘’=’’。
二、测试结果

三、结果分析
测试未考虑业务场景，单纯从数据存储进行。
使用五种数据类型对相同的数据进行存储，使用容量从大到小依次为集合、列表、有序集合、字符串和哈希。
当  数量为两百万时，字符串和哈希使用容量基本一样。
当  数量为五百万是，字符串的使用容量小于哈希。
四、 版本
 
五、机器内存
 
六、测试方法
、字符串 万

  
 
前：

后：

、哈希 万


 
前：

后：

、列表 万

 

前：

后：

、集合 万


 
前：

后：

、有序集合 万


  
前：

后：

、字符串 万



前：

后：

、哈希 万


 
前：

后：导语
除了闷头专研技术之外，程序员还需要不断地写作进行技术积累，写博客是其中最重要的方式之一。商业博客平台不少，但是更符合程序员背景的方案，是自己开发一个博客平台或者使用开源的博客平台。
开源的博客平台多如牛毛，而且不乏优秀之作，如 、、、。本系列文章将分享如何利用各种博客引擎在云端搭建属于自己的个人博客。今天是第一篇，介绍如何在   上部署  博客。
 是用  开发的一个静态站点生成器  ，支持  语法写作，有着强大的插件系统，而且性能优异。阅读不少技术社区分享的文章时，看到国内不少同学都有在用这个引擎，看来「市场占有率」不低。
本文将介绍如何在一台   的  云服务器上快速部署  博客站点，如何快速发布一篇博文并通过云服务器上的私有  仓库部署到  服务器目录下。
前提条件
如果想跟着本教程顺利完成  博客的搭建，需要具备以下条件：

一台安装了   的  云服务器。一般个人博客的流量都比较低，初期选择 核 内存类型的服务器即可，而且有不少免费试用的时间。

在本地电脑上安装  和 ，建议谷歌相应关键词了解具体步骤。


此外，还要在云服务器上安装  和  两个必备的软件包。 用于版本管理和部署， 用于静态博客托管。
  
     
另外，本文均以  为例，演示在本地端的操作， 上的操作会更为简单。 上没有  的  ，我们以     组成的终端作为替代。如果有读者感兴趣，后续再撰文介绍具体配置方法。

 本地  安装及初始化
 上还有许多  相关的包，但是只要安装好了  和  这两个核心组件之后，就可以让博客跑起来了。
我们使用  的包管理器  安装  和 。
    
 是  的命令行工具，可用于快速新建、发布、部署博客； 是  的内建服务器，可用于部署前的预览和测试。 选项，表示全局安装。
接下来，为  博客做一些基础配置，包括创建基础文件。这步操作很简单， 提供了一个快捷命令，只需要提供一个存放文件的目录地址即可。
  _
在国内环境下执行该命令，速度会有些慢。因为需要从  在  上的仓库克隆；仓库克隆成功后，会自动执行一系列  命令，自安装依赖模块。
这时，我们就已经有了一个写作、管理博客的环境。
 云端服务器配置
完成本地端的操作之后，暂时回到服务器的配置。在下面的操作之前，请确保已经购买了一台云服务器，并且能够以  用户身份正常登陆。
在这部分，要完成以下件事情：

为本地的 _ 配置一个部署静态文件的远程仓库。
许多教程均以  作为中转的平台，但是会让整个流程变得更为复杂，而且会受服务器与  之间网络情况的影响。假如  宕机或者被封，你将无法更新博客。

配置  托管博客文件目录。

配置远程仓库自动更新到博客文件目录的钩子。


 创建私有  仓库
在  下，创建一个名为 _ 的裸仓库 。
如果没有  目录，需要先创建；然后修改目录的所有权和用户权限，之后  用户都具备  目录下所有新生成的目录和文件的权限。
  
    
    
然后，执行如下命令：
 
   _
 配置  托管文件目录
接下来，创建  目录，用于  托管。
   
和上一步类似，这里也需要修改目录的所有权和权限。
    
    
然后，修改  的  设置：
  
将其中的  指令指向  目录。


 {
      _
      _ =

       需要修改的部分
      

保存并退出文件。如果以后购买并备案域名之后，可以再将配置中的 _ 修改为你的域名。
最后，重启  服务，使得改动生效。
   
做完这一步之后，你去访问服务器的  时，应该还是会报错的，因为  目录是空的。
 创建  钩子
接下来，在服务器上的裸仓库 _ 创建一个钩子，在满足特定条件时将静态  文件传送到  服务器的目录下，即 。
在自动生成的  目录下创建一个新的钩子文件：
 _
在该文件中添加两行代码，指定  的工作树源代码和  目录配置文件等。


 = =_  
保存并退出文件，并让该文件变为可执行文件。
  _
至此，服务端的配置基本结束。
 完成本地  配置
在第三部分的操作中，我们将完成以下任务：

修改  配置中的  和默认文章版式

新建博客草稿并发布

配置自动部署到服务器端的 _ 裸仓库


 修改  部分默认配置
进入 _ 目录后，主要有以下文件。
        _
         
           _
         
           
           
           
           
其中，_ 为  的主配置文件。我们首先修改博客的  地址。
 
                

   没有绑定域名时填写服务器的实际  地址。
 
 
_

接下来，修改 _，该字段位于在  部分。将其从  修改为  ，表示每篇博文默认都是草稿，必须经过发布之后才能在博客站点上访问。

 
__       
_   原来的值是 
      
暂时保存并退出文件。在  部分继续进行配置。
 新建博客草稿并发布
这里简单演示通过  新建博文草稿，并发布的过程。
执行如下命令，创建第一篇博文。
  
你会看到类似如下输出：
   \\\_\\_\
在本地通过自己熟悉的编辑器，编辑博文。这里，我们把本文的内容写入第一篇博客中。
 在   服务器上部署  博客

   
   

   
 
  


 以下为  文章正文。

然后，通过如下命令发布博客：
  
输出类似下面这样：
   \\\_\\_\
博客推送到服务器之后，就可以在网站上访问了。
 通过  部署
到了这一步，可以说万事俱备，只欠东风了。这个东风，就是通过  将  生成的静态内容推送到服务器。
继续编辑 _ 文件，找到  部分，按照如下情况修改：

     
      云服务器的地址_
     

保存并退出文件。
之后，需要安装一个  包，负责将博客所需的静态内容发送到设置好的  仓库。
   
安装好后可以测试部署：
    
期间可能会提示输入  用户的登录密码如果没有设置  登录。成功之后的输出大致如下：

    
    
          _
 _
           
    
现在，我们就可以在浏览器中打开 ，即可看到自己的博客网站了。
我们发现， 对  标签的样式并不太美观，需要后续再调优。

 通过镜像快速部署
本文虽然将  博客的大致部署过程明确地列出，但是对于部分初学用户来说可能还会显得较为复杂。如何利用  云服务器提供商即腾讯云的其他服务，快速让其他用户不必经过上面的步骤，快速进行部署呢？
在云计算中，与虚拟机相关的一个概念是镜像。用户通过镜像，可以一键启动多个配置一模一样的云服务器。我们这一步通过  的「制作系统镜像」功能，将  博客的服务器端打包。

打包后的镜像，还可以上传到官方的服务市场，供所有用户使用；还可以直接共享给其他用户。
如果有用户希望使用该镜像，可在本文下方评论区留下自己的腾讯云账号登录时使用的号或邮箱。
 镜像的使用
镜像中已经设置好了服务端，通过镜像启动  云服务器之后，读者只需要根据本文第三部分「完成  本地配置」中的步骤，设置好本地  写作环境的部署地址和服务器 等参数即可。
这里有一点一定要注意，通过镜像启动云服务器时，务必重新设置密码或密钥，否则镜像的制作者有可能轻松地登录你的服务器。

不要选择上图中的方式安装。
总结
本文较为完整地介绍了  博客的安装及初始化，服务端如何配置通过  部署等。与其他教程不同，我们没有使用公开的  等第三方服务，而是直接在服务器上创建了私有仓库。然后，通过  钩子，将  生成的博客静态文件，快速地推送到  服务的托管目录。
由于  是采用  开发的，可能对于其他语言的学习者来说吸引力不大，因为后续自主二次开发难度较高。因此，后续笔者还将介绍其他语言的博客引擎，如用  编写的  和用  编写的  等。
敬请期待。

相关推荐利用搭建数据科学博客免费体验腾讯云服务器，快速上云【腾讯云的种玩法】快速通过搭建个人博客导语
机器学习算法性能很差怎么办？过拟合和欠拟合是什么？调优方法有哪些？如何高效运用？
大家知道最近  非常火，经常看到各种相关技术介绍，像什么论坛啊、牛人讲座啊，当然网上也有很多非常好的大牛的教程，像最近公司刚跟优达学城合作，提供了很多免费的课程。相信大家或多或少都了解到一些机器学习的相关技术和算法了，有些同学可能也用过一些算法，然后就感觉自己可以称之为懂机器学习了。我曾经也是这么认为的，但是后来发现真正懂机器学习的人是确实知道如何高效运用的，而另一些人，像我这种，其实并没有完全理解，所以总是把时间浪费在一些毫无意义的尝试上面。最近我在学习吴恩达的   课程中看到他讲的关于如何高效对机器学习效果进行调优的内容，感觉非常有用，想给大家分享下。
大概会从三个方面进行介绍，首先会给大家讲一个简单的例子，了解为什么要做调优这件事情。然后会介绍一些具体的调优方法。最后会对这些调优方法进行一个总结概括。
一、引子

我们都知道机器学习的应用范围很广，算法也有很多种，耳熟能详像逻辑回归，，神经网络等算法。在用这些算法的过程中可能会遇到效果不能达到预期的情况，这个时候就需要对算法和模型进行调优。我们先来看一个例子。
 过拟合
这里我们来看一个识别天鹅的例子：
打个形象的比方，有一些天鹅的图片，让机器通过这些图片来学习天鹅的特征，经过训练后，知道了天鹅是有翅膀的，天鹅的嘴巴是长长的弯曲的，天鹅的脖子是长长的有点曲度，天鹅的整个体型像一个且略大于鸭子。这时候机器已经基本能区别天鹅和其他动物了。
然后，很不巧已有的天鹅图片全是白天鹅的，于是机器经过学习后，会认为天鹅的羽毛都是白的，以后看到羽毛是黑的天鹅就会认为那不是天鹅。

好，来分析一下上面这个例子： 中的规律都是对的，所有的天鹅都有的特征，是全局特征；然而， 中的规律：天鹅的羽毛是白的。这实际上并不是所有天鹅都有的特征，只是局部样本的特征。机器在学习全局特征的同时，又学习了局部特征，这才导致了不能识别黑天鹅的情况。
机器在学习过程中是无法区别局部特征和全局特征的，学习的局部特征比重越多，那么新样本中不具有这些局部特征但具有所有全局特征的样本也越多，于是机器能识别到的正确样本的概率就会下降，也就是所谓的泛化性变差，这是过拟合会造成的最大问题。
所谓过拟合，就是指把学习进行的太彻底，把样本数据的几乎所有特征都学习到了，于是机器学到了过多的局部特征，过多的由于噪声带来的假特征，造成模型的泛化性和识别正确率几乎达到谷点，于是用这个机器识别新的样本的时候会发现就没几个是正确识别的。
解决过拟合的方法，其基本原理就是限制机器的学习，使机器学习特征时学得不那么彻底，因此这样就可以降低机器学到局部特征和错误特征的几率，使得识别正确率得到优化。
从上面的分析可以看出，要防止过拟合，训练数据的选取也是很关键的，良好的训练数据本身的局部特征应尽可能少，噪声也尽可能小。
欠拟合
我们再来看一下对应欠拟合的情况。同样让机器学习一堆天鹅图片的特征，然后经过训练后，知道了天鹅是有翅膀的，天鹅的嘴巴是长长的。因为具备这两个特征的动物很多，像鸭子、鹦鹉都具有这些特征，所以这时候让机器去区别天鹅和其他动物，效果是很差的。因为机器学习到的天鹅特征太少了，导致区分标准太粗糙，不能准确识别出天鹅。这个时候就需要去扩充天鹅的特征，让特征更为具体些。
 
二、调优方法选取
为了避免过拟合和欠拟合的情况，我们可以进行哪些优化呢？一提到模型优化，可能我们最容易想到的就是增大或者减小训练集，这算是一个方向；获取更多或者更少特性，这也是一个方向；除此以外，还有一些增加多项式特征、增加或者减少正则化参数λ等都是行之有效的方法。如下所示：
•     获取更多训练样本
•     尝试少些特征
•     尝试增大λ
•     尝试更多特征•     尝试增加多项式特征，
•     尝试减小λ
这上面列的很多方法都可以扩展成一个六个月或者更长时间的项目。其实大部分人都是随随便便试一试，可能花费了六个月后发现这是一条不归路。其实是可以通过诊断，排除掉单子上至少一半的方法，留下真正有效的方法的，这样的话，可以节省大量不必要的时间开销。那到底如何做到这一点呢？接下来让我们看看如何判断什么时候该选取什么方法。
假设函数 
为了介绍判断方法，我们首先来了解下假设函数。我们来看个预测房价的例子，如下图所示，这里仅考虑房屋面积对房价的影响。红叉叉是实际房价，蓝线是预测的房价。
如果我们用一条直线来拟合实际房价，如下图中左图所示，可以看到这些红叉叉基本上都不在蓝线上，并且有一定偏差。
为了更好的拟合这些红叉叉，我们改用一个  次函数来拟合，如中间这幅图所示，可以看到这些红叉叉基本上都在蓝线上或者临近的地方，偏差不算太大。
我们想继续减小偏差，于是用一个  次函数来拟合，如右图所示，可以看到几乎所有红叉叉都在线上，偏差趋于 。
 
以上所用的这些函数就是假设函数。可以看到随着假设函数的次数越来越高，越来越复杂，对样本的拟合程度会越来越好。但是大家有没有想过，如果用右边这个函数来预测房价会有什么问题吗？因为这个函数对训练样本，也就是上面这些红叉叉拟合得太精确了，导致了过拟合，所以如果要预测一个训练集中从未出现过的样本的时候，它会缺乏预测能力，效果会很差。当然效果的好坏并不能全凭我们肉眼观察，特别对于更多样本、更多维度等更复杂的情况，我们应该如何选取最佳的假设函数呢。
评估假设函数 
让我们来看看评估假设函数效果的方法。这里我们仍然以预测房价为例子，我们有一个  个数据样本的数据集，从中随机选择  个样本作为训练集，剩下  个作为测试集，为什么这么选，是因为 ，这种配比是最常见的一种，当然也可以有其他选择。
 
这里我们要评估  种线性回归的假设函数，如上图所示，通过分别针对每个假设函数进行训练，最小化训练集的偏差，我们可以得到每个假设函数的参数 θ；然后把参数代入假设函数中，去计算测试集的总偏差，对比每个假设函数的测试集总偏差，选出最小的那个，就是我们认为最好的假设函数了。

这里提出一个问题。如上所示，可能大家会说简直是送分题，不就是  吗？其实并不一定。因为  是在特定测试集上的效果最好，所以它对于这个测试集中的那些样本是适配得最好的，但是如果换一个测试集就不一定了。所以如果以此作为判断来选取假设函数，其实并不公平。这样选取出来的假设函数对于从未出现过的新样本来说，并不一定支持得很好。所以为了解决这个问题，下面介绍改良版的评估假设函数的方法。
评估假设函数 
同样我们有  个样本，然后从中随机选取 作为训练集，作为交叉验证集 ，剩下 作为测试集。，，，这种配比，也是一种常规选择方法，当然也可以有所变化。

同样我们分别将  个假设函数用于训练集的训练，通过最小化训练集上的总偏差得到参数θ，然后分别将θ用于交叉验证集，计算出各自在交叉验证集上的总偏差，以此作为标准，对比选出最小的那个，例如是 ，然后将  对应的参数θ在测试集上进行验证，计算出测试集上的总偏差，这才能评估  这个假设函数真正的性能。
高偏差  高度不一致诊断
实际情况中我们不可能穷举所有假设函数，对比选出他们中效果最好的那个。我们只会选取少数几个假设函数进行评估，那么当我们针对一个假设函数，算出训练集和交叉验证集的偏差后，如何选择方法进行下一步优化呢？这里画一张关于假设函数的维度大小跟数据集总偏差的关系图：

横坐标是假设函数的维度，也就是前面所说的  次、 次这种。纵坐标是数据集的总偏差。这里包括训练集和交叉验证集的总偏差两种。
我们知道当维度很低时，如一次函数，非常简单，所以在拟合训练集时，偏差会很大，同样把它用在交叉验证集上时，偏差也是很大的。但是因为有针对训练集做参数优化，所以交叉验证集的偏差还是会比训练集更大一些。所以就画出图上左边这部分，此时就是所谓的欠拟合状态，习惯上也叫高偏差状态，即训练集和交叉验证集的偏差都很高。
然后增加维度，如我们前面所说的  次函数，它的复杂性会适当提高，于是能更好的拟合训练集上的样本，于是训练集上的偏差会降低。对于交叉验证集来说，也会拟合得更好，所以交叉验证集的偏差也会降低。
继续增大维度，当维度过大时，如前面所说的  次函数，它的复杂性很高，所以对于训练集来说可以非常好的拟合，于是训练集偏差会继续下降，甚至趋于 。但是因为复杂度过高，对于新样本泛化能力会变弱，所以对于交叉验证集来说，偏差会大大提高。即图中右边部分。此时就是过拟合状态，习惯上也叫高度不一致状态，即训练集的偏差和交叉验证集的偏差高度不一致。
通过这幅图可以看出：

在高偏差的时候，训练集和交叉验证集的偏差都很大，且相近；

而在高度不一致的时候，训练集的偏差很小，但是交叉验证集的偏差非常大，远远大于训练集偏差。


所以通过这种性质就能判断模型当前是高偏差还是高不一致，就可以对此采用行之有效的方法去解决。如果发现是高偏差可以提高假设函数的维度，如果是高不一致可以降低假设函数的维度。这就是一种解决方法。下面我们来认识另一种解决方法——正则化。
正则化
在实际应用中欠拟合的状态是比较容易发现的，因为在训练时就可知道，但是过拟合是比较难发现的。为了防止过拟合，我们在训练时，对训练集总偏差引入一个正则化项，也就是下图中黄色框框所示这部分，它的目的是让参数尽可能小，避免参数过多过大。

例如：对于这个  次假设函数来说，在它的总偏差后面加上这样一个正则化项，也就是将参数到 的平方累加起来，前面乘上一个λ，其中  是训练集样本数。
因为在训练模型时，我们的目的是让训练集的总偏差最小，所以在引入正则化项后，会更多的考虑让参数变小一些。特别是如果当 λ 非常大如  时，参数到会趋近 ，这时候，我们的假设函数会约等于，于是就变成一条直线，转变为欠拟合问题。相反，当 λ 很小，趋近于  时，就会让参数变大，于是就更倾向于没有正则化项的时候，也就是回到了过拟合问题。
既然 λ 这么有用，那么我们如何找到一个最佳的 λ 呢？

这里我们列出一系列 λ 的取值通常会按照  的指数次方这种模式进行选取，针对每个 λ 进行训练，最小化训练集上的总偏差，得到各自对应的一组参数 θ，然后将各自的参数 θ 应用到交叉验证集上，算出交叉验证集上的总偏差 ，然后对比选出最小的那个，这里假如是第  个，然后就用这一组参数对测试集进行验证，就得到了测试集上的总偏差。
这里提出一个思考，也是容易误解的地方，我之前也是不小心掉进了这个坑：
不是说在计算总偏差时要加上正则化项吗？为何计算测试集偏差时不加上呢？
其实不管是计算训练集、还是交叉测试集、还是测试集的总偏差时，都不用也不能加上正则化式，因为它只是在训练时为了提高训练效果采用的一个技巧而已，跟偏差本身并没有半毛钱关系。这点需要理解清楚，不然就没理解为啥要用 λ 。
为了进一步理解正则化参数 λ 对数据集偏差的影响，我们也来画一张它们之间的关系图：

当 λ 很大的时候，参数会变小，更倾向于一条直线，所以模拟函数会变简单，倾向于欠拟合，所以训练集偏差很大，交叉验证集的偏差也很大，且两者近似。
这时候减小 λ，参数会变大，模拟函数会稍微复杂一些，拟合程度会提高，所以训练集和交叉验证集的偏差都会降低。
继续减小 λ，到λ很小的时候，参数会继续变大，模拟函数会更复杂，拟合程度会更好，更容易出现过拟合，所以训练集偏差很小，但是交叉验证集偏差很大。
于是就得到图中这样两条曲线。中间会有一个点让交叉验证集上的偏差最小。对应的λ就是我们要求的最优 λ 。
所以可以根据这个图确定当前所处的状态，并可以据此调节 λ 来提高模型效果。
学习曲线 
下面介绍另一种很有用的工具，学习曲线。通过画出学习曲线，也可以判断当前模型是否处于高偏差或者高不一致状态。学习曲线反应的是训练集大小跟数据集总偏差之间的关系，下面我们看下怎么画出一条学习曲线。

我们首先来画训练集的：
这里我们选取假设函数为一个二次函数，当样本数为  时，用二次函数很容易拟合一个点，误差绝对也很小，当样本数为  时也可以完全拟合，然后继续增加样本数到 、，也还是可以基本拟合，只是误差会逐渐变大一点。事实上随着训练集越来越大，会发现拟合所有点越来越困难了，也就是说误差会越来越大。于是我们得到一条学习曲线，如浅蓝色曲线所示。
那对交叉验证集来说误差又会如何变化呢？当训练集样本很少时，泛化程度很差，对新样本的适应能力很差，所以误差会非常大。随着训练样本的增加，泛化程度会越来越好，对新样本的适应能力会越来越强，所以误差会越来越小。就得到了关于交叉验证集的红色的这条学习曲线。
下面我们来看下过拟合和欠拟合，也可以是高偏差状态下的学习曲线是什么样子。

假设我们用一条直线来拟合我们的训练集，当只有一个样本的时候，可以完全拟合，所以误差为 ，然后随着样本的增加，它很快就不能很好的拟合这些样本了。所以误差会越来越大，当找到一个最佳拟合的直线后，再增大训练集，发现误差也不会有太大变化了，所以趋于平直。大致也就是淡蓝色曲线所示的样子。
而交叉验证集的误差如何变化呢？一开始同样因为泛化能力差，所以误差很大，然后随着样本增加，泛化能力变强所以误差会降低，然后等到找到最佳拟合直线后，误差就基本上不会怎么变化了，趋于平直，并且误差跟训练集相近。
所以在高偏差的情况下呢，无论如何增大训练集样本，训练集和交叉验证集的误差都会处于一个比较高的水平，而且两者比较接近。
所以当我们发现画出的学习曲线中，交叉验证集误差不会随着横坐标的增大而有明显下降，而是变为水平了，就说明算法处于高偏差的情况，这个时候增大训练集，对于改善算法并没有太大用处，所以也不要在这上面做太多无用功了。
接下来再让我们看下高不一致的情况吧。

我们选用一个超级复杂的假设函数，一个  次的函数，即使用了正则化，λ 也非常小。这时候如果要用这个函数去拟合几个点，会发现拟合得非常非常好，继续增大训练集，虽然误差有所上升，但仍然拟合得非常好。误差始终处于一个相对较低的水平。
但是对于交叉验证集误差来说又如何呢？同样当样本非常少时，由于缺乏泛化能力，所以误差很高，随着样本的增加，误差有所下降，但是因为存在过拟合的情况，所以交叉验证集的误差始终很高。所以在训练集和交叉验证集之间存在着一个很大的差距。
同时从图中可以看出如果继续增大训练集，也就是把图中的线往右边延伸，两条曲线是在逐渐逼近的，虽然训练集误差在增大，但我们更关注的交叉验证集的误差在减小，所以增大训练样本在过拟合的情况下是有意义的。
当然我们上面画的这些学习曲线都是理想情况下的，实际中可能会出现一点噪声或者干扰，但大体上还是差不多的。所以可以通过画出学习曲线，帮助我们去判断当前算法模型是处于高偏差还是高不一致，还是两者都有的情形。这样可以节省不少时间。
三、总结
通过前面介绍的这些判断方法，就可以判断当前算法模型所处状态，一旦我们确定当前算法是过拟合还是欠拟合后，就可以采取对应的方法进行调优了。
总结起来就是这些方法。

针对过拟合

获取更多训练样本

尝试少些特征

尝试增大 λ



针对欠拟合

尝试更多特征
尝试增加多项式特征，

尝试减小 λ




针对过拟合的场景：我们可以获取更多训练样本，这样可以覆盖更多场景。第二个呢，可以尝试少一些特征，这样模拟函数会简单一些。也可以尝试增大正则化参数 λ，这样函数参数会变小一些，模拟函数会更倾向于简单。
相反，针对欠拟合的情况呢：可以尝试更多特征，让模拟函数复杂一些；也可以尝试增加多项式特征，也是为了让模拟函数复杂一些。还可以尝试减小 λ，这样函数参数会变大一些，模拟函数会更倾向于复杂。
最后我们来看看在神经网络中，如何判断和解决过拟合欠拟合问题。

当设计神经网络算法时，首先要选择层次。最常用的神经网络是三层，也就是一个隐藏层，当神经网络层次很少，然后每一层的节点很少的时候，对应的参数就很少，模型就更简单，计算就更简单，但是也更容易出现欠拟合；
当神经网络层次很多，或者每一层的节点很多的时候，对应的参数就很多，模型就会很复杂，计算开销也会很大，也就更容易出现过拟合。一个很有效的避免过拟合的方法就是使用正则化项。前面我们也提到了增大正则化参数 λ 对避免过拟合的好处。
实际应用中可以把数据集拆分成训练集、交叉训练集和测试集，然后用交叉验证的方法来尝试多种层次和节点个数，对比他们的效果，最终选定一个最佳的神经网络结构。作者： 


  发布之后公示了很多新特性，其中一些特性继承在了 当中，这些不易被我们发现比如新的签名机制   ，本文对  新推出来的新签名打包机制新签名方案作出相关分析，目前在 以及之上版本已经对这套新签名机制提供了支持，因此随着版本的提升，新签名机制方案将是大势所趋。
新签名机制集成在了  以及之上版本的插件当中，默认是开启的，它的优点在于加块了包签名验证的过程，减少了包安装的时间，增强了包的完整性保障。对于新签名打包机制，想在签名过后的包内容做任何改动都会导致在 以及之上版本安装不成功。
最后本文实现了一种在的签名块中写入信息，读取信息，删除信息还原等功能，验证了在签名块中写入信息可以通过检验的例子。
现在我们就来一起看看新的签名机制是啥样的。
起源
在此之前我们得先大概了解一下老的签名方案后面以表示老签名方案是什么样的，看看它到底存在哪些问题使得提出一套更好的签名校验机制呢。

签名方案我们都知道在签名之后，打开包，在目录下的—目录下一般有三个文件：三个文件，这里用不同的证书和签名方式得到的名字可能不同，以及对于多个证书的情况就会对应有多个文件。 文件当中的原始文件信息用摘要算法如计算得到的摘要信息并用编码保存，以及对应采用的摘要算法如这个算法的特性是不管多大的文件内容都能够得到长度相同的摘要信息但是不同的文件内容信息得到的摘要信息肯定不同 文件文件的摘要信息以及文件当中每个条目在用摘要算法计算得到的摘要信息并用编码保存 文件存放证书信息，公钥信息，以及用私钥对文件的加密数据即签名信息，这段数据是无法伪造的，除非有私钥，另外文件还记录了所用的签名算法等信息。包在安装的时候，是按照从到的顺序依次校验的，先用公钥还原签名信息，然后和文件中的信息比对，然后用同样的摘要算法对文件里面的每一个条目计算对应的摘要信息，然后比对文件是否一致。

在这个过程中，我们发现有两点： 在校验的过程中需要解压，因为文件的摘要信息是基于原始未压缩文件内容，因此在校验的时候就需要解压出原始数据，而这个解压操作无疑是耗时操作。 包的完整性校验不够强。这里可以看到如果我们在签名后，如果对包中没有涉及到原始文件内容的数据块做改变那么这层校验机制就会失效如直接通过二进制改变包的无关数据块如核心中央目录注释字段写一些无关注释，然后用工具对齐，则包还是可以正常安装的，这样就绕过了层的校验机制
由此模式的签名机制提出来了。看看是怎么改善上述两个问题的。
问题：耗时问题签名机制不存在解压原始数据，签名校验时间显著减少，因此安装时间也相应减少。
问题：一致性校验是否够强签名机制是直接基于的二进制内容做的签名信息签名块本身不参与加密校验，因此打包后改变的原来三部分的任何字节都会导致签名校验不通过。
采用签名机制也有一些苦恼，那就是在签名之后对包中的任何改动都不再允许了，否则在大于等于 之上版本就会安装不成功。默认的   是开启了签名机制的，当然我们是可以选择关掉的，可以在中的闭包中如下面配置：
 
 
当然我们签名机制也是提供了命令行方式可以签名的。用工具工具不兼容签名
 签名模式具体详解
简单来说，签名模式在原先块中增加了一个新的块签名块，新的块存储了签名，摘要，签名算法，证书链，额外属性等信息，这个块有特定的格式，具体格式分析见后文，先看下现在成什么样子了。

的格式签名后变成了下面个部分：
         第一部分开始
      
    可选
   
      
      
    可选   第一部分结束

           签名块

      第二部分开始
   
      第二部分结束
        第三部分
其中第三部分有一个偏移值直接指向了第二部分的开始位置，而每个第二部分如  …  的有一个偏移字段指向了其中对应的第一部分。
    

    
签名块包括对第一部分，第二部分，第三部分的二进制内容做加密保护，摘要算法以及签名算法。签名块本身不做加密，这里需要特殊注意的是由于第三部分包含了对第二部分的引用偏移，因此如果签名块做了改变，比如在签名过程中增加一种签名算法，或者增加签名者等信息就会导致这个引用偏移发生改变，因此在算摘要的时候需要剔除这个因素要以第三部分对签名块的偏移来做计算。
 签名块格式
接下来我们来看看具体的签名块的格式，具体参考源码，如下图所示：
该格式分为个部分，都很好理解，其中块大小不包含第一块本身的字节：其中第二部分包含了模式块，模式块的具体格式稍复杂如下图右边所示，模式块对应的为：

 分块计算摘要信息
从上面我们可以看到模式块有点类似于我们文件夹下的信息内容。那么对于上述当中摘要的信息又是怎么计算出来的呢。如下图：

首先将上述中第一部分，第二部分，第三部分按照大小分割成一些小块。对于每个小块如图中第二层上每个摘要信息取的信息来源是级联对应块上字节，块字节长度，块内容。顶部第一层的摘要信息取的信息来源是级联字节，对应块的数目，以及中第二层如按照对应顺序，…的摘要信息的级联。计算这个信息可以可以采用并行计算。
 实际二进制信息查看签名块信息
接下来，来一个实际用  打的包，来看看里面的信息内容是怎样的吧。
首先找到对应包中第三部分

找到标识符然后定位到偏移核心中央目录的偏移字段。
然后定位到，找到了中第二部分，按照现在的格式，在这个部分上面就应该是签名块了。看看这部分的数据是不是这样：

我们看到处的个字节为这刚好是核心重要目录的标识符，往上个字节就是签名块的魔法数               代表：”   “的固定值，以大端存储。
在往上个字节就是签名块的大小：这里可以看到大小为：所以这里我们根据块大小和魔法数位置可以快速定位到签名块的开始位置偏移处，通过计算=定位到处，往后个字节也为块大小，发现两个块大小的确一致。接下来开始分析  块的格式，如下图所示：

由上面签名块格式中我们可以知道，在模式块部分当中，包含了长度，以及值，其中以特殊标识=开始，值则为模式块当中的具体内容。




从这里看到接下来的数据就是属于签名模式块的数据格式了，如图一右边所示以及图所示
接下来按照图二的格式依次解析：

可以看到在下面有一处为：
签名算法：
长度前缀 

其中表明用的签名算法是：_   
 签名校验过程
接下来我们来看签名的校验过程，整体大概流程如下图所示：

其中签名机制是在 以及以上版本才支持。因此对于 以及以上版本在安装过程中，如果发现有签名块，则必须走签名机制，不能绕过。否则降级走签名机制。和签名机制是可以同时存在的，其中对于和版本同时存在的时候，版本的_的文件属性当中有一个 属性：

 
因此如果想绕过走校验是不行的。
 签名校验信息内容
 的签名块 签名块中的两个字节大小字段是否相等 的第三部分和第二部分是紧挨着的，且核心中央目录在前面。 第三部分后面没有任何多余的数据。
 定位到模式签名块，如果存在的话，即存在=的调到步骤否则降级为校验。
  对于每个签名者的签名块具体格式见上面图 从签名当中选择系统支持的最强的签名算法 用公钥还原模式块中的签名信息，并比对是否和图中原始的加密数据是否一致。 比对模式块中加密数据和签名信息所用的签名算法列表是否一致。 用同样的摘要算法计算内容对应块的摘要，和签名块中的摘要信息是否一致。 比对公钥信息当中所用数字证书是否一致。
校验成功定义：至少找到其中一个签名者的签名信息，以及每个签名者的签名信息都校验成功。
  新签名写入渠道号信息的实现
至此，模式的新签名机制就结束了。新的模式签名机制提醒我们在签名之后，对本身做任何改动都会导致校验不通过的情况，导致在 以及之上都会安装不成功。歌由于一些原因需要在上打包签名的最后一步会对的注释字段会写部分信息，那么按照新的机制，则打出来的包在 必然存在安装不上的情况。下面是失败提醒：

因此对于 的签名过程必然是发生在最后一步，如果非要写部分信息，考虑是否可以写到签名块当中，因为签名块本身是没有加密的。这里也实现了一下渠道包的写入，经过检验，成功通过了和的校验。核心部分就是下面这个函数。具体可以查看源码 。
        {
        上面就是原始的个块接下来开始重点改造第二个块，然后重写对应的偏移即可喽。
          ==  ||    {
                
                
        }

          = 
          =
                  
                                  
                           
                           
                           
                
          = 
        _
          =   
         被修改了

          =    这个值还没变
        
        _____
        

        _
        

        
        ___

         
    }
具体用法如下：
    原  签名后  渠道号名字

由于涉猎知识有限，本文讲述的内容难免有误。如有误的地方，望不吝指出。近日，记者从国家知识产权局了解到，腾讯公司正式向国家知识产权局提交了一份关于图片编码技术的专利申请。此项专利被命名为  ，在数据上图片格式产生的文件大小明显小于、、、等业界主流的图片格式，处于世界领先水平。
资料显示，此项专利技术由腾讯音视频实验室基于内核自主研发。据了解，腾讯音视频实验室，其前身是腾讯公司即通产品部音视频技术中心，主要致力于音视频及图像处理技术的研究和创新工作。

图片格式压缩率世界领先
腾讯申请新专利的图片格式到底有何不同？
通过目前已经公开的测试数据对比就可以一较高低。在同等质量的前提下，与、、、等不同图片格式进行对比，的文件大小最小，位居第一：对小以上，比小以上，对格式图片采用编码可以小以上，对比采用编码的格式则能够小。相对推出的 格式，文件大小可以减少近。






可以看到，对比非常明显，在保证同样的清晰度的前提下，图片格式普遍小于其他格式。
如果换个角度来看，文件大小相同的话，使用编码会不会更清晰？通过与质量对比可以看出，的图片的效果差，而的图片会更清晰。

除了在文件大小方面的优势，在渐进式、透明通道、动态格式、高清、无损等核心指标上，实现全面性能优化。

小步快跑决胜负，腾讯创新力不可小觑
一个高效的图片编码算法能大大降低带宽和存储成本，这种创新对于正在飞速发展的中国互联网行业来说，显得尤为重要。
据了解，图片编码技术未来可以被广泛应用在社交应用、新闻客户端、浏览器、游戏等多个领域。一旦在整个中国互联网行业推广开，不但能为互联网公司省下大量成本，也能给用户节省图片流量，降低用户加载图片的等待时间，提升用户体验。
那么，图片文件减少几十，这样细微的创新与优化，对一个企业来说意味着什么？
腾讯的微创新从来都不可小觑，与的对决是最有代表性的案例：年，拥有亿用户的进入中国市场，凭借免费绑定策略、高端品牌形象、强大的邮箱，迅速打开中国的商务通讯市场。据易观国际当年的数据统计，在当时约万的商务用户当中，用户约万，占比，在这块市场上，此时的相比处于劣势。但最终的结果是战胜了，打赢了自己的保卫战。
马化腾在回忆起那段历史时曾说到：“那时候很强势，基本上大家认为是死定的，只是什么时候死而已。但我们针对国内网络结构做了大量的优化。我们传文件很快，有聊天室，包括我们的头像是个性化的，口碑就这样建立起来了。”除了他提到的传文件、聊天室等，后期推出的屏幕截图、文件断点续传等小的技术创新，都为最终成为中国国民级的社交工具，打下了坚实的基础。今天，腾讯仍然在不断地进行着技术的创新和迭代，从细微之处的创新积累出今天在整个世界互联网的实力和地位。
：雷锋网回调地狱
一个段子
以前有个段子讲一个小偷，潜入某神秘机构，偷出代码最后一页，打开一看：
                                        }
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }
    }
}

什么？这只是段子不是现实？那看看现实版快滴打车的源代码：

因为的异步特性，每个开发者都无法避免会碰到一些 ，同时在代码的迭代过程当中因为这样一些 导致代码越来越不可维护。尤其是当回调过程中去参杂一些同步逻辑判断，那都是迭代过程中的代码杀手。
一个例子
产品：我们需要从服务器取数据，然后再
开发：搞定
  {
      {
          
    }
}

产品：我们要插个小功能，取另一分数据，然后再
开发：
  {
      {
          {
              
        }
    }
}

产品：需要在取第二份数据前加个小判断，部分用户不需要取第二份数据。
开发：改起来会有点麻烦。
产品：不就加个条件判断么？怎么会麻烦。
开发：
  {
      {
          =   {
              
        }
          {
              {
                
            }
        }  {
            
        }
    }
}

产品：再帮我加一个很小的功能。
开发：
解套平坑
解决方案
其实 一直在避免回调地狱的问题做出努力，比如，包括下的， 等等。这里不去细讲，想进一步了解这些解决方案的差异的话可以看尤雨溪大神在直呼上的回答：异步控制「、、 、『原生』、、」有何优缺点？最爱哪个？哪个简单？
 
这里要讲的是一种更平滑更接近同步体验的一种方案 。
语法最早是在中引入，引入后引起了一致好评，因此使用异步编程最多的迫不及待的向提交了草案，但因为某些原因，呼声很高的 并没能赶上的，估计最晚会在中加入到正式规范，但是并不妨碍我们在的帮助下在的环境下使用它。
先看看在使用 的情况下，上面产品需求的代码开发将会怎么实现：
    {
      
     =  
      {
         =  
    }
      
}

加入了神奇的和关键字后，上面的异步回调完全以同步的方式展现，也不用去担心产品需要再在某个回调中插入流程了而且导致代码结构大面积改动了。
实现方式
编译 需要插件，参考官方文档安装。
基于
写上测试代码：
  {
        = {
         = {
                
        }   
    }
}

    {
      
      =  
    
     
}

  = 

配置文件如下：
{
   
}
执行命令编译：
   

编译后主要代码如下：
  =  = {
     _ = _  {
          
          =  
        
         
    }

       {
         _ 
    }
}

编译后的代码和很相似，可以理解为基于的和的语法糖。
基于
因此要进一步运行在浏览器环境下我们还需要使用 和插件。
配置文件如下：
{
   
    
}
编译后关键代码如下：
  =   {
     _ =  __ _ {
         
         _ __ {
              {
                 _ = _ {
                     
                          
                        _ = 
                         

                     
                         = _

                        
                         _ 

                     
                     
                         _
                }
            }
        } _ 
    }

       {
         _ 
    }
}

可以看到编译后代码是由状态机实现，并无任何下不兼容代码。
使用与实践
错误捕捉
在使用时，我们有和，如下：
  {
     =  = 
}

在 中写法如下：
  {
     {
          =  
        
    }   {
        
    }
}

在是使用相当于中的
   {
     
     
}
  = 
 =  = 
 输出

返回值
在函数中， 返回值永远是
   {
     
     
}
  = 
 = 
 输出

循环中使用
因为同步非阻塞的表现，所以在循环中使用将会比以前的代码更易读明了。
   {
      =  
      = 
      =  
      = 

      {
          = 
         = 
          
         =  
    }

     
}

匿名函数中使用
同样在匿名函数中可以一样去使用关键字，如下：
  =   = {
      =  
     
}

连续使用问题
代码一：
   {
     
     
     
}

运行完需要秒。
代码二：
   {
      = 
      = 
     
     
     
}

代码二运行完却只要秒，因为是在同一时间运行的。
结束语： 无疑是现阶段最好的异步回调同步化的解决方案，不过因为暂时没有纳入规范，而且主流浏览器的支持的不足，所以我们只能通过使用尝鲜。但是我们也可以借此看到未来在回调问题上的主流解决方案。前言
本文以为例，因为腾讯云的云函数正在内测，还没申请到。
现如今云计算时代渐渐出现了越来越多的新型模式，从
 基础设施即服务
 平台即服务
 软件即服务
到：   容器云
再到的微服务架构，都在试着将各种软、硬件资源或抽象的事物做为一种服务提供给开发者使用，让开发者不再担心基础设施、资源需求、中间件等等，在减轻心智负担的同时更好地专注于业务。
是   函数即服务的简称，它往往和无服务架构 一同被提起。
正文
腾讯云的
无服务器云函数  是腾讯云提供的无服务器执行环境，您无需购买和管理服务器，而只需使用平台支持的语言编写核心代码并设置代码运行的条件，代码即可在腾讯云基础设施上弹性、安全地运行。腾讯云完全管理底层计算资源，包括服务器 、内存、网络和其他配置资源维护、代码部署、弹性伸缩、负载均衡等。代码按需运行，空闲时不收费。使用无服务器云函数将帮您免除所有运维性操作，使您更加专注于核心业务的开发，实现快速上线和迭代，把握业务发展的黄金时期。

云函数使开发人员能够访问和 的一些事件，以及可扩展的计算来运行代码以响应处理这些事件。 以独特的方式使用云函数来满足其独特需求，典型运用的领域：

当发生了一些新奇有趣的事情通知用户

执行实时的数据库清理和维护

在云上执行密集的任务，而不是在本地的应用程序上

与第三方的服务和集成


下面就进行一一说明。
一、当发生了一些新奇有趣的事情通知用户
开发人员可以使用云函数来保持与用户之间的联系和获取最新的有关应用程序的相关信息。 
比如，在一些社交网站或应用上如微博。 在这样的程序中，由实时数据库触发的写入功能以存储新的关注者可以创建的云消息通知，让用户知道他们的粉丝数又增加了。
下面是它的工作原理图：


该函数在对实时的数据库路径写入了相关信息，存储粉丝

该函数通过向的推送服务发送消息

向用户的设备发送通知消息



其它通知的用例

向订阅取消订阅的用户发送确认电子邮件

用户完成注册后发送欢迎邮件

当用户创建新帐户时发送短信确认


等等
二、实时进行数据库的清理和维护
使用云函数数据库处理事件，可以根据用户行为修改实时数据库，保持系统的更新和清洁。 例如，在基于实时数据库的聊天室应用程序中，您可以监视写入的事件，并从用户的消息中擦除一些带有敏感词或不恰当的文本。 下面是它的工作原理图：


函数的数据库事件处理程序监听特定路径上的写入事件，并检索所有聊天消息的事件。

该函数处理文本以检测和擦除敏感词或不恰当的语言。

该函数将更新的文本重新写回数据库。



其他实时数据库清理和维护用例

从实时数据库中清除已删除用户的账户信息

限制数据库中的子节点数

跟踪实时数据库列表中的元素数量

将文本转换为表情符号

管理数据库记录的计算元数据


三、在云上执行密集的任务，而不是在本地的应用程序上
开发人员可以利用云端功能将云资源密集型工作要耗费繁重的资源或网络资源将运行的实际情况传送到在用户设备上。 例如，您可以编写一个函数来监听图像上传到谷歌的一个存储图像的程序中，将图片的映像下载到运行该功能的实例，修改它并将其上传回页面中。 修改包括调整图片大小，裁剪或转换图像。利用命令行工具，与云功能一起使用，使其工作变得更加简单容易。
下面是它的工作原理图：


当图像上传到的时候，该函数会被触发

该函数下载该图像的并创建它的缩略图

该函数将此缩略图的位置写入数据库，这样客户端程序就可以使用它

该函数将缩略图上传到新的存储位置



 其他在云上执行密集的任务，而不是在本地的应用程序上用例
定期删除未使用的帐户
自动和上传的图像
向用户发送批量电子邮件
定期汇总数据
处理待处理的工作队列
四、与第三方的服务和集成
云函数可以通过调用和公开服务或来使你的应用程序可以更好地与其他服务配合工作。 例如，用于开发团队的应用程序可以将提交到开发团队的聊天室。
下面是它的工作原理图：


当有人提交给，通过的 触发功能。

该函数将提供一个   来发送提交的通知。

然后把消息发送给团队的聊天室中

其他与第三方的服务和集成用例

使用的  分析和标记上传的图像。

使用翻译邮件

使用或身份验证服务

向实时数据库写入的发送请求

实时数据库元素的全库搜索

创建自动回复电话和短信

使用助手创建聊天机器人




再回头看腾讯云提供的
这里仅仅讨论它的应用场景
Ⅰ、实时文件处理
视频应用、社交应用等场景下，用户上传的图片、音视频的总量大频率高，对移动应用的实时性和并发能力都有较高的要求。例如：使用多个云函数对上传的视频短片进行转码，分别对应不同的清晰度、 等，以满足不同场景下用户的需求，适应移动网络带宽较小且不稳定的特性。


先由客户端上传视频至云对象存储

然后通过自动触发云函数对视频进行处理不同清晰度的转码

然后将转码后的视频重新上传至云对象存储

最后再发送给用户


其中视频文件始终在上
Ⅱ、数据处理
一些数据处理系统中，常常需要周期性计划性地处理庞大的数据量。例如：证券公司每小时统计一次该时段的交易情况并整理出该时段交易量  ，每天处理一遍秒杀网站的交易流日志获取因售罄而导致的错误从而分析商品热度和趋势等。
此时，腾讯云无服务器云函数  近乎无限扩容的能力可以使您轻松地进行大容量数据的计算。在下图所示的例子中， 可以对源数据并发执行多个  函数，在短时间内完成工作，相比传统的工作方式，更能避免资源的闲置浪费而节省资金。

类似于上面的在云上执行密集的任务，而不是在本地的应用程序上

将存储在云对象存储的文件通过云函数进行文件映射

将映射出来的许多小文件分别通过云函数处理

然后将处理后的文件存储至云数据库中使得更加持久化

然后通过函数将文件整合

最后会重新把这个新得到的存储到中


Ⅲ、移动及应用后端
无服务器云函数和其他腾讯云云服务紧密结合，开发者能够构建可弹性扩展并在多个数据中心高可用运行的移动或  应用程序 – 轻松创建丰富的无服务器后端，无需在可扩展性、备份冗余方面执行任何管理工作。


用户授权登陆利用云函数进行验证上面的与第三方服务或集成

浏览商品，商品信息存储在云对象存储上

云函数处理用户的下单历史数据或刚刚下的单来对用户进行产品推荐


其中使用  托管静态网站，构建商品明细模块；
使用 无服务器云函数 构建登录模块，可以直接复用  的授权登录逻辑；
使用 无服务器云函数 构建订单模块，在用户调用下单相关接口时触发增删订单等函数；
同时使用 无服务器云函数 支持个性化模块，根据用户的订单信息生成个性化数据并返回给客户端。 作为官方推出的客户端，功能可以满足我们大部分操作需求，涉及镜像及容器的功能操作，利用可以轻松开发出的管理平台，以便维护大规模的集群，本文介绍如何通过创建一个服务的镜像，再通过远程对容器进行管理。
一、环境准备
 、环境说明
   主机 服务主机
 、环境部署
安装镜像源  _
关闭修改配置文件： 
安全起见，先升级系统至最新版本需要或更高的版本，的内核版本是 或者更高，为了让工作需要特定的内核补丁。  重启系统： 
安装、启动服务注意：如果安装了不相关的包，它将与冲突。在安装之前，请先卸载
安装   
启动服务  如果我们需要开机自启动，如下：
添加随机启动  
查看服务运行状态      
 要获取最新的镜像  
命令行查看镜像：               通过以上步骤安装部署，测试，一个基础环境已经运行起来了。
、修改自启动服务文件，支持远程接口与本地连接；
  
 
          
  
二、创建镜像
、获取最新的镜像   
、编写支持服务
  
  
  
 
       
   
     

    
      
                
      
      
 _   

   
        ___  
        ___  
     ___    
            _         _   
             
   |   

   
     
    

   
   
   

   
  _  
 _ _  

   
   
通过来维护容器中服务进程，编写  
 
  
=  

  
=   

  
= 
创建镜像，运行：
     
注：最后有一个“”，别遗漏。
镜像生成完毕后运行 查看，见下图：

三、编写操作
登录服务器    
、安装         
如正常导入模块 说明安装成功。
、创建容器_
 
   

 = _===  
_=_===  ===  
通过_方法创建容器，指定镜像名称，使用接管进程服务，挂载主宿机作为数据卷，容器监听与端口，容器的名称为  
 
、运行容器_
 
   

 = _===  
== ={{  }} _={} _=  
        __= = =  
        = _= _= _=  
        _= _= _=  
通过方法启动容器，指定数据卷的挂载关系及权限，以及端口与主宿机的映射关系等  
 
、运行  _  _更多参考
、在主机观察结果，见下图：

四、校验服务
、校验服务

、校验服务

、检查数据卷 预计今年也会正式发布， 这个最具变革性且变革性最适于程序的版本，终于准备正式支持。从自己开发的感受，说一说 应该使用的新特性。程序员，你应该拥抱变化。 注：本文不讲具体语法，具体语法请下载下方分享的《  实战 》。

   的产品经理 ：’                                                         
我们决定弃用  工具链，改为直接在最新的  和  工具集中增加对   语言功能的支持。经过这番改弦易辙，依赖于  类文件格式的现有工具和插件仍可继续工作。今后，  语言功能将得到  构建系统的原生支持。

一、桌面类软件特点
图形界面的应用程序有几个特点：
● 基于消息驱动模型
● 强交互，实时性要求高
● 用户触发执行与用户触发结束

二、表达式
举个实际应用中的例子，下面这部分的代码是过滤出某个目录下所有后缀的文件， 之前的写法是这样子的：

 的写法

需要解决的一个核心问题啰嗦，能做的内部类都能做。是面向对象的语言，不支持方法。语言的方法，在里面可能是一个接口，可能是一个静态方法。这个方法需要的是一个行为行为参数化，更高级的抽象，这个行为是“”，但是不支持传递行为方法。所以， 之前我们不得不用函数接口只包含一个方法的接口，专有名词函数接口对象的方式来对行为进行包装。刻薄的讲类命名为更加贴切。

、方法引用
有一种快捷写法，方法引用。之前说，在中定义方法的方式，一种是接口，一种是静态方法，现有的库中已经包含有大量的方法。方法引用，可以让我们重用这些方法，让这些方法像一样能够被传递。

程序中的用法这种写法 之前，在或者程序中都应该会大量出现

 之后的写法应该是这样的
这两者的差别，解释起来应该是这样子的。本质：”直接调用这个方法”或者 之前”描述如何调用这个方法”。你没必要再去描述如何调用，因为都知道该怎么调用。我们知道程序最基本的设计时，解决的是视图和逻辑分离，这几乎是程序设计里面最基本的。逻辑处理方法一般并不会包含在控制器的类里面，而是在逻辑层，有了方法引用你可以直接与逻辑层的方法相关联。

、为什么要
● 简洁的代码，跟利于行为参数化高级抽象， 参数化行为参数化
● 预设的接口，、、等， 大量库支持。如果你不理解，你将不理解大量 的接口。
● 类型检查、类型推断更优
注：写的时候，参数一定要有含义，本来就不写类型了，再不写有含义的变量就真的是天书了。
三、组合式异步编程
一个解析 信息的类，可能会解析很长一段时间，所以需要有超时。 之前的写法

 的写法

 

那么除了少些几句代码之外，它到底有什么好处呢？
● 约定：与设计模式一样，这是程序员的一种约定。接口返回，调用者一眼就只这是个异步，也知道如何调用它
● 同步转异步：配合，几句话就能完成。
● 异常传递：  ，其他线程的异常可以传递过来。程序里面，异常通常要转化为用户的一种视图。
● 协调：等待多个异步操作完成合并如查找多家网站酒店价格，取最小值，等待多个异步操作中最快的一个完成，异步操作完成后回调一个函数异步操作完成，来个。在以前这些协调性的功能，可能需要借助，来完成。一步到位
注：配合可以极大的提高并发的效率
举个简单的上面这个例子返回后的用法：

四、流处理
        用流以表达式的方式来完成数据处理。我自己的理解是，以数据库的操作方式来完成数据的处理。 的内置了许多类似于数据库的操作、、、等。
优点：
● 以数据库操作数据的方式，专注于如何做这个某个步骤，表达式的方式
● 高并发看到、就应该能想到了
__
举个用法的例子，业务时获取所有在线的可测试的手机：

注：的写法的确对原因的思维方式会造成一定的冲击，不过写过了，加上有一定数据库使用基础的话理解起来非常容易。高性能的特点的确感受不深，因为处理大量数据的情况毕竟是少数。
五、
           一个可能包含指的对象包装器。不可避免，能避免的是。最大的罪在于它可以代表任何类型。下面这两个接口，不去看你的注释，我并不知道你是否可能会返回。在业务需求变化如此快的今天，贴切非常容易出现对返回值不做检查的情况，任何人都会偷懒。的处理逻辑是，强迫你去检查。如果我的返回值是，这个接口显式的告诉你可能返回的是值，这个在程序里面特别常见。

的弹出框用户可能并不填内容内容，返回。

所以，的核心思想就是我明确告诉你可能会返回，你一定要处理。所以，现在模块间提供给其他人的接口，如果有可能返回为都要声明为。 大量的官方接口也都会放回，这个是一定要学的内容。

近日，谷歌发布了安卓开发者预览版。腾讯立刻在云真机产品中增加了带有安卓系统的真机。
想要率先体验的用户可以登录：
如在使用中有任何疑问，欢迎联系企业：导语
在知乎等地方经常看到有人问， 的多线程是不是鸡肋？为何我用多线程性能一点没有提升，有时候性能反而下降？在这里通过日常工作中遇到的问题以及自己的一些总结，来一探  多线程究竟是不是鸡肋；如果不是，那又该如何使用。
、遇到的问题
工作中常用到  来分析文件，统计数据；随着业务的发展，原先的代码性能受到了一定的挑战，下面根据两个案例来讲解在  的使用过程中，遇到的一些问题，以及自己的一些总结。 
案例一：数据统计，将文件按照一定的逻辑统计汇总后，入库到本地  中。
最开始的代码流程框图：

大概流程： 
、循环读文件，按照一定格式将文本进行拆分计算；
、根据指定的  来统一汇总数据；
、入库本地 ，入库时，会先查找  中是否存在这条记录，然后再判断是否插入  中；相当于这里会有两次  操作，一次查询，一次写入。
一开始业务量小， 数据量少，整个流程耗时较短，在秒级能够完成，随着业务发展，所需时间也有秒级变成了分钟级，十分钟级别等。
测试 
通过对其中的一个业务某天的数据进行测试，它的耗时主要分部为，读文件文件大小  左右耗时  秒，逻辑计算及汇总 ，数据入库 ；总耗时大概在  分半钟。
 方案一
流水线形式的多线程

线程１负责读取数据，然后通过  自带的 ， 传递数据给线程 ；线程  负责逻辑计算，然后通过  传递数据给线程 ；线程  负责汇总数据，然后通过  传递数据给线程 ；线程  则入库数据；
这个方案在实现之后立马就被废弃了，它的效率比单进程的效率低很多，通过查看系统调用之后，发现是因为多个线程一直在竞争锁，以及线程切换导致其执行效率还不如单线程。
 方案二
数据分片分段多线程  
在不同的时机采用多线程来处理，同时尽量避免多线程对同一资源进行竞争，以减少锁的切换带来的消耗。因此这里在逻辑计算和数据入库阶段分别采用数据分组，多线程执行的方式来进行处理。 
分段一、逻辑计算和汇总，将内存读到内存中后，按照线程数量，将数据切分成多块，让第  个线程 处理第  份数据 ，最后再将计算得到的  份数据汇总，按照相同的  进行汇总；得到 _。
分段二、将 _ 按照线程数量，切分成多份，同样让 处理 _的数据，让他们各自进行数据的查询以及写入操作。

测试 
对同一个文件进行测试，读文件耗时  秒，逻辑计算及汇总 ，数据入库 ；总耗时大概在  多秒，相比最开始的单线程，时间大概下降了  多 ；但可以看出，逻辑计算的时间相比单线程确增加了不少，而入库操作的时间减少了  多 ；这里就引发一个问题，逻辑计算跟入库的差异在哪里？为何前面的多线程性能下降，而后面性能确大幅度提高。
这里的原因究竟为何？
案例二
案例  的整体流程为，将几份不同的数据源从  中取出来，按天取出，经过一定的整合后，汇总插入到一个目标  中。
一开始的代码流程：

同样最初的时候，需要整合的数据量较少， 中的数据量也较少。随着业务增长，每天需要处理的数据量也逐渐增加，并且  中的数据量也越来越大，处理的时间也从开始的秒级别也逐渐增加到分钟级别，每次都是统一处理一个月的数据，整体耗时需要几个小时。
测试 
对某天的数据进行测试，结果为：取数据 整合 耗时 ；插入数据耗时约  分钟。
更改成以下模型：入库操作同样需要先根据  查找当前  中是否存在该条数据，不存在则写入。

测试 
取数据 整合 耗时 ；插入数据耗时约  分钟。
更改之后性能大幅度提升，由原先的  分半钟，缩减为不到  分半钟左右，缩减的时间主要体现在入库阶段；
从以上两个例子可以看到，当涉及  操作时， 的多线程能发挥较好的性能；而当涉及到  密集型逻辑运算时， 的多线程性能不升反降。这里都是由于  的  在发挥的作用。
、了解  的 
这里我们使用的解释器为官方实现的 ，它是由  语言实现的  解释器。同时还存在由  实现的  解释器，由 实现的  等解释器。这里我们主要是依据  来讲解  锁。
，全称   ， 是一个全局解释器锁，当解释器需要执行  代码时，都必须要获得这把锁，然后才能执行。当解释器在遇到到  操作时会释放这把锁。但如果当程序为  密集型时，解释器会主动的每间隔  次操作就释放这把  锁，这样别的线程有机会执行，具体的间隔次数是由    来设定这个值，通过  返回这个值，默认为 。所以，尽管  的线程库直接封装操作系统的原生线程，但  进程，在同一时间只会有一个获得了  的线程在跑，其它的线程都处于等待状态等着  的释放。就这样对于  密集型操作来说，多线程不但不会提升性能，还会因为线程切换，锁竞争等导致性能的下降。
在我们上面的两个例子中，当涉及到数据的查询与插入时，都需要进行  交互，并且会等待数据库服务器返回，这个时候，线程会主动释放锁，其他线程能够合理利用这个时间，来做同样的事情。
知道了  之后，我们才能更加合理的使用  的多线程，并不是所有场景都适用于多线程。
同样， 的多线程也并不是大家所说的鸡肋，在适合的场景用上了，还是能够起到惊艳的作用。——
业内对头条的恭维，大都围绕着由搜索技术演进而来的推荐算法，即：针对不同的用户推荐不同的内容。
然而，精准的阅读内容推荐只能提升读者的阅读体验，并不能够带来商业上的巨大利益，而真正为头条带来巨大商业利益的，还有其它几点，其中最最主要的一点是：
头条将传统新闻客户端那种有限的流量转化为了无限的流量。
前边几篇我们一直强调的流量是用户量，即：用户量越大，流量越大。
然而，对于商业角色来说，影响其收益的不仅仅有用户量，还有单个用户的浏览量。
第一代互联网公司强调的是用户数，后来大家开始强调用户访问的频次、持续时间，以及，质量。
对于同一家超市而言，同样一个消费者每天进来一次和每天进来三次显然结果是不同的；每次进来呆十分钟和呆六十分钟也是不同的；最最关键的是，同样一个消费者最终在超市买了多少价值的商品。所以，超市除了位置选在居民区周围，而且通过班车来吸引人流量之外，超市内部的布局也花了不少心思，比如：出口都距离入口很远，基本上从入口到出口要经过几乎所有的货架。
同样的道理，所有的网站客户端都希望用户越多越好，都希望同一个用户的访问频次越多越好，都希望同一个用户每次停留的时间越长越好，
——
对于新闻客户端，很大的一笔收入来源是广告，而每个页面的广告数目总是有上限的否则会导致用户反感，因此，大家能够动用的广告位也就是有限的，因为每天也就那么些重要的新闻可供读者阅读。
我们来看看头条是怎么做的。
首先，既然头条具备向不同用户推荐不同阅读内容的能力，那当然也意味着它可以向不同用户推荐不同的广告。通常来说，广告投放方会对自己所投广告的展现人数有所要求，而且根据用户数的多少来决定广告价格。然而，广告的最终目的是“有效用户流量”，虽然头条分散降低了单个广告的“总用户流量”，但通过更为精准的推荐算法，“有效用户流量”不见得有所降低。甚至，对于广告投放方，这种更为精准的广告展现能够提升广告的单价效果。简单地说就是：通过流量广告位的精准匹配，将不同的广告位卖给不同的厂商。
其次，由于传统的新闻客户端每次更新的阅读内容都是固定的比如一小时篇，如果读者花三十分钟看完了所有的新闻，他就没什么新的内容可以阅读了。头条采用的方式却是完全动态的，每次进入，看到的内容都是不同的，这相当于无限扩展了用户阅读量。传统的新闻客户端，使用的是传统的网站类新闻布局，所有的页面都是固化好的，包括一个新闻正文底部的相关新闻，大都是老的已经发布过的内容。而头条的展现方式，每一个页面都是动态的，每一个新闻正文底部的相关新闻都是最新发生的，甚至比当前新闻还要新。这是完全一种不同的技术实现方式。之前的那种“关联老的已经发布过的新闻”，基本上是人工的方式；而头条这种实时关联最新内容的方式，显然依赖于足够好的“关联算法”即推荐算法。
再次，传统的新闻客户端，是传统互联网媒体的渠道拓展，内容来自自己的原创、采编团队，由于人力有限，因此内容的数量也有限。而头条，从一开始，并不是一个原创或采编团队，而仅仅是个提供搜索、推荐结果的技术产品。头条上所有的新闻、文章，都不是头条自己的团队写出来、贴出来的，而是从别的媒体抓过来的或者可以说是直接跳转到别的媒体页面。因此，从数据量上，显然头条很有优势。其实这个事情之前几个搜索引擎巨头都有做过，比如谷歌。然而，谷歌搜索出来的新闻，最终是完全跳转到了新闻来源网站。头条虽然也是抓取或跳转，但头条做了额外的加工：跳转之后的内容展现，头条在底部加入了自己的“关联推荐内容”。所以，用谷歌，看了一篇新闻后，读者就不知道会去向何处了；用头条，看了一篇新闻后，读者还能看很多相关的关联新闻，而且一直是在头条里边。
以上几种方式，使得头条在跟传统的新闻客户端竞争时，
、同样的流量卖出更高的价格；

、提供了几乎无限的广告位；

、降低了内容数量对人力的依赖；

、保持了对用户的持续引导、控制。
——头条的最大风险和优势
头条的最大风险，当然是内容的版权。因为头条的内容都是从别的网站搜索出来的，如果所有的原创媒体都拒绝头条的内容展现，显然头条就活不下去了。
比如：人民网、新浪网、腾讯网、等等官方或半官方的原创媒体全都禁止头条拉取自己的内容，那么，头条也就空有架子。如果整个超市只有货架没有商品，消费者又如何肯去呢？
还好，中国够大，媒体够多，总会有小的媒体愿意把自己的内容开放给头条，哪怕是免费的，毕竟，具有原创报道权的地方媒体多的是，既然通过头条这个平台可以扩大自己的知名度和用户覆盖度，何乐不为呢？
当这些势力薄弱的地方媒体为了流量而主动站到头条这边，头条原创能力的缺乏反倒成为优势。
因为，其它的几个竞争对手，都是具有很强内容原创能力的，比如网易新闻、腾讯新闻，都有很庞大的采编团队。
那么问题就来了：同样一个事件，自己的原创团队创作的内容，和其他媒体创作的内容，网易和腾讯会如何选择如何排布？
头条显然没有这个包袱，谁的内容更好就用谁的。
从这个角度看，如果你是一个提供原创内容的媒体或自媒体，会如何选择？
当然了，对手都不是傻子，内部原创团队和外部团队的竞争，这种事情，耗费一些时日，经过组织架构的调整，网易和腾讯就没这个问题了。腾讯投资京东，但腾讯新闻上一样有淘宝的广告。
——流量和内容质量
头条经过技术改进极大的提升了用户流量主要是单个用户的频次及效率，从而获得了远超对手的商业盈利能力。
然而，笔者越来越强烈的感觉到：伴随着之前流量有限的各种地方媒体逐渐站到与全国性媒体同样的流量地位，内容的数量越来越多，相对来讲，平均质量显然是下滑的，读者获取到高质量内容的成本越来越高，甚至许多内容鱼龙混杂，真假难辨。
 目前的技术只是解决了推荐算法的某些问题：即我喜欢看什么，哪些东西是更多数人愿意看的。
而未来的技术需要解决如下问题：哪些内容是真实的虚假的，哪些内容是科学的错误的，哪些内容是有价值的垃圾的，哪些内容是消遣的有毒的，
更甚至，随着整个网民群体的日渐成熟，大家希望看到更多更深入的阅读内容，而不总是停留在表面的哗众取宠。
这是一个过程，也是必然的趋势：从有限的信息发展到无限的信息，从杂乱的信息发展到有条理的信息，从浅层的了解发展到深入的熟悉。
当我们单调无聊的时候，想看一眼花花世界；当花花世界看得多了，又想回归一下简单。
所以，虽然现在许多内容原创团队尤其是优质内容原创团队活得不如那些抄抄写写的拼凑内容团队，但长远来看，优质的、深入的原创能力，是内容行业最为核心的竞争力。
今天，或许大家还很享受每天看一千篇新闻，未来，或许大家更倾向于每天看十篇新闻。
随着经济的发展，购买力的提升，娱乐方式的多样化，闲着没事逛街的人越来越少了，要买什么东西，直接网上下单就是了，没必要逛三家商场两家超市之后才买。
因此，最终的用户价值依然在产品内容的质量，流量只是催化剂。
百度的使用频率越来越低了，迟早有一天，头条也一样。

本篇为《互联网陷阱——流量战争》的第四篇。以下为相关文章请到公众号：【水滴的声音】查看《小米：我们从来不打广告——互联网陷阱：流量战争》《 盛大盒子：误判的野心——互联网陷阱：流量战争》《互联网，流量的战争》作者简介：李浩成，腾讯广州研发部  工程师

经过长时间的打磨迭代，  作为腾讯广研  团队的一个开源项目，正式发布到  。  是一个   的解决方案，从零开始，由编码规范，到组件和工具方法的制作，再到工作流的整合，不断在迭代，也不断在优化，走过了不少的路。趁着发布的机会，我们正好回顾这一路的探索过程，分享其中的点滴，也希望能借此让大家更了解  。
地址：_
背景
 年中， 团队支持的主要项目是  邮箱， 端的邮箱是个庞大的项目，但其并没有统一的  基础库，多年的高速迭代使得项目的  代码变得混乱，各个模块之间各自开发，除了在代码层面表现出混乱和不可控之外，表现层面也并没有很好地统一起来。因此，项目急需一套统一的团队编码规范以及一个  基础库。
恰好，这个时候  等  预处理器已经发展成熟，自动化工作流的工作模式也日趋完善，因此，我们决定基于这些技术制作一套通用于不同项目的   框架。框架的场景定位很明确：需要控制整体样式，并且可以适应频繁迭代打磨的大型项目。所以，这套即将诞生的   框架的特性也很明确：需要方便地控制项目的整体样式，应对频繁的界面变动，并保持项目质量稳健。
此后经过三年的发展，  最终发展为包含编码规范、样式工具方法与样式管理、内置工作流，配套的  桌面 ，以及拥有完整文档的解决方案。
设计理念
在制作框架的过程中，我们把框架需要的特性进行整理和思考，形成了一套对于该框架的设计理念，在这些设计理念之中，最核心的关键为通用于多个项目，高效迭代和保持代码稳健，框架的设计也遵循这三个核心点，体现在框架上，具体就是：

框架和组件需要剥离业务。作为  框架，框架内整合的组件和样式必须有能力剥离业务，才能跨项目使用。
能轻易控制整体样式。需要高效地迭代项目，样式的整体控制必不可少。
保持代码稳健。

而具体到代码层面，则可以归纳为两个方面：

 命名规范。
基础样式配置与半封装组件。

 命名规范
作为一个   框架，编写代码主要是  与 ，而提到  与  的编写，首先要处理的是  的命名，在过往的开发中， 的命名并没有固定的规范，开发人员各自进行开发，一个项目经过长时间的迭代后，经常会遇到如命名冲突，命名混乱等问题，这使得项目的迭代变得笨重，也不好维护。因此，我们需要一套具有如下特点的  命名规范：

命名有迹可循，容易编写。
避免命名冲突，包括内部多人协作命名冲突，以及外部库引入时的被动污染。
命名具有语义，能晰地描述整个页面，方便理解上下文。

因此，最终   制定了一套以命名空间为核心的命名方式，这个命名方式主要由“命名空间”，“业务与组件的拆分”，“精确表达 ”三个部分构成。
命名空间
一个    应该包含一个命名空间，也是  的开头，如果是业务，则以业务内容为命名空间，如果是公共组件，则全局使用项目的名字或缩写为命名空间。如一个名为  的项目，项目缩写可以是 ，那么该项目下的项目组件和公共类可以这样命名： _按钮、_图标、_输入框、_工具栏。
逻辑模块命名以具体业务作为前缀，如简历功能里面的非公共组件部分，以 _ 作为前缀_、_、，个人信息页面的非公共组件部分，则可以以  作为前缀_、__。
命名空间作为一种基础的隔离，把组件与业务，以及不同的业务之间的  命名隔离开来，避免冲突，而后父子元素之间逐级展开编写，保证了项目内多人协助不易冲突，同时命名带有语义，也方便理解和阅读。
业务与组件的拆分
接着，  中把项目的代码划分为通用组件跨项目的组件，项目全局组件适用于某个具体项目，业务组件适用于某个业务，以及业务逻辑代码，这样区分出个颗粒度可以使得代码更容易被组织和复用，一个模块随着设计元素迭代，也可以在这个颗粒度之间进行迭代，从而使得模块在迭代时会更加稳健。而   框架中的组件应该只收纳通用组件，即跨项目组件。
精准表达 
精准表达  是指在命名  节点时要明确这是一个怎样的 ，这里的  指的就是  层面上这个元素表示的含义，常见的场景是，一个命名为 _ 的元素，在经历多次迭代后实际在代码中却充当了页脚，这样的命名在多人协作时很容易给后面的开发者造成困扰，而精准表达  则要求我们明确一个  元素的含义，并在命名时准确地表达。
基础样式配置与半封装组件
前面的“ 命名规范”主要是在规范层面上去实践   的核心理念，而接着更多地就是在代码层面上去实践了，主要包括三点：

半封装组件，即面向项目的组件。
使用组合而不是继承。
颗粒度的把控。

半封装组件即面向项目的组件
前文提到，  把组件划分为通用组件，项目全局组件，业务组件三种组件，而   框架收纳的则是通用组件，也是跨项目的组件，但每个项目的  表现并无关联，如何处理跨项目组件就成为了一个问题。为此， 在处理组件时采取的是“半封装”的处理方式， 框架封装的是代码，所谓半封装，即封装那些与项目具体  表现没有必然联系的代码。例如按钮组件，  中只封装了文字居中对齐，鼠标手型，浏览器样式重置，低版本  兼容性处理等代码，而常用的样式如边框、背景、字体表现等，都抽取成变量控制，这些组件的变量最终都汇集到一个配置表  文件中，配合全局的颜色变量、字体变量等变量，就可以做到跨项目抽取组件，每个新项目只需要关注具体  表现而无需再处理各种常见的  问题，同时方便地通过调整这些变量的值而快速修改整个项目的样式。
组合而不是继承
在处理组件时，继承的方式是指一个组件类承担复杂的功能，而组合的方式则是把组件类拆分成一个基类，以及多个子类，每个子类承担的功能不重复，对于我们的主场景——频繁迭代，保持稳健，显然组合会更加适合，这种方式避免了在频繁的迭代中需要不断修改组件类，每次迭代只需要修改对应的子类即可。
颗粒度
对于组件的抽取，时常要考虑颗粒度的划分，颗粒度本身就是一个比较开放性的问题，在这里与大家分享一些沉淀的经验：

抽取组件以  表现为区分，例如一个删除按钮，是以删除   删除文案作为内容的，但在表现上它就是一个带  的文字按钮，因此就抽取出一个支持  的文字按钮，而不用只局限于按“删除”这个业务来命名组件。
抽取组件可以选择较大的颗粒度，也可以选择较小的颗粒度。颗粒度较大的组件实现复杂，能对应复杂的场景，但扩展性也会因此下降，而颗粒度较小的组件则实现简单，能轻松实现一个主场景，但又方便扩展，能灵活地应对变化。因此建议是像按钮、输入框、下拉菜单这类通常位于页面   末端的元素可以抽取成尽量简单的组件，同时通过扩展的方式去处理各种场景差异。而其他复杂的组件则可以专注于一个业务，不必过多地考虑不同的场景，否则组件很容易变得难以维护。

以上便是   具体的设计理念，通过命名规范、基础样式配置与半封装组件来保证多人协作时的高效率与可维护性，也使得一个  框架能为不同的项目服务。
具体组成
作为一个框架，  主要提供了四种能力来提升  开发的效率与质量，对应前文提到的框架设计理念，  提供的这些功能都是为了帮助开发者方便地控制项目整体样式，应对频繁变动，同时保持代码稳健。
基础配置与组件
前文提到，框架中会有一份配置表，是各种  的变量，这些变量控制了一个网页基本的字体样式，链接颜色，通用组件的样式配置等基础样式，在创建一个新项目时，应该先根据设计稿配置好这些信息，当这些信息配置完成，那么一个项目的基本样式就可以快速实现了。例如下图中这些配置属于  通用配置，通过修改这些配置则可以快速修改项目的字体策略、正文字体大小，链接颜色等  常用的  属性。

内置工作流
 中包含一个基于  的内置工作流，用于快速解决大量重复劳动力的工作，从而提升效率。 的  中预先实现了监控  文件并自动编译和优化，雪碧图处理，模板  能力可以传参和使用条件判断，浏览器自动刷新，图片压缩，文件清理，文件合并以及自动变更等能力。
 增强支持
 中提供了大量基于  的  预处理的方法，包括  ，一些常见的  类例如清除浮动，计算长度值的简便方法例如获取  在某个方向的值，计算两个长度值的中间值，快速实现一些样式效果的工具方法例如实现  三角形，适应多倍屏幕的  边框等，这些都是用于提高样式开发的效率和质量。
扩展组件
扩展组件并不是由   的主源码提供，而是由  提供，通常是因为这类组件结构较复杂，因此业务性无法很好地剥离，从而不能抽取成公共组件，因此这类组件就放在一个  页，以参考组件的形式帮助开发。

我们提供了一个用于管理   项目的桌面 ，在代码层面它独立于   的源码。它通过  界面处理   的服务开启关闭，并提供了编译提醒，出错提醒，进程关闭提醒等额外的功能，在处理多项目，多分支时能更方便地进行开发。

优化和开源
在经历较长时间的迭代后，  也逐渐完善起来，此时我们也开始将   进行开源。开源意味着   会进入更加全面的环境中去打磨，在框架的非主体内容如代码规范、注释、文档上面也需要更费心思，考虑的点也需要更加周全。这对团队来说无疑是个很好的机会，可以有更多的渠道审视框架，吸收建议，持续进行优化。
在加入开源的大环境后，我们从 、社区论坛中都获取了不少建议，除了  的反馈外，也指出了一些待完善的地方和提出一些优化的解决方案，从而使得   注入了更多活力，因此我们也逐步进行了如“自动化测试用例”、“ 结构化”，“引入  自动化生成文档”，“编译  时引入增加更新”等优化，其中不少优化点我们也在项目的   链接：_中进行了详细的分享，有兴趣的用户可以自行浏览。
总结与展望
至此，  发展为现在这套完整的方案，也终于开源到   与大家分享，我们期望通过开源与大家进行更多的交流，也使得   进入更加全面的环境中去打磨，形成对代码规范、注释、项目文档的优化。感谢公司与部门给我们提供了一个平台，可以在大型项目中经历迭代和沉淀。开源只是一个开始，我们后续仍会不断进行探索和优化，期待更好的  。
关注  地址：_来  给_  吧！

转载自【腾讯开源】公众号，腾讯官方开源资讯，期待您的关注。作者 | 程丽萍编辑 | 顾乡

微信开启了新的传播方式，对于企业来说，如何利用微信平台为企业带来实实在在的效益，增加销售的业绩，树立和传播品牌形象，是企业品牌部门正在不断探索的工作。国际顶级域名注册管理机构中网旗下“易企秀”致力于为中小企业提供移动场景营销平台，微场景的出现，图片、文字、声音的动态组合方式，给了用户完全不一样的体验。
客户挑战
易企秀为大量的企业提供提供基于场景包括文本、图片、音乐、视频、表单、图集等富媒体信息的自营销闭环服务，方便中小企业制作展示场景、数据收集、二次营销。
基于微信社交关系链的传播，的访问量经常出现爆发式增长。此外品牌推广具有很强的节假日属性，这些都使易企秀平台平时的带宽处于平缓的低谷，碰到节假日会有超出平时几倍甚至数十倍的带宽峰值出现。
突发带宽带来的极大的成本、服务质量压力，如何保证易企秀所有的企业客户的终端用户能够在带宽突发时段仍然保持流畅稳定的访问体验，并取得质量和成本的平衡？
腾讯解决方案
腾讯云  提供了一体化的解决方案，可最大限度的平衡加速、成本各方面的因素：
、 腾讯云特有智能路由和流量调度能力：
拥有微信海量终端，可以实时获取用户真实的链路访问情况，即时调整路由和调度策略，优化服务质量。
拥有  和  两大解析平台，对用户访问调度具有先天优势。 全自动管理能力，避免资源冲突，管理风险。
自研智能路由产品，可定期对加速网络中的各个阶段进行探测，并上报系统后台，使用多种算法，算出最佳路径，实现资源调度最优化。
此外，腾讯云  具有先天的带宽储备优势以及多年来内外部各类型业务的运营积累的应对带宽突发型业务的成熟监控和运营手段，从  状态监控到用户体验指标监控，通过  拨测，服务器拨测等手段多维度控制  运营质量。
、 针对客户业务，提供 压缩方案等优化，优化带宽压力
制定灰度分批切换计划，保障客户业务切换无感知，业务正常运行无风险；
制定中间源解决方案，减少中间源压力。
、  专业完善的支撑团队：从客户、业务、时间、技术等多重纬度指定割接计划，保障业务的平稳运行。提供小时不间断专业服务，包含企业  服务、工单系统服务及值班电话服务等多种服务渠道。
为客户带来收益
、依托于腾讯全球节点优势，多家运营商线路、机房支持，以及依托微信海量终端而来的对链路质量的把控，全量切换后，平均时延下降，客户业务体验效果有明显提升。

、没有改变原有的系统，平稳完成切换，源站流量稳定
、按流量付费，以及通过  压缩，成本相比以前费用下降以上。

相关推荐
深入浅出腾讯云：缓存篇借助腾讯云开启全站及问题解决分享图片流量节省大杀器：基于的自适应图片技术实践导语： 关于的解读已经很多，本文尝试从另外的角度解读的源码。本文所涉及代码皆以版本，代码皆以版本为准。

一个请求包的处理流程
从生成的中我们可以看到，框架帮我们实现了的个入口函数。

__
__
__
__
__

接下来深入到源码看看框架都帮我们做了什么事情。
   __   
{
         =  
      = 

    配置文件
     = 
    配置路径
     = _
    应用名
     = _
    服务名
     = __

    ____
                         __  \
                          

      == __
    {
         初始化框架 
          =  
           
        {
            ____
                                     \
                                 
             
        }

         初始化
         

         业务自身初始化 
        
                                       
                                       
    }

     
}
在的初始化函数中，我们只是看到对一系列的变量赋值和一些初始化函数的调用。和进程都会调用这个初始化函数，其中进程的调用做了些特殊处理。接下来我们主要看下进程所做的一系列初始化调用。
框架初始化
 我们可以从源码中看到这个方法的实现，这其中比较重要的是下面几条语句：
_ 初始化框架需要用的管理资源
  = _ __   初始化微线程库
_ = _ 通过侦听命名管道
  微线程主动让出执行权
这里每个函数又都做了一些更底层的操作，有兴趣的同学可以去追踪一下代码看实际都做了些什么事情。
数据包完整性检查
__函数主要由调用来检查数据包完整性，框架主要做的就是对结构体进行检查。其中主要的代码只是一句：
  =  
这个方法由框架实现，我们来看看做了什么事情。
    _ 
{
     _ 
}
这个方法主要调用了这个类的方法：
     _   
{
     
    {
           
    }

      =   \ 
     == 
    {
         _
    }

     =     

     _
}
这个方法中如果不是字符串协议直接交给了这个类来检查；如果是字符串协议则直接检查\字符。
类中：
     _   
{
       _
    {
         _
    }

     数据包长
    _  = 
      _
     = 

     限制包长
       _ ||
          ___
    {
         _
    }

       
    {
         _
    }

     = _

     _
}
其中也只是对数据包的长度进行了一些基本的检查而已。
数据包路由
__方法实现了数据包路由，其实现在中非常简单：
   __     
{
     
}
这里的返回是我们建的组，其实也就是与通信所使用的命名管道的。一般在服务中我们也都只建一个组，其为。
数据包处理
__方法是进程所调用的消息处理函数：
   __     
{
    _        = _
      = 

       = 
          = 

    ____ __    \
                         
                         
                         _ __
                         __

     
     
         = _ __

     简单的单发单收模型示例  
      =  
      {
        _ 
          = 
           = 
          
        ____   \ 

         
    }

     设置信息 
    
    
    
      配置化
    
     设置来源地址
     _ _
    ___ = _
    __ = _
    _
     设置本地地址
     _ _
    ___ = _
    __ = _
    _
     设置收包时间
      _
    __ = _
    __ = _
    _

     微线程有独立空间这里要拷贝一次报文
     

    

     
}
其中最主要的一句就只是最后的那个调用，这个方法的实现在源码中：
  
{
       ==  
    {
        __   创建失败
        __      
         
         
    }
     
}
这个方法主要就是创建了一个微线程来处理一个结构，其中是结构的派生类。
这时候我们进微线程框架来看一看：
      
{
      = 
      =  
      == 
    {
        _  
         
    }
     

      {
        
    }

     
}
是一个全局共享的单例对象，这里只是申请了一个微线程资源去处理这个请求包，并以为入口函数去执行。这里并不一定是去新建一个微线程，我们去看下的代码：
 
{
    ___ __  微线程池大小

      = 
     _
    {   
         = _
        _

        _

        _
        __
         
    }

    __     
     __ = __
    {
        __     
         
    }

     =  
      ==  ||  == 
    {
        __     
        _     
            
         
    }
    __
    __

         
}
这里可以看到是尝试从_中取一个微线程来使用，为空的话才去创建一个新的微线程。我们回到函数，申请一个微线程资源后会把微线程放入可运行队列里面去调度执行。
接下来我们可以去看看函数的实现，其主要起作用的也只有一行代码：
 = 
这里执行的是类中的方法，这个方法的实现代码比较长这里就不贴了。主要的作用就是解包然后调用类中的方法。当然还有一些支持其他调用方式的其他逻辑，这里就不再赘述了。这里的实现也很简单：
     
{
      
}
只是直接调用了虚函数，框架生成代码中对这一方法进行了重写。该方法其实是对请求包所调用的接口进行分发。最终调用了我们在类中所实现的逻辑代码。
业务终止
__的代码很简单只是做一些对象的析构而已。

   __   
{
      = 
    ___ __\

       == __ 
    {
        
    }
}
至此一个请求包的处理流程我们已经理清楚了。
调用流程
回想我们用一个服务调用另一个服务的流程。首先在类里需要声明所要调服务的代理指针，然后在初始化函数里一下这个指针，之后就可以在逻辑代码里直接调用其它服务接口了。我们深入代码看一下这其中到底做了什么事情。
初始化
首先，我们看一下类的方法：
 
            = 
    {
        __ 
          _ 

         协程版本和非协程版本分开存储
             = 
                                                        __  _

          = 
             = 
         ==  ||  == 
        {
             =  
              
            ____
            ____
             = 
            _ 
        }

         =  _

         
    }
其参数前面是所要调用的服务名，第二个是服务代理指针，第三个是是否需要使用微线程标记。其作用其实是将相关调用信息保存在中以供后面查询使用。
同步调用过程
我们在声明代理指针时，会先将对端的引入到自己的项目中生成其调用的代理类。我们所声明的代理对象中包含了所有对端服务所对外提供的接口，其实现主要都是调用了一个_方法。其实现也很简单：
 _ 
              
              
               
               
             
    {
         == 
         _
         ___
        {
            __     
             
        }
        
         框架包请求编码
          =  _
               = 
            = 
           = _
              = 
                = 
                = 
                 = 
                     = 
         =   
             

        _
         = 

         
    }
可以看到这里主要调用了_方法：
     _  
    {
          = 
         == 
        {
             
                    _
        }
         = 

          = _  
         = _
        {
             
             _  _
        }

         = _
        {
             
             _  __
        }

         = 
        _     

         = _
        {
             = 
             
             =
        }     

        
    }
其实现主要是从连接池中取出一个连接，然后组包发请求上报。其调用了封装过的方法进行收发包。这是同步调用模式的过程。
微线程调用过程
从上面_方法可以看到如果是微线程版本则调用了__，这个方法跟同步方法相比只是把收发包的接口换成了微线程的版本。使用了_和_这两个方法。
微线程组件
前面两个章节已经涉及到了一些微线程的创建以及微线程的收发包接口，本节我们主要看一下微线程的实现代码。
我们先从涉及到的_方法实现看看：
 _ _       _  _    
{
      ||  || _ ||  
    {
        _     _ 
              _ 
         
    }

      =   = 
     _ =  _
    _ _ = 
    _ _ = 
     _ = 

      获取连接池对象，挂接通知对象
      = 
      = ____ 
      ==  ||   
    {
        _     
         = 
         _
    }

      尝试检测或新建连接
     =     _ _
       
    {
        _     
         = 
         _
    }

      发送数据处理
    _ =   _
    _ =   _    _  
     =     _
       
    {
        _     
         = 
         _
    }

      接收数据处理
    _ =   _
    _ =   _    _  
     = ___ _ _  _ 
       
    {
        _     
         = 
         _
    }

     = 

_

     失败则强制释放连接，否则定时保活
      = 
    {
           
    }

     
}
这里主要是调用了类中的方法去发送数据，这个类是一个全局单例类。这里的方法实现为：
_      _     
{
      = 
    _  = 
      = 
    _  = 

    _  = 
    _ _ = 
     _  
    {
         = 
             
        {
             =             
             
        }

        __
         = __   _   _ 
           
        {
              ==  {
                
            }

              =    =  {
                _    
                 
            }
        }
        
        {
            _ = 
             _ =  {
                 
            }
        }

         
        
        
        
            {
             
        }
    }

     
}
其中__是一个宏主要作用是利用获取动态链接库中的函数地址。其实现为：
 __        \
  {                                \
         ____ {          \
           ____ = __ \
        }            \
    }  
微线程框架实现了系统原生的网络相关接口的版本，其版本也都是在进行网络的时候触发微线程切换来充分利用进而提高吞吐量。
本文为国庆假期期间在家里闲暇时写的一点东西，有理解错误之处还望指正。作者：莫卓颖

相信很多前端同学对于二维码识别、图像对比等这类高大上的图像识别技术望而生畏，觉得此类识别技术只能通过更加底仓的高级语言才能实现诸如等，本文试图从前端的角度出发介绍如何通过来进行简单的图像识别。
是什么
是中的新元素，你可以使用用它来绘制图形、图标、以及其它任何视觉性图像
图片处理运用
   对于来说，主要是两个方法对图片处理比较重要，一个是通过 的  方法获取图片的像素信息，可以很方便的通过方法导入到把网络图片或者本地的图片导入至中并获取图片的像素信息，可以修改像素信息后通过另外一个重要的方法导出处理后的图片。
、获取调用
      = 
     = 
、获取导入图像信息
  =  
    =图片地址
          
        ={
          
    }
、获取图片的像素信息
   =    
注意这个获取的是数组，注意每个像素由数组的个元素组成，四个元素分别代码四个通道的值
 =={
     =={
 注意这里获取图片信息后可以进行定制化处理
            =
              = 
              =   
              =   
              = 

    }
  }
   {
             
    }
、导出处理过的图片
第三步处理过得像素信息
二维码识别思路
、设计一个自动等分切割图片的程序利用导出原图的二进制数组，然后等分数组后出单个图片的序列库、简单做个爬虫程序，利用步骤完成的程序到需要识别的网站下载该网站的二维码序列图库、手工翻译二维码序列图库对应的真实含义，并建立图片到真实含义的表。、设计自动图片识别程序，导入需要识别的原二维码后，按照的步骤进行等分，分别拿等分后的图片依次对比步骤获取的图库，对比出对比度最接近的图片，然后通过步骤三翻译出来的表获取对应图片的真实含义
好了，授人以鱼不如授人以渔，通过前端进行做坏事的方法告诉你了，如何发扬光大就看你的灵活运用。
后记
相信在很多人眼中，  前端仅仅是一门简单的处理网页交互、样式门面学科。随着、等前端新技术的流行，前端不再是功能有限的学科，而是功能强大到只有你想不到木有做不到地步。

原文链接：


相关推荐【腾讯】看图测试指南——图像识别在测试中的应用前端开发框架简介和作者：赖博先

导语
最近准备为神盾推荐系统做一些特征工程相关的插件，整理了一些特征工程相关的方法，在这里跟大家分享，希望对大家有帮助！后期也会把插件的工程实践经验跟大家分享！
背景
随着我们底层特征库中特征数目的不断增长，如何组合特征，如何针对不同场景选择适合的特征，如何评估特征优劣？这些问题已经日益凸显，所以这次想梳理现有的特征工程方法，并将通用的模块抽象成工具，封装到神盾离线计算平台。
特征构造
对于一个推荐场景，特征构造主要是根据业务目标来扩展的，也就是说哪些因素会对业务目标产生影响，那么就可能是我们需要构造的特征笔者理解的所谓特征其实就是一系列独立存在，且可以被测量或者描述的属性；举个例子，假如你现在想在人群中找到你的朋友；这个场景的目标是找到你的朋友，那么你会怎么来找呢？当然你会根据你朋友的长相、身高、穿着、说话声音等等来进行判断，综合这些因素，你或许可以完成你的场景目标——找到你的朋友。
再举一个实际业务场景例子，比如游戏列表推荐，要构造这个场景的特征，首先可以分析出这个场景是由三个成分组成的：受众用户、推荐内容游戏、平台业务场景，那么我们在构造特征也是从三者入手，比如用户有什么特征，年龄、性别、学历、地域等等，这些是用户画像，对应数据中心的达芬奇系统；游戏呢！有品类、游戏 、付费参透率等；场景特征，，，点击，下载量等；除了单个成分去提取之外，还可以组合提取，也就是把用户的单特征和游戏、平台的单特征可以进行两两组合。比如用户  游戏，如不同年龄、性别对游戏的偏好；平台  游戏，某个游戏或者某个品类的游戏在这个场景下的点击、下载特征；这种组合特征的方式可以是内积、外积和笛卡尔积，它们都可以帮助我们构造非线性的特征，当然这样做也会大大增加特征维度，特别是笛卡尔积。当然这种人肉组合的方式在对业务有深刻的理解下是可以构造出出色的特征，但时间这种方式时间周期长，也需要进行线上线下测试来检验特征效果。
惰性是推动科技发展的动力，很多算法工程也在思考，能不能通过模型的方式来自动的学习和构成特征呢？所有的想法都会有实现的一天，现在市面上有效的特征构造模型有   因子分解机、深度学习提取训练好的模型中隐层作为特征可以自己学习出一些特征以及特征之间的组合关系。笔者使用过主题模型 、、 来作为特征生成的模型，将模型训练的中间结果，比如  的主题分布、 生成的词向量用于  这样的线性模型，线上测试效果都非常好。
通过上面的例子我们可以知道特征构造大致思路，也就是从场景目标出发，去找出与之有关的因素。但是在实际场景除了天马行空想特征之外，还需要对于想出来的特征做一可行性评估：获取难度、覆盖度、准确度等，比如笛卡尔积会使得特征维度增加的非常快，会出现大量覆盖度低的特征，如果把这些覆盖度低的特征加入到模型中训练，模型会非常不稳定；然而这一系列的工作就是传说中的特征工程。
特征清洗
在实际生产环境中，业务数据并非如我们想象那样完美，可能存在各种问题，比如上报异常、恶意作弊行为、爬虫抓取等。为了让模型能够学到真实的行为规律，我们需要对已经构造的原始特征进行清洗，排除掉脏数据。主要包括一下两个方面：
．结合业务情况进行数据的过滤，例如去除  抓取，，作弊等数据。
．异常点检测，采用异常点检测算法对样本进行分析，常用的异常点检测算法包括

偏差检测，例如聚类，最近邻等。

基于统计的异常点检测算法


例如极差，四分位数间距，均差，标准差等，这种方法适合于挖掘单变量的数值型数据。全距，又称极差，是用来表示统计资料中的变异量数   ，其最大值与最小值之间的差距；四分位距通常是用来构建箱形图，以及对概率分布的简要图表概述。

基于距离的异常点检测算法，

主要通过距离方法来检测异常点，将数据集中与大多数点之间距离大于某个阈值的点视为异常点，主要使用的距离度量方法有绝对距离  曼哈顿距离  、欧氏距离和马氏距离等方法。

基于密度的异常点检测算法

考察当前点周围密度，可以发现局部异常点，例如  算法
特征预处理
很多特征开发出来之后，可能并不在同一个值域中，比如用户对某个游戏的活跃时长特征，可以是  或者  这样，而用户的性别的取值是  或者 ，那么这两个特征如果不做处理，直接放入模型中进行训练，会严重影响模型效果。下面介绍一些单特征预处理的以一些方法：
、归一化
归一化有很多好处，比如可以加快梯度下降寻找最优解的速度，可以提升模型的精度，同时也使得特征之间具有可比性，当然所有的事情都是双面的，经过归一化处理之后，会损失掉源特征的一些信息，但这个损失相对应带来的好处我们还是可以接受的。
归一化可以分成以下类型：

线性归一化


这种归一化方法比较适用在数值比较集中的情况。这种方法有个缺陷，如果  和  不稳定，很容易使得归一化结果不稳定，使得后续使用效果也不稳定。实际使用中可以用经验常量值来替代  和 。

标准差归一化

在完全随机的情况下，我们可以假设我们的数据是符合标准正态分布的，也就是均值为 ，标准差为 ；那么其归一化函数如下：


非线性归一化

在数据分化比较大的场景中，有些数值很大，有些很小。通过一些数学函数，将原始值进行映射。该方法包括 、指数，正切等。需要根据数据分布的情况，决定非线性函数的曲线，比如   还是   等。
实际业务中我们可以根据自己对数据的理解进行不同的归一化方法，下面是手游推荐业务使用到的归一化函数：
正向特征，特征越大打分越大，例如付费金额
 其中 
反向特征，特征越大打分越小，例如首次付费距离当前天数
 其中
汇总特征，取均值，例如活跃天
=天数
可能很多同学会问，这样的归一化为啥会比其他归一化更好呢！或许数学家们可以从公式上进行推到证明，而我们的理解是，其实每个业务的数据都会有特定的分布，比如完全随机的时候数据满足正态分布，那么所选择的方法必须要符合这种数据分布的特点，一般情况下会根据自己对业务数据的了解，对公式进行调整，但是归一化的思路还是跟上面提到的一样的。
、离散化
离散化也可以理解成特征的二值化，即是把原来连续的特征值分段，转化成一个元素取值要么是  要么是  的向量。原始值落在某个段里，向量中此段对应的元素就是为 ，否则为 。其中对原始值进行分段，具体如何分、分成几分，这里面又很多学问；离散化对于线性模型来说是非常有帮助的，原因是它可以将目标值  与特征值的线性转为目标值与离散化之后转化的向量里的每个元素之间的线性关系，这样向量的每个分量都有一个权重，引入了非线性，提升了模型拟合能力。之前做过实验，使用同样的特征，有经过离散化处理的特征训练出来的模型，会比没有经过离散化训练出来的模型效果好 以上；现在使用比较多的特征离散化的方法有，等频离散、等距离散、树模型离散。

等频离散

等频意思是说我们在对特征值进行离散的时候，根据样本点量来选取分割点，举个例子假设就是我们有  个样本，每个样本对应于需要进行离散化的特征都会有一个值，把这个值做一个排序，假设将特征离散成  段，等频就是说  个分段里面的样本数是相同的，一段，排在  这个样本对应的特征值就是一个分割点，依次类推。这种分割方式可以保证每个离散分量有相同的样本数，但也会出现特征值差异非常大的样本被放在一个分段的情况。

等距离散

等距离散顾名思义就是我们根据特征值来进行离散化，比如特征取值是 ，将特征离散成  段，那么【第一个分段，【，一个分段，以此类推；使用这种离散化的方式需要样本分布均匀，不然会出现一个分段占据了大部分的样本，这样不同时间训练出来的模型会偏差很大，也就是说模型不鲁棒。

树模型离散化

树模型是在机器学习中使用非常广泛的非线性模型，其因简单、直观、解释性强而被广泛用于工业界。说到树模型，可能大家第一印象肯定是决策树，决策树的直观理解就是一堆  ，所以这种模型天生具有对连续型特征切分的能力，用于特征离散化也是合情合理的。实际操作中，我们可以单独连续特征和目标值  训练一个决策树模型，然后把训练获得的模型内的特征分割点作为离散化的离散点。
、缺失值填补
在实际业务中，可能会因为各种原因会造成数据的缺失，比如某些用户年龄、性别、设备这类型的特征无法获取到，同时线上模型又有使用这些类型的特征，那么缺失了这些特征的用户在线上打分的时候会出现比较大的偏差；通常会有几种方式来进行处理：数值型特征可以使用均值或者中位数进行简单的替换，年龄这类型的特征可以通过关系链进行加权打分，当然也可以通过把缺失的全部都归为一类，用户默认值来替代。
当然对于新用户或者新  来说其实也是属于一种缺失值情况，对于这种情况已经属于领一个非常大的领域，那就是推荐系统的启动问题。对于冷启动我问题，现在的做法会从两个方面着手，一种是通过集体智慧来解决，另外一种是通过网络模型；第一种方法就是使用协同过滤的思想，与这个新用户类似的用户表现来知道新用户的推荐。第二种利用网络把  周围信息考虑进去，比如下面会提到的层次平滑，热传导模型也可以通过引入基础属性到二部图中，达到解决冷启动问题。
、数据平滑
在推荐场景中会有大量的点击率类型的特征，这类型的特征通常都是使用行为操作量曝光量得到，这类统计类特征会受到行为操作与曝光量之间的关系的影响；比如同一个游戏的  的随着曝光量的增长，点击量的增长率是会不断下降的，也就是说如果不做任何处理行为操作量曝光量产生的特征对曝光量大的游戏是不公平的。对于曝光量小  是有利的，极端的例子是曝光一次，点击一次，那么点击率就是 ，这明显是不可能的；那么如何做呢？一种常用的方式是训练一个 分布，使用行为操作量 曝光量  ；原理是我们可以把每次点击与不点击看成是一个伯努利分布，那么所有用户与所有游戏这种点击与不点击对可以看成是一个  分布，从全局的角度学习到平滑因子；
还有一种方法是，既然不能对不同量级的曝光量进行比较，那我们可以把曝光量进行分段，同一个曝光量级的点击率进行比较。当然还有一种叫做层次平滑的算法，把游戏进行分类，如果单个游戏的曝光量很少，可以使用所述类的平均值进行平滑处理。
特征选择
特征选择的目的是选择模型最优特征子集。特征与特征之间多多少少会有一些相互作用，比如有些特征是包含其他特征，有些特征与另一些特征存在相关性的，也有一些特征需要与其他特征组合起来才能起作用，还有一些特征是会存在负相关的；正是因为特征之间的这些关系，合理的选择适合的特征集合对于模型效果有非常大的作用。现有的特征选择方法可以大体分成三种类型：
、 
这种方法是衡量单个特征值与目标变量也就是样本  值之间的关联，常用的方法有：

相关系数

卡方检验

信息增益：互信息

基尼系数


、 
 这一类特征选择方法，应该来说是比较科学的，但是也是非常耗时，工业界在生产环境中很少使用，非常耗时，也是一个  复杂的问题，一般通过不断迭代，然后每次加入一个特征，来训练模型，使用模型评估比如  或者  等函数评估是否将特征加入到特征子集中。
、
 方法我觉得是一个比较可行的一种方法，它的思想是使用模型自身自动的选择特征，比如正则化——  具有特征选择能力，决策树，每次选择分类节点时，都会选择最佳的分类特征来进行切分，高级一点的如深度学习，很多项目组也在开始使用比如  或者  进行特征选择。
特征评估
前面写了很多特征构造和处理的方法，可能更多时间我们更想知道一个特征是否真的靠谱，在时间有限的情况下，用贪心的思想，每次选择表现最好的特征加入到模型训练中，这个时候就会特征评估这个东西了，特征评估可能会从几个维度进行衡量：
、特征自身的质量

特征覆盖度，这个指标是衡量某个特征能够影响的样本量，一般情况下，会排查覆盖度特别低的

特征的准确性，也就是说特征值是否考虑，会不会存在太多错误数据

特征方差，衡量特征是否有区分度，比如  个训练样本，有  个是 ，那么这个特征方差就特别低，肯定有问题。


、特征与目标值的相关性

相关系数

单特征 


神盾推荐系统特征工程模块

特征工程主要功能模块划分，主要是从特征类型上进行划分，单特征主要包括特征分析、特征组合、特征评估；多特征包括特征选择；衍生特征：特征构造，主要是用过现有特征，通过模型学习的方式生成新特征。
、单特征特征报告

归一化

平滑

离散化

覆盖度

缺失值

单特征 

特征与目标值相关系数

 散度

基尼系数


、多特征特征选择

卡方检验

信息增益：互信息

正则化






、衍生特征特征生成

基于  的  模型

相似度衡量模型，、、热传导



深度学习：、


 
参考文献
斯坦福机器学习视频特征选择常用算法综述      机器学习第十讲 数据降维机器学习中的数学线性判别分析 主成分分析维基百科： 维基百科：维数灾难《        》《   》作者介绍：熊训德

 是一个高可靠性、高性能、面向列、可伸缩的分布式存储系统，利用  技术可在廉价   上搭建起大规模结构化存储集群。本文档用于说明  的  简单原理以及从源码的角度分析一个“写”请求是如何到达  ， 又会做哪些请求。
特别说明  不同版本的的源码差异比较大，但是原理几乎类似，本文档是采用当前线上使用版本  来分析的。
简单原理
有关  的  基本原理在《权威指南》以及网络教程中叙述的算比较清晰详尽，在此只做简单的叙述。
 是基于  树的存储系统，它使用日志文件和内存存储来的存储架构将随机写转换成顺序写，以此保证稳定的数据插入速率。而这里说的日志文件即是文件，用于在服务器崩溃后回滚还没持久化的数据。
 是  的  在处理数据插入和删除的过程中用来记录操作内容的一种日志。大致过程如下图所示，首先客户端启动一个操作来修改数据，每一个修改都封装到  对象实例中，并通过调用发送到含有匹配  的  。一旦  到达，它们就会被发送管理相应行的  实例。数据被写到 ，然后被放入到实际拥有记录的存储文件的  中。同时还会检查  是否满了，如果满了就会被刷写到磁盘中去。

调用链源码分析
本节将从源码角度如上所简述分析的一个“写”过程。
其中基本调用过程如下：

从时序图中可以大体看到

首先  端先把  等  操作封装成，然后使用  协议使用  服务发送到对应的  ， 调用  方法解析发送过来的  协议二进制包，通过  找到相应的  并调用  方法执行：



 等“写”操作会使用  这个  来作用，在  中将会调用  方法去处理，真正调用  的是  的一个实现类 ， 类实现了  的行事务。从 类文档可以看出其主要作用


  方法会  所找到对应的 ，并调用其对应实例  的  方法具体实现写入过程。

在 类中  方法查看有没执行器  ，如果没有则创建一个再调用 方法。 方法是整个“写”操作最核心的方法：把写刷以及写流程都在这里流转。在这里包括异常处理一共有步之多。
它的原型如下：
其中的实现类是。
虽然方法步骤很多，但是最关键的是如下几步：
在这里，将会对加锁，加锁的方式是把所有写相关的行锁都拿到的二阶段锁方式。
在这里将会把放入，但是这里并不是真正的放到了，真正的执行会等方法把日志或者说真正刷入磁盘后，通过版本号异步通知再把数据写到。
在这里会把封装好的使用的方法追加到日志文件，但是由于文件本身在内存中有缓存的原因，还需要调用刷入磁盘。这里只是把数据放到一个  中。这个是一个线程安全的消息队列，在中主要用于有效且安全的协调多个生产者一个消费者模型。其中多个生产者就是这个方法，将会有很多产生数据都放到这个消息队列中，但是只有一个消费者从这个队列中取数据并调用方法把数据从缓存刷到磁盘，这样能保证日志并发写入时日志的全局唯一顺序。
其中有关  可以参看文章，介绍的非常详尽：在这步中会会调用方法，除了，将根据设置的持久化等级选择是否调用的方法


中可以通过设置的持久化等级决定是否开启机制、以及的落盘方式。
可以通过设置持久化等级，如代码： _ 
版本的的持久化等级分为如下四个等级：
_：默认如果用户没有指定持久化等级，使用_等级持久化数据。
_：只写缓存，不写日志。这种方式因为只写内存，因此可以提升写入性能，但是数据有丢失的风险。
_：异步将数据写入日志中。
_：同步将数据写入日志文件中，有可能只是被写入文件系统中，并没有真正落盘。
_：同步将数据写入日志文件并强制落盘。最严格的日志写入等级，可以保证数据不会丢失，但是性能相对比较差。
如代码中所示当前_和_采用的是同一策略都是：调用的方法。是一个阻塞方法，需要等到数据真正的刷到磁盘后，便会唤醒它，然后工作线程返回写入，完成一次“写”操作。
小结
是一个高可靠性、高性能、面向列、可伸缩的分布式存储系统，利用技术可在廉价 上搭建起大规模结构化存储集群。本文档在介绍基本“写”原理后着重从源码角度，比较浅显地分析了一个“写”操作后在的调用过程，为以后继续更深入学习研究“写”过程梳理了脉络。

相关推荐 写入源码分析 线程模型源码分析 跨版本数据迁移总结导语
在领域，语义相似度的计算一直是个难题：搜索场景下和的语义相似度、场景下和的语义相似度、机器翻译场景下句子和句子的语义相似度等等。本文通过介绍、、等深度学习模型在计算语义相似度上的应用，希望给读者带来帮助。
  提纲
 背景
 
 
 
 后记
 引用
  背景
以搜索引擎和搜索广告为例，最重要的也最难解决的问题是语义相似度，这里主要体现在两个方面：召回和排序。
在召回时，传统的文本相似性如 ，无法有效发现语义类  结果对，如从北京到上海的机票与携程网的相似性、快递软件与菜鸟裹裹的相似性。
在排序时，一些细微的语言变化往往带来巨大的语义变化，如小宝宝生病怎么办和狗宝宝生病怎么办、深度学习和学习深度。
   为计算语义相似度提供了一种思路。
本文的最后，笔者结合自身业务，对  的使用场景做了一些总结，不是所有的业务都适合用 。
 
    的原理很简单，通过搜索引擎里  和  的海量的点击曝光日志，用  把  和  表达为低纬语义向量，并通过  距离来计算两个语义向量的距离，最终训练出语义相似度模型。该模型既可以用来预测两个句子的语义相似度，又可以获得某句子的低纬语义向量表达。
 从下往上可以分为三层结构：输入层、表示层、匹配层 

 输入层
输入层做的事情是把句子映射到一个向量空间里并输入到  中，这里英文和中文的处理方式有很大的不同。
英文
英文的输入层处理方式是通过 。举个例子，假设用  来切分单词 个字母为一组，表示开始和结束符， 这个单词会被切为      

这样做的好处有两个：首先是压缩空间， 万个词的  向量空间可以通过  压缩为一个  万维的向量空间。其次是增强范化能力，三个字母的表达往往能代表英文中的前缀和后缀，而前缀后缀往往具有通用的语义。
这里之所以用  个字母的切分粒度，是综合考虑了向量空间和单词冲突：

以  万个单词的词库为例， 个字母的切分粒度的单词冲突为 冲突的定义：至少有两个单词的  向量完全相同，而  个字母的单词冲突降为  效果很好，且转化后的向量空间  万维不是很大，综合考虑选择  个字母的切分粒度。
中文
中文的输入层处理方式与英文有很大不同，首先中文分词是个让所有  从业者头疼的事情，即便业界号称能做到 左右的分词准确性，但分词结果极为不可控，往往会在分词阶段引入误差。所以这里我们不分词，而是仿照英文的处理方式，对应到中文的最小粒度就是单字了。曾经有人用偏旁部首切的，感兴趣的朋友可以试试
由于常用的单字为  万左右，而常用的双字大约到百万级别了，所以这里出于向量空间的考虑，采用字向量作为输入，向量空间约为  万维。
 表示层
 的表示层采用   的方式，相当于把字向量的位置信息抛弃了，整个句子里的词都放在一个袋子里了，不分先后顺序。当然这样做会有问题，我们先为  和  埋下一个伏笔。
紧接着是一个含有多个隐层的 ，如下图所示：

用  表示第  层的权值矩阵， 表示第  层的  项。则第一隐层向量  维，第  个隐层向量  维，输出向量  维可以分别表示为：

用  作为隐层和输出层的激活函数：

最终输出一个  维的低纬语义向量。
 匹配层
 和  的语义相似性可以用这两个语义向量 维 的  距离来表示：

通过 函数可以把 与正样本  的语义相似性转化为一个后验概率：

其中  为  的平滑因子， 为  下的正样本，为  下的负样本采取随机负采样， 为  下的整个样本空间。
在训练阶段，通过极大似然估计，我们最小化损失函数：

残差会在表示层的  中反向传播，最终通过随机梯度下降使模型收敛，得到各网络层的参数{}。
 优缺点
优点： 用字向量作为输入既可以减少切词的依赖，又可以提高模型的范化能力，因为每个汉字所能表达的语义是可以复用的。另一方面，传统的输入层是用  的方式如  的词向量或者主题模型的方式如  的主题向量来直接做词的映射，再把各个词的向量累加或者拼接起来，由于  和  都是无监督的训练，这样会给整个模型引入误差， 采用统一的有监督训练，不需要在中间过程做无监督模型的映射，因此精准度会比较高。
缺点：上文提到  采用词袋模型，因此丧失了语序信息和上下文信息。另一方面， 采用弱监督、端到端的模型，预测结果不可控。
 
针对  词袋模型丢失上下文信息的缺点，   应运而生，又叫 。 与  的区别主要在于输入层和表示层。
 输入层
英文
英文的处理方式，除了上文提到的 ， 还在输入层增加了

如上图所示，其实就是一个包含了上下文信息的滑动窗口。举个例子：把      这句话提取出前三个词  ，之后再分别对这三个词进行映射到一个  万维的向量空间里，然后把三个向量  起来，最终映射到一个  万维的向量空间里。
中文
英文的处理方式 在中文中并不可取，因为英文中虽然用了  把样本空间拉成了百万级，但是经过  又把向量空间降到可控级别，只有  万。而中文如果用 ，那向量空间就是百万级的了，显然还是字向量 万维比较可控。
 表示层
 的表示层由一个卷积神经网络组成，如下图所示：

卷积层—— 
卷积层的作用是提取滑动窗口下的上下文特征。以下图为例，假设输入层是一个  行， 万列的矩阵，代表  个字向量 的和  的长度一般小于 ，这里少了就补全，多了就截断，每个字向量有  万维。而卷积核是一个  的权值矩阵，卷积核以步长为  向下移动，得到的   是一个  的矩阵，  的计算公式是输入层维数 卷积核大小  步长 步长 =。而这样的卷积核有  个，所以形成了  个  的   矩阵。

池化层——  
池化层的作用是为句子找到全局的上下文特征。池化层以   的方式，每个   都取最大值，得到一个  维的向量。 可以解决可变长度的句子输入问题因为不管   中有多少个值，只需要提取其中的最大值。不过我们在上一步已经做了句子的定长处理固定句子长度为 ，所以就没有可变长度句子的问题。最终池化层的输出为各个   的最大值，即一个  的向量。这里多提一句，之所以   层要保持固定的输出维度，是因为下一层全链接层要求有固定的输入层数，才能进行训练。
全连接层—— 
最后通过全连接层把一个  维的向量转化为一个  维的低维语义向量。全连接层采用  函数：

 匹配层
 的匹配层和  的一样，这里省略。
 优缺点
优点： 通过卷积层提取了滑动窗口下的上下文信息，又通过池化层提取了全局的上下文信息，上下文信息得到较为有效的保留。
缺点：对于间隔较远的上下文信息，难以有效保留。举个例子，        ，显然  和  是具有上下文依赖关系的，但是由于  滑动窗口卷积核大小的限制，导致无法捕获该上下文信息。
 
针对  无法捕获较远距离上下文特征的缺点，有人提出了用 来解决该问题。不过说  之前，要先介绍它的爸爸。
 
  可以被看做是同一神经网络的多次复制，每个神经网络模块会把消息传递给下一个。如果我们将这个循环展开：

假设输入  为一个  中几个连续的词， 为输出。那么上一个神经元的输出  与当前细胞的输入  拼接后经过  函数会输出 ，同时把  传递给下一个细胞。

不幸的是，在这个间隔不断增大时， 会逐渐丧失学习到远距离信息的能力。因为  随着距离的加长，会导致梯度消失。简单来说，由于求导的链式法则，直接导致梯度被表示为连乘的形式，以至梯度消失几个小于  的数相乘会逐渐趋向于 。
 
 是一种  特殊的类型，可以学习长期依赖信息。我们分别来介绍它最重要的几个模块：

细胞状态
细胞状态这条线可以理解成是一条信息的传送带，只有一些少量的线性交互。在上面流动可以保持信息的不变性。
 
遗忘门
遗忘门 由  提出，它用来控制细胞状态  有哪些信息可以通过，继续往下传递。如下图所示，上一层的输出   上本层的输入 ，经过一个  网络遗忘门产生一个从  到  的数值 ，然后与细胞状态  相乘，最终决定有多少细胞状态可以继续往后传递。

输入门
输入门决定要新增什么信息到细胞状态，这里包含两部分：一个  输入门和一个  函数。 决定输入的信号控制， 决定输入什么内容。如下图所示，上一层的输出   上本层的输入 ，经过一个  网络输入门产生一个从  到  的数值 ，同样的信息经过  网络做非线性变换得到结果 ， 的结果和  的结果相乘，最终决定有哪些信息可以输入到细胞状态里。

输出门
输出门决定从细胞状态要输出什么信息，这里也包含两部分：一个  输出门和一个  函数。 决定输出的信号控制， 决定输出什么内容。如下图所示，上一层的输出   上本层的输入 ，经过一个  网络输出门产生一个从  到  的数值 ，细胞状态  经过  网络做非线性变换，得到结果再与  的结果  相乘，最终决定有哪些信息可以输出，输出的结果  会作为这个细胞的输出，也会作为传递个下一个细胞。

 
 其实用的是  的一个变种——加入了的 。如下图所示：

看起来有点复杂，我们换一个图，读者可以看的更清晰：

这里三条黑线就是所谓的 ，传统的  中遗忘门、输入门和输出门只用了  和  来控制门缝的大小， 的意思是说不但要考虑  和 ，也要考虑  和 ，其中遗忘门和输入门考虑了 ，而输出门考虑了 。总体来说需要考虑的信息更丰富了。
好了，来看一个  整体的网络结构：

红色的部分可以清晰的看到残差传递的方向。
 后记
介绍完了  及其几个变种，还要给读者泼点冷水， 就一定适合所有的业务吗？
这里列出  的  个缺点以供参考：
  是端到端的模型，虽然省去了人工特征转化、特征工程和特征组合，但端到端的模型有个问题就是效果不可控。对于一些要保证较高的准确率的场景，用有监督人工标注的  分类作为打底，再结合无监督的 、 等进行语义特征的向量化，显然比较可控至少  分类的准确率可以达到 以上。
  是弱监督模型，因为引擎的点击曝光日志里  和  的语义信息比较弱。举个例子，搜索引擎第一页的信息往往都是  的包含匹配，笔者统计过，完全的语义匹配只有不到 。这就意味着几乎所有的标题里都包含用户  里的关键词，而仅用点击和曝光就能作为正负样例的判断？显然不太靠谱，因为大部分的用户进行点击时越靠前的点击的概率越大，而引擎的排序又是由 、、 等多种因素决定的。从这种非常弱的信号里提取出语义的相似性或者差别，那就需要有海量的训练样本。 论文中提到，实验的训练样本超过  亿。笔者和同事也亲测过，用传统  预估模型千万级的样本量来训练，模型无法收敛。可是这样海量的训练样本，恐怕只有搜索引擎才有吧？普通的搜索业务  有上千万，可资源顶多只有几百万，像论文中说需要挑出点击和曝光置信度比较高且资源热度也比较高的作为训练样本，这样就过滤了 的长尾  和  结果对，所以也只有搜索引擎才有这样的训练语料了吧。另一方面，超过  亿的训练样本作为输入，用深度学习模型做训练，需要大型的  集群，这个对于很多业务来说也是不具备的条件。
 引用
                                
                              
                
     ¨      –  
                  – 
         ¨            –  蔡述雄，现腾讯用户体验设计部空间高级工程师。智图图片优化系统首席工程师，曾参与《众妙之门》书籍的翻译工作。目前专注前端图片优化与新技术的探研。

上一篇《包学会之浅入浅出：开学篇》中，我们初步了解单页面组件这个概念，现在通过一个项目，来进一步解析组件的应用吧，
需求背景
组件库是做和前端日常需求中经常用到的，把一个按钮，导航，列表之类的元素封装起来，方便日常使用，调用方法只需直接写上或者这样的代码就可以，是不是很方便呢，接下来我们将要完成以下页面：

这是我们组件库的首页，包含三个子页面，按钮页面、列表页面、导航页面；点击进去子页面会由路由来配置。先看我们的目录结构：

目录存放我们的页面，包括首页和三个子页面；目录存放我们的具体组件，包括按钮组件，箭头组件，列表组件和导航组件组件和页面其实是一样的文件类型，只是由于功能不一样，我们就叫不同的称呼
先看路由配置的代码吧！
路由配置
   
   
 引用页面模板供路由使用
   
   
   
   



   {
   
    {
       
       
       
    }
    {
       
       
       
    }
    {
       
       
       
    }
    {
       
       
       
    }
  
}
有了上一篇的分析之后，这里应该很容易看出来几个路由地址
首页：
按钮子页：
列表子页：
导航子页：
具体每一页的内容分别对应每一页的文件，不知大家是否还记得入口页，这个文件承载着一些公用的元素，还有就是一个路由容器，我们的首页到时候也是挂载在路由容器中的，看看的代码
入口页

   =
     = =开发组件库
    
  



    {
     
}


 
   

简单分析一下入口页的代码，标签是一个公用元素，也就是说到时候每个子页面都会带着这个，他的作用就是方便我们快速回到首页，子页面的内容会注入到中。这里值得关注的地方是标签，我们可以在标签里面直接写样式，也可以直接引入一个样式文件，关键字表示这个样式是私有的，也就是说，即使两个组件写着一样的{}样式也不会冲突，程序会加上命名空间，这也就是为什么在标签中有个参数。
首页

   = 
     = 
       =
         =
           = =按钮
        
      
       =
         =
           = =列表
        
      
       =
         =
           = =导航
        
      
    
  


 
  

首页的代码也是非常简单，和我们平时写差不多，就是几个跳转链接跳到对应的子页面，程序运行的时候，会将标签里面的内容都注入到页面中的标签中，从而实现无刷新的路由跳转。

从下面的内容开始，我们的知识将会深入一些。我们先不急着看其他几个子页面，因为子页面里面只是引用对应的组件，所以我们先从组件开始入手。
按钮组件

   =
    {{}}
  



    {
        {
             {
                下载
            }
        }
  }

 
   
   

按钮组件很简单，就是一个正常的标签，标签中暴露这个组件的属性是的属性值，不是乱写的。当按钮组件被初始化的时候，自定义属性会被绑定到标签中的{{}}中，两个花括号用来绑定属性，这种写法学过模版化前端代码的人应该都比较熟悉。这里需要注意一个地方，如果不是组件的话，正常的写法可以直接写一个对象，比如：{  ：  下载  }，但由于组件是会在多个地方引用的，中直接共享对象会造成引用传递，也就是说修改了后所有按钮的都会跟着修改，所以这里用来每次返回一个对象实例。
这就是一个非常简单的按钮组件，结构、样式文案。
这时候问题来了，按钮中的文案我希望可以异化，不能每次都初始化一个叫做“下载”文案的按钮吧，希望可以以属性的方式来使用，比如这样子写就可以改变我们的按钮文案：
 =确定 =
没问题，属性的接口暴露只需要写在里面就可以了，如下所示修改下标签的内容：

    {
     {
       {
         下载
      }
    }
  }

把属性写在里面，就可以暴露给其他页面调用了，在组件中，是专门用来暴露组件的属性接口的，这里给了一个默认值‘下载’，后面我们要使用的话，只需要 =确认 就可以修改按钮的默认文案了。
我们在上一篇文章的开头就讲了是数据驱动模式的，当我在结构写上=确认的时候，对应里面的属性就会自动修改了。
按钮事件
按钮总少不了点击事件吧，那在中怎么绑定事件呢，用属性，看下代码：

   = =
    {{}}
  



    {
     {
       {
         下载
      }
    }
     {    绑定事件的关键代码
       {
        
      }
    }
  }

属性中可以写任何的自定义函数，写完之后绑定的方式也很简单，在上写关键字，把对应的事件写上就可以了，以上代码实现的就是点击按钮弹出按钮中的文案，是里的一些关键字，叫做指令，我们后面会慢慢学到更多的指令；可以缩写为，当然还有其他的事件比如等等；
使用按钮组件
现在我们大致做了一个按钮组件了，那么怎么调用它呢，去到我们的子页面。


   =
    使用
     =确定 =
  


      引用
    {
     
     {
        注册自定义标签
    }
  }

从开始解析，首先引入我们的组件赋值给变量，使用时候直接将作为对象的一部分写进属性，这是用来存储引用组件的关键字，同时对应我们自定义的标签 ，完成这些操作之后，我们就可以在中使用自定义的按钮组件上面也说了用属性来自定义按钮的文案。完成之后，我们就可以在页面中看到具体效果，点击按钮弹出对应的文案。

上述我们将按钮事件写成默认的，如果有些按钮想要异化怎么办。之前说了属性可以支持自定义，那么按钮的点击事件如何支持自定义呢？

监听子组件的事件
 = =我可以点击 
上面的代码在引用组件的时候，注册了一个事件，这个事件是之前我们在按钮组件中绑定到按钮的事件中的，然后我们给这个事件一个自定义的方法，同时，在中声明这个自定义的方法如下：

页面中引用子组件并监听子组件的事件

     
    {
     
     {
       
    }
     {
       {
        你点击了组件的
      }
    }
  }

专业一点的说，这种做法叫做监听，由引用方暂且叫做父组件监听子组件的内置方法；同时在子组件中，需要触发这个事件，以下是在子组件中的关键代码：

子组件中的代码

    {
     {
       {
         下载
      }
    }
     {
       {
        先弹出默认的文案
        关键代码父组件触发自定义事件
      }
    }
  }

这里的关键代码就是，也叫触发机制，父组件监听，子组件触发。如果觉得绕，以下描述可能会比较好理解：小子组件有一个电话号码子组件注册的事件，有一天小把电话号码告诉了小父组件，让小打电话给他，于是小就拨打了小的电话号码监听，这时候整个沟通流程没有结束，必须要小接听了电话触发，两人之间才算完成了打电话这件事情。
完成这步之后，引用方父组件就可以给不同子组件调用不同的事件处理了：
 = =确定 
 = =取消 

这里只是简单展示
     {
       {
        
      }
       {
        
      }
    }

给按钮加图标
有时候单纯的文案异化还不够，比如一些按钮是图标文字类型的，而且图标还可能不一样，那应该怎么办呢？

如果按钮组件的结构除了开发时候预设的那些结构之外，允许我们在调用的时候添加一些自己想要的结构，那是不是解决了呢，是的，早就为我们考虑了这一点，他就是标签。
下面给我们的按钮组件加上一段结构



   = =
     =重点在这里
    {{}}
  

加入了关键字并赋予一个值之后，我们再看看引用如何使用

 =下载 =
   = = = 

上有个关键字=对应组件中的=，渲染的时候，会将整个替换掉组件中的对应的标签，其实很好理解，的翻译是插槽的意思，相当于把这块内容插到一个名叫的插槽里面去。
中场休息一下
学到这里，我们已经学会了用给按钮自定义文案，用和给按钮自定义点击触发，用给按钮添加一些自定义结构。当你回头去翻文档的时候，你会发现，事件，这三样刚好就是学习组件通讯中最最最关键的三个环节。将这三个环节以实际案例解析出来后，好像也没有那么难了吧！
上述我们已经讨论了如何制作一个按钮组件，以及如何使用我们的按钮组件。

接下来我们通过制作一个导航组件，来了解中对于循环的巧妙使用。
导航组件

我们将完成这样一个导航组件，点击导航中的，可以给当前加上一个类，同时切换底部的黄色滑条，并且输出当前的文案，同时支持自定义事件。
由于在现实项目中，我们导航的个数是不定的，所以制作组件的时候，我们希望可以暴露一个属性来支持导航的个数，而的长相和应用其实是一样的，那么这时候我们可以用一个循环来输出每一个。先看看关键代码：


   = 
     =    关键代码
       ={{}}
    
  



    {
    {
       {
        
          {
             首页
              
          }
          {
             列表
              
          }
          {
             关于
              
          }
          {
             招聘
              
          }
        
      }
    }
    }
  }

该段代码的关键地方在于标签上关键字还记得我们在前面说过的绑定事件吗，关键字是预留的可以把它理解为中的  循环，是我们在里面定义的对象还记得为什么要写在中返回吗？。=  暴露了和两个接口，这是提供的，代表中的每一项以及该项对应的下标，接着我们就可以在标签中使用绑定｛｛｝｝了。
这段代码理解了之后，我们再延伸一个动态添加的概念。我们希望每个都有默认的类名比如类，在点击每个的时候，当前添加类，其他的删除这个类。在怎么实现呢？
动态类名


   = 
     =    =     
       ={{}}
    
  



    {
    {
       {
        
        
        
            数据
        
      }
    }
  }

在中添加了一句关键代码
=    
给组件绑定一个属性类似中的方法，这里的写法是缩写，他的全拼应该是又一个写法。注意到最前面有个冒号，：=和=的区别在于不带冒号的是静态的字符串绑定，带冒号的是动态的变量绑定。我们给绑定了一个数组，这个数组带有变量，先看，这个变量在中定义了，然后数组的第二个元素是一个的三元运算符：，当每个中的值为时，绑定变量对应的类，如果为，则为空。最后的结果是当为时候，的值为 ，当为，就只有。
上面的代码可以理解的话，那么我们切换的类，就转换为修改每个里面的的值再次体现数据驱动。
那么问题来了，怎么去修改每个里面的值呢？没错，给每个绑定一个点击事件，当点击事件触发的时候，修改当前对应的值。于是代码变成了如下：

   = 
     =    =     = 
       ={{}}
    
  



    {
    {
       {
        
        
        
          {
             首页
              
          }
          
        
      }
    }
    {
      {
        默认切换类的动作
        {
           = 
        }
         = 
        开放用户自定义的接口
        
      }
    }
  }

我们利用循环给每个标签绑定了一个事件，对应中定义的，接收两个参数和你也可以传人和，看个人代码喜好，然后当点击的时候，把中的每个置为，把当前的的值置为，这样就可以动态切换类了。最后再触发一次自定义事件参考按钮制作自定义事件。
以上就是我们导航组件的内容了，回想下我们做了啥？循环输出每个，为每个绑定动态的类名，同时在点击事件中动态切换类底部的小黄条其实是利用类做的
小结
回顾下我们这一篇章都学了什么内容。

页面路由的配置
按钮组件自定义属性
按钮组件自定义事件  
按钮组件自定义子块
循环实现导航组件
动态类名

上述内容已经基本上涵盖了组件的重要知识点，主要是父组件页面和子组件之间的调用和通讯数据交互绑定，好好消耗一下我们会发现，其实的总体逻辑思想和是一样的，毕竟最后都回归到，只是由于代码设计角度的不同，我们可能看到和以前调用时候的写法不一致，但其实都有对方的影子在里面，相信理解了的代码思想之后，以后我们学习等其他类似的框架的时候，也会比较得心应手了。
下一篇文章《包学会之浅入浅出：结业篇》中，我们将会学习如何用多个组件来组成一个大的组件，也就是真正意义上的父子组件之间的关系。再忍耐一下，就可以出山了，新领域的大门就在前面，让我们大步往前跨吧。
文末附上所有相关代码和官方文档地址

相关推荐
第一篇：《包学会之浅入浅出：开学篇》
第三篇：《包学会之浅入浅出：结业篇》腾讯云小微自月日上线内测以来，吸引了众多关注。在月日腾讯“云未来”峰会现场，腾讯云小微以“声音连接物理世界”为主题，正式在小微专场上亮相发布。
腾讯云刚刚宣布“即服务”战略，小微作为具有代表性的解决方案与能力平台，吸引了众多关注。小微专场门口排起了长队。
腾讯云小微此次发布的不仅仅是此前内测上线的三大平台，更重要的是腾讯云小微与大量合作伙伴也在此次专场上登台亮相。

腾讯云小微是一套腾讯云的智能服务系统，也是腾讯云倾力打造的一款智能服务开放平台，可以让硬件快速具备语音和视觉感知能力。同时，腾讯云小微又是一种智能解决方案，可以赋予硬件更多的能力扩展，从而构建一个丛云到端的“智能云生态”。
腾讯云副总裁王涛在会议中对小微给出了定义：“小微就是将腾讯这些取得突破性的成果、将这些人工智能的能力，再结合物联的技术，我们赋予这些硬件设备听觉、视觉，打造智能人机交互的开放平台和解决方案。”

腾讯物联云语音云总经理毛华认为，智能硬件的时代结束了，但真正的智能时代开始了。智能硬件加上云计算，将带来实用可靠的能力和产品。
毛华介绍，腾讯云小微是一套腾讯云的智能服务系统，也是腾讯云倾力打造的一款智能服务开放平台，可以让硬件快速具备语音和视觉感知能力。同时，腾讯云小微又是一种智能解决方案，可以赋予硬件更多的能力扩展，从而构建一个丛云到端的“智能云生态”。

目前，已经有余家合作伙伴接入了腾讯云小微，多家硬件企业也在现场进行了与腾讯云小微合作的新品发布。
腾讯产品总监发布了小机器人第二代。定位于儿童成长伴侣，能够智能伴随孩子的成长。在关注孩子的成长同时，腾讯云小微与机器人平台、优必选、华硕共同进行了产品发布。腾讯云小微全面支持的优必选和腾讯的联合品牌会在月份左右进行产品上市，月底基于腾讯云小微能力打造的和华硕的合作产品也将全面上市。
数字家圆创始人兼唐波携着数字家圆和腾讯云合作的新一代产品“亲见家庭语音助手”亮相。通过腾讯云小微为其提供的项全新能力，“亲见”具备了智能能力，满足于生活的各个场景。据了解很快就会出现在终端市场，正式和消费者见面。另外，物联网平台也已经接入腾讯云小微能力，让家电也具有智慧。
在技术方面，腾讯云小微的语音和视觉感知能力基于腾讯强大的技术积累。微信首席架构师牛成在专场中解释了自然预言理解在腾讯云小微的应用，优图实验室基础研究组研究总监戴宇荣也做了图片识别技术应用的分享。
作为小微的核心能力，音乐负责人王宝华分享了智能时代的音乐体验，搜狗搜索总经理许静芳也带来了智能网红“汪仔机器人”，并介绍了搜狗的回答与翻译技术。
腾讯云小微目前还刚刚起步，正在积极的接入更多的合作伙伴，共同打造智能云生态。月日，深圳，腾讯云未来峰会，腾讯云发布战略新品——智能云，定义人工智能进“即服务的智能云”时代，宣布腾讯云在领域全线布局，将腾讯积累近年的能力向政府、企业和开发者开放，腾讯云将首先开放腾讯在计算机视觉、智能语音识别、自然语言处理的三大核心能力，截至目前，腾讯云围绕这三大能力，已提供种服务，包括应用服务种，平台服务种，框架服务种。    
腾讯云本次开放的三项核心能力计算机视觉、智能语音识别、自然语言处理有由上述个团队提供的技术。 提供的自然语言处理能力识别准确率超过 ；优图实验室提供计算机视觉处理能力，在国际权威人脸识别数据库测试中准确率超过 ；而微信智能语音团队提供的智能语音识别能力高于。以上均属业界领先水平。
对于普通开发者而言，现在可以通过腾讯云开发者实验室门槛体验优图鉴黄等能力。
选择 体验万象优图   
选择体验万象优图   这个实验，微信扫码即可免费领取实验机器。

准备工作
、在使用万象优图前，您需要实名认证。
前往 密钥管理 页面获取你的 ， 和  信息，这些信息将会在调用万象优图的接口时候用到。如果你还没有创建过密钥，可以在该页面点击 
、创建 ， 用于存储使用万象优图时候用到的图片。
点击这里前往腾讯云控制台 万象优图  管理 页面创建一个  并记住名称，其他选项默认即可。 
、配置使用环境
安装  与 
      
创建测试要用到的图片：创建  目录用于存放图片
  
随意上传一张测试用的图片到此服务器的  目录，这里我们用


使用下面的命令将此图片保存到  目录。
 ____  
安装 万象优图   
   
使用万象优图的鉴黄
编写调用代码：
在  目录下创建 ___ 文件 内容如下

_ ____  
 \

 =  你的_ 你的_ 你的_ 你的名称


_
    =  可将此处鉴别的图片替换成自己要鉴定的图片
    
其中个人密钥在 中查看：

执行并查看结果
执行以下命令来运行编写好的  代码：
    ___
执行成功后返回结果如下：
其中返回字段数据代表的意义如下

 供参考的识别结果，正常，黄图，疑似图片
 识别为黄图的置信度，范围；是_ _ _的综合评分
_ 图片为正常图片的评分
_ 图片为性感图片的评分
_ 图片为色情图片的评分
_ 封禁状态，表示正常，表示图片已被封禁只有存储在万象优图的图片才会被封禁

也就是我们上传的 调用优图接口后被识别为正常图片，属于性感图片的得分，为黄色图片的得分为。
虽然很高大上，通过这样一个小小的腾讯云上实验，开发者分钟就可以体验到腾讯云提供的智能鉴黄服务 的便利。云计算会让人工智能变得更加触手可及了解更多腾讯云相关的产品可以查看：
万象优图 智能语音服务 文智自然语言处理深度学习平台 
还有我们的系列教程：
使用腾讯云  学习深度学习系列之一：传统机器学习的回顾使用腾讯云  学习深度学习系列之二： 简明原理使用腾讯云  学习深度学习系列之三：搭建深度神经网络使用腾讯云  学习深度学习系列之四：深度学习的特征工程使用腾讯云学习深度学习系列之五：文字的识别与定位一、概要
腾讯分布式文件存储的数据量在短短数年时间里从增加至级别，使用了几十万块磁盘，增长速度非常迅猛。另外， 承载的几乎都是互联网在线存储业务，需要在保证业务正常访问的情况下经常性快速扩容。在这种情况下，存储系统的伸缩性显得尤为重要，扩容过程的高效、稳定就成为必须要解决的问题。
下面介绍平台实现级存储伸缩的几个关键技术。
二、存储  模型
在系统快速扩容的过程中，必须要解决的问题是：系统以何种方式进行扩容，扩容的时候如何保证扩容操作和流程简单、快速、可靠。 的数据层使用了存储来解决这些问题。
存储  是  系统内部快速扩容的一个标准单位。 整体的系统架构采用了文件索引和文件数据内容分离存储的设计方式，整个数据集群划分为多个存储  ，各个存储  独立运营，之间没有任何依赖。每次需要扩容的时候，只要增加存储  到  存储系统中即可。

、存储  定义
存储内部自成存储集群。每个  内部有控制节点  和若干存储节点  组成。其中  节点负责整个子系统内部的集群控制、路由、数据调度等控制层逻辑；而  则部署到各个存储服务器上，负责本地数据的存取，  内部的数据复制与重建，底层磁盘管理等数据层的逻辑。
存储  有以下特点：
◆ 每个存储  对外提供了独立的数据读写功能，数据上传之后， 会返回一个存储  内部的  供客户端后续访问。
◆ 存储  内部的各个存储节点采用了同构设计，一个存储  内部只有一种类型的存储服务器硬件，这样可以大大简化存储  内部的负载均衡和空间管理。各个存储  之间采用同样数量的硬件。比如典型备份的存储  都使用了台存储服务器。

、存储  的使用优点
当集群规模变大之后，不可避免地会遇到人工操作失误、评估困难、资源调整、软硬件更新换代等问题。而  把数据集群拆分成各个标准化的存储之后，可以带来以下好处：
标准化部署
因为每次需要扩容的时候，只需要再多部署指定数量的存储。这种例行的扩容操作就很容易标准化下来。对于系统规格的评估也变得相对简单，可以简化为每个可以提供多少存储容量，以及对应的性能规格。这样人工操作失误导致事故的概率就大大降低，也很容易从系统层面自动进行校验，提前发现风险。
故障隔离
数据的复制、流动限制在存储内部，所以单个节点故障造成的影响只会限制在单个存储内部，不会影响到整个系统。这样就可以起到很好的故障隔离效果，解决大规模集群下，错误扩散的问题。
单独的读写控制
因为各个存储各自相对独立，我们很容易在接入层对各个存储的写负载进行单独控制。在进行新的软件版本测试和灰度上线的时候，就可以逐步放量，比较容易控制节奏。
高效数据迁移
 系统已经运行好多年，几乎每年都会有机房裁撤和机器退役导致的数据迁移需求。存储  模型固定之后就可以使用两个存储  之间数据对拷的方式，而不用修改文件索引层，大大降低数据迁移的成本。
三、弹性小表
 的文件索引部分使用的是基于一致性哈希设计的分布式  系统  。 通过将哈希空间等分为  份，每份作为一个虚拟节点，在  系统中使用称为小表的逻辑结构来承载。在进行数据迁移和扩容的时候，小表是最小的调度单元。
 的索引系统无法像数据层那样分为各个  ，只能使用中心服务式的设计，在弹性方面要能够从台服务器扩展到上千台。在云服务的场景下，除了常规的扩容之外，还需要解决多租户、以及成本优化等问题。
、资源隔离
作为云存储的平台， 需要支持多租户特性。在多个租户共享一个存储集群的时候，各个租户之间在容量和访问性能上难免会有冲突。
 给底层的小表分配各自独立的物理存储空间，同时每个小表的  性能也从存储引擎层面做了限制。通过将不同的小表分配给不同的租户的方式，解决了云平台多租户数据物理隔离的问题，并且为每个租户提供了基础性能保证。

、按需分配
在进行容量配额管理的时候，从一开始就为每个小表指定好一段连续的物理存储空间是最简单的实现方式。但是在实际运营的过程中，往往会遇到容量预估不准确等问题。另外在进行扩容的时候，为了保证迁移粒度不至于过大，需要进行小表分裂。但是当分裂刚完成的时候，空间利用率又会有突然下降。这样每个小表都需要各自独立的预留空间，存储空间利用率很低。
为解决这个问题，我们对每个小表的存储空间采用按需分配的策略。只有当数据真实写入的时候，才从整个  线型空间上分配一个  给这个小表。这样在进行小表分裂的时候，各个小表未使用的空间不必预先占用，从整体上提高了  系统的存储利用率，并且又不会丧失在物理上资源隔离的优点。

四、 系统
 系统使用了非常多的大容量廉价机械磁盘，同时这些磁盘是整个  系统中故障率最高的硬件部件。另外，在系统不断变迁的同时，不可避免会引入不同规格、不同供应商提供的各种硬件。如何高效使用这些硬件，并提供统一的错误处理，是整个存储系统保证稳定可靠必须要解决的问题。
 系统使用了  作为底层磁盘的一个管理系统，将底层不稳定、异构的硬件介质屏蔽为相对统一、稳定的资源，在扩容的时候良好地支持各种存储类型的硬件。
、盘符管理
  的盘符漂移一直以来都是分布式存储系统需要解决的一个问题。但是传统存储系统中，修改内核固定盘符的做法过于笨重，每当需要适配新内核版本的时候，盘符管理的部分也需要随着更新一次。并且添加新的硬件类型支持也不容易。
 使用的是纯用户态处理的方式，使用  机制，将现有系统的盘符重新映射，为上层软件提供必需的硬件槽位信息。这种做法没有  内核版本的限制，对于硬件的兼容性也较好。在插拔硬盘的时候，即使不重启存储服务器，逻辑盘符也不会发生变动，也很大程度上降低了运维的压力，以及坏盘对系统带来的冲击。

、 栈定制
 默认的  栈为了通用性考虑，比较复杂。目前开源的分布式存储系统普遍基于文件系统进行设计，整个链路过长，出问题的话定位起来也很困难。如果存储进程因为  未响应卡住，必须重启服务器才可以解决，影响范围较大。
 采用了定制的  栈，绕过了  等部分，并且提供了  超时处理，防  挂死等强化设计，使得整个底层  路径更加简单可靠。

、磁盘扫描
机械磁盘上的数据在长久存储之后，会因为磁盘坏道等原因造成部分数据丢失或损坏。但是如果没有业务访问来触发这个错误的话，很可能无法及时修复，造成数据可靠性降低，有数据丢失的风险。这个问题在数据规模越来越大，数据越来越“冷”的情况下显得尤为严重。
 提供了磁盘定期扫描的功能来解决数据静默错误的问题。每个月会将磁盘上的数据完整扫描一遍，发现磁盘坏扇区，并针对这些区域进行自动修复。提升了  数据的可靠性，并避免整盘替换带来的系统冲击。
另外，磁盘扫描的时候，会对业务  的性能表现造成影响，所以  会实时监控业务访问的压力。当磁盘比较空闲的时候全速扫描，业务有压力的时候降低扫描的压力，如果业务压力过大则暂停。
五、总结
 存储系统通过  模型、弹性小表、 等关键的技术和设计，切实地解决了大规模存储系统在快速扩容时遇到的一系列问题，有效地支撑了  存储系统的高速发展，为所有使用  存储系统的业务保驾护航。 搭建开发环境
本文描述了在下用 搭建开发环境，以及在本地和上运行应用。 
 安装 
下载并安装版本的。版本的是免费的，下载地址：。 
 创建项目
首先安装插件，点击菜单栏    ，搜索，点击右侧即可：

我们是通过 创建工程的，创建项目之前需先添加新的，点击菜单栏    …，选择项目，点击 ：

 
 
 
只需手工添加一次。
然后创建工程的，点击菜单栏    …，选择刚才添加的：

填好相关参数，一路，等初始化完成后，得到如下的项目结构：
 
 编译
的版本是，版本是。编译前需修改的内容，否则会导致编译错误。
在的中，把 改成：

在的中，添加对的依赖：

    
    _
    

在的中，添加对的依赖：

    
    _{}
    
    

修改，添加 中的代码做演示：
 

 
 { }

  {
      = {
      =  “”
      =   

      =       
      =    

      =    
       {
         =
            =     
            =     
                      
      }
      _  _

               

    
  }
}
点击菜单栏     编译工程，得到如下的错误提示：

这个错误是因为我们用的版本的编译器已经不支持该编译选项了，解决办法是打开，查找到该行，删掉即可。 
重新编译项目  ，没有错误了，编译成功，编译结果保存在 目录下。 
 打包
在上运行应用需要上传文件，打包文件也很方便，打开  对话框：

填入打包命令  – ，点击：
 
等构建完成，在目录下得到包：

 运行应用
 本地运行
支持在本地运行应用，非常便于测试和调试。要在本地运行应用，只需在创建时设置其为即可：
  =  
    
    
点击菜单栏  …    运行，在大段的日志中得到的运行结果：
 
由于在上运行时不能设置为，有个小技巧兼容这种情况，即根据操作系统类型来创建：
   = {
      = 
        

      {
       
        
        
    }  {
       
        
    }
}
使用这个技巧的前提是本地开发的系统是，生产环境是。 
 参考资料


_ 


 
性能调优



相关推荐
【教程】核心概念【腾讯云的种玩法】  单机环境搭建与初步学习一、环境配置



操作系统





内存




选择自己语言版本的  下载地址，这里我选择的是  版本 。
二 环境依赖
安装 
 安装  可以用如下命令：
    
 或者自己下载  版本的安装包安装  下载地址 ，注意选择  版本。 典型的安装方式如下：
 
  
   
如果请求采用  方式，安装时需打开  支持。
安装完成后可以随便找个  试下命令：
  会出现如下  代码就表示安装成功： 

如果安装后不能使用，这时候可能是你没有安装  
输入命令：
   
然后根据提示选择相应版本进行安装即可。
 生成   库文件
首先，在安装完  后，查找到  这个文件夹一般是在网上下载的  压缩
包解压后， 文件夹下，这里有生成库需要依赖的头文件，把  文件拷到你项目的  目录下： 备注： 为测试项目，详见附件 
 
接下来，查找到  的库文件，链接到项目的  目录下，之后生成   库文件。
将目录切到项目的  下： 
 
执行  命令，会生成  和  库文件。 

至此，库文件生成已经完成，接下来就是配下环境就可以做试用了。
  试用
在使用之前需要配上库的路径： 
 目录为  示例代码，执行  可编译，执行示例程序前，如果是链接的 需把其所在目录加入到环境变量__ 中，方法：
 __= 所在目录__

加入完成后是这样的： 

库文件路径加好之后，就可以进行编译了。
切到  目录下：
执行  进行编译 

 完成后生成可执行文件。
在这一步的过程中可能会出现这样的错误： 

这个错误是由  位  位的问题引起的，这时候要检查一下  文件里的 
=
=
这两项，因为我装是的  位  所以用  位的编译方法。根据具体操作系统位数调整。 

以上步骤完成之后， 文件夹下会生成 _ 的可执行文件，这时候在去执行就好了。 

至此，就全部结束啦！然后可以根据自己的业务去写代码使用了。有需要补充的地方希望大家多多补充。

相关推荐
 腾讯云消息队列测试腾讯云分布式高可靠消息队列架构 消息服务快速入门 的使用非常普遍，跟有关的话题也非常多，如性能优化、高可用性、强一致性、安全、备份、集群、横向扩展、纵向扩展、负载均衡、读写分离等。要想掌握其中的精髓，可得花费不少功力，虽然目前流行的替代方案有很多，可是从最小成本最容易维护的角度而言，还是首选。下面从应用场景的角度切入，对的技术点进行组织，写一份知识图谱，方便“下学期年”进行更深入的学习和总结。
如下图整理，我试着把  的应用场景分为种，每种场景下需要考虑的重点问题不一样，从而引出不同问题点下需要补齐的知识点，后续继续基于这些知识点进行学习和整理。期待大家的意见和提供学习材料，谢谢！

一、单

单的情况是普遍存在的，对于很多个人站点、初创公司、小型内部系统，考虑到成本、更新频率、系统重要性等问题，系统只依赖一个单例数据库提供服务，基本上已经满足需求。这种场景下我觉得重点应该关注的话题有上图所示的四点。
其中最重要的环节是数据备份，如果是交易量非常低，并且具有非常明确的服务时间段特性的话，简单的是可以胜任的。但是这是有缺陷的，数据还原之后注定从备份点到还原点之间的数据会丢失。然而在极多数的情况下，备份的工作是没法马虎的，如下列举的几点小细节，下学期将分享更多操作性的文章。
冷备：停机，直接物理文件，引擎文件、共享表空间文件、独立表空间文件、重做日志文件、。
恢复：把文件到对应目录。
热备： 或者工具，记录重做日志文件检查点的，共享表空间文件以及独立表空间文件不产生任何阻塞，记录后重做日志文件检查点的，备份是产生的重做日志。
恢复：恢复表空间文件，应用重做日志文件。 
温备： 

，参数进行事务管理保证数据一致性。备份时不能用语句。 恢复：直接执行文件， – – 文件名

二进制半同步复制，主从服务器增量复制


恢复：
二、一主一从

考虑一主一从的多数初衷是系统性能和系统高可用性问题，除了单场景中的备份工作需要做好以外，还有性能优化、读写分离、负载均衡三项重点工作需要考虑。其中性能优化的内容比较多，也是一块大主题，要从系统的服务指标作为依据采取相应的动作，多数系统要求的是秒内完成请求，总体换算下来，数据库大概可以有秒的总执行时间，能满足这个性能要求就是合理的优化方案。下学期以这样的优先级来分别整理内容：索引优化 》 表设计优化 》数据库配置优化 》硬件优化。
读写分离和负载均衡的实现相对简单些，我目前维护的系统比较落后，没有做读写分离，因为是一套以报表类功能为主的系统，而负载均衡是依赖代码来做的，从实际运维效果来看，不大理想，而且负载均衡的代码过分嵌入到业务逻辑代码中，给代码维护带来一定噪音。下学期计划对各种中间件进行实践和性能测试，到时候把一些测试数据分享出来。
三、一主  从

一旦开始考虑一主多从的服务器架构，则证明你的系统对可用性、一致性、性能中一种或者多种的要求比较高。好多系统在开始搭建的时候都会往这个方向看齐，毕竟这样“看起来”系统会健壮很多。不过其实并不能单单依靠的配置和自带的中间件来解决可用性、一致性方面的问题。
四、横向集群

系统庞大到需要分库分表，其实是一件可喜可贺的事情，但是切记的是要前面提到性能优化工作做到极致之后才好考虑这些会增加系统复杂度的解决方案。横向集群主要是从业务特性的角度对系统进行切分，最彻底就是切分成了各个子系统，子系统之间通过一些数据同步的方案来把一些核心数据进行共享，以避免跨库调用跨库。
然后是各种系统接口调用，把大事务拆成小事务，事务之间做好隔离和同步。上图中的三个问题在横向集群的架构体系中应属于很有特色的问题，在实际项目中其实是尽量去避免这些需求的存在的，不过如果确实需要了，也得有解决方案。下学期也将针对这些问题进行逐一整理，并测试一下一些号称支持这些功能的中间件。
五、纵向集群

横向集群的切分思路最终是切分子系统，而纵向集群最后遇到的最棘手的问题是扩缩容，我运维的一个系统是提前对数据做了个切片，切片中切片和切片分别存在两个一主两从的数据库集群中，系统运维了年多，目前还没有扩容需求。设计初衷应该是考虑得到，假设有一天数据量非常大，可以把个切片分大片，分别存储到个一主两从的集群中，从而实现扩容。
这个思路的确是可取的，只是我们的分库逻辑当前是代码实现，也有一定程度上影响了业务代码的逻辑，运维起来有点心惊胆战，还是保持业务代码清爽比较好。
下学期将介绍一些实现了库路由功能的中间件的使用，也根据实际情况把想到的一些扩缩容方案实践一遍，敬请期待实操效果的分享。
六、混合模式
与其说这部分内容讨论上面种场景的混合，不如说这部分内容是做总结。上面的种场景中，一共列举了个问题点，这个问题点基本上都是叠加式的，越往深入的框架去做就越需要考虑齐这个问题点。个问题点考虑全了，混合模式下的问题就不成问题了。
数据库的文章有很多，不过文章只能局限在某个细节上进行分析，阅读得太零散往往会只见树木不见森林，所以好的文章得看，好的书更得看，基于这些知识的汇总梳理更更得做，年撸起袖子加油干！作者：莫卓颖

背景：

最近一段时候由于需要搭建后台测试系统，因此需要在系统下搭建、、、，由于网上的教程比较零散并且很多都过时，因此重新梳理整理如下：


安装
        

数据库配置文件
    

 启动
      

 开机自启动
      

 设置登录密码
     用户名字 密码

 登录
     用户名字 密码

 忘记密码
      
    _ = 
      
     
       =_  =
     

安装
 配置源
      _ 
      

 确认安装的版本
      = = |  

 安装
      = =                   

 确认版本
     

 启动
     

 开机自启动
      
       

安装 库
 安装
       

 建立库地址
      
      

 设置权限
进入上面生成的文件夹下，进行配置   有以下几个文件  ，设置
 设置权限
设置上面的用户对文件的权限
 设置访问权限
     =   使非授权用户无法访问
 =   使授权用户有写权限
 = 
 =     访问控制文件
 =   认证命名空间，会在认证提示里显示，并且作为凭证缓存的关键字。

启动
       设置目录

查看端口
      |  

安装
 安装
         

启动
      

 开机自启动
      
        

、 启动
         
     _
      _
     _
      

     _=安装目录
      _=安装目录


原文链接：


相关推荐新时代运维监控能力的进化——天网云用户体验监控平台实践 占用空间一键查询实践开发工具、或、

技术框架 核心框架：   持久化框架：  安全框架：   日志管理： 、  数据库连接池：  消息总线：  工具包：   框架：

系统运行环境  软件环境：
 
 或以上
 或其他容器
  
  硬件环境最小配置：
 ：核
 内存：

安装部署  说明
 运营管理系统登录账号密码：
 商户后台系统登录账号密码：在运营后台添加用户时录入手机和密码
 ：公共类工程，不用单独部署
 ：核心业务类工程，不用单独部署
 ：通知应用工程，独立方式启动
 ：对账应用工程，独立方式启动
 ：结算应用工程，独立方式启动
 ：运营管理后台，部署启动
 ：支付网关工程，部署启动
 ：模拟商城工程，部署启动
 ：商户后台工程，部署启动
  步骤
  创建数据库，导入初始化脚本《》
  修改系统数据库连接
  从工程的文件夹下加载支付宝支付“”和
 “”
  下载 并安装，修改配置 _，
        以独立方式启动工程
      注：商户通知是独立的一块，不影响支付及其他功能，可以省略该步骤
  以独立方式启动工程
  修改对账文件下载后存放地址_，
        以独立方式启动
  添加支付宝和微信测试账号信息_
        和_
     注：不需要本地测试支付，可以省略该步骤
  通过 命令打包编译系统
  拷贝、、、至启动


在线支付演示：后台运营管理：地址：开源中国地址：我们都知道虚拟机的内存划分了多个区域，并不是一张大饼。那么为什么要划分为多块区域呢，直接搞一块区域，所有用到内存的地方都往这块区域里扔不就行了，岂不痛快。是的，如果不进行区域划分，扔的时候确实痛快，可用的时候再去找怎么办呢，这就引入了第一个问题，分类管理，类似于衣柜，系统磁盘等等，为了方便查找，我们会进行分区分类。另外如果不进行分区，内存用尽了怎么办呢？这里就引入了内存划分的第二个原因，就是为了方便内存的回收。如果不分，回收内存需要全部内存扫描，那就慢死了，内存根据不同的使用功能分成不同的区域，那么内存回收也就可以根据每个区域的特定进行回收，比如像栈内存中的栈帧，随着方法的执行栈帧进栈，方法执行完毕就出栈了，而对于像堆内存的回收就需要使用经典的回收算法来进行回收了，所以看起来分类这么麻烦，其实是大有好处的。
提到虚拟机的内存结构，可能首先想起来的就是堆栈。对象分配到堆上，栈上用来分配对象的引用以及一些基本数据类型相关的值。但是·虚拟机的内存结构远比此要复杂的多。除了我们所认识的还没有认识完全的堆栈以外，还有程序计数器，本地方法栈和方法区。我们平时所说的栈内存，一般是指的栈内存中的局部变量表。下面是官方所给的虚拟机的内存结构图

从图中可以看到有大内存区域，按照是否被线程所共享可分为两部分，一部分是线程独占区域，包括栈，本地方法栈和程序计数器。还有一部分是被线程所共享的，包括方法区和堆。什么是线程共享和线程独占呢，非常好理解，我们知道每一个进行都会有多个线程同时运行，那么线程共享区的这片区域就是被所有线程一起使用的，不管有多少个线程，这片空间始终就这一个。而线程的独占区，是每个线程都有这么一份内存空间，每个线程的这片空间都是独有的，有多少个线程就有多少个这么个空间。上图的区域的大小并不代表实际内存区域的大小，实际运行过程中，内存区域的大小也是可以动态调整的。下面来具体说说每一个区域的主要功能。
程序计数器，我们在写代码的过程中，开发工具一般都会给我们标注行号方便查看和阅读代码。那么在程序在运行过程中也有一个类似的行号方便虚拟机的执行，就是程序计数器，在语言中，我们知道会有一个语句，其实就是跳转到了指定的行，这个行号就是程序计数器。存储的就是程序下一条所执行的指令。这部分区域是线程所独享的区域，我们知道线程是一个顺序执行流，每个线程都有自己的执行顺序，如果所有线程共用一个程序计数器，那么程序执行肯定就会出乱子。为了保证每个线程的执行顺序，所以程序计数器是被单个线程所独显的。程序计数器这块内存区域是唯一一个在规范中没有规定内存溢出的。
虚拟机栈，虚拟机栈是程序运行的动态区域，每个方法的执行都伴随着栈帧的入栈和出栈。 栈帧也叫过程活动记录，是编译器用来实现过程函数调用的一种数据结构。栈帧中包括了局部变量表，操作数栈，方法返回地址以及额外的一些附加信息，在编译过程中，局部变量表的大小已经确定，操作数栈深度也已经确定，因此栈帧在运行的过程中需要分配多大的内存是固定的，不受运行时影响。对于没有逃逸的对象也会在栈上分配内存，对象的大小其实在运行时也是确定的，因此即使出现了栈上内存分配，也不会导致栈帧改变大小。
一个线程中，可能调用链会很长，很多方法都同时处于执行状态。对于执行引擎来讲，活动线程中，只有栈顶的栈帧是最有效的，称为当前栈帧，这个栈帧所关联的方法称为当前方法。执行引擎所运行的字节码指令仅对当前栈帧进行操作。

局部变量表：我们平时所说的栈内存一般就是指栈内存中的局部变量表。这里主要是存储变量所用。对于基本数据类型直接存储其值，对于引用数据类型则存储其地址。局部变量表的最小存储单位是，每个都能存放一个、、、、、、或类型的数据。
既然前面提到了数据类型，在此顺便说一下，一个可以存放一个位以内的数据类型，中占用位以内的数据类型有、、、、、、和八种类型。前面六种不需要多解释，大家都认识，而后面的是对象的引用。虚拟机规范既没有说明它的长度，也没有明确指出这个引用应有怎样的结构，但是一般来说，虚拟机实现至少都应当能从此引用中直接或间接地查找到对象在堆中的起始地址索引和方法区中的对象类型数据。而是为字节码指令、_和服务的，它指向了一条字节码指令的地址。
对于位的数据类型，虚拟机会以高位在前的方式为其分配两个连续的空间。语言中明确规定的位的数据类型只有和两种类型则可能是位也可能是位。值得一提的是，这里把和数据类型读写分割为两次读写的做法类似。不过，由于局部变量表建立在线程的堆栈上，是线程私有的数据，无论读写两个连续的是否是原子操作，都不会引起数据安全问题。
操作数栈是一个后入先出    栈。同局部变量表一样，操作数栈的最大深度也在编译的时候被写入到字节码文件中，关于字节码文件，后面我会具体的来描述。操作数栈的每一个元素可以是任意的数据类型，包括和。位数据类型所占的栈容量为，位数据类型所占的栈容量为。在方法执行的任何时候，操作数栈的深度都不会超过在_数据项中设定的最大值。
当一个方法刚刚开始执行的时候，这个方法的操作数栈是空的，在方法的执行过程中，会有各种字节码指令向操作数栈中写入和提取内容，也就是入栈出栈操作。例如，在做算术运算的时候是通过操作数栈来进行的，又或者在调用其他方法的时候是通过操作数栈来进行参数传递的。
举个例子，整数加法的字节码指令在运行的时候要求操作数栈中最接近栈顶的两个元素已经存入了两个型的数值，当执行这个指令时，会将这两个值和并相加，然后将相加的结果入栈。
操作数栈中元素的数据类型必须与字节码指令的序列严格匹配，在编译程序代码的时候，编译器要严格保证这一点，在类校验阶段的数据流分析中还要再次验证这一点。再以上面的指令为例，这个指令用于整型数加法，它在执行时，最接近栈顶的两个元素的数据类型必须为型，不能出现一个和一个使用命令相加的情况。
本地方法栈 与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行方法也就是字节码服务，而本地方法栈则是为虚拟机使用到的方法服务。虚拟机规范中对本地方法栈中的方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。甚至有的虚拟机譬如 虚拟机直接就把本地方法栈和虚拟机栈合二为一。与虚拟机栈一样，本地方法栈区域也会抛出和异常。
方法区经常会被人称之为永久代，但这俩并不是一个概念。首先永久代的概念仅仅在虚拟机中存在，不幸的是，在中，去掉了永久代这一说法，使用了 ，也就是空间。那么方法区是干嘛的呢？我们可以这么理解，我们要运行代码，首先需要编译，然后才能运行。在运行的过程中，我们知道首先需要加载字节码文件。也就是说要把字节码文件加载到内存中。好了，问题就来了，字节码文件放到内存中的什么地方呢，就是方法区中。当然除了编译后的字节码之外，方法区中还会存放常量，静态变量以及及时编译器编译后的代码等数据。
堆，一般来讲堆内存是虚拟机中最大的一块内存区域，同方法区一样，是被所有线程所共享的区域。此区域所存在的唯一目的就存放对象的实例对象实例并不一定全部在堆中创建。堆内存是垃圾收集器主要光顾的区域，一般来讲根据使用的垃圾收集器的不同，堆中还会划分为一些区域，比如新生代和老年代。新生代还可以再划分为，等区域。另外为了性能和安全性的角度，在堆中还会为线程划分单独的区域，称之为线程分配缓冲区。更细致的划分是为了让垃圾收集器能够更高效的工作，提高垃圾收集的效率。
如果想要了解更多的关于虚拟机的内容，可以观看深入理解虚拟机这套视频教程。现象
长期运营中发现部署了集群的磁盘满，经过排查发现的日志目录导致。
具体问题
具体看的大文件日志发现，某个相关的持续抛出异常，打印了大量的日志

分析过程
根据这个异常信息即：
      
字面意思为服务的状态连接已经关闭的状态下，仍然有提交事务操作，抛出了异常，但这个异常持续抛出，仍需要深入分析。
配置分析
既然是抛出的，且与有关，那缩小问题范围，查找里谁在写。的配置一般位于
 
 
 
根据配置中唯一一条与相关的配置逻辑：读取的日志，过滤其中的语句以 过滤，结果存入到里配置的数据表__。
逻辑分析
以上里调用了一个的类，这是一个自定义类，我们在引用路径里找到这个类所在并反编译之，基本逻辑与注释如下：
初始化阶段
 
 
循环执行阶段
 
 
 
 
关闭阶段
 
关闭阶段仅仅检查连接是否存在。
可能的原因
从的逻辑看，只有在空连接的情况下，状态才会是，其他情况下状态都是，且在向提交事务前后，不会检查连接状态，即使在抛出异常的情况下也没有修改状态，导致提交抛出异常后，循环执行，循环抛出异常。这里就是不断抛出异常的根本。那么连接到底是什么时候关闭的呢？这里的原因猜测有个：长时间与没有交互，超过连接自动关闭时间；的异常关闭。
问题确认
是否长时间与无交互
查询的超时配置如下：
 
配置为默认配置秒即小时。
查看的日志，统计每小时执行的数量如下：
 
可见，与之间的断开并非二者长期无交互。
是否人为断开服务
查询人为启动的时间如下：
 
的异常时间如下：从异常提交的事务本身内容的时间看：
 
时间吻合。
结论：服务异常导致提交事务时连接中断，且没有处理这种异常，引发死循环提交事务，并在这种异常情况下，已无法正常工作。
问题重现
根据以上的推论，可进行如下验证这个异常：
产生日志
在里执行多次
 
手动强制关闭
 
手动重启写入的实例。
查看表现
 
进入无限循环的抛出异常状态，验证成功。
总结
这里的主要原因是服务异常导致产生的连锁反应。权宜之计可以在的代码中提交事务出异常时，修改下的状态为，防止不断打印日志造成机器磁盘满影响其他服务待验证。

相关推荐 腾讯云大数据套件索引插件使用总结基于的与集群准实时同步介绍 基于用户画像大数据的电商防刷架构作者：秦策

接《 浏览器  树结构概览上》
四、 流的修改
现代浏览器中，为了更好的用户体验，页面经常需要根据不同情况动态进行变化， 流也需要相应的进行修改。为了提高对于流的访问效率， 浏览器采用   来对这个流进行操作。 虽然名义上称作 ，其实并不是一个真正意义上树结构，其本质是为了高效操作流结构而产生的一套改进算法。
 中 的基本数据结构为 ，用于表示流中各数据在  中的逻辑关系，再看一遍  的数据结构，其_、_ 指针便是用于描述当前节点在  中的逻辑关系。
 
{

           _   左子树中的   数量以及一些与  有关的属性
           _            左子树中的字符数量
       _        指向第一个子节点
       _               若当前节点为父节点的最后一个节点，则该指针指向父节点，否则指向兄弟节点
       _
       _
}
 的主要功能既是在保证流结构顺序的情况下，使得最后访问的节点处在树的最顶层，从而提升访问效率。以如下页面举例想要在在页面、 位置插入标签
首先访问  位置，通过  操作将  所指节点旋转置树顶，此时  如下左树所示；接着访问  位置， 变为如下右图，此时针对 的操作只需要发生在  的右子树上即可

                                 
    \                                 \
                                   
         \                           \
                        =           
                \                            \
                                             
                     \
                        

  表示   的头结点，表示  的尾节点。依次类推
 的核心函数 逆向如下，部分冗余代码没有给出
   _
{
     
     
     
     
     
     
     
      = _
     = _
     = 

          
    {
         = 
         如果  没有当前节点已经旋转到第三层，没有曾祖父节点了则只进行一次单旋；否则进行一次之字旋或者一字旋
         
        {
             = __  _
               __   如果 _ 与其父节点形成左右、或者右左的关系， 则进行之字形旋转
            {
                                                                                   
                            \                         \                                \
                                                                                    
                          \                         \                               \ 
                                     =                         =               
                             \                         \                       \      \
                                                                                   
                          \                               \
                                                          
                _    _
                 = 
            }
                        如果 _ 与 其父节点均为左节点、或均为右节点，则进行一字型旋转
            {
                                                                                         
                                \                             \                             \
                                                                                         
                              \                            \                             \
                                         =                           =              
                            \                         \      \                             \
                                                                                         
                         \                                                                      \
                                                                                                
                       
                 = 
            }
             = 
        }
        
        {
             = 
             = 
        }
        _      _
          = _
         = _
         = 
    }
    
}

    
{
     
     
     
     
     
     
     
     

     
    {
         右旋
                               
                   \                  \
                      =         
               \                          \
                                           
        
         得到  的左节点 ，通过  指示出来
         = _ 
           
             = 
        
             = 
        得到  的右节点，通过  表示
         = _
         = 
         
        {
             
            {
                 如果其左节点有兄弟节点则该兄弟节点为右节点
                  
                     = _
            }
            
            {
                 = 
            }
        }
        得到  的右节点，通过  表示
         = _
         = 
         
        {
             
            {
                 如果其左节点有兄弟节点则该兄弟节点为右节点
                 
                     = _
            }
            
            {
                 = 
            }
        }
        替换  节点和  节点的上下关系
         
         如果  有左节点，则该节点为  的第一个子节点，且该节点的兄弟节点应为 
         如果  没有左节点，则  的第一个子节点为 
         
        {
            
            _ = 
        }
        
        {
            _ = 
        }
         如果  有右节点，则  节点的第一个节点为该节点
         如果  没有右节点，则  节点的第一个节点为其右节点
         
        {
            _ = 
            
             如果  节点也有右节点，则此节点为原  右节点的兄弟节点
             如果  节点没有右节点，则此节点变为  最后一节点，需要为其设置父节点指针
             
            {
                
                _ = 
            }
            
            {
                
                _ = 
            }
        }
        
        {
            _ = 
        }
         节点变为  节点的右节点，也即最后一个节点，将其父节点指针设置为 
        
        
        _ = 
         调整  节点和  节点的  
         = _  __  __     清除 位的干扰
        _  
        _
        _ = _  _
          节点
         = _
            
        {
             
            {
                _ =   
                    
                    _       减一
            }
        }
          
        {
             =   __  
            _ = 
        }
        
    }
    
    {
         左旋
                                 
                    \                   \
                       =         
                      \             \
                                    
        代码总体和右旋差异不大，这里不再逆向
    }
}
在通过  高效的实现了  流的访问之后， 设计了一套专门用于操作  树的机制称为 ，对于  流的一系列修改操作均通过它来进行。 函数部分功能逆向如下
  _   _    _  ， 
{

   
   
   

   = 
   = 
   

   =  _ _  _   
    
    
    {
         = 
         = 
    }
    
   {
     = 
     = 
     = 
    }
    
  
   
}
函数首先调用 函数将源  流中的节点信息备份一遍，接着根据操作要求决定是否将源  流中的节点信息删除，最后将之前备份的节点信息插入目标  流中。
对  流结构进行操作还需要有一个重要的结构 ，该结构用于指示两个  之间的内容，在对流进行插入和删除操作时都需要用到结构来指示需要操作的区间。 数据结构如下所示
 {
        _  指定  所在的范围
        _     指示与  相关联的 
        _          当前  是否在   的左边
        _  
        _  
}
当然上述操作均要通过 来作为  流的指针才能完成。
通常情况下，一个页面内容被修改之后， 页面中的还会保留在之前未修改时的位置。举例来说


当第一个页面被修改为第二个页面之后，虽然页面的内容发生了改变，但是 的相对位置仍然保持不变。但如果页面的修改发生在  指向的位置，如上例中，向、之间插入一个， 的位置就会出现二义性。
    这时就需要引用另一个重要的概念，每一个  都有一个  值标识着其左偏或右偏。仍以上述页面为例
分别在的位置插入一对 标签。这时由于的存在，页面会变成如下
默认情况下 的 值是 。下面的函数负责查看或者修改 的  值
 _ {
    __
    __
}

 
    _ 


 
    _ 

再考虑如下例子
当 段被移动到 之间时的位置也出现了二义性，是应该随着移动，还是应该继续保持在原位呢
  这就需要  的存在，如果指定了属性，那么页面操作之后就会成为右边所示的情况，否则就会出现左边所示的情况
和 可以协同作用，考虑下面的例子
移动到、之间，如果指定了 属性，并且  值为 ，那么便会跟随一起到之间。这种情况下如果被删除，那么也会跟着从 流中移除，但并不会销毁，因为还有可能重新被使用。相关的函数，函数原型如下
 
     


 
     

下面通过实际的  操作来说明如何对  流进行修改的

 意为在目标  的最后添加一个子节点，其内部其实是通过 来实现的，

{
     = 
         

        __ 
     
}
函数首先通过  指定到  的 位置，再调用   进行实际的插入操作，一般而言标签都是成对出现的，因此这里需要使用两个  分别指定新插入标签的  和  位置
               __ 
{
       
       
    
    _      ==    
      
    _      ==    
      
    
      
     = 
     = 
    
           
         = 
       =  _  
        
         =    
        
         
        
        
       =   == 
        
        
         =   
        
       =  
        
         
}
函数的主要逻辑为，首先通过一系列的  操作，指定  和  的位置；接着新建一个 并与  关联。调用 初始化标签对象的  ；接着调用  将  插入  流中，同时也插入  中，并调用  获取 信息，更新  结构，同时触发  ，进行响应事件的分发。完成了  的操作之后，对  也执行相同的操作，最终完成功能。

 用于将  流中一个节点替换为另一个节点，其主要功能函数我这里显示不出符号表，其逆向主要功能代码如下
 _        
{
 
   
   
   =        
     ==  
     =           
   
   
   
}
函数的主要逻辑为，通过两个  指针指定需要替换的目标节点在  流中的  和  位置，接着调用  函数完成功能。 则直接通过调用  来实现
                  
{
    
       _
       _
       _
     
         
         =            
      
         =      

   
}
 根据传入的  位置信息构造三个  对象，并根据调用者的要求，选择是进行 操作还是 进行操作，最终将请求传递给 。
五、总结
 的这种  流结构是由于历史原因形成的一种特殊情况，随着浏览器功能的越来越丰富，这种  组织方式出现越来越多的问题。在  中微软已经抛弃了  流的设计，转而构建了一个真正意义上的  树。
 中与  相关的内容还有很多，这里仅仅列出了一点微小的工作，还有很多复杂的结构需要进一步分析。
六、
 =导读
开始敲这篇“软”文，我觉得颈肩都好硬，转转头抖抖肩，许多事情如开闸水般涌入脑海，整个人顿时放松了下来。也烦请读者朋友耐心读下来，看一看这千千万万测试人的一些共鸣！

我们是谁
年，我入职腾讯无线研发部质管中心的前身，负责浏览器项目测试。当时本书作者丁如敏是浏览器测试组负责人，本书另一作者张锦铭早我一年入职，还有另一位同事张佳也做浏览器测试一年后转入其它项目，所以没有参与本书编写，但是要感谢这位同事在平台贡献的测试经验。这几人组建了最开始的测试团队班底。丁如敏先生带领着我们三个毕业生从零开始，学习国内外相关资料，不断在实践中尝试和改进，对的性能、功能、自动化测试都有一定程度的经验积累。
年我们项目发生了变动，从平台切换为平台，同样还是浏览器的项目。同样的操作系统平台，我们就这样将上的测试经验、工具和方法移植到上。
年我们测试团队迎来了第一次扩张，本书作者程春林和纪文静相继加入，程春林是从一名纯粹的开发转为测试开发，这给我们的测试团队带来了极强的开发基因，为平台的自动化测试框架开发奠定了重要基础。纪文静的是一名活泼开发的后美女硕士，为我们的测试团队注入了新鲜血液，两年多以来在版本测试管理方面十分有心得。年初本书的另一位作者叶方正加入，专项测试出身的他给我们团队带来了更丰富的专业领域知识，进一步完善了整个测试团队的测试基因。至此本书的作者已经集齐，我们的测试团队也在平台深耕细作了五年之久，各方面的测试积累也达到了一个相对成熟的状态。

我们想干什么
按理说企业里做工程师就踏踏实实的做测试或者开发工作就好了，写书做什么？我们的初心特别简单，做了这么多年的测试，坑踩了不少，干货也不少，希望能够总结沉淀下来。往情怀方面说，市面上关于的开发和测试书千千万，放眼平台的却寥寥无几，这么好用的手机平台，应该有个与之匹配的专业测试书。往大了说，独乐乐不如众乐乐，好东西好经验要分享出去才能价值最大化，共享经济时代，知识更应该共享。
开始的时候，我们是想写个内部总结，真的，绝对没有考虑过出书。我们这群单调的工程师认为出书的这种事是业界的大牛干的，我们这些只会写代码和脚本的普通码农，讲不出什么很有感染力的道理和高大上的设计概念。在公司内部因为我们团队做测试时间比较长，积累经验相对较多，很多想了解测试的同学会邀请我们去分享，每次分享都感觉意犹未尽，一两个小时是道不尽的，于是我们就考虑把这几年的经验梳理一下，用文字的形式展现，文字的传播效率最高，减少沟通成本的同时给大家最好的知识传播。
那就开始写，写着写着发现内容有点多，貌似不是几篇文章就能写完了，我们就想干脆写个电子书得了，范围也不限于公司内了，让更多的人能够接触到。这样问题就来了，我们的定位原来是为了给初次接触平台的同学阅读的，如果写成电子书，就要再扩大一下范围，增加一些业界时鲜的方法和工具使用介绍，给想进阶的同学以参考，这样书的架构就更大了，我们要进行分类和串联。
大约从年月份启动初稿收集，持续收集到月底。先集体拉到会议室讨论要写哪些主题，一番后定下来了十几个主题，大家分头领任务开始撰写。每周都开会同步当前写作进度，从年月份开始审稿一直持续到年月份。曹雪芹曾经批阅十载，增删数次而成红楼梦，我们几个写个电子书，也时常推倒重来，写好的主题文章讨论下觉得价值不大就被拆分重组或者干脆删除；或者写的不够全，现查现学现实践现补充；写的不严谨的都打回去确认后重新提交评审。
还好到年初的时候我们的初稿已经完成了，电子稿已经好了，只是尚未对外发布。上半年偶尔有几篇文章发到品质中心的公众号上，这些文章引发了大量的阅读量和转载。这时候部门和中心的领导就鼓励我们要不要考虑出本纸质书，此时的我们感觉距离纸质书的质量要求还有很大的差距犹豫不决。时间进入年年中，发布，带来了新的测试工具和实现方式，之前电子稿的很多内容需要更新和补充，在这个契机之下，丁如敏先生建议我们联系出版社，计划出一本纸质书。在同事盛娟感谢的介绍下联系了机械工业出版社的杨福川和孙海亮两位编辑老师，表达了我们想出版这样一本书的意愿，两位编辑老师十分热情的帮我分析出版行情、申请书号和写稿事宜，顺利签署了出版社合同。就这样在年下半年我们正式开启了纸质书的撰稿过程。
与时俱进和严谨务实
纸质书的出版比电子书更加严格，所有的内容都要求科学、严谨、原创、时新。我们开始新一轮的迭代。这次出现多稿的重构，因为业界工具和技术的更新，比如性能测试、自动化测试入门、测试框架二次开发这几章都经历了完全后重新书写的磨砺。走进测试这一章也做了大规模更新，关于证书、灰度的概念都更新到最新的情况。兼容性测试这一章，关于机型系统的相关内容和案例也进行了更新。关于这部分的内容主要大纲如下图所示，分为基础测试、进阶测试、高级测试三部分，各自有对应的章节内容。可以供入门学习、通用技能学习、高级探讨的读者使用。

做了大量特色测试的章节内容后，我们觉得这本书还缺点灵魂性的东西。是的，这是一本给测试人看的书，如果全书都只是说平台怎么测试，那最多能成为一本实用的操作手册，价值并不大。因此丁如敏先生结合当前测试行业的热点和趋势，为读者朋友特别奉送了一章测试观，用他十年多的测试经验，深入解读了科学测试的理念。
测试=工程效率品质管理。
就像下面的车轮一样，工程效率是项目能够顺利运转的驱动力，品质管理作为前车轮是项目质量的方向引导，怎样行驶好这辆车依赖于我们测试人员以及全体项目组成员对工程效率和品质管理的理解和实践程度。

我们还针对业界流行的探索式测试、缺陷分析等技术和分析方式进行了全面的解读。也用实际案例和代码为读者展示这些流行趋势在腾讯的实践，语言平实无浮夸，客观公正的评估每种实践给我们带来的利弊。这几章的内容关系如下图所示，标准化测试是升级版的探索式测试，这两者的过程产出可以通过缺陷分析来进行结果引导，反向促进探索式测试良好进行，形成闭环。当然具体内容还是书里介绍的更详细。

书的最后还展望了一下测试人员的未来，希望大家能够切实感受到“光荣在于平淡，艰巨在于漫长”这句话背后的坚持。
我们作者六人，用了长达两年的时间为读者朋友书写此书，以工程师低调务实的态度，不求火热大卖，只求能为有需要的同行们送去你们的所需。我们热忱的欢迎读者朋友能够与我们联系反馈，欢迎来邮件，或者留言均可。
如果你对本书感兴趣，欢迎采购阅读，不吝赐教。我们也将在月日日登陆对本书进行专家问答，届时欢迎大家参与。
购书链接：本文是【开源项目贡献指南】系列的第二章，原文【  ——    】

什么是开源，为什么要开源
那么你正准备拥抱开源吗？恭喜你，开源世界感谢你的贡献。接下来让我们聊聊什么是开源，我们为什么要开源。
“开源”意味着什么？
当一个项目开源后，意味着 不论什么目的，所有人都可以浏览，使用，修改和分发你的项目。 这些权限都是来自于开源协议
开源非常的强大。因为它降低了使用的门槛，使新奇的思想得到快速的传播。
来理解它如何工作，想象下你的朋友正在吃便当，这时你带来了樱桃派。

每个人都会想要樱桃派使用

这个派引起了一场轰动！周围的人会想知道你的烹饪方法浏览

有一位朋友是一名糕点师，他会建议少放一点糖修改

另外一位朋友要求使用它作为下个星期的晚餐分发


同样的，闭源就像是你去餐厅必须付钱才能吃樱桃派。但是，餐厅不会告诉你樱桃派的烹饪方法。如果你恰好抄袭了他们的派，并以你自己的名义出售，那么餐厅将会采取行动抵制你。
人们为什么要将他们的工作开源？
我从开源使用和协作中获得的最有价值的经验之一来自我与其他面临许多相同问题的开发者建立的关系。
—  “         ”
即使你是一个开发者，非代码部分的贡献是一个很好的方式让你参与一个项目和认识社区的成员。建立这种关系会给你从事项目其他部分工作的机会。
这里列举了很多理由 来解释为什么个人或者组织想要开源自己的项目。下面列举了部分：

协作 开源项目欢迎所有人参与。例如， 是一个有超过人协作开发的练习编程的平台。

采用和重新混合 任何人可以出于几乎任何目的使用开源项目。人们甚至可以将开源项目用于构建其他的项目。例如， 是基于开源项目 构建的。

透明度 所有人都可以检查开源项目中存在的问题。透明度对于政府如 保加利亚 或者 美国 产业调整如银行业或者医疗健康行业 和软件安全如 ’ 。


不仅仅是可以开源软件，你可以开源一切，从数据集到书籍。通过浏览   你可以知道什么东西可以被开源。
开源是否意味着免费
开源最吸引之处就是它不用花钱。然而免费只是开源的价值的一个副产品。
因为 开源协议要求开源项目可以被任何人出于几乎任何目的使用，修改和分享，这些项目一般都是免费的。如果有些开源项目需要付费使用，任何人都可以合法地使用其免费版。
结果是大多数开源项目都是免费的。但免费并不属于开源定义的一部分。开源项目可以通过双重许可协议或者其它的方法进行间接收费，同时不违背开源的官方定义。
我应该发起属于自己的开源项目吗
答案是肯定的，因为不论结果是什么，发起一个属于自己的开源项目是学习开源最好的方法。
如果你还没有开源过一个项目，你可能会因为没有人关注或者别人的说辞而紧张。如果真是这样的话，你并不孤独！
开源与其他有创意的活动是一样的，无论是写作还是画画。你可能会害怕向世界分享你的工作，但练习是唯一让你变得更好的方法，即使你没有一位听众。
如果你不确信，那么请花一点时间想想你的目标可能是什么。
设定你的目标
目标可以帮助你知道该做什么，不因该说什么和需要从他人那里获得哪些帮助。请开始问自己，我为什么要开源这个项目？
这个问题没有一个正确的答案。你可能为一个简单的项目设定了多个目标，或者不同的项目有不同的目标。
如果你唯一的目的是展示你的工作，你可能不想将它贡献出去，甚至会在中这么说。但是，如果你想贡献自己的项目，你要花更多的时间在书写简洁明了的文档上，使新来的参与者感到欢迎。

在某一时刻，我创建了一个自定义的，并且决定开源。因此我对进行了一些修改使其更加动态灵活，同时上传到。我编写了一份技术文档以便其他开发者将用于他们的项目中。或许没有人使用这个项目，因为这是一个简单的项目。但是我为自己的贡献感到开心。
—  “         ”

随着你的项目的发展，你的社区可能不仅需要你提供的代码。回复，审查代码和传播你的项目在一个开源项目中都是非常重要的任务。
虽然你花费在非编码上的时间取决于项目的规模和范围，但你应准备好作为维护者来自己解决问题或者向他人寻求帮助。
如果你参与了公司的开源项目， 确保你的项目拥有它所需要的内部资源。当项目启动后，你会想知道由谁负责维护和在你的社区如何分配这些任务。
如果你需要为项目的宣传，操作和维护准备一笔专用预算或者人员配置，那么尽早开始讨论。

一旦你项目开源后，最重要的是你要考虑到项目周围社区的贡献和能力。你不必担心那些不是你公司员工的贡献者参与到项目的关键部分。
—  “       ”

为其他的项目做贡献
如果你的目标是想学习如何与他人一起协作或者了解开源是如何工作的，那么你可以考虑为一个已存在的项目做贡献。开始参与你曾经使用过和喜爱的项目。为项目做贡献就像修改错别字或者更新文档一样简单。
如果你不知道如何开始做一个贡献者，那么可以阅读我们的开源项目贡献指南。
发起属于你的开源项目
如果没有充足的时间来开源你的工作，你可以开发一个想法，一个正在进行的工作或者多年后将被关闭的资源。
一般来说，当你发现有人对你的工作反馈了一些有建设性的观点后，你应该开源你的项目。
无论你决定开源你项目的哪个阶段，每个项目都应该包含这些文档：

 



 

  


作为一名维护者，这些文档将会有助于你表达想法，管理贡献和保护每个人的合法权益包括你自己的。他们大大增加了你获得积极经验的机会。
如果你的项目在上，将这些文件按上面推荐的命名方式放在你的根目录，这样对你的读者会一目了然。
选择协议
开源协议可以保障他人对你的项目进行使用，复制，修改和贡献时不会产生影响。它还保护你免受法律的困扰。当你发起一个开源项目时必须选择一个协议。
法律工作很乏味。好消息是你可以在你的仓库中使用一个已经存在的开源协议。这样你只花了很少的时间，但很好的保护了你的工作。
     都是非常流行的开源协议，但是 还有其它的开源协议 可供你选择。
当你上创建了一个新项目，你可以选择许可协议。包括可以使你的项目开源的协议。

如果你还有其它的疑问或者与开源项目相关的法律问题，请来这里。
编写
不仅解释了如何使用你的项目，他们还解释了你的项目为什么重要，以及用户可以用它做什么。
在你的中尽量要回答以下的问题：

这个项目是做什么的？

为什么这个项目有用？

我该如何开始

如果我需要使用它，我能从哪里获得更多帮助。


你可以用去回答其它的问题，像你如何处理贡献，项目的目标是什么，开源协议的相关信息。如果你的项目不想接受贡献，或者你的项目不能用于产品，你就可以将这些写在中。

一份好的文档意味着会吸引更多的用户，收到更少的支持请求，得到更多的贡献。···请记住你的读者们不是你。参与同一个项目的开发者们有着完全不同的经历。
—  “      ”

有时候，人们不会去编写。因为他们觉得项目还没有完成或者他们不想要贡献。这些都是非常好的为什么要编写的理由。
为了获得更多的灵感，可以尝试使用 ’ “编写可阅读的” 或者 ’  模板去编写一份。
当你的根目录中包含文件后，就会显示在仓库的首页上。
编写你的贡献指南
一份文件能否告诉你的粉丝如何参与你的项目。例如，文件中可能会包含如下信息：

如何报告 尽量使用  和   目标

如何提议一个新特性

如何建立你的开发环境和运行测试


另外技术清单和一份文件是一个你向贡献者传达你的期望的机会。如：

你渴望得到什么类型的贡献

项目的发展路线或者期望

贡献者应该如何联系你


使用温暖，友好的语气，并提供具体的建议如写作文档或做一个网站可以很大程度上让新来者感到欢迎和兴奋参与。
例如，      

首先，感谢你考虑为 做贡献。就是因为有了像您这样的人让 成为了一个伟大的工具。

在项目的早期，你的文件会比较简单。为了做出贡献，你应该总是解释如何报告或者文件和一些技术要求像测试。
过了一段时间，你肯会把频繁出现的提问添加到文件中。写下这些信息意味着会有更少的人再重复向你提相同的问题。
想获得更多书写文件的帮助，请查阅 ’ 贡献指南模板  ’ “如何创建 ”
在中附上文件的链接，这样会让跟多的人看到。如果你 将文件放在项目的仓库中会自动链接你的文件当贡献者创建一条或者打开一个 。

制定行为规则
我们有过这样的经历，我们面临什么是滥用，或者作为一名维护者试图解释为什么有些事必须按一定的方式，或者作为一名用户提出简单的问题。…一份行为规则会变成一份简单的参考和可链接的表示你的团队提出的建设性的话语非常认真的文档。—  “     ”
最后，一份行为规则帮助你为你项目的参与者建立了行为准则。如果你为一个社区或者一家公司发起一个开源项目，它是非常有价值的。一份行为规则授权你促成健康，有建设性的社区行为，这回减轻你作为一名维护者的压力。
想获得更多信息，请查阅我们的 行为规则指南
除了沟通如何期望参与者行为之外，行为准则还倾向于描述这些期望适用于谁，何时应用，以及如果违规发生时该做什么。
许多开源协议一般也会为行为规则制定标准，所以你可以不用再编写。这份贡献者盟约 是一份被超过个开源项目所使用的行为规则，包括  和。无论你使用哪个文本，在必要的时候你都应该执行你的行为规则。
将文本直接粘贴到你仓库中的__文件中。将文件放在项目的根目录中方便查找，同时在中添加相应的链接。
命名和品牌化你的项目
品牌不仅是一个华丽的或者易记的项目名。它还关于你如何谈论你的项目，以及你想把信息传递给谁。
选择正确的名字
选择一个容易记住，有创意，能表达项目用意的名字。例如：

 监控应用程序的崩溃报告

 是一个简单快速的 服务器


如果你的项目是基于一个已存在的项目创建，那么使用他们的名字作为你项目名的前缀会帮助你阐述你项目的用途。 例如 将 添加到了 。
考虑阐明所有。押韵虽然有趣，但是记住玩笑不可能转变成其它的文化，或者他人与你有不同的经历。你的一些潜在用户可能是公司员工，你不能让他们在工作中很难解释你的项目！
避免命名冲突
查看是否有同名的开源项目，尤其是你分享的是同样的语言或者生态系统。如果你的名字与一个已存在的知名的项目有冲突，你会让你的粉丝感到困惑。
如果你想要一个网站，账号或者其他特性来展示你的项目，先确保你能得到你想要的名字。理想情况下，为了美好的未来现在保留这些名字，即使你现在不想用他们。
确保你的项目名没有侵权。如果有侵权，可能会有公司要求你的项目下架，或者对你采取法律措施。这样得不偿失。
你可以查阅全球品牌数据库避免商标冲突。如果你是在公司工作，法律团队会帮你做这件事。
最后，去谷歌搜索你的项目名。大家会很容易地找到你的项目吗？在搜索结果礼是否有你不想让大家看到的东西？
你的写作和代码如何影响你的品牌
在项目的整个生命周期中，你需要做很多文字工作：，教程，社区文档，回复，甚至肯能要处理很多来信和邮件。
是否是官方文档或者一封普通的邮件，你的书写风格都是你项目品牌的一部分。考虑你可能会拥有粉丝，以及这是你想传达的声音。

我尝试处理每一个细节，包括：处理邮件，展示示例，友好待人，认真处理大家的以及试图帮助到大家。经过一段时间后，大家可能不再是只问问题，还会帮助我解决其他人的疑问以及给我喜悦，他们模仿我的风格。
—    “  ”

使用热情，通俗易懂的语言如“他们”，即使是指一个人能够让新来的贡献者感觉项目非常欢迎他们。使用简单的语言，因为你的读者可能英语不是很好。
除了书写风格外，你的编码风格也是你项目品牌的一部分。  和 是两个项目代码风格严谨的示例和指南。
当你的项目才开始时，没有必要为项目编写一份风格指南。你可能会发现你喜欢将不同的编码风格融入到项目。但是你应该想到你的书写和编码风格会吸引或者拒绝不同类型的人。项目的早期是你建立你希望看见的先例的机会。
你的预发布清单
准备好开源你的项目了吗？有一份帮助检查清单。检查所有内容？你准备开始吧！ 点击 “” 以及拍下自己的后背。
文档

需要为项目指定一个开源协议

项目要有基础文档   __

易记的项目名，指出项目是做什么的，不能和已存在的项目冲突或者商标侵权

最新的队列，组织和标记清除的


代码

项目使用一致的代码风格和明确的功能方法可用的名字

注释清晰的代码，记录意图和边缘案例

在修改历史，或者   中没有敏感的信息 例如 密码或者其他不能公开的信息


人
如果你是代表个人：

你已经告诉了你的法律部门，以及或者理解了你公司如果你是某一家公司的员工的开源政策和

如果你有一家公司或者组织：

你已经告诉了你的法律部门

你有一个宣布和促进项目的营销计划

一些人被允许管理社区互动回复，检查和合并 

至少有两人管理访问项目


你做到了！
恭喜你开源了你的首个项目。不论结果如何，对开源社区都是一份礼物。随着每次和 ，你正在为自己或者他人创造学习和成长的机会。最近半年以来，热补丁技术热潮继续爆发，各大公司相继推出自己的开源框架。在最近也顺利完成了公司的审核，并非常荣幸的成为上第一个正式公开的项目。
回顾这半年多的历程，这是一条跪着走完，坑坑不息之路。或许只有自己真正经历过，深入研究过 才会真正的明白

热补丁不是请客吃饭

对热补丁技术本身，还是对使用者来说都是如此。它并不简单，也有着自己的局限性，在使用之前我们需要对它有所了解。我希望通过分享微信在这历程中的思考与经验，能帮助大家更容易的决定是否在自己的项目中使用热补丁技术，以及选择什么样方案。
热补丁技术背景
热补丁是什么以及它的应用场景介绍，大家可以参考文章微信热补丁实践演进之路
在笔者看来热补丁技术应该分为以下两个流派：

，代表有阿里的、与腾讯的内部方案；
 代表有的超级补丁、大众点评的、百度金融的 饿了么的以及美团的。

流派与流派都有着自己的优缺点，它们具体差异大家可参考上文。事实上从来都没有最好的方案，只有最适合自己的。
对于微信来说，我们希望得到一个“高可用”的补丁框架，它应该满足以下几个条件：

稳定性与兼容性；微信需要在数亿台设备上运行，即使补丁框架带来的异常，也将影响到数万用户。保证补丁框架的稳定性与兼容性是我们的第一要务；
性能；微信对性能要求也非常苛刻，首先补丁框架不能影响应用的性能，这里基于大部分情况下用户不会使用到补丁。其次补丁包应该尽量少，这关系到用户流量与补丁的成功率问题；
易用性；在解决完以上两个核心问题的前提下，我们希望补丁框架简单易用，并且可以全面支持，甚至可以做到功能发布级别。

在“高可用”这个大前提下，微信对当时存在的两个方案做了大量的研究：

；最大挑战在于稳定性与兼容性，而且异常排查难度更高。另一方面，由于无法增加变量与类等限制，无法做到功能发布级别；
；最大挑战在于性能，即平台存在插桩导致的性能损耗，平台由于地址偏移问题导致补丁包可能过大的问题；

在年月，微信为了追寻“高可用”这个目标，决定尝试搭建自己的补丁框架——。框架的演绎并不是一蹴而就，它大致分为三个阶段，每一阶段需要解决的核心问题并不相同。而 的核心问题是实现符合性能要求的补丁框架。
 －性能极致追求之路
为了稳定性与兼容性，微信选择了流派。当前最大难点在于如何突破方案的性能问题，这时通过研究 的冷插拔与的给了我们灵感。它们的思想都是全量替换新的。
简单来说，我们通过完全使用了新的，那样既不出现地址错乱的问题，在也无须插桩。当然考虑到补丁包的体积，我们不能直接将新的放在里面。但我们可以将新旧两个的差异放到补丁包中，这里我们可以调研的方法有以下几个：


；它格式无关，但对效果不是特别好，而且非常不稳定。当前微信对于与部分资源，依然使用算法；
；它主要问题在于合成时内存占用过大，一个的，峰值内存可能达到多；
；通过深入格式，实现一套差异小，内存占用少以及支持增删改的算法。

如何选择？在“高可用”的核心诉求下，性能问题也尤为重要。非常庆幸微信在当时那个节点坚决的选择了自研算法，这过程虽然有苦有泪，但也正是有它，才有现在的。
一 技术实践
在不断的深入研究格式后，我们发现自己跳进了一个深坑，主要难点有以下三个：

格式复杂；大致分为像，这些区域以及使用的区域。它们有大量的互相引用，一个小小的改变可能导致大量的与变化；
与校验；在这两个过程系统会做例如四字节对齐，部分元素排序等校验，例如按照内容的排序，按照排序
低内存，快速；这要求我们对每一块做到一次读写，无法像与那样完全结构化。


这不仅要求我们需要研究透的格式，也要把与的代码全部研究透。现在回想起来，这的确是一条跪着走完的路。与研究与执行一致，这是经历一次次翻看源码，一次次编查看日志，一次次内存结构换来的结果。
下面以最简单的区域举例：

要想将从左边序列更改成右边序列，算法的核心在于如何生成最小操作序列，同时修正与，实现增删改的功能。

 ；元素被删除，它对应的是，为了减少补丁包体积，除了新增的元素其他一律只存
  元素自动前移，无须操作；
 在第五个位置增加这个元素。

对于区，由于每个可能有非常多的元素，这里会更加复杂。最后我们得到最终的操作队列，为什么可以做到内存非常少？这是因为算法是每一个操作的处理，它无需一次性读入所有的数据。的各项数据如下：

通过算法的实现，我们既解决了平台的性能损耗问题，又解决了平台补丁包过大的问题。但这套方案的缺点在于占体积比较大，微信考虑到移动设备的存储空间提升比较快，增加几十的空间这个代价可以接受。
二  的挑战
信心满满上线后，却很快收到华为反馈的一个：

而且这个只在 上出现，在当时对我们震动非常大，难道 不支持方式热补丁了？难道这两个月的辛苦都白费了吗？一切想象都苍白无力，只有继续去源码里面找原因。
在之前的基础上，这一块的研究并没有花太多的时间，主要是 的混合编译模式导致。更多的详细分析可参考文章 混合编译与对热补丁影响解析。
三 厂商的挑战
刚刚解决完 的问题，还在沉醉在自己的胜利的愉悦中。前线很快又传来噩耗，小米反馈开发版的一些用户在微信启动时黑屏，甚至

当时第一反应是不可能，所有的操作都是放到单独的进程，为什么只在平台出现？为什么小米开发版用户反馈比较多？经过分析，我们发现优化后文件存在有效性的检查：

平台：
平台： __

这就非常好理解了，因为之后系统改变了，文件用到的偏移地址很可能已经错误。对于文件，在升级系统已完成重新，而补丁是动态加载的，只能在第一次执行时同步执行。
这个耗时可能高达十几秒，黑屏甚至也是非常好理解。那为什么只有小米用户反馈比较多呢？这也是因为小米开发版每周都会推送系统升级的原因。
在当时那个节点上，我们重新的审视了全量合成这一思路，再次对方案原理本身产生怀疑，它在平台上面带来了以下几个代价：

后黑屏问题；这里或许可以通过界面实现，但并不是很好的方案；
体积问题；一个的，在下产物只有左右，但在平台，可以达到多；
 的问题； 在混合编译上努力，被补丁全量合成机制所废弃了。这是因为动态加载的，依然是全量编译。

回想起来，方案它只把需要的类打包成补丁推送，在平台上可能导致补丁很大，但它肯定比全量合成的少很多很多。在此我们提出分平台合成的想法，即在平台合成全量，在平台合成需要的

算法已经非常复杂，事实上要实现分平台合成并不容易。

主要难点有以下几个方面：

 的类收集；什么类应该放在这个小的中呢？
处理；对于怎么样处理，可能出现类从一个移动到另外一个
偏移二次修正 补丁包中的操作序列如何二次修正？
的大小； 为了修正偏移所引入的文件的大小？

庆幸的是，面对困难我们并没有畏惧，最后实现了这一套方案，这也是其他全量合成方案所不能做到的：

全量合成，解决了插桩带来的性能损耗；
平台合成 ，解决了全量合成方案占用体积大 升级以及 的问题；
大部分情况下仅仅 解决由于补丁包可能过大的问题；

事实上，算法变的如此复杂，怎么样保证它的正确性呢？微信为此做了以下三件事情：

随机组成校验，覆盖大部分；
微信个版本的随机校验 覆盖日常使用情况；
文件合成产物有效性校验，即使算法出现问题，也只是编译不出补丁包。

每一次算法的更新，都需要经过以上三个才可以提交，这样的这套算法已完成了整个闭环。
四 其他技术挑战
在实现过程，我们还发现其他的一些问题：

等微信插件 市面上有各种各样的微信插件，它们在微信启动前会提前加载微信中的类，这会导致两个问题：
  平台：出现        的；
  平台出现部分类使用了旧的代码，这可能导致补丁无效，或者地址错乱的问题。
 微信在这里的处理方式是若时发现安装了，即清除并不再应用补丁。

反射成功但是不生效；部分三星版本存在反射成功，但出现类重复时，查找顺序始终从开始。 微信在这里的处理方式是增加反射成功校验，具体通过在框架中埋入某个类的变量为。在补丁时，我们自动将这个变量改为。通过这个变量最终的数值，我们可以知道反射成功与否。



 总结
一 关于性能
通过 ，的努力，我们解决了方案的性能问题，得到一个符合“高可用”性能要求的补丁框架。

它补丁包大小非常少，通常都是以内；
对性能几乎没有影响 的性能影响主要原因是微信运行时校验补丁文件的导致虽然文件在目录，微信为了更高级别的安全；
平台通过革命性的分平台合成，既解决了地址偏移的问题，占体积与方案一致。


二 关于成功率
也许有人会质疑微信成功率为什么这么低，其他方案都是以上。事实上，我们的成功率计算方式是：

应用成功率= 补丁版本转化人数基准版本安装人数

即三天后，的基础版本都成功升级到补丁版本，由于基础版本人数也是持续增长，同时可能存在基准或补丁版本用户安装了其他版本，所以本统计结果应略为偏低，但它能现实的反应补丁的线上总体覆盖情况。
事实上，采用方案，天的成功率大约为，这里还是有很多的优化空间。
三  －稳定性的探寻之路
在阶段，大部分的异常都是通过厂商反馈而来，并没有解决“高可用”下最核心的稳定性与兼容性问题。我们需要建立完整的监控与补丁回退机制，监控每一个阶段的异常情况。这也是 的核心任务，由于边幅问题这部分内容将放在下一篇文章。

关注，来给我们吧

在之前的文章里，我们教了大家如何设置  的提示语，来告知操作人，正在操作的是哪台服务器。但是，很多时候，我们经常要执行非常多的命令，来完成我们的工作，那么在同时操作多个服务器时，依然容易迷失在命令行之中。
今天，我来教你如何自定义我们的  的提示，来帮助我们认清我们的服务器。
什么是   

我们的命令行前面会有一个简单的提示，这个提示就是   。我们通过自定义   可以实现自定义的提示。通过这个提示，就可以提醒用户，你目前操作的是什么服务器。
   的格式
  的格式被定义在  变量中，你可以通过执行  来拿到当前的提示。比如我的提示就是\\ \\

我们通过修改 变量，就可以实现修改  的提示。
  的含义
在上面的提示中，我们去掉用作区分的标点符号，我们可以提取出来 \、\、\和\，这些符号都有其特殊的含义，借助它们的特殊含义，我们可以实现我们的需求。

\：展示当前的用户的用户名
\：展示主机名
\：展示当前的目录的目录名
\：展示当前目录的全路径
\：展示小时制的时间
\：换行符
\：回车符
\：名
\：当是普通用户时，会展示，如果是  用户展示
\：展示  主机名
\：展示 ／ 形式的日期。

完整的内容可以查看：    
安全起见下，我们如何选择我们的？
为了实现我们的提醒效果，建议大家在中展示全路径、主机名、用户身份，并且注明当前服务器是什么环境，比如。我设置完成后，是这样的。
 | \\ \ \ \ \

这样一个提示，可以立刻明白我是在操作生产环境，以免我误操作时，没有注意到我使用的是哪个环境。你也可以根据你的需要来设置你的   的内容。
给 上个色
有些时候，文字可能无法给我们足够的警示。这时，我们可以选择为我们的   加个颜色，这样能够更好的展示。
如果想要为我们的上色，就要在我们的中加入上色的代码
其中，

\  为给后续的文字上色，都是颜色的编号。其中常用的红色为，蓝色，绿色
\则为停止上色。


\  \ | \\ \ \ \ \
设置为默认的输出
虽然目前我们设置成功了，但是并没有像我们的提示信息一样存留，重新连接就会消失。
这是，我们需要修改一下配置文件，来加入我们的设置。
我们可以修改 或_，再其中添加代码，来实现我们的输出效果
在这个文件中加入如下代码，即可实现效果。
  = \  \ | \\ \ \ \ \
相关推荐主要逻辑源码级分析——运行流程连接示例准备篇
、配置防火墙，开启端口、端口
    
                 
                        允许端口通过防护墙
                    允许端口通过防火墙
           最后重启防火墙使我们上面的配置生效
、关闭 
   
    = 修改为 =
    = 修改为 =
      重启系统
安装篇
、安装
         安装服务
       启动
    正在启动               
     解决办法：
        
    找到   修改为      这里也可以写自己的域名，没有域名就写
        设为开机启动
       重启
、安装
           安装数据库必要服务
       启动
        设为开机启动
        拷贝配置文件注意：如果目录下面默认有一个，直接覆盖即可
  __    为帐户设置密码
回车，根据提示输入。输入次密码，回车。根据提示一路输入 最后出现     密码设置完成，重新启动
       重启
、安装
         安装软件
                      这里选择以上安装包进行安装
       重启
       重启
配制篇
：配置
   
          在行     修改为：   在出现错误页的时候不显示服务器操作系统的名称
            在行    修改为：   在错误页中不显示的版本
        在行  修改为：   允许服务器执行及，禁止列出目录
        在行  修改为：    允许扩展名为的脚本运行
      在行  修改为：  允许
      在行  修改为： 添加为默认编码
        在行  修改为：  不在浏览器上显示树状目录结构
       在行 修改为：         设置默认首页 增加
      在行 修改为：  允许程序性联机
      在行 修改为：  增加同时连接数
        保存退出
       重启
         删除默认测试页
、配置
   
     =  在行 把前面的分号去掉，改为 = 
    _ = __________________ ___ _______ ___ _ ___ _____ _______
 在行 列出可以禁用的函数，如果某些程序用到这个函数，可以删除，取消禁用。
    _ =  在行 禁止显示版本的信息
    __ =  在行 打开__来防止注入
    __ =  在行支持短标签
    _ =  在行 设置表示允许访问当前目录即脚本文件所在之目录和目录可以防止木马跨站如果改了之后安装程序有问题例如：织梦内容管理系统，可以注销此行，或者直接写上程序的目录
        保存退出
       重启
       重启
测试篇
   
    输入下面内容
     
    
     
在客户端浏览器输入服务器地址，可以看到相关的配置信息！注意：默认的程序目录是权限设置： 至此，安装配置服务器教程完成！各位同学大家好，我是本次参赛选手李博，现在就读于北京邮电大学，是一名研一的在校生，研究方向是数据分析和机器学习。这次腾讯的比赛参加的比较晚，因为前面在准备京东的决赛答辩。不过看了几天数据，现在我把我的一些初步分析分享给大家。
一、训练集和测试集的划分：
大家都知道，腾讯决赛数据集巨大，简直让人绝望。所以我建议大家按每天划分数据集，再分开处理，提取各天的特征，这样一方面数据控制能力强，另一方面，统计特征不会穿越，最重要的是还能跑得动。。。。
二、业务理解：
大家都知道了一些，我在这就不说了。我想强调的一点是，我们解决的任何问题都不能脱离业务场景进行分析，因为好的特征都来自于与业务场景的深入理解和对原始数据的细致分析，所以大家要设身处地想用户是怎么看到广告，点击广告，转化广告的。通过思考想一下自己在使用过程中，哪些东西吸引了自己去点击，哪些东西吸引了自己去转化。这样可以找到很强的特征噢
三、特征工程：
在特征工程部分，我提几点吧：、因为我们要对每天进行统计，所以我建议大家把和转化为这种形式，方便我们统计一些时间特征，也方便我们划分数据集：、我们看数据介绍，广告的类型是二级的，所以我们要把广告类型分开一级和二级两列我发现很多同学都没处理这个，这样一方面模型更加合理，另一方面我们可以得到哪个一级广告热度高，每个用户分别钟爱哪种一级广告等等统计量；
、选取特征时不要穿越就不用说太多了，大家要注意不是没利用标签就是不穿越，你的各种超前统计可能都是穿越噢
、我们可以把业务转化为一个简单的图模型，然后在图模型里面找一些统计量来作为特征，通过图模型也可以更加深入的理解业务场景。我做个简单的示意图：
初步分析：上图是一个用户对一个时间窗口内的的考察记录，之间的箭头表示用户点击之间的跳转，在整个过程中，我们可以计算每个的入度，这样可以找到哪个更受此用户欢迎。
图模型是一个非常强的分析工具，比如你还可以加自环，这样可以看到用户的重复点击情况等等。
当然，如果你把时序特征分析的很清晰，那么可以不用图模型，但是图模型确实是个很简单又有效的分析方法。
、大家可以做一些数据可视化分析，找到一些分辨能力强的统计量。比如统计用户的活跃时间、的活跃时间等等，说不定有惊喜。
、交叉特征在这个赛题里面十分重要，不要忘记交叉特征，具体怎么做就不方便透露了说太多队友会打死我哈哈
四、模型算法与框架设计：
模型的话，看来是不怎么好用了，速度有点慢，反馈不及时，大热天的等的心烦。。。建议大家换吧，比效果差一丢丢，不过速度快很多，看着就爽。另外大家可以多思考一下框架设计这部分，比如融合方法，其实不仅仅局限于模型融合，还有其他的融合方法可以用来提高成绩。
说了这么多希望给大家一些提示，或者更加清晰的思路。
 ！本节分享一下爬取知乎用户所有用户信息的爬虫实战。
本节目标
本节要实现的内容有：

从一个大用户开始，通过递归抓取粉丝列表和关注列表，实现知乎所有用户的详细信息的抓取。
将抓取到的结果存储到，并进行去重操作。

思路分析
我们都知道每个人都有关注列表和粉丝列表，尤其对于大来说，粉丝和关注尤其更多。
如果我们从一个大开始，首先可以获取他的个人信息，然后我们获取他的粉丝列表和关注列表，然后遍历列表中的每一个用户，进一步抓取每一个用户的信息还有他们各自的粉丝列表和关注列表，然后再进一步遍历获取到的列表中的每一个用户，进一步抓取他们的信息和关注粉丝列表，循环往复，不断递归，这样就可以做到一爬百，百爬万，万爬百万，通过社交关系自然形成了一个爬取网，这样就可以爬到所有的用户信息了。当然零粉丝零关注的用户就忽略他们吧～
爬取的信息怎样来获得呢？不用担心，通过分析知乎的请求就可以得到相关接口，通过请求接口就可以拿到用户详细信息和粉丝、关注列表了。
接下来我们开始实战爬取。
环境需求

本项目使用的版本是，项目开始之前请确保你已经安装了。

是一个强大的爬虫框架，安装方式如下：
  

非关系型数据库，项目开始之前请先安装好并启动服务。

的连接库，安装方式如下：
  
创建项目
安装好以上环境之后，我们便可以开始我们的项目了。在项目开始之首先我们用命令行创建一个项目：
  
创建爬虫
接下来我们需要创建一个，同样利用命令行，不过这次命令行需要进入到项目里运行。
 
   
禁止_
接下来你需要打开文件，将_修改为。
_ = 

它默认为，就是要遵守 的规则，那么  是个什么东西呢？
通俗来说，  是遵循  协议的一个文件，它保存在网站的服务器中，它的作用是，告诉搜索引擎爬虫，本网站哪些目录下的网页 不希望 你进行爬取收录。在启动后，会在第一时间访问网站的  文件，然后决定该网站的爬取范围。
当然，我们并不是在做搜索引擎，而且在某些情况下我们想要获取的内容恰恰是被  所禁止访问的。所以，某些时候，我们就要将此配置项设置为  ，拒绝遵守 协议 ！
所以在这里设置为。当然可能本次爬取不一定会被它限制，但是我们一般来说会首先选择禁止它。
尝试最初的爬取
接下来我们什么代码也不修改，执行爬取，运行如下命令：
  
你会发现爬取结果会出现这样的一个错误：
   
访问知乎得到的状态码是，这说明爬取并没有成功，其实这是因为我们没有加入请求头，知乎识别发现不是浏览器，就返回错误的响应了。
所以接下来的一步我们需要加入请求信息，你可以在的参数里加，也可以在里面的_里面加，当然最简单的方法莫过于在全局里面加了。
我们打开文件，取消__的注释，加入如下的内容：
__ = {
           __      
}

这个是为你的请求添加请求头，如果你没有设置的话，它就会使用这个请求头请求，添加了信息，所以这样我们的爬虫就可以伪装浏览器了。
接下来重新运行爬虫。
  
这时你就会发现得到的返回状态码就正常了。
解决了这个问题，我们接下来就可以分析页面逻辑来正式实现爬虫了。
爬取流程
接下来我们需要先探寻获取用户详细信息和获取关注列表的接口。
回到网页，打开浏览器的控制台，切换到监听模式。
我们首先要做的是寻找一个大，以轮子哥为例吧，它的个人信息页面网址是：
首先打开轮子哥的首页

我们可以看到这里就是他的一些基本信息，我们需要抓取的就是这些，比如名字、签名、职业、关注数、赞同数等等。
接下来我们需要探索一下关注列表接口在哪里，我们点击关注选项卡，然后下拉，点击翻页，我们会在下面的请求中发现出现了开头的请求。这个就是获取关注列表的接口。

我们观察一下这个请求结构

首先它是一个类型的请求，请求的是，后面跟了三个参数，一个是，一个是，一个是。
观察后可以发现，是一些获取关注的人的基本信息的查询参数，包括回答数、文章数等等。
是偏移量，我们现在分析的是第页的关注列表内容，当前为。
为每一页的数量，这里是，所以结合上面的可以推断，当为时，获取到的是第一页关注列表，当为时，获取到的是第二页关注列表，依次类推。
然后接下来看下返回结果：

可以看到有和两个字段，就是数据，包含个内容，这些就是用户的基本信息，也就是关注列表的用户信息。里面又有几个字段，_表示当前翻页是否结束，是下一页的链接，所以在判读分页的时候，我们可以先利用_判断翻页是否结束，然后再获取链接，请求下一页。
这样我们的关注列表就可以通过接口获取到了。
接下来我们再看下用户详情接口在哪里，我们将鼠标放到关注列表任意一个头像上面，观察下网络请求，可以发现又会出现一个请求。

可以看到这次的请求链接为后面又一个参数，是一些查询参数，与刚才的接口类似，不过这次参数非常全，几乎可以把所有详情获取下来，另外接口的最后是加了用户的用户名，这个其实是_，上面的那个接口其实也是，在返回数据中是可以获得的。

所以综上所述：

要获取用户的关注列表，我们需要请求类似 {}={}={}={} 这样的接口，其中就是该用户的_，是固定的查询参数，是分页偏移量，是一页取多少个。
要获取用户的详细信息，我们需要请求类似 {}={} 这样的接口，其中就是该用户的_，是查询参数。

理清了如上接口逻辑后，我们就可以开始构造请求了。
生成第一步请求
接下来我们要做的第一步当然是请求轮子哥的基本信息，然后获取轮子哥的关注列表了，我们首先构造一个格式化的，将一些可变参数提取出来，然后需要重写_方法，生成第一步的请求，接下来我们还需要根据获取到到关注列表做进一步的分析。
 
    
   

 
     = 
    _ = 
    _ = {}={}
    _ = {}={}={}={}
    _ = 
    _ = _______________________________________________________________=_
    _ = _____=_

     _
         _=_ =_ _
         _=_ =_ = =
                      _

然后我们实现一下两个解析方法_和_。
     _ 
        
     _ 
        

最简单的实现他们的结果输出即可，然后运行观察结果。
  
这时你会发现出现了 
         
访问被禁止了，这时我们观察下浏览器请求，发现它相比之前的请求多了一个请求头。


它是 的缩写。
_进行到最后一步得到的一个“令牌”，通过此“令牌”请求，就可以去拥有资源的网站抓取任意有权限可以被抓取的资源。
在这里我知乎并没有登陆，这里的值是
 
经过我长久的观察，这个一直不会改变，所以可以长久使用，我们将它配置到__里，这样它就变成了：
__ = {
           __      
      
}

接下来如果我们重新运行爬虫，就可以发现可以正常爬取了。
_
接下来我们处理一下用户基本信息，首先我们查看一下接口信息会返回一些什么数据。

可以看到返回的结果非常全，在这里我们直接声明一个全保存下就好了。
在里新声明一个
    

 
            
     = 
     = 
    _ = 
     = 
     = 
     = 
    _ = 
     = 
    _ = 
     = 
     = 

    _ = 
    _ = 
    __ = 
    _ = 
    _ = 
    _ = 
    __ = 
    _ = 
    _ = 
    _ = 
    __ = 
    __ = 
    _ = 
    __ = 
    __ = 
    _ = 
    __ = 
    __ = 
    __ = 
    __ = 
    __ = 
    __ = 
    __ = 

     = 
     = 
     = 

所以在解析方法里面我们解析得到的内容，然后转为对象，然后依次判断字段是否存在，赋值就好了。
 = 
 = 
   
       
         = 
 

得到后通过返回就好了。
这样保存用户基本信息就完成了。
接下来我们还需要在这里获取这个用户的关注列表，所以我们需要再重新发起一个获取关注列表的
在_后面再添加如下代码：
 
            _=_ =_ = =
            _

这样我们又生成了获取该用户关注列表的请求。
_
接下来我们处理一下关注列表，首先也是解析的文本，然后要做两件事：

通过关注列表的每一个用户，对每一个用户发起请求，获取其详细信息。
处理分页，判断内容，获取下一页关注列表。

所以在这里将_改写如下：
 = 

   
       
         _=_ =_
                      _

     _ == 
    _ = 
     _
                  _

这样，整体代码如下：
    
 

    
   


 
     = 
    _ = 
    _ = {}={}
    _ = {}={}={}={}
    _ = 
    _ = _______________________________________________________________=_
    _ = _____=_

     _
         _=_ =_ _
         _=_ =_ = =
                      _

     _ 
         = 
         = 

           
               
                 = 
         

         
            _=_ =_ = =
            _

     _ 
         = 

           
               
                 _=_ =_
                              _

             _ == 
            _ = 
             _
                          _

这样我们就完成了获取用户基本信息，然后递归获取关注列表进一步请求了。
重新运行爬虫，可以发现当前已经可以实现循环递归爬取了。

上面我们实现了通过获取关注列表实现爬取循环，那这里少不了的还有粉丝列表，经过分析后发现粉丝列表的也类似，只不过把换成了，其他的完全相同，所以我们按照同样的逻辑添加相关信息，
最终代码如下：
    
 

    
   


 
     = 
    _ = 
    _ = {}={}
    _ = {}={}={}={}
    _ = {}={}={}={}
    _ = 
    _ = _______________________________________________________________=_
    _ = _____=_
    _ = _____=_

     _
         _=_ =_ _
         _=_ =_ = =
                      _
         _=_ =_ = =
                      _

     _ 
         = 
         = 

           
               
                 = 
         

         
            _=_ =_ = =
            _

         
            _=_ =_ = =
            _

     _ 
         = 

           
               
                 _=_ =_
                              _

             _ == 
            _ = 
             _
                          _

     _ 
         = 

           
               
                 _=_ =_
                              _

             _ == 
            _ = 
             _
                          _

需要改变的位置有

_里面添加 信息
_里面里面添加 信息
_做相应的的抓取详情请求和翻页。

如此一来，就完成了，这样我们就可以实现通过社交网络递归的爬取，把用户详情都爬下来。
小结
通过以上的，我们实现了如上逻辑：

_方法，实现了第一个大用户的详细信息请求还有他的粉丝和关注列表请求。
_方法，实现了详细信息的提取和粉丝关注列表的获取。
_，实现了通过关注列表重新请求用户并进行翻页的功能。
_，实现了通过粉丝列表重新请求用户并进行翻页的功能。

加入
在这里数据库存储使用，所以在这里我们需要借助于 ，实现如下：
 
    _ = 

     ____ _ _
        _ = _
        _ = _

    
     _ 
         
            _=_
            _=_
        

     _ 
         = _
         = _

     _ 
        

     _  
        _{_ _} { } 
         

比较重要的一点就在于_，在这里使用了方法，第一个参数传入查询条件，这里使用的是_，第二个参数传入字典类型的对象，就是我们的，第三个参数传入，这样就可以保证，如果查询数据存在的话就更新，不存在的话就插入。这样就可以保证去重了。
另外记得开启一下 
_ = {
     
}
然后重新运行爬虫
  
这样就可以发现正常的输出了，会一直不停地运行，用户也一个个被保存到数据库。

看下，里面我们爬取的用户详情结果。

到现在为止，整个爬虫就基本完结了，我们主要通过递归的方式实现了这个逻辑。存储结果也通过适当的方法实现了去重。
更高效率
当然我们现在运行的是单机爬虫，只在一台电脑上运行速度是有限的，所以后面我们要想提高抓取效率，需要用到分布式爬虫，在这里需要用到来维护一个公共的爬取队列。
更多的分布式爬虫的实现可以查看自己动手，丰衣足食！网络爬虫实战案例​即  词汇转向量。
我们希望词义相近的两个单词，在映射之后依然保持相近，词义很远的单词直接则保持很远的映射距离。
关于实例总结为步
、下载数据；
、将原词汇数据转换为字典映射；
、为 模型 建立一个扫描器；
、建立并训练  模型；
、开始训练模型；
、结果可视化。
现在来详细解说。
、下载数据
打开下载进来的词汇数据，由于是无监督学习，并没有标签，就只是整整大小文本数据。
这是第一步下载得到的数据

、将原词汇数据转换为字典映射
然后开始第二步将原词汇数据转换为字典映射，比如我取出这段文本的头一句，它会进行如下变换：

现在我们的词汇文本变成了用数字编号替代的格式以及词汇表和逆词汇表。逆词汇只是编号为词汇为。
、为 模型建立一个扫描器
首先看一下扫描器函数
__ _ __是指一次扫描多少块，_为左右上下文取词的长短，_输入数字的重用次数。假设我们的扫描器先扫这大段文字的前个单词，左右各取个单词，重用次数为次。我们就会观察到如下结果

关于参数设置：
_每次训练时候扫描的数据大小 _ 词向量的大小，_窗口大小。
_ =  表示用了产生的次数限制。
中默认是，可以设置为。
对比下：
默认的时候：

设置的时候：

就是对于一个中心词 在范围 随机选取_个词，产生一系列_ _ 作为_ 这些都是正样本。
、建立图形
这里谈得都是嵌套，那么先来定义一个嵌套参数矩阵。我们用唯一的随机值来初始化这个大矩阵。

对噪声比对的损失计算就使用一个逻辑回归模型。对此，我们需要对语料库中的每个单词定义一个权重值和偏差值。也可称之为输出权重 与之对应的 输入嵌套值。定义如下。

我们有了这些参数之后，就可以定义模型了。简单起见，假设我们已经把语料库中的文字整型化了，这样每个整型代表一个单词。模型有两个输入。一个是一组用整型表示的上下文单词，另一个是目标单词。给这些输入建立占位符节点，之后就可以填入数据了。

然后我们需要对批数据中的单词建立嵌套向量，提供了方便的工具函数。

 = _ _好了，现在我们有了每个单词的嵌套向量，接下来就是使用噪声比对的训练方式来预测目标单词。

我们对损失函数建立了图形节点，然后我们需要计算相应梯度和更新参数的节点，比如说在这里我们会使用随机梯度下降法，也已经封装好了该过程。

训练模型
训练的过程很简单，只要在循环中使用_不断给占位符填充数据，同时调用 即可。

现在通过上面一步，我们构造出了和，就可以进行监督学习，下面

、 
这里为什么不用更为常见的   呢？

因为如果在这里使用  作为损伤函数会有一个问题，当有几万的分类时，速率会大大下降。
其速度对比如下：
 个类，每秒处理  个样本，每秒处理  个样本。
 个类，每秒处理  个样本，每秒处理  个样本。
这里再整理出其他同学关于   源码的理解，下面就是一段   的实现代码，但不得而知  是否使用该 的实现。

的主要思想是，对于每一个样本，除了本身的，同时采样出个其他的，从而我们只需要计算样本在这个上的概率，而不用计算样本在所有上的概率。而样本在每个上的概率最终用了的损失函数。
这里可谓是整个  的关键。
至此，已经搭建好训练模型，然后便可以进行分批次的训练即可。那么下一个问题是完成训练后，我们如何判断两个词汇的相似度呢？

这里我们使用  来表示相似度会比使用  向量差值会好一些。
这是根据训练方式所决定的，因为向量的长度与分类无关。

、最后调用 的模块进行降维到元，__函数绘图展示：

获取更多测试干货，请搜索微信公众号：腾讯移动品质中心！汇总国外社区相关文章，覆盖 等内容：

  正式发布链接： 
点评： 当前  已支持   ，今年稍后交付的版本将会支持   ，都是为了和 兼容
     链接：
点评：随着  和。   的发布，本文简要介绍了  以及实际运用于应用的开发。
      链接：
点评：介绍微软 大会上和开发者相关的内容
         链接：
点评：     和   可以并行安装，如何通过 设置运行的版本，内容相同的还有这篇文章              

       链接：
点评：这是作者写的      系列文章，欢迎关注
       链接：
点评： 重新回归  这篇文章介绍 里面如何使用
           链接：
点评：这是介绍 使用 处理图片系列文章
       链接：
点评：     的简要教程
      链接：
点评：   已经，本文介绍使用   开发 ，
主题：性能分析
关于服务端性能、 和链接： 
点评：微软的 搜索引擎使用构建的，的经验这对于运行大规模服务器的人们非常有用
使用诊断 的问题链接：
点评： 是一个可以帮助你分析和内存问题的工具软件。它非常轻量级也不会入侵诊断的程序，在诊断过程中对诊断的程序影响甚微，可以用 诊断和 应用程序的性能问题。
性能分析工具链接：
点评：能够收集事件跟踪数据来追踪程序的调用流向，这些程序通过调用哪个函数识别频率。除了配置程序性能数据、和等工具不能轻松完成，还能分析程序内存堆来帮助确定内存的运用是否高效。它还有一个功能，可以让你确定跟踪间的任意差别来帮助你认出所有逆行。最后，该工具还有一个功能可以生成一个程序内存转储
在上如何收集 的  链接：
点评：性能分析的前提就是收集数据，在上如何收集 的 ，然后用工具进行分析。作者：

本文首先简单介绍响应式编程的应用，随之详细阐述如何实现一个轻量的响应式的函数库。
响应式编程
这篇文章介绍一种编程泛型，叫做响应式编程。将响应式称作“编程泛型”可能有些夸大其作用范畴，不过通过引入响应式确实会改变我们对特定问题的思考方法，就像刚接触  带来的函数式编程一样。
响应式和从前听说的“面向事件编程”很像，是针对事件的一种处理办法，且比从前的\\方法来处理事件，响应式会做得更加的优雅。
响应式编程基于“流”这个对象。“流”是一个管道，管道中流淌的是事件携带的数据，我们在这个管道的一个截面监听事件，当该事件流淌通过截面时，触发我们的事件句柄。

无论是异步的返回、用户事件、还是自定义的数据，都可以作为管道数据的来源，利用统一的进行处理。

来看一看代码吧
首先引入一个响应式的函数库，我用的，还可以选择：






下面的代码，你将每个一秒接受到一个
  = 

    

下面的代码，你将延时一秒获得鼠标的信息。
 
    
    

利用此代码可以做出一个很有意思的效果：

更多的例子，可以在各开源函数库的中查看。这里就不再复述。
下面的文章内容，将讨论如何手动实现一个轻量化的响应式函数库。从设计到代码，都有阐述。
如何构建一个
以下内容基于我自己写的一个响应式库：还在开发阶段，目前还未实现全部的接口。我们从一个简单的例子入手，请看下面的代码：
 
     =   
    

的开发过程也是从实现以上这一小段代码入手的。这三行代码每一行分别实现了三个功能：

创建一个新的
利用映射一个新的流
利用或者观察流发射出的事件

第三项是最复杂的，下面我们依次讲起。
创建一个
要创建一个，需要知道对象涵盖的方法和属性。这是一个引人深思的问题，设想现实生活中洗手间的一条水管，包含哪些属性呢？

首先是水管，无论是铁质的还是的，我们首先需要一个水管容器；
然后是水，水管需要有流淌的实体
最后是水源，不同的水源供水习惯不一样。并且，水源负责供水。

这样，可以粗略的构建个类。
 {   就是水管，只是个容器而已
     = 
}
  {   水源
     =             水源的供水习惯
     =         水源里的水
}

然后再来看最初代码的第一行：
 

其实就是调用了和的构造方法：
 =  {
        
}
 利用方法我们可以写得更加简洁一点
      

很明显，这里的参数就是水源的供水习惯，它是周期性的，一秒供水一次，参数就是水源的供水，它是一个值：“”。
通过映射一个新的
如何映射出一个新的流呢？熟悉数组函数的同学很快想出了答案：
 = {
    
}
 = {
     = 
}

貌似是一个很好的办法，不过，还有一种我们没有碰到的情况，那就是不存在的情况。例如，有些是来自于，只有当了之后，才会知道具体是什么，我们不能在此之前一个。另外，函数式编程里面讲究惰性执行，这样做违背了惰性原则。
要解决这个问题很简单，不要去直接一个，而是将的方法放进一个队列里，真正需要它的时候再拿出来执行，而这个队列，我们取名叫做，当然，里面装的，那就是大名鼎鼎的了。
  {
    
     = 
}
 = {
    
}


这个概念，经常在开源的库里看到，但是又很少看到一个准确的、易于理解的解释。大致可以翻译为“槽”，一个就是一个事件的加工厂。里面流动的是事件，而当一个事件真正被发出时，这个事件会经过一个个，改变了最初的模样，最终到达观察者的手中。这样的描述是不是很像中的？通过一个个，将最终的产物的交给。也一样，一个经过一个个水槽加工厂，将最终的产物交给。其中道理没想象中神秘。

下图展示了一个请求网络资源的组合。黄色背景的方框即是一个个。

对于函数的设计也是需要详细讨论的，最初，每个函数都被简单的设计为输入输出的纯函数。当发出一个，经过重重，最后输出的结果用一个函数就可以完成：
  =  {
     
} 

这样设计期初看起来非常优雅，要是所有函数都是没有副作用的纯函数该多好啊事实上，这种方法我们没法完成异步的操作。例如，需要加入一个。该会住，若干秒之后再将它交给下一个。这样的需求纯函数的是没办法完成的。所以我参照了中间件的代码，如果每一个都能取得对下一个的引用，那么就可以由来控制数据的向下传递时间和方式。中间件的设计方法其实也参考了的中间件，可以去看这里的文章了解中间件的代码实现。
最终，函数的接口被设计成这样：
   {
      = 
        
    
              
      _=_
}

例如，对于的实现就是：
 = {
        {
          
    }
}

这样就实现了 =   这样的接口调用。
利用观察流发射出的事件
回顾一下，流发射出的事件被描述为的属性。在流出之前会经过的层层加工。然后我们如何观察这段水流事件呢？
经过的第一和第二步骤，形形色色的被创造了出来，但是这个水管中还是没有水在流动，我们还要激活它，激活水的源头。给构造函数再加一个开闸方法，当调用方法后，这个水源才真正源源不断的输送水流事件。
 = {
     问题来了
}

问题来了，方法里面要怎样实现呢？
注意到，一旦，就需要按需触发事件，本质上还是需要来完成。不同的需要触发事件的方式不一样，本文的例子，源是需要每隔秒周期性的发射水流事件，换做其他流，可能就需要其他的事件发射规律，这就涉及到：

计算出时间点
根据利用往的时间队列里添加方法
设计一个类来管理和

第一点，需要实现一个，负责计算每个应该在多久之后执行；第二点，我们实现一个，职责很简单，就是根据传入的往队列里添加方法；第三点，我们实现一个，负责管理和。

这三者的实现代码比较繁杂，的这部分代码也是参考完成的。有兴趣可以去看源码。

类有一个类似事件循环的机制，每当有分配给，它会执行这个，然后再在队列里寻找是否还有下一个。其流程图如下：

有了类对于时序的控制，激活一个就等于往里面丢一个，会自动管理好这个。这个接口调用起来也很简便：
 = {
        
}

每一秒钟会调用一次，会调用第一个，然后第一个按需调用方法将数据交给下一个。代码的实现请看中间件的实现方法。
最后，既然掌握了激活的方法，剩下的就是观察发射的事件了，原理更简单，给的最后加入一个观察用的即可：
 {
         = 
}
 = {
    
    
}


这样，除了最复杂的时序控制的的代码实现，我们已经阐述了一个的建模方法。可以参考下图，再回到文章看不懂的地方。


原文链接：


相关推荐微加响应式建站平台打造永不过时的网站腾讯云主机上测试编译从的纯函数到函数式编程话题背景：
岁，不是今天才有这个问题的。只不过，之前轮不到后的最广大一波人群，所以没有太多人关注。
年，年出生的也已经岁了。难怪，岁的问题开始引起了大家的关注。
作为一个面临体力精力不断下降而技术更新迭代速度极快的职业，码农，岁的真的要被早早地淘汰了么？未来的道路又在哪里呢？
作为程序员，我们或早或晚总有要面临岁的一天……

你是“而立之年”了么？


你是怎么看待它的？


你对于程序员岁面临的各种纠结和困境又有什么想法？

不妨一起来聊一聊？
互动奖品
黑轴机械键盘腾讯云充电宝腾讯云元代金券
话题参与规则：
、登录并在本帖下回复你对这个话题的看法，请勿水贴。
、评论的第楼、第楼、第楼会获得腾讯云元代金券张。
、黑轴机械键盘  腾讯云充电宝  两项奖品，专家会在相应的话题回复下如【恭喜您已获得了“奖品名”】，即可获得对应奖品
、活动时间：年月日年月日
本期话题主持人：
王拥军 已入驻腾云阁
腾讯产经资讯部 移动客户端开发 团队主持人公众号【水滴的声音】关注企业文化、团队管理
相关文章：
拿什么拯救你，我的三十五岁从华为大龄员工看员工激励、股权激励的问题被空降到一个团队当领导，你会如何烧自己的三把火？
获奖结果：
黑轴机械键盘翟志军
腾讯云充电宝腾讯云用户钱进
腾讯云元代金券第楼：陈涛第楼：腾讯云用户第楼：刘卓夫
请添加腾讯云技术社区的号：  ，领取奖品腾讯云沙龙继月成都站，将于月日来到深圳站，与游戏厂商和游戏开发者，畅聊游戏加速。
游戏全球化“蓝海”的竞争将日益激烈，全球环境下，网络延迟所引发的卡顿、更新包难以顺利下载等问题却让游戏玩家逐渐远离您的游戏。本期腾讯云沙龙深圳站，我们将与您探讨实时对战类游戏网络优化、全球游戏加速和游戏更新等话题，期待您的光临！

腾讯游戏云产品总监王永和将分享腾讯游戏云生态产品规划及最新进展。腾讯云游戏业务中心除了为游戏提供灵活而稳定的部署解决方案外，同时也秉承腾讯公司”开放“的战略理念，将腾讯内部领先的游戏开发技术和丰富的游戏服务资源，向外部游戏开放，并共享大平台优质渠道资源、以及提供丰厚的专项扶持金，助力您的游戏业务腾飞。
腾讯游戏云高级产品经理张小华将分享如何打造多快好省的游戏更新体验。腾讯云整合平台的技术优势和海量自研游戏的开发运营经验，为手游和应用开发者提供专业、稳定的应用程序和游戏资源更新服务，解决客户端大、更新流量消耗大、更新时间长、渠道审核时间长且多样化管理复杂等问题。
腾讯游戏运营部新终端中心资深工程师宁斌辉将针对实时手游的网络优化探索进行分享。实时竞技手游为代表的移动游戏对网络稳定性和延迟要求严格，腾讯游戏与运营商、终端厂商合作，在移动网络稳定性方面做了诸多优化实践，通过腾讯云向游戏行业开放“智营网优”服务，为用户提供优质网络体验！
腾讯游戏云资深产品经理马亮将分享腾讯云全球游戏加速方案。随着类游戏和全球同服游戏需求的增长，游戏厂商如何让全球玩家共同竞技无卡顿、让玩家就近接入、实现跨区吃鸡？腾讯云全球游戏加速服务提供全面的网络层解决方案，让玩家连接更稳定、更高效、更安全。
参会指南：
报名方式：识别下方二维码，或访问 填写报名问卷。我们将在会前发送确认短信给参会嘉宾。如有关于沙龙参会与合作的问题，欢迎联系和。

访问沙龙官网 ，了解最新沙龙资讯和更多往期回顾。背景
近日在开发过程中，发现每次点击  从桌面启动都有一个在桌面明显的等待时间，机型越低端的越明显，冷启动优化看来已经势在必行，所以怒而一顿研究再解决之。话不多说先上优化前后效果图：
买家秀：

淘宝秀： 

  启动流程：
俗话说要想优化好，流程不可少！关于   启动的流程图如下：

总结一下一个完成的冷启动  过程应该是经过：
         
这里主要是把相应的生命周期回调写出来。 因为一般大家的业务代码都是在这些函数回调中调用。
 冷启动相关优化点
 生命周期内减少耗时操作

：

 
这个方法中一般雷区主要都在这句代码上，因为在    以下会存在  方法数分包的问题，当  过大时会导致  启动慢，  或者  等异常，关于分包解决和优化方案网上一堆就不在做赘述了。



这个方法是需要重点优化的，因为大家的第三方插件初始化一般都会放在这里，在  初始化做繁重的东西会严重阻塞  启动，网络请求等。以下是我们第三方插件初始化的耗时：
：
 
：

这里把  和  下的时间都贴出来，是希望大家不要重蹈覆辙。。。  因为  模式下和  模式下一个是  左右， 一个是  左右，误差很大，请大家一定要在  下测试数据！！！！
针对于解决第三方插件初始化耗时方案一般是：
 分优先级加载，非必要  由懒加载实现。
可以多线程初始化的  由多线程方式来进行初始化。

  

同上一样，尽量不要在此布局做一些耗时的操作或者呈现一些过于复杂的布局。在具体分析自己的  时发现  中有这样一行代码：

其作用是希望用户在打开时，一定能看见  的画面，主动延迟了  加载。这里其实有更好的解决办法处理，则是把跳转  的方法放在  中而不是放在  中。因为  系统中  一定是处于可见可交互的状态，用户一定能看见  再去跳转，由系统生命周期决定，而不是固定的等待 ，此处优化后启动速度又提升了 。所以建议大家以后还是遵循生命周期去做一些事情，尽量别进行人为延迟阻塞。
 避免冷启动
 启动方式一般有  种：

 ——冷启动：

此种方式最为耗时，一般是因为进程被干掉，系统需要重新  进程进行一系列初始化。

 ——暖启动

比  稍快，因为  的所有  还常驻在内存中，并没有被杀掉，所做的只是把  从后台提到前台来展示，并不需要重走初始化一系列行为，减少了对象初始化、布局加载等工作。但其行为表现与冷启动一致，是会     直到  渲染 。这个   后面会解释。

 ——热启动

启动方式最快，类似于返回键退出应用又立即进入的那种行为。
优化方案：
既然冷启动那么慢，我们就在非用户主动  进程或系统通知  进程的其他情况下不再主动退出进程。那答案很简单了，就是在位于  栈底  中  其返回键行为，保证用户点击返回键后不再退出 。在我们  里位于我们栈底的一定是我们的 ，因为一系统行为都是由其向下衍生的。所以只需加入以下几句话：

：作用是不再  到此 ，仅仅是把它放到后台隐藏。类似于用户主动触发系统  键的效果。在同是点击返回键优化前后的对比如下：
 优化前： 
  
 优化后： 

若图  中时间久后进程回收后优化效果会更为明显。
——脱下秒开的最后一层薄丝袜
经过上面一顿操作后，我发现然并卵！！！启动速度是提升了，但是  一点击还是会在桌面停顿一下。哇呀很难受细细思考了一下，一个  启动无论如何都是会新  进程，难道就是这个问题导致其在桌面上停顿一会儿？那其他  又是怎么做到秒开的呢？在  的  有这么一句话：

其实在创建  进程时， 系统会为你立即显示一个  ，然后再去创建  进程，当  完成   时，会立即由你的 即默认启动的 替换掉它。这里的   就是上文  中提到的  。谜底到此解开所谓的秒开原来就是视觉欺骗。。。所以说有人给你说他只是仅仅是优化生命周期内初始化代码达到秒开都是扯淡。但不得不承认这样用户体验大大的提升了，一点击  就渲染好一个背景图片，给用户一种已经启动的感觉，前面做的一系列优化，不过为了让用户少看一会儿系统给渲染的  。
那为什么我们的  会出现在系统桌面上停留一会，而不是渲染背景图呢？原来在项目创建时，系统会为  默认了一个 ，这样就会导致  点击启动后会白屏一段时间然后展示自己的 ，为了解决白屏的问题把  主题换成透明的就像下面

但其实这样虽然解决了白屏的问题，但是就会出现上文所说的，点击后停留在桌面一会儿，直至  渲染出来。这是大部分  的做法，但并不是最佳解决方案。
 最佳解决方案：
应该由  此属性作为你的品牌推广页或者  页，如果你的  完全不需要做任何初始化，只是希望有个闪屏页，完全可以由  来满足。
设置自定义带  的 

前两行代码是设置  不透明并且默认渲染的背景图是我们必看影视闪屏页的图片。

：关键，主要设置你想要的背景图或者是动态自绘的  皆行，这个视图会在你冷启动时渲染给用户过渡看。

：全屏展示，免得顶部状态栏显现颜色不一致过于脱节和突兀


 为你的   设置你的启动 

 在   启动后再把主题设置回自己的 


此时你的  就能完成秒开了！
推荐测试工具
最终我们  从  点击到第一个  渲染完成总共需要时间是 ，很吉利！

   
上图的那行日志是由系统打印出来的，意思就是渲染  所需要的时间，如果是第一个  启动时长也是算在内的。 在 以上才会有此  打出，在  级别搜索  即可。不仅可以看自己的还可以看到其他  的启动时长。

附带一张小米  上业界各大  的冷启动时长仅供参考

执行时间打印神器，集成至项目后，只需在想要测试的地方加上注解即可：

可以是  级别，也可以是函数级别。如果注解是  类级别，还会把各大生命周期回调函数执行时间打印出来及其方便！ 传送门
效果如下：


这是非死不可出的调试神器，如果开发  这个没用过的话，你一定会觉得相见恨晚！ 传送门最近研发的项目对  依赖比较重，梳理了这段时间使用遇到的个比较具有代表性的问题，答案也比较偏自己的开发实践，没有 专业和深入，有出入的请使劲拍砖！

读写性能是多少，有哪些性能相关的配置参数？

负载高时，如何找到是由哪些引起的？

如何针对具体的做优化？

层面已难以优化，请求量继续增大时的应对策略？

如何做主从数据同步？

如何防止误操作和做好容灾？

该选择哪种存储引擎，具有什么特性？

内部结构有哪些层次？


读写性能是多少，有哪些性能相关的重要参数？
这里做了几个简单压测实验
机器：核，内存表结构尽量模拟业务：个字段个为自增 ，个，个，个，存储引擎。实验写： = 前提：连接数，每次单条记录分析：跑了，这时磁盘为顺序写，故性能较高
实验写：条件命中索引 = 前提：连接数，条记录，每次单条记录的个字段个，个分析：跑，瓶颈明显在的随机写
实验读：条件命中索引 = 前提：连接数，条记录，每次单条记录的个字段个，个分析：跑，瓶颈在，和的大小相关
实验读：条件没命中索引 = 前提：连接数，条记录，每次单条记录的个字段个，个分析：跑到，每次都需遍历所有记录，看来索引的效果非常明显！
几个重要的配置参数，可根据实际的机器和业务特点调整
_：最大连接数
_：缓存打开表的数量
__：索引缓存大小
__：查询缓存大小
__：排序缓存大小会将排序完的数据缓存起来
__：顺序读缓存大小
___：某种特定顺序读缓存大小如 子句的查询
：查看配置方法：   _
负载高时，如何找到是由哪些引起的？
方法：慢查询日志分析
慢查询日志例子，可看到每个慢查询的耗时：
  __   
 _   _  _   _ 
 =
   ___
日志显示该查询用了秒，返回行记录，一共遍历了行记录。及具体的时间戳和语句。
使用进行慢查询日志分析
     __
输出查询耗时最多的条语句
：排序方法，表示按时间 此外，为按次数，为按返回记录数等：去多少条， 表示取前条
执行完分析结果如下：
   =   =   =  __
     ___  __  
   =   =   =  __
     __  __  
   =   =   =  __
   _  ___  __  
   =   =   =  __
     ___  ___  
   =   =   =  __
   ___  __   
   __  __  
以第条为例，表示这类可以取很多值，这里会归并起来在月号的慢查询日志内出现了次，总耗时秒，总返回行记录，有个客户端用到。
通过慢查询日志分析，就可以找到最耗时的，然后进行具体的分析
慢查询相关的配置参数
__：是否打开慢查询日志，得先确保=后面才有得分析
__：查询时间大于多少秒的被当做是慢查询，一般设为
____：是否将没有使用索引的记录写入慢查询日志
___：慢查询日志存放路径
如何针对具体的做优化？
使用分析语句执行计划
     ___  __  

|  | _ |                   |  | _ |   | _ |   |  |        |

|   |       | ___ |   |           |  |     |  |    |   |

     
如上面例子所示，重点关注下，和：
：使用类别，有无使用到索引。结果值从好到坏：  使用到索引    全表扫描，一般查询应达到级别
：执行检查的记录数
：执行的附加信息，如 表示查询只用到索引列，不需要去读表等
使用分析语句执行时间和消耗资源
  = 启动，默认是没开启的
    ___  __   执行要分析的语句
  

| _ |    |                                                                                         |

|         |  |    ___  __   |

     
        可看出在各个环节的耗时和资源消耗

|                |  | _ | _ | __ | __ |


|            |  |  |    |             |              |
|            |  |  |    |             |              |
|             |  |  |    |             |              |
|             |  |  |    |             |              |
|           |  |  |    |             |              |

优化的技巧 只提一些业务常遇到的问题

最关键：索引，避免全表扫描。

对接触的项目进行慢查询分析，发现的基本都是忘了加索引或者索引使用不当，如索引字段上加函数导致索引失效等如 __

| _ |    |                                  |

|         |  |      =    |
|         |  |      =  |

另外很多同学在拉取全表数据时，喜欢用     这种形式批量拉取，其实这个每次都是全表扫描，建议添加个自增做索引，将改为       

| _ |    |                                                |

|         |  |      =  = |
|         |  |                    |

合理用好索引，应该可解决大部分问题。当然索引也非越多越好，过多的索引会影响写操作性能

只出需要的字段，避免 

| _ |    |                                                |

|         |  |             |
|         |  |              |


尽量早做过滤，使或者等后续操作的数据量尽量小

把能在逻辑层算的提到逻辑层来处理，如一些数据排序、时间函数计算等




：关于优化，已经有足够多文章了，所以就不讲太全面了，只重点说自己个感受：索引！基本都是因为索引！
层面已难以优化，请求量继续增大时的应对策略？
下面是我能想到的几个方法，每个方法又都是一篇大文章了，这里就不展开。

分库分表

使用集群，读写分离

增加业务的层

使用连接池


如何做主从数据同步？
复制机制
通过复制机制，将的写操作通过传到生成中继日志，再将中继日志，使得主库和从库的数据保持同步
复制相关的个线程

上的线程：向请求数据

上的 线程：读取事件并把数据发送给的线程

上的线程：读取中继日志并执行，更新数据库


属于主动请求拉取的模式
实际使用可能遇到的问题
数据非强一致：默认为异步复制，和的数据会有一定延迟称为主从同步距离，一般  主从同步距离变大：可能是写入压力大，也可能是机器负载高，网络波动等原因，具体问题具体分析
相关监控命令
 ：查看进程信息，包括个同步线程的当前状态
   ：查看配置及当前复制信息
  ：查看配置及当前复制信息
如何防止误操作和做好容灾？
业务侧应做到的几点：

重要数据的手工修改操作，操作前需做到点： 先在测试环境操作  备份数据

根据业务重要性做定时备份，考虑系统可承受的恢复时间

进行容灾演练，感觉很必要


备份和恢复操作
备份：使用导出数据
  用户名  数据库名 表名  导出的文件名
      
恢复：导入备份数据
     
恢复：导入备份数据之后发送的写操作。先使用导出这部分写操作基于时间点或位置如导出 之后的：
 = =    
如导出起始为之后的：
 = =   
最后把要恢复的导入
     
该选择哪种存储引擎，具有什么特性？
存储引擎简介
插件式存储引擎是的重要特性，支持多种存储引擎以满足用户的多种应用场景存储引擎解决的问题：如何组织数据在介质中高效地读取，需考虑存储机制、索引设计、并发读写的锁机制等支持的存储引擎有、、、等
和的区别只说重点了

，之后及的默认引擎。

支持行锁：并发性能好

支持事务：故称为事务性存储引擎，支持，提供了具有提交、回滚和崩溃恢复能力的事务安全

支持外键：当前唯一支持外键的引擎



，之前默认引擎

支持表锁：插入查询速度快，更新删除速度慢

不支持事务




使用 可查看当前支持的存储引擎详情

内部结构有哪些层次？
非专业，这里只简单贴个结构图说明下。是开源系统，其设计思路和源代码都出自大牛之手，有空可以学习下。


：连接器。接收不同语言的交互

   ：系统管理和控制工具

  连接池。管理用户连接

  接口。接受用户的命令，并且返回用户需要查询的结果

 解析器。验证和解析语句成内部数据结构

 查询优化器。为查询语句选择合适的执行路径

和：查询缓存。缓存查询的结果，有命中即可直接返回

：存储引擎。数据最后组织并存储成具体文件



相关推荐 数据库的高可用性分析数据库设计总结云数据库  团队简介：腾讯社交平台业务运维团队，负责、微云、相册、天天图、优图等产品的技术运营工作。致力于服务质量优化、服务保障、自动化运维体系建设等工作。经历过农牧场、红包、军装图等多次活动保障。团队一直在进行自动运维，智能运维探索和实践。


前言
近两天人民日报腾讯云联合运营“军装照”活动，想必已经刷爆了各位的朋友圈。在这场营销盛宴的背后，伴随了又一次海量运维能力的：台设备，峰值带宽，次运维自动扩容。这类利用社交关系引爆的运营事件对腾讯的运维团队早已不是什么新鲜事，从全民农牧场、全民刷红包、甄嬛传、军装照，的运维团队早已把应对业务突发的变化作为织云智能运维平台能的核心能力。今天就让我们一起来探秘下，织云智能运维平台的关键技术和核心功能。
织云智能运维平台
、    标准化运维
织云智能支撑平台管理着超过十万台服务器，上万个功能小时提供服务，而运维操作人员却很少。一个人维护近万台服务器，军装活动来临时可以快速无误的完成台服务器上线，是依托什么实现的呢？最主要得益于长期以来织云推行的标准化服务和运维的理念和要求。织云平台提供的统一包框架，集中配置管理，统一路由，统一组件等标准化技术手段，帮助运维研发质量等多团队完成高效协作，标准交付，快速应对等重要运营能力。标准化运维体系帮助我们在任何时候都能快速应对各种突发业务需求。
、    强大的供应基础
依托腾讯云的海量资源，织云可以提供秒级的供给能力，结合自动化变更扩容缩容技术，可以快速应对万级服务资源供给上线需求。
、    应用配置介绍
织云的设计，以模块为管理节点模块：提供单一功能服务的集群。会记录相关的配置信息，具体包括：硬件配置、软件配置、运营设置、软件包、配置文件、脚本、流程、测试用例等自动化依赖的关键系统。以天天图业务的应用配置示意图如下。
、    自动化流程的介绍
织云提倡的自动化理念是：标准化  配置化  自动化，让企业的常用操作固化成流程工具。不依赖容易过期的文档，不依赖容易流失的人的经验。参考持续交付的原则“为软件的发布创建一个可重复且可靠的过程”，运维团队为了解决人肉操作经验差异的难题，将运维操作通过流程编排能力，实现标准操作的固化。“军装照”活动扩容，任何一个运维人员只需要执行天天图的扩容功能即可实现容量扩展，而织云流程会自动化的完成整个服务部署和上线的操作。如下图
、    关键的技术点：
、    织云路由：

名字服务

将调用对象、端口为维度抽象为名字服务，主调方调用时，无需关注实际被调服务器，而只需要确定名字服务。以此实现，被调方的变化对主调方完全透明。

负载均衡

由于有些被调服务器本身存在差异，存在计算能力不一致的可能，可对不同的被调对象配置不同的权重，织云平衡木能够自动根据服务器处理能力、容量情况自动进行权重配置，达到负载均衡的目的。

请求调度

链路、机房环境发生故障时，可能导致单服务器故障机率较大，织云具有的主动探测、调整机器，将故障机主动踢出被调，在故障机恢复后将其自动加回被调集群。在大面积机房故障时，也可借助的调度功能将整体被调对象切换到其他机房。
、    大并发传输
运维平台如何实现快速文件分发，在织云平台的技术实现上，主要有两个技术要点：

异步、基于消息队列的执行引擎直接操作现网机器执行命令的命令通道、以及执行扩缩容任务的流程系统，均采用面向消息与异步通信的架构，高并发，易于水平扩展。

分布式多级文件分发系统文件分发是服务部署强依赖的基础功能。源文件存储在分布式文件系统上，三份冗余。既提高了可靠性，同时也提高了本地读取速度。对于多区域环境，每个区域还有独立的文件缓存，就近传输。


、活动平台：自动缩容
社交运营活动是腾讯的常态，因此织云专门针对这种活动业务的特点：快上快下，定义了活动平台的功能给予支持。
自动缩容功能支持定时缩容与低负载缩容，由不同的策略触发运维自动化流程操作。“军装照”的台设备活动热度过后，运维人员可设置自动的缩容策略，即可实现自动化的缩容，无需人工介入操作。缩容操作如下图
容量监控的方法
、    高低负载日常管理运维工作要尽量减少救火式的任务，鼓励有计划有准备的工作，将容量管理变成重要不紧急的工作。因此，我们倾向于把这部分工作例行化，将容量管理从计划外任务转变成计划内任务。以腾讯对生产环境容量管理的度量方法为例，织云平台提供统计数据以模块为管理单位：

低负载：使用率 ，流量 秒，访问密度 次秒
高负载：使用率 ，流量 秒，访问密度 次秒

、    异常容量的处理在腾讯运维日常工作中，与容量相关的运维对象有：单机、模块、。 单机的容量管理利用亲和或内核多队列网卡的特性，解决多核间负载不均，导致容量浪费的问题。
 模块的容量管理
利用织云路由服务的请求权重调度的能力参考开源、、等，解决集群内负载不均的问题。利用织云一致性管理能力，解决应用程序或配置文件部署不一致的问题。λ    的容量管理结合压测找到的性能短柄，保持容量模型可靠，以备关键时刻调度所用。、    实时模块容量监控在模块内容量一致的情况下，织云监控实时采集单机硬件性能指标，即可汇总计算出模块的实时容量指标，供自动化决策所用。织云主机监控技术架构如下图，支撑着台设备量的主机性能数据采集，为腾讯社交业务提供准确高效的基础监控能力。
写在最后
社交平台业务运维团队在腾讯云和织云平台的辅助下，为人民日报的“军装照”运营活动提供了强有力的运维支撑，虽然镁光灯下不常有运维的身影，但我们依然为腾讯产品自豪、为我们的运维工作感到自豪！
欢迎关注「腾讯织云」微信公众号，获取最新织云的技术资讯。因为 很影响的读写性能，所以在不同版本是否 其实社区一直都在寻求优化，可根据需要选择不同的实现类、和，选择了不同的实现类后，也选择了相应的选择算法从对应中选择合适的文件进行合并。有关不同的算法性能影响及适合场景可参考文章：

版本使用的实现类是
 
下面，从方法中开始分析 的过程，从方法中可以看到 将调用的方， 将调用的方法，但这两个方法都会调用的方法：
 
这个是方法原型：
 
从源码中可以看到，和的区别再于参数和。
这个方法很简单：根据请求的文件大小以及判断使用或者线程池，然后封装成放到对应线程池中执行。
方法有点长。
方法是真正实现方法，在为了完成一共分为以下步骤：
选择需要的问题只有 
执行前置
在中以为单位执行
是否需要
执行后置


选择文件的方法是利用滑动窗口把最多的小文件进行合并，可参考：，本文档将着重分析在中以为单位进行：
 
在保证当前并没有在后：
首先对的锁加上读锁；
创建一个用于监控和跟踪的过程
调用方法进行的准备，当前实现为空
调用对应的方法
标记成功
在的方法中：

检查参数
通过查看类图的方法，并返回后的新文件
根据判断是否做一些的工作：
把生成的文件移动到正确的位置
记录日志   
更新相关的数据结构
归档旧的文件，关闭，重新计算的大小
执行结束之后会生成临时文件，临时文件的意义在于，在执行期间，对于原数据访问没有影响。执行合并操作生成的文件生效过程，需要对的写操作加锁，阻塞内的更新操作，直到更新的完成为止。
生成新文件的方法很简单，给源文件创建一个，之前说过能从多个当中每次都取出最小的，然后用的方法不停地追加写入即可：

 
 
，对的读写性能均有一定影响，有关对性能影响以及相关调优可参考：

免责说明：本文介绍的  与公司的叮当助手没有任何关系。

这个项目其实来源于我生活中的一个需求：我每天晚上都会去厨房做一个面包当明天的早餐，当我把用料按顺序准备好放进面包机时，我需要准确预约到明天早上我吃早餐的时间。然而，几乎每次在这个时候我都没有带手机在身边，而是都放在客厅里充电，这时只能跑去客厅看时间。虽然厨房到客厅只有几步之遥，但自己又是懒癌患者，每天都要这么来回奔波就觉得很不方便。要解决这个问题当然有很多种方法，比如直接买个小时钟放在厨房。不过我更希望“连看都不用看”，直接有人告诉我时间。所以，我需要一个像   那样的智能音箱。
然而，不论是   、  还是微软  音箱，在国内的使用都是个问题。虽然国内也有类似的智能音箱产品，但我没有用过这些产品，不知道可定制性如何。比如，如果我需要开发个功能让它告诉我某种面包的配方是什么，这些产品就不一定能做到了。考虑再三，我决定自己动手写一个。整个项目用了差不多三个星期的业余零碎时间。
先放上项目主页：
：
下面分享一下我在开发这个项目过程中的心得。
硬件
首先要解决的是硬件问题。我选择在   上开发。于是我买了块   三代主板。麦克风和音响方面，出于美观的目的，买了个自带音响的  全向会议麦克风。整套设备看起来就像这样：

过了不久觉得这个麦克风自带的音响音质太一般了，所以我又外接了一个小音箱。然后再插了一个摄像头，用来实现拍照功能，又进化成了这样：

发布了不到一个星期， 的商务经理看到了我这个项目，希望能提供硬件上的支持，所以我又玩上了各种  的硬件做为回报，我也零报酬给他们带去了  多个  的销量：

因为软件本身是和硬件解耦的，并不依赖具体的硬件要求，所以很多用户也自己做了硬件上的定制和尝试最后一张图里预装了  的是熊，不是妹子 ：

硬件有了，接下来就得开始写软件了。主要的框架借鉴了  项目，并加入了我自己的定制和想法。这里说说一些有意思的部分。
指令接收
智能音箱要解决的一个最重要的问题就是如何接收指令。这里头主要涉及两个问题：

被动唤醒 ，即“什么时候开始听”。这个阶段只监听唤醒词。当听到唤醒词时，进入主动聆听。
主动聆听 ，即“什么时候结束听”。这个阶段主动聆听用户的任何语音指令，然后对听到的内容进行分析处理。

被动唤醒阶段的基本策略是：每次以  的采样率录制  个采样作为一个采样集，然后对采样集进行信号强度估计，当某个采样集信号强度大于一个阈值时，就认为可能接受到了指令。然后持续录制多  秒时间，再转交给语音识别模块。当语音识别模块认为是唤醒词时，进入主动聆听阶段。
主动聆听的策略与被动唤醒基本相似，每次以  的采样率录制  个采样作为一个采样集，然后对采样集进行信号强度估计，当某个采样集信号强度低于一个阈值约  秒的时间时，就认为用户已说完了指令。当然还要考虑环境吵杂，一直处于聆听的可能。因此可以再加一个超时保护，超过  秒就结束聆听。
语音处理
说说语音识别，说成也是一回事啦引擎和语音转文本引擎的选择。由于被动唤醒会试图识别所有听到的内容，出于隐私保护的目的，应该使用离线的语音识别引擎，因此我选择的是  。而对于主动聆听，由于是在唤醒阶段才会进行转换，进入主动聆听前会有蜂鸣提示，用户也会清楚此时叮当正在听他们说话，相对来说隐私泄露的可能性就比较低，因此我最初选择的是在线的百度  语音识别服务，也省下了扩展语音识别模型的工夫，有利于更好地实现插件可扩展。 引擎方面同样也先支持了百度的语音合成。
在实际测试中， 的识别出乎意料的好。由于我的离线指令集只有几个候选唤醒词， 对这些唤醒词的识别非常灵敏，甚至有时候其他声音也可能被误当成唤醒词而唤醒叮当。但即使被意外唤醒了，不去理会叮当就可以了。
相比之下，百度的语音识别就比较迟钝了。有时候明明我发音很清晰了，还是会识别成另外的含义。通过在百度的语音识别平台上传自定义的语音识别词库 可以提高识别的准确率。另外，由于我用的是  ，网速比较差的时候响应也比较慢。我在家用的是  带宽的网络，反应速度还算可以接受。
下面这个视频是我与叮当对话的演示。我把唤醒词设置成了“小梅”：

一个问题是当回答内容比较长比如问叮当当天的新闻时，合成语音的耗时会变得很长，给人的感受是叮当的响应很慢。所以我加了个 __ 的选项。当内容过长时，改成发送到用户的邮箱或者微信。

到了九月份的时候， 在离线唤醒方面又增加了  引擎，在主动聆听和语音合成方面又增加了阿里、科大讯飞的服务，无论是识别速度和合成音色的丰富程度又有了很大的进步。

技能插件
叮当最好玩的部分当然就是玩插件了，通过写插件可以让叮当接入各种各样的服务，完成各种各样的事情。我在叮当里也内置了几个插件。为了方便用户扩展，我定义了三个技能插件目录：

：官方插件，与  同一仓库；
：用户贡献的第三方插件，单独维护一个  仓库；
：用户自定义插件，用于存放用户自己开发的，暂时不计划对外发布的插件。

如下是截至本文发布前  提供的插件，可以看出，其他用户贡献的插件已经达到了叮当自带的插件的两倍：



插件名
用途
是否用户贡献





简单的回声传话功能。
否



检查邮件功能。
否



时间插件。询问叮当时间。
否



用于调起摄像头拍照如果安装了摄像头的话。
部分



要求叮当发送微信登录二维码到用户邮箱方便远程微信登录。
否



用于进入退出闲聊模式的插件。
否



用于机器人聊天兜底。
否



用于控制接入的设备
是



网易云音乐播放插件
否



天气查询插件
否



播报主机地址插件
是



重新启动操作系统用户
是



启动服务器插件
是



向微信好友发消息插件
是



通过协议与其他开发板通讯
是



通过  实现语音开机
是



以邮件方式实现语音操控电脑
是



简单的备忘插件
是



简单的树莓派状态查询插件
是



新闻头条播报插件
是



出行路线规划插件
是



百度音乐播放插件
是



音乐播放
既然是智能音箱，当然少不了播放音乐的功能。所以我额外写了个播放网易云音乐的插件  。出于版权考虑，并不集成进官方插件中，而是放进  里头。
这个插件的实现比较复杂。普通的插件接受到指令，响应完就退出了。而为了能支持各种指令控制音乐播放，这个插件在接收到播放控制指令后并不退出插件，而是进入一个播放器模式，这个模式主动聆听得到的指令只会在播放控制指令集中匹配，其他的插件指令都不起作用。只有当用户要求退出播放时才回到普通模式。 的播放控制指令如下：



指令
相同指令
用途




播放音乐

进入音乐播放模式。在音乐播放模式下，其他的插件功能将不可用。


下一首
切歌 下一首歌 下首歌
切换到下一首歌。如果没有下一首歌，就回到列表中第一首歌


上一首
上一首歌，上首歌
切换到上一首歌。如果没有上一首歌，就跳到列表中最后一首歌


大声点
大点声，大声
调高播放音量


小声点
小点声，小声
降低播放音量


随机播放

随机播放列表中的音乐


顺序播放

顺序播放列表中的音乐


暂停播放

暂停音乐的播放


播放
继续
继续音乐的播放


榜单

播放推荐榜单


歌单

播放用户的歌单如果有多张，将只播放第一张


结束播放
退出播放，停止播放
退出音乐播放模式。


搜索
查找
搜索歌曲歌手。将自动播放搜索结果。


什么歌

正在播放的是什么歌



实现这个插件的过程中还参考了  的  项目以及  的  。为了方便重用，我把  的核心  抽离了出来封成了一个  库 。比较坑爹的是就在我准备发布叮当的前几天，老的获取音乐地址的方式彻底不能用了，而新的接口批量获取的地址不知道为什么是乱序的，于是我只能在播放每首歌前都调用一下新版的获取地址的  接口，又增加了一点响应时间。
下面这段音频是使用叮当控制音乐播放的演示：

完成了音乐播放功能后，叮当的好玩程度提高了很多。以前要听歌，至少得把电脑或者手机打开。现在只需要喊一声叫叮当播放歌曲就可以了。想换歌、搜索歌曲、调节音量都是说句话就搞定的事情，生活幸福指数大幅提升 _ 。
开源心得
 的正式开源时间是今年的  月  日是的，我专门挑了个好日子，截至本文发表时，该项目的相关数据如下：

 ：，平均一个月  
群用户：
 ：
项目主页 ：
捐赠记录：

虽然数据并不是特别亮眼，不过对于这样的小众项目，我已经比较满意了。下面谈谈个人怎么维护一个开源项目吧。
前期：做好框架
根据二八法则，项目的前期应该要把整个项目期望能达到的  的基本要求完成。一个人的力量毕竟有限，要完成剩余的  的功能可能要耗费非常多的精力，还不如先推出来，形成社区后再去尝试完成。
以  为例，其实智能音箱最重要的几个用途：音乐播放、闹钟提醒和智能家电控制只有音乐播放是我在首次发布的时候提供的因为不能播放在线音乐的智能音箱实在不好意思叫智能音箱。剩下的几个功能都是我提了   大致提供了实现思路，然后由其他的开发者去完成的。
所以，对于一个比较大的项目，更重要的是在这个阶段界定好  的目标，设计好项目的框架，确定 ，写好  和 代码审核、持续集成测试等。
中期：推广  社区搭建
项目发布之后，推广和社区搭建是非常重要的，毕竟直接关系到项目的用户数量和这个项目的生命力。
推广方面，这个阶段我发布了三篇文章：

叮当：一个开源的中文智能音箱项目：介绍这个项目。
手把手教你编写叮当机器人插件：介绍如何开发和贡献技能插件。
使用叮当声控智米电风扇：介绍如何使用叮当控制家电。

这三篇文章推到了开发者头条和树莓派实验室上，都取得了不错的点击率。
另外，如果你跟微博上一些大  关系不错，也可以尝试  他们帮忙推广，当然前提是项目要足够拿得出手才行。
在这个阶段，项目的主页和文档也必须尽快搞好，良好的主页和文档是吸引用户付出精力去尝试你的项目的必要前提。如果像我一样想省点事，可以直接用   生成简单的项目主页，然后直接用   维护文档。
社区的搭建也是非常关键的一环。可以考虑的渠道比如：

即时通讯工具：如果项目主要针对国内用户，可以使用群；如果针对国际用户，可以使用  。
论坛。即时通讯工具的最大问题就是存在时效性。类似的问题在群里刚回答完，新加入的用户又问了一遍，非常崩溃。所以搭建一个论坛，引导用户多去使用论坛交流就可以解决这样的问题。

以  为例，群是很多人决定参与项目之前先加入的社区。刚开始群里才几个人的时候也是非常冷清尴尬，但后面随着人越来越多，群里变得非常热闹甚至我不得不选择上班时间屏蔽该群。而论坛最初是其中一个用户用  搭建的，但邮箱认证没搞定，久而久之论坛里一堆的  。趁着国庆我又用  重新搭了一个，加了严格的审核策略，正好用腾讯云的体验代金券。
市集模式合作阶段：促进合作，保持生命力
一旦用户数量足够多，参与贡献的人就会多了起来。这时候怎么调动大家参与贡献的热情就显得格为重要了。
为了达到这个目的，项目作者本身首先当然要以身作则，体现出充足码力。该你承担的部分积极实现，该   的时候赶紧 ，该发布新版本的时候保证发布。然后在社区里头多多抛出可能的  和实现方案，这时候往往就会有人愿意参与贡献。
我比较喜欢的形式是在项目的   页里提出需求，然后过不久就可以看到有人参与贡献了比如   和 。对于参与贡献的用户，要不吝致谢，让他们的名字出现在  中。
除了这种市集模式的合作方式之外，未来我可能会考虑其他新颖的促进合作的方式，比如在线直播写插件、发布新版本，线下  等。
总结和后续
对于有  能力的  而言，自己动手做一个智能音箱，不仅可以当做业余练手项目，还可以自由地定制硬件模块，并实现自己需要的各种功能，这远比直接购买一个   有趣得多。
更重要的，我更希望能有其他有兴趣的朋友参与进来，一同开发完善这个智能音箱项目。我相信，这种个性化服务的产品本身就应该是完全可定制的。而您的加入可以使  变得更智能！作者：陈诚
团队：腾讯移动品质中心
一、过度渲染概述
、从卡顿说起
通常我们可以从各种渠道听到用户反馈卡顿，究竟是什么用户觉得卡顿呢？因为大多数手机的屏幕刷新频率是，如果在=内没有办法把这一帧的任务执行完毕，就会发生丢帧的现象。丢帧越多，用户感受到的卡顿情况就越严重。
所以，可以看出更新每一帧耗时至关重要，说道每一帧图像的更新过程不得不提到和。负责包括，，，的计算操作，负责栅格化操作。例如显示图片的时候，需要先经过的计算加载到内存中，然后传递给进行渲染。一旦或者的工作超过了规定事件，就会出现卡顿现象。比如：
耗时导致卡顿原因：通常与画面的渲染有关，比如界面存在严重的过度渲染，渲染高清大图等，与 的渲染方法如、、等关联。
的耗时导致卡顿原因：主要是由于线程有耗时较久的操作，比如处理大图片、进行耗时的通信等，自然会拖长线程处理的时间。线程通常会运行以下方法： 渲染相关方法； 布局相关方法：
，；
： ；
；
相关方法， 如：
，，，等。
、再谈过度渲染
过度渲染是指的手机屏幕上的一个像素点在一帧更新时间内被绘制了多次，我们就认为试过绘制了。显然过渡绘制发生时，在层次中处于被遮挡的绘制是不可见的，也是对资源的浪费。用一个简单的例子好比我们刷墙，刷了一层又一层，最终能看到的墙还是最后一次刷上去的样子。
既然过度渲染问题严重，那么如何发现是否有过度渲染存在呢？在安卓系统中开发了查看过度渲染计数的入口，在开发者选项中，打开调试，选择过度渲染计数，屏幕左下方可以看到当前窗口过度渲染计数。如手机管家主页过度渲染计数。
具体的数值代表的意义为：
蓝色：倍过度绘制，；
绿色：倍过度绘制，；
淡红色：倍过度绘制，；
红色：倍或以上过度绘制， 。
二、自动化测试方案
既然能够通过系统设置知道过度渲染次数，测试时候就读取该值，填写报告就完了啊，为何要自动化呢？因为在对进行系统的测试时，会发现页面非常多，如管家一二级页面就多大多个，且集成包，灰度包，正式包，回归包都要进行一次测试，所以进行自动化过度渲染计数读取是有必要的。
、获取页面过度渲染计数
系统方法，读取过度渲染计数。
通过查看安卓的源码，可以知道在
中有一个叫做的内部类，该类还有一个方法如下： 
我们能够该方法，抓取入参并打印到日志，就是我们需要的过度渲染计数。
【难点】
如何内部类的方法：在外部类和内部类之间添加 符号定位内部类；
如何构造一个隐藏的参数类型，如上述：直接使用包名加类名定位该类型。
通过的方法输出的过度渲染计数来源于系统调用，所以什么时候能拿到这个值不受人为控制，使用者只能等待系统日志输出，这也是技术的通病，为此我们引入第二种方法。
反射系统过度渲染计数的类，输出过度渲染计数。
系统在屏幕中绘制过度渲染计数时，是通过绘制到屏幕上上述方法的源码截图看出，所以找到调用绘制方法的类，就可以得到过度渲染计数，同样在代码中调用了绘制的方法，该方法也是过度渲染计数获取的方法。
注：以上方法都是通过系统函数获取过度渲染计数，所以测试时，必须打开设置中的过度渲染计数。
、实现自动化测试
在什么时候读取页面值？
页面从创建到销毁，什么时候页面才是最绘制最稳定的时候呢？我们假设页面上有需要下载的资源，需要耗时才能获取的资源等，所以只有在页面消失前一刻，我们才认为此时页面相对绘制最完整。所以跟进安卓生命周期，我们在时来读取过度渲染计数。
如何实现自动化呢？
因为在调用时候会自动读取过度渲染值，所以我们要做的自动化仅仅是如何在被测页面之间切换，搜集各个页面的过度渲染值，输出报告，所以流程可以归纳为：
三、测试收益
、整个测试方案在手机管家中运行起来，对集成包，灰度包，正式包的一二级页面进行了过度渲染测试，优化后管家正式包一二级页面平均过度渲染计数为，小于管家标准。
报告样例为：
、对手机管家个基础页面监控，到正式版发布时全部页面过度渲染计数都小于。下图为管家部分页面优化前后对比。
管家主界面：
体检优化界面：
个人中心页面：
、问题页面优化前后过度渲染计数对比
获取更多测试干货，关注腾讯移动品质中心微信公众号。岁的程序员是怎样的程序员？成为技术大牛？或者转管理？或者依然是敲代码？
在话题讨论“【有奖讨论】程序员，怎么应对你的三十岁？”中多岁的一个程序员说：“劳资还在一线写代码，一点不觉得丢人，反而越写越轻松，感恩公司老板給我写代码的机会！”
另一个兄弟说：“都说人老会限制思维，行动缓慢，但是人老饱经人世、阅历丰富。”
还有一个网友说：“今年了，没特别感觉有什么太大区别，涉猎的范围广了，接受新的技术比以前还快一些。开发中也能根据经验避免很多坑，质量和速度并没减少。”
是的，岁，依然可以愉快的敲代码。“正如马云谈实体经济的一句话：‘不是实体经济不行了，而是你们家的实体经济不行了！’ 同理，不是岁的程序员不行了，而是你不行了。”
鉴于中国互联网及软件行业的发展趋势以及中国人口发展趋势，未来，会有越来越多的中老年程序员敲代码。“都说国外的技术人员的发展都呈一个型 以后管理和技术都存在中国目前的情况是一个型。个人观点中国的技术发展比国外要迟一点我觉得慢慢的也是往型上走的”。
现在，中国年轻人多，用不着老年人敲代码；美国年轻人不喜欢敲代码，所以不得不用老年人继续敲代码。除了软件行业，再比如说：美国飞机上的空妈，商店里的销售阿姨。中国，迟早也会这样的，甚至，由于之前计划生育的管控，会比美国更加明显。
当然了，转管理也是一个出路，没错，仅仅是个“出路”。
有网友一针见血的指出：
“岁程序员转行干管理，这是在给你的下半场找出路，不是在找目标。试想你已经用年做程序员还是想着转行，你又能有多大机会在管理的岗位上达到你期望的“成功”呢？如果没有特别的机会，你还是一个普通的“管理”者，“管理”着一群普通的年轻程序员，由于脱离了一线研发，不会有更多的机会用实践和代码磨砺你的头脑，更像是一个会议召集人或者里程碑撰写人来度过下半场。”
另外，笔者认为：不要以为做管理就那么简单，做管理比做技术要难得多！今天，之所以有这么多的程序员可以转管理，那是因为整个行业的爆发式增长为大家提供了管理岗位的机会。然而，这其中，有多少被提拔出来做管理的程序员，其实对管理一窍不通，并且经过了两年的实战之后依然对管理一窍不通？笔者接触过不少技术大牛，转管理岗位做了两年之后，主动申请放弃管理岗位重新做技术写代码。
至于是否能够成为技术大牛，取决于自己平时技术的积累、对新技术的热情、对行业发展的关注、。。。。。。
许多年轻的程序员有这样的想法，包括我自己曾经的某个下属：“如果到三十来岁转不了管理，那我就去一个比较好的地，小区啊或者学校周围，开一家小饭馆，学学做菜，然后分享手艺。”
我当时对我的下属泼冷水道：“如果你抱持这样的心态，到最后，你会发现自己什么都不适合，什么都做不好。”
“三十来岁转不了管理”，为什么转不了？如果自己坐等，团队问题不关注，管理知识不学习，凭什么让你转管理？
就算是开一家小饭馆，你以为随随便便就能做出吸引我们这帮苦逼程序员每天都会进来吃的蛋炒饭么？
任何事情都讲究个专业化，无论自己的主动规划也好，无论自己的被动选择也好，只要能够主动专研，发现问题、研究问题、解决问题，一步一步，成为某个领域的专家只是时间问题。
如果自己不钻研，只是坐等，那就只能看天了！
乔吉拉德岁才开始卖汽车，然后卖到全世界最牛；王德顺岁才开始真正的事业起步。
有些人，不到岁已经老了，坐在那里等着命运的降临；有些人，岁也不会老，依然主动与命运拼搏，比如褚时健。
苍天对每个人都不同，但，我们自己有选择是否老去以及何时老去的权力。
附：【有奖讨论】程序员，怎么应对你的三十岁 获奖名单
黑轴机械键盘
翟志军
腾讯云充电宝
腾讯云用户钱进
腾讯云元代金券
第楼：陈涛第楼：腾讯云用户第楼：刘卓夫工作中经常使用到，为对有个比较深刻的了解，重新拾起学习的任务。在看书的同时，记录下思考的过程，也记录下重要的知识点。
从数据的存储开始
计算机中的数据都存储在内存中，这就离不开各种数据类型在内存中的编码方式。从最简单的整型开始聊聊，整型数据在内存是如何编码以及必须要的坑。
整型中的有符号以及无符号
无符号即数据不能表示负数。有符号即数据的最高位用来表示正负。
如十六位机器中：   = 十六进制编码为：二进制编码为： 
  = 十六进制编码为：二进制编码为： 
如何表达负数有符号数编码
负数的编码可由正数的补码反码加一可以得到如得到  的编码。的正数为 ， 的补码为   ，反码   加上 
使用整型的建议
注意有无符号数据比较
上面提及到，有无符号编码的格式比较重要的一个区别便是其最高位是否使用来表示负数。但在语言中，两数进行比较时，并不会严格的检查数据的类型，而是直接对比二进制编码中数据的大小。在有符号中的负数经常会表示为一个非常大的数。例如，下面代码中，结果会输出与异常的 “   ”所以，千万要避免有无符号数据大小的直接对比。
这是因为位 的二进制编码为      的二进制编码位     的值在比较中远远大于。
   =
  = 
    {
        \
}{
        \
}
正确的做法是，在有无符号整型数据比较时，强制转换成有符号数
     =
    = 
      {
          \
  }{
          \
  }
整型数据边界问题
数据所能代表的范围有限的，当使用到数据时，需考虑到边界值。有无符号整型超过最大值时，会回到，继续累加。在使用时也需要注意。
例如下面例子：此时为  的最大值，二进制编码为 ，当加一时，发生回绕，二进制编码变为 此时输出  ，这种会让人十分疑惑的问题。
   = 
 = 
    {
      
}{
      
}
同样情况也会发生在有符号整型数据中
浮点数在计算机中的编码
浮点数其实就是科学计数法在计算机中的表现形式。只是在日常的使用场景中使用的是十进制，需要转换成计算机认识的科学计数法的二进制表示形式。科学计数法中由符号位指数位 有效数字位三部分组成。三者就可以表达



符号位
指数位
有效数字位










如十进制 ：十进制科学计数法  二进制科学计数法  
走到这便会发现一个问题，十进制数转换到二进制时，小数部分在使用二进制数表达时，很多情况下并不能精确表示。这也浅出一个编程中经常遇到的问题，浮点数为什么很多情况下并不是精确的
浮点数为什么是不精确的？
最直接的原因，便是十进制数的小数位，在小数最后一位非时，并不能精确的转换成二进数。如。 转换成二进制数
整数部分
 =        = 
小数部分
     = 
 转换成二进制  
但是对于小数最后一位非的情况，如 
整数部分
  =        = 
小数部分  使用转换公式进行计算
   =  取整数位  
   =   取整数位  
   =   取整数位 
   =   取整数位 
   =  取整数位  
   =   取整数位  

最后发现，根据转换公式，其实无法得到一个精确值，只能获得一个大约的值如 ，也就是说，在计算机保持的值中，永远也不是个精确的值
例如，下面不会得到，而是接近的
   = 
   = 
  =  \   = 
但对于最后一位小数位的浮点数而言，二进制精度会得以保证如下例中输出的结果为  = 
      = 
      = 
     =  \   = 
在实际运用中，对于浮点数的比较是否相同，我们只能约定一个范围来进行判断
      = 
            {
          
    }作者：

 是一个提供数据监视的，在  中已经可以使用。是   的一个提案规范，官方建议的是“谨慎使用”级别，但是个人认为这个非常有用，例如可以对现在流行的框架作一些简化和优化。虽然标准还没定，但是标准往往是滞后于实现的，只要是有用的东西，肯定会有越来越多的人去使用，越来越多的引擎会支持，最终促使标准的生成。
可以做什么
从字面意思就可以知道，这玩意儿就是用来做观察者模式之类的东东。
简单地说，就是观察一个对象的变化，在被观察者变化时作出一些回调。
实际应用中，可以优化数据模型和网页试图的双向绑定。
语法
语法很简单：
 


就是你要监听的数据模型例如一个接口对应的数据

就是数据模型变化后触发的回调例如网页视图的变化
函数的参数形式

 被修改的属性名称
 修改后该对象的值
 表示对该对象做了何种类型的修改，可能的值为    
 对象修改前的值。该值只在与有效

实例：
感兴趣可以跑一下下面简单的代码，你就知道各个参数的作用了
 

    
         =
    
    
        
              = {}
               {
                  {
                    变化的属性：    
                    变化的类型：   
                    旧值：    
                    新值：    
                }
            }
        
    

实现
当然这里不是要取代框架，只是想通过来实现一些性能上的优化。
在中有一个叫“脏值检查”的东西，大概的原理就是只要任何时候数据发生了变化，这个库都会通过一个或者 去检查变化是否发生了。在中，一个循环意味着所有所有被监视的表达式都会被循环一遍以便查看其中是否有变化发生。
用以下代码，大大优化了脏值检查
 

    
         =
         
    
    
         =
             = = =名字
             = = =年龄
        

        
              = 
              = {}

               {
                   {
                      {
                          = 
                         = 
                    }
                }

                  {
                       {
                          = 
                          ==  {
                            
                        }
                          = 
                         = 
                    }
                }
            }

             
        
    

脏值检查在任何数据可能发生变化的时候都必须要运行。这很明显并不是一个非常鲁棒的方法，并且任何实现脏值检查的途径都是有缺陷的例如，在轮询中进行检查可能会造成视觉上的假象以及涉及到代码的紊乱情况。脏值检查也需要注册一个全局的观察者，这很可能会造成内存泄漏，而会避免这一点。
参考


原文链接：


相关推荐一个只有行代码的流程框架【腾讯云的种玩法】项目部署指南作者： 

主要的计算环节
大象为什么跳不高跑不快？因为它很重。为什么访问比较慢为什么消耗资源呢？同样也是因为它很重。的重，体现在如下几方面：
、大量的计算。的每一个字节都涉及到较为复杂的计算。即使是，也需要在握手完成时做校验。
、协议的封装和解析。所有数据都是按照 格式进行封装和解析的。
、协议的网络交互。从的握手过程可以看出，即使不需要进行任何计算，的握手也需要至少个  以上的网络交互。
其中第和第点不是本文重点。本文侧重为大家分析计算方面的原理，计算性能的测试和优化。
总体来说，主要有如下计算环节：
、非对称密钥交换。比如  这类算法的主要作用就是根据客户端和服务端不对称的信息，经过高强度的密钥生成算法，生成对称密钥，用于加解密后续应用消息。
、对称加解密。服务端使用密钥对响应内容进行加密，客户端使用相同的密钥对加密内容进行解密，反之亦然。
、消息一致性验证。每一段加密的内容都会附加一个消息，即消息认证码。简单地说就是对内容进行的安全哈希计算，接收方需要校验码。
、证书签名校验。这个阶段主要发生在客户端校验服务端证书身份时，需要对证书签名进行校验，确保证书的真实性。
上述环节的简单图示如下：

那上述阶段为什么需要消耗呢？简单介绍一下计算原理及算法分析。
计算原理及算法分析
上一节提到四个主要的计算环节，事实上每个环节都需要用到指定的算法。下面结合腾讯现在主要使用到的证书签名和密码套件分别介绍一下。什么是密码套件 ？它其实是一套算法的统称，包括密钥交换算法、消息认证码算法、内容加密算法和伪随机数算法。统计线上的 可以得出一个大概的使用情况，如下表所示：

证书签名算法
证书签名算法主要用于身份校验，现在的签名算法主要是安全哈希系列，目前算法已经不安全，不推荐使用，但由于部分比较老的操作系统只支持算法，所以目前线上使用到的签名算法主要是和少量的。
和算法最主要的操作还是位之间的运算，包括  ，然后进行最多不超过轮的迭代。所以从算法原理来看，安全哈希的计算速度应该会比较快。

密钥交换算法
密钥交换就是指客户端和服务端通过交换各自的信息完成共同密钥的生成。目前线上使用到的主要密钥交换算法主要是如下三类：

三类算法最主要的数据运算公式如下：
的安全性建立在大数因子分解很困难的基础上。它的核心数学运算公式如下：

的安全性建立在离散对数求解比较困难的基础上，它的核心数学运算公式如下：

是在椭圆曲线有限域上实现的算法，具备同样的安全性，它的核心数学运算公式如下：

分析上述运算方程有什么意义呢？
、可以看出和的主要计算都是模幂计算。模幂计算通常进行的轮次比较多，计算量比较大，对于是一个很大的负担。
、椭圆曲线实际上是一个集合，并且定义了一套计算规则。使用较小的数字就能实现同样的安全强度。如下表所示，使用位长度的密钥就能实现位长度的安全性。

对称加密算法对称加密算法就是使用相同的密钥对数据进行加解密，常用的对称加密算法如下：

由于对称加密算法最主要的数学运算是，虽然不同的模式对速度有一定的影响，但是由于密钥长度短，同时计算过程简单，对称加密的效率非常高。
消息认证码算法
消息认证码算法和证书签名算法的核心操作有点类似，主要是基于安全哈希函数，比如或者。所以这里就不做多余介绍。
性能测试
从上一章的数学原理分析可以得出初步的性能结论，类运算应该是最消耗资源的。但是纯数学分析还不能完全代表真正的软件性能。本章我们使用三种方式测试一下的性能。
 
提供了一个速度测试的工具： 。顾名思义，它的功能就是测试支持的全部算法的速度。
 测试的基本原理是在指定时间内比如或者，循环调用指定的密码算法，最后的运算次数就代表了该算法的性能。测试平台的信息如下：

由于线上业务单个请求的平均大小约为字节，所以下表统计了加密和安全哈希算法每秒能够处理的字节数以及处理字节需要的用户时间。

可以看出，数据加解密和安全哈希的操作时间基本都是微秒级别以下。其中耗时最多的是，需要微秒。下表统计了签名、校验及椭圆曲线的操作时间：

可以看出位的签名操作速度很慢，单次操作需要耗时毫秒，的操作速度要快一些，大概需要毫秒。椭圆曲线的操作时间统计如下：

椭圆曲线的操作曲线基点选取，耗时大概毫秒。
运行时间分析
 只能统计单个算法的性能和执行时间，但这个时间不能代表线上业务真实运行需要消耗的时间，原因是：
、一次完整请求涉及到不同算法的组合，单个算法无法反映整体时间。
、协议交互时需要协议解析，网络交互，异步异常处理，这里肯定会有一些额外的性能损耗。
、实现协议栈时需要调用多个应用层函数和系统调用，也会有一定的开销。
所以需要进一步统计真实的运行时间，主要是统计处理各个主要环节的消耗时间。限于篇幅，这里只介绍_密钥交换算法的性能，具体的统计函数和时序如下：

从上图所示的数据能够非常明显地看到，消耗了毫秒，要显著超过其他消息的耗时。那消息为什么消耗时间呢？进一步分析如下：

 事件及火焰图分析
是内核提供的一个性能分析工具。它的主要功能是能够周期性地采集各个函数的周期数，从而反映性能瓶颈及热点代码。火焰图能更加形象直观地展示 记录下来的事件。通过 纪录压力测试过程中的 事件，分别绘制_和密钥交换算法下的火焰图，如下所示：

火焰图是格式的向量图，由于事件数太多，截图无法反映详细的事件和函数关系图。这里简单的概括一下： 和计算相关的事件占全部采样约，相关的计算占比约。

简单概括一下：使用密钥交换时，相关的事件采样占整体采样的比例约。
性能测试的结论
性能测试的最终目的是为了性能优化。根据之前的测试数据，的计算性能优化思路可以总结如下：
、完全握手对性能的影响非常大，性能降低至普通性能的 以下。应该尽量提升 及 ，减少完全握手的发生。
、密钥交换过程中的算法对性能的影响非常大，一次正常交互过程，计算过程需要消耗整体性能的左右。也就是说，如果能够提升的性能，那么整体性能将最多提升倍。
、曲线相关的计算约占整体计算量的，对整体性能的影响不大。但如果计算优化好了，的性能将逐渐成为瓶颈。
、对称加解密及计算对性能影响很小微秒级别，暂时不需要考虑优化。
让大象起舞—计算性能优化
异步代理计算
从上一章的分析可以知道，协议中最消耗计算资源的就是密钥交换过程中的计算。也是我们优化的最主要对象。如何优化呢？思路如下：
、算法分离。将最消耗计算的过程分离出来，释放本地，提升整体吞吐性能。
、并行计算。使用硬件加速卡或者空闲并行计算，提升计算效率。
、异步代理。算法分离和计算的过程是异步的，不需要同步等待加速计算的结果返回。
下面详细介绍一下上述步骤：
【算法分离】此的核心思想是：分析加密算法的完整过程，将最消耗的计算过程剥离出来，避免在本地上进行同步计算。
需要分离哪些算法呢？由于我们现在的证书主要使用签名，暂时没有签名证书，所以当前设计只针对签名证书。签名证书最常用的密钥交换算法是_，_和，所以我们需要重点解决的就是这三个算法，如下图示：

由于_算法性能较差，所以优先推荐使用_和密钥交换算法。下面详细描述一下两个算法的具体分离过程。【_密钥交换算法分离】完全握手过程中，_涉及到的最消耗的握手消息为，它在整个握手过程中的位置如下：

其中绿色框标示的__并不是一个握手消息，它表示的是生成 的过程，主要是调用完成计算。红色标示的消息需要大量的计算。那消息为什么需要大量的计算？它需要处理哪些内容呢？主要是如下两步：
、选择椭圆曲线密码的曲线类型、基点、曲线系数等参数，并根据这些参数生成公钥。
、对曲线参数和公钥进行签名。
由之前的分析得知，这里的签名过程需要使用位长度的私钥对数据进行加密，非常消耗。
【密钥交换算法分离】密钥交换算法的过程相对简单，因为没有参数及公钥生成的过程。根据描述，客户端使用公钥对内容进行加密，服务端需要使用私钥解密 ，从而生成最终的 。上述过程图示如下：

其中__主要分为如下两步：
、私钥私钥解密 。
、根据 和其他参数生成 。这一步同样是调用完成计算。
同样地根据之前的分析，解密相比计算要消耗更多的计算量。
并行计算
为了提升单位时间内处理的性能，有两个思路：
、减少单个请求的计算时间。
、提升请求并发计算能力。即能够同时处理更多个请求。
减少单个请求的计算时间通过采用更高频率和性能的或者专用硬件加速卡的方案能够解决，本文不多做介绍。提升请求并发计算能力是指同一时刻使用多个或者多个硬件加速卡方案实现性能的提升。模型如下：

显然，如果使用更多个数的和硬件加速单元，并行计算能力就得到了显著提升。同样单位时间内，能够处理的请求数变成了：  。相比串行计算，性能提升了倍。
异步请求
的当前进程必须等待完成或者 的处理后才能返回进行其他工作。如下图所示：

上图只是简单说明了签名的同步计算过程，事实上解密的计算过程类似。假设请求需要进行签名_操作，必须等待上图中 到 共个步骤全部完成才能处理下一个请求。飘红标示的__是指大数的模幂计算，是的核心运算过程，由于指数非常大，所以它是个非常消耗的运算。
同步请求的弊端是：
、由于该过程需要消耗大量的，整体性能受到严重制约。
、除非同步计算的能力非常强，否则即使将过程分离到其他硬件或者完成，由于进程间或者网络间的开销，同步过程也会严重制约的整体性能。所以上述计算过程需要异步进行，即在进行高强度计算时，比如处理或者 消息，当前进程无需等待计算结果的返回，可以马上执行其他工作。异步过程如下图所示：
、接收到请求后，调用_。
、_此时会调用__，然后直接返回，不需等待的签名结果。
、此时可以处理其他请求。
、__是签名的核心函数，主要是使用私钥对哈希值进行加密。它的最主要计算过程还是大数的模幂计算。
、最消耗的计算由于已经被分离到其他或者硬件加速卡，所以不会消耗本地，同时由于这个过程是异步的，也不会阻塞上层的。

异步代理计算的工程实现
难点
工程实现的难点主要体现在对和核心代码的掌控上。可以概括成如下几点：
、需要学习和理解的知识量大。包含 到协议，体系，标准，标准，标准，光的阅读涉及至少个以上，常用的比如，等。
、代码量大、旧、乱、深。
大。代码行数超过万行。因为要实现不同协议版本，不同算法组合，还要跨平台，支持各种硬件，所以代码量非常庞大。
旧。有很多历史遗留的无用代码，比如一些过时的算法、系统及加速硬件。
乱。风格不良不统一，充斥着大量宏定义，宏开关，缺少注释等。
深。由于涉及到版本和算法很多，本身就比较难懂，又进行了一系列的高层抽象和封装，比如，，系列等。
提到了这么多不好的地方，网上甚至有一些文章公开嘲笑甚至辱骂，但是在我的心里却一直认为，一份开源免费却守护着虚拟世界安全的代码，值得每一个人尊敬和崇拜。
、虽然非常重要，但是互联网上关于和代码工程方面有深度有价值的参考资料几乎为零。
、需要修改事件框架实现完全握手的优化。虽然代码优良，参考资料也多，但是代码有很多细节设计得比较巧妙，修改事件框架很容易踩坑。
计算架构的变化
计算方式的变化必然会导致计算架构的变化。其中现在默认的广泛使用的方式又叫本机同步计算架构。
【本机同步计算架构】这里的同步是指上层应用比如必须等待执行完计算后才能返回执行其他工作。这里需要注意的是，即使将同步模型的换成硬件加速卡，对性能的提升也非常有限，不到。

【异步代理计算架构】改造后的架构如下：

异步代理计算架构的特点将最消耗性能的计算分离出来，使用并行计算能力更强的方案替代本机完成计算，同时整个过程是异步的，上层应用程序不需要等待计算结果的返回就能接收其他请求。
异步代理性能优化结论
最终通过异步代理计算， _完全握手性能提升了倍，由提升到了。
对称加解密的优化
虽然之前性能分析里提到了相比非对称密钥交换算法来讲，对称加密算法的性能非常卓越好到个数量级，但是如果应用层传输内容较大的话，特别是移动端的计算能力较弱，对称加密算法对性能的影响也不容忽视。如何优化呢？通过异步代理的方式显然不可能。原因是：会极大降低用户访问速度。由于应用层的每一个字节都需要对称加解密，使用异步的方式实现会严重降低加解密的实时性。
那有没有同步的优化方式呢？有。类似硬件加速卡，针对算法实现硬件加速，并将它集成到了指令里。
指令
是推出的针对对称加密算法进行优化的一系列指令，通过硬件计算实现计算速度的提升。如何测试的性能呢？通过环境变量

对性能的提升约， 由提升到。这里需要注意的是，如果需要单独使用的进行对称加解密，最好使用  ，这样才会默认开启指令。
、
是由 发明，并且由推出的一种带身份认证的对称加密算法。其中是指对称加密算法，指身份认证算法。这个算法是对没有硬件加速功能的移动平台的补充，比如芯片。从公布的数据来看，能够提升以上的加解密性能，节省移动端耗电量。当然，如果手机端支持指令的话，就没有优势了。
我们最开始选用的一个重要原因也是它支持，虽然暂时不支持，不过最近发布的版本应该马上就会支持了。
、 
最消耗性能的阶段就是完全握手，不管是对用户的访问速度还是资源消耗，避免完全握手的发生都能够极大地提升性能。协议目前提供两种机制来实现简化握手，避免完全握手的发生：
 
引入了 机制，如果客户端使用的协议版本大于全部浏览器都支持，包括，那么端在收到 消息时会生成一个字节长度的以后是到字节长度，保存在缓存并且将生成的 通过 消息发送给用户。客户端在后续的握手请求中通过 消息发送 ，端获取到后会从本地或者集群缓存中查找，如果查找命中，表明这个 是可以信任的，能够复用。握手提前完成，不需要继续处理完全握手需要的密钥交换等消耗资源的步骤，同时节省了一个。
【分布式 的应用】 支持得非常广泛。但目前只支持内置缓存及单机进程间共享的缓存，在多服务器的接入架构下，单机的缓存几乎是无效的。
针对这种场景，支持四层会话保持，这样在会话保持期间内的都会落到相同的机器，显著地提升了 的命中率。
 
  是一种不需要端保存状态信息的恢复机制。客户端在 消息里发送   表示支持 机制，服务端的在 里也会发送一条   消息表示支持。这样在完全握手快要结束时，会发送  消息生成一个新的。客户端在后续的请求过程中会在 包里携带这个，如果能够正确解密这个，标明能够复用。握手完成，同时发送  更新。即每次发送请求的都不同。
【分布式 的应用】在多个接入的环境下，同样存在不同用户的 无法被正确处理的问题。为了解决这个问题，配置了全局的  ，即针对全部的，使用相同的来进行加解密。相同客户端的 ，不管下次落到哪台，都能被正确处理，实现简化握手。

结论
、提升 比率，尽量实现分布式 及 ，减少完全握手的发生。不仅节省网络，提升用户访问速度，也避免了非对称密钥交换的发生，减少了的消耗。、通过异步代理完成的私钥计算。完全握手性能由提升到了提升了倍。节省了接入机器成本，提升了业务的活动运营及防攻击能力。、使用性能更高，更安全的对称加密算法，，、开启对称算法加速指令。序言
年腾讯架构平台部相继推出了两朵云  云存储和云接入，在公司内外打造了良好的口碑同时，资源量也得到了增加，依托于部门海量的存储资源，建设了 弹性计算平台。截至目前，弹性平台运营的计算力，服务了公司图片压缩、视频转码、离线计算和计算等多个计算场景，前不久平台服务的 绝艺围棋获得了第十届比赛的冠军。平台强大的计算并非直购设备堆积，而是未增加任何预算成本，默默挖矿耕耘，不断优化逻辑细节所得。
平台演变
年图片上传下载量剧增，为扛住海量图片压缩，平台快速上线直接混部策略，存储和压缩同机部署，虽然服务了业务的增长，但运营困难，资源抢占的问题日显，给运维带来了繁巨的工作量，为解决资源抢占等问题，平台启动重构，取消直接混部，改用虚拟机，平台维护虚拟机生命周期，截至年，虽稳定服务了图片压缩、视频转码，但资源静态不可弹性调度，利用率低。年被引爆，大数据计算更是指数级增长，虚拟机的静态资源策略已不适用，需要一个弹性可调度平台盘活部门整体和公司闲置资源的计算力，弹性计算平台应运而生。
整体设计
弹性平台对外提供名字化服务供用户接入，并在服务中集成了负载均衡、容灾逻辑，用户无需自主设计架构，即可享受到集群化服务。针对某些已有管理系统的业务，平台也提供了资源租赁策略，用户无需改动，便可快速接入。平台借助技术，并解决了负载的监控调度、资源的弹性伸缩和分布式镜像管理等方面的问题。
．监控调度：秒级反馈，预先调度
监控：打造自主的 监控指标，结合定制化内核优先级策略，当高优先级的容器指令延时增加，自动调节低优先级容器的值，保障业务服务正常。若低优先级的值低于阈值，会触发母机替换，高优先级容器可全占母机。内存：_预先调度和优先级兜底；借助内核_技术，当_ 触发，依据容器的优先级，调度低优先级容器到其他母机，若出现调度不及时触发，则会按照对优先级配置，将低优先级的容器快速回收，释放内存；然后低优先级容器会被调度到其他容器，继续服务。监控：引入 内核的限速方案，对每个上架的容器配置带宽限制， 限制配额。
．弹性伸缩：水平伸缩和垂直伸缩
水平伸缩：基于业务负载状况，业务低峰期自动缩减容器量，高峰期自动扩容，业务上削峰填谷，资源所见即所得，维持资源高使用率的同时，也缓解了业务突发运维扩容的压力。垂直伸缩：针对有状态的逻辑，每次的水平伸缩都会打乱原路由表，甚至会导致并发写脏数据的问题，平台使用单机资源垂直伸缩方案，在维护原路由信息的前提下，对单机资源做加减容器操作，盘活不可伸缩的母机低峰期的计算资源。
．镜像服务：镜像和配置分离
镜像分发：借助部门的云存储平台搭建的分布式镜像服务，实现了标准镜像预先分发，资源服务秒级上线。配置隔离：一个镜像，多套配置，配置变更不会变动镜像，尽可能的减少对业务影响
价值依归
．服务场景
平台当前服务多个业务，根据业务场景和计算的实时性划分了种类型，每种类型都有相应的模型，作为监控调度、资源抢占的服务基础。

弹性平台优先保证在线服务型和在线计算型业务，尤其在节假日高峰期，平台会自动腾挪离线类型业务资源服务用户请求；针对离线计算业务，平台采用核时量化，实时水平和垂直伸缩业务计算力，资源上互补在线型业务。
．提升
基于弹性伸缩的功能，平台维持资源使用率稳定的前提下，资源量可随着请求变化波动，摒弃了资源量恒定状态中，资源使用率随请求波峰波谷波动的使用方式；后者的资源量因业务峰值而定，使用率较前者低许多。当前平台整体均值使用率全天小时求平均，相比去年提升显著。

展望
弹性计算平台年底将全面服务计算、游戏类场景模拟等新兴的计算需求，资源调度可定制化，持续提升使用率，并且以弹性平台为基础，搭建云函数计算平台、函数计算，在云计算领域继续挖矿耕耘。最近看《机器学习系统设计》前两章。学到了一些用  进行数据可视化的方法。在这里整理一下。
声明：由于本文的代码大部分是参考书中的例子，所以不提供完整代码，只提供示例片段，也就是只能看出某一部分用法，感兴趣的需要在自己的数据上学习测试。
最开始，当然还是要导入我们需要的包：
  = 
     
   _
   
 

 画散点图
画散点图用 。画连续曲线在下一个例子中可以看到，用到了 。
， 可以自定义  轴刻度的显示，第一个参数表示的是第二个参数  显示的位置 。
= 可以自动调整图像显示的最佳化比例 。

 


          
=



画出散点图如下：

 多项式拟合并画出拟合曲线
 多项式拟合
 = 
 = 

 = 
==
  函数的阶数
=  = 


效果图：

 画多个子图
这里用到的是  的 _鸢尾花数据集。
此数据集包含四列，分别是鸢尾花的四个特征：

  ——花萼长度
  ——花萼宽度
  ——花瓣长度
  ——花瓣宽度

这里首先对数据进行一定的处理，主要就是对特征名称进行两两排列组合，然后任两个特征一个一个做  轴另一个做  轴进行画图。
  = 
     
   _
   
 

 = _

_


 = 
_ = _
 = 
 = _


_

这里有一个排列组合参考代码，最后是取出了两两组合的情况。
排列组合的结果是 __ 包含了排列组合的所有情况，它的每一个元素包含了一个排列组合的所有情况，比如第一个元素包含了所有单个元素排列组合的情况，第二个元素包含了所有的两两组合的情况所以这里取出了第二个元素，也就是所有的两两组合的情况
__ = 
排列组合
   _
     = _
    __

__
   __
    

下面是在  循环里画多个子图的方法。对我来说，这里需要学习的有不少。比如

   __ 这一句老是记不住。
比如从列表中取出某元素所在的索引的方法： = _，也即  =  的形式。
比如  循环中画子图的方法：
比如  循环的下面这用法：   


   __
     = _
     = _
    
               
        ======
        
        
        
        
        
        _      


这里的可视化效果如下：

 画水平线和垂直线
比如在上面最后一幅图中，找到了一种方法可以把三种鸢尾花分出来，这是我们需要画出模型一条直线。这个时候怎么画呢？
下面需要注意的就是 __ 和 __ 的用法。

           
    ======
    _
    _
     
     
        
    = = = 
    = = = 


此时可视化效果如下：

 动态画图
 打开交互模式。 不再阻塞程序运行。
注意  的用法。
   


   
     = 
    
     
    

可视化效果：


文章首发公众号：  在众多技术中，绝对是当红炸子鸡。这年头，如果你不懂一点容器，不学一些，还怎么出去跟人炫耀技术？
 也是云计算技术中较为热门的一种，腾讯云技术社区一直有持续分享相关的干货。以下就是目前社区的一些优质内容，能够助你深入浅出地了解  技术。
快速上手
快速入门以及安装使用
摘要：通过内核虚拟化技术及等来提供容器的资源隔离与安全保障等，由于通过操作系统层的虚拟化实现隔离，所以容器在运行时，不需要类似虚拟机额外的操作系统开销，提供资源利用率。本文介绍了许多的基础操作。
 使用指南 一—— 基本操作 使用指南 二—— 搭建本地仓库 使用指南 三—— 网络配置 使用指南 四—— 数据卷的使用 使用指南 五——  详解 使用指南 六—— 使用  部署  容器栈
上面这六篇文章，涵盖了从基础操作到部署等一系列内容，读完这六篇，相信你会对有一个非常全面的了解。
在腾讯云上使用
下面是一些在腾讯云生产环境中体验、使用的教程，可以让你更好地理解的不同使用场景。
在腾讯云服务器上体验
利用  快速搭建  仓库  与代码审阅  平台
在  上使用腾讯云  镜像加速构建
 部署
此外，腾讯云还推出了容器服务，可以在托管的云服务器实例集群上轻松运行应用程序。使用该服务，您将无需安装、运维、扩展您的集群管理基础设施，只需进行简单的调用，便可启动和停止应用程序，查询集群的完整状态，以及使用各种云服务。作者：

要做什么
假设你有一个博客，有一台网站服务器或者很多台作负载均衡的服务器，当你的博客要升级时，你可能要在你自己的电脑上写好代码可能包括本地调试好，然后提交到或，然后在每个服务器中一份代码并重启服务器应用……
这里要介绍的是一种直接在本地提交代码，即可自动完成服务器部署的方法。
怎么做
假设你有网站主机后面统称线上机：



并且确保你的本地开发机器后面统称开发机与线上机均已安装好不是
  线上机增加三个文件夹：
 
 
 
其中  作为代码仓库，即开发机的代码统一提交到这里存放。
 和  是开发机上的部署目录，比如测试目录和正式线上内容目录。
  线上机  仓库初始化：
 
  
 
  
  在  文件中写入以下内容：


_=
_=

 ={_}  
 ={_}  

 ={_}  
 ={_}  
  本地机增加文件夹并克隆远程  仓库：
 
 
 
    
注：此处会要求输入线上机器的登陆密码  
最终效果
本地机目录可以自由增删文件，并提交到线上机  仓库。
例如：
 
  
     
   
此步操作完成后，查看线上机中第一步建立的那几个目录、、，是不是多了一个你刚刚在本地创建的文件 ？
还有一步
如果你的网站比较简单，到这一步就已经是完事了。
试想上面的例子，假如你的网站是静态网站，在、这两个文件夹中部署了同样的网站，一个用于测试，一个是真实环境，这样你就已经可以直接提交文件就完成上线了，是不是挺爽的？
事实上，通过这种方式，实际上就成了你的一个服务器，上面第三步编辑的就是一个钩子文件，实际上就是一个可执行的脚本，当你在你的本地提交代码 时，服务器收到你的文件提交同时会触发这个钩子的动作，也就是执行这个脚本。说到这里，接下来这个脚本能做什么，重启服务器？触发构建？把文件部署到别的机器上……尽情地发挥你的想象吧！

原文链接：


相关推荐如何写好     和工作流规范高水平的应用程序容错能力，无缝负载均衡容量 算法

算法的详细介绍见文章：深度强化学习    初探
 实现  及效果
 状态空间的表示 
使用三维数组来表示   ___

 离下个管道竖直方向的距离
 离下个管道水平方向的距离
 可能的操作：点击屏幕或者不点击


 奖励

 移动后小鸟还活着
 穿过了柱子小鸟还活着
， 小鸟死了

 学习
表初始化为
步骤一：观察所处的状态，并执行最大化预期奖励的操作。 执行游戏帧播放循环。现在，处于下一个状态’
步骤二：观察新状态’与其相关的奖励，按照中的规则来获取值
步骤三：根据算法更新数组
 ←   α   γ’  
训练大约个小时，小鸟已经足够“智能”，可以一口气穿过个管道了。

  算法的局限性
对于，算法通过训练可以实现一个效果还不错的。主要是因为中的状态表比较小， 决定小鸟”跳”或者“不跳”，仅仅取决于与下一个管道之间的相对距离。在本例代码中，状态表 ______的大小为：    = 。 所以训练一个小时，就可以收到不错的效果了。对于稍微复杂些的游戏， 算法就显得力不从心了，如下面的游戏：

我们看看状态来如何表示：决定我方飞机飞行轨迹的因素有：屏幕中全部子弹的相对位置、全部道具的相对位置、以及之前几幅画面中的子弹和道具。状态表的大小可用如下公式估算：

其中表示屏幕像素宽度，表示屏幕像素高度， 表示决定飞机动作的物品个数，表示决定飞机动作的最近几幅画面。可以看到，此例中，状态表太大，并且维度很难降低。
如何用有限的内存空间来表示近乎无穷的状态呢？答案是： 用函数拟合。 没错， 这就是 深度神经网络  最有名的实现之一要属了，参见    深度强化学习    初探背景
前面一篇文章《 入门：求  元一次方程》在已知表达式形式的情况下，获得了各个参数的值，但是现实中大部分情况是不能简单使用  元一次方程这样的公式表达的，神经网络的出现，给这类问题提供了一个很好的解决方法。本文继续给出一个简单的例子，使用 ，利用神经网络对  元一次方程进行拟合。 关于神经网络的简单入门介绍，可以参考  这篇文章。
如何实现
在使用  之前，还是要  相关的包：

=
   
   

_              日志级别设置成 ，避免干扰
_=                    打印内容不限制长度
首先回顾一下前面的功能，我们有一个函数，它有  个输入值，一个输出值，这里使用 _ 表示输入值的个数，当前它的值为 ：
_ =          变量数
我们需要一个已知的函数来生成数据，根据函数 =， 是这个函数的参数，令它为大小为 _的矩阵，这里我随便填了  个  到  的数字：   
要求的值
_ = =_
 _
对于训练的输入和输出值，使用  进行表示：
 是输入量，对应 _，用于训练输入，在训练过程中，由外部提供，因此是  类型
 = =_
 = =
而之前的 ，因为我们使用神经网络表示了，因此不需要了，我们甚至不需要知道这个函数一定是个  元一次方程。接下来就是重点部分，构造神经网络。 提供了很多高级 ，这个问题是一个回归问题，回归问题，就是通过一定的值，预测值的问题，这个和前篇的分类是不同的问题。我们使用  来构造神经网络，首先需要告诉它输入有哪些参数，叫做特征列，因为我们只有一个  输入，它是一个大小为 _的矩阵，因此定义一个输入 ：
_ = __
使用上面构造的特征列构造一个  的实例，这里先把隐藏层 _ 设置为 ，表示有  个隐藏层，每层有  个神经元，关于这个值怎么设置，学问很大，我暂时还说不清楚，未来了解后再补充。另一个参数 _ 指定学习的结果存放的路径，如果存在则读取，不存在则创建，因为训练神经网络一般比较耗时，因此尽量将结果保存下来，这样即便中途中断，也可以恢复，如果格式不一样，比如特征列或者隐藏层数量不一样， 会报错。
 = _=_
                                                                                _=
                                                                                _=
然后就可以开始训练过程了，训练的过程可以每次生成一组新的训练数据，然后调用  函数训练  次，其中参数  表示输入值，参数  表示输出值。然后生成一组新的测试数据调用  函数进行评估，当  函数小于一定值的时候停止训练：   
__ = 
 
        _ =   _=
        _ = __
        =_=_ =

        _ =   _=
        _ = __
        _ = =_=_
         _

         _  __
                
不出意外的话，现在就可以开始训练了。最终训练的目的是为了给出指定的输入值，返回一个预测值，我们生成一组预测值，并且看看预测效果：
_ =   _=
_ = __
 预测输入  _
 实际结果  _
 预测值 _
完整代码如下：

=
   
   

_              日志级别设置成 ，避免干扰
_=                    打印内容不限制长度

_ =          变量数

要求的值
_ = =_
 _

 是输入量，对应 _，用于训练输入，在训练过程中，由外部提供，因此是  类型
 = =_
 = =

 是要求的各个参数的权重，是目标输出，对应 _
 = _=_     

_ = __
 = _=_
                                                                                _=
                                                                                _=

__ = 
 
        _ =   _=
        _ = __
        =_=_ =

        _ =   _=
        _ = __
        _ = =_=_
         _

         _  __
                

_ =   _=
_ = __
 预测输入  _
 实际结果  _
 预测值  _
这样训练大约  次后使用  大约需要  小时的时间， 函数会降低到  以内，得到的预测值和实际结果已经相差很小了。  

{  _ }
{  _ }
{  _ }
{  _ }
预测输入         
实际结果 
预测值
但是可以看到  函数并不是很稳定，可能突增或者突降，因为每次提供的训练数据太少了，我们可以通过提高  和  的大小来加快训练，同时提高训练效果，可以通过修改  和  矩阵大小来达到目的，修改后的代码如下：

=
   
   

_              日志级别设置成 ，避免干扰
_=                    打印内容不限制长度

_ =          变量数
_ =          每次训练的样本数

要求的值
_ = =_
_

 是输入量，对应 _，用于训练输入，在训练过程中，由外部提供，因此是  类型
 = =__
 = =_

 是要求的各个参数的权重，是目标输出，对应 _
 = _=_     

_ = __
 = _=_
                                                                                _=
                                                                                _=

__ = 

 
        _ =   __=
        _ = __
        =_=_ =

        _ =   __=
        _ = __
        _ = =_=_
         _

         _  __
                

_ =   __=
_ = __
预测输入  _
实际结果  _
预测值  _
同时跑上面  个训练，可以发现优化后的训练速度大大加快了， 函数降低很迅速。由于  函数是  个值的标准差，所以相应要提高一些。神经网络训练出来的结果不是一个 的矩阵，因此对于验证和预测输入，不能只是大小为 的矩阵，需要是大小为 的矩阵，所以在预测的时候，可以填充无效值，结果只取  的第一个值就好了。 在经过  次训练之后，得到了比较准确的预测效果：

{  _ }
{  _ }
{  _ }
{  _ }
{  _ }
{  _ }
{  _ }
预测输入          
           
           
          
           
           
          
          
          
          
          
          
          
          
          
          
           
          
          
           
实际结果  
   
   
   
   
   
   
   
   
  
  
  
   
  
  
   
   
   
  
   
预测值                   
通过函数传入训练数据
 还提供通过函数的方式传入输入数据，上面的例子是在  循环中将训练数据生成好传入，如果训练数据比较复杂或者不想将其与训练的代码耦合太大，可以将读取训练数据封装成一个函数传给 、 和 。 这个函数需要返回  个值，第一个返回值是输入，它是一个字典， 是特征列， 是特征值，第二个返回值是输入对应的输出值，比如上面的例子，可以这样构造训练集：
 __
        _ =   __=
        _ = __

        第一个参数是一个字典， 是变量名称， 是变量的值转成 
        _ = { _}

        第二个参数就是结果值，也要转成 
         __
传入到  的方式是这样的：
_= __ =
完整代码如下：

=
   
   

_              日志级别设置成 ，避免干扰
_=                    打印内容不限制长度

_ =          变量数
_ =          每次训练的样本数

要求的值
_ = =_

_

 是输入量，对应 _，用于训练输入，在训练过程中，由外部提供，因此是  类型
 = =__
 = =_

_ = __
 = _=_
                                                                                _=
                                                                                _=

 __
        _ =   __=
        _ = __

        第一个参数是一个字典， 是变量名称， 是变量的值转成 
        _ = { _}

        第二个参数就是结果值，也要转成 
         __

 __
        _ =   __=
        _ = __

        _ = { _}
         __

 __
        _ =   __=
        _ = { _}
        _ = __
        预测输入  _
        实际结果  _
         _

__ = 
 
        _= __ =
        _ = _= __=
        _

         _  __
                

 = _= __
预测结果  
在训练了  次后， 函数降低到了  以内：


{  _ }
{  _ }
{  _ }
{  _ }
{  _ }
{  _ }
{  _ }
{  _ }
{  _ }
{  _ }
预测输入         
          
          
           
          
          
          
          
           
          
          
          
          
          
           
          
          
           
           
          
实际结果  
   
   
   
   
  
  
   
   
  
   
   
   
  
   
   
  
   
   
   
预测结果                   
因为预测需要提供  组数据，如果我们只需要预测一组怎么办呢？可以在全  矩阵中，只设置第一行的值：
 __
        _ =   __=
        _ =   __=
        _ = 
        _ = { _}
        _ = __
        预测输入  _
        实际结果  _
         _
这样预测出来的结果中，只取第一行的值就好了：
预测输入                 
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
实际结果 
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
预测结果                   
实际值是 ，预测值是 ，可见预测还是挺准确的。
参考资料

 王小草【深度学习】笔记第一弹神经网络
 
    


相关推荐
 入门：求  元一次方程 入门：使用分类器对数据进行分类前言
在微服务的架构下 产品或许会有上百个或上千个微服务。所以 当这些上百个或上千个微服务 同时都依赖于某个库  时 则当此共享的库 即使只是针对某个微服务做些很少量的修改 也可能会对其他上百个或上千个微服务 造成不可预期的影响。
但在实际的项目中 产品中的微服务又无法避免的会对某些库  产生依赖 共享某些库 。
所以 架构师必需要知道要如何管理微服务间的共享。
本文
微服务会形成共享的原因 主要是来自于

微服务共同继承于某个抽象的接口。
微服务同时依赖于某个共享的库 。

　
架构师可采用以下的四种方案 管理微服务间的共享
  
将多个微服务会共享的代码 置入在一共享的项目中。在编译的时候 共享的代码便与特定的微服务的代码编译在一起。此种方案 从开发的角度 其好处是显而易见的 不需重启运维中的微服务 而是在编译 单元测试的时候 特定的微服务便可立即知道 在共享项目中的任何的修改或变更 对微服务自身的影响为何 
然而   却存在著个严重的问题 当共享的项目与数十个、上百个微服务是   时 则有的微服务可编译 可测试通过 可发布、有的微服务却发生了无法编译 或测试不通过、有的微服务则发生了无法发布 真的是一场灾难。更糟糕的是 当灾难发生时 各个微服务也没法对所共享的项目 有任何的选择权或控制权 各个微服务无法选择自身所要的共享项目的版本。 
 
    
各微服务间共享著编译 构建后的包    如 包。
此方案最大的好处便是 各个微服务间对其所共享的   拥有所谓的选择权 也就是说 某个微服务可选择  版的  另一个微服务则可以选择  版的 。当然 缺点是 当有数十个、上百个 甚至是上千个微服务共享某个发生变更的   时 则这些为数众多的微服务便得一一的重新启动后 才能执行测试 才能得知   的改变 对各个微服务的影响。
  应尽量的能细分到某一特殊功能的粒度 如 某一庞大的  应细分为   。某一大而全的  亦应细分为 。这样的细分粒度 将有利于能更精确的分析出   在每个版本中到底变更些了什么 各微服务针对这些变更 所应采取的相对应的措施为何

 
将各微服务都会用到模块 代码   到各个微服务中。
此方案虽然违背了     但却使得每个微服务维持了自身的边界上下文   而使得产品中的数百个或甚至数千个微服务间的依赖降低 产品中的数百个或甚至数千个微服务间的依赖越少 各微服务便得以更高效的方式进行开发、测试、发布。
当然 架构师必需要确保  到各个微服务中的模块 代码 的质量是稳定的与变更的频率是不高的。因为 任何一个质量上的缺陷或任意的变更 将会造成数百个或甚至数千个微服务维护的工作量。   

  
当某个  如 某个 被多个微服务所共用时 则当此   有变更时 多个共用此   的微服务 将必需再次的被测试 再次的被发布。架构师此时应重新的思考 这些共用   的微服务 那些或全部可与   合并为一单一的微服务 合并后 将可减化   变更后的测试与发布的复杂度与工作量。

结论
一个相当基本却相当重要的思维 当产品采用微服的架构时 我们绝不能只是遵循著微服务的定义 将产品微服务化。而是应该在团队开发的效率、产品的质量与微服务的边界上下文   之间  作一权衡、作一考量。
在管理微服务间的共享 我们提供了四个架构方案 期望大家能在权衡、考量 团队开发的效率、产品的质量与微服务的边界上下文   后 能从中找到最 适合 自身产品的架构方案。前言
由于本文与上一篇检测篇一——猫脸检测具有知识上的连贯性，所以建议没读过前一篇的先去阅读一下前一篇，前面讲过的内容这里会省略掉。
笑脸检测
其实也没什么可省略的，因为跟在中，无论是人脸检测、人眼检测、猫脸检测、行人检测等等，套路都是一样的。正所谓：
自古深情留不住，总是套路得人心。
发挥主要作用的函数有且仅有一个：。前一篇猫脸检测中已经提到过这个函数，这里就不再详细赘述。
这里只说一下笑脸检测的流程，显然也都是套路：
加载人脸检测器进行人脸检测
 加载笑脸检测器进行笑脸检测
检测的时候用的都是同一个函数，也即上述函数。这里需要注意的一点是：

笑脸检测是在人脸检测之后得到的人脸区域中进行的。我猜它用到的算法很可能是检测人的嘴角的姿态，因为笑脸检测最后的输出结果就是框住了人上扬的嘴角。

效果展示

更多
这么多内容作为一篇的话我觉得是不是略少？那就加点内容吧，我把上面的内容用有写了一遍，不同于上面的直接检测图片，版本是调用摄像头来检测自己的笑脸。
代码获取
分别是想要亲自尝试一下的朋友可以从我的上获取代码。
版本：
版本：
代码
  = 
 

 人脸检测器
 = _
 = 

 笑脸检测器
 = _
 = 

 =   
 =  _

 首先检测人脸，返回的是框住人脸的矩形框
 = 
    
    = 
    =
    = 
    =__


 画出每一个人脸，提取出人脸所在区域
      
            
    _ =  
    _ =  

     对人脸进行笑脸检测
     = 
        _
        = 
        =
        = 
        =__
    

     框出上扬的嘴角并对笑脸打上标签
          
        _        
               _

 

 = 

Ｃ＋＋代码
\  
   
   

  
  

 __ = __
 __ = _
 _     
 _   
 _ =    

 
{
       
       

     ___
    {
           \ 
         
    }
     ___ 
    {
           \ 
         
    }

           
      
      
    { 
           \ 
          
    }  

     
    {
         
        {
                  
            
        }

         
         _

         _ _
        _ _
        __    __

         _  =     
        {
                   

              = _
             

                 
            _    __

             _  =     
            {
                        
                       
            }
        }
              
        _ 
        _ 
        
    }
      = 
      ==  {   } 

     
}嘉宾：黄明编辑：转载自：前线

摘要
年月，腾讯正式开源面向机器学习的第三代高性能计算平台 ，在上备受关注；年月日，腾讯专家黄明将为上海的听众奉上一场  的精彩分享。作为的主要开发者和团队负责人，同时也是的早期研究者和布道者，他的工作经历可以说同步了通用大数据平台到专用机器学习平台的转变历程。因此，在这之前，对黄明的进行了一次采访问答，他将与大家分享人工智能时代的大数据平台演进之路，并结合的开发经验，谈谈如何打造一个优秀的机器学习平台，以及开源后的最新消息和未来规划。
开源地址： 
人工智能到底会给企业带来什么？——是改变，机遇，还是更大的挑战？
在之前的大数据时代，企业开始意识到数据的重要性并着手搭建自己的大数据平台，大数据成为业界关注的焦点，、等等各式各样的大数据框架、组件、平台层出不穷。随着人工智能时代来临，大数据平台发生了新的变化，也提出了更高的要求。等大数据平台多是为通用数据处理而设计的，并非专用于机器学习任务，企业该如何更好地利用机器学习、深度学习等人工智能技术从实时数据中高效挖掘有价值的信息？
在过去的两年，随着机器学习、特别是深度学习在多个领域取得革命性成功，各种专用的机器学习平台应运而生，百花齐放。也是其中的一员。为此，我们对其进行了采访。
人工智能时代，大数据平台的演进之路
：您不仅是的主要开发者和团队负责人，还是的早期研究者和布道者，并且一直从事分布式计算和机器学习领域的开发工作。能否结合您的工作经历，为我们介绍一下通用大数据平台到专用机器学习平台的演进历程？是什么推动了这一转变？您认为将来大数据中心的大多数任务会变成机器学习任务吗？
黄明： 其实推动这一转变的，本质上是人们对更高层面的追求所驱动的。从了解过去，到预知未来；从有限空间的穷举，到无限空间的探索；从有监督的训练，到无监督的自我学习……无论是企业高管，还是产品用户，大家都希望能得到更加智能的服务，而也只有提供了这种服务级别的的产品和公司，才能在残酷的互联网竞争中胜出。
年，业界的大数据刚刚兴起，当时有很多受欢迎的项目都是统计类的，可以告诉大家昨天最流行的是什么。底层的框架是和，很多平台的最大的功能就是出各种各样的报表，天报表、月报表……这时的层次是知道发生了什么。
年，当时有两个大发展方向，一种是更快的，一种是机器学习，涌现了很多的开源项目。能够胜出，是因为它在两者中间取得了均衡，并展现了机器学习的潜质。 等人在的 提到了，的目标是为了解决 和   这两类问题，这个判断从现在来看，依然是正确的。后来普及开来，目前很多公司依然会把当成他们首选的通用数据处理平台兼机器学习平台。这是人们希望知道，即将发生什么。
到了年，李沐等人在关于 的中，给出了分布式机器学习一个更好的思路，后面和的就出来了。当时的跟进不是很到位，而且本身的理念和也有些冲突。我们当时还给提过一个，后来也没被接受，但是引出了。到现在为止，官方的依然以为核心来实现机器学习算法，这是个很大的约束和障碍。
但是在年，的发展也受到了深度学习的冲击，随着的出现，大家纷纷转向了深度学习的框架开发。包括微软的转向，的转向……但是实际上，很多公司的数据中心依然有大量机器，大量的非深度学习算法还是需要在大规模数据集上进行分布式训练，这个领域是有空缺的，深度学习替代不了。
腾讯是年开始调研和开发，其目的就是为了填补上面所说的空缺，年，开始在内部使用，到了年，终于开源，整个开源的过程还是很不容易的。希望还是能把这块的空白填补上，成为一个专用的分布式机器学习平台，服务更多的公司内外产品，推动人们对更高层次的追求。
最后，未来数据中心，相信依然会有很多数据处理任务的任务。因为无论什么样的模型和算法，其前提都要建立在干净的数据之上。脱离了完整的数据预处理流程，谈机器学习和人工智能都是不现实的。但是大部分数据任务，它们的最终出口和末端，也将会是机器学习和人工智能的任务，因为如果没有了这个终点，前面的数据处理，也将是毫无意义的，能把控住末端的人，才是最终的胜利者。
：大数据平台早期多以离线批处理为主，实时计算作为补充，但是现在越来越多应用场景对数据处理有了高时效性的要求。腾讯大数据平台也历经了离线计算、实时计算、机器学习三个阶段的发展。未来批处理计算和实时流式计算在企业构建平台的基础架构中将分别起到什么作用？
黄明：对一个高科技企业来说，实时计算能力和机器学习能力，都是能力的基础，确实是必备的。而且机器学习的训练和推理两个阶段的重要性会并驾齐驱，实时计算能力的优势还将进一步辐射到推理场景。但是这并不代表离线批量计算不重要了，尤其是训练阶段，离线批量计算依然是主要场景，原因是：
好的模型需要大量的数据，反复迭代并达到一定的精确度才能上线，尤其是效果好的深度学习模型，通常需要多张卡，训练较长的时间，才能完成，所以这里高性能的分布式机器学习平台，必不可少。
有很多的算法和场景不支持实时更新，本身就存在约束，或者数学证明不成立，或者不支持流式叠加，所以模型还是需要离线训练好之后，再推送到手机端或者其它终端设端。
在线学习 这个领域，模型的持续优化和更新的非常重要，但是总是需要一个基础模型，而这个基础模型的质量，很重要的制约了后续的改进效果。
综合以上点，离线批量处理，依然会是非常重要和核心的场景，不可替代。但是实时流式计算会快速发展，尤其是在推理阶段。主要是因为在深度学习时代：
模型比以前复杂，从浅层模型变成了深度模型，其推理计算不是简单的代数计算。
传输数据比之前大，输入很可能是图片、声音、文本等，对吞吐量要求很高，而对推理过程依然要求在毫秒级别完成。这对推理的性能有更高的要求。
所以相信在未来年，这方面，从硬件到软件都将会涌现出很多优秀的初创公司。
一个优秀的机器学习平台是如何炼成的
：计算是机器学习平台的基础，但不是全部，在你看来，一个优秀的机器学习平台需要具备哪些特性？
黄明： 在机器学习界，有些人喜欢把调参和训练的过程，比喻为炼丹， 上升到”道”的层面。而道器相融，在我看来，那炼丹就需要一个好的丹炉了，也就是一个优秀的机器学习平台。它需要能为炼丹提供合适的火候，也就是为创新的模型和算法提供最佳的运行环境。因此，一个机器学习平台要取得成功，最好具备如下五个特点：
 精辟的核心抽象
一个机器学习平台，必须有其灵魂，也就是它的核心抽象。当这个核心抽象和它要面对的模型和算法匹配时，这个平台就成功了一半。如果一开始就错误了，例如作为平台的核心抽象，那么对后期的发展制约将会非常明显，无异于缘木求鱼，无论怎么努力都不会成功的。
的核心抽象，很好的解决了分布式大数据的通用问题；而中、 和 的个核心抽象，高度概括了深度学习中的各个元素。目前的核心抽象是，重点解决了分布式机器学习中模型切分，数据并行和模型并行，模式异步 这大问题，基本上可以满足大部分非深度学习的机器学习需求。
 充分的性能优化
在核心抽象正确的大前提下，性能是决定速度的关键。这就涉及了到平台层对硬件层的理解、调优和封装。去年我们用台高性能机器，获得了比赛的冠军，也是这种性能优化能力的体现，并将其嫁接到了之上。

现在已经不是的时代走海量低配机器路线。无论是机器，还是机器，都在往更强更快的方向走。去年比赛我们用的是很高性能的单机，包括的，的内存，多个的，的网络……都是业界的顶配。
但是光有硬件堆砌是不够的，平台要对硬件有充分的利用。对于非深度学习，系的莫过于的调优了。怎样更好地使用内存，避免的产生，尽量让计算不落地，预读数据流水化处理……这些都是对平台设计的考验。而对于深度学习，和的性能利用，显存和内存的数据拷贝，浮点运算和定点运算的选择，一机多卡的内部通讯……平台都需要进行很多调整，甚至于引入像这样的黑科技。
 既然是分布式机器学习平台，肯定会涉及到分布式的拓扑结构。目前来看，比较成熟的分布式拓扑结构依然是、、这者。机器学习中，基本上已经出局了，凭借深度学习卷土重来，和分庭抗礼，当然也有整体用、局部用的做法，这也未尝不可。在确定网络拓扑之后，就要考虑网络加速了。和这个关键技术很值得关注，也是未来的方向。毕竟数据是直接显存落显存，还是走两次内存，差别是可想而知的，再加上不需要开销，对性能带来的影响还是很可观的。

所有这些优化，最后暴露给平台用户的，最好是越简单越好，平台能够依据简单的参数，自动选择最佳的性能通道，这才是对算法工程师和数据科学家意义最大的。
 强大的容错能力
谈到容错，不得不再提一下和。在时代，海量低配机器理论的盛行，使被打压得很厉害。但是到了深度学习时代，大家发现这些高配机器和也差不了太多，十几万一台的机器，可靠性还是很强的，出错的概率很低，相比之下性能更加重要了，所以这种模式又活了过来。
都是从整体来看，规模上去之后，在大型的数据中心，高配版本的机器和级别的训练数据，对容错性依然需要取得一定的均衡，这种情况下模式仍是最合适的。整体架构包括网络的通讯性能是最灵活和鲁棒的，可以做的容灾措施很多，代价也小。最终能够达到的效果会远胜于简单的定期。
 灵活的接口设计
正如大家所知，年已经借助人工智能成为了第一编程语言。这在某种程度上，当然归功于和的神助攻，但是这个趋势背后有其必然原因。语言的优势在于语法简单、上手难度低，而且资源丰富，有充实的数据、可视化和机器学习算法库，建立了非常良好的生态环境，同时它又能与无缝结合，借助还能和结合。基于以上原因，能够为后台强劲的平台提供友好的接口层，达到简约而不简单的效果，也就难怪它会奇军突起、一枝独秀了。
但其实始终只是后台接口的体现，决定整体的，还是后台的接口设计，这时架构师的整体设计能力就非常重要了。核心理念的封装和延伸、多个机器学习概念的整合、系统的分层和解耦、多个子系统的一致性，这些最终都会体现到接口上，从而决定用户基于接口编写算法的难度。
 完善的周边系统
开源之初，吸引眼球的工具之一，莫过于它的，惊艳的超越了同期产品。当时还怀疑它是否会部分开源，不开源这个模块。一个好的机器学习平台还是要在周边系统的完善上多做些功夫，如果用户基于你的平台，可以快速地调试和定位，将会大大增强他们使用的信心，这会对用户形成很强的吸引力，最终也有助于形成更好的生态 。
接《道器相融，由  谈一个优秀机器学习平台的自我修养下》作者 | 郭诗雅编辑 | 京露

郭诗雅，华南理工大学计算机科学与技术硕士，目前就职于腾讯社交用户体验设计部 担任开发工程师。

背景
首先简单介绍一下，是用写的基于的第三方库，通过它可以在网页中进行建模，结合上动画库，在网页中实现动画效果就变得很简单了。
这是建模的简单流程图例：

用通俗的话来讲，首先可以用创建各种形状的几何体，或者从外部导入建好的模型文件，然后为几何体添加材质纹理、颜色等，就组成了一个网格模型，我们可以创建很多的模型，塞进场景容器里，还要为场景加入灯光，通过“打光”照相机才能拍到场景里面的物体，当要拍摄动态场景时，就需要照相机不断的拍摄然后通过渲染器不停地渲染到屏幕上渲染循环，最后屏幕展现的就是一个动态场景。
既然是通过照相机去拍摄场景，让我们在屏幕上可以看到，那么移动照相机用不同的角度拍摄这个世界，自然就可以看到不一样的世界了。
中的
中的分为两种，一种是正投影相机，一种是透视投影相机，两种的大致区别是：

图片来自中文网
在透视投影下，同样大小的物体，在屏幕下远处的物体会比近处的物体小，而正投影下两者是一样大小的。
在本例中，我们用的是透视投影，实例化代码如下：
 =       
四个参数分别表示视角，看到的窗口宽度和高度的比例，能看到的最近处的距离，和能看到的最远处的距离。视角越大，拍摄到的场景范围就越大，能看到的物体就显得越小。
接着便是位置的设置，在初始化时，一般都会先设置好它的个属性，以为例讲解一下这三个属性。在这之前，我们先了解一下的坐标系，使用的是右手坐标系，如下图所示：

就是这么有气质的手势大拇指指向轴正方向，食指指向轴正方向，中指指向轴正方向。
再回来看看的初始化代码：
 = 
 = 
 = 
 = 
 = 
 = 
{        }

 顾名思义，就是在坐标系中的所在位置，处于轴正方向上离原点处。

比较难理解，指的是“头顶”的方向和向量，，同向，即和轴正方向同向。画个图理解一下：




 指的就是面向哪里，这里是直接面向原点。

另外，设置的方向必须与位置和的连线不能平行，否则拍不到场景，这个大家自己可以摆摆手势体会一下～
实现过程－计算
准备过程
在初始化后，创建我们需要的物体，在这里我随机创建了几个正方体，它们的大小和位置都是随机的，面向屏幕的一面加载了一张图片纹理，作为正面，如下图所示：

如果从轴正方向往轴负方向看，示意图大致是这样子的蓝色代表正方体，有粗线加箭头的一面代表正方体有图片的正面，黑色的圆柱体代表照相机，箭头指明拍摄方向：

 接下来便是动画过程，需要注意的是，接下来的都是物体只绕方向旋转，方向只做位移，这样就把一个三维空间的运动转化为二维空间了～～
将照相机移到轴上，旋转正方体和照相机使之正对，如下图所示：
 
在初始化时，我们便记录了正方体的坐标值，正方体从面向屏幕到面向轴要旋转多少角度，我这里用了初中数学方法——反三角函数算出。如下图所示分别为四个象限物体需要旋转的角度值。

旋转了正方体后，照相机只要和正方体旋转同样的角度，并坐标中的值移到和正方体同向，就可以拍摄到正方体正面了。

因为之前所说的正方体是大小不一的，需要移动照相机使得照相机和正方体的距离与正方体的大小保持一定的比例，这样看到每个正方体的大小才是一致的。所以需要计算照相机的位移，如下图：


我们已知正方体的边长，假设照相机与正方体中心点的距离设置为，利用相似三角形边长等比例的原理得出照相机的该移到的地方坐标，公式如下：


为了让正方体具备随机摆放的感觉，还可以让正方体再绕方向随机转动一定角度，照相机再绕正方体的中心点旋转到正对正方体正面的位置：


计算方法如下：

如上图所示，照相机原来是在正方体中心和原点的连线上的坐标，绕正方体的中心点旋转随机角度θ后得到的的计算公式如下： 

以上的角度计算过程，都可以用中强大的函数搞定，包括\等等，具体代码就不贴了。
实现过程－动画
上面过程中的第、步，直接调用的动画库，控制就可以了。但是第步由于不能想一样直接设定为正方体中心点，所以必须自己实现。例如控制位移：


      指明控制的属性
     动画时间
    { } 需要移动的距离

这里用到的是来实现，通过一点点地改变的旋转和位置的移动，直到达到角度θ。
   旋转频率
 {
     
    当物体的旋转角度大于
        {
         =   
         = {
              =          
              =          
             = 
             = 
             = 
             = 
        }{
            
        }
    当物体的旋转角度小于
    }{
         代码和大于时相似
        }{
            
        }
    }
      {
         =   
    }
}
总结
通过只改变里的，就可以做很多动效啦～～～
贴上地址：  有些时候角度和正方体的随机性太强控制不住它寄几，欢迎各位大大提出指正和优化！！

相关推荐
【腾讯】再不建模你就了【腾讯】基于模型的自动化测试工具——